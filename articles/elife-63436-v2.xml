<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">63436</article-id><article-id pub-id-type="doi">10.7554/eLife.63436</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Optimal policy for attention-modulated decisions explains human fixation behavior</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-208611"><name><surname>Jang</surname><given-names>Anthony I</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3073-8228</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-209478"><name><surname>Sharma</surname><given-names>Ravi</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-199772"><name><surname>Drugowitsch</surname><given-names>Jan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7846-0408</contrib-id><email>jan_drugowitsch@hms.harvard.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Neurobiology, Harvard Medical School</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Division of Biostatistics and Bioinformatics, Department of Family Medicine and Public Health, UC San Diego School of Medicine</institution><addr-line><named-content content-type="city">La Jolla</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Tsetsos</surname><given-names>Konstantinos</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>26</day><month>03</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e63436</elocation-id><history><date date-type="received" iso-8601-date="2020-09-24"><day>24</day><month>09</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-03-17"><day>17</day><month>03</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Jang et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Jang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-63436-v2.pdf"/><abstract><p>Traditional accumulation-to-bound decision-making models assume that all choice options are processed with equal attention. In real life decisions, however, humans alternate their visual fixation between individual items to efficiently gather relevant information (Yang et al., 2016). These fixations also causally affect one’s choices, biasing them toward the longer-fixated item (Krajbich et al., 2010). We derive a normative decision-making model in which attention enhances the reliability of information, consistent with neurophysiological findings (Cohen and Maunsell, 2009). Furthermore, our model actively controls fixation changes to optimize information gathering. We show that the optimal model reproduces fixation-related choice biases seen in humans and provides a Bayesian computational rationale for this phenomenon. This insight led to additional predictions that we could confirm in human data. Finally, by varying the relative cognitive advantage conferred by attention, we show that decision performance is benefited by a balanced spread of resources between the attended and unattended items.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>visual attention</kwd><kwd>diffusion models</kwd><kwd>optimality</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH115554</award-id><principal-award-recipient><name><surname>Drugowitsch</surname><given-names>Jan</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000913</institution-id><institution>James S. McDonnell Foundation</institution></institution-wrap></funding-source><award-id>220020462</award-id><principal-award-recipient><name><surname>Drugowitsch</surname><given-names>Jan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A normative decision-making model that incorporates an information-limiting attention bottleneck is able to qualitatively replicate human behavior and make novel predictions that are verified in data.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Would you rather have a donut or an apple as a mid-afternoon snack? If we instantaneously knew their associated rewards, we could immediately choose the higher-rewarding option. However, such decisions usually take time and are variable, suggesting that they arise from a neural computation that extends over time (<xref ref-type="bibr" rid="bib46">Rangel and Hare, 2010</xref>; <xref ref-type="bibr" rid="bib51">Shadlen and Shohamy, 2016</xref>). In the past, such behavior has been modeled descriptively with accumulation-to-bound models that continuously accumulate noisy evidence from each choice option, until a decision boundary is reached in favor of a single option over its alternatives. Such models have been successful at describing accuracy and response time data from human decision makers performing in both perceptual and value-based decision tasks (<xref ref-type="bibr" rid="bib47">Ratcliff and McKoon, 2008</xref>; <xref ref-type="bibr" rid="bib39">Milosavljevic et al., 2010</xref>). Recently, we and others showed that, if we assume these computations to involve a stream of noisy samples of each item’s perceptual feature (for perceptual decisions) or underlying value (for value-based decisions), then the normative strategy could be implemented as an accumulation-to-bound model (<xref ref-type="bibr" rid="bib9">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib20">Drugowitsch et al., 2012</xref>; <xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>). Specifically, the normative strategy could be described with the diffusion decision model (<xref ref-type="bibr" rid="bib47">Ratcliff and McKoon, 2008</xref>) with time-varying decision boundaries that approach each other over time.</p><p>Standard accumulation-to-bound models assume that all choice options receive equal attention during decision-making. However, the ability to drive one’s attention amidst multiple, simultaneous trains of internal and external stimuli is an integral aspect of everyday life. Indeed, humans tend to alternate between fixating on different items when making decisions, suggesting that control of overt visual attention is intrinsic to the decision-making process (<xref ref-type="bibr" rid="bib36">Kustov and Robinson, 1996</xref>; <xref ref-type="bibr" rid="bib43">Mohler and Wurtz, 1976</xref>). Furthermore, their final choices are biased toward the item that they looked at longer, a phenomenon referred to as a choice bias (<xref ref-type="bibr" rid="bib53">Shimojo et al., 2003</xref>; <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib15">Cavanagh et al., 2014</xref>). While several prior studies have developed decision-making models that incorporate attention (<xref ref-type="bibr" rid="bib66">Yu et al., 2009</xref>; <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib61">Towal et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Cassey et al., 2013</xref>; <xref ref-type="bibr" rid="bib26">Gluth et al., 2020</xref>), our goal was to develop a normative framework that incorporates control of attention as an integral aspect of the decision-making process, such that the agent must efficiently gather information from all items while minimizing the deliberation time, akin to real life decisions. In doing so, we hoped to provide a computational rationale for why fixation-driven choice biases seen in human behavior may arise from an optimal decision strategy. For example, the choice bias has been previously replicated with a modified accumulation-to-bound model, but the model assumed that fixations are driven by brain processes that are exogenous to the computations involved in decision-making (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>). This stands in contrast to studies of visual attention where fixations appear to be controlled to extract choice-relevant information in a statistically efficient manner, suggesting that fixations are driven by processes endogenous to the decision (<xref ref-type="bibr" rid="bib65">Yang et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Hoppe and Rothkopf, 2016</xref>; <xref ref-type="bibr" rid="bib27">Hayhoe and Ballard, 2005</xref>; <xref ref-type="bibr" rid="bib16">Chukoskie et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">Corbetta and Shulman, 2002</xref>).</p><p>We asked if the choice bias associated with fixations can be explained with a unified framework in which fixation changes and decision-making are part of the same process. To do so, we endowed normative decision-making models (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>) with attention that boost the amount of information one collects about each choice option, in line with neurophysiological findings (<xref ref-type="bibr" rid="bib3">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib17">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib41">Mitchell et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Wittig et al., 2018</xref>). We furthermore assumed that this attention was overt (<xref ref-type="bibr" rid="bib45">Posner, 1980</xref>; <xref ref-type="bibr" rid="bib25">Geisler and Cormack, 2012</xref>), and thus reflected in the decision maker’s gaze which was controlled by the decision-making process.</p><p>We first derive the complex normative decision-making strategy arising from these assumptions and characterize its properties. We then show that this strategy featured the same choice bias as observed in human decision makers: it switched attention more frequently when deciding between items with similar values, and was biased toward choosing items that were attended last, and attended longer. It furthermore led to new predictions that we could confirm in human behavior: choice biases varied based on the amount of time spent on the decision and the average desirability across both choice items. Lastly, it revealed why the observed choice biases might, in fact, be rational. Overall, our work provides a unified framework in which the optimal, attention-modulated information-seeking strategy naturally leads to biases in choice that are driven by visual fixations, as observed in human decisions.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>An attention-modulated decision-making model</title><p>Before describing our attention-modulated decision-making model, we will first briefly recap the attention-free value-based decision-making model (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>) that ours builds upon. This model assumes that for each decision trial, a true value associated with each item (<italic>z</italic><sub>1</sub>,<italic>z</italic><sub>2</sub>) is drawn from a normal prior distribution with mean <inline-formula><mml:math id="inf1"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf2"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>. Therefore, <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for both <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The smaller the <inline-formula><mml:math id="inf5"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, the more information this prior provides about the true values. We assume the decision maker knows the shape of the prior, but can’t directly observe the drawn true values. In other words, the decision maker a priori knows the range of values associated with the items they need to compare, but does not know what exact items to expect nor what their associated rewards will be. For example, one such draw might result in a donut and an apple, each of which has an associated value to the decision maker (i.e. satisfaction upon eating it). In each <italic>n</italic>th time step of length <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, they observe noisy samples centered around the true values, called <italic>momentary evidence</italic>, <inline-formula><mml:math id="inf7"><mml:mrow><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. In <xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref> , the variance of the momentary evidence was <inline-formula><mml:math id="inf8"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> rather than <inline-formula><mml:math id="inf9"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. We here added the factor 2 without loss of generality to relate it more closely to the attention-modulated version we introduce further below. The variance <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> here controls how informative the momentary evidence is about the associated true value. A large <inline-formula><mml:math id="inf11"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> implies larger noise, and therefore less information provided by each of the momentary evidence samples. While the model is agnostic to the origin of these samples, they might arise from computations to infer the items’ values (e.g. how much do I currently value the apple?), memory recall (e.g. how much did I previously value the apple?), or a combination thereof (<xref ref-type="bibr" rid="bib51">Shadlen and Shohamy, 2016</xref>). As the decision maker’s aim is to choose the higher valued item, they ought to accumulate evidence for some time to refine their belief in the items’ values. Once they have accumulated evidence for <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> seconds, their posterior belief for the value associated with either item is<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf13"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the accumulated evidence for item <inline-formula><mml:math id="inf14"><mml:mi>j</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>). The mean of this posterior (i.e. the first fraction in brackets) is a weighted sum of the prior mean, <inline-formula><mml:math id="inf15"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula>, and the accumulated evidence, <inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The weights are determined by the accumulation time (<inline-formula><mml:math id="inf17"><mml:mi>t</mml:mi></mml:math></inline-formula>), and the variances of the prior (<inline-formula><mml:math id="inf18"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>) and the momentary evidence (<inline-formula><mml:math id="inf19"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>), which control their respective informativeness. Initially, <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf21"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, such that the posterior mean equals that of the prior, <inline-formula><mml:math id="inf22"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula>. Over time, with increasing <inline-formula><mml:math id="inf23"><mml:mi>t</mml:mi></mml:math></inline-formula>, the influence of <inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> becomes dominant, and the mean approaches <inline-formula><mml:math id="inf25"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> (i.e. the average momentary evidence) for a large <inline-formula><mml:math id="inf26"><mml:mi>t</mml:mi></mml:math></inline-formula>, at which point the influence of the prior becomes negligible. The posterior’s variance (i.e. the second fraction in brackets) reflects the uncertainty in the decision maker’s value inference. It initially equals the prior variance, <inline-formula><mml:math id="inf27"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, and drops toward zero once <inline-formula><mml:math id="inf28"><mml:mi>t</mml:mi></mml:math></inline-formula> becomes large. In this attention-free model, uncertainty monotonically decreases identically over time for both items, reflecting the standard assumption of accumulation-to-bound models that, in each small time period, the same amount of evidence is gathered for either choice item.</p><p>To introduce attention-modulation, we assume that attention limits information about the unattended item (<xref ref-type="fig" rid="fig1">Figure 1</xref>). This is consistent with behavioral and neurophysiological findings showing that attention boosts behavioral performance (<xref ref-type="bibr" rid="bib17">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib18">Cohen and Maunsell, 2010</xref>; <xref ref-type="bibr" rid="bib62">Wang and Krauzlis, 2018</xref>) and the information encoded in neural populations (<xref ref-type="bibr" rid="bib44">Ni et al., 2018</xref>; <xref ref-type="bibr" rid="bib49">Ruff et al., 2018</xref>; <xref ref-type="bibr" rid="bib63">Wittig et al., 2018</xref>). To achieve this, we first assume that the total rate of evidence across both items, as controlled by <inline-formula><mml:math id="inf29"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, is fixed, and that attention modulates the relative amount of information gained about the attended versus unattended item. This 'attention bottleneck' is controlled by <inline-formula><mml:math id="inf30"><mml:mi>κ</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf31"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>κ</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), such that <inline-formula><mml:math id="inf32"><mml:mi>κ</mml:mi></mml:math></inline-formula> represents the proportion of total information received for the unattended item, versus <inline-formula><mml:math id="inf33"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula> for the attended item. The decision maker can control which item to attend to, but has no control over the value of <inline-formula><mml:math id="inf34"><mml:mi>κ</mml:mi></mml:math></inline-formula>, which we assume is fixed and known. To limit information, we change the momentary evidence for the attended item <inline-formula><mml:math id="inf35"><mml:mi>j</mml:mi></mml:math></inline-formula> to <inline-formula><mml:math id="inf36"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and for the unattended item <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf38"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>κ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore, if <inline-formula><mml:math id="inf39"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>≤</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>, the variance of the unattended item increases (i.e. noisier evidence) relative to the attended item. This makes the momentary evidence less informative about <italic>z</italic><sub><italic>k</italic></sub>, and more informative about <italic>z</italic><sub><italic>j</italic></sub>, while leaving the overall amount of information unchanged (see Materials and methods). Setting <inline-formula><mml:math id="inf40"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula> indicates equally informative momentary evidence for both items, and recovers the attention-free scenario (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Attention-modulated evidence accumulation.</title><p>(<bold>A</bold>) Schematic depicting the value-based decision-making model. When choosing between two snack items (e.g. apple versus donut), people tend to evaluate each item in turn, rather than think about all items simultaneously. While evaluating one item, they will pay less attention to the unattended item (blurred item). (<bold>B</bold>) Schematic of the value-based decision process for a single decision trial. At trial onset, the model randomly attends to one item (green box). At every time step, it accumulates momentary evidence (orange box) that provides information about the true value of each item, which is combined with the prior belief of each item’s value to generate a posterior belief. Note that the momentary evidence of the attended item comes from a tighter distribution. Afterwards, the model assesses whether to accumulate more evidence (orange), make a choice (black), or switch attention to the other item (green). (<bold>C</bold>) Evolution of the evidence accumulation process. The top panel shows momentary evidence at every time point for the two items. Note that evidence for the unattended item has a wider variance. The middle panel shows how the posterior estimate of each item may evolve over time (mean ± 1SD). The horizontal dotted lines indicate the unobserved, true values of the two items. The bottom panel shows how uncertainty decreases regarding the true value of each item. As expected, uncertainty decreases faster for the currently attended item compared to the unattended one. For this descriptive figure, we used the following parameters: <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>13</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf42"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf43"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf45"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig1-v2.tif"/></fig><p>Lowering information for the unattended item impacts the value posteriors as follows. If the decision maker again accumulates evidence for some time <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, their belief about item <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>’s value changes from <xref ref-type="disp-formula" rid="equ3">Equation (1)</xref> to<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>t</italic><sub>1</sub> and <italic>t</italic><sub>2</sub>, which sum up to the total accumulation time (<inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), are the durations that items 1 and 2 have been attended, respectively. The accumulated evidence <inline-formula><mml:math id="inf49"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> now isn’t simply the sum of all momentary pieces of evidence, but instead down-weights them by <inline-formula><mml:math id="inf50"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mi>κ</mml:mi></mml:mfrac></mml:math></inline-formula> if the associated item is unattended (see Materials and methods). This prevents the large inattention noise from swamping the overall estimate (<xref ref-type="bibr" rid="bib21">Drugowitsch et al., 2014</xref>). An analogous expression provides the posterior <inline-formula><mml:math id="inf51"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for item 2 (see Appendix 1).</p><p>The attention modulation of information is clearly observable in the variance of the value’s posterior for item 1 (<xref ref-type="disp-formula" rid="equ4">Equation 2</xref>). For <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>, this variance, which is proportional to the decision maker’s uncertainty about the option’s value, drops more quickly over time if item 1 rather than item 2 is attended (i.e. if <italic>t</italic><sub>1</sub> rather than <italic>t</italic><sub>2</sub> increases). Therefore, it depends on how long each of the two items have been attended to, and might differ between the two items across time (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). As a result, decision performance depends on how much time is allocated to attending to each item.</p><p>The decision maker’s best choice at any point in time is to choose the item with the larger expected value, as determined by the value posterior. However, the posterior by itself does not determine when it is best to stop accumulating evidence. In our previous attention-free model, we addressed the optimal stopping time by assuming that accumulating evidence comes at cost <inline-formula><mml:math id="inf53"><mml:mi>c</mml:mi></mml:math></inline-formula> per second, and found the optimal decision policy under this assumption (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>). Specifically, at each time step of the decision-making process, the decision maker could choose between three possible actions. The first two actions involve immediately choosing one of the two items, which promises the associated expected rewards. The third action is to accumulate more evidence that promises more evidence, better choices, and higher expected reward, but comes at a higher cost for accumulating evidence. We found the optimal policy using dynamic programming that solves this arbitration by constructing a value function that, for each stage of the decision process, returns all expected rewards and costs from that stage onward (<xref ref-type="bibr" rid="bib6">Bellman, 1952</xref>; <xref ref-type="bibr" rid="bib8">Bertsekas, 1995</xref>). The associated policy could then be mechanistically implemented by an accumulation-to-bound model that accumulates the difference in expected rewards, <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, and triggers a choice once one of two decision boundaries, which collapse over time, is reached (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>).</p><p>Once we introduce attention, a fourth action becomes available: the decision maker can choose to switch attention to the currently unattended item (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). If such a switch comes at no cost, then the optimal strategy would be to continuously switch attention between both items to sample them evenly across time. We avoid this physically unrealistic scenario by introducing a cost <italic>c</italic><sub><italic>s</italic></sub> for switching attention. This cost may represent the physical effort of switching attention, the temporal cost of switching (<xref ref-type="bibr" rid="bib64">Wurtz, 2008</xref>; <xref ref-type="bibr" rid="bib14">Cassey et al., 2013</xref>), or a combination of both. Overall, this leads to a value function defined over a four-dimensional space: the expected reward difference <inline-formula><mml:math id="inf55"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>, the evidence accumulation times <italic>t</italic><sub>1</sub> and <italic>t</italic><sub>2</sub>, and the currently attended item <inline-formula><mml:math id="inf56"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (see Appendix 1). As the last dimension can only take one of two values, we can equally use two three-dimensional value functions. This results in two associated policies that span the three-dimensional <italic>state space</italic><inline-formula><mml:math id="inf57"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Navigating the optimal policy space.</title><p>(<bold>A</bold>) The optimal policy space. The policy space can be divided into regions associated with different optimal actions (choose item 1 or 2, accumulate more evidence, switch attention). The boundaries between these regions can be visualized as contours in this space. The three panels on the right show cross-sections after slicing the space at different <inline-formula><mml:math id="inf58"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> values, indicated by the gray slices in the left panel. Note that when <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (middle panel), the two items have equal value and therefore there is no preference for one item over the other. (<bold>B</bold>) Optimal policy spaces for different values of <inline-formula><mml:math id="inf60"><mml:mi>y</mml:mi></mml:math></inline-formula> (currently attended item). The two policy spaces are mirror-images of each other. (<bold>C</bold>) Example deliberation process of a single trial demonstrated by a particle that diffuses across the optimal policy space. In this example, the model starts by attending to item 1, then makes two switches in attention before eventually choosing item 1. The bottom row shows the plane in which the particle diffuses. Note that the particle diffuses on the (gray, shaded) plane perpendicular to the time axis of the unattended item, such that it only increases in <italic>t</italic><sub><italic>j</italic></sub> when attending to item j. Also note that the policy space changes according to the item being attended to, as seen in (<bold>B</bold>). See results text for more detailed description. See <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> to view changes in the optimal policy space depending on changes to model parameters.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Changes in the optimal policy space and model behavior with adjustments in free model parameters.</title><p>Changes in the optimal policy space and model behavior with adjustments in free model parameters. The optimal policy space and its associated psychometric curves from the base model are shown in the top row. The policy space and psychometric curves corresponding to changes in single free parameters are shown in subsequent rows. In rows 2–4, psychometric curves from the base model on row 1 is shown in red for comparison.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig2-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Features of the optimal policy</title><p>At any point within a decision, the model’s current state is represented by a location in this 3D policy space, such that different regions in this space designate the optimal action to perform (i.e. choose, accumulate, switch). The boundaries between these regions can be visualized as contours in this 3D state space (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). As previously discussed, there are two distinct policy spaces for when the decision maker is attending to item 1 versus item 2 that are symmetric to each other (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><p>Within a given decision, the deliberation process can be thought of as a particle that drifts and diffuses in this state space. The model starts out attending to an item at random (<inline-formula><mml:math id="inf61"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), which determines the initial policy space (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Assume an example trial where the model attends to item 1 initially (<inline-formula><mml:math id="inf62"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). At trial onset, the decision maker holds the prior belief, such that the particle starts on the origin (<inline-formula><mml:math id="inf63"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) which is within the ‘accumulate’ region. As the model accumulates evidence, the particle will move on a plane perpendicular to <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, since <italic>t</italic><sub>2</sub> remains constant while attending to item 1 (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, first column). During this time, evidence about the true values of both items will be accumulated, but information regarding item 2 will be significantly noisier (as controlled by <inline-formula><mml:math id="inf66"><mml:mi>κ</mml:mi></mml:math></inline-formula>). Depending on the evidence accumulated regarding both items, the particle may hit the boundary for ‘choose 1’, ‘choose 2’, or 'switch (attention)'. Assume the particle hits the ‘switch’ boundary, indicating that the model is not confident enough to make a decision after the initial fixation to item 1. In other words, the difference in expected rewards between the two items is too small to make an immediate decision, and it is deemed advantageous to collect more information about the currently unattended item. Now, the model is attending to item 2, and the policy space switches accordingly (<inline-formula><mml:math id="inf67"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>). The particle, starting from where it left off, will now move on a plane perpendicular to the <italic>t</italic><sub>1</sub> axis (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, second column). This process is repeated until the particle hits a decision boundary (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, third column). Importantly, these shifts in attention are endogenously generated by the model as a part of the optimal decision strategy — it exploits its ability to control how much information it receives about either item’s value.</p><p>The optimal policy space shows some notable properties. As expected, the ‘switch’ region in a given policy space is always encompassed in the ‘accumulate’ region of the other policy space, indicating that the model never switches attention or makes a decision immediately after an attention switch. Furthermore, the decision boundaries in 3D space approach each other over time, consistent with previous work that showed a collapsing 2D boundary for optimal value-based decisions without attention (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>). The collapsing bound reflects the model’s uncertainty regarding the difficulty of the decision task (<xref ref-type="bibr" rid="bib20">Drugowitsch et al., 2012</xref>). In our case, this difficulty depends on how different the true item values are, as items of very different values are easier to distinguish than those of similar value. If the difficulty is known within and across choices, the boundaries will not collapse over time, and their (fixed) distance will reflect the difficulty of the choice. However, since the difficulty of individual choices varies and is a priori unknown to the decision maker in our task, the decision boundary collapses so that the model minimizes wasting time on a choice that is potentially too difficult.</p><p>The optimal model had five free parameters that affect its behavior: (1) variance of evidence accumulation (<inline-formula><mml:math id="inf68"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>), (2) variance of the prior distribution (<inline-formula><mml:math id="inf69"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>), (3) cost of evidence accumulation (<inline-formula><mml:math id="inf70"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), (4) cost of switching attention (<italic>c</italic><sub><italic>s</italic></sub>), and (5) relative information gain from the attended vs. unattended items (<inline-formula><mml:math id="inf71"><mml:mi>κ</mml:mi></mml:math></inline-formula>). The contour of the optimal policy boundaries changes in intuitive ways as these parameters are adjusted (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Increasing the noisiness of evidence accumulation (<inline-formula><mml:math id="inf72"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>) causes an overall shrinkage of the evidence accumulation space. This allows the model to reach a decision boundary more quickly under a relatively higher degree of uncertainty, given that evidence accumulation is less reliable but equally costly. Similarly, increasing the cost of accumulating evidence (<inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) leads to a smaller accumulation space so that the model minimizes paying a high cost for evidence accumulation. Increasing the switch cost <italic>c</italic><sub><italic>s</italic></sub> leads to a smaller policy space for the ‘switch’ behavior, since there is an increased cost for switching attention. Similarly, decreasing the inattention noise by setting <inline-formula><mml:math id="inf74"><mml:mi>κ</mml:mi></mml:math></inline-formula> closer to <inline-formula><mml:math id="inf75"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:math></inline-formula> leads to a smaller ‘switch’ space because the model can obtain more reliable information from the unattended item, reducing the necessity to switch attention. To find a set of parameters that best mimic human behavior, we performed a random search over a large parameter space and selected the parameter set that best demonstrated the qualitative aspects of the behavioral data (see Appendix 1).</p></sec><sec id="s2-3"><title>The optimal policy replicates human behavior</title><p>To assess if the optimal policy features the same decision-making characteristics as human decision makers, we used it to simulate behavior in a task analogous to the value-based decision task performed by humans in <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>. Briefly, in this task, participants first rated their preference of different snack items on a scale of −10 to 10. Then, they were presented with pairs of different snacks after excluding the negatively rated items and instructed to choose the preferred item. While they deliberate on their choice, the participants’ eye movements were tracked and the fixation duration to each item was used as a proxy for visual attention.</p><p>We simulated decision-making behavior using value distributions similar to those used in the human experiment (see Materials and methods), and found that the model behavior qualitatively reproduces essential features of human choice behavior (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). As expected in value-based decisions, a larger value difference among the compared items made it more likely for the model to choose the higher-valued item (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; <inline-formula><mml:math id="inf76"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>105.7</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Furthermore, the model’s mean response time (RT) decreased with increasing value difference, indicating that less time was spent on trials that were easier (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; <inline-formula><mml:math id="inf77"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>11.1</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Of note, while human RTs appeared to drop linearly with increasing value difference, our model’s drop was concave across a wide range of model parameters (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>). The model also switched attention less for easier trials, indicating that difficult trials required more evidence accumulation from both items, necessitating multiple switches in attention (<xref ref-type="fig" rid="fig3">Figure 3C</xref>; <inline-formula><mml:math id="inf78"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>8.10</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Since the number of switches is likely correlated with response time, we also looked at switch rate (number of switches divided by response time). Here, although human data showed no relationship between switch rate and trial difficulty, model behavior showed a positive relationship, suggesting an increased rate of switching for easier trials. However, this effect was absent when using the same number of trials as humans, and did not generalize across all model parameter values (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1D–G</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Replication of human behavior by simulated optimal model behavior (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>).</title><p>(<bold>A</bold>) Monotonic increase in probability of choosing item 1 as a function of the difference in value between item 1 and 2 (<inline-formula><mml:math id="inf79"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>105.7</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>B</bold>) Monotonic decrease in response time (RT) as a function of trial difficulty (<inline-formula><mml:math id="inf80"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>11.1</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). RT increases with increasing difficulty. (<bold>C</bold>) Decrease in the number of attention switches as a function of trial difficulty. More switches are made for harder trials (<inline-formula><mml:math id="inf81"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>8.10</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>D</bold>) Effect of last fixation location on item preference. The item that was fixated on immediately prior to the decision was more likely to be chosen. (<bold>E</bold>) Attention’s biasing effect on item preference. The item was more likely to be chosen if it was attended for a longer period of time (<inline-formula><mml:math id="inf82"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>5.32</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Since the probability of choosing item 1 depends on the degree of value difference between the two items, we normalized the p(choose item 1) by subtracting the average probability of choosing item 1 for each difference in item value. (<bold>F</bold>) Replication of fixation pattern during decision making. Both model and human data showed a fixation pattern where a short initial fixation was followed by a longer, then medium-length fixation. Error bars indicate standard error of the mean (SEM) across both human and simulated participants (<inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>39</mml:mn></mml:mrow></mml:math></inline-formula> for both). See <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> for an analogous figure for the perceptual decision task.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Parameter-dependence of psychometric/chronometric curves, and exploration of switch rate rather than switch number for the optimal model.</title><p>Parameter-dependence of psychometric/chronometric curves, and exploration of switch rate rather than switch number for the optimal model. (<bold>A–C</bold>) Psychometric (<bold>A,B</bold>) and chronometric (<bold>C</bold>) curves after decreasing the evidence noise term (<inline-formula><mml:math id="inf84"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) from 27 to 5. <xref ref-type="fig" rid="fig3">Figure 3</xref> suggests a qualitative difference in psychometric/chronometric curves between human and model behavior. For <xref ref-type="fig" rid="fig3">Figure 3A,D</xref>, the model’s psychometric curve appeared linear rather than sigmoidal. To show that this is a result of the difficulty of the task, as determined by the evidence noise term (<inline-formula><mml:math id="inf85"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>), and not a generalizable property of the model, we set (<inline-formula><mml:math id="inf86"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) in (<bold>A</bold>) and (<bold>B</bold>) to a lower value, in which case the model exhibits sigmoidal psychometric curves. This sigmoidal shape arises because the decision becomes easier at extreme value differences and approaches perfect performance. In <xref ref-type="fig" rid="fig3">Figure 3B</xref>, the model’s chronometric curve had a concave shape, whereas that of the humans appeared linear. As (<bold>C</bold>) shows, decreasing the noise term diminished, but did not eliminate this concave shape. (<bold>D</bold>) Human switch rate (number of switches divided by time) did not change significantly with trial difficulty (<inline-formula><mml:math id="inf87"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.32</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>E</bold>) In the optimal model, it significantly increased with a decrease in task difficulty (<inline-formula><mml:math id="inf88"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.96</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0052</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>F</bold>) This relationship ceases to be apparent once we reduce the number of simulated trials to that of the human data (<inline-formula><mml:math id="inf89"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.02</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.31</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), suggesting the human data may be underpowered to show such a relationship. (<bold>G</bold>) The relationship between switch rate and trial difficulty is not a general property of the optimal model, as a significant increase in the switch cost (adjusting <inline-formula><mml:math id="inf90"><mml:msub><mml:mi>C</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> from 0.018 to 0.1) removes the effect seen in (<bold>E</bold>) (<inline-formula><mml:math id="inf91"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.50</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.62</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), even with a large number of simulated trials. Error bars indicate SEM across participants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Replicating human perceptual decision-making behavior with the optimal model.</title><p>Replicating human perceptual decision-making behavior with the optimal model. In each trial of the perceptual decision task used in <xref ref-type="bibr" rid="bib60">Tavares et al., 2017</xref>, human decision makers had to identify which of two presented lines were closer in orientation to a preceding target orientation. To model this decision, the authors assumed that the decision maker compares the difference in perceptual quality (i.e. angle of a line; 0°, 5°, 10°, 15°) between the target and the two lines, then converted this difference to a scale ranging from 0 to 3 with three denoting the best possible proximity (i.e. 0°). Following this, we simulated the task such that our model accumulates noisy evidence centered around the perceptual difference scale (0–3) between the target and the two lines, and chose the item with a larger value using this scale (see Appendix 1). (<bold>A</bold>) Monotonic increase in probability of choosing item 1 as a function of the perceptual difference between item 1 and 2. (<bold>B</bold>) Decrease in response time (RT) as a function of trial difficulty. (<bold>C</bold>) Decrease in the number of switches as a function of trial difficulty. (<bold>D</bold>) Effect of last fixation location on item preference. The item that was fixated on immediately prior to the decision was more likely to be chosen. (<bold>E</bold>) Attention’s biasing effect on item choice. The item was more likely to be chosen if it was attended to for a longer period of time. (<bold>F</bold>) Replication of fixation pattern during decision making. In the perceptual decision-making task, both model and human data showed increased duration for every subsequent fixation, a notable difference compared to fixation behavior in the value-based task. For (<bold>A–D</bold>), the behavioral data has a smaller range of perceptual differences due to insufficient trials with such large perceptual difference. Error bars indicate SEM across participants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig3-figsupp2-v2.tif"/></fig></fig-group><p>The model also reproduced the biasing effects of fixation on preference seen in humans (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>). An item was more likely to be chosen if it was the last one to be fixated on (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), and if it was viewed for a longer time period (<xref ref-type="fig" rid="fig3">Figure 3E</xref>; <inline-formula><mml:math id="inf92"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>5.32</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Interestingly, the model also replicated a particular fixation pattern seen in humans, where a short first fixation is followed by a significantly longer second fixation, which is followed by a medium-length third fixation (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). We suspect this pattern arises due to the shape of the optimal decision boundaries, where the particle is more likely to hit the ‘switch’ boundary in a shorter time for the first fixation, likely reflecting the fact that the model prefers to sample from both items at least once. Consistent with this, <xref ref-type="fig" rid="fig3">Figure 3C</xref> shows that the ‘accumulate’ space is larger for the second fixation compared to the first fixation. Of note, the attentional drift diffusion model (aDDM) that was initially proposed to explain the observed human data did not generate its own fixations, but rather used fixations sampled from the empirical distribution of human subjects. Furthermore, they were only able to achieve this fixation pattern by sampling the first fixation, which was generally shorter than the rest, separately from the remaining fixation durations (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3E</xref>).</p><p>One feature that distinguishes our model from previous attention-based decision models is that attention only modulates the variance of momentary evidence without explicitly down-weighting the value of the unattended item (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib56">Song et al., 2019</xref>). Therefore, at first glance, preference for the more-attended item is not an obvious feature since our model does not appear to boost its estimated value. However, under the assumption that decision makers start out with a zero-mean prior, Bayesian belief updating with attention modulation turns out to effectively account for a biasing effect of fixation on the subjective value of items (<xref ref-type="bibr" rid="bib37">Li and Ma, 2019</xref>). For instance, consider choosing between two items with equal underlying value. Without an attention-modulated process, the model will accumulate evidence from both items simultaneously, and thus have no preference for one item over the other. However, once attention is introduced and the model attends to item 1 longer than item 2, it will have acquired more evidence about item 1’s value. This will cause item 1 to have a sharper, more certain likelihood function compared to item 2 (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). As posterior value estimates are formed by combining priors and likelihoods in proportion to their associated certainties, the posterior of item 1 will be less biased towards the prior than that of item 2. This leads to a higher subjective value of item 1 compared to that of item 2 even though their true underlying values are equal.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Behavioral predictions from Bayesian value estimation, and further properties of the optimal policy.</title><p>(<bold>A</bold>) Bayesian explanation of attention-driven value preference. Attending to one of two equally-valued items for a longer time (red vs. blue) leads to a more certain (i.e. narrower) likelihood and weaker bias of its posterior towards the prior. This leads to a subjectively higher value for the longer attended item. (<bold>B</bold>) Effect of response time (RT; left panel; <inline-formula><mml:math id="inf93"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>3.25</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0024</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) and sum of the two item values (value sum; right panel; <inline-formula><mml:math id="inf94"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.95</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0054</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) on attention-driven choice bias in humans. This choice bias quantifies the extent to which fixations affect choices for the chosen subset of trials (see Materials and methods). (<bold>C</bold>) Effect of response time (left panel; <inline-formula><mml:math id="inf95"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>32.0</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) and sum of the two item values (right panel; <inline-formula><mml:math id="inf96"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>11.4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) on attention-driven choice bias in the optimal model. See Materials and methods for details on how the choice bias coefficients were computed. For (<bold>B</bold>) and (<bold>C</bold>), for the left panels, the horizontal axis is binned according to the number of total fixations in a given trial. For the right panels, the horizontal axis is binned to contain the same number of trials per bin. Horizontal error bars indicate SEM across participants of the mean x-values within each bin. Vertical error bars indicate SEM across participants. (<bold>D</bold>) Comparing decision performance between the optimal policy and the original aDDM model. Performance of the aDDM was evaluated for different boundary heights (error bars = SEM across simulated participants). Even for the reward-maximizing aDDM boundary height, the optimal model significantly outperformed the aDDM (<inline-formula><mml:math id="inf97"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>3.01</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0027</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>E</bold>) Decision performance for different degrees of the attention bottleneck (<inline-formula><mml:math id="inf98"><mml:mi>κ</mml:mi></mml:math></inline-formula>) while leaving the overall input information unchanged (error bars = SEM across simulated participants). The performance peak at <inline-formula><mml:math id="inf99"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> indicates that allocating similar amounts of attentional resource to both items is beneficial (<inline-formula><mml:math id="inf100"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>8.51</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Effect of item values on attention switch rate and fixation duration across trials for the human data, optimal model, and aDDM.</title><p>Effect of item values on attention switch rate and fixation duration across trials for human data, optimal model, and aDDM. (<bold>A</bold>) Effect of absolute value difference (i.e. trial difficulty) on switch rate. Only the aDDM showed a significant dependence of switch rate on difficulty, featuring a higher switch rate for less difficult trials (<inline-formula><mml:math id="inf101"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>4.97</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>B</bold>) Relationship between value sum and switch rate. A larger value sum led to a smaller switch rate for the optimal model (<inline-formula><mml:math id="inf102"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>3.36</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0018</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Human data showed a non-significant trend in the same direction (<inline-formula><mml:math id="inf103"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1.31</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.20</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>C</bold>) Dependence of middle fixation duration on absolute value difference. Humans and both models featured shorter fixation duration in easier trials (human: <inline-formula><mml:math id="inf104"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>4.15</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; optimal model: <inline-formula><mml:math id="inf105"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>2.85</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0070</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; aDDM: <inline-formula><mml:math id="inf106"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>6.52</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>D</bold>) Dependence of middle fixation duration on value sum. Both the optimal model and the aDDM featured shorter fixation durations for larger value sums (optimal model: <inline-formula><mml:math id="inf107"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>4.06</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; aDDM: <inline-formula><mml:math id="inf108"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>4.34</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Human data featured a non-significant trend in the same direction (<inline-formula><mml:math id="inf109"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1.53</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.13</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). For all plots, we computed the mean switch rate (number of switches divided by RT) and middle fixation duration for every trial, then grouped the trials by absolute value difference (i.e. trial difficulty) or value sum. We then computed the mean switch rate and fixation duration across participants for each x-variable. Curves with a slope significantly different from zero are indicated by a bar above the curve with its associated p-value (see Materials and methods for statistics involving slopes). For both model’s simulations, we used the same item pairs and trial numbers as the human data. For the aDDM simulations, we used the same parameter setup used in the original paper by <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref> rather than the signal-to-noise-matched version we used to compare the mean reward between the optimal model and aDDM. Error bars indicate SEM across participants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Effect of passed time on switch probability and fixation duration within trials.</title><p>Effect of passed time on switch probability and fixation duration within trials. (<bold>A</bold>) Effect of passed time on switch probability, using all trials. Switch probability for humans and aDDM peaked within 1 s of stimulus onset and gradually decreased thereafter. For the optimal model, the majority of attention switches were clustered around discrete time points. Note that the optimal model assumes the decision maker to use precise time estimates to drive attention switches. If we were to take into account the noisiness of human choice estimates (<xref ref-type="bibr" rid="bib12">Buhusi and Meck, 2005</xref>), we would expect the optimal model curves to smoothen out and approach those of human data and the aDDM. (<bold>B–D</bold>) Effect of passed time on switch probability after dividing trials into upper and lower one-third of certain variables (B: RT, C: value sum, D: absolute value difference). When trials are split by RT (<bold>B</bold>), humans and aDDM featured a higher switch probability for longer (i.e. higher RT) trials. The optimal model featured comparable patterns within the time periods in which switches occurred. The dashed line indicates the point in time in which all trials were completed for the lower RT group. (<bold>E</bold>) Effect of passed time on fixation duration. Fixation duration increased with passed time for humans and the optimal model, suggesting that more time is allotted to each fixation as the trial becomes more difficult (human: <inline-formula><mml:math id="inf110"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>4.50</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; optimal model: <inline-formula><mml:math id="inf111"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>46.4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). This trend is not seen in the aDDM which draws all middle fixations randomly from the same empirical distribution, therefore eliminating any effect of time on fixation duration within a single trial (<inline-formula><mml:math id="inf112"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.57</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). To compute the switch probability (<bold>A–D</bold>), we aligned all trials within each participant by stimulus onset, then counted the number of switches within each 0.2 s time bin. We then averaged the switch count in each time bin across trials to compute the switch probability. We only included time points up to when at least 1/3 of the total trials are included, and removed the last fixations since they are prematurely terminated when a decision is made. To split trials based on different variables, all trials within a participant were split into three equally sized bins based on the variable of interest. We plot the mean switch probability across participants, only including the first (green) and last (magenta) bins. At each time point, we performed a t-test across participants between the two bins, and marked all time points with a significant difference across bins with an asterisk (Bonferroni corrected; <xref ref-type="bibr" rid="bib10">Bonferroni, 1936</xref>). For (<bold>E</bold>), whenever a new fixation occurred, we recorded its duration until the next fixation, excluding the first and last fixations. We averaged the fixation durations at each 0.05 s time bin across trials, dropping any time bin that contain data from less than 1/3 of all trials. We then plotted the mean fixation duration at each time bin across participants. Error bars indicate SEM across participants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Additional analyses of fixation behavior and performance between human data, optimal model, and aDDM.</title><p>Additional analyses of fixation behavior, performance, and choice bias between human data, optimal model, and aDDM. (<bold>A</bold>) Proportion of all trials that ended after a single fixation. Both the optimal model and aDDM featured more single fixation trials when compared to human data (optimal model: <inline-formula><mml:math id="inf113"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>76</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.96</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0052</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; aDDM: <inline-formula><mml:math id="inf114"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>76</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>3.35</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0019</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). (<bold>B</bold>) Comparing the mean reward received by humans versus the two models using the best-fitting model parameters. There was no significant difference between the mean rewards of humans versus either model (optimal model: <inline-formula><mml:math id="inf115"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>76</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.69</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.49</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; aDDM: <inline-formula><mml:math id="inf116"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>76</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.062</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Unlike in <xref ref-type="fig" rid="fig4">Figure 4D</xref>, the mean reward of the optimal model was not larger than the aDDM in this scenario because we simulated the aDDM using the original parameters rather than those that match the optimal model’s signal-to-noise ratio of the momentary evidence. To calculate mean reward, we used the same cost per unit time used for the optimal model (<inline-formula><mml:math id="inf117"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0.23</mml:mn></mml:mrow></mml:math></inline-formula>). For model simulations in (<bold>A</bold>) and (<bold>B</bold>), we used three times as many trials as performed by humans. (<bold>C,D</bold>) Effect of RT (<bold>C</bold>) and value sum (<bold>D</bold>) on choice bias in the aDDM. The aDDM also replicated the same effects as predicted by the optimal model (RT: <inline-formula><mml:math id="inf118"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>48.6</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; value sum: <inline-formula><mml:math id="inf119"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>14.7</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). For both plots, trial data were binned into equally sized bins based on the variable on the x-axis. See Materials and methods for how to compute the choice bias coefficient. (<bold>E</bold>) Mean fixation duration of the first three fixations across simulated aDDM participants. Since the fixation durations in the aDDM are sampled from the empirical distribution, it closely mimics those from human data. (<bold>F</bold>) Distribution of response times. Both models predict an RT distribution that seem to include more trials with RT &lt;1 s. For the aDDM simulations, we used the same parameter setup used in the original paper by <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>. For (<bold>A–E</bold>), vertical error bars indicate SEM across participants. For (<bold>C</bold>) and (<bold>D</bold>), horizontal error bars indicate the SEM of the bin means.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-fig4-figsupp3-v2.tif"/></fig></fig-group><p>This insight leads to additional predictions for how attention-modulated choice bias should vary with certain trial parameters. For instance, the Bayesian account predicts that trials with longer response times should have a weaker choice bias than trials with shorter response times. This is because the difference in fixation times between the two items will decrease over time as the model has more opportunities to switch attention. Both the human and model behavior robustly showed this pattern (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; human, <inline-formula><mml:math id="inf120"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>3.25</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0024</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; model, <inline-formula><mml:math id="inf121"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>32.0</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Similarly, choice bias should increase for trials with higher valued items. In this case, since the evidence distribution is relatively far away from the prior distribution, the posterior distribution is ‘pulled away’ from the prior distribution to a greater degree for the attended versus unattended item, leading to greater choice bias. Both human and model data confirmed this behavioral pattern (<xref ref-type="fig" rid="fig4">Figure 4C</xref>; human, <inline-formula><mml:math id="inf122"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.95</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0054</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; model, <inline-formula><mml:math id="inf123"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>11.4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Since response time may be influenced by the sum of the two item values and vice versa, we repeated the above analyses using a regression model that includes both value sum and response time as independent variables (see Materials and methods). The results were largely consistent for both model (effect of RT on choice bias: <inline-formula><mml:math id="inf124"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>5.73</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, effect of value sum: <inline-formula><mml:math id="inf125"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>7.88</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) and human (effect of RT: <inline-formula><mml:math id="inf126"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1.32</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.20</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, effect of value sum: <inline-formula><mml:math id="inf127"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.91</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.006</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) behavior.</p><p>Next, we assessed how the behavioral predictions arising from the optimal model differed from those of the original attentional drift diffusion model (aDDM) proposed by <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>. Unlike our model, the aDDM follows from traditional diffusion models rather than Bayesian models. It assumes that inattention to an item diminishes its value magnitude rather than increasing the noisiness of evidence accumulation. Despite this difference, the aDDM produced qualitatively similar behavioral predictions as the optimal model (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, and <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref> for additional behavioral comparisons between human data, the optimal model, and aDDM). We also tested to which degree the optimal model yielded a higher mean reward than the aDDM, which, despite its simpler structure, could nonetheless collect competitive amounts of reward. Given that our model provides the optimal solution to the decision problem under the current assumptions, it is expected to outperform, or at least match, the performance of alternative models. To ensure a fair comparison, we adjusted the aDDM model parameters (i.e. attentional value discounting and the noise variance) so that the momentary evidence provided to the two models has equivalent signal-to-noise ratios (see Appendix 1). Using the same parameters fit to human behavior without this adjustment in signal-to-noise ratio yielded a higher mean reward for the aDDM model (<inline-formula><mml:math id="inf128"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>76</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>14.8</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), since the aDDM receives more value information at each time point than the optimal model. The original aDDM model fixed the decision boundaries at ±1 and subsequently fit model parameters to match behavioral data. Since we were interested in comparing mean reward, we simulated model behavior using incrementally increasing decision barrier heights, looking for the height that yields the maximum mean reward (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). We found that even for the best-performing decision barrier height, the signal-to-noise ratio-matched aDDM model yielded a significantly lower mean reward compared to that of the optimal model (<inline-formula><mml:math id="inf129"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>76</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>3.01</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0027</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>).</p><p>Recent advances in artificial intelligence used attentional bottlenecks to regulate information flow with significant associated performance gains (<xref ref-type="bibr" rid="bib5">Bahdanau et al., 2015</xref>; <xref ref-type="bibr" rid="bib24">Gehring et al., 2017</xref>; <xref ref-type="bibr" rid="bib42">Mnih et al., 2014</xref>; <xref ref-type="bibr" rid="bib4">Ba et al., 2015</xref>; <xref ref-type="bibr" rid="bib57">Sorokin et al., 2015</xref>). Analogously, attentional bottlenecks might also be beneficial for value-based decision-making. To test this, we asked if paying relatively full attention on a single item at a time confers any advantages over the ability to pay relatively less reliable, but equal attention to multiple options in parallel. To do so, we varied the amount of momentary evidence provided about both the attended and unattended items while keeping the overall amount of evidence, as controlled by <inline-formula><mml:math id="inf130"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, fixed. This was accomplished by varying the <inline-formula><mml:math id="inf131"><mml:mi>κ</mml:mi></mml:math></inline-formula> term. The effect of <inline-formula><mml:math id="inf132"><mml:mi>κ</mml:mi></mml:math></inline-formula> on the optimal policy was symmetric around <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, such that information gained from attended item at <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> is equal to that of the unattended item at <inline-formula><mml:math id="inf135"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>. Setting <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> resulted in equal momentary evidence about both items, such that switching attention had no effect on the evidence collected about either item. When tuning model parameters to best match human behavior, we found a low <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>≈</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:math></inline-formula>, suggesting that humans tend to allocate the majority of their presumably fixed cognitive resources to the attended item. This allows for reliable evidence accumulation for the attended item, but is more likely to necessitate frequent switching of attention.</p><p>To investigate whether widening this attention bottleneck leads to changes in decision performance, we simulated model behavior for different values of <inline-formula><mml:math id="inf138"><mml:mi>κ</mml:mi></mml:math></inline-formula> (0.1 to 0.9, in 0.1 increments). Interestingly, we found that mean reward from the simulated trials is greatest at <inline-formula><mml:math id="inf139"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> and decreases for more extreme values of <inline-formula><mml:math id="inf140"><mml:mi>κ</mml:mi></mml:math></inline-formula>, suggesting that a more even distribution of attentional resources between the two items is beneficial for maximizing reward (<inline-formula><mml:math id="inf141"><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>38</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>8.51</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></sec><sec id="s2-4"><title>Optimal attention-modulated policy for perceptual decisions</title><p>The impact of attention is not unique to value-based decisions. In fact, recent work showed that fixation can bias choices in a perceptual decision-making paradigm (<xref ref-type="bibr" rid="bib60">Tavares et al., 2017</xref>). In their task, participants were first shown a target line with a certain orientation, then shown two lines with slightly different orientations. The goal was to choose the line with the closest orientation to the previously shown target. Consistent with results in the value-based decision task, the authors demonstrated that the longer fixated option was more likely to be chosen.</p><p>We modified our attention-based optimal policy to perform in such perceptual decisions, in which the goal was to choose the option that is the closest in some quantity to the target, rather than choosing the higher valued option. Therefore, our model can be generalized to any task that requires a binary decision based on some perceptual quality, whether that involves finding the brighter dot between two dots on a screen, or identifying which of the two lines on the screen is longer. Similar to our value-based case, the optimal policy for perceptual decisions was successful at reproducing the attention-driven biases seen in humans in <xref ref-type="bibr" rid="bib60">Tavares et al., 2017</xref>, (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this work, we derive a novel normative decision-making model with an attentional bottleneck, and show that it is able to reproduce the choice and fixation patterns of human decision makers. Our model significantly extends prior attempts to incorporate attention into perceptual and value-based decision-making in several ways. First, we provide a unified framework in which fixations are endogenously generated as a core component of the normative decision-making strategy. This is consistent with previous work that showed that fixation patterns were influenced by variables relevant for the decision, such as trial difficulty or the value of each choice item (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Krajbich and Rangel, 2011</xref>). However, prior models of such decisions assumed an exogenous source of fixations (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Krajbich and Rangel, 2011</xref>) or generated fixations using heuristics that relied on features such as the salience or value estimates of the choice options (<xref ref-type="bibr" rid="bib61">Towal et al., 2013</xref>; <xref ref-type="bibr" rid="bib26">Gluth et al., 2020</xref>). Other models generated fixations under the assumption that fixation duration should depend on the expected utility or informativeness of the choice items (<xref ref-type="bibr" rid="bib14">Cassey et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Ke et al., 2016</xref>; <xref ref-type="bibr" rid="bib56">Song et al., 2019</xref>). For example, (<xref ref-type="bibr" rid="bib14">Cassey et al., 2013</xref>) assumed that the informativeness of each item differed, which means the model should attend to the less informative item longer in general. Furthermore, since their decision task involved a fixed-duration, attention switches also occurred at fixed times rather than being dynamically adjusted across time, as in our case with a free-response paradigm. A recent normative model supported a continuous change of attention across choice items, and so could not relate attention to the observed discrete fixation changes (<xref ref-type="bibr" rid="bib28">Hébert and Woodford, 2019</xref>). Our work significantly builds on these prior models by identifying the exact optimal policy using dynamic programming, demonstrating that fixation patterns could reflect active information gathering through controlling an attentional bottleneck. This interpretation extends previous work on visual attention to the realm of value-based and perceptual decision-making (<xref ref-type="bibr" rid="bib65">Yang et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Hoppe and Rothkopf, 2016</xref>; <xref ref-type="bibr" rid="bib27">Hayhoe and Ballard, 2005</xref>; <xref ref-type="bibr" rid="bib16">Chukoskie et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">Corbetta and Shulman, 2002</xref>).</p><p>Second, our model posits that attention lowers the variance of the momentary evidence associated with the attended item, which enhances the reliability of its information (<xref ref-type="bibr" rid="bib21">Drugowitsch et al., 2014</xref>). In contrast, previous models accounted for attention by down-weighting the value of the unattended item (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib56">Song et al., 2019</xref>), where one would a priori assume fixations to bias choices. Our approach was inspired by neurophysiological findings demonstrating that visual attention selectively increases the firing rate of neurons tuned to task-relevant stimuli (<xref ref-type="bibr" rid="bib48">Reynolds and Chelazzi, 2004</xref>), decreases the mean-normalized variance of individual neurons (<xref ref-type="bibr" rid="bib40">Mitchell et al., 2007</xref>; <xref ref-type="bibr" rid="bib63">Wittig et al., 2018</xref>), and reduces the correlated variability of neurons at the population level (<xref ref-type="bibr" rid="bib17">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib41">Mitchell et al., 2009</xref>; <xref ref-type="bibr" rid="bib3">Averbeck et al., 2006</xref>). In essence, selective attention appears to boost the signal-to-noise ratio, or the reliability of information encoded by neuronal signals rather than alter the magnitude of the value encoded by these signals. One may argue that we could have equally chosen to boost the evidence’s mean while keeping its variance constant to achieve a similar boost in signal-to-noise ratio of the attended item. However, doing so would still distinguish our model from previous accumulation-to-bound models, as Bayes-optimal evidence accumulation in this model variant nonetheless demands the use of at least three dimensions (see <xref ref-type="fig" rid="fig2">Figure 2</xref>), and could not be achieved in the two dimensions used by previous models. Furthermore, this change would have resulted in less intuitive equations for the value posterior (<xref ref-type="disp-formula" rid="equ4">Equation 2</xref>).</p><p>Under this framework, we show that the optimal policy can be implemented as a four-dimensional accumulation-to-bound model where the particle drifts and diffuses according to the fixation duration to either item, the currently attended item, and the difference the in items’ value estimates. This policy space is significantly more complex compared to previous attention-free normative models, which can be implemented in a two-dimensional space. Nevertheless, the attention-modulated optimal policy still featured a collapsing boundary in time consistent with the attention-free case (<xref ref-type="bibr" rid="bib20">Drugowitsch et al., 2012</xref>; <xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>).</p><p>When designing our model, we took the simplest possible approach to introduce an attentional bottleneck into normative models of decision-making. Our aim was to provide a precise (i.e. without approximations), normative explanation for how fixation changes qualitatively interact with human decisions rather than quantitatively capture all details of human behavior, which is likely driven by additional heuristics and features beyond the scope of our model (<xref ref-type="bibr" rid="bib1">Acerbi et al., 2014</xref>; <xref ref-type="bibr" rid="bib22">Drugowitsch et al., 2016</xref>). For instance, it has been suggested that normative allocation of attention should also depend on the item values to eliminate non-contenders, which we did not incorporate as a part of our model (<xref ref-type="bibr" rid="bib61">Towal et al., 2013</xref>; <xref ref-type="bibr" rid="bib26">Gluth et al., 2020</xref>). Perhaps as a result of this approach, our model did not provide the best quantitative fit and was unable to capture all of the nuances of the psychometric curves from human behavior, including a seemingly linear relationship between RT and trial difficulty (<xref ref-type="fig" rid="fig3">Figure 3</xref>). As such, we expect other models using approximations to have a better quantitative fit to human data (<xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib13">Callaway et al., 2020</xref>). Instead, a normative understanding can provide a basis for understanding limitations and biases that emerge in human behavior. Consistent with this goal, we were able to qualitatively capture a wide range of previously observed features of human decisions (<xref ref-type="fig" rid="fig3">Figure 3</xref>), suggest a computational rationale for fixation-based choice biases (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), and confirm new predictions arising from our theory (<xref ref-type="fig" rid="fig4">Figure 4B–C</xref>). In addition, our framework is compatible with recent work by <xref ref-type="bibr" rid="bib50">Sepulveda et al., 2020</xref> that demonstrated that attention can bias choices toward the lower-valued option if participants are instructed to choose the less desirable item (see Appendix 1).</p><p>Due to the optimal policy’s complexity (<xref ref-type="fig" rid="fig2">Figure 2</xref>), we expect the nervous system to implement it only approximately (e.g. similar to <xref ref-type="bibr" rid="bib59">Tajima et al., 2019</xref> for multi-alternative decisions). Such an approximation has been recently suggested by <xref ref-type="bibr" rid="bib13">Callaway et al., 2020</xref>, where they proposed a model of N-alternative choice using approaches from rational inattention to approximate optimal decision-making in the presence of an attentional bottleneck. Unlike our work, they assumed that the unattended item is completely ignored, and therefore could not investigate the effect of graded shifts of attentional resources between items (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). In addition, their model did not predict a choice bias in binary choices due to a different assumption about the Bayesian prior.</p><p>In our model, we assumed the decision maker’s prior belief about the item values is centered at zero. In contrast, <xref ref-type="bibr" rid="bib13">Callaway et al., 2020</xref> chose a prior distribution based on the choice set, centered on the average value of only the tested items. While this is also a reasonable assumption (<xref ref-type="bibr" rid="bib52">Shenhav et al., 2018</xref>), it likely contributed to their inability to demonstrate the choice bias for binary decisions. Under the assumption of our zero-mean prior, formulating the choice process through Bayesian inference revealed a simple and intuitive explanation for choice biases (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) (see also <xref ref-type="bibr" rid="bib38">Li and Ma, 2020</xref>). This explanation required the decision maker to a-priori believe the items’ values to be lower than they actually are when choosing between appetitive options, consistent with evidence that item valuations vary inversely with the average value of recently observed items (<xref ref-type="bibr" rid="bib33">Khaw et al., 2017</xref>). The zero-mean prior also predicts an opposite effect of the choice bias when deciding between aversive items, such that less-fixated items should become the preferred choice. This is exactly what has been observed in human decision makers (<xref ref-type="bibr" rid="bib2">Armel et al., 2008</xref>). We justified using a zero-mean bias by pointing out that participants in the decision task were allowed to rate items as having both positive or negative valence (negative-valence items were excluded from the binary decision task). However, there is some evidence that humans also exhibit choice biases when only choosing between appetitive items (<xref ref-type="bibr" rid="bib15">Cavanagh et al., 2014</xref>; <xref ref-type="bibr" rid="bib54">Smith and Krajbich, 2018</xref>; <xref ref-type="bibr" rid="bib55">Smith and Krajbich, 2019</xref>). Although our setup suggests a zero-mean prior is required to reproduce the choice bias, the exact features and role of the Bayesian prior in human decisions still remains an open question for future work.</p><p>We show that narrowing the attentional bottleneck by setting <inline-formula><mml:math id="inf142"><mml:mi>κ</mml:mi></mml:math></inline-formula> to values closer to 0 or 1 does not boost performance of our decision-making model (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). Instead, spreading a fixed cognitive reserve evenly between the attended and unattended items maximized performance. This is consistent with prior work that showed that a modified drift diffusion model with a continuously varying attention would perform optimally when attention is always equally divided (<xref ref-type="bibr" rid="bib23">Fudenberg et al., 2018</xref>). However, this does not necessarily imply that equally divided attention always constitutes the normative behavior. If the decision maker has already paid more attention to one item over the other within a decision, it may be optimal to switch attention and gain more information about the unattended item rather than to proceed with equally divided attention.</p><p>Parameters fit to human behavior reveal that humans tend to allocate a large proportion of their cognitive resource toward the attended item, suggesting that the benefits of an attentional bottleneck might lie in other cognitive processes. Indeed, machine learning applied to text translation (<xref ref-type="bibr" rid="bib5">Bahdanau et al., 2015</xref>; <xref ref-type="bibr" rid="bib24">Gehring et al., 2017</xref>), object recognition (<xref ref-type="bibr" rid="bib42">Mnih et al., 2014</xref>; <xref ref-type="bibr" rid="bib4">Ba et al., 2015</xref>), and video-game playing (<xref ref-type="bibr" rid="bib57">Sorokin et al., 2015</xref>) benefits from attentional bottlenecks that allow the algorithm to focus resources on specific task subcomponents. For instance, image classification algorithms that extract only the relevant features of an image for high-resolution processing demonstrated improved performance and reduced computational cost compared to those without such attentional features (<xref ref-type="bibr" rid="bib42">Mnih et al., 2014</xref>). Similarly, attentional bottlenecks that appear to limit human decision-making performance might have beneficial effects on cognitive domains outside the scope of binary value-based decisions. This is consistent with the idea that the evolutionary advantage of selective attention involves the ability to rapidly fixate on salient features in a cluttered environment, thereby limiting the amount of information that reaches upstream processing and reducing the overall computational burden (<xref ref-type="bibr" rid="bib30">Itti and Koch, 2001</xref>).</p><p>An open question is whether our findings can be generalized to multi-alternative choice paradigms (<xref ref-type="bibr" rid="bib61">Towal et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Ke et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">Gluth et al., 2020</xref>; <xref ref-type="bibr" rid="bib59">Tajima et al., 2019</xref>). While implementing the optimal policy for such choices may be analytically intractable, we can reasonably infer that a choice bias driven by a zero-mean prior would generalize to decisions involving more than two options. However, in a multi-alternative choice paradigm where heuristics involving value and salience of items may influence attention allocation, it is less clear whether an equally divided attention among all options would still maximize reward. We hope this will motivate future studies that investigate the role of attention in more realistic decision scenarios.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Here, we provide an outline of the framework and its results. Detailed derivations are provided in Appendix 1.</p><sec id="s4-1"><title>Attention-modulated decision-making model</title><p>Before each trial, <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub> are drawn from <inline-formula><mml:math id="inf143"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub> correspond to the value of each item. In each time-step <inline-formula><mml:math id="inf144"><mml:mrow><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> of duration <inline-formula><mml:math id="inf145"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, the decision maker observes noisy samples of each <italic>z</italic><sub><italic>j</italic></sub>. This momentary evidence is drawn from <inline-formula><mml:math id="inf146"><mml:mrow><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for the attended item <inline-formula><mml:math id="inf147"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf148"><mml:mrow><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>κ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for the unattended item <inline-formula><mml:math id="inf149"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. We measure how informative a single momentary evidence sample is about the associated true value by computing the Fisher information it provides about this value. This Fisher information sums across independent pieces of information. This makes it an adequate measure for assessing the informativeness of momentary evidence, which we assume to be independent across time and items. Computing the Fisher information results in <inline-formula><mml:math id="inf150"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> in <inline-formula><mml:math id="inf151"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> about <italic>z</italic><sub><italic>j</italic></sub> for the attended item, and in <inline-formula><mml:math id="inf152"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> in <inline-formula><mml:math id="inf153"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> about <italic>z</italic><sub><italic>k</italic></sub> for the unattended item. Therefore, setting <inline-formula><mml:math id="inf154"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>≤</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula> boosts the information of the attended, and reduces the information of the unattended item, while keeping the total information about both items at a constant <inline-formula><mml:math id="inf155"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The posterior <italic>z</italic><sub><italic>j</italic></sub> for <inline-formula><mml:math id="inf156"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> after <inline-formula><mml:math id="inf157"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> seconds is found by Bayes’ rule, <inline-formula><mml:math id="inf158"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∏</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which results in <xref ref-type="disp-formula" rid="equ4">Equation (2)</xref>. If <inline-formula><mml:math id="inf159"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> identifies the attended item in each time-step, the attention times in this posterior are given by <inline-formula><mml:math id="inf160"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf161"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The attention-weighted accumulated evidence is <inline-formula><mml:math id="inf162"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mi>κ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mi>κ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, down-weighting the momentary evidence for periods when the item is unattended. Fixing <inline-formula><mml:math id="inf164"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> recovers the attention-free case of <xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>, and the associated posterior, <xref ref-type="disp-formula" rid="equ3">Equation (1)</xref>.</p><p>We found the optimal policy by dynamic programming (<xref ref-type="bibr" rid="bib6">Bellman, 1952</xref>; <xref ref-type="bibr" rid="bib20">Drugowitsch et al., 2012</xref>), which, at each point in time, chooses the action that promises the largest expected return, including all rewards and costs from that point into the future. Its central component is the value function that specifies this expected return for each value of the sufficient statistics of the task. In our task, the sufficient statistics are the two posterior means, <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf166"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the two accumulation times, <italic>t</italic><sub>1</sub> and <italic>t</italic><sub>2</sub>, and the currently attended item <italic>y</italic><sub><italic>n</italic></sub>. The decision maker can choose between four actions at any point in time. The first two are to choose one of the two items, which is expected to yield the corresponding reward, after which the trial ends. The third action is to accumulate evidence for some more time <inline-formula><mml:math id="inf167"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, which comes at cost <inline-formula><mml:math id="inf168"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, and results in more momentary evidence and a corresponding updated posterior. The fourth is to switch attention to the other item <inline-formula><mml:math id="inf169"><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, which comes at cost <inline-formula><mml:math id="inf170"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. As the optimal action is the one that maximizes the expected return, the value for each sufficient statistic is the maximum over the expected returns associated with each action. This leads to the recursive Bellman’s equation that relates values with different sufficient statistics (see Appendix 1 for details) and reveals the optimal action for each of these sufficient statistics. Due to symmetries in our task, it turns out these optimal actions only depend on the difference in posterior means <inline-formula><mml:math id="inf171"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>, rather than each of the individual means (see Appendix 1). This allowed us to compute the value function and associated optimal policy in the lower-dimensional <inline-formula><mml:math id="inf172"><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>-space, an example of which is shown in (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><p>The optimal policy was found numerically by backwards induction (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Brockwell and Kadane, 2003</xref>), which assumes that at a large enough <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, a decision is guaranteed and the expected return equals <inline-formula><mml:math id="inf174"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>. We set this time point as <inline-formula><mml:math id="inf175"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> based on empirical observations. From this point, we move backwards in small time steps of 0.05 s and traverse different values of <inline-formula><mml:math id="inf176"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> which was also discretized into steps of 0.05. Upon completing this exercise, we are left with a three-dimensional grid with the axes corresponding to <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub> and <inline-formula><mml:math id="inf177"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>, where the value assigned to each point in space indicates the optimal decision to take for the given set of sufficient statistics. The boundaries between different optimal actions can be visualized as three-dimensional manifolds (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p></sec><sec id="s4-2"><title>Model simulations</title><p>Using the optimal policy, we simulated decisions in a task analogous to the one humans performed in <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>. On each simulated trial, two items with values <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub> are presented. The model attends to one item randomly (<inline-formula><mml:math id="inf178"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), then starts accumulating noisy evidence and adjusts its behavior across time according to the optimal policy. Since the human data had a total of 39 participants, we simulated the same number of participants (<inline-formula><mml:math id="inf179"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>39</mml:mn></mml:mrow></mml:math></inline-formula>) for the model, but with a larger number of trials. For each simulated participant, trials consisted of all pairwise combinations of values between 0 and 7, iterated 20 times. This yielded a total of 1280 trials per simulated participant.</p><p>When computing the optimal policy, there were several free parameters that determined the shape of the decision boundaries. Those parameters included the evidence noise term (<inline-formula><mml:math id="inf180"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>), spread of the prior distribution (<inline-formula><mml:math id="inf181"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>), cost of accumulating evidence (<inline-formula><mml:math id="inf182"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), cost of switching attention (<italic>c</italic><sub><italic>s</italic></sub>), and the relative information gain for the attended vs. unattended items (<inline-formula><mml:math id="inf183"><mml:mi>κ</mml:mi></mml:math></inline-formula>). In order to find a set of parameters that best mimics human behavior, we performed a random search over a large parameter space and simulated behavior using the randomly selected set of parameters (<xref ref-type="bibr" rid="bib7">Bergstra and Bengio, 2012</xref>). We iterated this process for 2,000,000 sets of parameters and compared the generated behavior to that of humans (see Appendix 1). After this search process, the parameter set that best replicated human behavior consisted of <inline-formula><mml:math id="inf184"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.0065</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf185"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0.23</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf186"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>27</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf187"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>18</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf188"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-3"><title>Statistical analysis</title><p>The relationship between task variables (e.g. difference in item value) and behavioral measurements (e.g. response time) were assessed by estimating the slope of the relationship for each participant. For instance, to investigate the association between response times and absolute value difference (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), we fit a linear regression within each participant using the absolute value difference and response time for every trial. Statistical testing was performed using one-sample t-tests on the regression coefficients across participants. This procedure was used for statistical testing involving <xref ref-type="fig" rid="fig3">Figure 3B,C,E</xref>, and <xref ref-type="fig" rid="fig4">Figure 4B,C</xref>. To test for the effect of RT and value sum on choice bias after accounting for the other variable, we used a similar approach and used both RT and value sum as independent variables in the regression model and the choice bias coefficient as the dependent variable. To test for a significant peak effect for <xref ref-type="fig" rid="fig4">Figure 4E</xref>, we used the same procedure after subtracting 0.5 from the original <inline-formula><mml:math id="inf189"><mml:mi>κ</mml:mi></mml:math></inline-formula> values and taking their absolute value. To compare performance between the optimal model and the aDDM (<xref ref-type="fig" rid="fig4">Figure 4D</xref>), we first selected the best-performing aDDM model, then performed an independent-samples t-test between the mean rewards from simulated participants from both models.</p><p>To quantify the degree of choice bias (<xref ref-type="fig" rid="fig4">Figure 4B,C</xref>), we computed a choice bias coefficient. For a given group of trials, we performed a logistic regression with fixation time difference (<inline-formula><mml:math id="inf190"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) as the independent variable and a binary-dependent variable indicating whether item 1 was chosen on each trial. After performing this regression within each participant’s data, we performed a t-test of the regression coefficients against zero. The the resulting t-statistic was used as the choice bias coefficient, as it quantified the extent to which fixations affected choice in the given subset of trials.</p></sec><sec id="s4-4"><title>Data and code availability</title><p>The human behavioral data and code are available through an open source license at <ext-link ext-link-type="uri" xlink:href="https://github.com/DrugowitschLab/Optimal-policy-attention-modulated-decisions">https://github.com/DrugowitschLab/Optimal-policy-attention-modulated-decisions </ext-link> (<xref ref-type="bibr" rid="bib31">Jang, 2021</xref>; copy archived at https://archive.softwareheritage.org/swh:1:rev:db4a4481aa6522d990018a34c31683698da039cb/). </p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Ian Krajbich for sharing the behavioral data, and members of the Drugowitsch lab, in particular Anna Kutschireiter and Emma Krause, for feedback on the manuscript. This work was supported by the National Institute of Mental Health (R01MH115554, JD) and the James S McDonnell Foundation (Scholar Award in Understanding Human Cognition, grant# 220020462, JD).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Methodology</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing - original draft, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Human behavioral data were obtained from previously published work from the California Institute of Technology (Krajbich et al., 2010). Caltech's Human Subjects Internal Review Board approved the experiment. Written informed consent was obtained from all participants.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="sdata1"><label>Source data 1.</label><caption><title>Human behavioral data readme.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63436-data1-v2.zip"/></supplementary-material><supplementary-material id="sdata2"><label>Source data 2.</label><caption><title>Human behavioral data.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63436-data2-v2.zip"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-63436-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The human behavioral data and code are available through an open source license archived at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4636831">https://doi.org/10.5281/zenodo.4636831</ext-link> copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:db4a4481aa6522d990018a34c31683698da039cb/">https://archive.softwareheritage.org/swh:1:rev:db4a4481aa6522d990018a34c31683698da039cb/</ext-link>.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acerbi</surname> <given-names>L</given-names></name><name><surname>Vijayakumar</surname> <given-names>S</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>On the origins of suboptimality in human probabilistic inference</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003661</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003661</pub-id><pub-id pub-id-type="pmid">24945142</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Armel</surname> <given-names>KC</given-names></name><name><surname>Beaumel</surname> <given-names>A</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Biasing simple choices by manipulating relative visual attention</article-title><source>Judgment and Decision Making</source><volume>3</volume><fpage>396</fpage><lpage>403</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname> <given-names>BB</given-names></name><name><surname>Latham</surname> <given-names>PE</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural correlations, population coding and computation</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nrn1888</pub-id><pub-id pub-id-type="pmid">16760916</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ba</surname> <given-names>JL</given-names></name><name><surname>Mnih</surname> <given-names>V</given-names></name><name><surname>Kavukcuoglu</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Multiple object recognition with visual attention</article-title><conf-name>International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings</conf-name></element-citation></ref><ref id="bib5"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bahdanau</surname> <given-names>D</given-names></name><name><surname>Cho</surname> <given-names>KH</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural machine translation by jointly learning to align and translate</article-title><conf-name>3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings</conf-name></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellman</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1952">1952</year><article-title>On the theory of dynamic programming</article-title><source>PNAS</source><volume>38</volume><fpage>716</fpage><lpage>719</lpage><pub-id pub-id-type="doi">10.1073/pnas.38.8.716</pub-id><pub-id pub-id-type="pmid">16589166</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergstra</surname> <given-names>J</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Random search for hyper-parameter optimization</article-title><source>Journal of Machine Learning Research</source><volume>13</volume><fpage>281</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.5555/2188385.2188395</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bertsekas</surname> <given-names>DP</given-names></name></person-group><year iso-8601-date="1995">1995</year><chapter-title>Athena scientific</chapter-title><person-group person-group-type="editor"><name><surname>Floudas</surname> <given-names>C</given-names></name><name><surname>Pardalos</surname> <given-names>P</given-names></name></person-group><source>Dynamic Programming and Optimal Control</source><publisher-name>Springer</publisher-name><fpage>8</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1007/978-0-387-74759-0_151</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname> <given-names>R</given-names></name><name><surname>Brown</surname> <given-names>E</given-names></name><name><surname>Moehlis</surname> <given-names>J</given-names></name><name><surname>Holmes</surname> <given-names>P</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bonferroni</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="1936">1936</year><article-title>Teoria statistica delle classi e calcolo delle probabilità</article-title><conf-name>Pubblicazioni Del R Istituto Superiore Di Scienze Economiche E Commerciali Di Firenze</conf-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brockwell</surname> <given-names>AE</given-names></name><name><surname>Kadane</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A gridding method for bayesian sequential decision problems</article-title><source>Journal of Computational and Graphical Statistics</source><volume>12</volume><fpage>566</fpage><lpage>584</lpage><pub-id pub-id-type="doi">10.1198/1061860032274</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buhusi</surname> <given-names>CV</given-names></name><name><surname>Meck</surname> <given-names>WH</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>What Makes Us Tick? Functional and Neural Mechanisms of Interval Timing</source><publisher-name>Hachette</publisher-name></element-citation></ref><ref id="bib13"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Callaway</surname> <given-names>F</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>Griffiths</surname> <given-names>TL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Fixation patterns in simple choice are consistent with optimal use of cognitive resources</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/57v6k</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cassey</surname> <given-names>TC</given-names></name><name><surname>Evens</surname> <given-names>DR</given-names></name><name><surname>Bogacz</surname> <given-names>R</given-names></name><name><surname>Marshall</surname> <given-names>JA</given-names></name><name><surname>Ludwig</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Adaptive sampling of information in perceptual decision-making</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e78993</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0078993</pub-id><pub-id pub-id-type="pmid">24312172</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanagh</surname> <given-names>JF</given-names></name><name><surname>Wiecki</surname> <given-names>TV</given-names></name><name><surname>Kochar</surname> <given-names>A</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Eye tracking and pupillometry are indicators of dissociable latent decision processes</article-title><source>Journal of Experimental Psychology: General</source><volume>143</volume><fpage>1476</fpage><lpage>1488</lpage><pub-id pub-id-type="doi">10.1037/a0035813</pub-id><pub-id pub-id-type="pmid">24548281</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chukoskie</surname> <given-names>L</given-names></name><name><surname>Snider</surname> <given-names>J</given-names></name><name><surname>Mozer</surname> <given-names>MC</given-names></name><name><surname>Krauzlis</surname> <given-names>RJ</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Learning where to look for a hidden target</article-title><source>PNAS</source><volume>110 Suppl 2</volume><fpage>10438</fpage><lpage>10445</lpage><pub-id pub-id-type="doi">10.1073/pnas.1301216110</pub-id><pub-id pub-id-type="pmid">23754404</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1594</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1038/nn.2439</pub-id><pub-id pub-id-type="pmid">19915566</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A neuronal population measure of attention predicts behavioral performance on individual trials</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>15241</fpage><lpage>15253</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2171-10.2010</pub-id><pub-id pub-id-type="pmid">21068329</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname> <given-names>M</given-names></name><name><surname>Shulman</surname> <given-names>GL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title><source>Nature Reviews Neuroscience</source><volume>3</volume><fpage>201</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1038/nrn755</pub-id><pub-id pub-id-type="pmid">11994752</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Moreno-Bote</surname> <given-names>R</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The cost of accumulating evidence in perceptual decision making</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>3612</fpage><lpage>3628</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4010-11.2012</pub-id><pub-id pub-id-type="pmid">22423085</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Moreno-Bote</surname> <given-names>R</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Optimal decision-making with time-varying evidence reliability</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name><name><surname>Devauchelle</surname> <given-names>AD</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational precision of mental inference as critical source of human choice suboptimality</article-title><source>Neuron</source><volume>92</volume><fpage>1398</fpage><lpage>1411</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.005</pub-id><pub-id pub-id-type="pmid">27916454</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fudenberg</surname> <given-names>D</given-names></name><name><surname>Strack</surname> <given-names>P</given-names></name><name><surname>Strzalecki</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Speed, accuracy, and the optimal timing of choices</article-title><source>American Economic Review</source><volume>108</volume><fpage>3651</fpage><lpage>3684</lpage><pub-id pub-id-type="doi">10.1257/aer.20150742</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gehring</surname> <given-names>J</given-names></name><name><surname>Auli</surname> <given-names>M</given-names></name><name><surname>Grangier</surname> <given-names>D</given-names></name><name><surname>Yarats</surname> <given-names>D</given-names></name><name><surname>Dauphin</surname> <given-names>YN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Convolutional sequence to sequence learning</article-title><conf-name>34th International Conference on Machine Learning ICML</conf-name></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Geisler</surname> <given-names>WS</given-names></name><name><surname>Cormack</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2012">2012</year><chapter-title><italic>Models of Overt Attention</italic></chapter-title><person-group person-group-type="editor"><name><surname>Everling</surname> <given-names>S</given-names></name><name><surname>Liversedge</surname> <given-names>S</given-names></name><name><surname>Gilchrist</surname> <given-names>I</given-names></name></person-group><source>The Oxford Handbook of Eye Movements</source><publisher-name>Oxford University Press</publisher-name><fpage>1</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1093/oxfordhb/9780199539789.001.0001</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gluth</surname> <given-names>S</given-names></name><name><surname>Kern</surname> <given-names>N</given-names></name><name><surname>Kortmann</surname> <given-names>M</given-names></name><name><surname>Vitali</surname> <given-names>CL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Value-based attention but not divisive normalization influences decisions with multiple alternatives</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>634</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1038/s41562-020-0822-0</pub-id><pub-id pub-id-type="pmid">32015490</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayhoe</surname> <given-names>M</given-names></name><name><surname>Ballard</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Eye movements in natural behavior</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>188</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.02.009</pub-id><pub-id pub-id-type="pmid">15808501</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hébert</surname> <given-names>B</given-names></name><name><surname>Woodford</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Rational Inattention When Decisions Take Time</source><publisher-name>Nber Working Paper Series</publisher-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoppe</surname> <given-names>D</given-names></name><name><surname>Rothkopf</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning rational temporal eye movement strategies</article-title><source>PNAS</source><volume>113</volume><fpage>8332</fpage><lpage>8337</lpage><pub-id pub-id-type="doi">10.1073/pnas.1601305113</pub-id><pub-id pub-id-type="pmid">27382164</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itti</surname> <given-names>L</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Computational modelling of visual attention</article-title><source>Nature Reviews Neuroscience</source><volume>2</volume><fpage>194</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1038/35058500</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jang</surname> <given-names>AI</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>DrugowitschLab/Optimal-policy-attention-modulated-decisions: Code as used in manuscript</data-title><source>Zenodo</source><version designator="1.0">v1.0</version><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4636831">https://doi.org/10.5281/zenodo.4636831</ext-link></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ke</surname> <given-names>TT</given-names></name><name><surname>Shen</surname> <given-names>ZJM</given-names></name><name><surname>Villas-Boas</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Search for information on multiple products</article-title><source>Management Science</source><volume>62</volume><elocation-id>e2316</elocation-id><pub-id pub-id-type="doi">10.1287/mnsc.2015.2316</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khaw</surname> <given-names>MW</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name><name><surname>Louie</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Normalized value coding explains dynamic adaptation in the human valuation process</article-title><source>PNAS</source><volume>114</volume><fpage>12696</fpage><lpage>12701</lpage><pub-id pub-id-type="doi">10.1073/pnas.1715293114</pub-id><pub-id pub-id-type="pmid">29133418</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Armel</surname> <given-names>C</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Visual fixations and the computation and comparison of value in simple choice</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1292</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1038/nn.2635</pub-id><pub-id pub-id-type="pmid">20835253</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions</article-title><source>PNAS</source><volume>108</volume><fpage>13852</fpage><lpage>13857</lpage><pub-id pub-id-type="doi">10.1073/pnas.1101328108</pub-id><pub-id pub-id-type="pmid">21808009</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kustov</surname> <given-names>AA</given-names></name><name><surname>Robinson</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Shared neural control of attentional shifts and eye movements</article-title><source>Nature</source><volume>384</volume><fpage>74</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1038/384074a0</pub-id><pub-id pub-id-type="pmid">8900281</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>SZ</given-names></name><name><surname>Ma</surname> <given-names>WJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cognitive computational neuroscience</article-title><conf-name>Valuation as Inference: A New Model for the Effects of Fixation on Choice</conf-name></element-citation></ref><ref id="bib38"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>Z</given-names></name><name><surname>Ma</surname> <given-names>W-J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An uncertainty-based model of the effects of fixation on choice</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/ajmwx</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milosavljevic</surname> <given-names>M</given-names></name><name><surname>Malmaud</surname> <given-names>J</given-names></name><name><surname>Huth</surname> <given-names>A</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The drift diffusion model can account for the accuracy and reaction time of Value-Based choices under high and low time pressure</article-title><source>SSRN Electronic Journal</source><volume>11</volume><elocation-id>1901533</elocation-id><pub-id pub-id-type="doi">10.2139/ssrn.1901533</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname> <given-names>JF</given-names></name><name><surname>Sundberg</surname> <given-names>KA</given-names></name><name><surname>Reynolds</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Differential attention-dependent response modulation across cell classes in macaque visual area V4</article-title><source>Neuron</source><volume>55</volume><fpage>131</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.06.018</pub-id><pub-id pub-id-type="pmid">17610822</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname> <given-names>JF</given-names></name><name><surname>Sundberg</surname> <given-names>KA</given-names></name><name><surname>Reynolds</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial attention decorrelates intrinsic activity fluctuations in macaque area V4</article-title><source>Neuron</source><volume>63</volume><fpage>879</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.013</pub-id><pub-id pub-id-type="pmid">19778515</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mnih</surname> <given-names>V</given-names></name><name><surname>Heess</surname> <given-names>N</given-names></name><name><surname>Graves</surname> <given-names>A</given-names></name><name><surname>Kavukcuoglu</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Recurrent models of visual attention</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohler</surname> <given-names>CW</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Organization of monkey superior colliculus: intermediate layer cells discharging before eye movements</article-title><source>Journal of Neurophysiology</source><volume>39</volume><fpage>722</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1152/jn.1976.39.4.722</pub-id><pub-id pub-id-type="pmid">823302</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname> <given-names>AM</given-names></name><name><surname>Ruff</surname> <given-names>DA</given-names></name><name><surname>Alberts</surname> <given-names>JJ</given-names></name><name><surname>Symmonds</surname> <given-names>J</given-names></name><name><surname>Cohen</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning and attention reveal a general relationship between population activity and behavior</article-title><source>Science</source><volume>359</volume><fpage>463</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1126/science.aao0284</pub-id><pub-id pub-id-type="pmid">29371470</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Orienting of attention</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>32</volume><fpage>3</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1080/00335558008248231</pub-id><pub-id pub-id-type="pmid">7367577</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>Hare</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neural computations associated with goal-directed choice</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>262</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.03.001</pub-id><pub-id pub-id-type="pmid">20338744</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname> <given-names>R</given-names></name><name><surname>McKoon</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The diffusion decision model: theory and data for two-choice decision tasks</article-title><source>Neural Computation</source><volume>20</volume><fpage>873</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.12-06-420</pub-id><pub-id pub-id-type="pmid">18085991</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname> <given-names>JH</given-names></name><name><surname>Chelazzi</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Attentional modulation of visual processing</article-title><source>Annual Review of Neuroscience</source><volume>27</volume><fpage>611</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.26.041002.131039</pub-id><pub-id pub-id-type="pmid">15217345</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname> <given-names>DA</given-names></name><name><surname>Ni</surname> <given-names>AM</given-names></name><name><surname>Cohen</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cognition as a window into neuronal population space</article-title><source>Annual Review of Neuroscience</source><volume>41</volume><fpage>77</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-061936</pub-id><pub-id pub-id-type="pmid">29799773</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sepulveda</surname> <given-names>P</given-names></name><name><surname>Usher</surname> <given-names>M</given-names></name><name><surname>Davies</surname> <given-names>N</given-names></name><name><surname>Benson</surname> <given-names>AA</given-names></name><name><surname>Ortoleva</surname> <given-names>P</given-names></name><name><surname>De Martino</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Visual attention modulates the integration of goal-relevant evidence and not value</article-title><source>eLife</source><volume>9</volume><elocation-id>e60705</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.60705</pub-id><pub-id pub-id-type="pmid">33200982</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Shohamy</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decision making and sequential sampling from memory</article-title><source>Neuron</source><volume>90</volume><fpage>927</fpage><lpage>939</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.036</pub-id><pub-id pub-id-type="pmid">27253447</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Dean Wolf</surname> <given-names>CK</given-names></name><name><surname>Karmarkar</surname> <given-names>UR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The evil of banality: when choosing between the mundane feels like choosing between the worst</article-title><source>Journal of Experimental Psychology: General</source><volume>147</volume><fpage>1892</fpage><lpage>1904</lpage><pub-id pub-id-type="doi">10.1037/xge0000433</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimojo</surname> <given-names>S</given-names></name><name><surname>Simion</surname> <given-names>C</given-names></name><name><surname>Shimojo</surname> <given-names>E</given-names></name><name><surname>Scheier</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Gaze Bias both reflects and influences preference</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1317</fpage><lpage>1322</lpage><pub-id pub-id-type="doi">10.1038/nn1150</pub-id><pub-id pub-id-type="pmid">14608360</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Krajbich</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attention and choice across domains</article-title><source>Journal of Experimental Psychology: General</source><volume>147</volume><fpage>1810</fpage><lpage>1826</lpage><pub-id pub-id-type="doi">10.1037/xge0000482</pub-id><pub-id pub-id-type="pmid">30247061</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Krajbich</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Gaze amplifies value in decision making</article-title><source>Psychological Science</source><volume>30</volume><fpage>116</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1177/0956797618810521</pub-id><pub-id pub-id-type="pmid">30526339</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Zhang</surname> <given-names>H</given-names></name><name><surname>Li</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Proactive information sampling in Value-Based Decision-Making: deciding when and where to saccade</article-title><source>Frontiers in Human Neuroscience</source><volume>13</volume><elocation-id>35</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2019.00035</pub-id><pub-id pub-id-type="pmid">30804770</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sorokin</surname> <given-names>I</given-names></name><name><surname>Seleznev</surname> <given-names>A</given-names></name><name><surname>Pavlov</surname> <given-names>M</given-names></name><name><surname>Fedorov</surname> <given-names>A</given-names></name><name><surname>Ignateva</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep attention recurrent Q-network</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1512.01693">https://arxiv.org/abs/1512.01693</ext-link></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tajima</surname> <given-names>S</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Optimal policy for value-based decision-making</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12400</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12400</pub-id><pub-id pub-id-type="pmid">27535638</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tajima</surname> <given-names>S</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Patel</surname> <given-names>N</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optimal policy for multi-alternative decisions</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1503</fpage><lpage>1511</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0453-9</pub-id><pub-id pub-id-type="pmid">31384015</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavares</surname> <given-names>G</given-names></name><name><surname>Perona</surname> <given-names>P</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The attentional drift diffusion model of simple perceptual Decision-Making</article-title><source>Frontiers in Neuroscience</source><volume>11</volume><elocation-id>468</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2017.00468</pub-id><pub-id pub-id-type="pmid">28894413</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Towal</surname> <given-names>RB</given-names></name><name><surname>Mormann</surname> <given-names>M</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Simultaneous modeling of visual saliency and value computation improves predictions of economic choice</article-title><source>PNAS</source><volume>110</volume><fpage>E3858</fpage><lpage>E3867</lpage><pub-id pub-id-type="doi">10.1073/pnas.1304429110</pub-id><pub-id pub-id-type="pmid">24019496</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>L</given-names></name><name><surname>Krauzlis</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Visual selective attention in mice</article-title><source>Current Biology</source><volume>28</volume><fpage>676</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.01.038</pub-id><pub-id pub-id-type="pmid">29456140</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wittig</surname> <given-names>JH</given-names></name><name><surname>Jang</surname> <given-names>AI</given-names></name><name><surname>Cocjin</surname> <given-names>JB</given-names></name><name><surname>Inati</surname> <given-names>SK</given-names></name><name><surname>Zaghloul</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attention improves memory by suppressing spiking-neuron activity in the human anterior temporal lobe</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>808</fpage><lpage>810</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0148-7</pub-id><pub-id pub-id-type="pmid">29786083</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neuronal mechanisms of visual stability</article-title><source>Vision Research</source><volume>48</volume><fpage>2070</fpage><lpage>2089</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.03.021</pub-id><pub-id pub-id-type="pmid">18513781</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>SC</given-names></name><name><surname>Lengyel</surname> <given-names>M</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Active sensing in the categorization of visual patterns</article-title><source>eLife</source><volume>5</volume><elocation-id>e12215</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12215</pub-id><pub-id pub-id-type="pmid">26880546</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>AJ</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dynamics of attentional selection under conflict: toward a rational bayesian account</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>35</volume><fpage>700</fpage><lpage>717</lpage><pub-id pub-id-type="doi">10.1037/a0013553</pub-id><pub-id pub-id-type="pmid">19485686</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><p>Here, we describe in more detail the derivations of our results, and specifics of the simulations presented in the main text. Of note, we sometimes use <inline-formula><mml:math id="inf191"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> to specify the conditional density <inline-formula><mml:math id="inf192"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Furthermore, <inline-formula><mml:math id="inf193"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes a Gaussian with mean µ and variance <inline-formula><mml:math id="inf194"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>.</p><sec id="s8" sec-type="appendix"><title>1 Task setup</title><sec id="s8-1"><title>1.1 Latent state prior</title><p>We assume two latent states <italic>z</italic><sub><italic>j</italic></sub>, <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, (here, the true item values) that are before each choice trial drawn from their Gaussian prior, <inline-formula><mml:math id="inf196"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with mean <inline-formula><mml:math id="inf197"><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf198"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>. Throughout the text, we will assume <inline-formula><mml:math id="inf199"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, to indicate that there is no a-priori preference of one item over the other.</p></sec><sec id="s8-2"><title>1.2 Likelihood function of momentary evidence</title><p>The decision maker doesn’t observe the latent states, but instead, in each time step of size <inline-formula><mml:math id="inf200"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, observes noisy evidence about both <italic>z</italic><sub><italic>j</italic></sub>’s. Let us assume that, in the <inline-formula><mml:math id="inf201"><mml:mi>n</mml:mi></mml:math></inline-formula> th such time step, the decision maker attends to item <inline-formula><mml:math id="inf202"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Then, they simultaneously observe <inline-formula><mml:math id="inf203"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf204"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, distributed as<disp-formula id="equ3"><label>(1)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mi>κ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we have defined the attention modulation parameter <inline-formula><mml:math id="inf205"><mml:mi>κ</mml:mi></mml:math></inline-formula>, bounded by <inline-formula><mml:math id="inf206"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>κ</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (we will usually assume <inline-formula><mml:math id="inf207"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>≤</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>), and the overall likelihood variance <inline-formula><mml:math id="inf208"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>. For the attended item <inline-formula><mml:math id="inf209"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, we have <inline-formula><mml:math id="inf210"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, such that the the variance of the momentary evidence for this item is <inline-formula><mml:math id="inf211"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For the unattended item, for which <inline-formula><mml:math id="inf212"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, this variance is instead <inline-formula><mml:math id="inf213"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula>. As long as <inline-formula><mml:math id="inf214"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula> this leads to a larger variance for the unattended item than the attended item, making the momentary evidence more informative for the attended item. In particular if we quantify this information by the Fisher information in the momentary evidence <inline-formula><mml:math id="inf215"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> about <italic>z</italic><sub><italic>j</italic></sub>, then we find this information to be <inline-formula><mml:math id="inf216"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> for the attended, and <inline-formula><mml:math id="inf217"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> for the unattended item. The total Fisher information across both items is thus <inline-formula><mml:math id="inf218"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, independent of <inline-formula><mml:math id="inf219"><mml:mi>κ</mml:mi></mml:math></inline-formula>. This shows that <inline-formula><mml:math id="inf220"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> controls the total information that the momentary evidence provides about the latent states, whereas <inline-formula><mml:math id="inf221"><mml:mi>κ</mml:mi></mml:math></inline-formula> controls how much of this information is provided for the attended vs. the unattended item.</p></sec><sec id="s8-3"><title>1.3 An alternative form for the likelihood</title><p>While the above form of the likelihood has a nice, intuitive parametrization, it is notationally cumbersome. Therefore, we will here introduce an alternative variance parametrization of this likelihood that simplifies the notation in the derivations that follow. We will use this parametrization for the rest of this Appendix.</p><p>This alternative parametrization assumes the variance of the momentary evidence of the attended item to be given by <inline-formula><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, while that of the unattended item is given by <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where the new attention modulation parameter <inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is assumed bounded by <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>γ</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Thus, the previous parameter pair <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mi>κ</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is replaced by the new pair <inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. A <inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> results in an increased variance for the unattended item, resulting in less information about the value of the unattended item. Overall, the momentary evidence likelihood is given with the alternative parametrization by<disp-formula id="equ4"><label>(2)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mfrac><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This is the likelihood function that we will use for the rest of this Appendix. Any of the results can easily be mapped back to the original parametrization (as used in the main text) by<disp-formula id="equ5"><label>(3)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ6"><label>(4)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>κ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>γ</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that the alternative parametrization does not preserve the separation between total information and balancing the information between the attended and unattended item. In particular, the total Fisher information is now given by <inline-formula><mml:math id="inf229"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, which depends on both <inline-formula><mml:math id="inf230"><mml:mi>γ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf231"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>.</p><p>Below we will derive the posterior <italic>z</italic><sub><italic>j</italic></sub>’s, given the stream of momentary evidences <inline-formula><mml:math id="inf232"><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:math></inline-formula>, and the attention sequence <inline-formula><mml:math id="inf233"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:math></inline-formula>. The mean and variance of the posterior distributions represent the decision maker’s belief of the items’ true values given all available evidence.</p></sec><sec id="s8-4"><title>1.4 Costs, rewards, and the decision maker’s overall aim</title><p>While the posterior estimates provide information about value, it does not tell the decision maker when to stop accumulating information, or when to switch their attention. To address these questions, we need to specify the costs and rewards associated with these behaviors. For value-based decisions, we assume that the reward for choosing item <inline-formula><mml:math id="inf234"><mml:mi>j</mml:mi></mml:math></inline-formula> is the latent state <italic>z</italic><sub><italic>j</italic></sub> (i.e. the true value) associated with the item. Furthermore, we assume that accumulating evidence comes at cost <inline-formula><mml:math id="inf235"><mml:mi>c</mml:mi></mml:math></inline-formula> per second, or cost <inline-formula><mml:math id="inf236"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> per time step. The decision maker can only ever attend to one item, and switching attention to the other item comes at cost <italic>c</italic><sub><italic>s</italic></sub> which may be composed of a pure attention switch cost, as well as a loss of time that might introduce an additional cost. As each attention switch introduces both costs, we only consider them in combination without loss of generality.</p><p>The overall aim of the decision maker is to maximize the total expected return, which consists of the expected value of the chosen item minus the total cost of accumulating evidence and attention switches. We address this maximization problem by finding the optimal policy that, based on the observed evidence, determines when to switch attention, when to accumulate more evidence, and when to commit to a choice. We initially focus on maximizing the expected return in a single, isolated choice, and will later show that this yields qualitatively similar policies as when embedding this choice into a longer sequence of comparable choices.</p></sec></sec><sec id="s9" sec-type="appendix"><title>2 Bayes-optimal evidence accumulation</title><sec id="s9-1"><title>2.1 Deriving the posterior <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub></title><p>To find the posterior over <italic>z</italic><sub>1</sub> after having accumulated evidence <inline-formula><mml:math id="inf237"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for some fixed amount of time <inline-formula><mml:math id="inf238"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> while paying attention to items <inline-formula><mml:math id="inf239"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, we employ Bayes’ rule,<disp-formula id="equ7"><label>(5)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mo>∝</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mfrac><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mfrac><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mo>∝</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we have defined <inline-formula><mml:math id="inf240"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> as the sum of all attention-weighted momentary evidence up to time t, and <inline-formula><mml:math id="inf241"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> as the total time that item <inline-formula><mml:math id="inf242"><mml:mi>j</mml:mi></mml:math></inline-formula> has been attended. Note that, for time periods in which item 2 is attended to, (i.e., when <inline-formula><mml:math id="inf243"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>), the momentary evidence is down-weighted by <inline-formula><mml:math id="inf244"><mml:mi>γ</mml:mi></mml:math></inline-formula>. With <inline-formula><mml:math id="inf245"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, the process becomes continuous in time, such that <inline-formula><mml:math id="inf246"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> becomes the integrated momentary evidence, but the above posterior still holds.</p><p>Following a similar derivation, the posterior belief about <italic>z</italic><sub>2</sub> results in<disp-formula id="equ8"><label>(6)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf247"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. As the decision maker acquires momentary evidence independently for both items, the two posteriors are independent of each other, that is <inline-formula><mml:math id="inf248"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s9-2"><title>2.2 The expected reward process</title><p>At each point in time, the decision maker must decide whether it’s worth accumulating more evidence versus choosing an item. To do so, they need to predict how the mean estimated reward for each option might evolve if they accumulated more evidence. In this section, we derive the stochastic process that describes this evolution for item 1. The same principles will apply for item 2.</p><p>Assume that having accumulated evidence until time <inline-formula><mml:math id="inf249"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the current expected reward for item 1 is given by <inline-formula><mml:math id="inf250"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf251"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the mean of the above posterior, <xref ref-type="disp-formula" rid="equ7">Equation (5)</xref>. The decision maker’s prediction of how the expected reward might evolve after accumulating additional evidence for <inline-formula><mml:math id="inf252"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> is found by the marginalization,<disp-formula id="equ9"><label>(7)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="2em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>∬</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>As the last term in the above integral shows, <inline-formula><mml:math id="inf253"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic>t</italic><sub>1</sub> and <italic>t</italic><sub>2</sub> fully determine the posterior <italic>z</italic><sub>1</sub> at time <inline-formula><mml:math id="inf254"><mml:mi>t</mml:mi></mml:math></inline-formula>. We can use this posterior to predict the value of the next momentary evidence <inline-formula><mml:math id="inf255"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. This, in turn, allows us to predict <inline-formula><mml:math id="inf256"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. As all involved densities are either deterministic or Gaussian, the resulting posterior will be Gaussian as well. Thus, rather than performing the integrals explicitly, we will find the final posterior by tracking the involved means and variances, which in turn completely determine the posterior parameters.</p><p>We first marginalize over <inline-formula><mml:math id="inf257"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, by expressing <inline-formula><mml:math id="inf258"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in terms of <inline-formula><mml:math id="inf259"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf260"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. To do so, we use <xref ref-type="disp-formula" rid="equ7">Equation (5)</xref> to express <inline-formula><mml:math id="inf261"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by<disp-formula id="equ10"><label>(8)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we have used <inline-formula><mml:math id="inf262"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Note that, for a given <inline-formula><mml:math id="inf263"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf264"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is uniquely determined by <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> becomes a random variable once we acknowledge that, for any <italic>z</italic><sub>1</sub>, <inline-formula><mml:math id="inf267"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is given by <xref ref-type="disp-formula" rid="equ4">Equation (2)</xref>, which we can write as <inline-formula><mml:math id="inf268"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mo>⁢</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf269"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Substituting this expression into <inline-formula><mml:math id="inf270"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and using <xref ref-type="disp-formula" rid="equ7">Equation (5)</xref> to re-express <inline-formula><mml:math id="inf271"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as <inline-formula><mml:math id="inf272"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, results in<disp-formula id="equ11"><label>(9)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mo>⁢</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The second marginalization over <italic>z</italic><sub>1</sub> is found by noting the distribution of <italic>z</italic><sub>1</sub> is given by <xref ref-type="disp-formula" rid="equ7">Equation (5)</xref>, which can be written as<disp-formula id="equ12"><label>(10)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msqrt><mml:mfrac><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>⁢</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with <inline-formula><mml:math id="inf273"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Substituting this <italic>z</italic><sub>1</sub> into the above expression for <inline-formula><mml:math id="inf274"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> results in<disp-formula id="equ13"><label>(11)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:msqrt><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we have dropped the <inline-formula><mml:math id="inf275"><mml:msub><mml:mi>η</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:math></inline-formula>-dependent term which had a <inline-formula><mml:math id="inf276"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> pre-factor, and thus vanishes with <inline-formula><mml:math id="inf277"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Therefore, <inline-formula><mml:math id="inf278"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> evolves as a martingale,<disp-formula id="equ14"><label>(12)</label><mml:math id="m14"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using the same approach, the expected future reward for item 2 is given by<disp-formula id="equ15"><label>(13)</label><mml:math id="m15"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s9-3"><title>2.3 The expected reward difference process</title><p>In a later section, we will reduce the dimensionality of the optimal policy space by using the expected reward difference rather than each of the of the expected rewards separately. To do so, we define this difference by<disp-formula id="equ16"><label>(14)</label><mml:math id="m16"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>As for <inline-formula><mml:math id="inf279"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf280"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we are interested in how <inline-formula><mml:math id="inf281"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> evolves over time.</p><p>To find <inline-formula><mml:math id="inf282"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> we can use<disp-formula id="equ17"><label>(15)</label><mml:math id="m17"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>As the decision maker receives independent momentary evidence for each item, <inline-formula><mml:math id="inf283"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf284"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are independent when conditioned on <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub> and <inline-formula><mml:math id="inf285"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Thus, so are their time-evolutions, <inline-formula><mml:math id="inf286"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf287"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. With this, we can show that<disp-formula id="equ18"><label>(16)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∼</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="1em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Unsurprisingly, <inline-formula><mml:math id="inf288"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is again a martingale.</p></sec></sec><sec id="s10" sec-type="appendix"><title>3 Optimal decision policy</title><p>We find the optimal decision policy by dynamic programming (<xref ref-type="bibr" rid="bib6">Bellman, 1952</xref>; <xref ref-type="bibr" rid="bib8">Bertsekas, 1995</xref>). A central concept in dynamic programming is the <italic>value function</italic> <inline-formula><mml:math id="inf289"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which, at any point in time during a decision, returns the <italic>expected return</italic>, which encompasses all expected rewards and costs from that point onwards into the future when following the optimal decision policy. Bellman’s equation links value functions across consecutive times, and allows finding this optimal decision policy recursively. In what follows, we first focus on Bellman’s equation for single, isolated choices. After that, we show how to extend the same approach to find the optimal policy for long sequences of consecutive choices.</p><sec id="s10-1"><title>3.1 Single, isolated choice</title><p>For a single, isolated choice, accumulating evidence comes at cost <inline-formula><mml:math id="inf290"><mml:mi>c</mml:mi></mml:math></inline-formula> per second. Switching attention comes at cost <italic>c</italic><sub><italic>s</italic></sub>. The expected reward for choosing item <inline-formula><mml:math id="inf291"><mml:mi>j</mml:mi></mml:math></inline-formula> is <inline-formula><mml:math id="inf292"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and is given by the mean of <xref ref-type="disp-formula" rid="equ7 equ8">Equations (5) and (6)</xref> for <inline-formula><mml:math id="inf293"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf294"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, respectively.</p><p>To find the value function, let us assume that we have accumulated evidence for some time <inline-formula><mml:math id="inf295"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, expect rewards <inline-formula><mml:math id="inf296"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf297"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and are paying attention to item <inline-formula><mml:math id="inf298"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. These statistics fully describe the evidence accumulation state, and thus fully parameterize the value function <inline-formula><mml:math id="inf299"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, we use <inline-formula><mml:math id="inf300"><mml:mi>y</mml:mi></mml:math></inline-formula> as a subscript rather than an argument to <inline-formula><mml:math id="inf301"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to indicate that <inline-formula><mml:math id="inf302"><mml:mi>y</mml:mi></mml:math></inline-formula> can only take one of two values, <inline-formula><mml:math id="inf303"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. At this point, we can choose among four actions. We can either immediately choose item 1, immediately choose item 2, accumulate more evidence without switching attention, or switch attention to the other item, <inline-formula><mml:math id="inf304"><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula>. The expected return for choosing immediately is either <inline-formula><mml:math id="inf305"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf306"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, depending on the choice. Accumulating more evidence for some time <inline-formula><mml:math id="inf307"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> results in cost <inline-formula><mml:math id="inf308"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, and changes in the expected rewards according to <inline-formula><mml:math id="inf309"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, as given by <xref ref-type="disp-formula" rid="equ14 equ15">Equations (12) and (13)</xref>. Therefore, the expected return for accumulating more evidence is given by<disp-formula id="equ19"><label>(17)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the expectation is over the time-evolution of <inline-formula><mml:math id="inf310"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf311"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf312"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf313"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> ensures that only the <italic>t</italic><sub><italic>y</italic></sub> associated with the currently attended item is increased by <inline-formula><mml:math id="inf314"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. Lastly, switching attention comes at cost <italic>c</italic><sub><italic>s</italic></sub>, but does not otherwise impact reward expectations, such that the expected return associated with this action is<disp-formula id="equ20"><label>(18)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the use of <inline-formula><mml:math id="inf315"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> implements that, after an attention switch, item <inline-formula><mml:math id="inf316"><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula> will be the attended item.</p><p>By the <xref ref-type="bibr" rid="bib6">Bellman, 1952</xref> optimality principle, the best action at any point in time is the one that maximizes the expected return. Combining the expected returns associated with each possible action results in Bellman’s equation<disp-formula id="equ21"><label>(19)</label><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Solving this equation yields the optimal policy for any combination of <inline-formula><mml:math id="inf317"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf318"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub> and <inline-formula><mml:math id="inf319"><mml:mi>y</mml:mi></mml:math></inline-formula> by picking the action that maximizes the associated expected return, that is, the term that maximizes the left-hand side of the above equation. The optimal decision boundaries that separate the <inline-formula><mml:math id="inf320"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>-space into regions where different actions are optimal lie at manifolds in which two actions yield the same expected return. For example, the decision boundary at which it becomes best to choose item 1 after having accumulated more evidence is the manifold at which<disp-formula id="equ22"><label>(20)</label><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="2em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In Section 6, we describe how we found these boundaries numerically.</p><p>Formulated so far, the value function is five-dimensional, with four continuous (<inline-formula><mml:math id="inf321"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf322"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, <italic>t</italic><sub>1</sub>, and <italic>t</italic><sub>2</sub>) and one discrete (<inline-formula><mml:math id="inf323"><mml:mi>y</mml:mi></mml:math></inline-formula>) dimension. It turns out that it is possible to remove one of the dimensions without changing the associated policy by focusing on the expected reward difference <inline-formula><mml:math id="inf324"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ16">Equation (14)</xref>, rather than the individual expected rewards. To show this, we jump ahead and use the value function property <inline-formula><mml:math id="inf325"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for any scalar <inline-formula><mml:math id="inf326"><mml:mi>C</mml:mi></mml:math></inline-formula>, that we will confirm in Section 5. Next, we define the value function on expected reward differences by<disp-formula id="equ23"><label>(21)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Applying this mapping to <xref ref-type="disp-formula" rid="equ21">Equation (19)</xref> leads to Bellman’s equation<disp-formula id="equ24"><label>(22)</label><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>which is now defined over a four-dimensional rather than a five-dimensional space while yielding the same optimal policy. This also confirms that optimal decision-making doesn’t require tracking individual expected rewards, but only their difference.</p></sec><sec id="s10-2"><title>3.2 Sequence of consecutive choices</title><p>So far, we have focused on the optimal policy for a single isolated choice. Let us now demonstrate that this policy does not qualitatively change if we move to a long sequence of consecutive choices. To do so, we assume that each choice is followed by an inter-trial interval <italic>t</italic><sub><italic>i</italic></sub> after which the latent <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub> are re-drawn from the prior, and evidence accumulation starts anew. As the expected return considers all expected future rewards, it would grow without bounds for a possibly infinite sequence of choices. Thus, rather than using the value function, we move to using the average-adjusted value function, <inline-formula><mml:math id="inf327"><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula>, which, for each passed time <inline-formula><mml:math id="inf328"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, subtracts <inline-formula><mml:math id="inf329"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf330"><mml:mi>ρ</mml:mi></mml:math></inline-formula> is the average reward rate (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>). This way, the value tells us if we are performing better or worse than on average, and is thus bounded.</p><p>Introducing the reward rate as an additional time cost requires the following changes. First, the average-adjusted expected return for immediate choices becomes <inline-formula><mml:math id="inf331"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf332"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> accounts for the inter-trial interval, and <inline-formula><mml:math id="inf333"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the average-adjusted value at the beginning of the next choice, where <inline-formula><mml:math id="inf334"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf335"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Due to the symmetry, <inline-formula><mml:math id="inf336"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> will be the same for both <inline-formula><mml:math id="inf337"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf338"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, such that we do not need to specify <inline-formula><mml:math id="inf339"><mml:mi>y</mml:mi></mml:math></inline-formula>. Second, accumulating evidence for some duration <inline-formula><mml:math id="inf340"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> now comes at cost <inline-formula><mml:math id="inf341"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. The expected return for switching attention remains unchanged, as we assume attention switches to be instantaneous. If attention switches take time, we would need to additionally penalize this time by <inline-formula><mml:math id="inf342"><mml:mi>ρ</mml:mi></mml:math></inline-formula>.</p><p>With these changes, Bellman’s equation becomes<disp-formula id="equ25"><label>(23)</label><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The resulting average-adjusted value function is shift-invariant, that is, adding a scalar to this value function for all states does not change the underlying policy (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>). This property allows us to fix the average-adjusted value for one particular state, such that all other average-adjusted values are relative to this state. For mathematical convenience, we choose <inline-formula><mml:math id="inf343"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, resulting in the new Bellman’s equation<disp-formula id="equ26"><label>(24)</label><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Comparing this to Bellman’s equation for single, isolated choices, <xref ref-type="disp-formula" rid="equ21">Equation (19)</xref>, reveals an increase in the accumulation cost from <inline-formula><mml:math id="inf344"><mml:mi>c</mml:mi></mml:math></inline-formula> to <inline-formula><mml:math id="inf345"><mml:mrow><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi></mml:mrow></mml:math></inline-formula>. Therefore, we can find a set of task parameters for which the optimal policy for single, isolated choices will mimic that for a sequence of consecutive choices. For this reason, we will focus on single, isolate choices, as they will also capture all policy properties that we expect to see for sequences of consecutive choices.</p></sec><sec id="s10-3"><title>3.3 Choosing the less desirable option</title><p>Recent work by <xref ref-type="bibr" rid="bib50">Sepulveda et al., 2020</xref> showed that when decision makers are instructed to choose the less desirable item in a similar value-based binary decision task, fixations bias choices for the lower-valued item. Here, we show that the optimal policy also makes a similar prediction. To set the goal to choosing the less desirable option, we simply flip the signs of the expected reward associated with choosing either item from <inline-formula><mml:math id="inf346"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> to <inline-formula><mml:math id="inf347"><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ21">Equation (19)</xref>,<disp-formula id="equ27"><label>(25)</label><mml:math id="m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This sign switch makes the item with the higher value the less desirable one to choose. Otherwise, the same principles apply to computing the value function and optimal policy space.</p></sec></sec><sec id="s11" sec-type="appendix"><title>4 Optimal decision policy for perceptual decisions</title><p>To apply the same principles to perceptual decision-making, we need to re-visit the interpretation of the latent states, <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub>. Those could, for example, be the brightness of two dots on a screen, and the decision maker needs to identify the brighter dot. Alternatively, they might reflect the length of two lines, and the decision maker needs to identify which of the two lines is longer. Either way, the reward is a function of <italic>z</italic><sub>1</sub>, <italic>z</italic><sub>2</sub>, and the decision maker’s choice. Therefore, the expected reward for choosing either option can be computed from the posterior <inline-formula><mml:math id="inf348"><mml:mi>z</mml:mi></mml:math></inline-formula>’s, <xref ref-type="disp-formula" rid="equ7 equ8">Equations (5) and (6)</xref>. Furthermore, these posteriors are fully determined by their means, <inline-formula><mml:math id="inf349"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf350"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, and the attention times, <italic>t</italic><sub>1</sub> and <italic>t</italic><sub>2</sub>. As a consequence, we can formulate the expected reward for choosing item <inline-formula><mml:math id="inf351"><mml:mi>j</mml:mi></mml:math></inline-formula> by the expected reward function <inline-formula><mml:math id="inf352"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>What are the consequences for this change in expected reward for the optimal policy? If we assume the attention-modulated evidence accumulation process to remain unchanged, the only change is that the expected return for choosing item <inline-formula><mml:math id="inf353"><mml:mi>j</mml:mi></mml:math></inline-formula> changes from <inline-formula><mml:math id="inf354"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> to <inline-formula><mml:math id="inf355"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore, Bellman’s equations changes to<disp-formula id="equ28"><label>(26)</label><mml:math id="m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The optimal policy follows from Bellman’s equation as before.</p><p>The above value function can only be turned into one over expected reward differences under certain regularities of <italic>R</italic><sub>1</sub> and <italic>R</italic><sub>2</sub>, which we will not discuss further at this point. Furthermore, for the above example, we have assumed two sources of perceptual evidence that need to be compared. Alternative tasks (e.g. the random dot motion task) might provide a single source of evidence that needs to be categorized. In this case, the formulation changes slightly (see, for example, <xref ref-type="bibr" rid="bib20">Drugowitsch et al., 2012</xref>), but the principles remain unchanged.</p></sec><sec id="s12" sec-type="appendix"><title>5 Properties of the optimal policy</title><p>Here, we will demonstrate some interesting properties of the optimal policy, and the associated value function and decision boundaries. To do so, we re-write the value function in its non-recursive form. To do so, let us first define the switch set <inline-formula><mml:math id="inf356"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which determines the switch times from the current time <inline-formula><mml:math id="inf357"><mml:mi>t</mml:mi></mml:math></inline-formula> onwards. Here, <inline-formula><mml:math id="inf358"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the time of the first switch after time <inline-formula><mml:math id="inf359"><mml:mi>t</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf360"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the second switch, and so on. A final decision is made at <inline-formula><mml:math id="inf361"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf362"><mml:mrow><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:msub><mml:mi>T</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, after <inline-formula><mml:math id="inf363"><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> switches with associated cost <inline-formula><mml:math id="inf364"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. As the optimal policy is the one that optimizes across choices and switch times, the associated value function can be written as<disp-formula id="equ29"><label>(27)</label><mml:math id="m29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒯</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where time expectation is over the time-evolution of <inline-formula><mml:math id="inf365"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf366"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, that also depends on <inline-formula><mml:math id="inf367"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula>. In what follows, we first derive the shift-invarance of this time-evolution, and then consider its consequences for the value function, as well as the decision boundaries.</p><sec id="s12-1"><title>5.1 Shift-invariance and symmetry of the expected reward process</title><p>Let us fix some <inline-formula><mml:math id="inf368"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula>, some time <inline-formula><mml:math id="inf369"><mml:mi>t</mml:mi></mml:math></inline-formula>, and assume that we are currently attending item 1, <inline-formula><mml:math id="inf370"><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Then, by <xref ref-type="disp-formula" rid="equ14">Equation (12)</xref>, <inline-formula><mml:math id="inf371"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be written as<disp-formula id="equ30"><label>(28)</label><mml:math id="m30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mfrac><mml:mi>σ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mi>γ</mml:mi></mml:msqrt></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mfrac><mml:mi>σ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where the <inline-formula><mml:math id="inf372"><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>’s are white noise processes associated with item 1. This shows that, for any <inline-formula><mml:math id="inf373"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula>, the change in <inline-formula><mml:math id="inf374"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf375"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, is independent of <inline-formula><mml:math id="inf376"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore, we can shift <inline-formula><mml:math id="inf377"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by any scalar <inline-formula><mml:math id="inf378"><mml:mi>C</mml:mi></mml:math></inline-formula>, and cause an associated shift in <inline-formula><mml:math id="inf379"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, that is<disp-formula id="equ31"><label>(29)</label><mml:math id="m31"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>As this holds for any choice of <inline-formula><mml:math id="inf380"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula>, it holds for all <inline-formula><mml:math id="inf381"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula>. A similar argument establishes this property for <inline-formula><mml:math id="inf382"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>.</p><p>The above decomposition of the time-evolution of <inline-formula><mml:math id="inf383"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> furthermore reveals a symmetry between <inline-formula><mml:math id="inf384"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf385"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. In particular, the same decomposition shows that <inline-formula><mml:math id="inf386"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> equals <inline-formula><mml:math id="inf387"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> if we flip <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub> and <inline-formula><mml:math id="inf388"><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore,<disp-formula id="equ32"><label>(30)</label><mml:math id="m32"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s12-2"><title>5.2 Shift-invariance of the value function</title><p>The shift-invariance of <inline-formula><mml:math id="inf389"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf390"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> implies a shift-invariance of the value function. To see this, fix some <inline-formula><mml:math id="inf391"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula> and some final choice <inline-formula><mml:math id="inf392"><mml:mi>j</mml:mi></mml:math></inline-formula>, in which case the value function according to <xref ref-type="disp-formula" rid="equ29">Equation (27)</xref> becomes<disp-formula id="equ33"><label>(31)</label><mml:math id="m33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the expectation is implicitly conditional on <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, <inline-formula><mml:math id="inf393"><mml:mi>y</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf394"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula>. Due to the shift-invariance of the time-evolution of <inline-formula><mml:math id="inf395"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf396"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, adding a scalar <inline-formula><mml:math id="inf397"><mml:mi>C</mml:mi></mml:math></inline-formula> to both <inline-formula><mml:math id="inf398"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf399"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> increases the above expectation by the same amount, <inline-formula><mml:math id="inf400"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. As a consequence,<disp-formula id="equ34"><label>(32)</label><mml:math id="m34"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>As this holds for any choice of <inline-formula><mml:math id="inf401"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf402"><mml:mi>j</mml:mi></mml:math></inline-formula>, it also holds for the maximum over <inline-formula><mml:math id="inf403"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf404"><mml:mi>j</mml:mi></mml:math></inline-formula>, and thus for the value function in general.</p><p>A similar argument shows that the value function is increasing in both <inline-formula><mml:math id="inf405"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf406"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. To see this, fix <inline-formula><mml:math id="inf407"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf408"><mml:mi>j</mml:mi></mml:math></inline-formula> and note that increasing either <inline-formula><mml:math id="inf409"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> or <inline-formula><mml:math id="inf410"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> causes the expectation in <xref ref-type="disp-formula" rid="equ33">Equation (31)</xref> to either remain unchanged or to increase to <inline-formula><mml:math id="inf411"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Therefore, for any non-negative <inline-formula><mml:math id="inf412"><mml:mi>C</mml:mi></mml:math></inline-formula>,<disp-formula id="equ35"><label>(33)</label><mml:math id="m35"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi/><mml:mo>≤</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ36"><label>(34)</label><mml:math id="m36"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi/><mml:mo>≤</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This again holds for any choice of <inline-formula><mml:math id="inf413"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf414"><mml:mi>j</mml:mi></mml:math></inline-formula>, such that it holds for the value function in general.</p><p>For the value function on expected reward differences, <inline-formula><mml:math id="inf415"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, changing both <inline-formula><mml:math id="inf416"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf417"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> by the same amount leaves <inline-formula><mml:math id="inf418"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>, and therefore the associated value <inline-formula><mml:math id="inf419"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, unchanged. In contrast, increasing only <inline-formula><mml:math id="inf420"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> or <inline-formula><mml:math id="inf421"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> by <inline-formula><mml:math id="inf422"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> increases or decreases <inline-formula><mml:math id="inf423"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> by <inline-formula><mml:math id="inf424"><mml:mi>C</mml:mi></mml:math></inline-formula>. Thus, we can use <inline-formula><mml:math id="inf425"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ23">Equation (21)</xref> and substitute it into the two above inequalities to find<disp-formula id="equ37"><label>(35)</label><mml:math id="m37"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>±</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>for some non-negative <inline-formula><mml:math id="inf426"><mml:mrow><mml:mi>C</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This shows that <inline-formula><mml:math id="inf427"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> changes sublinearly with <inline-formula><mml:math id="inf428"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>. However, we cannot anymore guarantee an increase or decrease in <inline-formula><mml:math id="inf429"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, as an increase in <inline-formula><mml:math id="inf430"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> could arise from both an increase in <inline-formula><mml:math id="inf431"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> or a decrease in <inline-formula><mml:math id="inf432"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>.</p></sec><sec id="s12-3"><title>5.3 Symmetry of the value function</title><p>The symmetry in time-evolution across <inline-formula><mml:math id="inf433"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf434"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> results in a symmetry in the value function. To show this, let us again fix <inline-formula><mml:math id="inf435"><mml:mi class="ltx_font_mathcaligraphic">𝒯</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf436"><mml:mi>j</mml:mi></mml:math></inline-formula>, such that the value function is given by <xref ref-type="disp-formula" rid="equ33">Equation (31)</xref>. Then, by <xref ref-type="disp-formula" rid="equ32">Equation (30)</xref>, the expectation in the value function becomes <inline-formula><mml:math id="inf437"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> if we flip <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, and <inline-formula><mml:math id="inf438"><mml:mi>j</mml:mi></mml:math></inline-formula>, while leaving the remaining terms of <xref ref-type="disp-formula" rid="equ33">Equation (31)</xref> unchanged. Therefore,<disp-formula id="equ38"><label>(36)</label><mml:math id="m38"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For the value function on expected reward differences, a flip of <inline-formula><mml:math id="inf439"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf440"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> corresponds to a sign change of <inline-formula><mml:math id="inf441"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>, such that we have<disp-formula id="equ39"><label>(37)</label><mml:math id="m39"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Both cases show that we are not required to find the value function for both <inline-formula><mml:math id="inf442"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf443"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> separately, as knowing one reveals the other by the above symmetry.</p></sec><sec id="s12-4"><title>5.4 Maximum <inline-formula><mml:math id="inf444"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> difference</title><p>By Bellman’s equation, <xref ref-type="disp-formula" rid="equ21">Equation (19)</xref>, it is best to switch attention if the expected return of accumulating evidence equals that of switching attention, that is, if<disp-formula id="equ40"><label>(38)</label><mml:math id="m40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Before that, <inline-formula><mml:math id="inf445"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, as otherwise, an attention switch would have already occurred. When it does, we have <inline-formula><mml:math id="inf446"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. That is, the attention switch happens if the value of doing so exceeds that for accumulating evidence by the switch cost <italic>c</italic><sub><italic>s</italic></sub>. Therefore, the difference between the value functions <italic>V</italic><sub>1</sub> and <italic>V</italic><sub>2</sub> can never be larger than the switch cost, that is<disp-formula id="equ41"><label>(39)</label><mml:math id="m41"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Once their difference equals the switch cost, a switch occurs. It is easy to see that the same property holds for the value function on expected reward differences, leading to<disp-formula id="equ42"><label>(40)</label><mml:math id="m42"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s12-5"><title>5.5 The decision boundaries are parallel to the diagonal <inline-formula><mml:math id="inf447"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></title><p>Following the optimal policy, the decision maker accumulates evidence until <inline-formula><mml:math id="inf448"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. For all times before that, <inline-formula><mml:math id="inf449"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, as otherwise, a decision is made. Let us first find an expression for the decision boundaries, and then show that these boundaries are parallel to <inline-formula><mml:math id="inf450"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. To do so, we will in most of this section fix <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub> and <inline-formula><mml:math id="inf451"><mml:mi>y</mml:mi></mml:math></inline-formula>, and drop them for notational convenience, that is <inline-formula><mml:math id="inf452"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>First, let us assume <inline-formula><mml:math id="inf453"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, such that <inline-formula><mml:math id="inf454"><mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and item 1 would be chosen if an immediate choice is required. Therefore <inline-formula><mml:math id="inf455"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>≥</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> always, and <inline-formula><mml:math id="inf456"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> once a decision is made. For a fixed <inline-formula><mml:math id="inf457"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, the value function is increasing in <inline-formula><mml:math id="inf458"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, such that reducing <inline-formula><mml:math id="inf459"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> if <inline-formula><mml:math id="inf460"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> will at some point lead to <inline-formula><mml:math id="inf461"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. The optimal decision boundary is the largest <inline-formula><mml:math id="inf462"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> for which this occurs. Expressed as a function of <inline-formula><mml:math id="inf463"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, this boundary on <inline-formula><mml:math id="inf464"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> is thus given by<disp-formula id="equ43"><label>(41)</label><mml:math id="m43"><mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>A similar argument leads to the optimal decision boundary for item 2. In this case, we assume <inline-formula><mml:math id="inf465"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, such that <inline-formula><mml:math id="inf466"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>≥</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> always, and <inline-formula><mml:math id="inf467"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> once a decision is made. The sublinear growth of the value function in both <inline-formula><mml:math id="inf468"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf469"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> implies that <inline-formula><mml:math id="inf470"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> grows at most as fast as <inline-formula><mml:math id="inf471"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, such that there will be some <inline-formula><mml:math id="inf472"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> at which <inline-formula><mml:math id="inf473"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> turns into <inline-formula><mml:math id="inf474"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. The optimal decision boundary is the smallest <inline-formula><mml:math id="inf475"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> for which this occurs, that is<disp-formula id="equ44"><label>(42)</label><mml:math id="m44"><mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Note that both boundaries are on <inline-formula><mml:math id="inf476"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> as a function of <inline-formula><mml:math id="inf477"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, and <inline-formula><mml:math id="inf478"><mml:mi>y</mml:mi></mml:math></inline-formula>.</p><p>To show that these boundaries are parallel to the diagonal, we will use the shift-invariance of the value function, leading, for some scalar <inline-formula><mml:math id="inf479"><mml:mi>C</mml:mi></mml:math></inline-formula>, to<disp-formula id="equ45"><label>(43)</label><mml:math id="m45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we have used <inline-formula><mml:math id="inf480"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. This shows that increasing <inline-formula><mml:math id="inf481"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> by some scalar <inline-formula><mml:math id="inf482"><mml:mi>C</mml:mi></mml:math></inline-formula> shifts the boundary on <inline-formula><mml:math id="inf483"><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> by the same amount. Therefore, the decision boundary for choosing item 1 is parallel to <inline-formula><mml:math id="inf484"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>An analogous argument for <inline-formula><mml:math id="inf485"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> results in<disp-formula id="equ46"><label>(44)</label><mml:math id="m46"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which showing that the same property holds for the decision boundary for choosing item 2. Overall, this confirms that the decision boundaries only depend on the expected reward difference (i.e., the direction orthogonal to <inline-formula><mml:math id="inf486"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>), confirming that it is sufficient to compute <inline-formula><mml:math id="inf487"><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> instead of <inline-formula><mml:math id="inf488"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s12-6"><title>5.6 Impact of re-scaled costs, rewards, and standard deviations</title><p>To investigate the impact of re-scaling all reward and cost-dependent parameters, <inline-formula><mml:math id="inf489"><mml:mi>c</mml:mi></mml:math></inline-formula>, <italic>c</italic><sub><italic>s</italic></sub>, <inline-formula><mml:math id="inf490"><mml:mi>σ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf491"><mml:msub><mml:mi>σ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:math></inline-formula>, by a constant factor <inline-formula><mml:math id="inf492"><mml:mi>α</mml:mi></mml:math></inline-formula>, we first show that this re-scaling causes an equal re-scaling of the reward expectation process. To do so, note that <inline-formula><mml:math id="inf493"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>→</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf494"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> causes the expected reward expectation decomposition, <xref ref-type="disp-formula" rid="equ30">Equation (28)</xref> to yield<disp-formula id="equ47"><label>(45)</label><mml:math id="m47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mi>σ</mml:mi><mml:msqrt><mml:mi>γ</mml:mi></mml:msqrt></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>That is, the expected reward process now describes the evolution of a re-scaled version, <inline-formula><mml:math id="inf495"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, of the expected reward. Therefore, with slight abuse of notation, for a fixed switch set <inline-formula><mml:math id="inf496"><mml:mi>τ</mml:mi></mml:math></inline-formula> and final choice <inline-formula><mml:math id="inf497"><mml:mi>j</mml:mi></mml:math></inline-formula>,<disp-formula id="equ48"><label>(46)</label><mml:math id="m48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where we have made explicit the dependency on <inline-formula><mml:math id="inf498"><mml:mi>σ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf499"><mml:msub><mml:mi>σ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:math></inline-formula>.</p><p>To show the effect of this on the value function, keep again <inline-formula><mml:math id="inf500"><mml:mi>τ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf501"><mml:mi>j</mml:mi></mml:math></inline-formula> fixed, and use <inline-formula><mml:math id="inf502"><mml:mrow><mml:mi>c</mml:mi><mml:mo>→</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf503"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, resulting in the value function<disp-formula id="equ49"><label>(47)</label><mml:math id="m49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>which establishes that<disp-formula id="equ50"><label>(48)</label><mml:math id="m50"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As this holds for all <inline-formula><mml:math id="inf504"><mml:mi>τ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf505"><mml:mi>j</mml:mi></mml:math></inline-formula>, it is true in general. Therefore, re-scaling all costs, rewards, and standard deviations of prior and likelihood results in equivalent re-scaling of the value function, and an analogous shift of switch and decision boundaries.</p></sec></sec><sec id="s13" sec-type="appendix"><title>6 Simulation details</title><sec id="s13-1"><title>6.1 Computing the optimal policy</title><p>In Section 3, we described the Bellman equation (<xref ref-type="disp-formula" rid="equ24">Equation (22)</xref>) which outputs the expected return given these four parameters: currently attended item (<inline-formula><mml:math id="inf506"><mml:mi>y</mml:mi></mml:math></inline-formula>), reward difference (<inline-formula><mml:math id="inf507"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>), expected return for accumulating more evidence, and expected return for switching attention. Note that the symmetry of the value function (Section 5) allows us to drop <inline-formula><mml:math id="inf508"><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:math></inline-formula> from the original <xref ref-type="disp-formula" rid="equ24">Equation (22)</xref>. Solving this Bellman equation provides us with a four-dimensional ‘policy space’ which assigns the optimal action to take at any point in this space defined by the four parameters above.</p><p>The solution to the optimal policy can be found numerically by backwards induction (<xref ref-type="bibr" rid="bib58">Tajima et al., 2016</xref>). To do so, first we assume some large <inline-formula><mml:math id="inf509"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where a decision is guaranteed. In this case, <inline-formula><mml:math id="inf510"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for both <inline-formula><mml:math id="inf511"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf512"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. We call this the base case. From this base case, we can move one time step backwards in <italic>t</italic><sub>1</sub> (<inline-formula><mml:math id="inf513"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>):<disp-formula id="equ51"><label>(49)</label><mml:math id="m51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The second expression in the maximum can be evaluated, since we assume a decision is made at time t. But <inline-formula><mml:math id="inf514"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, which is the value function for switching attention, is unknown. This unknown value function is given by<disp-formula id="equ52"><label>(50)</label><mml:math id="m52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In this expression, the second term can again be found, but <inline-formula><mml:math id="inf515"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is unknown. Looking at the two expressions above, we see that under the parameters <inline-formula><mml:math id="inf516"><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf517"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf518"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, which cannot both be true. Therefore, we first assume that <italic>V</italic><sub>1</sub> is not determined by <inline-formula><mml:math id="inf519"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, removing the <inline-formula><mml:math id="inf520"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> term from the maximum. This allows us to find <inline-formula><mml:math id="inf521"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ51">Equation (49)</xref>. Then, we compute <xref ref-type="disp-formula" rid="equ52">Equation (50)</xref> including the <inline-formula><mml:math id="inf522"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> term. If we find that <inline-formula><mml:math id="inf523"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="inf524"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≠</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, which means the <inline-formula><mml:math id="inf525"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> term could not have mattered in <xref ref-type="disp-formula" rid="equ51">Equation (49)</xref>, and we are done. If not, we re-compute <italic>V</italic><sub>1</sub> with the <inline-formula><mml:math id="inf526"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> term included, and we are done. Therefore, we were able to compute <italic>V</italic><sub>1</sub> and <italic>V</italic><sub>2</sub> under the parameters <inline-formula><mml:math id="inf527"><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> using information about <inline-formula><mml:math id="inf528"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf529"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Using the same approach, we can find <inline-formula><mml:math id="inf530"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> based on <inline-formula><mml:math id="inf531"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf532"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, given that we know <inline-formula><mml:math id="inf533"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> above a certain <inline-formula><mml:math id="inf534"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, we can move backwards to compute <italic>V</italic><sub>1</sub> and <italic>V</italic><sub>2</sub> for <inline-formula><mml:math id="inf535"><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="inf536"><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, and so on, until <inline-formula><mml:math id="inf537"><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> for all relevant values of <inline-formula><mml:math id="inf538"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>. Subsequently, we can do the same moving backwards in <italic>t</italic><sub>2</sub>, solving for <inline-formula><mml:math id="inf539"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf540"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, …, <inline-formula><mml:math id="inf541"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Following this, we can continue with the same procedure from <inline-formula><mml:math id="inf542"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, until we have found <inline-formula><mml:math id="inf543"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> for all combinations of <italic>t</italic><sub>1</sub> and <italic>t</italic><sub>2</sub>.</p><p>In practice, the parameters of the optimal policy space were discretized to allow for tractable computation. We set the large time at which decisions are guaranteed at <inline-formula><mml:math id="inf544"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, which we determined empirically. Time was discretized into steps of <inline-formula><mml:math id="inf545"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The item values, and their difference (<inline-formula><mml:math id="inf546"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>) were also discretized into steps of 0.05.</p><p>Upon completing this exercise, we now have two 3-dimensional optimal policy spaces. The decision maker’s location in this policy space is determined by <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, and <inline-formula><mml:math id="inf547"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>. Each point in this space is assigned an optimal action to take (choose item, accumulate more evidence, switch attention) based on which expression was largest in the maximum of the respective Bellman equation. The decision maker moves between the two policy spaces depending on which item they are attending to (<inline-formula><mml:math id="inf548"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>).</p><p>In order to find the three-dimensional boundaries that signify a change in optimal action to take, we took slices of the optimal policy space in planes of constant <inline-formula><mml:math id="inf549"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>’s. We found the boundary between different optimal policies within each of these slices. We in turn approximated the three-dimensional contour of the optimal policy boundaries by collating them along the different <inline-formula><mml:math id="inf550"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula>’s.</p></sec><sec id="s13-2"><title>6.2 Finding task parameters that best match human behavior</title><p>In computing the optimal policy, there were several free parameters that determined the shape of the policy boundaries, thereby affecting the behavior of the optimal model. These parameters included <inline-formula><mml:math id="inf551"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf552"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf553"><mml:mi>c</mml:mi></mml:math></inline-formula>, <italic>c</italic><sub><italic>s</italic></sub>, and <inline-formula><mml:math id="inf554"><mml:mi>γ</mml:mi></mml:math></inline-formula>. Our goal was to find a set of parameters that qualitatively mimic human behavior as best as possible. To do so, we performed a random search over the following parameter values: <inline-formula><mml:math id="inf555"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.05</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (steps size 0.001), <inline-formula><mml:math id="inf556"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (steps size 0.01), <inline-formula><mml:math id="inf557"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (step size 1), <inline-formula><mml:math id="inf558"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (step size 1), <inline-formula><mml:math id="inf559"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (step size 0.001) (<xref ref-type="bibr" rid="bib7">Bergstra and Bengio, 2012</xref>).</p><p>To find the best qualitative fit, we simulated behavior from a randomly selected set of parameter values (see next section for simulation procedure). From this simulated behavior, we evaluated the match between human and model behavior by applying the same procedure to each of <xref ref-type="fig" rid="fig3">Figure 3B,C,E</xref>. For each bin for each plot, we subtracted the mean values between the model and human data, then divided this difference by the standard deviation of the human data corresponding to that bin, essentially computing the effect size of the difference in means. We computed the sum of these effect sizes for every bin, which served as a metric for how qualitatively similar the curves were between the model and human data. We performed the same procedure for all three figures, and ranked the sum of the effect sizes for all simulations. We performed simulations for over 2,000,000 random sets of parameter values. The set of parameters for which our model best replicated human behavior according to the above criteria was <inline-formula><mml:math id="inf560"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.0065</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf561"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0.23</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf562"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>27</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf563"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>18</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf564"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s13-3"><title>6.3 Simulating decisions with the optimal policy</title><p>The optimal policy allowed us to simulate decision making in a task analogous to the one humans performed in <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>. For a given set of parameters, we first computed the optimal policy. In a simulated trial, two items with values <italic>z</italic><sub>1</sub> and <italic>z</italic><sub>2</sub> are presented. At trial onset, the model attends to an item randomly (<inline-formula><mml:math id="inf565"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), and starts accumulating noisy evidence centered around the true values. At every time step (<inline-formula><mml:math id="inf566"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>), the model evaluates <inline-formula><mml:math id="inf567"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> using the mean of the posteriors between the two items (see <xref ref-type="disp-formula" rid="equ7 equ8">Equations (5) and (6)</xref>). Then, the model performs the optimal action associated with its location in the optimal policy space. If the model makes a decision, then the trial is over. If the model instead accumulates more evidence, then the above procedure is repeated for the next time step. If the model switches attention, it does not obtain further information about either item, but switches attention to the other item. Switching attention allows for more reliable evidence from the now-attended item, and also switches the optimal policy space to the appropriate one (see <xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><p>To allow for a relatively fair comparison between the model and human data, we simulated the same number of subjects (<inline-formula><mml:math id="inf568"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>39</mml:mn></mml:mrow></mml:math></inline-formula>) for the model, but with a larger number of trials. For each simulated subject, trials were created such that all pairwise combinations of values between 0 and 7 were included, and this was iterated 20 times. This yielded a total of 1280 trials per subject.</p></sec><sec id="s13-4"><title>6.4 Attention diffusion model</title><p>In order compare the decision performance of the optimal model to that of the original attentional drift diffusion model (aDDM) proposed by <xref ref-type="bibr" rid="bib34">Krajbich et al., 2010</xref>, we needed to ensure that neither model had an advantage by receiving more information. We did so by making sure that the signal-to-noise ratios of evidence accumulation of both models were identical. In aDDM, the evidence accumulation evolved according to the following process, in steps of 0.05 s (assuming y = 1):<disp-formula id="equ53"><label>(51)</label><mml:math id="m53"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>v</italic><sub><italic>t</italic></sub> is the relative decision value that represents the subjective value difference between the two items at time <inline-formula><mml:math id="inf569"><mml:mi>t</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf570"><mml:mi>d</mml:mi></mml:math></inline-formula> is a constant that controls the speed of integration (in <inline-formula><mml:math id="inf571"><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), <inline-formula><mml:math id="inf572"><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> controls the biasing effect of attention, and <inline-formula><mml:math id="inf573"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is a normally distributed random variable zero mean and variance <inline-formula><mml:math id="inf574"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. Written differently, the difference in the attention-weighted momentary evidence between item 1 and item 2 can be expressed as<disp-formula id="equ54"><label>(52)</label><mml:math id="m54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>δ</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf575"><mml:mi>d</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf576"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> were replaced by <inline-formula><mml:math id="inf577"><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf578"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, respectively. Here, the variance term <inline-formula><mml:math id="inf579"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> can be split into two parts, such that the <inline-formula><mml:math id="inf580"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:math></inline-formula> term can be expressed as<disp-formula id="equ55"><label>(53)</label><mml:math id="m55"><mml:mrow><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The signal-to-noise ratios (i.e. the ratio of mean over standard deviation) of the two terms in the above equation are <inline-formula><mml:math id="inf581"><mml:mfrac><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:msqrt><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="inf582"><mml:mfrac><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:msqrt></mml:mrow></mml:mfrac></mml:math></inline-formula>, respectively.</p><p>Continuing to assume <inline-formula><mml:math id="inf583"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, in the Bayes-optimal model, evidence accumulation evolves according to<disp-formula id="equ56"><label>(54)</label><mml:math id="m56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>δ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>γ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Therefore, the difference in the attention-weighted momentary evidence between item 1 and item 2 can be expressed as:<disp-formula id="equ57"><label>(55)</label><mml:math id="m57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>δ</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>γ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The signal-to-noise ratios of the two terms in the above equation are <inline-formula><mml:math id="inf584"><mml:mfrac><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msqrt><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="inf585"><mml:mfrac><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:msqrt></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:math></inline-formula>, respectively.</p><p>In order to match the signal-to-noise ratios of the two models, we set equal their corresponding expressions, to find the following relationship between the parameters of the two models:<disp-formula id="equ58"><label>(56)</label><mml:math id="m58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Therefore, we simulated the aDDM with model parameters <inline-formula><mml:math id="inf586"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:msqrt></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf587"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>In the original aDDM model, the model parameters were estimated by fitting the model behavior to human behavior after setting a decision threshold at ±1. Since we adjusted some of the aDDM parameters, we instead iterated through different decision thresholds (1 through 10, in increments of 1) and found the value that maximizes model performance. To keep it consistent with behavioral data, we generated 39 simulated participants that each completed 200 trials where the two item values were drawn from the prior distribution of the optimal policy model, <inline-formula><mml:math id="inf588"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> using both the optimal model and the aDDM model.</p></sec></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63436.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Tsetsos</surname><given-names>Konstantinos</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Tsetsos</surname><given-names>Konstantinos</given-names> </name><role>Reviewer</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Although recent research has described the interplay between attention and decision-making processes, the merits of employing selective attention during choice tasks remain largely underexplored. This paper closes this gap by offering a normative framework that specifies how reward-maximizing agents should employ attention while making value-based decisions. This framework, asides its theoretical importance, makes contact with the existing empirical literature while also providing detailed behavioural predictions that can be tested in future experiments.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Optimal policy for attention-modulated decisions explains human fixation behavior&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Konstantinos Tsetsos as the Reviewing Editor and Reviewer #, and the evaluation has been overseen by Joshua Gold as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require a modest amount of additional new data, as they do with your paper, we are asking that the manuscript be revised to either limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Our expectation is that the authors will eventually carry out the additional experiments and report on how they affect the relevant conclusions either in a preprint on bioRxiv or medRxiv, or if appropriate, as a Research Advance in <italic>eLife</italic>, either of which would be linked to the original paper.</p><p>Summary:</p><p>In this paper the authors derive a normative model of attentional switching during binary value-based decisions. The model the authors propose assumes that attentional allocation is under the control of the agent, who on each moment decides among halting deliberation and choosing an alternative, carrying on sampling from the currently attended alternative, switching attention to the other alternative. Under certain assumptions about deliberation and attentional allocation costs, the authors derive the optimal policy, showing also that this policy reproduces key aspects of human behaviour. The approach here stands in contrast with the majority of past research on this topic, which has assumed that attentional allocation is exogenous and that it influences- but is not influenced by- the ongoing choice process. All reviewers agreed that this is an interesting and timely article that takes a normative approach to the important issue of attentional allocation in decision-making tasks. However, the reviewers also agreed that there are several points that will need to be addressed in a revision.</p><p>Essential revisions</p><p>1. Link between the normative model and human data.</p><p>One of the main claims in the paper is that the normative model reproduces key aspects of human behaviour in a value-based binary choice task reported elsewhere (Krajbich et al., 2010). This claim needs to be backed up by additional analyses and clarifications. In particular:</p><p>a. In Figure 3A, the model predicts a linear choice curve (as opposed to a sigmoidal in the human data) while, also unlike in the data, the RT curves are concave. Are the shapes of these curves a general feature of the model or do they emerge for a certain parametrisation? Would for example the results look different with fixed bounds?</p><p>b. Similarly, in Figure 3D, the model shows that the last fixation influences probability of choice equally across value differences. In the human data this effect diminishes as value difference increases. Is this prediction or a feature of the model?</p><p>c. In Figure 3C the authors focus on the number of switches, which however are highly correlated with RTs. Can the authors show in addition the number of switches per unit of time (equivalent to probability of switching) in the human data and in their model?</p><p>d. In Figure 4B-C, RTs and &quot;value sum&quot; may covary, with high value sums presumably resulting in shorter RTs. Does the value sum effect persist in the model and in the data once the influence of RTs is accounted for?</p><p>2. Comparison between the normative and aDDM models.</p><p>The two models differ in the way they conceptualise attentional switching (exogenous vs. endogenous). Does this difference manifest itself in the predictions the two models make? And can the human data distinguish between the two models? The authors comment in the Discussion that their model is more constrained by normative considerations, and may thus fit the data worse than other ad-hoc models. Asides quantitative fitting, which the authors may elect to perform, we would like to see a qualitative comparison between the two models.</p><p>a. How does the probability of switching changes as a function of time (within trial) and as a function of absolute value difference and sum (across trials) in the two models and in the data?</p><p>b. How does the fixation duration changes as a function of time (within trial) and as a function of absolute value difference and sum (across trials) in the two models and in the data?</p><p>c. The model seems to predict a non-negligible number of single fixation trials. How does this align with the data and the aDDM predictions?</p><p>d. How do reaction time distributions look like under the normative model? Are these comparable to the RT distributions in the data?</p><p>e. Please also show the aDDM predictions together with the novel predictions made by the normative model in Figure 4C.</p><p>f. The comparison between the two models is currently done on the basis of mean reward. How do the predictions of the models compare to the mean reward accrued by human participants in Krajbich et al? Please also clarify in the main text that the models are not compared on the basis of goodness of fit. In particular, in the paragraph starting in line 260, terms such as &quot;outperformed&quot;, &quot;competitive performance&quot;, &quot;comparison&quot; are ambiguous.</p><p>g. Please explain why the model shows the pattern that is demonstrated in Figure 3F. Is this pattern also predicted by the aDDM?</p><p>3. Comprehensibility of the modelling.</p><p>The authors have done an admirable job of boiling down some heavy mathematics (in the SI) into just the key steps in the main text. A lot of this builds on prior work in Tajima et al. Still, the authors could do more to explain the math, which would make this paper more self-contained and really help the reader understand the core ideas/intuitions.</p><p>a. Equation 1 – it isn't obvious how the mean will behave over time or where this expressions comes from. It would be helpful to state that the z part is the prior, and that as t-&gt;infinity the σ terms become negligible and the expression converges to x/t, namely the true value. The σ-squared terms seem to come out of nowhere. In the methods the authors explain that this has to do with Fisher information, but most readers won't know what that is or why it is the appropriate thing to include here. Also, σ<sub>x</sub> is defined later in the text, but should be defined up front here.</p><p>b. Between Equation 1 and 2: In the means for δ<sub>x</sub>, one has a δ<sub>t</sub> multiplying z and one doesn't. Why? Is this a typo? The δ<sub>t</sub> should always be there, but again, it isn't obvious.</p><p>c. Equation 2: Why does the mean have a z1| at the beginning of it? Is that a typo?</p><p>d. Could the authors elaborate more on why/when the decision maker chooses to switch attention? They say that the decision at each time point only depends on the difference in posterior means but Figure 2c seems to indicate that if the difference in posterior means stays constant over a period of time, then the process enters the &quot;switch&quot; zone and shifts attention.</p><p>4. Model assumptions.</p><p>a. The model assumes that attention can take one of two discrete states. However, attention is often regarded as operating in a more graded fashion, which would necessitate parameter kappa in the model to be free to change within a trial. This will probably render the model intractable. However, a more viable and less radical assumption, would be to allow for a third &quot;divided attention&quot; mode in which the agent samples equally from both alternatives (divided attention mode). If this extension is technically challenging, one conceptual question that the authors can discuss in the paper, is whether the normative model would ever switch away from this divided attention mode.</p><p>b. The authors need to assume a certain prior, namely z_bar = 0, in order to always get a positive effect of attention. This seems like an important controversy in the model; it is a noticeably non-Bayesian feature of a Bayesian model. The authors try to explain this away by noting that the original rating scale included both negative and positive values. However, only positive items were included in the choice task, and there is a consistently positive effect of attention on choice for other tasks (see Cavanagh et al. 2014; Smith and Krajbich 2018; Smith and Krajbich 2019) with only positive outcomes. This needs to be more openly acknowledged and discussed.</p><p>c. The last paragraph of Discussion talks about a lack of benefit of focussed attention in the analysed task. Would focussing attention would become beneficial in decision tasks with more than 2 options? Although answering this question would be a separate paper, a few sentences on generalising this work to more than two options could be included in the Discussion.</p><p>5. Coverage of literature.</p><p>a. In the Introduction, the authors state that the &quot;final choices are biased towards the item that they looked at longer, irrespective of its desirability&quot;. This is not quite true. The desirability does matter, as shown in Smith and Krajbich 2019, as well as Westbrook et al. 2020. Moreover, as the authors note in the discussion, Armel et al. 2008 show that attention has a reverse effect when the items are aversive. Please update the introduction accordingly.</p><p>b. The authors do not mention that there is some work that has argued for value attracting attention in multi-alternative choice. While that work does not go to the lengths that this paper does, it does make normative arguments for why this should occur, namely to eliminate non-contenders (Krajbich and Rangel 2011; Towal et al. 2013; Gluth et al. 2020). Finally, the authors might also want to mention Ke, Shen, Villas-Boas (2016), which also takes a normative approach to information search in consumer choice.</p><p>c. On page 2 the authors state that &quot;no current normative framework incorporates control of attention as an intrinsic aspect of the decision-making process&quot;. This does not seem to be accurate given the study by of Cassey et al. (2013). The key difference is that in Cassey et al. the focus was placed on the fixed duration paradigm, while the present manuscript focuses on the free-response paradigm. Please clarify the link of the current study with Cassey et al.</p><p>d. In lines 318-321, the authors state that the model of Cassey et al. &quot;could not predict when they [fixation switches] ought to occur&quot;. The model of Cassey et al. does predict when the optimal switching times are, but for the case of a fixed duration paradigm with \kappa = 0. In this case the optimal switch policy is much simpler (single or at most double switch at particular times) than in the free-response paradigm nicely analysed in the present manuscript.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Optimal policy for attention-modulated decisions explains human fixation behavior&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Joshua Gold (Senior Editor) and a Reviewing Editor.</p><p>Summary:</p><p>The authors have done an excellent and thorough job in addressing most of the comments that were raised during the first review. Please find below a list of remaining issues.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>Essential revisions</p><p>1. In our previous points 2a-b the request was to show the switch rate and fixation duration as a function of time, value sum and value difference. We apologise if that was not clear previously but with the term &quot;time&quot; we referred to elapsed time within a trial rather than reaction times (RT). Because RT's will be influenced by various properties of the trial (e.g. trial difficulty) the analyses reported in the revision are not very easy to interpret. Additionally, we are puzzled by the fact that the aDDM model predicts non-flat switch rates and fixation durations as a function of the different quantities (Figure 4—figure supplement 1), given that switching in the aDDM version the authors used is random. The aim of these previous points was to (a) highlight the differences between random switching (aDDM) and deliberate switching (optimal model), and (b) understand how switching tendencies change as a function of trial-relevant quantities and time elapsed in the optimal model. We appreciate that such analyses might be difficult to perform given the interrelationship among time, value sum and absolute value difference. Below we offer a few suggestions:</p><p>– One possibility is to consider a &quot;stimulus locked&quot; approach, in which the switch rate and fixation duration is plotted as a function of time elapsed from the stimulus onset and up to &quot;x&quot; milliseconds before the response. Inevitably, later time points will more likely include certain trial types, e.g. only difficult trials (or trials with low value sum). The authors can consider using a &quot;stratification&quot; approach, subsampling the trials such that all time-points have comparable trial distributions (in terms of value difference and value sum). The influence of value difference and value sum can be examined using median splits based on these quantities.</p><p>– Specifically for the switch rate analysis, the authors could perform a logistic regression trying to predict at each point in time the probability of switching, also considering covariates such as value sum or absolute value difference.</p><p>– Since the last fixation can be cut short, we recommend excluding the last fixation from these analyses.</p><p>– We recommend that the scaling of the x and y axis in the data and in the models is the same to allow comparison in absolute terms.</p><p>2. Krajbich et al. 2010 used an aDDM implementation in which fixations were not random but instead sampled from the empirical switching times distributions (thus fixations depended on fixation number, trial difficulty etc). The authors currently do not acknowledge this previous implementation. The aDDM with random switching is a good baseline for the scope of this paper, but the version used by Krajbich et al. 2010 makes different predictions than the random aDDM; and this should be explicitly acknowledged. For instance, the aDDM where switching matches the empirical distributions, accounts for the fact that the first fixations were shorter than the rest. Discussing this non-random aDDM used by Krajbich et al. 2010, will fit easily in the current discussion, since the optimal model offers a rationale fort the empirical fixation patterns that the older work simply incorporated into the aDDM simulations.</p><p>3. The authors slightly mischaracterise Krajbich and Rangel 2011 by saying that &quot;fixation patterns were assumed to be either independent of the decision-making strategy&quot;. That paper did condition fixation patterns on the values of the items. Here is a direct quote from the Discussion: &quot;These patterns are interesting for several reasons. First, they show that the fixation process is not fully independent from the valuation process, and contains an element of choice that needs to be explained in further work.&quot;</p><p>4. When comparing the mean reward of the models, the authors simulate the aDDM not with the parameters from Krajbich et al. 2010, but with different parameters meant to &quot;ensure a fair comparison&quot; between the models. We believe that this approach sets the aDDM to a disadvantage. If the best-fitting parameters of the &quot;optimal model&quot; lead to a lower signal-to-noise ratio than the aDDM best-fitting parameters, that should be acknowledged and accepted as is. We recommend the authors state upfront that the best-fitting optimal model does not outperform the data or the aDDM. However, if you use a non-best-fitting aDDM, then the aDDM underperforms both.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63436.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions</p><p>1. Link between the normative model and human data.</p><p>One of the main claims in the paper is that the normative model reproduces key aspects of human behaviour in a value-based binary choice task reported elsewhere (Krajbich et al., 2010). This claim needs to be backed up by additional analyses and clarifications. In particular:</p><p>a. In Figure 3A, the model predicts a linear choice curve (as opposed to a sigmoidal in the human data) while, also unlike in the data, the RT curves are concave. Are the shapes of these curves a general feature of the model or do they emerge for a certain parametrisation? Would for example the results look different with fixed bounds?</p></disp-quote><p>The model predicts linear choice curves in Figure 3A due to the difficulty of the task, which is set by the model parameters including the evidence noise term (𝜎<sup>&quot;</sup>). Therefore, if we set the evidence noise term (𝜎<sup>&quot;</sup>) to a lower value, the model will exhibit sigmoidal choice curves because the decision becomes easier at extreme value differences. Below is the RT curve after decreasing the evidence noise term (𝜎<sup>&quot;</sup>) from 27 to 5, which renders the decisions easier due to an overall more reliable evidence accumulation. This can be seen in Figure 3—figure supplement 1A.</p><disp-quote content-type="editor-comment"><p>b. Similarly, in Figure 3D, the model shows that the last fixation influences probability of choice equally across value differences. In the human data this effect diminishes as value difference increases. Is this prediction or a feature of the model?</p></disp-quote><p>Similar to above, for Figure 3D, decreasing the noise term causes the choice curves to reach an asymptote at less extreme value differences. This is reflected in the last fixation effect, which shows a diminishing effect as the value difference increases. In Figure 3—figure supplement 1B is the last fixation effect curve after decreasing the evidence noise term (𝜎<sup>&quot;</sup>) from 27 to 5.</p><disp-quote content-type="editor-comment"><p>c. In Figure 3C the authors focus on the number of switches, which however are highly correlated with RTs. Can the authors show in addition the number of switches per unit of time (equivalent to probability of switching) in the human data and in their model?</p></disp-quote><p>We thank the reviewers for this suggestion, and agree that the rate of switching is an important measure to report. Human data showed no relationship between rate of switching and trial difficulty (Figure 3—figure supplement 1D; t(38) = -0.32, p = 0.75). Interestingly, we found that with the large number of simulated trials, our optimal model shows an increase in the rate of switching as the task difficulty decreases (Figure 3—figure supplement 1E; t(38) = 2.96, p = 0.0052). However, when using the same number of trials as human data, this relationship was not apparent in the model (Figure 3—figure supplement 1F; t(38) = 1.02, p = 0.31), suggesting the human data may be underpowered to show such a relationship. Furthermore, we find that an increase in switch rate with decreasing trial difficulty is not a general property of the optimal model, as a significant increase in the switch cost (𝐶<sub>$</sub> from 0.018 to 0.1) reduces the overall number of switches, and removes this effect (Figure 3—figure supplement 1G; t(38) = -0.50, p = 0.62), even with a large number of simulated trials.</p><p>We have added the following to the Results to briefly summarize the switch rate analysis:</p><p>“Since the number of switches is likely correlated with response time, we also looked at switch rate (number of switches divided by response time). Here, although human data showed no relationship between switch rate and trial difficulty, model behavior showed a positive relationship, suggesting an increased rate of switching for easier trials. However, this effect was absent when using the same number of trials as humans, and did not generalize across all model parameter values (Figure 3—figure supplement 2).”</p><disp-quote content-type="editor-comment"><p>d. In Figure 4B-C, RTs and &quot;value sum&quot; may covary, with high value sums presumably resulting in shorter RTs. Does the value sum effect persist in the model and in the data once the influence of RTs is accounted for?</p></disp-quote><p>To address this, we repeated the analysis for the effect of value sum on the choice bias coefficients using a regression model with both value sum and RT as independent variables. We fit a regression model for each participant, then performed a t-test of the regression coefficients across participants. For simulated data from the model, after accounting for the RT, value sum still had a significant effect on choice bias (t(38) = 7.88, p &lt; 0.001). Conversely, in the regression model for RT, adding value sum as another independent variable still led to a significant effect of RT on the choice bias coefficients (t(38) = -5.73, p &lt; 0.001).</p><p>For human data, value sum had a significant effect on choice bias coefficients after adding RT to the regression (t(38) = 2.91, p = 0.006). RT had a non-significant effect on choice bias after adding value sum to the regression, although it was trending in the expected direction (t(38) = -1.32, p = 0.20).</p><p>We added the following segment to the Results and Methods and Materials sections:</p><p>Results:</p><p>“Since response time may be influenced by the sum of the two item values and vice versa, we repeated the above analyses using a regression model that includes both value sum and response time as independent variables (see Methods and Materials). The results were largely consistent for both model (effect of RT on choice bias: t(38) = -5.73, p &lt; 0.001, effect of value sum: t(38) = 7.88, p &lt; 0.001) and human (effect of RT: t(38) = -1.32, p = 0.20, effect of value sum: t(38) = 2.91, p = 0.006) behavior.”</p><p>Methods and Materials:</p><p>“To test for the effect of RT and value sum on choice bias after accounting for the other variable, we used a similar approach and used both RT and value sum as independent variables in the regression model and the choice bias coefficient as the dependent variable.”</p><disp-quote content-type="editor-comment"><p>2. Comparison between the normative and aDDM models.</p><p>The two models differ in the way they conceptualise attentional switching (exogenous vs. endogenous). Does this difference manifest itself in the predictions the two models make? And can the human data distinguish between the two models? The authors comment in the Discussion that their model is more constrained by normative considerations, and may thus fit the data worse than other ad-hoc models. Asides quantitative fitting, which the authors may elect to perform, we would like to see a qualitative comparison between the two models.</p></disp-quote><p>Indeed, we had fairly limited qualitative analysis in how our model behavior differs from that of the aDDM, and – potentially – from human data. We have thus performed additional analyses that we describe below. Following this, we provide the text we added to the main text to describe these analyses.</p><disp-quote content-type="editor-comment"><p>a. How does the probability of switching changes as a function of time (within trial) and as a function of absolute value difference and sum (across trials) in the two models and in the data?</p></disp-quote><p>To test the relationship between switch rate and time, for each participant, we divided all trials into five equallysized bins based on RT. The plots show the average curves across participants, where vertical error bars indicate SEM for the relevant y-variable (e.g., switch rate), and horizontal error bars indicate the SEM of the bin means. A linear relationship between the x and y variables were performed by fitting a linear regression model within each participant, then performing a t-test of the regression coefficients across subjects against zero. Analogous binning and statistical procedures were used when dividing trials by value sum and value difference. For model simulations, we used the same trials and their corresponding item values as the human task.</p><p>In human data, the probability of switching decreases as a function of time (t(38) = -4.49, p &lt; 0.001), while this relationship is neither apparent in the optimal model nor the aDDM (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>).</p><fig id="respfig1"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig1-v2.tif"/></fig><p>However, the shape of the optimal model curve suggested that trials with only a single fixation (switch rate = 0) may be distorting the relationship between switch rate and time. When only including trials where at least one switch occurred, both models predicted a decrease in switch rate over time, consistent with human data (optimal model: t(38) = -29.6, p &lt; 0.001, aDDM: t(38) = -7.70, p &lt; 0.001). This suggests that in both models, single fixation trials significantly affect the switch rate (<xref ref-type="fig" rid="respfig2">Author response image 2</xref>).</p><fig id="respfig2"><label>Author response image 2.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig2-v2.tif"/></fig><p>The shape of the curve before and after removing single fixation trials suggests that the RT distribution in single fixation trials are more tightly distributed in the optimal model compared to the aDDM. Plotting the RT distribution of these trials confirmed this prediction.</p><fig id="respfig3"><label>Author response image 3.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig3-v2.tif"/></fig><p>Regarding the relationship between switch rate and value sum, human data showed no significant relationship (value sum, t(38) = -0.84, p = 0.40). However, both the optimal model and the aDDM showed a negative association, such that switch rate decreased as the value sum increased, suggesting that the model is less likely to switch attention within the same time frame for trials where higher value items are being compared (optimal model, t(38) = -4.11, p &lt; 0.001; aDDM, t(38) = -2.09, p = 0.044) (<xref ref-type="fig" rid="respfig4">Author response image 4</xref>).</p><fig id="respfig4"><label>Author response image 4.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig4-v2.tif"/></fig><p>Regarding the relationship between switch rate and absolute value difference (i.e., trial difficulty), human data again showed no significant relationship (t(38) = -0.67, p = 0.51). The optimal model also showed no significant relationship between switch rate and value difference (t(38) = -0.41, p = 0.68). However, the aDDM showed a positive association, suggesting that more switches occurred within the same time-frame for easier trials (t(38) = 4.62, p &lt; 0.001) (<xref ref-type="fig" rid="respfig5">Author response image 5</xref>).</p><fig id="respfig5"><label>Author response image 5.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig5-v2.tif"/></fig><p>To summarize, human data and both models show a decrease in switch rate as a function of time, suggesting that while the number of switches increases as a function of time, optimal behavior involves decreasing the likelihood of switching attention within the same time frame as the deliberation process takes longer. In contrast, we did not see a consistent relationship between switch rate and value sum or value difference for both human and model behavior. Of note, both the optimal model and aDDM show similar patterns when using a large number of simulated trials rather than the same trials used in human data, such that both models predict a negative association between switch rate and value sum, and a positive association between switch rate and absolute value difference. Therefore, we suspect that human data may still exhibit a similar relationship if more trials are performed. We report these findings in Figure 4—figure supplement 1A-D and its corresponding figure legend.</p><disp-quote content-type="editor-comment"><p>b. How does the fixation duration changes as a function of time (within trial) and as a function of absolute value difference and sum (across trials) in the two models and in the data?</p></disp-quote><p>Human data shows a positive association between fixation duration and RT (t(38) = 9.28, p &lt; 0.001), a negative association between fixation duration and value sum (t(38) = -2.81, p = 0.0078), and a negative association between fixation duration and value difference (t(38) = -5.46, p &lt; 0.001). Both the optimal model and the aDDM predicted similar patterns (optimal model, RT: t(38) = 85.6, p &lt; 0.001 , value sum: t(38) = -4.19, p &lt; 0.001, value diff: t(38) = -3.60, p &lt; 0.001; aDDM, RT: t(38) = 13.65, p &lt; 0.001, value sum: t(38) = -3.32, p = 0.002, value diff: t(38) = -6.44, p &lt; 0.001) (<xref ref-type="fig" rid="respfig6">Author response image 6</xref>).</p><fig id="respfig6"><label>Author response image 6.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig6-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>c. The model seems to predict a non-negligible number of single fixation trials. How does this align with the data and the aDDM predictions?</p></disp-quote><p>While both the optimal model and aDDM over-estimated the number of single fixation trials compared to human data, the aDDM predicted significantly more than the optimal model (t(76) = 5.84, p &lt; 0.001) (<xref ref-type="fig" rid="respfig7">Author response image 7</xref>).</p><fig id="respfig7"><label>Author response image 7.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig7-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>d. How do reaction time distributions look like under the normative model? Are these comparable to the RT distributions in the data?</p></disp-quote><p>Both models predict a RT curve that includes more sub-1s trials, consistent with the above results showing more single-fixation trials (Figure 4—figure supplement 3F).</p><disp-quote content-type="editor-comment"><p>e. Please also show the aDDM predictions together with the novel predictions made by the normative model in Figure 4C.</p></disp-quote><p>The aDDM also replicated the effects of RT and value sum on fixation bias (RT: t(38) = -48.6, p &lt; 0.001; value sum: t(38) = 14.7, p &lt; 0.001). This is not surprising given the initial assumptions made by the model wherein fixations boost the value of the item. Since increasing RT allows the model to spend similar amounts of time to each item, fixation bias will decrease. Also, since the impact of fixation is proportional to the value of the items, choosing between items with higher value will lead to a stronger fixation bias (Figure 4—figure supplement 3C and D).</p><disp-quote content-type="editor-comment"><p>f. The comparison between the two models is currently done on the basis of mean reward. How do the predictions of the models compare to the mean reward accrued by human participants in Krajbich et al? Please also clarify in the main text that the models are not compared on the basis of goodness of fit. In particular, in the paragraph starting in line 260, terms such as &quot;outperformed&quot;, &quot;competitive performance&quot;, &quot;comparison&quot; are ambiguous.</p></disp-quote><p>To test for this, we performed an independent samples t-test to the mean reward achieved by human participants versus the simulated participants of both models. We found there is no significant difference between the mean rewards of humans versus the optimal model (t(76) = 0.69, p = 0.49) and humans versus the aDDM (t(76) = -0.062, p = 0.95). Of note, for this analysis we used the aDDM setup used in the original paper by Krajbich et al., 2010 rather than the signal-to-noise-matched version we used to compare the mean reward between the optimal model and aDDM. Therefore, the mean reward of the optimal model was not greater than that of the aDDM in this scenario. To calculate mean reward, we used the same cost per unit time used for the optimal model (c = 0.23) (Figure 4—figure supplement 3B).</p><p>We also modified the ambiguous terms the reviewer mentioned:</p><p>“We also tested to which degree the optimal model yielded a higher mean reward than aDDM, which, despite its simpler structure, could nonetheless collect competitive amounts of reward. To ensure a fair comparison, we adjusted the aDDM model parameters (i.e., attentional value discounting and the noise variance) so that the momentary evidence provided to the two models has equivalent signal-to-noise ratios (see Supplementary file 1).”</p><disp-quote content-type="editor-comment"><p>g. Please explain why the model shows the pattern that is demonstrated in Figure 3F. Is this pattern also predicted by the aDDM?</p></disp-quote><p>The aDDM did not predict the same fixation pattern as the data and optimal model. This fixation pattern in the optimal model is well-preserved across different parameter values. We suspect this pattern arises due to the shape of the optimal decision boundaries, where the particle is more likely to hit the “switch” boundary in a shorter time for the first fixation, since the model likely prefers to sample from both items at least once. Consistent with this, Figure 2C shows that the “accumulate” space is larger for the second fixation compared to the first (<xref ref-type="fig" rid="respfig8">Author response image 8</xref>).</p><fig id="respfig8"><label>Author response image 8.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig8-v2.tif"/></fig><p>We added the following to the Results:“Interestingly, the model also replicated a particular fixation pattern seen in humans, where a short first fixation is followed by a significantly longer second fixation, which is followed by a medium-length third fixation (Figure 3F). We suspect this pattern arises due to the shape of the optimal decision boundaries, where the particle is more likely to hit the “switch” boundary in a shorter time for the first fixation, likely reflecting the fact that the model prefers to sample from both items at least once. Consistent with this, Figure 2C shows that the “accumulate” space is larger for the second fixation compared to the first fixation. Of note, the attentional drift diffusion model (aDDM) that was initially proposed to explain the observed human data (Krajbich et al., 2010) did not show this fixation pattern Figure 4—figure supplement 2D.”</p><p>Overall, we added the following Figures / panels to describe the comparison to aDDM: Figure 3—figure supplement 2G, Figure 4—figure supplement 1, and Figure 4—figure supplement 2. Furthermore, we added the following to the main text:</p><p>“Next, we assessed how the behavioral predictions arising from the optimal model differed from those of the original attentional drift diffusion model (aDDM) proposed by Krajbich et al., (2010). Unlike our model, the aDDM follows from traditional diffusion models rather than Bayesian models. It assumes that inattention to an item diminishes its value magnitude rather than the noisiness of evidence accumulation. Despite this difference, the aDDM produced qualitatively similar behavioral predictions as the optimal model (Figure 3—figure supplement 2G, Figure 4—figure supplement 1), although the optimal model was able to better reproduce some of the fixation patterns seen in human behavior (Figure 4—figure supplement 2A,D).”</p><disp-quote content-type="editor-comment"><p>3. Comprehensibility of the modelling.</p><p>The authors have done an admirable job of boiling down some heavy mathematics (in the SI) into just the key steps in the main text. A lot of this builds on prior work in Tajima et al. Still, the authors could do more to explain the math, which would make this paper more self-contained and really help the reader understand the core ideas/intuitions.</p><p>a. Equation 1 – it isn't obvious how the mean will behave over time or where this expressions comes from. It would be helpful to state that the z part is the prior, and that as t-&gt;infinity the σ terms become negligible and the expression converges to x/t, namely the true value. The σ-squared terms seem to come out of nowhere. In the methods the authors explain that this has to do with Fisher information, but most readers won't know what that is or why it is the appropriate thing to include here. Also, sigma<sub>x</sub> is defined later in the text, but should be defined up front here.</p></disp-quote><p>We agree that this expression might come as a surprise to some. We could have simplified it slightly, with the downside of a less direct relation to Eq. (2). As we felt that establishing this relationship is essential, we decided to keep Eq. (1) in its more complex form. To nonetheless make Eq. (1) it easier to digest, we have added additional information about how the prior and likelihood variances relate to their respective informativeness. Additionally, we have added additional details about the structure of the posterior mean and how it changes with increasing accumulation time t.</p><p>In particular, we added that “the smaller the prior variance (𝜎<sub>%</sub><sup>&quot;</sup>), the more information this prior provides about the true values”, and that “the evidence accumulation variance (𝜎<sub>and</sub><sup>&quot;</sup>) controls how informative the momentary evidence is about the associated true value. A large 𝜎<sub>and</sub><sup>&quot;</sup> implies larger noise, and therefore less information provided by each of the momentary evidence samples.” We were also more explicit in describing how the posterior mean and variance evolves over time: “The mean of this posterior (i.e., the first fraction in brackets) is a weighted sum of the prior mean, 𝑧, and the accumulated evidence, 𝑥(𝑡). The weights are determined by accumulation time, 𝑡, and the variances of the prior, 𝜎<sub>%</sub><sup>&quot;</sup>, and the momentary evidence, 𝜎<sub>and</sub><sup>&quot;</sup>, which control their respective informativeness. Initially, 𝑡 = 0 and 𝑥(𝑡) = 0, such that the posterior mean equals that of the prior, 𝑧. Over time, with increasing 𝑡, the influence of 𝑥(𝑡) = 0 becomes dominant, and the mean approaches 𝑥(𝑡)/𝑡 (i.e., the average momentary evidence) for large 𝑡, at which point the influence of the prior becomes negligible. The posterior's variance (i.e., the second fraction in brackets) reflects the uncertainty in the decision maker's value inference. It initially equals the prior variance, 𝜎<sub>%</sub><sup>&quot;</sup>, and drops towards zero once 𝑡 becomes large.”</p><p>We refrained from mentioning ‘Fisher information’ in the main text to avoid confusing readers that are not familiar with this concept. Instead, we kept discussion at a more informal level. Furthermore, we have added additional information about why we assess informativeness by Fisher information to Methods and Materials:</p><p><bold>“</bold>We measure how informative a single momentary evidence sample is about the associated true value by computing the Fisher information it provides about this value. This Fisher information sums across independent pieces of information. This makes it an adequate measure for assessing the informativeness of momentary evidence, which we assume to be independent across time and items.<bold>”</bold></p><disp-quote content-type="editor-comment"><p>b. Between Equation 1 and 2: In the means for delta<sub>x</sub>, one has a delta<sub>t</sub> multiplying z and one doesn't. Why? Is this a typo? The delta<sub>t</sub> should always be there, but again, it isn't obvious.</p><p>c. Equation 2: Why does the mean have a z1| at the beginning of it? Is that a typo?</p></disp-quote><p>Both instances are indeed typos, and we thank the reviewers for pointing them out. We have corrected all instances of such typos from the main text and the Supplementary file 1.</p><disp-quote content-type="editor-comment"><p>d. Could the authors elaborate more on why/when the decision-maker chooses to switch attention? They say that the decision at each time point only depends on the difference in posterior means but Figure 2c seems to indicate that if the difference in posterior means stays constant over a period of time, then the process enters the &quot;switch&quot; zone and shifts attention.</p></disp-quote><p>Optimal decisions are determined as a function of not only the difference in posterior means (𝛥), but also the times attended to item 1 (𝑡<sub>1</sub>) and item 2 (𝑡<sub>&quot;</sub>). This results in an optimal policy shape where the particle will hit the “switch” zone if the difference in expected rewards between the two items is too small to make an immediate decision, and it is deemed advantageous to collect more reward-related evidence of the currently unattended item. This prevents the model from deliberating for too long while attending to a single item. We added this clarification in Results under ‘Features of the Optimal Policy.’:</p><p>“In other words, the difference in expected rewards between the two items is too small to make an immediate decision, and it is deemed advantageous to collect more information about the currently unattended item.”</p><disp-quote content-type="editor-comment"><p>4. Model assumptions.</p><p>a. The model assumes that attention can take one of two discrete states. However, attention is often regarded as operating in a more graded fashion, which would necessitate parameter kappa in the model to be free to change within a trial. This will probably render the model intractable. However, a more viable and less radical assumption, would be to allow for a third &quot;divided attention&quot; mode in which the agent samples equally from both alternatives (divided attention mode). If this extension is technically challenging, one conceptual question that the authors can discuss in the paper, is whether the normative model would ever switch away from this divided attention mode.</p></disp-quote><p>We agree that a decision-making model that incorporates a continuously variable attention would be an interesting endeavor. As the reviewers suggest, we could address this by adding another state to the Bellman equation in which attention is perfectly divided. Since this will add another dimension to the value and policy space, we anticipate this will become intractable quickly. However, we believe there is sufficient literature on this topic to reasonably predict how such a model would behave.</p><p>Previous work by Fudenberg, Strack and Strzalecki (2018) discusses a modified drift diffusion model in which attention can vary continuously and gradually across two choice options. They show that, consistent with our results, the model with equally divided attention performs optimally. Drawing from this, we can confidently state that our optimal model would always engage in the divided attention mode. However, the authors also state that there may be instances within a decision when it would be optimal to pay unequal attention. In fact, if the normative decision maker has already paid more attention to one item over the other item, it may be optimal to switch attention and gain more information about the unattended item rather than to proceed in the divided attention mode.</p><p>To address this, we added the following to the Discussion:</p><p>“We show that narrowing the attentional bottleneck by setting κ to values closer to 0 or 1 does not boost performance of our decision-making model (Figure 4E). Instead, spreading a fixed cognitive reserve evenly between the attended and unattended items maximized performance. This is consistent with prior work that showed that a modified drift diffusion model with a continuously varying attention would perform optimally when attention is always equally divided (Fudenberg et al., 2018). However, this does not necessarily imply that equally divided attention always constitutes the normative behavior. If the decision maker has already paid more attention to one item over the other within a decision, it may be optimal to switch attention and gain more information about the unattended item rather than to proceed with equally divided attention.”</p><disp-quote content-type="editor-comment"><p>b. The authors need to assume a certain prior, namely z_bar = 0, in order to always get a positive effect of attention. This seems like an important controversy in the model; it is a noticeably non-Bayesian feature of a Bayesian model. The authors try to explain this away by noting that the original rating scale included both negative and positive values. However, only positive items were included in the choice task, and there is a consistently positive effect of attention on choice for other tasks (see Cavanagh et al. 2014; Smith and Krajbich 2018; Smith and Krajbich 2019) with only positive outcomes. This needs to be more openly acknowledged and discussed.</p></disp-quote><p>We agree with the reviewers that the exact features and role of the Bayesian prior remains a topic of discussion, and we acknowledge that while our formulation suggests a zero-mean prior, there is also evidence suggesting the prior should be centered on the choice set. We have modified the Discussion to be more transparent regarding this point, and added the citations suggested by the reviewers in support of a non-zeromean prior distribution.</p><p>“In our model, we assumed the decision maker's prior belief about the item values is centered at zero. In contrast, Callaway et al. (2020) chose a prior distribution based on the choice set, centered on the average value of only the tested items. While this is also a reasonable assumption (Shenhav et al., 2018), it likely contributed to their inability to demonstrate the choice bias. Under the assumption of our zero-mean prior, formulating the choice process through Bayesian inference revealed a simple and intuitive explanation for choice biases (Figure 4A) (see also Li and Ma (2020)). This explanation required the decision maker to a-priori believe the items' values to be lower than they actually are when choosing between appetitive options, consistent with evidence that item valuations vary inversely with the average value of recently observed items (Khaw et al., 2017). The zero-mean prior also predicts an opposite effect of the choice bias when deciding between aversive items, such that less-fixated items should become the preferred choice. This is exactly what has been observed in human decision-makers (Armel et al., 2008). We justified using a zero-mean bias because participants in the decision task were allowed to rate items as having both positive or negative valence (negative-valence items were excluded from the binary decision task). However, there is some evidence that humans also exhibit choice biases when only choosing between appetitive items (Cavanagh et al., 2014, Smith et al., 2018, Smith et al., 2019). Although our setup suggests a zero-mean prior is required to reproduce the choice bias, the exact features and role of the Bayesian prior in human decisions still remains an open question for future work.”</p><disp-quote content-type="editor-comment"><p>c. The last paragraph of Discussion talks about a lack of benefit of focussed attention in the analysed task. Would focussing attention would become beneficial in decision tasks with more than 2 options? Although answering this question would be a separate paper, a few sentences on generalising this work to more than two options could be included in the Discussion.</p></disp-quote><p>We agree it is interesting to discuss whether our findings would generalize to multi alternative choices. While we cannot definitively answer this question, we believe that under the same framework of our binary choice model, the same principles would apply such that divided attention across all items would lead to optimal behavior. Once the framework becomes more complex and involves features such as increased attention to items based on value or salience, this may lead to scenarios where focused attention may be beneficial. This is consistent with the idea that although divided attention maximizes reward on average, focusing attention to single items may be preferred if the decision maker has already done so for any other item(s) for heuristical reasons.</p><p>We have added the following text to the Discussion to highlight this point:</p><p>“An open question is whether our findings can be generalized to multi-alternative choice paradigms (Towal et al., 2013, Ke et al., 2016, Gluth et al., 2020, Tajima et al., 2019). While implementing the optimal policy for such choices may be analytically intractable, we can reasonably infer that a choice bias driven by a zero-mean prior would generalize to decisions involving more than two options. However, in a multi alternative choice paradigm where heuristics involving value and salience of items may influence attention allocation, it is less clear whether an equally divided attention among all options would still maximize reward. We hope this will motivate future studies that investigate the role of attention in more realistic decision scenarios.”</p><disp-quote content-type="editor-comment"><p>5. Coverage of literature.</p><p>a. In the Introduction, the authors state that the &quot;final choices are biased towards the item that they looked at longer, irrespective of its desirability&quot;. This is not quite true. The desirability does matter, as shown in Smith and Krajbich 2019, as well as Westbrook et al. 2020. Moreover, as the authors note in the discussion, Armel et al. 2008 show that attention has a reverse effect when the items are aversive. Please update the introduction accordingly.</p></disp-quote><p>Thank you for this suggestion. We have now removed the phrase “irrespective of its desirability.”</p><disp-quote content-type="editor-comment"><p>b. The authors do not mention that there is some work that has argued for value attracting attention in multi-alternative choice. While that work does not go to the lengths that this paper does, it does make normative arguments for why this should occur, namely to eliminate non-contenders (Krajbich and Rangel 2011; Towal et al. 2013; Gluth et al. 2020). Finally, the authors might also want to mention Ke, Shen, Villas-Boas (2016), which also takes a normative approach to information search in consumer choice.</p></disp-quote><p>We agree that the effect of value and salience of the choice items on attention allocation is a relevant topic to discuss. We also agree that these processes are likely contributing to the fixation behavior of human participants, and elements that could be added to our normative formulation in future work. We have added the following text to note this, and added the citations, including Ke et al., (2016), suggested by the reviewer (see bolded text for added information).</p><p>“In previous work, fixation patterns were assumed to be either independent of the decision-making strategy (Krajbich et al., 2010, Krajbich et al., 2011) or generated by heuristics that relied on features such as the salience or value estimates of the choice options (Towal et al., 2013, Gluth et al., 2020). Other models generated fixations under the assumption that fixation time to different information sources should depend on the expected utility or informativeness of the choice items (Ke et al., 2016, Cassey et al., 2013, Song et al., 2019).”</p><p>“When designing our model, we took the simplest possible approach to introduce an attentional bottleneck into normative models of decision-making. When doing so, our aim was to provide a precise (i.e., without approximations), normative explanation for how fixation changes qualitatively interact with human decisions rather than quantitatively capture all details of human behavior, which is likely driven by additional heuristics and features beyond the scope of our model (Acerbi et al., 2014, Drugowitsch et al., 2016). For instance, it has been suggested that normative allocation of attention should also depend on the item values to eliminate non-contenders, which we did not incorporate as a part of our model (Towal et al., 2013, Gluth et al., 2020). As such, we expect other models using approximations to have a better quantitative fit to human data (Krajbich et al., 2010, Callaway et al., 2020).”</p><p>“An open question is whether our findings can be generalized to multi-alternative choice paradigms (Towal et al., 2013, Ke et al., 2016, Gluth et al., 2020, Tajima et al., 2019).”</p><disp-quote content-type="editor-comment"><p>c. On page 2 the authors state that &quot;no current normative framework incorporates control of attention as an intrinsic aspect of the decision-making process&quot;. This does not seem to be accurate given the study by of Cassey et al. (2013). The key difference is that in Cassey et al. the focus was placed on the fixed duration paradigm, while the present manuscript focuses on the free-response paradigm. Please clarify the link of the current study with Cassey et al.</p></disp-quote><p>We agree with this point, and modified the statement to the following:</p><p>“While several prior studies have developed decision-making models that incorporate attention (Yu et al., 2009, Krajbich et al., 2010,Towal et al., 2013, Cassey et al., 2013, Gluth et al., 2020), our goal was to develop a normative framework that incorporates control of attention as an intrinsic aspect of the decision-making process in which the agent must efficiently gather information from all items while minimizing the deliberation time, akin to real life decisions. In doing so, we hoped to provide a computational rationale for why fixationdriven choice biases seen in human behavior may arise from an optimal decision strategy.”</p><disp-quote content-type="editor-comment"><p>d. In lines 318-321, the authors state that the model of Cassey et al. &quot;could not predict when they [fixation switches] ought to occur&quot;. The model of Cassey et al. does predict when the optimal switching times are, but for the case of a fixed duration paradigm with \kappa = 0. In this case the optimal switch policy is much simpler (single or at most double switch at particular times) than in the free-response paradigm nicely analysed in the present manuscript.</p></disp-quote><p>We thank the reviewers for this clarification, and modified the statement to the following:</p><p>“Furthermore, since their decision task involved a fixed-duration, attention switches also occurred at fixed times rather than being dynamically adjusted across time, as in our case with a free-response paradigm.”</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Essential revisions</p><p>1. In our previous points 2a-b the request was to show the switch rate and fixation duration as a function of time, value sum and value difference. We apologise if that was not clear previously but with the term &quot;time&quot; we referred to elapsed time within a trial rather than reaction times (RT). Because RT's will be influenced by various properties of the trial (e.g. trial difficulty) the analyses reported in the revision are not very easy to interpret. Additionally, we are puzzled by the fact that the aDDM model predicts non-flat switch rates and fixation durations as a function of the different quantities (Figure 4—figure supplement 1), given that switching in the aDDM version the authors used is random. The aim of these previous points was to (a) highlight the differences between random switching (aDDM) and deliberate switching (optimal model), and (b) understand how switching tendencies change as a function of trial-relevant quantities and time elapsed in the optimal model. We appreciate that such analyses might be difficult to perform given the interrelationship among time, value sum and absolute value difference. Below we offer a few suggestions:</p><p>– One possibility is to consider a &quot;stimulus locked&quot; approach, in which the switch rate and fixation duration is plotted as a function of time elapsed from the stimulus onset and up to &quot;x&quot; milliseconds before the response. Inevitably, later time points will more likely include certain trial types, e.g. only difficult trials (or trials with low value sum). The authors can consider using a &quot;stratification&quot; approach, subsampling the trials such that all time-points have comparable trial distributions (in terms of value difference and value sum). The influence of value difference and value sum can be examined using median splits based on these quantities.</p><p>– Specifically for the switch rate analysis, the authors could perform a logistic regression trying to predict at each point in time the probability of switching, also considering covariates such as value sum or absolute value difference.</p><p>– Since the last fixation can be cut short, we recommend excluding the last fixation from these analyses.</p><p>– We recommend that the scaling of the x and y axis in the data and in the models is the same to allow comparison in absolute terms.</p></disp-quote><p>Thank you for the clarification, and we apologize for the misunderstanding.</p><p>We reanalyzed the data completely in order to address the discrepancies the editors have brought up. For the aDDM simulations in the previous version of the manuscript, we already used the empirical distribution of fixation durations as described in the original literature (Krajbich et al., 2010), but did not sample the first fixations separately. As we discuss below (point #2), we do so now. We also noted that in the human data, RT was not equal to the sum of all fixation durations since there were procedures to remove non-item fixations by the original authors. This likely added to some discrepancy between the aDDM simulations and human data, especially for the switch rate analysis where we divided the number of switches by the RT. For the following analyses, we have adjusted the behavioral data so that RT is now equal to the sum of all fixations.</p><p>First, we would like to address the reviewers’ point that the aDDM model should predict flat switch rates and fixation duration as a function of different quantities. As the reviewers correctly point out, the aDDM samples fixation durations from human data, separately for each absolute value difference between the two items. Therefore, the relationship between switch probability and other variables such as time, value difference, and value sum should be reasonably preserved between the model and human data. However, we find that the implementation of the aDDM results in some systematic discrepancies in the switching behavior. For instance, since the aDDM terminates the trial whenever a decision boundary is reached, long fixations are more likely to result in boundary crossings than short fixations, such that long fixations are more likely considered last fixations and thus excluded from analysis. This causes the model to feature lower mean middle fixation durations and a higher switch frequency when compared to human data.</p><p>In <xref ref-type="fig" rid="respfig9">Author response image 9</xref>, we show how middle fixation duration and switch rate varies across trials based on the trial RT, absolute value difference, and value sum for humans and the aDDM simulations. For every trial, we computed the mean middle fixation duration and switch rate (total number of switches divided by RT), then grouped the trials based on RT (using 0.5s bins from 1-4s), absolute value difference (i.e., trial difficulty) and value sum. We then computed the mean fixation duration and switch rate across participants for each x-variable. We show these results mainly to demonstrate that, although the aDDM randomly samples non-first fixations from empirical middle fixation durations, trial variables such as RT and item values still influence the switching behavior when implemented in the aDDM framework.</p><fig id="respfig9"><label>Author response image 9.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig9-v2.tif"/></fig><p>The plots are shown in <xref ref-type="fig" rid="respfig9">Author response image 9</xref>, along with analogous plots for the optimal model, for the new Figure 4—figure supplement 1. The purpose of this figure is to show a clearer version of our between-trial analyses of how switch rate and fixation duration are affected by value sum and value difference for the human and the two simulated behavioral data sets. We did not show the effect of RT on these quantities since, as the reviewers mention, this is difficult to interpret since RT correlates with other task variables such as difficulty. We also decided to use different y-axis scales, since using the same scale for all three datasets makes it difficult to appreciate the slope of certain plots.We next turned to the original intent of the review question, which is to show how switch probability and fixation duration varies across time within trials. To do so, we followed the reviewers’ recommended analyses. For a given participant, we aligned all trials by the stimulus onset, then counted the number of switches within each 200ms time bin. We then averaged the switch count within each time bin across trials to get the switch probability. Since RTs differ across trials, we only included time points up to when at least ⅓ of the total trials are included. This implies that switch probabilities at later times are averaged across fewer trials. We also removed the last fixations as suggested.</p><p>We found that switching behavior within trials is well-preserved between humans and the aDDM. Both humans and the aDDM show a peak in switch probability within 1s of stimulus onset, followed by a gradual decrease (Figure 4—figure supplement 2 column A). The optimal model, in comparison, exhibits more discrete time points where a majority of attention switches occur. This is not surprising given the shape of the optimal policy space, where the particle is guaranteed to hit either a switch or decision boundary within a fixed time period for each fixation. Note, however, that these simulations assumed that time is perceived and measured with millisecond precision by the decision-maker, while humans are known to feature noisy time estimates (Buhusi and Meck, 2005). Furthermore, we assumed the additive non-decision time to be noise-free. We therefore anticipate that, with noisy time perception, the shape of the curve will smoothen out and approach that of human behavior and the aDDM.</p><p>Next, we explored whether the relationship between switch probability and time is influenced by variables such as RT (Figure 4—figure supplement 2 column B), value sum (Figure 4—figure supplement 2 column C) and value difference (Figure 4—figure supplement 2 column D). To do so, for each participant, we split all trials into three equally sized bins based on the variable of interest, and then made the same plots as column A only including the first and last bin. At each time point, we performed a t-test across participants between the two bins, and marked any time point with a significant difference across bins (Bonferroni corrected) with an asterisk. Humans and aDDM simulations featured a higher switch probability across time for trials with longer RTs compared to trials with shorter RTs, likely reflecting the fact that trials with longer RTs are more difficult, resulting in more early attention switches. Consistent with this, both human data and aDDM simulations showed a slightly higher switch probability across time for trials with low value difference (i.e., difficult trials) compared to those with a high value difference (i.e., easy trials). Within the time periods in which switches occurred, the optimal model featured comparable patterns.</p><p>We used a similar method to investigate fixation duration over time. Whenever a switch occurred within a trial, we recorded the fixation duration until the next switch occurred. We only used middle fixations (excluding first and last fixations), similar to the analyses performed in Krajbich et al. (2010). We averaged the fixation durations at each time point across trials, dropping all time points that contain data from less than ⅓ of all trials. We then plotted the mean fixation duration at each time point across participants, shown in <xref ref-type="fig" rid="respfig10">Author response image 10</xref>.</p><fig id="respfig10"><label>Author response image 10.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63436-resp-fig10-v2.tif"/></fig><p>The results show that under the current parameterization, the optimal model features overall longer fixation durations than humans. Interestingly, these durations increased for both humans and the optimal model with time, suggesting that more time is allotted to each fixation as the trial becomes more difficult (human: t(38)=4.50, p &lt; 0.001; optimal model: t(38)=46.4, p&lt;0.001). This trend is not seen in the aDDM which draws all middle fixations randomly from the same empirical distribution (t(38)=-0.57, p=0.57). Therefore, any effect of time within a single trial on fixation duration would be eliminated.</p><disp-quote content-type="editor-comment"><p>2. Krajbich et al. 2010 used an aDDM implementation in which fixations were not random but instead sampled from the empirical switching times distributions (thus fixations depended on fixation number, trial difficulty etc). The authors currently do not acknowledge this previous implementation. The aDDM with random switching is a good baseline for the scope of this paper, but the version used by Krajbich et al. 2010 makes different predictions than the random aDDM; and this should be explicitly acknowledged. For instance, the aDDM where switching matches the empirical distributions, accounts for the fact that the first fixations were shorter than the rest. Discussing this non-random aDDM used by Krajbich et al. 2010, will fit easily in the current discussion, since the optimal model offers a rationale fort the empirical fixation patterns that the older work simply incorporated into the aDDM simulations.</p></disp-quote><p>We thank the reviewers for this suggestion, as it brought to attention an oversight in our aDDM simulations. In our previous analyses, we simulated the aDDM by sampling all fixation durations from middle fixations in human data (split by absolute value difference), but did not sample the first fixation separately from the other fixations. This led to the result on the previous Figure 4—figure supplement 2D, where the fixation duration of the first three fixations for the aDDM did not replicate the patterns seen in humans. We have now repeated the same analyses while separately sampling the first fixations which leads to an aDDM prediction that better mimics human fixation behavior. We added this new result to Figure 4—figure supplement 3E.</p><p>However, as the reviewers correctly point out, a strength of our model is that it provides a rationale for the fixation patterns seen in humans, whereas the aDDM simply sampled from the empirical distribution. We have now removed all discussions stating that the optimal model better-predicted this fixation pattern compared to the aDDM and clarified this point in the Results section as follows:</p><p>“Of note, the attentional drift diffusion model (aDDM) that was initially proposed to explain the observed human data (Krajbich et al., 2010) did not generate its own fixations, but rather used fixations sampled from the empirical distribution of human subjects. Furthermore, they were only able to achieve this fixation pattern by sampling the first fixation, which was generally shorter than the rest, separately from the remaining fixation durations.”</p><disp-quote content-type="editor-comment"><p>3. The authors slightly mischaracterise Krajbich and Rangel 2011 by saying that &quot;fixation patterns were assumed to be either independent of the decision-making strategy&quot;. That paper did condition fixation patterns on the values of the items. Here is a direct quote from the Discussion: &quot;These patterns are interesting for several reasons. First, they show that the fixation process is not fully independent from the valuation process, and contains an element of choice that needs to be explained in further work.&quot;</p></disp-quote><p>We thank the reviewers for pointing this out, and agree that the Krajbich et al. (2010) as well as the Krajbich and Rangel (2011) papers suggest that fixations are not completely independent of the decision-making strategy, but rather, that they are affected by decision-relevant variables such as trial difficulty or item value. We have modified our Discussion to reflect this:</p><p>“This is consistent with previous work that showed that fixation patterns were influenced by variables relevant for the decision, such as trial difficulty or the value of each choice item (Krajbich et al., 2010; Krajbich and Rangel, 2011). However, prior models of such decisions assumed an exogenous source of fixations (Krajbich et al., 2010; Krajbich and Rangel, 2011) or generated fixations using heuristics that relied on features such as the salience or value estimates of the choice options (Towal et al., 2013; Gluth et al., 2020).”</p><disp-quote content-type="editor-comment"><p>4. When comparing the mean reward of the models, the authors simulate the aDDM not with the parameters from Krajbich et al. 2010, but with different parameters meant to &quot;ensure a fair comparison&quot; between the models. We believe that this approach sets the aDDM to a disadvantage. If the best-fitting parameters of the &quot;optimal model&quot; lead to a lower signal-to-noise ratio than the aDDM best-fitting parameters, that should be acknowledged and accepted as is. We recommend the authors state upfront that the best-fitting optimal model does not outperform the data or the aDDM. However, if you use a non-best-fitting aDDM, then the aDDM underperforms both.</p></disp-quote><p>We understand the reviewers’ concern here, and believe that the method in which we perform the comparison depends on the question we are trying to answer. Our goal was to establish that, since our model provides the optimal solution to the decision problem under the current assumptions, it should outperform or at least match the performance of any alternative model. Therefore, it is an attempt to demonstrate optimality of our model, rather than necessarily make any conclusions about the performance of the aDDM or any other model we may use as a comparison. However, the editors correctly point out that another relevant question would be to compare the performance of the best-fitting versions of each model. To address both perspectives, we have now provided the results to both instances, and changed the text in the Results section as following:</p><p>“Given that our model provides the optimal solution to the decision problem under the current assumptions, it is expected to outperform, or at least match, the performance of alternative models. To ensure a fair comparison, we adjusted the aDDM model parameters (i.e., attentional value discounting and the noise variance) so that the momentary evidence provided to the two models has equivalent signal-to-noise ratios (see Appendix 1). Using the same parameters fit to human behavior without this adjustment in signal-to-noise ratio yielded a higher mean reward for the aDDM model (t(76) = -14.8, p &lt; 0.001), since the aDDM receives more value information at each time point than the optimal model. The original aDDM model fixed the decision boundaries at $\pm1$ and subsequently fit model parameters to match behavioral data. Since we were interested in comparing mean reward, we simulated model behavior using incrementally increasing decision barrier heights, looking for the height that yields the maximum mean reward (Figure 4D). We found that even for the best-performing decision barrier height, the signal-to-noise ratio-matched aDDM model yielded a significantly lower mean reward compared to that of the optimal model (t(76) = 3.01, p = 0.0027).”</p></body></sub-article></article>