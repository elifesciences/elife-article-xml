<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">62362</article-id><article-id pub-id-type="doi">10.7554/eLife.62362</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Accelerating with FlyBrainLab the discovery of the functional logic of the <italic>Drosophila</italic> brain in the connectomic and synaptomic era</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-27920"><name><surname>Lazar</surname><given-names>Aurel A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4261-8709</contrib-id><email>aurel@ee.columbia.edu</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="fn1">†</xref></contrib><contrib contrib-type="author" id="author-204373"><name><surname>Liu</surname><given-names>Tingkai</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3075-7648</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="fn1">†</xref></contrib><contrib contrib-type="author" id="author-204374"><name><surname>Turkcan</surname><given-names>Mehmet Kerem</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9273-7293</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="fn1">†</xref></contrib><contrib contrib-type="author" id="author-204419"><name><surname>Zhou</surname><given-names>Yiyin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4618-4039</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="fn1">†</xref></contrib><aff id="aff1"><institution>Department of Electrical Engineering, Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Senior Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="other" id="fn1"><label>†</label><p><italic>The authors’ names are listed in alphabetical order.</italic></p></fn><fn fn-type="other" id="fn2"><label>‡</label><p><italic>The authors’ names are listed in alphabetical order.</italic></p></fn><fn fn-type="other" id="fn3"><label>§</label><p><italic>The authors’ names are listed in alphabetical order.</italic></p></fn><fn fn-type="other" id="fn4"><label>#</label><p><italic>The authors’ names are listed in alphabetical order.</italic></p></fn><fn fn-type="other" id="fn5"><label>¶</label><p><italic>The authors’ names are listed in alphabetical order.</italic></p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>22</day><month>02</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e62362</elocation-id><history><date date-type="received" iso-8601-date="2020-08-22"><day>22</day><month>08</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-02-21"><day>21</day><month>02</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Lazar et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Lazar et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-62362-v2.pdf"/><abstract><p>In recent years, a wealth of <italic>Drosophila</italic> neuroscience data have become available including cell type and connectome/synaptome datasets for both the larva and adult fly. To facilitate integration across data modalities and to accelerate the understanding of the functional logic of the fruit fly brain, we have developed FlyBrainLab, a unique open-source computing platform that integrates 3D exploration and visualization of diverse datasets with interactive exploration of the functional logic of modeled executable brain circuits. FlyBrainLab’s User Interface, Utilities Libraries and Circuit Libraries bring together neuroanatomical, neurogenetic and electrophysiological datasets with computational models of different researchers for validation and comparison within the same platform. Seeking to transcend the limitations of the connectome/synaptome, FlyBrainLab also provides libraries for molecular transduction arising in sensory coding in vision/olfaction. Together with sensory neuron activity data, these libraries serve as entry points for the exploration, analysis, comparison, and evaluation of circuit functions of the fruit fly brain.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>open source</kwd><kwd>interactive computing</kwd><kwd>executable circuits</kwd><kwd>connectomics</kwd><kwd>synaptomics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000181</institution-id><institution>Air Force Office of Scientific Research</institution></institution-wrap></funding-source><award-id>FA9550-16-1-0410</award-id><principal-award-recipient><name><surname>Lazar</surname><given-names>Aurel A</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000185</institution-id><institution>Defense Advanced Research Projects Agency</institution></institution-wrap></funding-source><award-id>HR0011-19-9-0035</award-id><principal-award-recipient><name><surname>Lazar</surname><given-names>Aurel A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>FlyBrainLab is an open-source computing platform that integrates 3D exploration and visualization of diverse Drosophila connectomic/synaptomic datasets with interactive exploration of the functional logic of modeled executable brain circuits.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The era of connectomics/synaptomics ushered in the advent of large-scale availability of highly complex fruit fly brain data (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>; <xref ref-type="bibr" rid="bib6">Berck et al., 2016</xref>; <xref ref-type="bibr" rid="bib82">Takemura et al., 2017a</xref>; <xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>), while simultaneously highlighting the dearth of computational tools with the speed and scale that can be effectively deployed to uncover the functional logic of fly brain circuits. In the early 2000’s, automation tools introduced in computational genomics significantly accelerated the pace of gene discovery from the large amounts of genomic data. Likewise, there is a need to develop tightly integrated computing tools that automate the process of 3D exploration and visualization of fruit fly brain data with the interactive exploration of executable circuits. The fruit fly brain data considered here includes neuroanatomy, genetics, and neurophysiology datasets. Due to space limitations, we mostly focus here on exploring, analyzing, comparing, and evaluating executable circuits informed by wiring diagrams derived from neuroanatomy datasets currently available in public domain.</p><p>To meet this challenge, we have built an open-source interactive computing platform called FlyBrainLab. FlyBrainLab is uniquely positioned to accelerate the discovery of the functional logic of the <italic>Drosophila</italic> brain. It is designed with three main capabilities in mind: (1) 3D exploration and visualization of fruit fly brain data, (2) creation of executable circuits directly from the explored and visualized fly brain data in step (1), and (3) interactive exploration of the functional logic of the executable circuits devised in step (2) (see <xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>FlyBrainLab provides, within a single working environment, (left) 3D exploration and visualization of fruit fly brain data, and (right) creation of executable circuit diagrams from the explored and visualized circuit on the left followed by an interactive exploration of the functional logic of executable circuits.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig1-v2.tif"/></fig><p>To achieve tight integration of the three main capabilities sketched in <xref ref-type="fig" rid="fig1">Figure 1</xref> into a single working environment, FlyBrainLab integrates fly brain data in the NeuroArch Database (<xref ref-type="bibr" rid="bib24">Givon et al., 2015</xref>) and provides circuit execution with the Neurokernel Execution Engine (<xref ref-type="bibr" rid="bib26">Givon and Lazar, 2016</xref>) (see <xref ref-type="fig" rid="fig2">Figure 2a</xref>). The NeuroArch Database stores neuroanatomy datasets provided by for example, FlyCircuit (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>), Larva L1EM (<xref ref-type="bibr" rid="bib59">Ohyama et al., 2015</xref>), the Medulla 7 Column (<xref ref-type="bibr" rid="bib82">Takemura et al., 2017a</xref>) and Hemibrain (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>), genetics datasets published by for example, FlightLight (<xref ref-type="bibr" rid="bib35">Jenett et al., 2012</xref>) and FlyCircuit (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>), and neurophysiology datasets including the DoOR (<xref ref-type="bibr" rid="bib57">Münch and Galizia, 2016</xref>) and our own in vivo recordings (<xref ref-type="bibr" rid="bib46">Lazar and Yeh, 2020</xref>; <xref ref-type="bibr" rid="bib37">Kim et al., 2011</xref>; <xref ref-type="bibr" rid="bib38">Kim et al., 2015</xref>). The Neurokernel Execution Engine (see <xref ref-type="fig" rid="fig2">Figure 2a</xref>) supports the execution of fruit fly brain circuits on GPUs. Finally, the NeuroMynerva front-end exhibits an integrated 3D graphics user interface (GUI) and provides the user a unified view of data integration and computation (see <xref ref-type="fig" rid="fig2">Figure 2a</xref> (top) and <xref ref-type="fig" rid="fig2">Figure 2b</xref>). The FlyBrainLab software architecture is depicted in the <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The software architecture and the user interface of FlyBrainLab.</title><p>(<bold>a</bold>) The main components of the architecture of FlyBrainLab: (top) NeuroMynerva user-side frontend, (bottom left) NeuroArch Database for storage of fruit fly brain data and executable circuits, (bottom right) Neurokernel Execution Engine for execution of fruit fly brain circuits on GPUs (see also <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> for a schematic diagram of the FlyBrainLab software architecture). (<bold>b</bold>) NeuroMynerva User Interface. The UI typically consists five blocks, including a (1) NeuroNLP 3D Visualization Window with a search bar for NLP queries, providing capabilities for displaying and interacting with fly brain data such as the morphology of neurons and position of synapses. (2) NeuroGFX Executable Circuits Window, for exploring executable neural circuits with interactive circuit diagrams. (3) Program Execution Window with a built-in Jupyter notebook, executing any Python code including calls to the FlyBrainLab Client (see also Appendix 1.2), for direct access to database queries, visualization, and circuit execution, (4) Info Panel displaying details of highlighted neurons including the origin of data, genetic information, morphometric statistics and synaptic partners, etc. (5) Local File Access Panel with a built-in Jupyter file browser for accessing local files.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig2-v2.tif"/></fig><p>To accelerate the generation of executable circuits from fruit fly brain data, NeuroMynerva supports the following workflow.</p><p>First, the 3D GUI, called the NeuroNLP window (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>, top middle-left), supports the visual exploration of fly brain data, including neuron morphology, synaptome, and connectome from all available data sources, stored in the NeuroArch Database (<xref ref-type="bibr" rid="bib24">Givon et al., 2015</xref>). With plain English queries (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>, top middle-left), a layperson can perform sophisticated database queries with only knowledge of fly brain neuroanatomy (<xref ref-type="bibr" rid="bib85">Ukani et al., 2019</xref>).</p><p>Second, the circuit diagram GUI, called the NeuroGFX window (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>, top middle-right) enables the interactive exploration of executable circuits stored in the NeuroArch Database. By retrieving tightly integrated biological data and executable circuit models from the NeuroArch Database, NeuroMynerva supports the interaction and interoperability between the biological circuit (or pathway for short) built for morphological visualization and the executable circuit created and represented as an interactive circuit diagram, and allows them to build on each other. This helps circuit developers to more readily identify the modeling assumptions and the relationship between neuroanatomy, neurocircuitry, and neurocomputation.</p><p>Third, the GUIs can operate in tandem with command execution in Jupyter notebooks (see also <xref ref-type="fig" rid="fig2">Figure 2b</xref>, bottom center). Consequently, fly brain pathways and circuit diagrams can be equivalently processed using API calls from Python, thereby ensuring the reproducibility of the exploration of similar datasets with minimal modifications. The Neurokernel Execution Engine (<xref ref-type="bibr" rid="bib26">Givon and Lazar, 2016</xref>) provides circuit execution on multiple computing nodes/GPUs. The tight integration in the database also allows the execution engine to fetch executable circuits directly from the NeuroArch Database. The tight integration between NeuroArch and Neurokernel is reinforced and made user transparent by NeuroMynerva.</p><p>Exploration, analysis, execution, comparison, and evaluation of circuit models, either among versions developed by one’s own, or among those published in literature, are often critical steps toward discovering the functional logic of brain circuits. Six types of explorations, analyses, comparisons, and evaluations are of particular interest. First, build and explore the structure of fly brain circuits with English queries (Use Case 1). Second, explore the structure and function of yet to be discovered brain circuits (Use Case 2). Third, interactively explore executable circuit models (Use Case 3). Fourth, starting from a given dataset and after implementing a number of circuit models published in the literature, analyze and compare these under the same evaluation criteria (Use Case 4). Fifth, automate the construction of executable circuit models from datasets gathered by different labs and analyze, compare, and evaluate the different circuit realizations (Use Case 5). Sixth, analyze, compare, and evaluate fruit fly brain circuit models at different developmental stages (Use Case 6).</p><p>In what follows, we present results, supported by the FlyBrainLab Circuits Libraries (see Materials and methods), demonstrating the comprehensive exploration, execution, analysis, comparison, and evaluation capability of FlyBrainLab. While our emphasis here is on building executable circuit models informed by the connectome/synaptome of the fruit fly brain, these libraries together with sensory neuron activity data serve as entry points for an in-depth exploration, execution, analysis, comparison, and evaluation of the functional logic of the fruit fly brain.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Use Case 1: building fly brain circuits with english queries</title><p>FlyBrainLab is equipped with a powerful and versatile user interface to build fruit fly brain circuits from connectome and synaptome datasets. The interface is designed to accommodate users with widely different expertise, such as neurobiologists, computational neuroscientists or even college or high school students. Knowledge of the nomenclature of the fruit fly brain is assumed.</p><p>The simplest way to build a fly brain circuit is via the NeuroNLP natural language query interface (<xref ref-type="bibr" rid="bib85">Ukani et al., 2019</xref>). By specifying in plain English cell types, synaptic distribution, pre- and post-synaptic partners, neurotransmitter types, etc, neurons and synapses can be visualized in the NeuroNLP window (see also <xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p><p>The motion detection pathway in the fruit fly Medulla has been, in part, mapped out thanks to the Medulla 7 Column dataset (<xref ref-type="bibr" rid="bib81">Takemura et al., 2015</xref>). While much research has focussed on the direct, feedforward pathway feeding into the motion sensitive T4 neurons (<xref ref-type="bibr" rid="bib83">Takemura et al., 2017b</xref>; <xref ref-type="bibr" rid="bib29">Haag et al., 2017</xref>), the contribution of the feedback pathways and the neighboring columnar neurons to the motion detection circuit has largely been ignored. To study the circuit that mediates the lateral feedback into the motion detection pathway, we used English queries to quickly visualize the neurons involved. Starting from a T4a neuron in the ‘home’ column that is sensitive to front-to-back-motion (<xref ref-type="bibr" rid="bib52">Maisak et al., 2013</xref> ‘show T4a in column home’; ‘color lime’), we queried its presynaptic neurons (‘add presynaptic neurons’; ‘color gray’) as well as their presynaptic neurons that are non-columnar, in particular, the Dm and Pm cells (<xref ref-type="bibr" rid="bib21">Fischbach and Dittrich, 1989</xref>) (‘add presynaptic $Dm$ neurons with at least five synapses’; ‘color cyan’; ‘add presynaptic $Pm$ neurons with at least five synapses’; ‘color yellow’). The resulting visualization of the circuit is depicted in <xref ref-type="fig" rid="fig3">Figure 3 (a1)</xref>, with neurons mediating cross-columnar interaction highlighted. The retrieved connectivity matrix is shown in <xref ref-type="fig" rid="fig3">Figure 3 (a2)</xref> (see also Materials and methods, Use Case 1).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Building fly brain circuits with English queries.</title><p>(<bold>a1</bold>) Lateral feedback pathways in the visual motion detection circuit. (green) a T4a neuron, (gray) neurons presynaptic to the T4a neuron, (cyan) glutamatergic and GABAergic Dm neurons that are presynaptic to the neurons in gray, (yellow) Pm neurons that are presynaptic to the neurons in gray. (<bold>a2</bold>) Connectivity matrix of the pathways in (<bold>a1</bold>). (<bold>b1</bold>) Pathways between MBONs and neurons innervating FB layer 3. (yellow) MBONs that are presynaptic to neurons that have outputs in FB layer 3. (green) Neurons that have outputs in FB layer 3 that are postsynaptic to the MBONs in yellow. (red) MBONs postsynaptic to neurons in green. (<bold>b2</bold>) Connectivity matrix of the pathways in (<bold>b1</bold>). (<bold>c1</bold>) The pathways of the g compartment of the larva fruit fly. (cyan) g compartment MBONs, (yellow) KCs presynaptic to the g compartment MBONs, (green) a DAN presynaptic to the g compartment MBONs, (white) an OAN presynaptic to the g compartment MBONs, (<bold>c2</bold>) Connectivity matrix of the pathways in (<bold>c1</bold>). (<bold>d1</bold>) Pathways between LPTCs and a potential translational motion-sensitive neuron GLN. (yellow) LPTCs, (cyan) GLNs, (red) neurons that form the path between LPTCs to GLNs. (<bold>d2</bold>) Connectivity matrix of the pathways in (<bold>d1</bold>). color bar in a2, b2, c2, and d2: <inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mo>log</mml:mo><mml:mn>10</mml:mn></mml:msub><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the number of synapses between 2 neurons. (<bold>a1</bold>)–(<bold>d1</bold>) are screenshots downloaded from the NeuroNLP Window. The sequence of queries that generates these visualizations is listed in Materials and methods Use Case 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig3-v2.tif"/></fig><p>The mushroom body (MB) has been known to be an associative olfactory memory center (<xref ref-type="bibr" rid="bib56">Modi et al., 2020</xref>), whereas the fan-shaped body (FB) shown to be involved in visual pattern memory (<xref ref-type="bibr" rid="bib50">Liu et al., 2006</xref>). Recently, it has been shown that the Kenyon cells in the MB also receive visual inputs (<xref ref-type="bibr" rid="bib47">Li et al., 2020a</xref>), and that the MB and FB are interconnected (<xref ref-type="bibr" rid="bib48">Li et al., 2020b</xref>). The pathway between the MB and the FB, or a particular layer in the FB can be easily visualized using NeuroNLP. We used English queries to establish and visualize the circuit that directly connects the MB with the layer 3 of the FB in the Hemibrain dataset, as depicted in <xref ref-type="fig" rid="fig3">Figure 3 (b1)</xref>. The connectivity matrix is shown in <xref ref-type="fig" rid="fig3">Figure 3 (b2)</xref> (see also Materials and methods, Use Case 1, for the sequence of queries that created this visualization).</p><p>Natural language queries supplemented by the NeuroNLP 3D interface and the Info Panel (see also <xref ref-type="fig" rid="fig2">Figure 2b</xref>) enable us to inspect, add and remove neurons/synapses. For example, in <xref ref-type="fig" rid="fig3">Figure 3 (c1)</xref>, we built a simple circuit around the g compartment of the mushroom body (<xref ref-type="bibr" rid="bib67">Saumweber et al., 2018</xref>) of the Larva L1EM dataset (<xref ref-type="bibr" rid="bib59">Ohyama et al., 2015</xref>) starting from the MBONs that innervate it. We then inspected these MBONs in the Info Panel and added all KCs presynaptic to each of them by filtering the name ‘KC’ in the presynaptic partner list. Similarly, we added the dopaminergic neurons (DANs) and octopaminergic neurons (OANs) presynaptic to these MBONs. <xref ref-type="fig" rid="fig3">Figure 3 (c2)</xref> depicts the connectivity matrix of this MB circuit (see also Materials and methods, Use Case 1, for the full sequence of queries/operations that created this visualization).</p><p>The FlyBrainLab UI provides users a powerful yet intuitive tool for building fly brain circuits at any scale, requiring no knowledge of programming or the data model of the underlying NeuroArch Database. For more advanced users, FlyBrainLab also exposes the full power of NeuroArch API for directly querying the NeuroArch database using the NeuroArch JSON format. Utilizing this capability, we built a circuit pathway that potentially carries translational visual motion information into the Noduli (NO) in <xref ref-type="fig" rid="fig3">Figure 3 (d1)</xref>. The search for this circuit was motivated by a type of cells in honey bees, called TN neurons, that are sensitive to translational visual motion and provide inputs to the NO (<xref ref-type="bibr" rid="bib77">Stone et al., 2017</xref>). In the Hemibrain dataset, a cell type ‘GLN’ resembles the TN neurons in the honey bee and is potentially a homolog in the fruit fly. We therefore asked if there exists a pathway to these neurons from visual output neurons that are sensitive to wide-field motion, in particular, the lobula plate tangential cells (LPTCs). Using a NeuroArch query, we found all paths between LPTCs and GLNs that are less than three hops and have at least five synapses in each hop (see also Materials and methods), Use Case 1, for the complete listing of the invoked NeuroArch JSON query. Only the HS cells and H2 cells, but not CH and VS cells (<xref ref-type="bibr" rid="bib30">Hausen, 1984</xref>) have robust paths to the GLNs. The connectivity of this circuit is shown in <xref ref-type="fig" rid="fig3">Figure 3(d2)</xref> (see also Materials and methods, Use Case 1).</p></sec><sec id="s2-2"><title>Use Case 2: exploring the structure and function of yet to be discovered brain circuits</title><p>Here, we further demonstrate the capabilities of FlyBrainLab in the quest of exploring the structure and function of yet to be discovered fly brain circuits. In particular, we demonstrate several use cases of the Utility Libraries (see Appendix 2) and their interaction with the rest of the FlyBrainLab components.</p><p>In the first example, we explore the structure of densely-connected brain circuits in the Hemibrain dataset. Such an exploration is often the starting point in the quest of understanding the function of a brain circuit without any prior knowledge of neuropil boundaries, or the identity of each neuron (see also Materials and methods, Use Case 2). By invoking the NeuroGraph Library on the Hemibrain dataset (see Appendix 2), we extracted eight densely connected neuron groups, as shown in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. We then visualized subsets of neurons pseudocolored by group membership as shown in <xref ref-type="fig" rid="fig4">Figure 4b</xref> and assigned six of the eight groups to several known brain regions/neuropils. These neuropils include the AL, the MB, the lateral horn (LH), the central complex (CX), the anterior ventrolateral protocerebrum (AVLP), and the superior protocerebrum (SP). The remaining two brain regions correspond to the anterior optic tubercle with additional neurons of the posterior brain (AOTUP) and the anterior central brain (ACB). A circuit diagram depicting the connections between these groups of neurons is shown in <xref ref-type="fig" rid="fig4">Figure 4c</xref>.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Exploratory analysis of the fly brain circuits.</title><p>(<bold>a</bold>) Louvain algorithm applied to all neurons in the Hemibrain dataset showing eight groups of densely connected neurons. Color indicates the value of <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>log</mml:mi><mml:mn>10</mml:mn></mml:msub><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf4"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of synapses; values larger than one are shown in the same color as value 1. AOTUP: anterior optic tubercle with additional neurons of the posterior brain, AVLP: anterior ventrolateral protocerebrum, LH: lateral horn, ACB: neurons in the anterior central brain, AL: antennal lobe, SP: superior protocerebrum, CX: central complex, MB: mushroom body. Labels were added after visually inspecting the neurons in each group of neurons in (<bold>b</bold>). (<bold>b</bold>) A subset of neurons pseudo-colored according to the group they belong to in (<bold>a</bold>). (<bold>c</bold>) A brain-level circuit diagram created by hand according to the grouping of neurons and the inter-group edge information obtained in (<bold>a</bold>). Visual and olfactory inputs from, respectively, the early visual system (EVS) and antenna (ANT) were added. Groups in the left hemisphere were added by symmetry. (<bold>d</bold>) Adjacency Spectral Embedding algorithm applied to the VA1v connectome dataset using the NeuroGraph library. The color of each circle indicates the cell-type labeling from the original dataset. Groups of neurons labeled by dashed circles are based on validated cell types. (<bold>e</bold>) Visualization of neurons analyzed in (<bold>d</bold>). Neuron colors were assigned according to the groups in (<bold>d</bold>). (<bold>f</bold>) A circuit diagram of the VA1v circuit analyzed in (<bold>d</bold>) automatically generated by the NeuroGraph Library. (<bold>g</bold>) Connectivity matrix of the lateral horn neurons downstream the V glomerulus projection neurons of the antennal lobe. Colorbar configured in the same way as in (<bold>a</bold>). (<bold>h</bold>) Morphology of the neurons in (<bold>g</bold>). (white) PNs arborizing in the V glomerulus, (red) LHLNs, (cyan) LHONs. (<bold>i</bold>) A circuit diagram automatically generated by the circuit visualization utilities of NeuroGraph starting with the circuit in (<bold>g</bold>) and (<bold>h</bold>), and the superior lateral protocerebrum (SLP), the primary neuropil that the LHONs project to.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig4-v2.tif"/></fig><p>In the second example, we sought to define cell types not just by visually inspecting the morphology of the neurons, but also by taking into account the underlying graph structure of the circuit pathways. This is useful when a new dataset is released without explicit definitions of cell types and/or when there is a need for refining such definitions. Here, to automatically analyze neuron cell types in the VA1v glomerulus dataset (<xref ref-type="bibr" rid="bib33">Horne et al., 2018</xref>), we applied the Adjacency Spectral Embedding algorithm (<xref ref-type="bibr" rid="bib79">Sussman et al., 2012</xref>) of the NeuroGraph library (see Appendix 2 and Materials and methods, Use Case 2). The embedding is visualized using UMAP (<xref ref-type="bibr" rid="bib53">McInnes et al., 2018</xref>) and depicted in <xref ref-type="fig" rid="fig4">Figure 4d</xref>, and it is validated by annotations from the original dataset. We note that the overlap between PNs and some LNs is due to the restricted volume of the traced tissue. For an additional adjustment of their cell-type assignment, the resulting clusters of neurons can be further visually inspected as shown in <xref ref-type="fig" rid="fig4">Figure 4e</xref>. Outliers that lie far away from their clusters may guide future inquiries into cell types that have not been previously described or provide new descriptions for existing cell types contingent on their connectivity. Finding new neuron subtypes, for example, LNs that cluster with OSNs or neurons that cluster with LNs can be further investigated. Finally, a circuit diagram can be automatically generated using the NeuroGraph Library, as shown in <xref ref-type="fig" rid="fig4">Figure 4f</xref>.</p><p>Lastly, we demonstrate the process of automatic circuit diagram generation of explored brain circuits. Here, we explored the lateral horn subcircuit downstream of the V glomerulus projection neurons, as well as the neuropils that the lateral horn output neurons (LHONs) project to <xref ref-type="bibr" rid="bib86">Varela et al., 2019</xref>. The circuit can be easily specified and visualized by NeuroNLP queries (see Materials and methods, Use Case 2), and individual neurons can be further added/removed from the GUI. The resulting circuit is depicted in <xref ref-type="fig" rid="fig4">Figure 4h</xref>. We then inspected the innervation pattern of each neuron, either visually, or by querying its arborization data from the NeuroArch Database, and classified it either as a lateral horn local neuron (LHLN) or a LHON. The connectivity of neurons of the resulting circuit is shown in <xref ref-type="fig" rid="fig4">Figure 4g</xref>, where the rows and columns are grouped by neuron type. Using this collection of information, we invoked the NeuroGraph Library to create the circuit diagram shown in <xref ref-type="fig" rid="fig4">Figure 4i</xref> (see also Materials and methods, Use Case 2). The circuit diagram can then be used for computational studies as outlined in the previous examples.</p></sec><sec id="s2-3"><title>Use Case 3: interactive exploration of executable fruit fly brain circuit models</title><p>Beyond exploring the structure of fruit fly brain circuits, a primary objective supported by FlyBrainLab is the study of the function of executable circuits constructed from fly brain data. FlyBrainLab provides users with rapid access to executable circuits stored on the NeuroArch Database. During program execution, these circuits can also be directly accessed by the Neurokernel Execution Engine.</p><p>In <xref ref-type="fig" rid="fig5">Figure 5a</xref>, we depict the pathways of a cartridge of the Lamina neuropil (<xref ref-type="bibr" rid="bib64">Rivera-Alba et al., 2011</xref>) visualized in the NeuroNLP window. The circuit diagram modeling the cartridge visualized in the NeuroGFX window is shown in <xref ref-type="fig" rid="fig5">Figure 5b</xref>. With proper labels assigned to blocks/lines representing the neurons and synapses, we made the circuit diagram interactive. For example, by clicking on the block representing a neuron, the neuron can be inactivated, an operation corresponding to the silencing/ablating a neuron in the fly brain. <xref ref-type="fig" rid="fig5">Figure 5d</xref> depicts a modified cartridge circuit in which several neurons have been silenced. As a result, the visualized neural pathways in the NeuroNLP window automatically reflect these changes, as shown in <xref ref-type="fig" rid="fig5">Figure 5c</xref>. The circuit components can also be disabled/reenabled by selecting through hiding/displaying visualized neurons in the NeuroNLP window.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Interactive exploration of executable circuit models.</title><p>(<bold>a</bold>) The pathways of a Lamina cartridge visualized in the NeuroNLP window. (<bold>b</bold>) A circuit diagram of the cartridge in (<bold>a</bold>) displayed in NeuroGFX window. (<bold>c</bold>) The cartridge pathways modified interactively using the circuit diagram in (<bold>b</bold>) that results in the circuit diagram in (<bold>d</bold>). (<bold>d</bold>) The circuit diagram modeling the chosen pathways in (<bold>c</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig5-v2.tif"/></fig><p>In the same interactive diagram, models of the circuit components and their parameters can be viewed/specified from a Model Library with all the available model implementations in the Neurokernel Execution Engine. In addition to these simple interactive operations further detailed in Materials and methods, Use Case 3, FlyBrainLab APIs support bulk operations such as updating models and parameters of an arbitrary number of circuit components (see also Appendix 4).</p></sec><sec id="s2-4"><title>Use Case 4: analyzing, evaluating, and comparing circuit models of the fruit fly central complex</title><p>We first demonstrate the workflow supported by FlyBrainLab for analyzing, evaluating and comparing circuit models of the fruit fly Central Complex (CX) based on the FlyCircuit dataset (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>). The circuit connecting the ellipsoid body (EB) and the protocerebral bridge (PB) in the CX has been shown to exhibit ring attractor dynamics (<xref ref-type="bibr" rid="bib69">Seelig and Jayaraman, 2015</xref>; <xref ref-type="bibr" rid="bib39">Kim et al., 2017</xref>; <xref ref-type="bibr" rid="bib72">Skaggs et al., 1995</xref>). Recently, a number of researchers investigated circuit mechanisms underlying these dynamics. Here, we developed a CXcircuits Library for analyzing, evaluating and comparing various CX circuit realizations. Specifically, we implemented three of the circuit models published in the literature, called here model A (<xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref>), model B (<xref ref-type="bibr" rid="bib36">Kakaria and de Bivort, 2017</xref>), and model C (<xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>), and compared them in the same FlyBrainLab programming environment.</p><p>In <xref ref-type="fig" rid="fig6">Figure 6 (a1, b1, c1)</xref>, the anatomy of the neuronal circuits considered in models A, B, and C is depicted, respectively. The corresponding interactive circuit diagram is shown in <xref ref-type="fig" rid="fig6">Figure 6 (a2, b2, c2)</xref>. Here, model A provides the most complete interactive CX circuit, including the core subcircuits for characterizing the PB-EB interaction with the EB-LAL-PB, PB-EB-LAL, PB-EB-NO, PB local, and EB ring neurons (see Materials and methods, Use Case 4, and <xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref> for commonly used synonyms). Models B and C exhibit different subsets of the core PB-EB interaction circuit in model A. While no ring neurons are modeled in model B, PB local neurons are omitted in model C. They, however, do not model other neurons in the CX, for example, those that innervate the Fan-shaped Body (FB).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Analysis, evaluation and comparison of three models of CX published in the literature.</title><p>(<bold>a1–a4</bold>) Model A (<xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref>), (<bold>b1–b4</bold>) Model B (<xref ref-type="bibr" rid="bib36">Kakaria and de Bivort, 2017</xref>), (<bold>c1–c4</bold>) Model C (<xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>). (<bold>a1, b1, c1</bold>) Morphology of the neurons visualized in the NeuroNLP window (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>). Displayed number of neurons in: (<bold>a1</bold>) 366, (<bold>a2</bold>) 87, (<bold>a3</bold>) 54. (<bold>a2, b2, c2</bold>) Neuronal circuits in the NeuroNLP window depicted in the NeuroGFX window (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>) as abstract interactive circuit diagrams. The naming of the ring neurons in (<bold>c2</bold>) follows <xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>. Number of neurons in the diagram: (<bold>b1</bold>) 348, (<bold>b2</bold>) 60, (<bold>b3</bold>) 56. As the FlyCircuit dataset contains duplicates, some neurons in the diagrams may correspond to multiple neurons in the dataset and some do not have correspondences due to the lack of morphology data. (<bold>a3, b3, c3</bold>) When a single vertical bar is presented in the visual field (d1/d2), different sets of neurons/subregions (highlighted) in each of the models, respectively, receive either current injections or external spike inputs. (<bold>a4, b4, c4</bold>) The mean firing rates of the EB-LAL-PB neurons innervating each of the EB wedges of the three models (see Materials and methods, Use Case 4), in response to the stimulus shown in (<bold>d3</bold>). Insets show the rates at 10, 20, and 30 s, respectively, overlaid onto the EB ring. (<bold>d1</bold>) A schematic of the visual field surrounding the fly. (<bold>d2</bold>) The visual field flattened. (<bold>d3</bold>) Input stimulus consisting of a bar moving back and forth across the screen, and a second fixed bar at <inline-formula><mml:math id="inf5"><mml:msup><mml:mn>60</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula> and with lower brightness.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig6-v2.tif"/></fig><p>In <xref ref-type="video" rid="video1">Video 1</xref>, we demonstrate the interactive capabilities of the three models side-by-side, including the visualization of the morphology of CX neurons and the corresponding executable circuits, user interaction with the circuit diagram revealing connectivity pattern, and the execution of the circuit. In the video, the visual stimulus depicted in <xref ref-type="fig" rid="fig6">Figure 6 (d3)</xref> was presented to three models (see Materials and methods, Use Case 4, for the details of generating the input stimulus for each model). The responses, measured as the mean firing rate of EB-LAL-PB neurons within contiguous EB wedges, are shown in <xref ref-type="fig" rid="fig6">Figure 6 (a4, b4, c4)</xref>, respectively. Insets depict the responses at 10, 20, and 30 s. During the first second, a moving bar in its fixed initial position and a static bar are presented. The moving bar displays a higher brightness than the static bar. All three models exhibited a single-bump (slightly delayed) response tracking the position of the moving bar. The widths of the bumps were different, however. After 30 s, the moving bar disappeared and models A and B shifted to track the location of the static bar, whereas the bump in model C persisted in the same position where the moving bar disappeared. Furthermore, for models B and C but not for model A, the bumps persisted after the removal of the visual stimulus (after 33 s), as previously observed in vivo (<xref ref-type="bibr" rid="bib69">Seelig and Jayaraman, 2015</xref>; <xref ref-type="bibr" rid="bib39">Kim et al., 2017</xref>).</p><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-62362-video1.mp4"><label>Video 1.</label><caption><title>Running three CX executable circuits in the FlyBrainLab.</title><p>(left) Model A (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). (middle) Model B (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). (right) Model C (<xref ref-type="fig" rid="fig6">Figure 6c</xref>).</p></caption></media><p>By comparing these circuit models, we notice that, to achieve the ring attractor dynamics, it is critical to include global inhibitory neurons, for example, PB local neurons in models A and B, and ring neurons in models A and C. The model A ring neurons featuring a different receptive field and the ring neurons in model C receiving spike train input play a similar functional role. However, to achieve the ring attractor dynamics characterized by a single bump response to multiple bars and persistent bump activity after the removal of the vertical bar, model C only required three out of the five core neuron types (see Materials and methods, Use Case 4), whereas model B requires all four neuron types included.</p></sec><sec id="s2-5"><title>Use Case 5: analyzing, evaluating, and comparing adult antenna and antennal lobe circuit models based upon the FlyCircuit and hemibrain datasets</title><p>In the second example, we demonstrate the effect on modeling the antenna and antennal lobe circuits due to, respectively, the FlyCircuit (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>) and the Hemibrain (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>) datasets (see also Materials and methods, Use Case 5).</p><p>We start by exploring and analyzing the morphology and connectome of the olfactory sensory neurons (OSNs), antennal lobe projection neurons (PNs), and local neurons (LNs) of the FlyCircuit (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>) and the Hemibrain (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>) datasets (see <xref ref-type="fig" rid="fig7">Figure 7a</xref>). Compared with the antennal lobe data in the FlyCircuit dataset, the Hemibrain dataset reveals additional connectivity details between OSNs, PNs, and LNs that we took into account when modeling the antennal lobe circuit (see Materials and methods, Use Case 5). Following (<xref ref-type="bibr" rid="bib43">Lazar et al., 2020a</xref>), we first constructed the two layer circuit based on the FlyCircuit dataset shown in <xref ref-type="fig" rid="fig7">Figure 7b</xref> (left) and then constructed a more extensive connectome/synaptome model of the adult antennal lobe based on the Hemibrain dataset as shown in <xref ref-type="fig" rid="fig7">Figure 7b</xref> (right).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Analysis, evaluation, and comparison between two models of the antenna and antennal lobe circuit of the adult fly based on the FlyCircuit (left) dataset (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>) and an exploratory model based on the Hemibrain (right) dataset (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>).</title><p>(<bold>a</bold>) Morphology of olfactory sensory neurons, local neurons, and projection neurons in the antennal lobe for the two datasets. The axons of the projection neurons and their projections to the mushroom body and lateral horn are also visible. (<bold>b</bold>) Circuit diagrams depicting the antenna and antennal lobe circuit motifs derived from the two datasets. (<bold>c</bold>) Response of the antenna/antennal lobe circuit to a constant ammonium hydroxide step input applied between 1 s and 3 s of a 5 s simulation; (left) the interaction between the odorant and 23 olfactory receptors is captured as the vector of affinity values; (middle and right) a heatmap of the uniglomerular PN PSTH values (spikes/second) grouped by glomerulus for the two circuit models. (<bold>d</bold>) The PN response transients of the two circuit models for uniform noise input with a minimum of 0ppm and a maximum of 100 ppm preprocessed with a 30 Hz low-pass filter (<xref ref-type="bibr" rid="bib37">Kim et al., 2011</xref>) and delivered between 1 s and 3 s.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig7-v2.tif"/></fig><p>Execution of and comparison of the results of these two circuit models show quantitatively different PN output activity in steady-state (<xref ref-type="fig" rid="fig7">Figure 7c</xref>) and for transients (<xref ref-type="fig" rid="fig7">Figure 7d</xref>). A prediction (<xref ref-type="bibr" rid="bib45">Lazar and Yeh, 2019</xref>; <xref ref-type="bibr" rid="bib43">Lazar et al., 2020a</xref>) made by the antenna and antennal lobe circuit shown in <xref ref-type="fig" rid="fig7">Figure 7b</xref> (left) using the FlyCircuit data has been that the PN activity, bundled according to the source glomerulus, is proportional to the vector characterizing the affinity of the odorant-receptor pairs (<xref ref-type="fig" rid="fig7">Figure 7c</xref>, left column).</p><p>The transient and the steady state activity response are further highlighted in <xref ref-type="fig" rid="fig7">Figure 7d</xref> for different amplitudes of the odorant stimulus waveforms. The initial results show that the circuit on the right detects with added emphasis the beginning and the end of the odorant waveforms.</p><p>The complex connectivity between OSNs, LNs, and PNs revealed by the Hemibrain dataset suggests that the adult antennal lobe circuit encodes additional odorant representation features (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>).</p></sec><sec id="s2-6"><title>Use Case 6: analyzing, evaluating, and comparing early olfactory circuit models of the larva and the adult fruit flies</title><p>In the third example, we investigate the difference in odorant encoding and processing in the <italic>Drosophila</italic> Early Olfactory System (EOS) at two different developmental stages, the adult and larva (see also Materials and methods, Use Case 6).</p><p>We start by exploring and analyzing the morphology and connectome for the Olfactory Sensory Neurons (OSNs), Antennal Lobe Projection Neurons (PNs) and Local Neurons (LNs) of the adult Hemibrain (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>) dataset and the LarvaEM (<xref ref-type="bibr" rid="bib6">Berck et al., 2016</xref>) dataset (see <xref ref-type="fig" rid="fig8">Figure 8a</xref>).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Evaluation and Comparison of two <italic>Drosophila</italic> Early Olfactory System (EOS) models describing adult (<italic>left</italic>, developed based on Hemibrain dataset) and larval (<italic>right</italic>, developed based on LarvaEM dataset) circuits.</title><p>(<bold>a</bold>) Morphology of Olfactory Sensory Neurons (OSNs) in the Antenna (ANT), Local Neurons (LNs) in the Antennal Lobe (AL) and Projection Neurons in the AL. (<bold>b</bold>) Circuit diagrams depicting the Antenna and Antennal Lobe circuit motifs. (<bold>c</bold>) (left) Interaction between 13 odorants and 37 odorant receptors (ORs) characterized by affinity values. The ORs expressed only in the adult fruit flies are grouped in the top panel; the ones that are expressed in both the adult and the larva are grouped in the middle panel; and those expressed only in the larva are shown in the bottom panel. Steady-state outputs of the EOS models to a step concentration waveform of 100 ppm are used to characterize combinatorial codes of odorant identities at the OSN level (middle) and the PN level (right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig8-v2.tif"/></fig><p>Detailed connectivity data informed the construction of the model for both the adult and larva EOS, that we developed based on parameterized versions of the previous literature (<xref ref-type="bibr" rid="bib43">Lazar et al., 2020a</xref>). In particular, the larval model includes fewer number of OSNs, PNs, and LNs in Antenna and Antennal Lobe circuit as shown in <xref ref-type="fig" rid="fig8">Figure 8b</xref> right.</p><p>The adult and larval EOS models were simultaneously evaluated on a collection of mono-molecular odorants whose binding affinities to odorant receptors have been estimated from physiological recordings (see also Materials and methods Use Case 6). In <xref ref-type="fig" rid="fig8">Figure 8c</xref> (left), the affinity values are shown for the odorant receptors that are only in the adult fruit fly (top panel), that appear in both the adult and the larva (middle panel) and, finally, that are only in the larva. The steady-state responses of the Antenna and Antennal Lobe circuit for both models are computed and shown in <xref ref-type="fig" rid="fig8">Figure 8c</xref> (middle and right, respectively). Visualized in juxtaposition alongside the corresponding affinity vectors, we observe a stark contrast in odorant representation at all layers of the circuit between adult and larva, raising the question of how downstream circuits can process differently represented odorant identities and instruct similar olfactory behavior across development. Settling such questions requires additional physiological recordings, that may improve the accuracy of the current FlyBrainLab EOS circuit models.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Historically, a large number of visualization and computational tools have been developed primarily designed for either neurobiological studies (see <xref ref-type="fig" rid="fig1">Figure 1</xref> (left)) or computational studies (see <xref ref-type="fig" rid="fig1">Figure 1</xref> (right)). These are briefly discussed below.</p><p>The computational neuroscience community has invested a significant amount of effort in developing tools for analyzing and evaluating model neural circuits. A number of simulation engines have been developed, including general simulators such as NEURON (<xref ref-type="bibr" rid="bib32">Hines and Carnevale, 1997</xref>), NEST (<xref ref-type="bibr" rid="bib22">Gewaltig and Diesmann, 2007</xref>), Brian (<xref ref-type="bibr" rid="bib75">Stimberg et al., 2019</xref>), Nengo (<xref ref-type="bibr" rid="bib5">Bekolay et al., 2014</xref>), Neurokernel (<xref ref-type="bibr" rid="bib26">Givon and Lazar, 2016</xref>), DynaSim (<xref ref-type="bibr" rid="bib71">Sherfey et al., 2018</xref>), and the ones that specialize in multi-scale simulation, for example MOOSE (<xref ref-type="bibr" rid="bib63">Ray and Bhalla, 2008</xref>), in compartmental models, for example ARBOR (<xref ref-type="bibr" rid="bib1">Akar et al., 2019</xref>), and in fMRI-scale simulation for example The Virtual Brain (<xref ref-type="bibr" rid="bib66">Sanz Leon et al., 2013</xref>; <xref ref-type="bibr" rid="bib54">Melozzi et al., 2017</xref>). Other tools improve the accessibility to these simulators by (i) facilitating the creation of large-scale neural networks, for example BMTK (<xref ref-type="bibr" rid="bib12">Dai et al., 2020a</xref>) and NetPyNE (<xref ref-type="bibr" rid="bib18">Dura-Bernal et al., 2019</xref>), and by (ii) providing a common interface, simplifying the simulation workflow and streamlining parallelization of simulation, for example PyNN (<xref ref-type="bibr" rid="bib15">Davison et al., 2008</xref>), Arachne (<xref ref-type="bibr" rid="bib2">Aleksin et al., 2017</xref>), and NeuroManager (<xref ref-type="bibr" rid="bib76">Stockton and Santamaria, 2015</xref>). To facilitate access and exchange of neurobiological data worldwide, a number of model specification standards have been worked upon in parallel including MorphML (<xref ref-type="bibr" rid="bib11">Crook et al., 2007</xref>), NeuroML (<xref ref-type="bibr" rid="bib27">Gleeson et al., 2010</xref>), SpineML (<xref ref-type="bibr" rid="bib84">Tomkins et al., 2016</xref>), and SONATA (<xref ref-type="bibr" rid="bib13">Dai et al., 2020b</xref>).</p><p>Even with the help of these computational tools, it still takes a substantial amount of manual effort to build executable circuits from real data provided, for example, by model databases such as ModelDB/NeuronDB (<xref ref-type="bibr" rid="bib31">Hines et al., 2004</xref>) and NeuroArch (<xref ref-type="bibr" rid="bib24">Givon et al., 2015</xref>). Moreover, with the ever expanding size of the fruit fly brain datasets, it has become more difficult to meet the demand of creating executable circuits that can be evaluated with different datasets. In addition, with very few exceptions, comparisons of circuit models, a standard process in the computer science community, are rarely available in the computational neuroscience literature.</p><p>Substantial efforts by the system neuroscience community went into developing tools for visualizing the anatomy of the brain. A number of tools have been developed to provide interactive, web-based interfaces for exploring, visualizing and analyzing fruit fly brain and ventral nerve cord datasets, for both the adult (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>; <xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>) and the larva (<xref ref-type="bibr" rid="bib59">Ohyama et al., 2015</xref>). These include the FlyCircuit (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>), the Fruit Fly Brain Observatory (FFBO/NeuroNLP) (<xref ref-type="bibr" rid="bib85">Ukani et al., 2019</xref>), Virtual Fly Brain (<xref ref-type="bibr" rid="bib55">Milyaev et al., 2012</xref>), neuPrintExplorer (<xref ref-type="bibr" rid="bib10">Clements et al., 2020</xref>), FlyWire (<xref ref-type="bibr" rid="bib17">Dorkenwald et al., 2020</xref>), and CATMAID (<xref ref-type="bibr" rid="bib65">Saalfeld et al., 2009</xref>). Similar tools have been developed for other model organisms, such as the Allen Mouse Brain Connectivity Atlas (<xref ref-type="bibr" rid="bib58">Oh et al., 2014</xref>), the WormAtlas for <italic>C. elegans</italic> (<ext-link ext-link-type="uri" xlink:href="https://www.wormatlas.org">https://www.wormatlas.org</ext-link>) and the Z Brain for zebra fish (<xref ref-type="bibr" rid="bib62">Randlett et al., 2015</xref>). A number of projects, for example (<xref ref-type="bibr" rid="bib4">Bates et al., 2020</xref>), offer a more specialized capability for visualizing and analyzing neuroanatomy data.</p><p>While these tools have significantly improved the access to and exploration of brain data a number of recent efforts started to bridge the gap between neurobiological data and computational modeling including the Geppetto (<xref ref-type="bibr" rid="bib8">Cantarelli et al., 2018</xref>), the OpenWorm (<xref ref-type="bibr" rid="bib80">Szigeti et al., 2014</xref>) and the Open Source Brain (<xref ref-type="bibr" rid="bib28">Gleeson et al., 2019</xref>) initiatives and the Brain Simulation Platform of the Human Brain Project (<xref ref-type="bibr" rid="bib19">Einevoll et al., 2019</xref>). However, without information linking circuit activity/computation to the structure of the underlying neuronal circuits, understanding the function of brain circuits remains elusive. Lacking a systematic method of automating the process of creating and exploring the function of executable circuits at the brain or system scale levels hinders the application of these tools when composing more complex circuits. Furthermore, these tools fall short of offering the capability of generating static circuit diagrams, let alone interactive ones. The experience of VLSI design, analysis, and evaluation of computer circuits might be instructive here. An electronic circuit engineer reads a circuit diagram of a chip, rather than the 3D structure of the tape-out, to understand its function, although the latter ultimately realizes it. Similarly, visualization of a biological circuit alone, while powerful and intuitive for building a neural circuit, provides little insights into the function of the circuit. While simulations can be done without a circuit diagram, understanding how an executable circuit leads to its function remains elusive.</p><p>The tools discussed above all fall short of offering an integrated infrastructure that can effectively leverage the ever expanding neuroanatomy, genetic and neurophysiology data for creating and exploring executable fly brain circuits. Creating circuit simulations from visualized data remains a major challenge and requires extraordinary effort in practice as amply demonstrated by the Allen Brain Observatory (<xref ref-type="bibr" rid="bib16">de Vries et al., 2020</xref>). The need to accelerate the pace of discovery of the functional logic of the brain of model organisms has entered a center stage in brain research.</p><p>FlyBrainLab is uniquely positioned to accelerate the discovery of the functional logic of the <italic>Drosophila</italic> brain. Its interactive architecture seamlessly integrates and brings together computational models with neuroanatomical, neurogenetic, and neurophysiological data, changing the organization of fruit fly brain data from a group of independently created datasets, arrays, and tables, into a well-structured data and executable circuit repository, with a simple API for accessing data in different datasets. Current data integration extensively focuses on connectomics/synaptomics datasets that, as demonstrated, strongly inform the construction of executable circuit models. We will continue to expand the capabilities of the NeuroArch database with genetic Gal4 lines (<ext-link ext-link-type="uri" xlink:href="https://gene.neuronlp.fruitflybrain.org">https://gene.neuronlp.fruitflybrain.org</ext-link>) and neurophysiology recordings including our own (<ext-link ext-link-type="uri" xlink:href="http://antenna.neuronlp.fruitflybrain.org/">http://antenna.neuronlp.fruitflybrain.org/</ext-link>). How to construct executable models of brain circuits using genetic and neurophysiology data sets is not the object of this publication and will be discussed elsewhere. Pointers to our initial work are given below.</p><p>As detailed here, the FlyBrainLab UI supports a highly intuitive and automated workflow that streamlines the 3D exploration and visualization of fly brain circuits, and the interactive exploration of the functional logic of executable circuits created directly from the analyzed fly brain data. In conjunction with the capability of visually constructing circuits, speeding up the process of creating interactive executable circuit diagrams can substantially reduce the exploratory development cycle.</p><p>The FlyBrainLab Utility and Circuit Libraries accelerate the creation of models of executable circuits. The Utility Libraries (detailed in the Appendix 2) help untangle the graph structure of neural circuits from raw connectome and synaptome data. The Circuit Libraries (detailed in the Appendix 3) facilitate the exploration of neural circuits of the neuropils of the central complex and, the development and implementation of models of the adult and larva fruit fly early olfactory system.</p><p>Importantly, to transcend the limitations of the connectome, FlyBrainLab is providing Circuit Libraries for molecular transduction in sensory coding (detailed in the Appendix 3), including models of sensory transduction and neuron activity data (<xref ref-type="bibr" rid="bib41">Lazar et al., 2015a</xref>; <xref ref-type="bibr" rid="bib42">Lazar et al., 2015b</xref>; <xref ref-type="bibr" rid="bib46">Lazar and Yeh, 2020</xref>). These libraries serve as entry points for discovery of circuit function in the sensory systems of the fruit fly (<xref ref-type="bibr" rid="bib45">Lazar and Yeh, 2019</xref>; <xref ref-type="bibr" rid="bib43">Lazar et al., 2020a</xref>). They also enable the biological validation of developed executable circuits within the same platform.</p><p>The modular software architecture underlying FlyBrainLab provides substantial flexibility and scalability for the study of the larva and adult fruit fly brain. As more data becomes available, we envision that the entire central nervous system of the fruit fly can be readily explored with FlyBrainLab. Furthermore, the core of the software and the workflow enabled by the FlyBrainLab for accelerating discovery of <italic>Drosophila</italic> brain functions can be adapted in the near term to other model organisms including the zebrafish and bee.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>The FlyBrainLab interactive computing platform tightly integrates tools enabling the morphological visualization and exploration of large connectomics/synaptomics datasets, interactive circuit construction and visualization and multi-GPU execution of neural circuit models for in silico experimentation. The tight integration is achieved with a comprehensive open software architecture and libraries to aid data analysis, creation of executable circuits and exploration of their functional logic.</p><sec id="s4-1"><title>Architecture of FlyBrainLab</title><p>FlyBrainLab exhibits a highly extensible, modularized architecture consisting of a number of interconnected server-side and user-side components (see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>) including the NeuroArch Database, the Neurokernel Execution Engine and the NeuroMinerva front-end. The architecture of FlyBrainLab and the associated components are described in detail in Appendix 1.</p></sec><sec id="s4-2"><title>FlyBrainLab Utilities Libraries</title><p>FlyBrainLab offers a number of utility libraries to untangle the graph structure of neural circuits from raw connectome and synaptome data. These libraries provide a large number of tools including high level connectivity queries and analysis, algorithms for discovery of connectivity patterns, circuit visualization in 2D or 3D and morphometric measurements of neurons. These utility libraries are described in detail in Appendix 2.</p></sec><sec id="s4-3"><title>FlyBrainLab Circuit Libraries</title><p>FlyBrainLab provides a number of libraries for analysis, evaluation and comparison of fruit fly brain circuits. The initial release of FlyBrainLab offers libraries for exploring neuronal circuits of the central complex, early olfactory system, and implementations of olfactory and visual transduction models. These circuit libraries are described in detail in Appendix 3.</p></sec><sec id="s4-4"><title>Loading publicly available datasets into NeuroArch Database</title><p>All datasets are loaded into the NeuroArch database (<xref ref-type="bibr" rid="bib24">Givon et al., 2015</xref>; <xref ref-type="bibr" rid="bib23">Givon et al., 2014</xref>) using the NeuroArch API (<ext-link ext-link-type="uri" xlink:href="https://github.com/fruitflybrain/neuroarch">https://github.com/fruitflybrain/neuroarch</ext-link>).</p><p>For the FlyCircuit dataset (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>) version 1.2, all 22,828 female <italic>Drosophila</italic> neurons were loaded, including their morphology, putative neurotransmitter type, and other available metadata. The original name of the neurons was used. These names also serve as the ‘referenceId’ pointing to the record in the original dataset. Connectivity between neurons was inferred according to <xref ref-type="bibr" rid="bib34">Huang et al., 2018</xref> and loaded as a different, inferred class of synapses, totaling 4,538,280 connections between pairs of neurons. The metadata was provided by the authors (<xref ref-type="bibr" rid="bib34">Huang et al., 2018</xref>).</p><p>For the Hemibrain dataset (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>), release 1.0.1. Attributes of the neurons, synapses and connections were obtained from the Neuprint database dump available at (<ext-link ext-link-type="uri" xlink:href="https://storage.cloud.google.com/hemibrain-release/neuprint/hemibrain_v1.0.1_neo4j_inputs.zip">https://storage.cloud.google.com/hemibrain-release/neuprint/hemibrain_v1.0.1_neo4j_inputs.zip</ext-link>). The neuropil boundary mesh and neuron morphology were obtained by invoking the neuprint-python API (<xref ref-type="bibr" rid="bib10">Clements et al., 2020</xref>) of the database server publicly hosted by the original dataset provider. The former was post-processed to simplify the mesh object in MeshLab (<ext-link ext-link-type="uri" xlink:href="https://www.meshlab.net">https://www.meshlab.net</ext-link>) using quadric edge collapse decimation with a percentage of 0.05. All coordinates were scaled by 0.008 to a [µm] unit. It included a total of 24,770 neurons that were designated in the Neuprint database as ‘Traced’, ‘Roughly Traced’, as well as the neurons that were assigned a name or a cell type. Cell type and neuron name follow the ‘type’ and ‘instance’ attributes, respectively, in the original dataset. To create a unique name for each neuron, neurons with the same instance names were padded with a sequential number. The BodyIDs of neurons in the original dataset use the ‘referenceId’. A total of 3,604,708 connections between pairs of neurons were loaded, and included the positions of 14,318,675 synapses.</p><p>At the time of publication, the Hemibrain dataset release 1.2 (<ext-link ext-link-type="uri" xlink:href="https://storage.cloud.google.com/hemibrain-release/neuprint/hemibrain_v1.2_neo4j_inputs.zip">https://storage.cloud.google.com/hemibrain-release/neuprint/hemibrain_v1.2_neo4j_inputs.zip</ext-link>) was also loaded into the NeuroArch Database. It included a total of 25,842 neurons, 3,817,700 connections between pairs of these neurons and the positions of 15,337,617 synapses.</p><p>For the Larva L1EM dataset (<xref ref-type="bibr" rid="bib59">Ohyama et al., 2015</xref>), a total of 1,051 neurons characterized by their morphology and metadata were loaded from the publicly served database server at <ext-link ext-link-type="uri" xlink:href="https://l1em.catmaid.virtualflybrain.org">https://l1em.catmaid.virtualflybrain.org</ext-link>. The IDs of neurons in the original dataset were used as ‘referenceId’. A total of 30,350 connections between pairs of neurons were loaded, including the position of 121,112 synapses. All coordinates were scaled by 0.001 to a [<inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula>] unit.</p><p>For the Medulla 7 Column dataset (<xref ref-type="bibr" rid="bib81">Takemura et al., 2015</xref>), the attributes of the neurons, synapses and connections were obtained from the Neuprint database server export available at <ext-link ext-link-type="uri" xlink:href="https://storage.cloud.google.com/hemibrain-release/neuprint/fib25_neo4j_inputs.zip">https://storage.cloud.google.com/hemibrain-release/neuprint/fib25_neo4j_inputs.zip</ext-link>. Neuron morphology was obtained from <ext-link ext-link-type="uri" xlink:href="https://github.com/janelia-flyem/ConnectomeHackathon2015">https://github.com/janelia-flyem/ConnectomeHackathon2015</ext-link> commit 81e94a9. Neurons without a morphology were omitted during loading. The rest of the procedure is the same as for loading the Hemibrain dataset. A total of 2365 neurons, 42,279 connections between pairs of neurons, and the positions of 130,203 synapses were loaded. Neurotransmitter data was obtained from the Gene Expression Omnibus accession GSE116969 of the transcriptome study published in <xref ref-type="bibr" rid="bib14">Davis et al., 2020</xref>.</p><p>Extra annotations were avoided as much as possible when loading these datasets to the NeuroArch database for public download. If any, they were used to comply with the NeuroArch data model. The complete loading scripts are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/datasets">https://github.com/FlyBrainLab/datasets</ext-link>.</p></sec><sec id="s4-5"><title>Use Case 1: building fly brain circuits with English queries</title><p>The circuit in <xref ref-type="fig" rid="fig3">Figure 3 (a1)</xref> was built using the Medulla 7 Column dataset. The following English queries were used to construct the circuit: (1) ‘show T4a in column home’, (2) ‘color lime’, (3) ‘add presynaptic neurons’, (4) ‘color gray’, (5) ‘add presynaptic $Dm$ neurons with more than five synapses’, (6) ‘color cyan’, (7) ‘add presynaptic $Pm$ neurons with more than five synapses’, (8) ‘color yellow’, (9) ‘pin T4a in column home’, (10) ‘pin $Dm$', (11) ‘pin $Pm$’.</p><p>The circuit in <xref ref-type="fig" rid="fig3">Figure 3 (b1)</xref> was built using the Hemibrain dataset release 1.2. The following English queries were used to construct the circuit: (1) ‘show MBON presynaptic to neurons that has outputs in FB layer 3 with at least 10 synapses’, (2) ‘color mbon yellow’, (3) ‘add postsynaptic neurons with at least 10 synapses that has output in FB layer 3’, (4) ‘color forest green’, (5) ‘add mbon postsynaptic to neurons that have input in FB layer 3 with at least 10 synapses’, (6) ‘color red’.</p><p>The circuit in <xref ref-type="fig" rid="fig3">Figure 3 (c1)</xref> was built using the Larva L1EM dataset. We first query the neuron MBON that innervate the g compartment by ‘show $MBON-g$ in right mb’. The Information Panel in the FlyBrainLab UI provides a list of presynaptic partners and a list of postsynaptic partners of the neuron selected. After filtering the list by name and by the number of synapses, each neuron and the synapses to/from the neuron can be added to the NeuroNLP window for visualization. Finally, the collection of all filtered results can be added to the NeuroNLP window for visualization by clicking a single button. The circuit in <xref ref-type="fig" rid="fig3">Figure 3 (c1)</xref> was constructed by leveraging this capability.</p><p>The circuit in <xref ref-type="fig" rid="fig3">Figure 3 (d1)</xref> was built using the Hemibrain dataset release 1.2. First, the LPTCs and GLNs in the right hemisphere were added with the NLP queries ‘show LPTC’ and ‘add /rGLN(.*)R(.*)/r’. Second, to obtain the pathway between the two neuron types, the following query was invoked:<code xml:space="preserve"># query for LPTC</code></p><p><code xml:space="preserve">res1 = client.executeNLPquery(&quot;show LPTC&quot;)</code></p><p><code xml:space="preserve"># color the neurons in the previous query
_ = client.executeNLPquery('color orange')</code></p><p><code xml:space="preserve"># query for GLN on the right hemisphere using regular expression 
res2 = client.executeNLPquery(&quot;add /rGLN(.*)R(.*)/r&quot;)</code></p><p><code xml:space="preserve"># color the neurons in the previous query
_ = client.executeNLPquery(&quot;color cyan&quot;) 
</code></p><p><code xml:space="preserve"># get the unique names of the GLNs
gln = [v['uname'] for v in res2.neurons.values()]</code></p><p><code xml:space="preserve"># query using NeuroArch JSON format 
task = {&quot;query&quot;: [
          {&quot;action&quot;: {&quot;method&quot;: {&quot;path_to_neurons&quot;: {
              &quot;pass_through&quot;: gln,
              &quot;max_hops&quot;: 2,
              &quot;synapse_threshold&quot;: 5
          }}},
          &quot;object&quot;: {&quot;state&quot;: 1}}],
        &quot;format&quot;: &quot;morphology&quot;,
        &quot;verb&quot;: &quot;add&quot;
}</code></p><p><code xml:space="preserve">res3 = client.executeNAquery(task)
_ = client.executeNLPquery(&quot;color red&quot;)</code></p><p>After building up the circuit in the NeuroNLP window, the connectivity matrices of the four circuits were retrieved using the ‘get_neuron_adjacency_matrix’ method.</p></sec><sec id="s4-6"><title>Use Case 2: exploring the structure and function of yet to be discovered brain circuits</title><p>To investigate the overall brain level structure from Hemibrain neurons (<xref ref-type="fig" rid="fig4">Figure 4a–c</xref>), NeuroArch Database was queried for all neurons in the Hemibrain dataset and connectivity information (in the form of a directed graph) was extracted using the FlyBrainLab Client API (see Appendix 1.2). The Louvain algorithm (<xref ref-type="bibr" rid="bib7">Blondel et al., 2008</xref>) of the NeuroGraph Library (see Appendix 2) was used to detect the structure of the graph. Apart from the connectivity of the neurons, any annotation of the neurons was excluded from the analysis. A random subset of neurons from each densely connected group are visualized and colored in the NeuroNLP. Group names are assigned by visually inspecting the results displayed by the NeuroNLP window and known neuropil structure of the fly brain. The circuit diagram was created by hand according to the groups and inter-group connections.</p><p>To define cell types in the VA1v glomerulus connectome dataset (<xref ref-type="fig" rid="fig4">Figure 4d–f</xref>), NeuroArch Database was queried for all neurons in the VA1v dataset and connectivity information (in the form of a directed graph) was extracted by using the FlyBrainLab Client API (see Appendix 1.2). The Adjacency Spectral Embedding algorithm (<xref ref-type="bibr" rid="bib79">Sussman et al., 2012</xref>) of the NeuroGraph library (see Appendix 2) was applied to calculate embeddings via the <inline-formula><mml:math id="inf7"><mml:mrow><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo>∘</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula> approach (<xref ref-type="bibr" rid="bib61">Priebe et al., 2017</xref>). Annotations of the identity of the neurons, if any, were not used in this step of the analysis. To check the quality of the embeddings result, human-annotated data from the original dataset was used to color the neurons according to their cell types. Neurons from each cell type were visualized and colored by NeuroNLP commands. The circuit diagram was generated using the NeuroGraph Library. Connections between neurons were established only if more than 10 synapses from a presynaptic neuron to a postsynaptic neuron could be identified. Coloring of the cell types matches the NeuroNLP commands.</p><p>To investigate the downstream neurons of V glomerulus projection neurons of the AL (<xref ref-type="fig" rid="fig4">Figure 4g–i</xref>), the latter neurons and their postsynaptic partners with more than 10 synapses were visualized with NeuroNLP queries. Arborization data of each neuron was queried to determine whether it is a local neuron or an output neuron of the lateral horn. NeuroGraph Library was used to generate the circuit diagram. The circuit diagram generation is based on the GraphViz library (<xref ref-type="bibr" rid="bib20">Ellson et al., 2001</xref>), and additional information such as group names were used for arranging the diagram.</p></sec><sec id="s4-7"><title>Use Case 3: interactive exploration of executable fruit fly brain circuit models</title><p>Connectome data published by <xref ref-type="bibr" rid="bib64">Rivera-Alba et al., 2011</xref> was uploaded into the NeuroArch Database, including the six photoreceptors, eight neurons, and six neurites of multiple amacrine cells that innervate the cartridge. For simplicity, each of the amacrine cell neurites was considered as a separate neuron. The traced neuron data were obtained from authors of <xref ref-type="bibr" rid="bib64">Rivera-Alba et al., 2011</xref> and subsequently converted into neuron skeletons in SWC format. The connectivity between these neurons was provided in <xref ref-type="bibr" rid="bib64">Rivera-Alba et al., 2011</xref> as supplementary information.</p><p>Loading data into NeuroArch Database was achieved with the FlyBrainLab 'query' module. The 'query' module provides a mirror of the functionality available in the high-level NeuroArch API. The pathway was then explored in the NeuroNLP window and the connectivity matrix extracted by FlyBrainLab Client API call, as described above.</p><p>The circuit diagram in <xref ref-type="fig" rid="fig5">Figure 5</xref> was created manually using Inkscape. All blocks representing the neurons were added with attributes that had the neuron’s unique name in the database as a label value, and added with '.neuron’ class designation. Similarly, all synapses were added with '.synapse' class designation. The diagram was made interactive by loading a javascript file available in the NeuGFX library. The runtime interaction is controlled by the circuit module of the FlyBrainLab Client API.</p><p>Appendix 4 provides a walk through of the process of creating and operating an interactive circuit diagram of a Lamina cartridge circuit starting from raw connectomic and synaptomic data (<xref ref-type="bibr" rid="bib64">Rivera-Alba et al., 2011</xref>). Some of the core FlyBrainLab capabilities (see also Appendix 1.2) are also highlighted. The walk through is accompanied by a Jupyter notebook available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/Tutorials/tree/master/tutorials/cartridge/Cartridge.ipynb">https://github.com/FlyBrainLab/Tutorials/tree/master/tutorials/cartridge/Cartridge.ipynb</ext-link>.</p><p>In what follows, the usage of FlyBrainlab in analyzing, evaluating and comparing more complex circuit models is demonstrated. For brevity, Jupyter notebooks are only provided on Github repositories disseminated at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab/wiki/FlyBrainLab-Resources">https://github.com/FlyBrainLab/FlyBrainLab/wiki/FlyBrainLab-Resources</ext-link>.</p></sec><sec id="s4-8"><title>Use Case 4: analyzing, evaluating, and comparing circuit models of the fruit fly central complex</title><p>Model A (<xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref>; <xref ref-type="fig" rid="fig6">Figure 6a</xref>), Model B (<xref ref-type="bibr" rid="bib36">Kakaria and de Bivort, 2017</xref>; <xref ref-type="fig" rid="fig6">Figure 6b</xref>) and Model C (<xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>; <xref ref-type="fig" rid="fig6">Figure 6c</xref>) were implemented using the CXcircuits Library (see also Appendix 3). A wild-type fruit fly CX circuit diagram based on model A was created in the SVG format and made interactive in the NeuroGFX window. The neurons modeled in the circuit diagram were obtained by querying all the neurons of the CX neuropils in the FlyCircuit dataset. The innervation pattern of each neuron was obtained from <xref ref-type="bibr" rid="bib49">Lin et al., 2013</xref> and visually examined in the NeuroNLP window. Based on the assumptions made for each model, a standard name was assigned to the model of the neuron according to the naming scheme adopted in the CXcircuits Library. The neurons with missing morphologies in the FlyCircuit dataset were augmented with the data available in the literature (<xref ref-type="bibr" rid="bib88">Wolff et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Lin et al., 2013</xref>).</p><p>This all encompassing circuit diagram was then adapted to the other models. Since the assumptions about the subregions that neurons receive inputs from and output to are different in each circuit model, slightly different names may be assigned to neurons in different circuit models. The complete list of modeled neurons of the three models are provided in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> ‘CX_models.xlsx’, along with their corresponding neurons in the FlyCircuit dataset. The CXcircuits Library also uses this list to enable synchronization of the neurons visualized in the NeuroNLP window with the neurons represented in the NeuroGFX window.</p><p>All three models include the same core subcircuits for modeling the Protocerebral Bridge - Ellipsoid Body (PB-EB) interaction. The core subcircuits include three cell types, namely, the PB-EB-LAL, PB-EB-NO, and EB-LAL-PB neurons (NO - Noduli, LAL - Lateral Accessory Lobe, see also <xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref> for a list of synonyms of each neuron class). These cells innervate three neuropils, either PB, EB and LAL or PB, EB, and NO. Note that only synapses within PB and EB are considered. For model A, this is achieved by removing all neurons that do not belong to the core PB-EB circuit. This can be directly performed on the circuit diagram in the NeuroGFX window or by using the CXcircuits API. Model B includes an additional cell type, the PB local neurons that introduce global inhibition to the PB-EB circuit. Model C does not include PB local neurons, but models 3 types of ring neurons that innervate the EB. Both PB local neurons and ring neurons are present in model A. However, except for their receptive fields, all ring neurons in model A are the same (see below). <xref ref-type="fig" rid="fig9">Figure 9</xref> depicts the correspondence established between the morphology of example neurons and their respective representation in the overall circuit diagram.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>The correspondence between the morphology and the circuit diagram representation of 5 classes of neurons that determine the PB-EB interaction.</title><p>(<bold>a1, a2</bold>) EB-LAL-PB neuron and its wiring in the circuit diagram. (<bold>b1, b2</bold>) PB-EB-LAL neuron and its wiring in the circuit diagram. (<bold>c1, c2</bold>) PB-EB-NO neuron and its wiring in the circuit diagram. (<bold>d1, d2</bold>) PB local neuron and its wiring in the circuit diagram. (<bold>e1, e2</bold>) Ring neuron and its wiring in the circuit diagram.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-fig9-v2.tif"/></fig><p>In Model C, the subcircuit consisting of the PB-EB-LAL and EB-LAL-PB neurons was claimed to give rise to the persistent bump activity while the interconnect between PB-EB-NO and EB-LAL-PB allowed the bump to shift in darkness. To better compare with the other two models that did not model the shift in darkness, PB-EB-NO neurons were interactively disabled from the diagram.</p><p>For a single vertical bar presented to the fly at the position shown in <xref ref-type="fig" rid="fig6">Figure 6 (d1)</xref> (see also the flattened visual input in <xref ref-type="fig" rid="fig6">Figure 6 (d2)</xref>, the PB glomeruli or the EB wedges innervated by neurons of each of the three circuit models that receive injected current or external spike inputs are, respectively, highlighted in <xref ref-type="fig" rid="fig6">Figure 6 (a3, b3, c3)</xref>. The CXcircuit Library generates a set of visual stimuli and computes the spike train and/or the injected current inputs to each of the three models.</p><p>For model A (<xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref>), each PB glomerulus is endowed with a rectangular receptive field that covers 20° in azimuth and the entire elevation. Together, the receptive fields of all PB glomeruli tile the 360° azimuth. All PB neurons with dendrites in a glomerulus, including the PB-EB-LAL and PB-EB-NO neurons, receive the visual stimulus filtered by the receptive field as an injected current. Additionally, each Bulb (BU) microglomerulus is endowed with a Gaussian receptive field with a standard deviation of 9° in both azimuth and elevation. The ring neuron innervating a microglomerulus receives the filtered visual stimulus as an injected current (see also the arrows in <xref ref-type="fig" rid="fig6">Figure 6 (a3)</xref>). Neuron dynamics follow the Leaky Integrate-and-Fire (LIF) neuron model<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf8"><mml:msup><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the membrane voltage of the <inline-formula><mml:math id="inf9"><mml:mi>i</mml:mi></mml:math></inline-formula> th neuron, <inline-formula><mml:math id="inf10"><mml:msup><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the membrane capacitance, <inline-formula><mml:math id="inf11"><mml:msubsup><mml:mi>V</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> is the resting potential, <inline-formula><mml:math id="inf12"><mml:msup><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the resistance, and <inline-formula><mml:math id="inf13"><mml:msup><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the synaptic current. Upon reaching the threshold voltage <inline-formula><mml:math id="inf14"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula>, each neuron’s, membrane voltage is reset to <inline-formula><mml:math id="inf15"><mml:msubsup><mml:mi>V</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula>. Synapses are modeled as <inline-formula><mml:math id="inf16"><mml:mi>α</mml:mi></mml:math></inline-formula>-synapses with dynamics given by the differential equations<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mover><mml:mi>g</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf17"><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is a scaling factor, <inline-formula><mml:math id="inf18"><mml:msubsup><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf19"><mml:msubsup><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> are, respectively, the rise and decay time of the synapse, <inline-formula><mml:math id="inf20"><mml:mrow><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the Heaviside function and <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the Dirac function. <inline-formula><mml:math id="inf22"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> indicates an input spike to the <inline-formula><mml:math id="inf23"><mml:mi>i</mml:mi></mml:math></inline-formula> th synapse at time <inline-formula><mml:math id="inf24"><mml:msubsup><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula>.</p><p>For Model B (<xref ref-type="bibr" rid="bib36">Kakaria and de Bivort, 2017</xref>), the receptive field of each of the 16 EB wedges covers 22.5° in azimuth. All EB-LAL-PB neurons that innervate a wedge receive a spike train input whose rate is proportional to the filtered visual stimulus (see also arrow in <xref ref-type="fig" rid="fig6">Figure 6 (b3)</xref>). The maximum input spike rate is 120 Hz when the visual stimulus is a bar of width 20° at maximum brightness 1. A 5 Hz background firing is always added even in darkness. Neurons are modeled as LIF with a refractory period of 2.2 ms as suggested in <xref ref-type="bibr" rid="bib36">Kakaria and de Bivort, 2017</xref>. For synapses, instead of using the postsynaptic current (PSC)-based model described in <xref ref-type="bibr" rid="bib36">Kakaria and de Bivort, 2017</xref>, the <inline-formula><mml:math id="inf25"><mml:mi>α</mml:mi></mml:math></inline-formula>-synapse described above was used and its parameters were chosen such that the time-to-peak and peak value approximately matched that of the PSC-based synapse.</p><p>For Model C (<xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>), the receptive field of each of the 16 EB wedges covers 22.5° in azimuth. Two PB-EB-LAL neurons project to a wedge each from a different PB glomerulus. Input to the Model C circuit is presented to pairs of PB glomeruli (see also arrows in <xref ref-type="fig" rid="fig6">Figure 6 (c3)</xref>), and all neurons with dendrites in these two PB glomeruli receive a spike train input at a rate proportional to the filtered visual stimuli, with a maximum 50 Hz when the bar is at maximum brightness 1. Neurons are modeled as LIF neurons with a refractory period of 2 ms (as suggested in <xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>). Synapses are either modeled by the AMPA/GABAA receptor dynamics as<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mover><mml:mi>g</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mfrac><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf26"><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the synaptic conductance, <inline-formula><mml:math id="inf27"><mml:msup><mml:mi>τ</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the time constant, and <inline-formula><mml:math id="inf28"><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the state variable of the <inline-formula><mml:math id="inf29"><mml:mi>i</mml:mi></mml:math></inline-formula> th synapse, or modeled by the NMDA receptor dynamics (<xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>)<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mover><mml:mi>g</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>0.062</mml:mn><mml:mi>V</mml:mi></mml:mrow><mml:mn>3.56</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mfrac><mml:mo>+</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf30"><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the synaptic conductance, <inline-formula><mml:math id="inf31"><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the maximum conductance, <inline-formula><mml:math id="inf32"><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the state variable, <inline-formula><mml:math id="inf33"><mml:msup><mml:mi>τ</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the time constant, <inline-formula><mml:math id="inf34"><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is a constant, <inline-formula><mml:math id="inf35"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is the extracellular concentration of <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, respectively, of the <inline-formula><mml:math id="inf37"><mml:mi>i</mml:mi></mml:math></inline-formula> th synapse and <inline-formula><mml:math id="inf38"><mml:mi>V</mml:mi></mml:math></inline-formula> is the membrane voltage of the postsynaptic neuron.</p><p>Parameters of the above models can be found in <xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Kakaria and de Bivort, 2017</xref>; <xref ref-type="bibr" rid="bib78">Su et al., 2017</xref> and in the CXcircuit Library.</p><p>Commonly used models, such as the LIF neuron and the α-synapse, are built-into the Neurokernel Execution Engine. Only the model parameters residing in the NeuroArch Database need to be specified via NeuroArch API. The Neurokernel automatically retrieves the circuit models and their parameters from the NeuroArch Database based on the last queried circuit model. For models that are not yet built-into the Neurokernel Execution Engine, such as the PSC-based model in Model B, users must provide an implementation supported by the Neurodriver API.</p><p>The 35 s visual stimulus, depicted in <xref ref-type="fig" rid="fig6">Figure 6 (d3)</xref>, was presented to all three models. A bright vertical bar moves back and forth across the entire visual field while a second bar with lower brightness is presented at a fixed position. <xref ref-type="fig" rid="fig6">Figure 6 (d3)</xref> (bottom) depicts the time evolution of the visual input.</p><p>To visualize the response of the three executable circuits, the mean firing rate <inline-formula><mml:math id="inf39"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of all EB-LAL-PB neurons that innervate the <inline-formula><mml:math id="inf40"><mml:mi>j</mml:mi></mml:math></inline-formula> th EB wedge was calculated following <xref ref-type="bibr" rid="bib78">Su et al., 2017</xref>.<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mn>0.7215</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where ∗ denotes the convolution operator, <inline-formula><mml:math id="inf41"><mml:msup><mml:mi>?</mml:mi><mml:mi>j</mml:mi></mml:msup></mml:math></inline-formula> is the index set of EB-LAL-PB neurons that innervate the <inline-formula><mml:math id="inf42"><mml:mi>j</mml:mi></mml:math></inline-formula> th EB wedge, whose cardinality is <inline-formula><mml:math id="inf43"><mml:msup><mml:mi>N</mml:mi><mml:mi>j</mml:mi></mml:msup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf44"><mml:msubsup><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> is the time of <italic>k</italic>th spike generated by <italic>i</italic>th neuron. CXcircuit Library provides utilities to visualize the circuit response.</p><p>Jupyter notebooks for Models A, B and C used to generate <xref ref-type="video" rid="video1">Video 1</xref> are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/CXcircuits/tree/master/notebooks/elife20">https://github.com/FlyBrainLab/CXcircuits/tree/master/notebooks/elife20</ext-link>.</p></sec><sec id="s4-9"><title>Use Case 5: analyzing, evaluating, and comparing adult antenna and antennal lobe circuit models based upon the FlyCircuit and hemibrain datasets</title><p>The Early Olfactory System models based on the FlyCircuit and the Hemibrain datasets were implemented using the EOScircuits Library (see also Appendix 3). The circuit architecture, shown in <xref ref-type="fig" rid="fig7">Figure 7b</xref> (left), follows previous work (<xref ref-type="bibr" rid="bib43">Lazar et al., 2020a</xref>) based upon the inferred connectivity between LNs and PNs in the FlyCircuit dataset and the functional connectivity between LNs and OSNs observed in experiments (<xref ref-type="bibr" rid="bib60">Olsen and Wilson, 2008</xref>) (see also <xref ref-type="fig" rid="fig7">Figure 7a</xref> (left)). Specifically, LNs are separated into two groups: a group of presynaptically-acting LNs assumed to receive inputs from all OSNs and to project to the axon terminals of each of the OSNs; another group of postsynaptically acting LNs assumed to receive inputs from all OSNs and to provide inputs to the PNs that arborize the same glomerulus. Only uniglomerular PNs are modeled and their characterization is limited to their connectivity. For the Hemibrain dataset, the exact local neurons and their connectivity within the AL circuit are used. Specifically, LNs are divided into presynaptically acting and postsynaptically acting ones based on the number of synaptic contacts onto OSNs and PNs, respectively. If the majority of synapses of an LN is targeting OSNs, it is modeled as a presynaptically acting LN. Otherwise, it is modeled as a postsynaptically acting LN. Note that the connectivity pattern in the circuit model based on FlyCircuit dataset is inferred (<xref ref-type="bibr" rid="bib43">Lazar et al., 2020a</xref>). whereas in the circuit model based on Hemibrain dataset is extracted from the data.</p><p>At the input layer (the Antenna Circuit), the stimulus model for the adult EOS circuit builds upon affinity data from the DoOR dataset (<xref ref-type="bibr" rid="bib57">Münch and Galizia, 2016</xref>), with physiological recordings for 23/51 receptor types. Receptors for which there is no affinity data in the DoOR dataset were assumed to have zero affinity values. Two input stimuli were used. The initial input stimulus was 5 s long; between 1 and 3 s, ammonium hydroxide with a constant concentration of 100 ppm was presented to the circuits in <xref ref-type="fig" rid="fig7">Figure 7b</xref> and the responses are shown in (<xref ref-type="fig" rid="fig7">Figure 7c</xref>). The same odorant waveform was used here as in <xref ref-type="fig" rid="fig7">Figure 7d</xref>. To generate the concentration waveform of the odorant, values were drawn randomly from the uniform distribution between 0 and 100 ppm every 10<sup>−4</sup> seconds between 1 and 3 s in <xref ref-type="fig" rid="fig7">Figure 7d</xref>. The sequence was then filtered by a lowpass filter with a 30 Hz bandwidth (<xref ref-type="bibr" rid="bib37">Kim et al., 2011</xref>) to obtain the concentration of the odorant.</p><p>Olfactory Sensory Neurons expressing each one receptor type processed the input odorant in parallel. The Antennal Lobe model based on FlyCircuit data is divided into two sub-circuits: (1) the ON-OFF circuit and (2) the Predictive Coding circuit (<xref ref-type="bibr" rid="bib45">Lazar and Yeh, 2019</xref>). The ON-OFF circuit describes odorant gradient encoding by Post-synaptic LNs in the AL, while the Predictive Coding circuit describes a divisive normalization mechanism by Pre-synaptic LNs that enable concentration-invariant odorant identity encoding by Projection Neurons in the AL.</p><p>The EOS model based on Hemibrain dataset takes advantage of the detailed connectivity between neurons (see <xref ref-type="fig" rid="fig7">Figure 7a</xref> (right)) and introduces a more extensive connectome-synaptome model of the AL (see <xref ref-type="fig" rid="fig7">Figure 7b </xref>(right)). FlyBrainLab utility libraries were used to (1) access the Hemibrain data, (2) find PNs and group them by glomeruli, (3) use this data to find the OSNs associated with each glomerulus, (4) find LNs and group connectivity between OSNs, LNs and PNs. Multiglomerular PNs were not included. Contralateral LN connections were ignored. All PNs were assumed to be excitatory. An executable circuit was constructed in FlyBrainLab using the Hemibrain data. In addition to the baseline model in <xref ref-type="fig" rid="fig7">Figure 7b </xref>(left), the following components were introduced (1) LNs that innervate specific subsets of glomeruli, (2) LNs that provide inputs to both OSN axon terminals and to PNs dendrites, (3) synapses from PNs onto LNs.</p></sec><sec id="s4-10"><title>Use Case 6: evaluating, analyzing, and comparing early Olfactory circuit models of the larva and the adult fruit flies</title><p>The Early Olfactory System models for both the adult and the larval flies were implemented using the EOScircuits library (see also Appendix 3). The circuit of the adult EOS follows the one described above. Similarly, the larval model is implemented using physiological recording on 14/21 receptor types (<xref ref-type="bibr" rid="bib40">Kreher et al., 2005</xref>). In both the adult and larval physiology datasets, 13 common mono-molecular odorants were employed (see <xref ref-type="fig" rid="fig8">Figure 8c</xref> (legend)). Together, 13/23 odorant/receptor pairs for adult and 13/14 odorant/receptor pairs for larva were used for model evaluation, where each odorant was carried by a 100 ppm concentration waveform. In both adult and larva Antenna circuits, Olfactory Sensory Neurons expressing each receptor type processed an odorant waveform in parallel.</p><p>The adult Antennal Lobe model follows the one built on the Hemibrain data (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>). Both the adult and the larva circuit components are parameterized by the number of LNs per type, where for instance there were 28 LNs used in the larval model in accordance to connectome data (<xref ref-type="bibr" rid="bib6">Berck et al., 2016</xref>). In addition to neuron types, the AL circuit was modified in terms of connectivity from (1) LNs to Projection Neurons (PNs), (2) PNs to LNs and (3) LNs to LNs. Refer to <xref ref-type="table" rid="table1">Table 1</xref> for more details.</p><p>The evaluation of both EOS models focused on the Input/Output relationship comparison between the adult and the larval EOS models. For each of the 13 odorants, the input stimulus is a 5 s concentration waveform that is 100 ppm from 1 to 4 s and 0 ppm otherwise. Both adult and larval models reach steady-state after 500 ms and the steady-state population responses averaged across 3–4 s are computed as odorant combinatorial code at each layer (i.e. OSN response, PN response).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Neurons and neuron types used for visualization and simulation in <xref ref-type="fig" rid="fig8">Figure 8</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Neuropil</th><th>Neuron Type</th><th>Organism</th><th>Number (Model in <xref ref-type="fig" rid="fig8">Figure 8b</xref>)</th><th>Number (Visualization in <xref ref-type="fig" rid="fig8">Figure 8a</xref>)</th></tr></thead><tbody><tr><td rowspan="2">Antenna</td><td rowspan="2">Olfactory Sensory Neuron</td><td>Adult</td><td>51 receptor types (channels), 1357 total olfactory sensory neurons</td><td>1357</td></tr><tr><td>Larva</td><td>14 receptor types (channels), 1 neuron expressing the same receptor type (14 neurons in total)</td><td>21</td></tr><tr><td rowspan="8">Antennal Lobe</td><td rowspan="2">Uniglomerular Projection Neuron</td><td>Adult</td><td>1 neuron per channel, 51 total</td><td>141 (Different number per glomerulus)</td></tr><tr><td>Larva</td><td>1 neuron per channel (14 neurons in total)</td><td>21</td></tr><tr><td rowspan="2">Presynaptic Local Neuron</td><td>Adult</td><td>97 neurons</td><td>97</td></tr><tr><td>Larva</td><td>6 pan-glomerular neurons</td><td>5</td></tr><tr><td rowspan="2">Postsynaptic Inhibitory Local Neuron</td><td>Adult</td><td>77 neurons</td><td>77</td></tr><tr><td>Larva</td><td>0-1 neuron per channel (11 neurons in total)</td><td>7</td></tr><tr><td rowspan="2">Postsynaptic Excitatory Local Neuron</td><td>Adult</td><td>77 (assumed to be the same as the Postsynaptic Inhibitory Local Neuron population)</td><td>77</td></tr><tr><td>Larva</td><td>0-1 neuron per channel (11 neurons in total)</td><td>7</td></tr></tbody></table></table-wrap></sec><sec id="s4-11"><title>Code availability and installation</title><p>Stable and tested FlyBrainLab installation instructions for user-side components and utility libraries are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab">https://github.com/FlyBrainLab/FlyBrainLab</ext-link> for Linux, MacOS, and Windows. The installation and use of FlyBrainLab does not require a GPU, but a service-side backend must be running, for example, on a cloud service, that the user-side of FlyBrainLab can connect to. By default, the user-side-only installation will access the backend services hosted on our public servers. Note that users do not have write permission to the NeuroArch Database, nor will they be able to access a Neurokernel Server for execution. The server-side backend codebase is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/fruitflybrain">https://github.com/fruitflybrain</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/neurokernel">https://github.com/neurokernel</ext-link>.</p><p>A full installation of FlyBrainLab, including all backend and frontend components, is available as a Docker image at <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/fruitflybrain/fbl">https://hub.docker.com/r/fruitflybrain/fbl</ext-link>. The image requires a Linux host with at least 1 CUDA-enabled GPU and the nvidia-docker package (<ext-link ext-link-type="uri" xlink:href="https://github.com/NVIDIA/nvidia-docker">https://github.com/NVIDIA/nvidia-docker</ext-link>) installed. For a custom installation of the complete FlyBrainLab platform, a shell script is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab">https://github.com/FlyBrainLab/FlyBrainLab</ext-link>.</p><p>To help users get started, a number of tutorials are available written as Jupyter notebooks at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/Tutorials">https://github.com/FlyBrainLab/Tutorials</ext-link>, including a reference to English queries at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/Tutorials/blob/master/tutorials/getting_started/1b_nlp_queries.ipynb">https://github.com/FlyBrainLab/Tutorials/blob/master/tutorials/getting_started/1b_nlp_queries.ipynb</ext-link>. An overview of the FlyBrainLab resources is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab/wiki/FlyBrainLab-Resources">https://github.com/FlyBrainLab/FlyBrainLab/wiki/FlyBrainLab-Resources</ext-link>.</p></sec><sec id="s4-12"><title>Data availability</title><p>The NeuroArch Database hosting publicly available FlyCircuit (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_006375">SCR_006375</ext-link>), Hemibrain, Medulla 7-column and Larva L1EM datasets can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/datasets">https://github.com/FlyBrainLab/datasets</ext-link>. The same repository provides Jupyter notebooks for loading publicly available datasets, such as the FlyCircuit dataset with inferred connectivity (<xref ref-type="bibr" rid="bib34">Huang et al., 2018</xref>), the Hemibrain dataset, the Medulla 7-column dataset and the Larva L1 EM dataset.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The research reported here was supported by AFOSR under grant #FA9550-16-1-0410 and DARPA under contract #HR0011-19-9-0035. The authors thank the reviewers for their constructive comments that significantly improved the presentation of the manuscript.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing - original draft, Project administration, Writing - review and editing, Conceived the study and FlyBrainLab software architecture. Developed comparative models of the central complex. Developed comparative models of the early olfactory system.</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing, Conceived the study and FlyBrainLab software architecture. Developed the FlyBrainLab platform. Developed user-side libraries. Developed comparative models of the early olfactory system.</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing, Conceived the study and FlyBrainLab software architecture. Developed the FlyBrainLab platform. Developed user-side libraries and utility libraries. Developed comparative models of the central complex. Developed comparative models of the early olfactory system.</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing, Conceived the study and FlyBrainLab software architecture. Developed the FlyBrainLab platform. Updated the server-side components of the existing FFBO architecture. Developed comparative models of the central complex.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Full list of neurons used in the three CX models in Use Case 4 and their correspondence in the FlyCircuit dataset.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-62362-supp1-v2.xlsx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-62362-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>General information about the FlyBrainLab is available at <ext-link ext-link-type="uri" xlink:href="https://www.fruitflybrain.org">https://www.fruitflybrain.org</ext-link>. Stable and tested FlyBrainLab installation instructions are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab">https://github.com/FlyBrainLab/FlyBrainLab</ext-link>. An overview of the FlyBrainLab resources can be found at the FlyBrainLab Resource wiki page at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab/wiki/FlyBrainLab-Resources">https://github.com/FlyBrainLab/FlyBrainLab/wiki/FlyBrainLab-Resources</ext-link>. It includes links to individual code repositories for components, libraries and tutorials. The NeuroArch Database hosting publicly available FlyCircuit, Hemibrain, Medulla 7-column and Larva L1EM datasets can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/datasets">https://github.com/FlyBrainLab/datasets</ext-link>. The same repository provides Jupyter notebooks for loading publicly available datasets, such as the FlyCircuit dataset with inferred connectivity, the Hemibrain dataset, the Medulla 7-column dataset and the Larva L1 EM dataset.</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>AS</given-names></name><name><surname>et</surname><given-names>al.</given-names></name></person-group><year iso-8601-date="2011">2011</year><data-title>FlyCircuit</data-title><source>FlyCircuit DB</source><pub-id assigning-authority="other" pub-id-type="doi">10.1016/j.cub.2010.11.056</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Ohyama</surname><given-names>T</given-names></name><name><surname>et</surname><given-names>al.</given-names></name></person-group><year iso-8601-date="2015">2015</year><data-title>L1EM</data-title><source>CATMAID</source><pub-id assigning-authority="other" pub-id-type="doi">10.1038/nature14297</pub-id></element-citation></p><p><element-citation id="dataset3" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Scheffer</surname><given-names>LK</given-names></name><name><surname>et</surname><given-names>al.</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Hemibrain</data-title><source>neuPrint</source><pub-id assigning-authority="other" pub-id-type="doi">10.7554/eLife.57443</pub-id></element-citation></p><p><element-citation id="dataset4" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Takemura</surname><given-names>SY</given-names></name><name><surname>et</surname><given-names>al.</given-names></name></person-group><year iso-8601-date="2015">2015</year><data-title>Medulla 7 Column Data</data-title><source>github</source><pub-id assigning-authority="other" pub-id-type="doi">10.1073/pnas.1509820112</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Akar</surname> <given-names>NA</given-names></name><name><surname>Ben Cumming</surname> <given-names>VK</given-names></name><name><surname>Küsters</surname> <given-names>A</given-names></name><name><surname>Klijn</surname> <given-names>W</given-names></name><name><surname>Peyser</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Arbor - a morphologically-detailed neural network simulation library for contemporary high-performance computing architectures</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1901.07454">https://arxiv.org/abs/1901.07454</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aleksin</surname> <given-names>SG</given-names></name><name><surname>Zheng</surname> <given-names>K</given-names></name><name><surname>Rusakov</surname> <given-names>DA</given-names></name><name><surname>Savtchenko</surname> <given-names>LP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>ARACHNE: a neural-neuroglial network builder with remotely controlled parallel computing</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005467</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005467</pub-id><pub-id pub-id-type="pmid">28362877</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ascoli</surname> <given-names>GA</given-names></name><name><surname>Donohue</surname> <given-names>DE</given-names></name><name><surname>Halavi</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>NeuroMorpho.Org: a central resource for neuronal morphologies</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>9247</fpage><lpage>9251</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2055-07.2007</pub-id><pub-id pub-id-type="pmid">17728438</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Manton</surname> <given-names>JD</given-names></name><name><surname>Jagannathan</surname> <given-names>SR</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Rohlfing</surname> <given-names>T</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The Natverse, a versatile toolbox for combining and analysing neuroanatomical data</article-title><source>eLife</source><volume>9</volume><elocation-id>e53350</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.53350</pub-id><pub-id pub-id-type="pmid">32286229</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bekolay</surname> <given-names>T</given-names></name><name><surname>Bergstra</surname> <given-names>J</given-names></name><name><surname>Hunsberger</surname> <given-names>E</given-names></name><name><surname>Dewolf</surname> <given-names>T</given-names></name><name><surname>Stewart</surname> <given-names>TC</given-names></name><name><surname>Rasmussen</surname> <given-names>D</given-names></name><name><surname>Choo</surname> <given-names>X</given-names></name><name><surname>Voelker</surname> <given-names>AR</given-names></name><name><surname>Eliasmith</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Nengo: a Python tool for building large-scale functional brain models</article-title><source>Frontiers in Neuroinformatics</source><volume>7</volume><elocation-id>48</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2013.00048</pub-id><pub-id pub-id-type="pmid">24431999</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berck</surname> <given-names>ME</given-names></name><name><surname>Khandelwal</surname> <given-names>A</given-names></name><name><surname>Claus</surname> <given-names>L</given-names></name><name><surname>Hernandez-Nunez</surname> <given-names>L</given-names></name><name><surname>Si</surname> <given-names>G</given-names></name><name><surname>Tabone</surname> <given-names>CJ</given-names></name><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Truman</surname> <given-names>JW</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Louis</surname> <given-names>M</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The wiring diagram of a glomerular olfactory system</article-title><source>eLife</source><volume>5</volume><elocation-id>e14859</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.14859</pub-id><pub-id pub-id-type="pmid">27177418</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blondel</surname> <given-names>VD</given-names></name><name><surname>Guillaume</surname> <given-names>J-L</given-names></name><name><surname>Lambiotte</surname> <given-names>R</given-names></name><name><surname>Lefebvre</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Fast unfolding of communities in large networks</article-title><source>Journal of Statistical Mechanics: Theory and Experiment</source><volume>2008</volume><elocation-id>P10008</elocation-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantarelli</surname> <given-names>M</given-names></name><name><surname>Marin</surname> <given-names>B</given-names></name><name><surname>Quintana</surname> <given-names>A</given-names></name><name><surname>Earnshaw</surname> <given-names>M</given-names></name><name><surname>Court</surname> <given-names>R</given-names></name><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name><name><surname>Idili</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Geppetto: a reusable modular open platform for exploring neuroscience data and models</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>373</volume><elocation-id>20170380</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2017.0380</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname> <given-names>AS</given-names></name><name><surname>Lin</surname> <given-names>CY</given-names></name><name><surname>Chuang</surname> <given-names>CC</given-names></name><name><surname>Chang</surname> <given-names>HM</given-names></name><name><surname>Hsieh</surname> <given-names>CH</given-names></name><name><surname>Yeh</surname> <given-names>CW</given-names></name><name><surname>Shih</surname> <given-names>CT</given-names></name><name><surname>Wu</surname> <given-names>JJ</given-names></name><name><surname>Wang</surname> <given-names>GT</given-names></name><name><surname>Chen</surname> <given-names>YC</given-names></name><name><surname>Wu</surname> <given-names>CC</given-names></name><name><surname>Chen</surname> <given-names>GY</given-names></name><name><surname>Ching</surname> <given-names>YT</given-names></name><name><surname>Lee</surname> <given-names>PC</given-names></name><name><surname>Lin</surname> <given-names>CY</given-names></name><name><surname>Lin</surname> <given-names>HH</given-names></name><name><surname>Wu</surname> <given-names>CC</given-names></name><name><surname>Hsu</surname> <given-names>HW</given-names></name><name><surname>Huang</surname> <given-names>YA</given-names></name><name><surname>Chen</surname> <given-names>JY</given-names></name><name><surname>Chiang</surname> <given-names>HJ</given-names></name><name><surname>Lu</surname> <given-names>CF</given-names></name><name><surname>Ni</surname> <given-names>RF</given-names></name><name><surname>Yeh</surname> <given-names>CY</given-names></name><name><surname>Hwang</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Three-dimensional reconstruction of brain-wide wiring networks in <italic>Drosophila</italic> at single-cell resolution</article-title><source>Current Biology</source><volume>21</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.11.056</pub-id><pub-id pub-id-type="pmid">21129968</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Clements</surname> <given-names>J</given-names></name><name><surname>Dolafi</surname> <given-names>T</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Neubarth</surname> <given-names>NL</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>neuPrint: analysis tools for EM connectomics</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.16.909465</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crook</surname> <given-names>S</given-names></name><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Howell</surname> <given-names>F</given-names></name><name><surname>Svitak</surname> <given-names>J</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>MorphML: level 1 of the NeuroML standards for neuronal morphology data and model specification</article-title><source>Neuroinformatics</source><volume>5</volume><fpage>96</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1007/s12021-007-0003-6</pub-id><pub-id pub-id-type="pmid">17873371</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dai</surname> <given-names>K</given-names></name><name><surname>Gratiy</surname> <given-names>SL</given-names></name><name><surname>Billeh</surname> <given-names>YN</given-names></name><name><surname>Xu</surname> <given-names>R</given-names></name><name><surname>Cai</surname> <given-names>B</given-names></name><name><surname>Cain</surname> <given-names>N</given-names></name><name><surname>Rimehaug</surname> <given-names>AE</given-names></name><name><surname>Stasik</surname> <given-names>AJ</given-names></name><name><surname>Einevoll</surname> <given-names>GT</given-names></name><name><surname>Mihalas</surname> <given-names>S</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Arkhipov</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>Brain modeling ToolKit: an open source software suite for multiscale modeling of brain circuits</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008386</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008386</pub-id><pub-id pub-id-type="pmid">33253147</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dai</surname> <given-names>K</given-names></name><name><surname>Hernando</surname> <given-names>J</given-names></name><name><surname>Billeh</surname> <given-names>YN</given-names></name><name><surname>Gratiy</surname> <given-names>SL</given-names></name><name><surname>Planas</surname> <given-names>J</given-names></name><name><surname>Davison</surname> <given-names>AP</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Devresse</surname> <given-names>A</given-names></name><name><surname>Dichter</surname> <given-names>BK</given-names></name><name><surname>Gevaert</surname> <given-names>M</given-names></name><name><surname>King</surname> <given-names>JG</given-names></name><name><surname>Van Geit</surname> <given-names>WAH</given-names></name><name><surname>Povolotsky</surname> <given-names>AV</given-names></name><name><surname>Muller</surname> <given-names>E</given-names></name><name><surname>Courcol</surname> <given-names>JD</given-names></name><name><surname>Arkhipov</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>The SONATA data format for efficient description of large-scale network models</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007696</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007696</pub-id><pub-id pub-id-type="pmid">32092054</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname> <given-names>FP</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Picard</surname> <given-names>S</given-names></name><name><surname>Reiser</surname> <given-names>MB</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Eddy</surname> <given-names>SR</given-names></name><name><surname>Henry</surname> <given-names>GL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A genetic, genomic, and computational resource for exploring neural circuit function</article-title><source>eLife</source><volume>9</volume><elocation-id>e50901</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.50901</pub-id><pub-id pub-id-type="pmid">31939737</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davison</surname> <given-names>AP</given-names></name><name><surname>Brüderle</surname> <given-names>D</given-names></name><name><surname>Eppler</surname> <given-names>J</given-names></name><name><surname>Kremkow</surname> <given-names>J</given-names></name><name><surname>Muller</surname> <given-names>E</given-names></name><name><surname>Pecevski</surname> <given-names>D</given-names></name><name><surname>Perrinet</surname> <given-names>L</given-names></name><name><surname>Yger</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>PyNN: a common interface for neuronal network simulators</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>11</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.011.2008</pub-id><pub-id pub-id-type="pmid">19194529</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vries</surname> <given-names>SEJ</given-names></name><name><surname>Lecoq</surname> <given-names>JA</given-names></name><name><surname>Buice</surname> <given-names>MA</given-names></name><name><surname>Groblewski</surname> <given-names>PA</given-names></name><name><surname>Ocker</surname> <given-names>GK</given-names></name><name><surname>Oliver</surname> <given-names>M</given-names></name><name><surname>Feng</surname> <given-names>D</given-names></name><name><surname>Cain</surname> <given-names>N</given-names></name><name><surname>Ledochowitsch</surname> <given-names>P</given-names></name><name><surname>Millman</surname> <given-names>D</given-names></name><name><surname>Roll</surname> <given-names>K</given-names></name><name><surname>Garrett</surname> <given-names>M</given-names></name><name><surname>Keenan</surname> <given-names>T</given-names></name><name><surname>Kuan</surname> <given-names>L</given-names></name><name><surname>Mihalas</surname> <given-names>S</given-names></name><name><surname>Olsen</surname> <given-names>S</given-names></name><name><surname>Thompson</surname> <given-names>C</given-names></name><name><surname>Wakeman</surname> <given-names>W</given-names></name><name><surname>Waters</surname> <given-names>J</given-names></name><name><surname>Williams</surname> <given-names>D</given-names></name><name><surname>Barber</surname> <given-names>C</given-names></name><name><surname>Berbesque</surname> <given-names>N</given-names></name><name><surname>Blanchard</surname> <given-names>B</given-names></name><name><surname>Bowles</surname> <given-names>N</given-names></name><name><surname>Caldejon</surname> <given-names>SD</given-names></name><name><surname>Casal</surname> <given-names>L</given-names></name><name><surname>Cho</surname> <given-names>A</given-names></name><name><surname>Cross</surname> <given-names>S</given-names></name><name><surname>Dang</surname> <given-names>C</given-names></name><name><surname>Dolbeare</surname> <given-names>T</given-names></name><name><surname>Edwards</surname> <given-names>M</given-names></name><name><surname>Galbraith</surname> <given-names>J</given-names></name><name><surname>Gaudreault</surname> <given-names>N</given-names></name><name><surname>Gilbert</surname> <given-names>TL</given-names></name><name><surname>Griffin</surname> <given-names>F</given-names></name><name><surname>Hargrave</surname> <given-names>P</given-names></name><name><surname>Howard</surname> <given-names>R</given-names></name><name><surname>Huang</surname> <given-names>L</given-names></name><name><surname>Jewell</surname> <given-names>S</given-names></name><name><surname>Keller</surname> <given-names>N</given-names></name><name><surname>Knoblich</surname> <given-names>U</given-names></name><name><surname>Larkin</surname> <given-names>JD</given-names></name><name><surname>Larsen</surname> <given-names>R</given-names></name><name><surname>Lau</surname> <given-names>C</given-names></name><name><surname>Lee</surname> <given-names>E</given-names></name><name><surname>Lee</surname> <given-names>F</given-names></name><name><surname>Leon</surname> <given-names>A</given-names></name><name><surname>Li</surname> <given-names>L</given-names></name><name><surname>Long</surname> <given-names>F</given-names></name><name><surname>Luviano</surname> <given-names>J</given-names></name><name><surname>Mace</surname> <given-names>K</given-names></name><name><surname>Nguyen</surname> <given-names>T</given-names></name><name><surname>Perkins</surname> <given-names>J</given-names></name><name><surname>Robertson</surname> <given-names>M</given-names></name><name><surname>Seid</surname> <given-names>S</given-names></name><name><surname>Shea-Brown</surname> <given-names>E</given-names></name><name><surname>Shi</surname> <given-names>J</given-names></name><name><surname>Sjoquist</surname> <given-names>N</given-names></name><name><surname>Slaughterbeck</surname> <given-names>C</given-names></name><name><surname>Sullivan</surname> <given-names>D</given-names></name><name><surname>Valenza</surname> <given-names>R</given-names></name><name><surname>White</surname> <given-names>C</given-names></name><name><surname>Williford</surname> <given-names>A</given-names></name><name><surname>Witten</surname> <given-names>DM</given-names></name><name><surname>Zhuang</surname> <given-names>J</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name><name><surname>Farrell</surname> <given-names>C</given-names></name><name><surname>Ng</surname> <given-names>L</given-names></name><name><surname>Bernard</surname> <given-names>A</given-names></name><name><surname>Phillips</surname> <given-names>JW</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A large-scale standardized physiological survey reveals functional organization of the mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>138</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0550-9</pub-id><pub-id pub-id-type="pmid">31844315</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dorkenwald</surname> <given-names>S</given-names></name><name><surname>McKellar</surname> <given-names>C</given-names></name><name><surname>Macrina</surname> <given-names>T</given-names></name><name><surname>Kemnitz</surname> <given-names>N</given-names></name><name><surname>Lee</surname> <given-names>K</given-names></name><name><surname>Lu</surname> <given-names>R</given-names></name><name><surname>Wu</surname> <given-names>J</given-names></name><name><surname>Popovych</surname> <given-names>S</given-names></name><name><surname>Mitchell</surname> <given-names>E</given-names></name><name><surname>Nehoran</surname> <given-names>B</given-names></name><name><surname>Jia</surname> <given-names>Z</given-names></name><name><surname>Alexander Bae</surname> <given-names>J</given-names></name><name><surname>Mu</surname> <given-names>S</given-names></name><name><surname>Ih</surname> <given-names>D</given-names></name><name><surname>Castro</surname> <given-names>M</given-names></name><name><surname>Ogedengbe</surname> <given-names>O</given-names></name><name><surname>Halageri</surname> <given-names>A</given-names></name><name><surname>Ashwood</surname> <given-names>Z</given-names></name><name><surname>Zung</surname> <given-names>J</given-names></name><name><surname>Brittain</surname> <given-names>D</given-names></name><name><surname>Collman</surname> <given-names>F</given-names></name><name><surname>Schneider-Mizell</surname> <given-names>C</given-names></name><name><surname>Jordan</surname> <given-names>C</given-names></name><name><surname>Silversmith</surname> <given-names>W</given-names></name><name><surname>Baker</surname> <given-names>C</given-names></name><name><surname>Deutsch</surname> <given-names>D</given-names></name><name><surname>Encarnacion-Rivera</surname> <given-names>L</given-names></name><name><surname>Kumar</surname> <given-names>S</given-names></name><name><surname>Burke</surname> <given-names>A</given-names></name><name><surname>Gager</surname> <given-names>J</given-names></name><name><surname>Hebditch</surname> <given-names>J</given-names></name><name><surname>Koolman</surname> <given-names>S</given-names></name><name><surname>Moore</surname> <given-names>M</given-names></name><name><surname>Morejohn</surname> <given-names>S</given-names></name><name><surname>Ben Silverman</surname> <given-names>KW</given-names></name><name><surname>Willie</surname> <given-names>R</given-names></name><name><surname>Yu</surname> <given-names>SC</given-names></name><name><surname>Murthy</surname> <given-names>M</given-names></name><name><surname>Sebastian Seung</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>FlyWire: online community for whole-brain connectomics</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.08.30.274225</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Suter</surname> <given-names>BA</given-names></name><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Cantarelli</surname> <given-names>M</given-names></name><name><surname>Quintana</surname> <given-names>A</given-names></name><name><surname>Rodriguez</surname> <given-names>F</given-names></name><name><surname>Kedziora</surname> <given-names>DJ</given-names></name><name><surname>Chadderdon</surname> <given-names>GL</given-names></name><name><surname>Kerr</surname> <given-names>CC</given-names></name><name><surname>Neymotin</surname> <given-names>SA</given-names></name><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Hines</surname> <given-names>M</given-names></name><name><surname>Shepherd</surname> <given-names>GM</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>NetPyNE, a tool for data-driven multiscale modeling of brain circuits</article-title><source>eLife</source><volume>8</volume><elocation-id>e44494</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.44494</pub-id><pub-id pub-id-type="pmid">31025934</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Einevoll</surname> <given-names>GT</given-names></name><name><surname>Destexhe</surname> <given-names>A</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name><name><surname>Grün</surname> <given-names>S</given-names></name><name><surname>Jirsa</surname> <given-names>V</given-names></name><name><surname>de Kamps</surname> <given-names>M</given-names></name><name><surname>Migliore</surname> <given-names>M</given-names></name><name><surname>Ness</surname> <given-names>TV</given-names></name><name><surname>Plesser</surname> <given-names>HE</given-names></name><name><surname>Schürmann</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The scientific case for brain simulations</article-title><source>Neuron</source><volume>102</volume><fpage>735</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.03.027</pub-id><pub-id pub-id-type="pmid">31121126</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ellson</surname> <given-names>J</given-names></name><name><surname>Gansner</surname> <given-names>E</given-names></name><name><surname>Koutsofios</surname> <given-names>L</given-names></name><name><surname>North</surname> <given-names>SC</given-names></name><name><surname>Woodhull</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2001">2001</year><chapter-title>Graphviz—open source graph drawing tools</chapter-title><source>International Symposium on Graph Drawing</source><publisher-name>Springer</publisher-name><fpage>pages 483</fpage><lpage>484</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischbach</surname> <given-names>K-F</given-names></name><name><surname>Dittrich</surname> <given-names>APM</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The optic lobe of <italic>Drosophila melanogaster</italic>. I. A Golgi analysis of wild-type structure</article-title><source>Cell and Tissue Research</source><volume>258</volume><fpage>441</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.1007/BF00218858</pub-id><pub-id pub-id-type="pmid">6187612</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gewaltig</surname> <given-names>M-O</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>NEST (NEural simulation tool)</article-title><source>Scholarpedia</source><volume>2</volume><elocation-id>1430</elocation-id><pub-id pub-id-type="doi">10.4249/scholarpedia.1430</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Givon</surname> <given-names>LE</given-names></name><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Ukani</surname> <given-names>NH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neuroarch: a graph-based platform for constructing and querying models of the fruit fly brain architecture</article-title><source>Frontiers in Neuroinformatics</source><volume>8</volume><elocation-id>e00042</elocation-id><pub-id pub-id-type="doi">10.3389/conf.fninf.2014.18.00042</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Givon</surname> <given-names>LE</given-names></name><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Ukani</surname> <given-names>NH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuroarch: a graph db for querying and executing fruit fly brain circuits</article-title><source>Neurokernel Request for Comments, Neurokernel RFC #</source><volume>5</volume><pub-id pub-id-type="doi">10.5281/zenodo.44225</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Givon</surname> <given-names>LE</given-names></name><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Yeh</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Generating executable models of the <italic>Drosophila</italic> central complex</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>11</volume><elocation-id>102</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2017.00102</pub-id><pub-id pub-id-type="pmid">28611607</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Givon</surname> <given-names>LE</given-names></name><name><surname>Lazar</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neurokernel: an open source platform for emulating the fruit fly brain</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0146581</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0146581</pub-id><pub-id pub-id-type="pmid">26751378</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Crook</surname> <given-names>S</given-names></name><name><surname>Cannon</surname> <given-names>RC</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Billings</surname> <given-names>GO</given-names></name><name><surname>Farinella</surname> <given-names>M</given-names></name><name><surname>Morse</surname> <given-names>TM</given-names></name><name><surname>Davison</surname> <given-names>AP</given-names></name><name><surname>Ray</surname> <given-names>S</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name><name><surname>Barnes</surname> <given-names>SR</given-names></name><name><surname>Dimitrova</surname> <given-names>YD</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>NeuroML: a language for describing data driven models of neurons and networks with a high degree of biological detail</article-title><source>PLOS Computational Biology</source><volume>6</volume><elocation-id>e1000815</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000815</pub-id><pub-id pub-id-type="pmid">20585541</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Cantarelli</surname> <given-names>M</given-names></name><name><surname>Marin</surname> <given-names>B</given-names></name><name><surname>Quintana</surname> <given-names>A</given-names></name><name><surname>Earnshaw</surname> <given-names>M</given-names></name><name><surname>Sadeh</surname> <given-names>S</given-names></name><name><surname>Piasini</surname> <given-names>E</given-names></name><name><surname>Birgiolas</surname> <given-names>J</given-names></name><name><surname>Cannon</surname> <given-names>RC</given-names></name><name><surname>Cayco-Gajic</surname> <given-names>NA</given-names></name><name><surname>Crook</surname> <given-names>S</given-names></name><name><surname>Davison</surname> <given-names>AP</given-names></name><name><surname>Dura-Bernal</surname> <given-names>S</given-names></name><name><surname>Ecker</surname> <given-names>A</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Idili</surname> <given-names>G</given-names></name><name><surname>Lanore</surname> <given-names>F</given-names></name><name><surname>Larson</surname> <given-names>SD</given-names></name><name><surname>Lytton</surname> <given-names>WW</given-names></name><name><surname>Majumdar</surname> <given-names>A</given-names></name><name><surname>McDougal</surname> <given-names>RA</given-names></name><name><surname>Sivagnanam</surname> <given-names>S</given-names></name><name><surname>Solinas</surname> <given-names>S</given-names></name><name><surname>Stanislovas</surname> <given-names>R</given-names></name><name><surname>van Albada</surname> <given-names>SJ</given-names></name><name><surname>van Geit</surname> <given-names>W</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Open source brain: a collaborative resource for visualizing, analyzing, simulating, and developing standardized models of neurons and circuits</article-title><source>Neuron</source><volume>103</volume><fpage>395</fpage><lpage>411</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.019</pub-id><pub-id pub-id-type="pmid">31201122</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haag</surname> <given-names>J</given-names></name><name><surname>Mishra</surname> <given-names>A</given-names></name><name><surname>Borst</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A common directional tuning mechanism of <italic>Drosophila</italic> motion-sensing neurons in the ON and in the OFF pathway</article-title><source>eLife</source><volume>6</volume><elocation-id>e29044</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.29044</pub-id><pub-id pub-id-type="pmid">28829040</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hausen</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1984">1984</year><chapter-title>The lobula-complex of the fly: structure, function and significance in visual behaviour</chapter-title><person-group person-group-type="editor"><name><surname>Ali</surname> <given-names>M. A</given-names></name></person-group><source>Photoreception and Vision in Invertebrates, NATO ASI Series (Series A: Life Sciences), Chapter the Lobula-Complex of the Fly: Structure, Function and Significance in Visual Behaviour</source><publisher-name>Springer</publisher-name><fpage>523</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1007/978-1-4613-2743-1_15</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Morse</surname> <given-names>T</given-names></name><name><surname>Migliore</surname> <given-names>M</given-names></name><name><surname>Carnevale</surname> <given-names>NT</given-names></name><name><surname>Shepherd</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>ModelDB: a database to support computational neuroscience</article-title><source>Journal of Computational Neuroscience</source><volume>17</volume><fpage>7</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1023/B:JCNS.0000023869.22017.2e</pub-id><pub-id pub-id-type="pmid">15218350</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname> <given-names>ML</given-names></name><name><surname>Carnevale</surname> <given-names>NT</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The NEURON simulation environment</article-title><source>Neural Computation</source><volume>9</volume><fpage>1179</fpage><lpage>1209</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.6.1179</pub-id><pub-id pub-id-type="pmid">9248061</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horne</surname> <given-names>JA</given-names></name><name><surname>Langille</surname> <given-names>C</given-names></name><name><surname>McLin</surname> <given-names>S</given-names></name><name><surname>Wiederman</surname> <given-names>M</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A resource for the <italic>Drosophila</italic> antennal lobe provided by the connectome of glomerulus VA1v</article-title><source>eLife</source><volume>7</volume><elocation-id>e37550</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.37550</pub-id><pub-id pub-id-type="pmid">30382940</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>YC</given-names></name><name><surname>Wang</surname> <given-names>CT</given-names></name><name><surname>Su</surname> <given-names>TS</given-names></name><name><surname>Kao</surname> <given-names>KW</given-names></name><name><surname>Lin</surname> <given-names>YJ</given-names></name><name><surname>Chuang</surname> <given-names>CC</given-names></name><name><surname>Chiang</surname> <given-names>AS</given-names></name><name><surname>Lo</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Single-Cell level and Connectome-Derived computational model of the <italic>Drosophila</italic> Brain</article-title><source>Frontiers in Neuroinformatics</source><volume>12</volume><elocation-id>99</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2018.00099</pub-id><pub-id pub-id-type="pmid">30687056</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenett</surname> <given-names>A</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Ngo</surname> <given-names>TT</given-names></name><name><surname>Shepherd</surname> <given-names>D</given-names></name><name><surname>Murphy</surname> <given-names>C</given-names></name><name><surname>Dionne</surname> <given-names>H</given-names></name><name><surname>Pfeiffer</surname> <given-names>BD</given-names></name><name><surname>Cavallaro</surname> <given-names>A</given-names></name><name><surname>Hall</surname> <given-names>D</given-names></name><name><surname>Jeter</surname> <given-names>J</given-names></name><name><surname>Iyer</surname> <given-names>N</given-names></name><name><surname>Fetter</surname> <given-names>D</given-names></name><name><surname>Hausenfluck</surname> <given-names>JH</given-names></name><name><surname>Peng</surname> <given-names>H</given-names></name><name><surname>Trautman</surname> <given-names>ET</given-names></name><name><surname>Svirskas</surname> <given-names>RR</given-names></name><name><surname>Myers</surname> <given-names>EW</given-names></name><name><surname>Iwinski</surname> <given-names>ZR</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>DePasquale</surname> <given-names>GM</given-names></name><name><surname>Enos</surname> <given-names>A</given-names></name><name><surname>Hulamm</surname> <given-names>P</given-names></name><name><surname>Lam</surname> <given-names>SC</given-names></name><name><surname>Li</surname> <given-names>HH</given-names></name><name><surname>Laverty</surname> <given-names>TR</given-names></name><name><surname>Long</surname> <given-names>F</given-names></name><name><surname>Qu</surname> <given-names>L</given-names></name><name><surname>Murphy</surname> <given-names>SD</given-names></name><name><surname>Rokicki</surname> <given-names>K</given-names></name><name><surname>Safford</surname> <given-names>T</given-names></name><name><surname>Shaw</surname> <given-names>K</given-names></name><name><surname>Simpson</surname> <given-names>JH</given-names></name><name><surname>Sowell</surname> <given-names>A</given-names></name><name><surname>Tae</surname> <given-names>S</given-names></name><name><surname>Yu</surname> <given-names>Y</given-names></name><name><surname>Zugates</surname> <given-names>CT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A GAL4-driver line resource for <italic>Drosophila</italic> neurobiology</article-title><source>Cell Reports</source><volume>2</volume><fpage>991</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2012.09.011</pub-id><pub-id pub-id-type="pmid">23063364</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakaria</surname> <given-names>KS</given-names></name><name><surname>de Bivort</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ring attractor dynamics emerge from a spiking model of the entire protocerebral bridge</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>11</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2017.00008</pub-id><pub-id pub-id-type="pmid">28261066</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>AJ</given-names></name><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Slutskiy</surname> <given-names>YB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>System identification of <italic>Drosophila</italic> olfactory sensory neurons</article-title><source>Journal of Computational Neuroscience</source><volume>30</volume><fpage>143</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1007/s10827-010-0265-0</pub-id><pub-id pub-id-type="pmid">20730480</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>AJ</given-names></name><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Slutskiy</surname> <given-names>YB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Projection neurons in <italic>Drosophila</italic> antennal lobes signal the acceleration of odor concentrations</article-title><source>eLife</source><volume>4</volume><elocation-id>e06651</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06651</pub-id><pub-id pub-id-type="pmid">25974217</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>SS</given-names></name><name><surname>Rouault</surname> <given-names>H</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ring attractor dynamics in the <italic>Drosophila</italic> central brain</article-title><source>Science</source><volume>356</volume><fpage>849</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1126/science.aal4835</pub-id><pub-id pub-id-type="pmid">28473639</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreher</surname> <given-names>SA</given-names></name><name><surname>Kwon</surname> <given-names>JY</given-names></name><name><surname>Carlson</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The molecular basis of odor coding in the <italic>Drosophila</italic> larva</article-title><source>Neuron</source><volume>46</volume><fpage>445</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.007</pub-id><pub-id pub-id-type="pmid">15882644</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Psychas</surname> <given-names>K</given-names></name><name><surname>Ukani</surname> <given-names>NH</given-names></name><name><surname>Zhou</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>A parallel processing model of the <italic>Drosophila</italic> retina</article-title><source>Neurokernel Request for Comments, Neurokernel RFC #</source><volume>3</volume><pub-id pub-id-type="doi">10.5281/zenodo.30036</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Psychas</surname> <given-names>K</given-names></name><name><surname>Ukani</surname> <given-names>NH</given-names></name><name><surname>Zhou</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Retina of the fruit fly eyes: a detailed simulation model</article-title><conf-name>BMC Neuroscience 16(Suppl 1): P301, 24th Annual Computational Neurocience Meeting. July 18-23, 2015, Prague, Czech Republic</conf-name><pub-id pub-id-type="doi">10.1186/1471-2202-16-S1-P301</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Liu</surname> <given-names>T</given-names></name><name><surname>Yeh</surname> <given-names>C-H</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>An odorant encoding machine for sampling, reconstruction and robust representation of odorant identity</article-title><conf-name>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2020)</conf-name><fpage>1743</fpage><lpage>1747</lpage><pub-id pub-id-type="doi">10.1109/ICASSP40776.2020.9054588</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Ukani</surname> <given-names>NH</given-names></name><name><surname>Zhou</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>Sparse identification of contrast gain control in the fruit fly photoreceptor and amacrine cell layer</article-title><source>The Journal of Mathematical Neuroscience</source><volume>10</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.1186/s13408-020-0080-5</pub-id><pub-id pub-id-type="pmid">32052209</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Yeh</surname> <given-names>C-H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Predictive coding in the <italic>Drosophila</italic> antennal lobe</article-title><conf-name>BMC Neuroscience, 20(Suppl 1):P346, 2019. 28th Annual Computational Neuroscience Meeting, July 13-17, 2019, Barcelona, Spain</conf-name><pub-id pub-id-type="doi">10.1186/s12868-019-0538-0</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazar</surname> <given-names>AA</given-names></name><name><surname>Yeh</surname> <given-names>C-H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A molecular odorant transduction model and the complexity of spatio-temporal encoding in the <italic>Drosophila</italic> antenna</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007751. Original version posted on bioRxiv (https://doi.org/10.1101/237669), December 2017</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007751</pub-id><pub-id pub-id-type="pmid">32287275</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>J</given-names></name><name><surname>Mahoney</surname> <given-names>BD</given-names></name><name><surname>Jacob</surname> <given-names>MS</given-names></name><name><surname>Caron</surname> <given-names>SJC</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>Visual input into the <italic>Drosophila melanogaster</italic> mushroom body</article-title><source>Cell Reports</source><volume>32</volume><elocation-id>108138</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.108138</pub-id><pub-id pub-id-type="pmid">32937130</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Lindsey</surname> <given-names>JW</given-names></name><name><surname>Marin</surname> <given-names>EC</given-names></name><name><surname>Otto</surname> <given-names>N</given-names></name><name><surname>Dreher</surname> <given-names>M</given-names></name><name><surname>Dempsey</surname> <given-names>G</given-names></name><name><surname>Stark</surname> <given-names>I</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Pleijzier</surname> <given-names>MW</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Eckstein</surname> <given-names>N</given-names></name><name><surname>Yang</surname> <given-names>T</given-names></name><name><surname>Francis</surname> <given-names>A</given-names></name><name><surname>Braun</surname> <given-names>A</given-names></name><name><surname>Parekh</surname> <given-names>R</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Litwin-Kumar</surname> <given-names>A</given-names></name><name><surname>Waddell</surname> <given-names>S</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>The connectome of the adult <italic>Drosophila</italic> mushroom body provides insights into function</article-title><source>eLife</source><volume>9</volume><elocation-id>e62576</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.62576</pub-id><pub-id pub-id-type="pmid">33315010</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>CY</given-names></name><name><surname>Chuang</surname> <given-names>CC</given-names></name><name><surname>Hua</surname> <given-names>TE</given-names></name><name><surname>Chen</surname> <given-names>CC</given-names></name><name><surname>Dickson</surname> <given-names>BJ</given-names></name><name><surname>Greenspan</surname> <given-names>RJ</given-names></name><name><surname>Chiang</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A comprehensive wiring diagram of the protocerebral bridge for visual information processing in the <italic>Drosophila</italic> brain</article-title><source>Cell Reports</source><volume>3</volume><fpage>1739</fpage><lpage>1753</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2013.04.022</pub-id><pub-id pub-id-type="pmid">23707064</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>G</given-names></name><name><surname>Seiler</surname> <given-names>H</given-names></name><name><surname>Wen</surname> <given-names>A</given-names></name><name><surname>Zars</surname> <given-names>T</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name><name><surname>Wolf</surname> <given-names>R</given-names></name><name><surname>Heisenberg</surname> <given-names>M</given-names></name><name><surname>Liu</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Distinct memory traces for two visual features in the <italic>Drosophila</italic> brain</article-title><source>Nature</source><volume>439</volume><fpage>551</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1038/nature04381</pub-id><pub-id pub-id-type="pmid">16452971</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>YY</given-names></name><name><surname>Slotine</surname> <given-names>JJ</given-names></name><name><surname>Barabási</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Controllability of complex networks</article-title><source>Nature</source><volume>473</volume><fpage>167</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1038/nature10011</pub-id><pub-id pub-id-type="pmid">21562557</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maisak</surname> <given-names>MS</given-names></name><name><surname>Haag</surname> <given-names>J</given-names></name><name><surname>Ammer</surname> <given-names>G</given-names></name><name><surname>Serbe</surname> <given-names>E</given-names></name><name><surname>Meier</surname> <given-names>M</given-names></name><name><surname>Leonhardt</surname> <given-names>A</given-names></name><name><surname>Schilling</surname> <given-names>T</given-names></name><name><surname>Bahl</surname> <given-names>A</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Dickson</surname> <given-names>BJ</given-names></name><name><surname>Reiff</surname> <given-names>DF</given-names></name><name><surname>Hopp</surname> <given-names>E</given-names></name><name><surname>Borst</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A directional tuning map of <italic>Drosophila</italic> elementary motion detectors</article-title><source>Nature</source><volume>500</volume><fpage>212</fpage><lpage>216</lpage><pub-id pub-id-type="doi">10.1038/nature12320</pub-id><pub-id pub-id-type="pmid">23925246</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>McInnes</surname> <given-names>L</given-names></name><name><surname>Healy</surname> <given-names>J</given-names></name><name><surname>Melville</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Umap: uniform manifold approximation and projection for dimension reduction</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1802.03426">https://arxiv.org/abs/1802.03426</ext-link></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Melozzi</surname> <given-names>F</given-names></name><name><surname>Woodman</surname> <given-names>MM</given-names></name><name><surname>Jirsa</surname> <given-names>VK</given-names></name><name><surname>Bernard</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The virtual mouse brain: a computational neuroinformatics platform to study whole mouse brain dynamics</article-title><source>Eneuro</source><volume>4</volume><elocation-id>ENEURO.0111-17.2017</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0111-17.2017</pub-id><pub-id pub-id-type="pmid">28664183</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milyaev</surname> <given-names>N</given-names></name><name><surname>Osumi-Sutherland</surname> <given-names>D</given-names></name><name><surname>Reeve</surname> <given-names>S</given-names></name><name><surname>Burton</surname> <given-names>N</given-names></name><name><surname>Baldock</surname> <given-names>RA</given-names></name><name><surname>Armstrong</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The virtual fly brain browser and query interface</article-title><source>Bioinformatics</source><volume>28</volume><fpage>411</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr677</pub-id><pub-id pub-id-type="pmid">22180411</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Modi</surname> <given-names>MN</given-names></name><name><surname>Shuai</surname> <given-names>Y</given-names></name><name><surname>Turner</surname> <given-names>GC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The <italic>Drosophila</italic> mushroom body: from architecture to algorithm in a learning circuit</article-title><source>Annual Review of Neuroscience</source><volume>43</volume><fpage>465</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-0621333</pub-id><pub-id pub-id-type="pmid">32283995</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Münch</surname> <given-names>D</given-names></name><name><surname>Galizia</surname> <given-names>CG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>DoOR 2.0--comprehensive mapping of <italic>Drosophila melanogaster</italic> odorant responses</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>21841</elocation-id><pub-id pub-id-type="doi">10.1038/srep21841</pub-id><pub-id pub-id-type="pmid">26912260</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oh</surname> <given-names>SW</given-names></name><name><surname>Harris</surname> <given-names>JA</given-names></name><name><surname>Ng</surname> <given-names>L</given-names></name><name><surname>Winslow</surname> <given-names>B</given-names></name><name><surname>Cain</surname> <given-names>N</given-names></name><name><surname>Mihalas</surname> <given-names>S</given-names></name><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>Lau</surname> <given-names>C</given-names></name><name><surname>Kuan</surname> <given-names>L</given-names></name><name><surname>Henry</surname> <given-names>AM</given-names></name><name><surname>Mortrud</surname> <given-names>MT</given-names></name><name><surname>Ouellette</surname> <given-names>B</given-names></name><name><surname>Nguyen</surname> <given-names>TN</given-names></name><name><surname>Sorensen</surname> <given-names>SA</given-names></name><name><surname>Slaughterbeck</surname> <given-names>CR</given-names></name><name><surname>Wakeman</surname> <given-names>W</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Feng</surname> <given-names>D</given-names></name><name><surname>Ho</surname> <given-names>A</given-names></name><name><surname>Nicholas</surname> <given-names>E</given-names></name><name><surname>Hirokawa</surname> <given-names>KE</given-names></name><name><surname>Bohn</surname> <given-names>P</given-names></name><name><surname>Joines</surname> <given-names>KM</given-names></name><name><surname>Peng</surname> <given-names>H</given-names></name><name><surname>Hawrylycz</surname> <given-names>MJ</given-names></name><name><surname>Phillips</surname> <given-names>JW</given-names></name><name><surname>Hohmann</surname> <given-names>JG</given-names></name><name><surname>Wohnoutka</surname> <given-names>P</given-names></name><name><surname>Gerfen</surname> <given-names>CR</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Bernard</surname> <given-names>A</given-names></name><name><surname>Dang</surname> <given-names>C</given-names></name><name><surname>Jones</surname> <given-names>AR</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A mesoscale connectome of the mouse brain</article-title><source>Nature</source><volume>508</volume><fpage>207</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1038/nature13186</pub-id><pub-id pub-id-type="pmid">24695228</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohyama</surname> <given-names>T</given-names></name><name><surname>Schneider-Mizell</surname> <given-names>CM</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Aleman</surname> <given-names>JV</given-names></name><name><surname>Franconville</surname> <given-names>R</given-names></name><name><surname>Rivera-Alba</surname> <given-names>M</given-names></name><name><surname>Mensh</surname> <given-names>BD</given-names></name><name><surname>Branson</surname> <given-names>KM</given-names></name><name><surname>Simpson</surname> <given-names>JH</given-names></name><name><surname>Truman</surname> <given-names>JW</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name><name><surname>Zlatic</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A multilevel multimodal circuit enhances action selection in <italic>Drosophila</italic></article-title><source>Nature</source><volume>520</volume><fpage>633</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1038/nature14297</pub-id><pub-id pub-id-type="pmid">25896325</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname> <given-names>SR</given-names></name><name><surname>Wilson</surname> <given-names>RI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Lateral presynaptic inhibition mediates gain control in an olfactory circuit</article-title><source>Nature</source><volume>452</volume><fpage>956</fpage><lpage>960</lpage><pub-id pub-id-type="doi">10.1038/nature06864</pub-id><pub-id pub-id-type="pmid">18344978</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Priebe</surname> <given-names>CE</given-names></name><name><surname>Park</surname> <given-names>Y</given-names></name><name><surname>Tang</surname> <given-names>M</given-names></name><name><surname>Athreya</surname> <given-names>A</given-names></name><name><surname>Lyzinski</surname> <given-names>V</given-names></name><name><surname>Vogelstein</surname> <given-names>JT</given-names></name><name><surname>Qin</surname> <given-names>Y</given-names></name><name><surname>Ben Cocanougher</surname> <given-names>KE</given-names></name><name><surname>Zlatic</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Semiparametric spectral modeling of the <italic>Drosophila</italic> connectome</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1705.03297">https://arxiv.org/abs/1705.03297</ext-link></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Randlett</surname> <given-names>O</given-names></name><name><surname>Wee</surname> <given-names>CL</given-names></name><name><surname>Naumann</surname> <given-names>EA</given-names></name><name><surname>Nnaemeka</surname> <given-names>O</given-names></name><name><surname>Schoppik</surname> <given-names>D</given-names></name><name><surname>Fitzgerald</surname> <given-names>JE</given-names></name><name><surname>Portugues</surname> <given-names>R</given-names></name><name><surname>Lacoste</surname> <given-names>AM</given-names></name><name><surname>Riegler</surname> <given-names>C</given-names></name><name><surname>Engert</surname> <given-names>F</given-names></name><name><surname>Schier</surname> <given-names>AF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Whole-brain activity mapping onto a zebrafish brain atlas</article-title><source>Nature Methods</source><volume>12</volume><fpage>1039</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3581</pub-id><pub-id pub-id-type="pmid">26778924</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname> <given-names>S</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>PyMOOSE: interoperable scripting in Python for MOOSE</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.006.2008</pub-id><pub-id pub-id-type="pmid">19129924</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivera-Alba</surname> <given-names>M</given-names></name><name><surname>Vitaladevuni</surname> <given-names>SN</given-names></name><name><surname>Mishchenko</surname> <given-names>Y</given-names></name><name><surname>Mischenko</surname> <given-names>Y</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Scheffer</surname> <given-names>L</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name><name><surname>de Polavieja</surname> <given-names>GG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Wiring economy and volume exclusion determine neuronal placement in the <italic>Drosophila</italic> brain</article-title><source>Current Biology</source><volume>21</volume><fpage>2000</fpage><lpage>2005</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.10.022</pub-id><pub-id pub-id-type="pmid">22119527</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalfeld</surname> <given-names>S</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name><name><surname>Tomancak</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CATMAID: collaborative annotation toolkit for massive amounts of image data</article-title><source>Bioinformatics</source><volume>25</volume><fpage>1984</fpage><lpage>1986</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp266</pub-id><pub-id pub-id-type="pmid">19376822</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanz Leon</surname> <given-names>P</given-names></name><name><surname>Knock</surname> <given-names>SA</given-names></name><name><surname>Woodman</surname> <given-names>MM</given-names></name><name><surname>Domide</surname> <given-names>L</given-names></name><name><surname>Mersmann</surname> <given-names>J</given-names></name><name><surname>McIntosh</surname> <given-names>AR</given-names></name><name><surname>Jirsa</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The virtual brain: a simulator of primate brain network dynamics</article-title><source>Frontiers in Neuroinformatics</source><volume>7</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2013.00010</pub-id><pub-id pub-id-type="pmid">23781198</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saumweber</surname> <given-names>T</given-names></name><name><surname>Rohwedder</surname> <given-names>A</given-names></name><name><surname>Schleyer</surname> <given-names>M</given-names></name><name><surname>Eichler</surname> <given-names>K</given-names></name><name><surname>Chen</surname> <given-names>YC</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name><name><surname>Eschbach</surname> <given-names>C</given-names></name><name><surname>Kobler</surname> <given-names>O</given-names></name><name><surname>Voigt</surname> <given-names>A</given-names></name><name><surname>Durairaja</surname> <given-names>A</given-names></name><name><surname>Mancini</surname> <given-names>N</given-names></name><name><surname>Zlatic</surname> <given-names>M</given-names></name><name><surname>Truman</surname> <given-names>JW</given-names></name><name><surname>Thum</surname> <given-names>AS</given-names></name><name><surname>Gerber</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Functional architecture of reward learning in mushroom body extrinsic neurons of larval <italic>Drosophila</italic></article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1104</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-03130-1</pub-id><pub-id pub-id-type="pmid">29549237</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Januszewski</surname> <given-names>M</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Huang</surname> <given-names>GB</given-names></name><name><surname>Shinomiya</surname> <given-names>K</given-names></name><name><surname>Maitlin-Shepard</surname> <given-names>J</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Clements</surname> <given-names>J</given-names></name><name><surname>Hubbard</surname> <given-names>PM</given-names></name><name><surname>Katz</surname> <given-names>WT</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Ackerman</surname> <given-names>D</given-names></name><name><surname>Blakely</surname> <given-names>T</given-names></name><name><surname>Bogovic</surname> <given-names>J</given-names></name><name><surname>Dolafi</surname> <given-names>T</given-names></name><name><surname>Kainmueller</surname> <given-names>D</given-names></name><name><surname>Kawase</surname> <given-names>T</given-names></name><name><surname>Khairy</surname> <given-names>KA</given-names></name><name><surname>Leavitt</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>PH</given-names></name><name><surname>Lindsey</surname> <given-names>L</given-names></name><name><surname>Neubarth</surname> <given-names>N</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Otsuna</surname> <given-names>H</given-names></name><name><surname>Trautman</surname> <given-names>ET</given-names></name><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Goldammer</surname> <given-names>J</given-names></name><name><surname>Wolff</surname> <given-names>T</given-names></name><name><surname>Svirskas</surname> <given-names>R</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Neace</surname> <given-names>E</given-names></name><name><surname>Knecht</surname> <given-names>CJ</given-names></name><name><surname>Alvarado</surname> <given-names>CX</given-names></name><name><surname>Bailey</surname> <given-names>DA</given-names></name><name><surname>Ballinger</surname> <given-names>S</given-names></name><name><surname>Borycz</surname> <given-names>JA</given-names></name><name><surname>Canino</surname> <given-names>BS</given-names></name><name><surname>Cheatham</surname> <given-names>N</given-names></name><name><surname>Cook</surname> <given-names>M</given-names></name><name><surname>Dreher</surname> <given-names>M</given-names></name><name><surname>Duclos</surname> <given-names>O</given-names></name><name><surname>Eubanks</surname> <given-names>B</given-names></name><name><surname>Fairbanks</surname> <given-names>K</given-names></name><name><surname>Finley</surname> <given-names>S</given-names></name><name><surname>Forknall</surname> <given-names>N</given-names></name><name><surname>Francis</surname> <given-names>A</given-names></name><name><surname>Hopkins</surname> <given-names>GP</given-names></name><name><surname>Joyce</surname> <given-names>EM</given-names></name><name><surname>Kim</surname> <given-names>S</given-names></name><name><surname>Kirk</surname> <given-names>NA</given-names></name><name><surname>Kovalyak</surname> <given-names>J</given-names></name><name><surname>Lauchie</surname> <given-names>SA</given-names></name><name><surname>Lohff</surname> <given-names>A</given-names></name><name><surname>Maldonado</surname> <given-names>C</given-names></name><name><surname>Manley</surname> <given-names>EA</given-names></name><name><surname>McLin</surname> <given-names>S</given-names></name><name><surname>Mooney</surname> <given-names>C</given-names></name><name><surname>Ndama</surname> <given-names>M</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Okeoma</surname> <given-names>N</given-names></name><name><surname>Ordish</surname> <given-names>C</given-names></name><name><surname>Padilla</surname> <given-names>N</given-names></name><name><surname>Patrick</surname> <given-names>CM</given-names></name><name><surname>Paterson</surname> <given-names>T</given-names></name><name><surname>Phillips</surname> <given-names>EE</given-names></name><name><surname>Phillips</surname> <given-names>EM</given-names></name><name><surname>Rampally</surname> <given-names>N</given-names></name><name><surname>Ribeiro</surname> <given-names>C</given-names></name><name><surname>Robertson</surname> <given-names>MK</given-names></name><name><surname>Rymer</surname> <given-names>JT</given-names></name><name><surname>Ryan</surname> <given-names>SM</given-names></name><name><surname>Sammons</surname> <given-names>M</given-names></name><name><surname>Scott</surname> <given-names>AK</given-names></name><name><surname>Scott</surname> <given-names>AL</given-names></name><name><surname>Shinomiya</surname> <given-names>A</given-names></name><name><surname>Smith</surname> <given-names>C</given-names></name><name><surname>Smith</surname> <given-names>K</given-names></name><name><surname>Smith</surname> <given-names>NL</given-names></name><name><surname>Sobeski</surname> <given-names>MA</given-names></name><name><surname>Suleiman</surname> <given-names>A</given-names></name><name><surname>Swift</surname> <given-names>J</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Talebi</surname> <given-names>I</given-names></name><name><surname>Tarnogorska</surname> <given-names>D</given-names></name><name><surname>Tenshaw</surname> <given-names>E</given-names></name><name><surname>Tokhi</surname> <given-names>T</given-names></name><name><surname>Walsh</surname> <given-names>JJ</given-names></name><name><surname>Yang</surname> <given-names>T</given-names></name><name><surname>Horne</surname> <given-names>JA</given-names></name><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Parekh</surname> <given-names>R</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name><name><surname>George</surname> <given-names>R</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name><name><surname>Jain</surname> <given-names>V</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A connectome and analysis of the adult <italic>Drosophila</italic> central brain</article-title><source>eLife</source><volume>9</volume><elocation-id>e57443</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57443</pub-id><pub-id pub-id-type="pmid">32880371</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seelig</surname> <given-names>JD</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural dynamics for landmark orientation and angular path integration</article-title><source>Nature</source><volume>521</volume><fpage>186</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1038/nature14446</pub-id><pub-id pub-id-type="pmid">25971509</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengupta</surname> <given-names>B</given-names></name><name><surname>Stemmler</surname> <given-names>M</given-names></name><name><surname>Laughlin</surname> <given-names>SB</given-names></name><name><surname>Niven</surname> <given-names>JE</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Action potential energy efficiency varies among neuron types in vertebrates and invertebrates</article-title><source>PLOS Computational Biology</source><volume>6</volume><elocation-id>e1000840</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000840</pub-id><pub-id pub-id-type="pmid">20617202</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherfey</surname> <given-names>JS</given-names></name><name><surname>Soplata</surname> <given-names>AE</given-names></name><name><surname>Ardid</surname> <given-names>S</given-names></name><name><surname>Roberts</surname> <given-names>EA</given-names></name><name><surname>Stanley</surname> <given-names>DA</given-names></name><name><surname>Pittman-Polletta</surname> <given-names>BR</given-names></name><name><surname>Kopell</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DynaSim: a MATLAB toolbox for neural modeling and simulation</article-title><source>Frontiers in Neuroinformatics</source><volume>12</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2018.00010</pub-id><pub-id pub-id-type="pmid">29599715</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname> <given-names>WE</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name><name><surname>Kudrimoti</surname> <given-names>HS</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>A model of the neural basis of the rat’s sense of direction</article-title><source>Advances in Neural Information Processing Systems</source><volume>7</volume><fpage>173</fpage><lpage>180</lpage><pub-id pub-id-type="pmid">11539168</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokal</surname> <given-names>RR</given-names></name></person-group><year iso-8601-date="1958">1958</year><article-title>A statistical method for evaluating systematic relationships</article-title><source>Univ. Kansas, Sci. Bull</source><volume>38</volume><fpage>1409</fpage><lpage>1438</lpage></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname> <given-names>Z</given-names></name><name><surname>Postma</surname> <given-names>M</given-names></name><name><surname>Billings</surname> <given-names>SA</given-names></name><name><surname>Coca</surname> <given-names>D</given-names></name><name><surname>Hardie</surname> <given-names>RC</given-names></name><name><surname>Juusola</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Stochastic, adaptive sampling of information by microvilli in fly photoreceptors</article-title><source>Current Biology</source><volume>22</volume><fpage>1371</fpage><lpage>1380</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.05.047</pub-id><pub-id pub-id-type="pmid">22704990</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stimberg</surname> <given-names>M</given-names></name><name><surname>Brette</surname> <given-names>R</given-names></name><name><surname>Goodman</surname> <given-names>DF</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brian 2, an intuitive and efficient neural simulator</article-title><source>eLife</source><volume>8</volume><elocation-id>e47314</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.47314</pub-id><pub-id pub-id-type="pmid">31429824</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stockton</surname> <given-names>DB</given-names></name><name><surname>Santamaria</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>NeuroManager: a workflow analysis based simulation management engine for computational neuroscience</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>24</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00024</pub-id><pub-id pub-id-type="pmid">26528175</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stone</surname> <given-names>T</given-names></name><name><surname>Webb</surname> <given-names>B</given-names></name><name><surname>Adden</surname> <given-names>A</given-names></name><name><surname>Weddig</surname> <given-names>NB</given-names></name><name><surname>Honkanen</surname> <given-names>A</given-names></name><name><surname>Templin</surname> <given-names>R</given-names></name><name><surname>Wcislo</surname> <given-names>W</given-names></name><name><surname>Scimeca</surname> <given-names>L</given-names></name><name><surname>Warrant</surname> <given-names>E</given-names></name><name><surname>Heinze</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An anatomically constrained model for path integration in the bee brain</article-title><source>Current Biology</source><volume>27</volume><fpage>3069</fpage><lpage>3085</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.08.052</pub-id><pub-id pub-id-type="pmid">28988858</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname> <given-names>TS</given-names></name><name><surname>Lee</surname> <given-names>WJ</given-names></name><name><surname>Huang</surname> <given-names>YC</given-names></name><name><surname>Wang</surname> <given-names>CT</given-names></name><name><surname>Lo</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Coupled symmetric and asymmetric circuits underlying spatial orientation in fruit flies</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>139</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-00191-6</pub-id><pub-id pub-id-type="pmid">28747622</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussman</surname> <given-names>DL</given-names></name><name><surname>Tang</surname> <given-names>M</given-names></name><name><surname>Fishkind</surname> <given-names>DE</given-names></name><name><surname>Priebe</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A consistent adjacency spectral embedding for stochastic blockmodel graphs</article-title><source>Journal of the American Statistical Association</source><volume>107</volume><fpage>1119</fpage><lpage>1128</lpage><pub-id pub-id-type="doi">10.1080/01621459.2012.699795</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szigeti</surname> <given-names>B</given-names></name><name><surname>Gleeson</surname> <given-names>P</given-names></name><name><surname>Vella</surname> <given-names>M</given-names></name><name><surname>Khayrulin</surname> <given-names>S</given-names></name><name><surname>Palyanov</surname> <given-names>A</given-names></name><name><surname>Hokanson</surname> <given-names>J</given-names></name><name><surname>Currie</surname> <given-names>M</given-names></name><name><surname>Cantarelli</surname> <given-names>M</given-names></name><name><surname>Idili</surname> <given-names>G</given-names></name><name><surname>Larson</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>OpenWorm: an open-science approach to modeling <italic>Caenorhabditis elegans</italic></article-title><source>Frontiers in Computational Neuroscience</source><volume>8</volume><elocation-id>137</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2014.00137</pub-id><pub-id pub-id-type="pmid">25404913</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Parag</surname> <given-names>T</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Plaza</surname> <given-names>S</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Katz</surname> <given-names>WT</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Weaver</surname> <given-names>C</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name><name><surname>Horne</surname> <given-names>JA</given-names></name><name><surname>Nunez-Iglesias</surname> <given-names>J</given-names></name><name><surname>Aniceto</surname> <given-names>R</given-names></name><name><surname>Chang</surname> <given-names>LA</given-names></name><name><surname>Lauchie</surname> <given-names>S</given-names></name><name><surname>Nasca</surname> <given-names>A</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Sigmund</surname> <given-names>C</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Tran</surname> <given-names>J</given-names></name><name><surname>Langille</surname> <given-names>C</given-names></name><name><surname>Le Lacheur</surname> <given-names>K</given-names></name><name><surname>McLin</surname> <given-names>S</given-names></name><name><surname>Shinomiya</surname> <given-names>A</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Synaptic circuits and their variations within different columns in the visual system of <italic>Drosophila</italic></article-title><source>PNAS</source><volume>112</volume><fpage>13711</fpage><lpage>13716</lpage><pub-id pub-id-type="doi">10.1073/pnas.1509820112</pub-id><pub-id pub-id-type="pmid">26483464</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Hige</surname> <given-names>T</given-names></name><name><surname>Wong</surname> <given-names>A</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Hess</surname> <given-names>H</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Parag</surname> <given-names>T</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Huang</surname> <given-names>G</given-names></name><name><surname>Katz</surname> <given-names>W</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Plaza</surname> <given-names>S</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Aniceto</surname> <given-names>R</given-names></name><name><surname>Chang</surname> <given-names>LA</given-names></name><name><surname>Lauchie</surname> <given-names>S</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Ordish</surname> <given-names>C</given-names></name><name><surname>Shinomiya</surname> <given-names>A</given-names></name><name><surname>Sigmund</surname> <given-names>C</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Tran</surname> <given-names>J</given-names></name><name><surname>Turner</surname> <given-names>GC</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>A connectome of a learning and memory center in the adult <italic>Drosophila</italic> brain</article-title><source>eLife</source><volume>6</volume><elocation-id>e26975</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.26975</pub-id><pub-id pub-id-type="pmid">28718765</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>The comprehensive connectome of a neural substrate for ‘ON’ motion detection in <italic>Drosophila</italic></article-title><source>eLife</source><volume>6</volume><elocation-id>e24394</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.24394</pub-id><pub-id pub-id-type="pmid">28432786</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomkins</surname> <given-names>A</given-names></name><name><surname>Ortiz</surname> <given-names>CL</given-names></name><name><surname>Coca</surname> <given-names>D</given-names></name><name><surname>Richmond</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>From GUI to GPU: a toolchain for GPU code generation for large scale <italic>Drosophila</italic> simulations using SpineML</article-title><source>Frontiers in Neuroinformatics</source><volume>2016</volume><elocation-id>49</elocation-id><pub-id pub-id-type="doi">10.3389/conf.fninf.2016.20.00049</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ukani</surname> <given-names>NH</given-names></name><name><surname>Yeh</surname> <given-names>C-H</given-names></name><name><surname>Tomkins</surname> <given-names>A</given-names></name><name><surname>Zhou</surname> <given-names>Y</given-names></name><name><surname>Florescu</surname> <given-names>D</given-names></name><name><surname>Ortiz</surname> <given-names>CL</given-names></name><name><surname>Huang</surname> <given-names>Y-C</given-names></name><name><surname>Wang C-T</surname></name><name><surname>Turkcan MK</surname></name><name><surname>Liu</surname> <given-names>T</given-names></name><name><surname>Richmond</surname> <given-names>P</given-names></name><name><surname>Lo</surname> <given-names>C-C</given-names></name><name><surname>Coca</surname> <given-names>D</given-names></name><name><surname>Chiang</surname> <given-names>A-S</given-names></name><name><surname>Lazar</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The fruit fly brain observatory: from structure to function</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/580290</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varela</surname> <given-names>N</given-names></name><name><surname>Gaspar</surname> <given-names>M</given-names></name><name><surname>Dias</surname> <given-names>S</given-names></name><name><surname>Vasconcelos</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Avoidance response to CO2 in the lateral horn</article-title><source>PLOS Biology</source><volume>17</volume><elocation-id>e2006749</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2006749</pub-id><pub-id pub-id-type="pmid">30653496</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Hierarchical grouping to optimize an objective function</article-title><source>Journal of the American Statistical Association</source><volume>58</volume><fpage>236</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1080/01621459.1963.10500845</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname> <given-names>T</given-names></name><name><surname>Iyer</surname> <given-names>NA</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuroarchitecture and neuroanatomy of the <italic>Drosophila</italic> central complex: A GAL4‐based dissection of protocerebral bridge neurons and circuits</article-title><source>Journal of Comparative Neurology</source><volume>523</volume><fpage>997</fpage><lpage>1037</lpage><pub-id pub-id-type="doi">10.1002/cne.23705</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><sec id="s8" sec-type="appendix"><title>The architecture of FlyBrainLab</title><p>To support the study of the function of brain circuits FlyBrainLab implements an extensible, modularized architecture that tightly integrates fruit fly brain data and models of executable circuits. <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> depicts the architecture of FlyBrainLab on both the user- and backend server-side.</p><p>The backend server-side components are described in Appendix 1.1. The user-side components are presented in Appendix 1.2.</p><sec id="s8-1"><title>1.1 The server-side components</title><p>The server-side backend consists of four components: FFBO Processor, NeuroArch, Neurokernel and NeuroNLP servers. They are collectively called the FFBO servers. A brief description of each of the components is given below.</p><p><bold>FFBO Processor</bold> implements a <ext-link ext-link-type="uri" xlink:href="https://crossbar.io/">Crossbar.io</ext-link> router (<ext-link ext-link-type="uri" xlink:href="https://crossbar.io/">https://crossbar.io/</ext-link>) that establishes the communication path among connected components. Components communicate using routed Remote Procedure Calls (RPCs) and a publish/subscribe mechanism. The routed RPCs enable functions implemented on the server-side to be called by the user-side backend (see also Section 1.2). After an event occurs, the publisher immediately informs topic subscribers by invoking the publish/subscribe mechanism. This enables, for example, the FFBO processor to inform the user-side and other servers when a new backend server is connected. The FFBO processor can be hosted locally or in the cloud. It can also be hosted by a service provider for, for example, extra data sharing. The open source code of the FFBO processors is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/fruitflybrain/ffbo.processor">https://github.com/fruitflybrain/ffbo.processor</ext-link>.</p><p><bold>NeuroArch Server</bold> hosts the NeuroArch graph database (<xref ref-type="bibr" rid="bib24">Givon et al., 2015</xref>) implemented with OrientDB (<ext-link ext-link-type="uri" xlink:href="https://orientdb.org">https://orientdb.org</ext-link>). The NeuroArch Database provides a novel data model for representation and storage of connectomic, synaptomic, cell type, activity, and genetic data of the fruit fly brain with cross-referenced executable circuits. The NeuroArch data model is the foundation of the integration of fruit fly brain data and executable circuits in FlyBrainLab. Low-level queries of the NeuroArch Database are supported by the NeuroArch Python API (<ext-link ext-link-type="uri" xlink:href="https://github.com/fruitflybrain/neuroarch">https://github.com/fruitflybrain/neuroarch</ext-link>). The NeuroArch Server provides high level RPC APIs for remote access of the NeuroArch Database. The open source code of the NeuroArch Server is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/fruitflybrain/ffbo.neuroarch_component">https://github.com/fruitflybrain/ffbo.neuroarch_component</ext-link>.</p><p><bold>Neurokernel Server</bold> provides RPC APIs for code execution of model circuits by the Neurokernel Execution Engine (<xref ref-type="bibr" rid="bib26">Givon and Lazar, 2016</xref>). Neurokernel supports the easy combination of independently developed executable circuits towards the realization of a complete whole brain emulation. The Neurokernel Execution Engine features:</p><list list-type="bullet"><list-item><p>the core Neurokernel services (<ext-link ext-link-type="uri" xlink:href="https://github.com/neurokernel/neurokernel">https://github.com/neurokernel/neurokernel</ext-link>) providing management capabilities for code execution, and communication between interconnected circuits,</p></list-item> <list-item><p>the Neurodriver services (<ext-link ext-link-type="uri" xlink:href="https://github.com/neurokernel/neurodriver">https://github.com/neurokernel/neurodriver</ext-link>) providing low level APIs for code execution on GPUs according to user-specified circuit connectivity, biological spike generators and synapses, and input stimuli.</p></list-item></list><p>The Neurokernel Server directly fetches the specification of executable circuits from the NeuroArch Server, instantiates these circuits and transfers them for execution to the Neurokernel Execution Engine. The open source code of the Neurokernel Server is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/fruitflybrain/ffbo.neurokernel_component">https://github.com/fruitflybrain/ffbo.neurokernel_component</ext-link>.</p><p><bold>NeuroNLP Server</bold> provides an RPC API for translating queries written as English sentences, such as 'add dopaminergic neurons innervating the mushroom body’, into database queries that can be interpreted by the NeuroArch Server API. This capability increases the accessibility of the NeuroArch Database to researchers without prior exposure to database programming, and facilitates research by simplifying the often-demanding task of writing database queries. The open source code of the NeuroNLP Server is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/fruitflybrain/ffbo.nlp_component">https://github.com/fruitflybrain/ffbo.nlp_component</ext-link>.</p></sec><sec id="s8-2"><title>1.2 The user-side components</title><p>The FlyBrainLab user-side consists of the NeuroMynerva frontend and the FlyBrainLab Client and Neuroballad backend components. A brief description of each of the components is given below.</p><p><bold>NeuroMynerva</bold> is the user-side frontend of FlyBrainLab. It is a browser-based application that substantially extends upon JupyterLab by providing a number of widgets, including a Neu3D widget for 3D visualization of fly brain data, a NeuGFX widget for exploring executable neural circuits with interactive circuit diagrams, and an InfoPanel widget for accessing individual neuron/synapse data. All widgets communicate with and retrieve data from the FlyBrainLab Client. A master widget keeps track of the instantiated widgets by the user interface. With the JupyterLab native notebook support, APIs of the FlyBrainLab Client can be directly called from notebooks. Such calls provide Python access to NeuroArch queries and circuit execution. Interaction between code running in notebooks and widgets is fully supported.</p><p><bold>FlyBrainLab Client</bold> is a user-side backend implemented in Python that connects to the FFBO processor and accesses services provided by the connected backend servers. FlyBrainLab Client provides program execution APIs for handling requests to the server-side components and parsing of data coming from backend servers. The FlyBrainLab Client also exhibits a number of high-level APIs for processing data collected from the backend servers, such as computing the adjacency matrix from retrieved connectivity data or retrieving morphometrics data. In addition, it handles the communication with the frontend through the Jupyter kernel.</p><p><bold>NeuroBallad</bold> is a Python library that simplifies and accelerates executable circuit construction and simulation using Neurokernel in Jupyter notebooks in FlyBrainLab. NeuroBallad provides classes for specification of neuron or synapse models with a single line of code and contains functions for adding and connecting these circuit components with one another. NeuroBallad also provides capabilities for compactly specifying inputs to a circuit on a per-experiment basis.</p><p><bold>Core Functionalities Provided by FlyBrainLab</bold> Examples of capabilities that users can directly invoke are: (1) Query using plain English and 3D graphics for building and visualizing brain circuits; (2) Query the NeuroArch Database using NeuroArch JSON format for building and visualizing brain circuits and constructing executable circuits; (3) Retrieval of the connectivity of the brain circuit built/visualized; (4) Retrieval of the graph representing the circuit built/visualized; (5) Retrieval of the circuit model corresponding to the brain circuit built; (6) User interface and API for circuit diagram interaction; (7) Specification of models and parameters for each circuit components; (8) Execution of the circuits represented/stored in the NeuroArch Database.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>The architecture of FlyBrainLab.</title><p>The server-side architecture (<xref ref-type="bibr" rid="bib85">Ukani et al., 2019</xref>) consists of the FFBO Processor, the NeuroNLP Server, the NeuroArch Server and the Neurokernel Server. The user-side provides the local execution environment as well as an easy-to-use GUI for multi-user access to the services provided by the server-side. The FlyBrainLab Utility Libraries and Circuit Libraries (see Sections 2 and 3 for details) can be loaded into the FlyBrainLab workspace of the user-side backend.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app1-fig1-v2.tif"/></fig></sec></sec></boxed-text></app><app id="appendix-2"><title>Appendix 2</title><boxed-text><sec id="s9" sec-type="appendix"><title>Utility libraries for the fruit fly connectome/synaptome</title><p>Different connectome and synaptome datasets are often available at different levels of abstraction. For example, some datasets come with cell types labeled and some only provide raw graph level connectivity. Without extensive analysis tools, it takes substantial manual effort to construct and test a neural circuit. FlyBrainLab offers a number of utilities to explicate the graph structure of neural circuits from raw connectome and synaptome data. In conjunction with the capability of visually constructing circuits enabled by the NeuroMynerva front-end, speeding up the process of creating interactive executable circuit diagrams can substantially reduce the exploratory development cycle.</p><p>The FlyBrainLab Utility Libraries include:</p><list list-type="bullet"><list-item><p><bold>NeuroEmbed</bold>: Cell Classification and Cell Type Discovery,</p></list-item> <list-item><p><bold>NeuroSynapsis</bold>: High Level Queries and Analysis of Connectomic and Synaptomic Data,</p></list-item> <list-item><p><bold>NeuroGraph</bold>: Connectivity Pattern Discovery and Circuit Visualization Algorithms,</p></list-item> <list-item><p><bold>NeuroWatch</bold>: 3D Fruit Fly Data Visualization in Jupyter Notebooks,</p></list-item> <list-item><p><bold>NeuroMetry</bold>: Morphometric Measurements of Neurons.</p></list-item></list><p>In this section, we outline the capabilities enabled by the Utility Libraries listed above.</p><sec id="s9-1"><title>NeuroEmbed: cell classification and cell type discovery</title><p>The NeuroEmbed library implements a set of algorithms for structure discovery based on graph embeddings into low-dimensional spaces providing capabilities for:</p><list list-type="bullet"><list-item><p>Cell type classification based on connectivity, and optionally morphometric features,</p></list-item> <list-item><p>Searching for neurons that display a similar connectivity pattern,</p></list-item> <list-item><p>Standard evaluation functions for comparison of embedding algorithms on clustering and classification tasks.</p></list-item></list></sec><sec id="s9-2"><title>NeuroSynapsis: high-level queries and analysis of connectomic and synaptomic data</title><p>The NeuroSynapsis Library offers a large set of utilities to accelerate the construction of circuits and analysis of connectomic and synaptomic data. It provides capabilities for</p><list list-type="bullet"><list-item><p>Retrieval of neuron groups according to user-defined criteria, such as cell type, innervation pattern and connectivity, etc.,</p></list-item> <list-item><p>Retrieval of connectivity between neurons, cell types, or user-defined neuron groups, through direct or indirect connections,</p></list-item> <list-item><p>Retrieval of synapse positions and partners for groups of neurons and the capability to filter synapses by brain region, partnership or spatial location,</p></list-item> <list-item><p>Statistical analysis of retrieved synapses, such as the synaptic density in a brain region,</p></list-item></list></sec><sec id="s9-3"><title>NeuroGraph: connectivity pattern discovery and circuit visualization algorithms</title><p>The NeuroGraph Library offers a set of tools to discover and analyze any connectivity pattern among cell groups within a circuit. Capabilities include:</p><list list-type="bullet"><list-item><p>Discovery of connectivity patterns between cell populations by automatic generation of connectivity dendrograms with different linkage criteria (such as Ward or average) (<xref ref-type="bibr" rid="bib87">Ward, 1963</xref>; <xref ref-type="bibr" rid="bib73">Sokal, 1958</xref>),</p></list-item> <list-item><p>Analysis of the structure of circuits by community detection algorithms such as Louvain, Leiden, Label Propogation, Girvan-Newman and Infomap,</p></list-item> <list-item><p>Analysis of neural circuit controllability, for example discovery of driver nodes (<xref ref-type="bibr" rid="bib51">Liu et al., 2011</xref>),</p></list-item> <list-item><p>Comparing observed connectivity between groups of cells with models of random connectivity.</p></list-item></list><p>In addition, the NeuroGraph Library provides utilities to visualize the connectivity of a neural circuit to aid the creation of interactive circuit diagrams. Further capabilities include</p><list list-type="bullet"><list-item><p>Force-directed layout for the architecture-level graph of the whole brain or circuit-level graph of circuits specified by NeuroSynapsis,</p></list-item> <list-item><p>Semi-automated generation of 2D circuit diagrams from specified connectome datasets either at single-neuron or cell-type scale by separating circuit components into input, local and output populations for layouting.</p></list-item></list></sec><sec id="s9-4"><title>NeuroWatch: 3D fruit fly data visualization in Jupyter notebooks</title><p>The NeuroWatch Library offers utilities to enable visualization of neuron morphology data using Neu3D in Jupyter Notebook cells. Capabilities include:</p><list list-type="bullet"><list-item><p>Loading brain regions in 3D mesh format,</p></list-item> <list-item><p>Recoloring, rescaling, repositioning and rotating neuropils, neurons and synapses for visualization,</p></list-item> <list-item><p>Interactive alignment of new neuromorphology datasets into FlyBrainLab widgets.</p></list-item></list></sec><sec id="s9-5"><title>NeuroMetry: morphometric measurements of neurons</title><p>Morphometric measurements of neurons can be extracted from neuron skeleton data available in connectome datasets in .swc format. NeuroMetry provides utilities for</p><list list-type="bullet"><list-item><p>Calculating morphometric measurements of neurons that are compatible with <ext-link ext-link-type="uri" xlink:href="http://www.neuromorpho.org">NeuroMorpho.org</ext-link> (<xref ref-type="bibr" rid="bib3">Ascoli et al., 2007</xref>), such as total length, total surface area, total volume, maximum euclidean distance between two points, width, height, depth, average diameter, number of bifurcations and the maximum path distance,</p></list-item> <list-item><p>Accessing precomputed measurements in currently available datasets in FlyBrainLab, including FlyCircuit and Hemibrain data.</p></list-item></list><p>An application of the morphometric measurements is the estimation of energy consumption arising from spike generation in axon-hillocks (<xref ref-type="bibr" rid="bib70">Sengupta et al., 2010</xref>).</p></sec></sec></boxed-text></app><app id="appendix-3"><title>Appendix 3</title><boxed-text><sec id="s10" sec-type="appendix"><title>Libraries for analyzing, evaluating, and comparing Fruit FlyBrain circuits</title><p>The Circuit Libraries are built on top of the core FlyBrainLab architecture and provide tools for studying the functional logic of a specific or a set of distributed brain regions/circuits. The FlyBrainLab Circuit Library includes:</p><list list-type="bullet"><list-item><p><bold>CXcircuits</bold>: Library for Central Complex Circuits,</p></list-item> <list-item><p><bold>EOScircuits</bold>: Library for Larva and Adult Early Olfactory Circuits,</p></list-item> <list-item><p><bold>MolTrans</bold>: Library for Molecular Transduction in Sensory Encoding.</p></list-item></list><p>These are respectively described in Appendix 3.1, 3.2 and 3.3 below.</p><sec id="s10-1"><title>3.1 CXcircuits: library for central complex circuits</title><p>The CXcircuits library facilitates the exploration of neural circuits of the central complex (CX) based on the FlyCircuit dataset (<xref ref-type="bibr" rid="bib9">Chiang et al., 2011</xref>). It supports the evaluation and direct comparison of the state-of-the-art of executable circuit models of the CX available in the literature, and accelerates the development of new executable CX circuit models that can be evaluated and scrutinized by the research community at large in terms of modeling assumptions and biological validity. It can be easily expanded to account for the Hemibrain dataset (<xref ref-type="bibr" rid="bib68">Scheffer et al., 2020</xref>). The main capabilities of the CX Library include programs for:</p><list list-type="bullet"><list-item> <p>Constructing <italic>biological</italic> CX circuits featuring</p> <list list-type="bullet"><list-item><p>A naming scheme for CX neurons that is machine parsable and facilitates the extraction of innervation patterns (<xref ref-type="bibr" rid="bib25">Givon et al., 2017</xref>),</p></list-item> <list-item><p>Algorithms for querying CX neurons in the NeuroArch database, by neuron type, by subregions they innervate, and by connectivity,</p></list-item> <list-item><p>An inference algorithm for identifying synaptic connections between CX neurons in NeuroArch according to their innervation patterns,</p></list-item></list> </list-item> <list-item> <p>Constructing <italic>executable</italic> CX circuit diagrams that</p> <list list-type="bullet"><list-item><p>Are interactive for CX circuits in wild-type fruit flies,</p></list-item> <list-item><p>Interactively visualize neuron innervation patterns and circuit connectivity,</p></list-item> <list-item><p>Are interoperable with 3D visualizations of the morphology of CX neurons,</p></list-item> <list-item><p>Easily reconfigure CX circuits by enabling/disabling neurons/synapses, by enabling/disabling subregions in any of the CX neuropils, and by adding neurons,</p></list-item> <list-item><p>Readily load neuron/synapse models and parameters,</p></list-item></list> </list-item> <list-item> <p>Evaluation of the executable CX circuits with</p> <list list-type="bullet"><list-item><p>A common set of input stimuli, and the</p></list-item> <list-item><p>Visualization of the execution results with a set of plotting utilities for generating raster plots and a set of animation utilities for creating videos.</p></list-item></list> </list-item></list></sec><sec id="s10-2"><title>3.2 EOScircuits library for larva and adult early olfactory circuits</title><p>The EOScircuits Library accelerates the development of models of the fruit fly early olfactory system (EOS), and facilitates structural and functional comparisons of olfactory circuits across developmental stages from larva to the adult fruit fly. Built upon FlyBrainLab’s robust execution backend, the EOScircuits Library enables rapid iterative model development and comparison for Antenna (ANT), Antennal Lobe (AL) and Mushroom Body (MB) circuits across developmental stages. ANTcircuits Modeled after the first layer of the olfactory pathway, the ANTcircuits Library builds upon the Olfactory Transduction (OlfTrans) library (see Section 3.3 below) and describes interactions between odorant molecules and Olfactory Sensory Neurons (OSNs). The library provides parameterized ANT circuits, that support manipulations including</p><list list-type="bullet"><list-item><p>Changing the affinity values of each of the odorant-receptor pairs characterizing the input of the Odorant Transduction Process (<xref ref-type="bibr" rid="bib46">Lazar and Yeh, 2020</xref>),</p></list-item> <list-item><p>Changing parameter values of the Biological Spike Generators (BSGs) associated with each OSN (<xref ref-type="bibr" rid="bib46">Lazar and Yeh, 2020</xref>),</p></list-item> <list-item><p>Changing the number of OSNs expressing the same Odorant Receptor (OR) type.</p></list-item></list><p>ALcircuits Modeled after the second layer of the olfactory pathway, the ALcircuits Library describes the interaction between OSNs in ANT, Projection Neurons in AL and Local Neurons in AL. The library provides parameterized AL circuits, that support manipulations including</p><list list-type="bullet"><list-item><p>Changing parameter values of Biological Spike Generators (BSGs) associated with each of the Local and Projection Neurons,</p></list-item> <list-item><p>Changing the number and connectivity of Projection Neurons innervating a given AL Glomerulus,</p></list-item> <list-item><p>Changing the number and connectivity of Local Neurons in the Predictive Coding and ON-OFF circuits of the AL (<xref ref-type="bibr" rid="bib45">Lazar and Yeh, 2019</xref>).</p></list-item></list><p>MBcircuits Modeled after the third neuropil of the olfactory pathway, the MBcircuits Library describes the expansion-and-sparsification circuit consisting of a population of Antennal Lobe Projection Neurons and Mushroom Body Kenyon Cells (KCs) (<xref ref-type="bibr" rid="bib43">Lazar et al., 2020a</xref>). The library provides a parameterized MB subcircuit involving Kenyon Cells and the Anterior Posterior Lateral (APL) neuron, and supports circuit manipulations including</p><list list-type="bullet"><list-item><p>Generating and changing random connectivity patterns between PNs and KCs with varying degree of fan-in ratio (number of PNs connected to a given KC),</p></list-item> <list-item><p>Changing the strength of feedback inhibition of the APL neuron.</p></list-item></list></sec><sec id="s10-3"><title>3.3 MolTrans library for molecular transduction in sensory encoding</title><p>The Molecular Transduction Library accelerates the development of models of early sensory systems of the fruit fly brain by providing (1) implementations of transduction on the molecular level that accurately capture the encoding of inputs at the sensory periphery, and (2) activity data of the sensory neurons such as electrophysiology recordings for the validation of executable transduction models. The MolTrans Library includes the following packages:</p><list list-type="bullet"><list-item><p><bold>Olfactory Transduction</bold> (<bold>OlfTrans</bold>): Molecular Transduction in Olfactory Sensory Neurons,</p></list-item> <list-item><p><bold>Visual Transduction</bold> (<bold>VisTrans</bold>): Molecular Transduction in Photoreceptors.</p></list-item></list><p>The capabilities of the two libraries are discussed in what follows.</p><sec id="s10-3-1"><title>OlfTrans: Odorant Transduction in Olfactory Sensory Neurons</title><p>The OlfTrans Library (<ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/OlfTrans">https://github.com/FlyBrainLab/OlfTrans</ext-link>) provides the following capabilities (see also <xref ref-type="bibr" rid="bib46">Lazar and Yeh, 2020</xref>):</p><list list-type="bullet"><list-item><p>Defines a model of odorant space for olfactory encoding in the adult and larva olfactory system,</p></list-item> <list-item><p>Hosts a large number of electrophysiology data of OSNs responding to different odorants with precisely controlled odorant waveforms (<xref ref-type="bibr" rid="bib37">Kim et al., 2011</xref>).</p></list-item></list><p>Moreover, the OlfTrans Library offers</p><list list-type="bullet"><list-item><p>The model of an odorant transduction process (OTP) validated by electrophysiology data and executable on Neurokernel/NeuroDriver,</p></list-item> <list-item><p>Algorithms for fitting and validation of OTP models with electrophysiology data of the Olfactory Sensory Neurons,</p></list-item> <list-item><p>Algorithms for importing odorant transduction models and data into NeuroArch and execution on Neurokernel.</p></list-item></list><p>The OlfTrans Library provides critical resources in the study of any subsequent stages of the olfactory system. It serves as an entry point for discovering the function of the circuits in the olfactory system of the fruit fly.</p></sec><sec id="s10-3-2"><title>VisTrans: PhotoTransduction in Photoreceptors</title><p>The VisTrans Library exhibits the following features and/or capabilities (see also <xref ref-type="bibr" rid="bib41">Lazar et al., 2015a</xref>):</p><list list-type="bullet"><list-item><p>A geometrical mapping algorithm of the visual field onto photoreceptors of the retina of the fruit fly,</p></list-item> <list-item><p>A molecular model of the phototransduction process described and biologically validated in <xref ref-type="bibr" rid="bib74">Song et al., 2012</xref>,</p></list-item> <list-item><p>A parallel processing algorithm emulating the visual field by the entire fruit fly retina,</p></list-item> <list-item><p>Algorithms for importing phototransduction models into the NeuroArch Database and for program execution on the Neurokernel Execution Engine.</p></list-item> <list-item><p>Algorithms for visually evaluating photoreceptor models.</p></list-item></list><p>The VisTrans Library accelerates the study of the contribution of photoreceptors towards the overall spatiotemporal processing of visual scenes. It also serves as an entry point for discovering circuit function in the visual system of the fruit fly (<xref ref-type="bibr" rid="bib44">Lazar et al., 2020b</xref>).</p></sec></sec></sec></boxed-text></app><app id="appendix-4"><title>Appendix 4</title><boxed-text><sec id="s11" sec-type="appendix"><title>Creating an interactive executable circuit model of the lamina cartridge</title><p>In this appendix section we walk through an example of creating an interactive executable circuit of the lamina cartridge. The starting point of the example is the connectomic data of a lamina cartridge. Through the example, we will highlight core FlyBrainLab capabilities to load data, to query and analyze data, to create interactive circuit diagram and to execute the resulting circuit.</p><p>The example here is accompanied by a Jupyter notebook available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/Tutorials/blob/master/tutorials/cartridge/Cartridge.ipynb">https://github.com/FlyBrainLab/Tutorials/blob/master/tutorials/cartridge/Cartridge.ipynb</ext-link>. The notebook is intended to be used inside NeuroMynerva. Running the code requires a full FlyBrainLab installation (see Code Availability and Installation), and write access to the NeuroArch server (default for a full installation).</p><p>For simplicity, start a new NeuroArch server connected to an empty database folder that will be populated with the cartridge data. After running ‘start.sh’ to start FlyBrainLab (see also <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab/wiki/How-to-use-FlyBrainLab-Full-Installation">https://github.com/FlyBrainLab/FlyBrainLab/wiki/How-to-use-FlyBrainLab-Full-Installation</ext-link> for instructions), run ‘run_neuroarch.sh lamina lamina’, where the first ‘lamina’ refers to the database folder and the second refers to the dataset name. Start now an NLP server using any of the named applications (such as hemibrain, flycircuit or medulla) by running ‘run_nlp.sh medulla lamina’. Here ‘medulla’ refers to the NLP application name, and ‘lamina’ refers to the dataset name. The latter should match the dataset name of the NeuroArch Server. In NeuroMynerva, configure a new FlyBrainLab workspace, called ‘adult (lamina)’, to connect to the lamina dataset (see <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/FlyBrainLab/wiki/Installation">https://github.com/FlyBrainLab/FlyBrainLab/wiki/Installation</ext-link> for instructions regarding how to add new servers/datasets).</p><p>In NeuroMynerva, start a new FlyBrainLab workspace using the lamina configuration. Connect the Python kernel of the notebook to the kernel of the new FlyBrainLab workspace. The code below is ready to run in the created workspace.<code xml:space="preserve">[1]: import flybrainlab as fbl
         import flybrainlab.query as fbl_query
         import flybrainlab.circuit as circuit 
         import pandas as pd 
         import numpy as np 
         import seaborn as sns 
         %matplotlib inline 
         import matplotlib.pyplot as plt</code></p><p>The following code obtains the FlyBrainLab Client object that is automatically created when launching a new workspace. It also makes sure that NeuroNLP, NeuroGFX and the client object can communicate with each other.<code xml:space="preserve">[2]: client = fbl.get_client() 
         for i in fbl.widget_manager.widgets: 
      if fbl.widget_manager.widgets[i].widget_id not in\ 
          fbl.client_manager.clients[ 
            fbl.widget_manager.widgets[i].client_id
          ]['widgets']: 
        fbl.client_manager.clients[ 
          fbl.widget_manager.widgets[i].client_id
          ]['widgets'].append( 
            fbl.widget_manager.widgets[i].widget_id)</code></p><sec id="s11-1"><title>4.1 Loading the connectome datasets into the NeuroArch database</title><p>Data can be loaded into NeuroArch database from the FlyBrainLab frontend by using the NeuroArch_Mirror class in the query module that mirrors the high-level NeuroArch API.<code xml:space="preserve">[3]: db = fbl_query.NeuroArch_Mirror(client)</code></p><p>We first create a species of <italic>Drosophila melanogaster</italic>:<code xml:space="preserve">[4]: species=db.add_Species(Drosophila melanogaster, 
                stage = 'adult', 
                sex = 'female', 
                synonyms = [
                     'fruit fly',
                     'common fruit fly',
                     'vinegar fly'
                ])</code></p><p>Then we create a data source under the species:<code xml:space="preserve">[5]: data_source = db.add_DataSource(
            'cartridge', 
            version = '1.0', 
            url = 'https://doi.org/10.1016/j.cub.2011.10.022', 
            description = 'Rivera-Alba et al.,\
                  Current Biology 2011', 
            species = list(species.keys())[0])</code></p><p>Make the above data source default.<code xml:space="preserve">[6]: db.select_DataSource(list(data_source.keys())[0])</code></p><p>[FBL NA 2021-01-18 10:53:11,717] Default datasource set</p><p>Add the lamina neuropil.<code xml:space="preserve">[7]: lam = db.add_Neuropil('LAM(L)', 
            synonyms = ['left lamina'])</code></p><p>Create function to read neuron skeleton data:<code xml:space="preserve">[8]: def load_swc(file_name): 
      df = pd.read_csv(file_name, 
            sep = ' ', 
            header = None, 
            comment = '#', 
            index_col = False, 
            names = [
                'sample', 'identifier',
                'x', 'y', 'z', 'r', 'parent'], 
            skipinitialspace = True) 
     return df 
   neuron_list = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6',
        'L1', 'L2', 'L3', 'L4', 'L5', 'T1',
        'a1', 'a2', 'a3', 'a4', 'a5', 'a6',
        'C2', 'C3'] 
   swc_dir = 'swc'</code></p><p>Reading synapse data:<code xml:space="preserve">[9]: connections = pd.read_csv('connection.csv', index_col = 0) 
         neuron_order = connections.columns.to_list() 
         adjacency = connections.to_numpy()</code></p><p>Loading Neuron data into database<code xml:space="preserve">[10]: for neuron in neuron_list: 
      df = load_swc('{}/{}.swc'.format(swc_dir, neuron)) 
      morphology = {'x': (df['x']*0.04).tolist(),
          'y': (df['y']*0.04).tolist(),
          'z': (df['z']*0.04).tolist(),
          'r': (df['r']*0.04).tolist(),
          'parent': df['parent'].tolist(),
          'identifier': [0]*(len(df['x'])),
          'sample': df['sample'].tolist(),
          'type': 'swc'} 
      arborization = [] 
      arborization.append(
        {'type': 'neuropil',
        'dendrites': {
          'LAM(L)': int(connections.loc[neuron].sum())},
        'axons': {
          'LAM(L)': int(connections[neuron].sum())}
        }) 
      db.add_Neuron(neuron, # uname 
          neuron, # name 
          referenceId = neuron, #referenceId 
          morphology = morphology, 
          arborization = arborization)</code></p><p>Loading synapse data into database<code xml:space="preserve">[11]: for post_ind, pre_ind in zip(*np.nonzero(adjacency)): 
            pre_neuron = neuron_order[pre_ind] 
            post_neuron = neuron_order[post_ind] 
           db.add_Synapse(pre_neuron, post_neuron,
           int(adjacency[post_ind][pre_ind]))</code></p></sec><sec id="s11-2"><title>4.2 Building and exploring cartridge pathways</title><p><code xml:space="preserve">[12]: # provide a wild-card regular expression to match all neuron names 
    res1 = client.executeNLPquery('show all')</code></p><p>[FBL NLP 2021-01-18 10:53:34,363] NLP successfully parsed query.</p><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>A lamina cartridge visualized in the NeuroNLP window.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig1-v2.tif"/></fig><p>Obtaining the connectivity matrix between neurons that are displayed in the NeuroNLP window.<code xml:space="preserve">[13]: g = client.get_neuron_graph(synapse_threshold = 0)
    M, order = g.adjacency_matrix() 
    sns.heatmap(M, xticklabels = order, yticklabels = order);</code></p><fig id="app4fig2" position="float"><label>Appendix 4—figure 2.</label><caption><title>The connectivity matrix of the lamina cartridge.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig2-v2.tif"/></fig></sec><sec id="s11-3"><title>4.3 Interactive exploration of the cartridge circuit diagram</title><p>Next, we interactively build an executable circuit using a circuit diagram manually created based on the connectivity above. We construct an ExecutableCircuit object from the NLP query result above. In this case, there is no model associated with these neurons yet. It initializes a new executable circuit.<code xml:space="preserve">[14]: c = circuit.ExecutableCircuit(client, res1, </code></p><p><code xml:space="preserve">                                           model_name = 'cartridge', version = '1.0')</code></p><sec id="s11-3-1"><title>Initializing a new executable circuit</title><p>We then load an SVG circuit diagram manually created and make it interactive through injecting a piece of standardized JavaScript code into the neuGFX widget. These can all be done easily using the ExecutableCircuit API. The first JavaScript file below defines the additional neuron models needed, the PhotoreceptorModel from the VisTrans Library. The second governs the interaction on the diagram in the NeuroGFX window.<code xml:space="preserve">[15]: filename = 'cartridge.svg' 
    jsmodeldef = 'update_available_models.js' 
    jsfilename = 'onCartridgeLoad.js'
    c.load_diagram(filename)
    c.load_js(jsmodeldef)
    c.load_js(jsfilename)</code></p><p>sending circuit configuration to GFX</p><fig id="app4fig3" position="float"><label>Appendix 4—figure 3.</label><caption><title>A circuit diagram of the lamina cartridge.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig3-v2.tif"/></fig><p>Now, we can interact with the diagram to highlight a neuron and its connected neurons, choose the model implementation for each of the cells by right clicking it, single click to silent/rescue the neuron. For example, right clicking on R1 neuron and choose PhotoreceptorModel as its model.</p><fig id="app4fig4" position="float"><label>Appendix 4—figure 4.</label><caption><title>A screenshot of the model library in NeuroGFX for selecting the neuron model and specifying the parameters.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig4-v2.tif"/></fig><p>The same model can be populated to other photoreceptors R2-R6 by sending circuit configuration to GFX<code xml:space="preserve">[16]: c.update_model_like(['R{}'.format(i) for i in range(2,7)], 'R1')</code></p><p>Repeat this for other neurons but use a non-spiking MorrisLecar model. You can update the model and parameters on the diagram or by the code below.<code xml:space="preserve">[17]: c.update_model('L2', {'V1': -20.0,
            'V2': 50.0,
            'V3': -40.0,
            'V4': 20.0,
            'phi': 0.1,
            'offset': 0.0,
            'V_L': -40.,
            'V_Ca': 80.0,
            'V_K': -80.0,
            'g_L': 15.0,
            'g_Ca': 2.0,
            'g_K': 10.,
            'name': 'MorrisLecar'}, 
        states = {'V': -46.08, 'n': 0.3525})

    c.update_model_like(['L1', 'L3', 'L4', 'L5', 'T1',
            'C2', 'C3', 'a1', 'a2', 'a3',
            'a4', 'a5', 'a6'],
            'L2')</code></p><p>sending circuit configuration to GFX</p><p>sending circuit configuration to GFX</p><p>Now we get all the synapses in the circuit. In particular, the photoreceptors express the histamine neurotransmitter that is inhibitory.<code xml:space="preserve">[18]: update_models = {} 
    for rid, v in c.get('Synapse').items(): 
      update_models[v['uname']] = {
        'params': {'name': 'SigmoidSynapse',
            'reverse': -80.0 if \ 
                v['uname'].split('--')[0][0] == 'R'\ 
                else 0,
            'threshold': -50.5,
            'slope': 0.05,
            'gmax': 0.04,
            'scale': c.graph.nodes[rid]['N']
            },
        'states': {'g': 0.0}}
    c.update_models(update_models)</code></p><p>sending circuit configuration to GFX</p><p>Finally, all the neurons and synapses have been configured. We write the executable circuit to the database with name cartridge and version 1.0.<code xml:space="preserve">[19]: c.flush_model()</code></p></sec></sec><sec id="s11-4"><title>4.4 Execution of the model circuit with the neurokernel execution engine</title><p>With the modeling data stored in the database, we can issue commands to execute the circuit in the Neurokernel Execution Engine. First we remove components that have been disabled.<code xml:space="preserve">[20]: res = c.remove_components()</code></p><p>We define the duration and time step of simulation<code xml:space="preserve">[21]: dur = 2.0
    dt = 1e-4
    steps = int(dur/dt)</code></p><p>We then define inputs to the circuit. Here we present a step input from time 0.5 s to 1.5 s at the light intensity equivalent to 10,000 photons per second, to the six photoreceptors. We also specify to return the inputs to the frontend.<code xml:space="preserve">[22]: input_processors = {'LAM(L)':
    [{'class': 'StepInputProcessor',
        'name': 'LAM(L)',
        'module': 'neurokernel.LPU.InputProcessors.StepInputProcessor',
        'variable': 'photon',
        'uids': [c.find_model(c.uname_to_rid['R{}'.format(i)]).
    popitem()[0] for i in range(1,7)],
        'val': 1e4,
        'start': 0.5,
        'stop': 1.5,
        'input_file': 'LAM_input.h5',
        'input_interval': 10}
        ]}</code></p><p>Next, we choose to record responses of the circuit with the ‘Record’ class and specify the variables and components to record. Here we request to return the membrane voltage ‘V’ of all neurons as specified by None in the ‘uids’ field.<code xml:space="preserve">[23]: output_processors = {'LAM(L)':
        [{'class': 'Record',
        'uid_dict': {'V': {'uids': None}},
        'sample_interval': 10}
        ]}</code></p><p>Execute the circuit. The execution will be queued and returned immediately to allow you to further explore the circuit or to work on other circuits while waiting for the execution result.<code xml:space="preserve">[24]: c.execute(input_processors = input_processors, 
        output_processors = output_processors, 
        steps = steps, dt = dt)</code></p><p>[FBL NK 2021-01-18 11:04:35,464] Execution request sent. Please wait.</p><p>[FBL NK 2021-01-18 11:04:35,464] Job received. Currently queued #1</p><p>[FBL GFX 2021-01-18 11:04:51,793] Receiving Execution Result for cartridge/1.0.</p><p>Please wait ...</p><p>[FBL GFX 2021-01-18 11:04:51,883] Received Execution Result for cartridge/1.0.</p><p>Result</p><p>stored in Client.exec result['cartridge/1.0']</p><p>A message like the above will be displayed to notify you that the result for th circuit cartridge/1.0 has been returned. Using the following method, the result will be reorganized to be referenced by the names of the neurons/synapses.<code xml:space="preserve">[25]: result = c.get_result('cartridge/1.0')</code></p><p>Plot the inputs to all photoreceptors and the response of R1 and L1 neurons.<code xml:space="preserve">[26]: client.plotExecResult('cartridge/1.0', outputs = ['R1', 'L1'])</code></p><fig id="app4fig5" position="float"><label>Appendix 4—figure 5.</label><caption><title>Inputs to the photoreceptors used during the execution of a full lamina cartridge circuit.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig5-v2.tif"/></fig><fig id="app4fig6" position="float"><label>Appendix 4—figure 6.</label><caption><title>The output voltage of the R1 photoreceptor and L1 neuron of the lamina cartridge circuit.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig6-v2.tif"/></fig></sec><sec id="s11-5"><title>4.5 Retrieving the executable circuit from the NeuroArch database</title><p>Now let’s clear the workspace and fire the same NLP query as before.<code xml:space="preserve">[27]: res1 = client.executeNLPquery('show all')</code></p><p>[FBL NLP 2021-01-18 11:05:28,105] NLP successfully parsed query.</p><p>This time we can retrieve the executable circuit from the database that we just wrote, using the same methods as before.<code xml:space="preserve">[28]: c = circuit.ExecutableCircuit(client, res1)</code></p><p>Please select from the exisiting models to initialize the executable</p><p>circuit, or</p><p>press a to abort</p><p>0: cartridge version 1.0 (rid #457:0) 0</p><p>#457:0</p><p>Sending circuit configuration to GFX</p><p>We were asked to choose from a list of executable circuits that models the circuit displayed in NeuroNLP window. Here only one such model exists, which is the one we created in Appendix 4.3.</p><p>This time we disable R2-R6, a1-a6, L3 and T1 neurons on the circuit diagram. Equivalently, we can issue the following command: sending circuit configuration to GFX<code xml:space="preserve">[29]: c.disable_neurons(['R{}'.format(i) for i in range(2, 7)] + \
        ['a{}'.format(i) for i in range(1, 7)] + \
        ['L3', 'T1'])</code></p><p>sending circuit configuration to GFX</p><fig id="app4fig7" position="float"><label>Appendix 4—figure 7.</label><caption><title>A lamina cartridge with several ablated neurons.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig7-v2.tif"/></fig><fig id="app4fig8" position="float"><label>Appendix 4—figure 8.</label><caption><title>A reconfigured lamina cartridge obtained by disabling a number of neurons in the interactive circuit diagram.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig8-v2.tif"/></fig><p>And then reflect this change in the database before executing it.<code xml:space="preserve">[30]: res = c.remove_components()</code></p><p><code xml:space="preserve">[31]: dur = 2.0
    dt = 1e-4
    steps = int(dur/dt) 

    input_processors = {'LAM(L)':
        [{'class': 'StepInputProcessor',
        'name': 'LAM(L)',
        'module': 'neurokernel.LPU.InputProcessors.StepInputProcessor',
        'variable': 'photon',
        'uids': [c.find_model(c.uname_to_rid['R1']).popitem()[0]],
        'val': 1e4,
        'start': 0.5,
        'stop': 1.5,
        'input_file': 'LAM_input.h5',
        'input_interval': 10}
        ]} 
    output_processors = {'LAM(L)':
        [{'class': 'Record',
        'uid_dict': {'V': {'uids': None}},
        'sample_interval': 10}
        ]}</code></p><p><code xml:space="preserve">[32]: c.execute(input_processors = input_processors, 
    output_processors = output_processors, 
    steps = steps, dt = dt)</code></p><p>[FBL NK 2021-01-18 11:18:47,961] Execution request sent. Please wait.</p><p>[FBL NK 2021-01-18 11:18:47,962] Job received. Currently queued #1</p><p>[FBL GFX 2021-01-18 11:19:05,231] Receiving Execution Result for cartridge/1.0.</p><p>Please wait …</p><p>[FBL GFX 2021-01-18 11:19:05,280] Received Execution Result for cartridge/1.0.</p><p>Result stored in Client.exec_result[’cartridge/1.0’]<code xml:space="preserve">[33]: result = c.get_result('cartridge/1.0')</code></p><p>Finally, we plot the input to the R1 neuron and the responses of the R1 and L1 neurons. Here, the L1 neuron only receives input from 1 photoreceptor as compared to 6 in Appendix 4.4.<code xml:space="preserve">[34]: client.plotExecResult('cartridge/1.0', outputs = ['R1', 'L1'])</code></p><fig id="app4fig9" position="float"><label>Appendix 4—figure 9.</label><caption><title>Input to the photoreceptor in the reconfigured lamina cartridge circuit.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig9-v2.tif"/></fig><fig id="app4fig10" position="float"><label>Appendix 4—figure 10.</label><caption><title>Voltage responses of the R1 photoreceptor and L1 neuron of the reconfigured lamina cartridge circuit.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62362-app4-fig10-v2.tif"/></fig></sec></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.62362.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Gleeson</surname><given-names>Padraig</given-names> </name><role>Reviewer</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>FlyBrainLab is a resource for driving connectomic analyses of the <italic>Drosophila</italic> brain and for carrying out computational modeling based on multiple data sources. It supports 3D visualization of datasets published in the worldwide literature, and a number of libraries for integrating anatomical, sensory and physiological data with published and exploratory computational models. It will be useful for a wide range of activities, from exploring the content and intersection of datasets, to comparing circuit models in the same computational setting, to running massively parallel circuit simulations.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;FlyBrainLab:Accelerating the Discovery of the Functional Logic of the <italic>Drosophila</italic> Brain in the Connectomic/Synaptomic Era&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Ronald Calabrese as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Padraig Gleeson (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional experiments are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>This manuscript outlines the FlyBrainLab platform, which brings together a number of software packages from the authors to provide a unified interface for viewing data and simulating neuronal activity related to <italic>Drosophila</italic>. The reviewers felt that the paper had promise but there was substantial work still to be done.</p><p>Essential revisions:</p><p>1) Could the authors provide substantially more detail on how an experimentalist would use the package? It should be clear why they would want to do so.</p><p>2) The manuscript must provide transparency on the data processing and</p><p>integration.</p><p>3) The package would be far more user-friendly if it had much simpler installation. Detailed instructions would help too.</p><p>4) Users would benefit from a process to keep the packages up-to-date, such as for the “hemibrain” module.</p><p>In addition, the reviewers have provided many helpful comments to help the authors with their revision.</p><p><italic>Reviewer #1:</italic></p><p>This manuscript outlines the FlyBrainLab platform, which brings together a number of software packages from the authors to provide a unified interface for viewing data and simulating neuronal activity related to <italic>Drosophila</italic>.</p><p>The application is well described and examples of its use are given. The code for the application components is open source and installation instructions and documented are provided. The suite of components clearly work well together providing a very good example of a user focussed computational neuroscience application for working with advanced data and models.</p><p>1) While much of the technical/implementation detail is reserved for the Materials and methods section, the main body of the manuscript would benefit from a high level diagram of the structure of the application (like Supplementary figure 1, or even simpler), or a table defining/summarising the various components mentioned in the main text (NeuroMinerva/CxCircuit/NeuroArch etc.) and how they related to each other.</p><p><italic>Reviewer #2:</italic></p><p>FlyBrainLab by Lazar et al. provides the ability to set up, execute, and analyze <italic>Drosophila</italic> neural circuits, while integrating/exploring connectomics data, in a single platform. Such a unified framework has the potential to advance our understanding of the functional logic of the fly brain. The authors show that FlyBrainLab tools can be used to execute models developed previously in the literature. What is missing, however, is a clear demonstration that the platform can be used for de novo exploration and guidance on how the tools offered by the platform will enable new discoveries. In particular, the case is not made that using this library provides an easier path to discovery than the normal ad-hoc approach. The work does not fully describe what a user needs to do to deploy it for their own studies, nor does it clearly show how its own examples were generated.</p><p>1) Across the circuit examples supplied in the manuscript, it is not clear what features need to be manually coded up for the particular circuit/question of interest vs. what features can be pulled from FlyBrainLab and directly used. At present, the discussion of the different libraries in the supplement lists capabilities, but there is no guidance or examples of how the libraries can be used in practice. We could not find documentation for CXcircuits, EOScircuits, and MolTrans online. Similarly, the supplementary video illustrates the interactive capabilities of the platform, but the manuscript does not guide the user in replicating these capabilities on their own. To fix this, we advise the authors to include the notebooks used to generate all of the figures/analysis in the main results as supplementary files, with detailed annotation so that a user can use them as starting points for their own analyses.</p><p>2) More must be included in the manuscript to describe how the tool can be used for exploratory analysis. Consider including a simple annotated code walkthrough that, starting with some list of neurons, perhaps from the Hemibrain, answers what utilities are available/what code is needed to visualize neuron morphologies, what code is needed to generate an interactive circuit diagram, what code is needed to set up a simple leaky integrate and fire model, what is needed to execute a circuit, and whether resultant firing rate outputs look reasonable. The panels in Supplementary figure 3 are close, but they show the results of the above workflow, and there is no demonstration on how one can get there. Such an example need not (and perhaps is better not to) focus on a well-characterized circuit. The simple examples found in FlyBrainLab/Neuroballad are promising.</p><p>3) More work can be done to lower the barrier of entry for FlyBrainLab. Even as a researcher with a few years of Python experience that is currently using the Hemibrain to set up, run, and analyze neural circuits, I had difficulty installing FlyBrainLab and knowing what steps to take to replicate the examples shown in the manuscript. In particular, the installation instructions seem inconsistent/not fully developed on https://github.com/FlyBrainLab/FlyBrainLab. It took hours to figure out which instructions to follow to end up with a Jupyter Lab configuration that resembles the supplementary video, with a notebook, a morphology viewer, and a circuit viewer in the same window. The installation instructions within NeuroMinerva, built on JupyterLab version &gt;2, helped get me to that point, but the instructions on FlyBrainLab, built on JupyterLab version &lt;2, did not get me to that point. In addition, the &quot;Starting Up FlyBrainLab&quot; section on https://github.com/FlyBrainLab/FlyBrainLab should have material on what to do if you do not see an FFBO section or cannot run the example notebook, perhaps in some troubleshooting page.</p><p><italic>Reviewer #3:</italic></p><p>Lazar and colleagues present a platform, FlyBrainLab that integrates <italic>Drosophila</italic> neuron and circuit modelling data with neuroanatomy, from morphology to synaptic resolution information. Their desktop system is modular and stand-alone, providing the ability to query, run and visualise particular circuits and models. To demonstrate the functionality of their platform they present 3 specific examples that cover the use of published models, light and electron-microscopy (EM) data and the comparison between larva and adult.</p><p>Although the need their platform is addressing is real, the manuscript does not present the work in a compelling way, particularly for this journal's audience. Furthermore, the methods used to integrate data, and how data are used are not described properly. If a system such as this aims to become a standard analytical tool for neuroscientists, it is essential that data integration and processing are transparent.</p><p>Please find below a number of concerns. I do not comment on the technical details of the FlyBrainLab platform modules, as that is not my expertise.</p><p>1) The structure of the manuscript and the way the examples are presented are not compelling for the average neuroscientist that wants to start using the public data (models, connectome and synaptome). Especially if the one of the main draws of this type of platform is for neuroscientists to start testing models based on real data. The main reason for this is that very little information is given on how experimental data is curated and integrated (see below for more).</p><p>2) What neuroanatomical data is being used and in what way is completely opaque. It is assumed that different modalities of data will have been processed in different ways, but very little information is given in this regard. How is the light-level FlyCircuit data processed to infer connectivity and how is this process validated? How are cell types identified and validated, in FlyCircuit and the hemibrain? How many neurons and types are used for each use case?</p><p>For example, regarding the CX circuit example, the authors say, &quot;The innervation pattern of each neuron was visually examined in the NeuroNLP window and a standard name assigned according to the naming scheme adopted in the CXcircuit Library.&quot; How do these standard names relate to the cell type names used by the community? Identifying cell types from morphological data requires expertise when this is done to the highest resolution, and thus this process should be described in detail. In addition, it becomes very difficult to assess the use cases presented when there is no clarity on what neurons and types are being used.</p><p>3) Related to the point above, the authors list the hemibrain data used is from version 1.0.1 (gs://hemibrain-release/neuprint/hemibrain_v1.0.1_neo4j_inputs.zip). However, a new version of the data (1.1) was released online in May, with the data dumps available at least from the end of June (according to https://dvid.io/blog/release-v1.1/). The latest version significantly improves the cell typing that had been released (see https://docs.google.com/document/d/1vae3ClHR8z8uekqwrOHtqiux3oY5-Y_xw6W2srCi3PI/edit?usp=sharing). The authors should update their manuscript to use the latest version of data. This should highlight issues of how data can be kept up to date in these types of platforms and how integration of versions can be achieved. The authors should comment on the processes they use for this.</p><p>4) Presenting this platform as a Resource, it becomes essential that it is easy to install. I attempted to install FlyBrainLab according to the instructions in https://github.com/FlyBrainLab/FlyBrainLab. Using miniconda on macOS, which I already had installed for other purposes, I unfortunately ran into errors, and the installation was unsuccessful (seemingly caused by msgpack not being found). The instructions mention that the platform has only been tested in Ubuntu but that it &quot;should work&quot; in other platforms. I understand that it is not possible to test for and avoid, all possible errors, but the authors should test the installation in at least one other OS, if they want the average neuroscientist to start using it.</p><p>The tutorials listed in https://github.com/FlyBrainLab/Tutorials are certainly a very useful introduction, although they suffer from the issues in points 2 and 3.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Accelerating with FlyBrainLab the Discovery of the Functional Logic of the <italic>Drosophila</italic> Brain in the Connectomic Era&quot; for consideration by <italic>eLife</italic>. Your article has been overseen by a Reviewing Editor and Ronald Calabrese as the Senior Editor.</p><p>The Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional work is required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>The revised manuscript has addressed some of the technical issues, but has not addressed the core issues of readability of the manuscript , and usability of the software, by a regular fly neurobiologist. This was stated in the Essential revisions, point 1: &quot;1. Could the authors provide substantially more detail on how an experimentalist would use the package? It should be clear why they would want to do so.&quot;</p><p>While the authors have responded with some limited explanations in the cover letter, the required changes are not evident in the manuscript, and it is there that these essential points of usability must be clarified. Again, it is not sufficient to refer the reader to the website to do this. The appendices, and much of the text, still mostly tell the reader what can be done, rather than how to do it. This should be rather early in the manuscript to motivate what follows.</p><p>Similarly, on essential point 2, the reviewers would like to know how their data goes in and is manipulated, and how they can be confident that what the program does is faithful to the original. Issues of installation, which have been presented, are relevant, but of secondary technical importance.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Accelerating with FlyBrainLab the Discovery of the Functional Logic of the <italic>Drosophila</italic> Brain in the Connectomic Era&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Ronald Calabrese as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Padraig Gleeson (Reviewer #1); Danylo Lavrentovich (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential Revisions:</p><p>The reviewers and I felt that the paper and FlyBrainLab provide a userful resource for the field. The revised version is considerably improved and the reviewers would like to suggest a few essential but straightforward revisions to make it even more accessible to the readers and users of this resource.</p><p>1) Update key references (indicated in the detailed reviews).</p><p>2) Clarify Figures and their legends, especially Figure 2 and 3.</p><p>There are several further important suggestions by the reviewers to strengthen the presentation and improve the accessibility of the paper and resource for readers. These are provided in the detailed reviewer comments below.</p><p><italic>Reviewer #1:</italic></p><p>This new version of the manuscript has a better layout and will be a more useful introduction to the application for new users. However there are still some issues with how the structure of the application is presented which may be difficult for readers.</p><p>Figure 2, especially the legend is quite minimal and there is nothing here to give a reader the key idea that this is a graphical application which a user would interact with through their browser. I suggest to move the screenshot of the application from Appendix 1—figure 2 to a panel in the main figure 2, and make sure these panels are well integrated and explained, e.g. NeuroMynerva in the top panel is what you see in the bottom. Refer the reader here to Appendix 1—figure 1 for more details (some of the colors of the blocks match between the simplified/full versions, e.g. green NeuroArch, there's no reason they all shouldn't for ease of readability).</p><p>NeuroNLP and NeuroGFX (window) are mentioned in the text without any context. These need to be shown/explained in Figure 2 and also described briefly where NeuroMynerva etc. are first defined in the Introduction. I would suggest highlighting all important component names in bold where they are first introduced so a user can go back to the definition as they are discussed later in the text.</p><p>It is strange that the actual short English language queries used for Figure 3 are not mentioned in the legend or main text. This is an important feature of the application and adding (at least some of) the sequence of commands for one of the panels (e.g. 3a, &quot;show T4a&quot;, &quot;color red&quot;, &quot;add cholinergic presynaptic neurons&quot; etc.) in another panel/table in the figure would be quite informative for readers. In the main text &quot;(see also Materials and methods)&quot; could be replaced with something better like: (the full sequence of queries which created this panel can be found in the Materials and methods). Also explain that the panels in Figure 3 are screenshots of the NeuroNLP window in Figure 2B, etc.</p><p>It is good having a section in the Materials and methods for each of other figures related to the main use cases/examples, but these could be tied together better also, making it clearer that the details of how the figure panels were generated can be found in the Materials and methods. Also some parts of the Materials and methods do not refer back to the figures, e.g. &quot;Model A [26], Model B [27] and Model C [28]&quot; could refer to Figure 6A, B, C etc. Small things like this would improve the readability of the paper significantly.</p><p>It might also be worth numbering the use cases/analysis types, e.g. Use Case 1-6, and adding these to subheadings to make it easier to move between the main text and Materials and methods.</p><p>Overall the manuscript is a good introduction to the range of features FlyBrainLab offers and is structured such that a user can see what can be accomplished, and is given some guidance how they would achieve it themselves.</p><p><italic>Reviewer #2:</italic></p><p>The text is clearer and more inviting for a general audience. The enumeration of capabilities in the Introduction is effective. The Results section is structured well, displaying different use cases of FlyBrainLab. The accompanying tutorials online serve as good launching points for researchers.</p><p>Thank you to the authors for the additions in the main text, the code walkthroughs in the appendices, and the improved installation instructions. The basic tutorials are simple to follow. My only suggestion on the code side is to be more verbose in the introduction to the lamina cartridge executable circuit notebook and in the limitations of the user-side-only installation.</p><p><italic>Reviewer #3:</italic></p><p>The revised version of the manuscript addresses many of the concerns previously reported. Thank you to the authors for providing much clearer information about the data that is ready to use in the FlyBrain Lab platform, how it can be used, installed and the components of the FlyBrainLab. There are still some corrections that are needed regarding the source of some of the datasets.</p><p>Throughout the paper, reference 4 (Xu et al., 2020) is used as the citation for the hemibrain dataset. This is a preprint that has been superseded by the publication in September 2020 of the peer-reviewed paper (Scheffer et al., 2020, https://doi.org/10.7554/<italic>eLife</italic>.57443). It also needs updating in GitHub (https://github.com/FlyBrainLab/Datasets#ref-1)</p><p>The reference to the larval L1EM dataset also needs correcting. For example this is given as reference 2 (Berck et al., 2016). The correct reference, as correctly shown in https://github.com/FlyBrainLab/Datasets#ref-3, is Ohyama et al., 2015 (reference 69). There might be other instances in the text that use the wrong citation.</p><p>The section added to the beginning of the Results, which includes Figure 3, provides readers with some examples on how they can start exploring the data in the platform (published datasets) using plain English queries. However, I do not think the added Figure 3 currently presents the data in a way that makes it easy for readers to link the relevant text and figure legend that describe the connectivity, to the panels. Each of the 4 examples (a-d) displays a neuron plot (left) and a connectivity matrix (right); other than reading each of the row/column names it is not possible to link the neurons plotted on the left to the data plotted on the right. Adding a colored annotation bar or even coloring the row/column names of the connectivity matrices according to the neuron plots would certainly help, or perhaps adding some clustering.</p><p>Example 2 refers to a possible direct connection between the mushroom body and the fan-shaped body (&quot;raising the question whether the two memory centers are directly connected&quot;). Some of the neurons directly connecting these 2 neuropils (and possible pathways for visual information in addition to reference 17), have been described already, in Li et al., 2020 (December 2020, https://doi.org/10.7554/<italic>eLife</italic>.62576), one of the recent papers based on the hemibrain dataset. Could the authors please rephrase?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.62362.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Could the authors provide substantially more detail on how an experimentalist would use the package? It should be clear why they would want to do so.</p></disp-quote><p>The FlyBrainLab platform has a number of capabilities that can be used by experimentalists with widely different backgrounds in computing.</p><p>a) For experimentalists with limited programming experience, the platform can be used for extensive visualization, interactive search and building of simple brain circuits of interest. The FlyBrainLab interactive capabilities only require here basic knowledge of terminology in neurobiology. The user interacts with the UI through natural language queries without the need to go through button-clicking or to learn a new, sophisticated database query language. For example, the NeuroNLP Window (see Appendix 1—figure 2) supports the construction of novel brain circuits (not just displaying individual neuron/cell types) on the morphological level of abstraction. Simple utilities enable the graphical display of connectivity diagrams (graphs). The neurons displayed can be subsequently targeted for genetic manipulation, optogenetic ablation and/or recording. As these properties are not the main focus of our manuscript, we created a notebook to guide the user through the use of English queries and illustrate its effectiveness.</p><p>b) Experimentalists with some computer background, say Python programming, have the capability to explore and analyze novel circuits as demonstrated in Figure 6. The level of computing knowledge required is akin to Matlab programming. Here, the exploration and analysis of yet unknown brain circuits may be of interest. For example, if the experimentalist has detailed morphology and/or neural activity data of a cell of interest, he/she can build with FlyBrainLab a circuit containing post and presynaptic neurons and computationally analyze the circuit connectivity and the effect of neuron ablation on its function. The same effect can often be evaluated by experimental means, say by optogenetic ablation of neurons suggested by the computational model. The same methodology can be followed through when choosing a circuit initially investigated in the literature. FlyBrainLab immediately extends the capabilities to visualize and evaluate the functionality of a chosen circuit in a larger context than previously published. In addition, the user can benefit from the Circuit Libraries written by more computationally-advanced users. Since FlyBrainLab bridges the gap between fly brain data and executable circuits, interactive computational models are much easier for an experimentalist to explore than an ad-hoc program. This is clearly reflected in the CX example depicted in Figure 3 where multiple windows synchronize morphology visualization data with circuits diagrams. Furthermore, these libraries provide an easier path for experimentalists to computationally explore the circuits under study and to validate or invalidate models using collected data. For example, users can intuitively silence neurons using an interactive circuit diagram (rather than digging into someone’s code) and compare its response to a recorded circuit where the same neuron is silenced genetically. Ultimately, the exact mechanism underlying the function of brain circuits is what is largely lacking.</p><p>c) Experimentalists with more advanced computational neuroscience background, can take full advantage of the capabilities to generate circuit diagrams, and run parallel programs with Neurokernel on GPUs. In this scenario, the experimentalist goes well beyond what is possible today on the bench. The key reason is scaling. An arbitrary number of interconnected neuropils of interest implemented by the same or different research groups can be interconnected and structurally and functionally explored, as these circuit models are also represented in the NeuroArch Database and can be easily retrieved for execution. Scaling circuits say by considering larger and larger brain regions, is clearly of paramount importance in the quest of understanding the logic of brain function. As in classical Computer Science, the question of scaling leads to deep questions of complexity. Here, the FlyBrainLab offers a platform for accelerating the discovery of the functional logic of the <italic>Drosophila</italic> brain something ad-hoc methods cannot deliver. By analogy, we can of course build cars in a garage, but in order to accelerate the building of cars, the car makers moved on long time ago to the assembly line.</p><p>To lower the bar of entry for systems and computational neuroscientists, we now provide a number of tutorials online at <ext-link ext-link-type="uri" xlink:href="https://github.com/FlyBrainLab/Tutorials">https://github.com/FlyBrainLab/Tutorials</ext-link> organized along the technical proficiency required. We are aware, however, that we do not/cannot accommodate the needs of all the users in the neuroscience research community interested in using the FlyBrainLab computing platform.</p><disp-quote content-type="editor-comment"><p>2) The manuscript must provide transparency on the data processing and</p><p>integration.</p></disp-quote><p>We would like to stress that FlyBrainLab is not positioned as a data provisioning platform, but rather a computing platform that provides utilities to visualize fly brain data and explore, analyze, evaluate and compare executable circuit models in a common environment.</p><p>To evaluate the transparency of the data integration and circuit execution capabilities presented here clearly requires that users have FlyBrainLab fully operational. We strongly recommend that if, for whatever reason, the reviewers run into installation problems, they contact us through the editors. In this context, we would like to emphasize that the complexity of FlyBrainLab platform is well beyond what has been typically attempted in the past computational neuroscience literature. The complexity involved is reminiscent to that of an operating system where processes running on a CPU (Neurokernel) interact with a database (NeuroArch) and are flexibly invoked by the UI through NeuroMynerva.</p><p>To further enhance the transparency of the computing platform, we included 2 new figures into the manuscript:</p><p>a) Figure 2 in the Introduction section gives an overview of the main components and hints at the complexity of the overall FlyBrainLab architecture.</p><p>b) Figure 6 in the Results section demonstrates the capability to effectively explore the structure and function of yet to be discovered brain circuits.</p><p>Figure 2 and Appendix 1—figure 1 and 2 help clarify the complexity of the FlyBrainLab architecture. Understanding the underlying design choices of the systems architecture of FlyBrainLab was previously detailed in papers describing the NeuroArch (Givon et al., 2015: http://dx.doi.org/10.5281/zenodo.44225) and Neurokernel (Givon and Lazar, 2016: https://doi.org/10.1371/journal.pone.0146581) components. The NeuroMynerva user-side front end, built on top of JupyterLab is new. We are avoiding listing more details here as they are too technical. They are of course available on Github.</p><p>We included now a number of tutorials to help the user take advantage of the Circuit and Utility libraries. Detailed notebooks provide users with an overview and a number of examples how to invoke the libraries. For example, we published the CXcircuits Library at https://github.com/FlyBrainLab/CXcircuits, and included notebooks for each of the three CX models analyzed in the main text. In addition, the notebooks and libraries of the other figures/results will be published once the paper is accepted. They will be listed in the “Publications and Talks” and ”Libraries” sections of the FlyBrainLab Wiki page https://github.com/FlyBrainLab/FlyBrainLab/ wiki/FlyBrainLab-Resources.</p><p>Although we do not consider the content of the datasets as being central to capabilities of FlyBrainLab as a computing tool, we welcome the use of our platform with (not instead of) other data provision platforms and have provided examples of how FlyBrainLab can be used with new datasets (https://github.com/FlyBrainLab/Tutorials/blob/ master/tutorials/swc_loading_tutorial/swc_loading.ipynb) However, in order to demonstrate the capabilities of FlyBrainLab to work with a wide range of datasets, we’ve included several publicly available datasets (listed and tracked in the FlyBrainLab Wiki) in the default FlyBrainLab package, which have been loaded into the NeuroArch database with minimal changes (apart from formatting edits for compatibility with the NeuroArch schema, which is specified in Givon et al., 2015 (http://dx.doi. org/10.5281/zenodo.44225)). Notebooks for loading these datasets into NeuroArch databases are provided in https://github.com/FlyBrainLab/datasets.</p><disp-quote content-type="editor-comment"><p>3) The package would be far more user-friendly if it had much simpler installation. Detailed instructions would help too.</p></disp-quote><p>We substantially improved upon and taken the installation process to the next level.</p><p>a) We corrected, and significantly expanded the installation instructions at https: //github.com/FlyBrainLab/FlyBrainLab, and added a Wiki page for troubleshooting (https://github.com/FlyBrainLab/FlyBrainLab/wiki/Troubleshooting).</p><p>b) We now provide multiple installation options for users of different expertise: 1) using a script, 2) using our docker image, and 3) using an Amazon AWS machine image. All these options typically only require a single command line for installation and a single command line for starting the application. We also clearly listed the system requirements for each installation option. Dependencies are fully described in the installation scripts.</p><p>c) We tested the installation procedure on Linux (Ubuntu and CentOS), macOS and Windows.</p><p>d) We asked a diverse range of users, including colleagues, collaborators, undergraduate students to test the installation and received positive feedback.</p><p>e) We created a number of “get started” tutorials to guide through the basic features of the system (https://github.com/FlyBrainLab/Tutorials/tree/master/ tutorials/getting_started).</p><p>f) We now provide users more information about available resources (https:// github.com/FlyBrainLab/FlyBrainLab/wiki/FlyBrainLab-Resources), including i) a list of the latest version of the components, and ii) a list of publicly available datasets that we loaded into the NeuroArch database.</p><disp-quote content-type="editor-comment"><p>4) Users would benefit from a process to keep the packages up-to-date, such as for the “hemibrain” module.</p></disp-quote><p>For installation purposes, we have published and will keep updating a list of the latest versions of all FlyBrainLab components https://github.com/FlyBrainLab/ FlyBrainLab/wiki/FlyBrainLab-Resources#repositories. The installation scripts provide the version number of the dependencies whenever applicable.</p><p>For datasets loaded into the NeuroArch Database, we</p><p>a) Provided a Datasets Version Tracker https://github.com/FlyBrainLab/datasets, that also includes the latest Hemibrain dataset,</p><p>b) Published the code/notebooks used to load the NeuroArch Database with different datasets, thereby helping users to load the NeuroArch Database independently of the main developers,</p><p>c) Will periodically and timely update the database, and welcome community contributions.</p><disp-quote content-type="editor-comment"><p>In addition, the reviewers have provided many helpful comments to help the authors with their revision.</p><p>Reviewer #1:</p><p>This manuscript outlines the FlyBrainLab platform, which brings together a number of software packages from the authors to provide a unified interface for viewing data and simulating neuronal activity related to <italic>Drosophila</italic>.</p><p>The application is well described and examples of its use are given. The code for the application components is open source and installation instructions and documented are provided. The suite of components clearly work well together providing a very good example of a user focussed computational neuroscience application for working with advanced data and models.</p><p>1) While much of the technical/implementation detail is reserved for the Materials and methods section, the main body of the manuscript would benefit from a high level diagram of the structure of the application (like Supplementary figure 1, or even simpler), or a table defining/summarising the various components mentioned in the main text (NeuroMinerva/CxCircuit/NeuroArch etc.) and how they related to each other.</p></disp-quote><p>Thank you for the suggestion! We added a new figure (Figure 2) to the manuscript to provide an early overview of the main FlyBrainLab components, i.e., NeuroArch, Neurokernel and NeuroMynerva. As suggested by the reviewer, Figure 2 is a simpler version of Appendix 1—figure 1. It provides an overview of the main datasets currently available in NeuroArch, and the circuit execution capabilities supported by Neurokernel. To put the FlyBrainLab components in a better context, we also added text relating the levels of abstraction underlying Figure 2 and Appendix 1—figure 1.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>FlyBrainLab by Lazar et al. provides the ability to set up, execute, and analyze <italic>Drosophila</italic> neural circuits, while integrating/exploring connectomics data, in a single platform. Such a unified framework has the potential to advance our understanding of the functional logic of the fly brain. The authors show that FlyBrainLab tools can be used to execute models developed previously in the literature. What is missing, however, is a clear demonstration that the platform can be used for de novo exploration and guidance on how the tools offered by the platform will enable new discoveries. In particular, the case is not made that using this library provides an easier path to discovery than the normal ad-hoc approach. The work does not fully describe what a user needs to do to deploy it for their own studies, nor does it clearly show how its own examples were generated.</p></disp-quote><p>We thank the reviewer for the constructive comments on the manuscript. At the end of the Results section, we now present several examples and ways for exploring an unknown circuit by expanding upon the Supplementary figure 3 of the original submission.</p><p>What FlyBrainLab offers may not be an easier path to discovery, but certainly a faster one. What does a car assembly line provide? Does one still need to design a car? Yes, and it’s a difficult problem. But assembly line makes the production much faster. Similarly, FlyBrainLab provides an essential workflow for building circuits from data, visualizing circuits, comparing existing models within the same platform, interactively manipulating circuits, creating new models that can all be completed within a single environment that provides the much needed integration to accelerate discoveries. Furthermore, we have substantially expanded the tutorials https://github.com/FlyBrainLab/Tutorials, specifically https://github.com/FlyBrainLab/Tutorials/tree/master/tutorials/getting_started to get users started with all aspects of the FlyBrainLab. Notebooks for the CX example have been published, and the notebooks for the other results in the manuscript will be published once the paper is accepted for publication.</p><p>The reviewer seems to suggest that comparison between models is not a novel exploration of circuit function. We argue the opposite. Comparison of models in the literature is one of the keys for an in-depth understanding of the exact assumptions, structure and function of the published models, operating under the same setting/environment. This is how fields like machine learning, signal processing, computer vision thrive, where comparisons and being able to run every line of code is a standard practice. However, this is not the norm in systems neuroscience and computational neuroscience, with very few exceptions (see this paper https://doi.org/10.1523/JNEUROSCI.3374-12.2013 for an example). In the two examples involving early olfactory circuits, we do not just “execute models developed previously in the literature”. Rather, the models considered have been adapted to new contexts to explore the function of the circuits under consideration, either due to the more precise connectivity information brought by the Hemibrain dataset, or due to a downsizing of the larva circuit. We consider these also as de novo exploration of the functional logic of the underlying circuits.</p><disp-quote content-type="editor-comment"><p>1) Across the circuit examples supplied in the manuscript, it is not clear what features need to be manually coded up for the particular circuit/question of interest vs. what features can be pulled from FlyBrainLab and directly used. At present, the discussion of the different libraries in the supplement lists capabilities, but there is no guidance or examples of how the libraries can be used in practice. We could not find documentation for CXcircuits, EOScircuits, and MolTrans online. Similarly, the supplementary video illustrates the interactive capabilities of the platform, but the manuscript does not guide the user in replicating these capabilities on their own. To fix this, we advise the authors to include the notebooks used to generate all of the figures/analysis in the main results as supplementary files, with detailed annotation so that a user can use them as starting points for their own analyses.</p></disp-quote><p>We thank the reviewer for this suggestion. To address the concern raised, we published the CXcircuits Library at https://github.com/FlyBrainLab/CXcircuits, and included notebooks for each of the three CX models analyzed in the main text. The notebooks are mentioned in the revised manuscript. To avoid duplication, we chose to publish the code directly on GitHub instead of using supplementary manuscript files. In this way, the code can constantly be updated to include new features and users can benefit from the most up-to-date version. We also note that the exact commit provides access to the code for reproducing the figures/results of the manuscript.</p><p>In addition, the notebooks and libraries of the other figures/results will be published once the paper is accepted. They will be listed in the “Publications and Talks” and ”Libraries” sections of the FlyBrainLab Wiki page https://github.com/FlyBrainLab/FlyBrainLab/wiki/ FlyBrainLab-Resources.</p><p>We would like to take this opportunity to further clarify the current division of the roles taken by FlyBrainLab platform and its Libraries.</p><p>The main components of the FlyBrainLab, as described in the Appendix 1, provide core functionalities required for data storage/retrieval, visualization, user interface and code execution of brain circuits. Examples of capabilities that users can directly invoke are given below:</p><p>1) Query using plain English and 3D graphics for building and visualizing brain circuits;</p><p>2) Retrieval of connectivity of the brain circuit built/visualized;</p><p>3) User interface and API for circuit diagram interaction;</p><p>4) Specification of models for each circuit components.</p><p>5) Execution of the circuits represented/stored in the NeuroArch Database.</p><p>The Utility Libraries provide tools for 1. analyzing data that are retrieved using the core FlyBrainLab functionality, 2. creating circuit diagrams semi-automatically.</p><p>The Circuit Libraries are built on top of the core FlyBrainLab functionality and provide tools to study functions of a specific brain region/circuit. An analogy of the relation between Circuit Libraries and the FlyBrainLab platform is that between the toolboxes and core functions of Matlab. In Matlab, the former provide high-level, application-specific functionality realized with some of the core built-in functions (such as a digital signal processing toolbox). In other words, the Circuit Libraries are examples of how the features of FlyBrainLab can/should be used.</p><disp-quote content-type="editor-comment"><p>2) More must be included in the manuscript to describe how the tool can be used for exploratory analysis. Consider including a simple annotated code walkthrough that, starting with some list of neurons, perhaps from the Hemibrain, answers what utilities are available/what code is needed to visualize neuron morphologies, what code is needed to generate an interactive circuit diagram, what code is needed to set up a simple leaky integrate and fire model, what is needed to execute a circuit, and whether resultant firing rate outputs look reasonable. The panels in Supplementary figure 3 are close, but they show the results of the above workflow, and there is no demonstration on how one can get there. Such an example need not (and perhaps is better not to) focus on a well-characterized circuit. The simple examples found in FlyBrainLab/Neuroballad are promising.</p></disp-quote><p>Thank you for your suggestion. We substantially expanded upon the exploratory example in Supplementary figure 3 and moved it to the end of the Results section. It appears now as Figure 6 in the subsection entitled “Exploring the Structure and Function of Yet to be Discovered Brain Circuits”. Three examples are described that demonstrate the use of the Utility Libraries in the quest of novel discoveries.</p><p>Furthermore, we have substantially expanded upon the online documentation and tutorials. We have added notebooks showing examples in each of the main steps of the workflow, including:</p><p>1) How to ask questions in English to obtain a list of neurons of interest (including visualizing their morphology) and how to build upon an initial set of neurons,</p><p>2) How to generate circuit diagrams,</p><p>3) How to interact with the circuit diagram layout, build a model and execute it, obtain the result and plot the response.</p><p>We will continue to release more examples in the future.</p><disp-quote content-type="editor-comment"><p>3) More work can be done to lower the barrier of entry for FlyBrainLab. Even as a researcher with a few years of Python experience that is currently using the Hemibrain to set up, run, and analyze neural circuits, I had difficulty installing FlyBrainLab and knowing what steps to take to replicate the examples shown in the manuscript. In particular, the installation instructions seem inconsistent/not fully developed on https://github.com/FlyBrainLab/FlyBrainLab. It took hours to figure out which instructions to follow to end up with a Jupyter Lab configuration that resembles the supplementary video, with a notebook, a morphology viewer, and a circuit viewer in the same window. The installation instructions within NeuroMinerva, built on JupyterLab version &gt;2, helped get me to that point, but the instructions on FlyBrainLab, built on JupyterLab version &lt;2, did not get me to that point. In addition, the &quot;Starting Up FlyBrainLab&quot; section on https://github.com/FlyBrainLab/FlyBrainLab should have material on what to do if you do not see an FFBO section or cannot run the example notebook, perhaps in some troubleshooting page.</p></disp-quote><p>We thank the reviewer for the valuable feedback and apologize for the confusion. We substantially improved upon the installation process:</p><p>1) We corrected, and significantly expanded the installation instructions at https:// github.com/FlyBrainLab/FlyBrainLab, and added a Wiki page for troubleshooting (https://github.com/FlyBrainLab/FlyBrainLab/wiki/Troubleshooting).</p><p>2) We tested the installation procedure on Linux (Ubuntu and CentOS), macOS and Windows.</p><p>3) We have already published and will keep updating a Docker image that has the full FlyBrainLab installed (https://hub.docker.com/r/fruitflybrain/fbl). We also included an Amazon Machine Image to be used on the AWS EC2 service https://github.com/ FlyBrainLab/FlyBrainLab#14-amazon-machine-image. Additional images for other cloud services will be provided upon request.</p><p>4) We asked a diverse range of users, including colleagues, collaborators, undergraduate students to test the installation and received positive feedback.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>Lazar and colleagues present a platform, FlyBrainLab that integrates <italic>Drosophila</italic> neuron and circuit modelling data with neuroanatomy, from morphology to synaptic resolution information. Their desktop system is modular and stand-alone, providing the ability to query, run and visualise particular circuits and models. To demonstrate the functionality of their platform they present 3 specific examples that cover the use of published models, light and electron-microscopy (EM) data and the comparison between larva and adult.</p><p>Although the need their platform is addressing is real, the manuscript does not present the work in a compelling way, particularly for this journal's audience. Furthermore, the methods used to integrate data, and how data are used are not described properly. If a system such as this aims to become a standard analytical tool for neuroscientists, it is essential that data integration and processing are transparent.</p></disp-quote><p>We thank the reviewer for providing this perspective and we would like to stress that FlyBrainLab is not positioned as a data provisioning platform, but rather as a computing platform that provides utilities to visualize fly brain data and explore, analyze, evaluate and compare executable circuit models in a common environment. We’d like to clarify that we consider data curation, integration and processing as porting currently publicly available datasets into the NeuroArch database, and we fully respect the expertise of researchers generating and curating fly brain data. As such, apart from formatting changes for consistency with NeuroArch database’s schema, minimal changes are done for any data saved to and loaded from the NeuroArch database into the Neurokernel Execution Engine. Although 6 default datasets are provided as starting points for users, the FlyBrainLab platform was developed to be agnostic of the content of the underlying datasets. We welcome the use of any additional datasets that can be loaded locally on machines running FlyBrainLab without communicating with our publicly hosted data servers. We do acknowledge, however, that in addition to providing the reference to the previous NeuroArch publications, transparency in terms of how data is saved to and loaded from the NeuroArch database could be make clearer. To that end, we’ve done the following:</p><p>1) We published the code used to create the NeuroArch database, which can be used directly or indirectly and independently of us to load new datasets and update upstream datasources,</p><p>2) We have updated the latest version of NeuroArch database that provides the Hemibrain version 1.1, and</p><p>3) We published a webpage tracking versioning of NeuroArch database.</p><disp-quote content-type="editor-comment"><p>Please find below a number of concerns. I do not comment on the technical details of the FlyBrainLab platform modules, as that is not my expertise.</p><p>1) The structure of the manuscript and the way the examples are presented are not compelling for the average neuroscientist that wants to start using the public data (models, connectome and synaptome). Especially if the one of the main draws of this type of platform is for neuroscientists to start testing models based on real data. The main reason for this is that very little information is given on how experimental data is curated and integrated (see below for more).</p></disp-quote><p>We thank the reviewer for this feedback. While, as we already mentioned, we do not curate datasets, we included additional tutorials and examples of how individual components of the FlyBrainLab platform can be used to access/visualize/manipulate data types such as neuroanatomical connectomics/synaptomics. We also note that in the example shown in Figure 4 of the Results section, the workflow employed for modifying a previous (FlyCircuit-based) model of the Antennal Lobe to reflect new public (Hemibrain-based) data is intended as an illustration of how models can be updated using more recent (connectomics/synamptomics) data. Furthermore, we would like to clarify that the purpose of the FlyBrainLab platform is to provide an integrated system to experiment with fly brain data that are publicly available worldwide. The developers of FlyBrainLab do minimal modifications to the datasets apart from porting them into the NeuroArch database using a specified schema (as specified in Givon et al., 2015 (http://dx.doi.org/10.5281/zenodo.44225)). We do acknowledge the need for clearer examples of how newly published data can be integrated into the database. For end-users who intend to use other datasets not currently provided as default in FlyBrainLab, we included additional example notebooks detailing how such datasets can be loaded into the FlyBrainLab. Finally, although not generally recommended, we note that components in NeuroMynerva (the user front-end) can be independently invoked without communicating with the database. The neuroanatomy visualizer (Neu3D-Widget), for example, can load arbitrary swc or mesh files, where the corresponding 3D data can be accessed in the associated python kernel once the files are loaded into the widget. An example notebook (link) has been added to highlight this use case as well.</p><disp-quote content-type="editor-comment"><p>2) What neuroanatomical data is being used and in what way is completely opaque. It is assumed that different modalities of data will have been processed in different ways, but very little information is given in this regard. How is the light-level FlyCircuit data processed to infer connectivity and how is this process validated? How are cell types identified and validated, in FlyCircuit and the hemibrain? How many neurons and types are used for each use case?</p><p>For example, regarding the CX circuit example, the authors say, &quot;The innervation pattern of each neuron was visually examined in the NeuroNLP window and a standard name assigned according to the naming scheme adopted in the CXcircuit Library.&quot; How do these standard names relate to the cell type names used by the community? Identifying cell types from morphological data requires expertise when this is done to the highest resolution, and thus this process should be described in detail. In addition, it becomes very difficult to assess the use cases presented when there is no clarity on what neurons and types are being used.</p></disp-quote><p>We believe that two types of questions are raised above by the reviewer. One relates to how the anatomical data from the original dataset are processed and stored, and the other relates to how the data is interpreted from a model’s perspective and used in modeling.</p><p>To address the first type of questions, we would like to reiterate the position we take on connectome data. We do not generate connectome data, including the morphology of the neurons and their connectivities, nor are we in the position to identify large quantities of cell types. The utility that the platform provides is the APIs to read/write the NeuroArch Database. We do not provide any additional interpretations of these datasets. For transparency, we now provide the code that we used to create NeuroArch labeled datasets from their original source (see also the response to your comment #3). For the Hemibrain dataset, the cell types and names of individual neurons have always been assigned according to the original dataset, along with a reference ID pointing to the ID used in the original dataset. For the FlyCircuit dataset, we included original neurons from FlyCircuit 1.2 (http://flycircuit.tw), and the inferred connectivity according to the algorithm published and made available to us by the authors (https://doi.org/10.3389/fninf.2018.00099 now cited in the Data Availability section). For the Larva L1EM dataset, we included detailed description of how the publicly served dataset (https://l1em.catmaid.virtualflybrain.org) is loaded into the NeuroArch Database (https://github.com/FlyBrainLab/datasets#README.md), including a CSV file that shows the mapping between original neuron labels in the raw Dataset to the labels used in FlyBrainLab. For transparency, IDs of the neurons of the original data source are always available/displayed in the Info Panel (see also Appendix 1—figure 2).</p><p>To address the second type of questions, we would like to note the following. First, even though a substantial amount of hard work has been put into annotating datasets by their original creators, often there may be missing data/labels, and some labels are simply not really useful. In order to create an executable circuit, a user may need to make additional assumptions to assign labels/names/types. One example is provided by the FlyCircuit dataset which contains no cell type information. Additional information must be brought in from the literature by a user or he/she needs to make further assumptions. Second, the naming scheme provided by the original dataset or even in the literature is not the best possible.</p><p>For example, as the reviewer pointed out, the standard naming scheme we used in the CX example is not the same as the one used by the research community (we also have to point out that there are many names used by the community for these neuron types, and depending on the researcher, the names used appear to be largely random). We have adopted a naming scheme (in the original submission) that is both human readable and easily machine-parsable. The latter property has never been the focus of naming schemes used by neurobiologists but is critical when it comes to specifying neurons for code execution. These two points highlight the need for flexibility in processing publicly available data. The FlyBrainLab provides users full access to the NeuroArch Database to update any of the neuron’s information/metadata as desired.</p><p>Finally, we would like to address the concern raised in the last sentence in the reviewer’s comment. The types of neurons in the CX example are already provided in the Materials and methods section, including in Figure 7 (in the revised manuscript). We also corrected our statement on visually examining these neurons. The visual examination was aided by the published neuron types in the paper (https://doi.org/10.1016/j.celrep.2013.04.022). For the neurons in the FlyCircuit dataset but not mentioned in the paper, we made assumptions in modeling according to the available evidence in the literature. The details are omitted here as they are largely out of scope. In the revised manuscript, however, we added further information on each individual neuron modeled. Similarly, the types of neurons and the number of neurons of each type is explicitly mentioned in the two examples of the early olfactory system.</p><disp-quote content-type="editor-comment"><p>3) Related to the point above, the authors list the hemibrain data used is from version 1.0.1 (gs://hemibrain-release/neuprint/hemibrain_v1.0.1_neo4j_inputs.zip). However, a new version of the data (1.1) was released online in May, with the data dumps available at least from the end of June (according to https://dvid.io/blog/release-v1.1/). The latest version significantly improves the cell typing that had been released (see https://docs.google.com/document/d/1vae3ClHR8z8uekqwrOHtqiux3oY5-Y_xw6W2srCi3PI/edit?usp=sharing). The authors should update their manuscript to use the latest version of data. This should highlight issues of how data can be kept up to date in these types of platforms and how integration of versions can be achieved. The authors should comment on the processes they use for this.</p></disp-quote><p>We thank the reviewer for this comment. Again, as mentioned in the responses to earlier questions, the main purpose of this manuscript is to describe the FlyBrainLab as a platform of which the NeuroArch database, not an individual dataset, is a critical component. Incidentally, we presented a usage case in which the Hemibrain dataset version 1.0.1 is the main source of data. This should bear no difference in showcasing the capabilities of the FlyBrainLab than using version 1.1. Therefore, we assert that there is no need to update the database in the example we presented in the paper.</p><p>To benefit the community, however, we do feel the need to periodically and in a timely fashion update the database for the purpose of general usage. We did the following: (1) we have updated the latest version of the NeuroArch database and currently provide the Hemibrain version 1.1, (2) we published a webpage tracking versions of the NeuroArch database, and 3) we published the code used to create the NeuroArch Database. The code can be used directly or indirectly and independently of us once an update of the upstream datasource is available.</p><disp-quote content-type="editor-comment"><p>4) Presenting this platform as a Resource, it becomes essential that it is easy to install. I attempted to install FlyBrainLab according to the instructions in https://github.com/FlyBrainLab/FlyBrainLab. Using miniconda on macOS, which I already had installed for other purposes, I unfortunately ran into errors, and the installation was unsuccessful (seemingly caused by msgpack not being found). The instructions mention that the platform has only been tested in Ubuntu but that it &quot;should work&quot; in other platforms. I understand that it is not possible to test for and avoid, all possible errors, but the authors should test the installation in at least one other OS, if they want the average neuroscientist to start using it.</p><p>The tutorials listed in https://github.com/FlyBrainLab/Tutorials are certainly a very useful introduction, although they suffer from the issues in points 2 and 3.</p></disp-quote><p>We thank the reviewer for the valuable comment. To address the concern, we did the following:</p><p>1) We significantly expanded the installation instruction on https://github.com/FlyBrainLab/FlyBrainLab, added a Wiki page for troubleshooting</p><p>(https://github.com/FlyBrainLab/FlyBrainLab/wiki/Troubleshooting), and mentioned that the Issue Trackers on GitHub can be useful in this case (we also understand that the reviewer needs the remain anonymous).</p><p>2) We tested the installation procedure on Linux (Ubuntu and CentOS), macOS and Windows.</p><p>3) We have already published and will keep updating a Docker image that has the full FlyBrainLab installed. We also provide an Amazon Machine Image to be used on the AWS EC2 service. Additional images on other services can be provided if requested.</p><p>4) We asked a diverse range of users, including colleagues, collaborators, undergraduate students to test the installation and received positive feedback.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The revised manuscript has addressed some of the technical issues, but has not addressed the core issues of readability of the manuscript , and usability of the software, by a regular fly neurobiologist. This was stated in the essential revisions, point 1: &quot;1. Could the authors provide substantially more detail on how an experimentalist would use the package? It should be clear why they would want to do so.&quot;</p><p>While the authors have responded with some limited explanations in the cover letter, the required changes are not evident in the manuscript, and it is there that these essential points of usability must be clarified. Again, it is not sufficient to refer the reader to the website to do this. The appendices, and much of the text, still mostly tell the reader what can be done, rather than how to do it. This should be rather early in the manuscript to motivate what follows.</p></disp-quote><p>Thank you for the clarification. In this revision, we substantially expanded the text to address the readability issue of the manuscript and how an experimentalist can use the platform. We added in the Results section two more examples showing the type of questions FlyBrainLab can be used effectively to answer questions raised by a regular fly neurobiologist, and in the Materials and methods section the steps needed to answer these with FlyBrainLab.</p><p>Specifically, we added in the Results section the entry “Building Fly Brain Circuits with English Queries”, showing the versatility of the English query interface of FlyBrainLab, also technically known as NeuroNLP. NeuroNLP enables users, without any programming knowledge, to perform complex queries to build, visualize and explore biological circuits, a capability that none of the current data provisioning services is designed to do or can provide to neurobiologists/neuroscientists. In the corresponding part in the Materials and methods section, the English queries employed are listed in full detail.</p><p>We also moved a part of the text previously included in the supplement/appendix to the new entry entitled “Exploring the Structure and Function of Yet to be Discovered Brain Circuits” in the Results section. Here, we provided several examples on how to analyze connectome/synaptome datasets using FlyBrainLab to identify structures and cell types, and create circuit diagrams modeling brain pathways. We describe the steps to achieve these results in the corresponding part of the Materials and methods section.</p><p>In the newly added entry “Interactive Exploration of Executable Fruit Fly Brain Circuits” in the Results section, we present the construction of an interactive circuit diagram for rapidly developing circuit models. The capability to remove or reenable a neuron in the circuit diagram is akin to, respectively, silencing and rescuing neurons in an experiment, and is of particular interest to systems neurobiologists. Such a capability quickly enable the exploration of biological findings by means of computational models, and it is highly flexible and scalable beyond the typical experimental settings.</p><p>Finally, we added Appendix 4 with a walk through of code highlighting the main capabilities of the FlyBrainLab regarding model creation and circuit execution, including: (1) loading the NeuroArch Database from connectome datasets, (2) building and exploring biological circuits, (3) interactively exploring circuit diagrams, (4) execution of circuits retrieved from the NeuroArch Database.</p><p>Concluding, the manuscript now comprehensively describes how neurobiologists and computational neuroscientists alike can leverage the power of FlyBrainLab, whether they want to simply visualize neural circuit through complex English queries, analyze the connectivity data, or construct executable circuit models for exploration, analysis, comparison and evaluation.</p><disp-quote content-type="editor-comment"><p>Similarly, on essential point 2, the reviewers would like to know how their data goes in and is manipulated, and how they can be confident that what the progam does is faithful to the original. Issues of installation, which have been presented, are relevant, but of secondary technical importance.</p></disp-quote><p>Thank you for the clarification. We added the entry “Loading Publicly Available Datasets into NeuroArch Database” in the Materials and methods section. We provided details of how each dataset is handled using the NeuroArch API for loading into the NeuroArch Database. We also provided some high-level statistics of the loaded datasets. The scripts for loading these datasets have been published on GitHub: https://github.com/FlyBrainLab/ Datasets. In addition, in Appendix 4, we now provide a complete walk through some of the core FlyBrainLab capabilities with a simple example, including data loading. Some basic usages of data loading are exemplified.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Essential Revisions:</p><p>The reviewers and I felt that the paper and FlyBrainLab provide a userful resource for the field. The revised version is considerably improved and the reviewers would like to suggest a few essential but straightforward revisions to make it even more accessible to the readers and users of this resource.</p><p>1) Update key references (indicated in the detailed reviews).</p></disp-quote><p>We updated the references according to the suggestions of reviewer #3. We also checked and updated references to preprints of other peer-reviewed publications.</p><disp-quote content-type="editor-comment"><p>2) Clarify Figures and their legends, especially Figure 2 and 3.</p></disp-quote><p>We updated Figure 2 and Figure 3 according to the suggestions from the reviewers.</p><disp-quote content-type="editor-comment"><p>There are several further important suggestions by the reviewers to strengthen the presentation and improve the accessibility of the paper and resource for readers. These are provided in the detailed reviewer comments below.</p><p>Reviewer #1:</p><p>This new version of the manuscript has a better layout and will be a more useful introduction to the application for new users. However there are still some issues with how the structure of the application is presented which may be difficult for readers.</p><p>Figure 2, especially the legend is quite minimal and there is nothing here to give a reader the key idea that this is a graphical application which a user would interact with through their browser. I suggest to move the screenshot of the application from Appendix 1—figure 2 to a panel in the main Figure 2, and make sure these panels are well integrated and explained, e.g. NeuroMynerva in the top panel is what you see in the bottom. Refer the reader here to Appendix 1—figure 1 for more details (some of the colors of the blocks match between the simplified/full versions, e.g. green NeuroArch, there's no reason they all shouldn't for ease of readability).</p></disp-quote><p>We updated Figure 2 as well as expanded on its caption as suggested.</p><disp-quote content-type="editor-comment"><p>NeuroNLP and NeuroGFX (window) are mentioned in the text without any context. These need to be shown/explained in Figure 2 and also described briefly where NeuroMynerva etc. are first defined in the Introduction. I would suggest highlighting all important component names in bold where they are first introduced so a user can go back to the definition as they are discussed later in the text.</p></disp-quote><p>As suggested, we highlighted the component names with bold font at their first instance.</p><disp-quote content-type="editor-comment"><p>It is strange that the actual short English language queries used for Figure 3 are not mentioned in the legend or main text. This is an important feature of the application and adding (at least some of) the sequence of commands for one of the panels (e.g. 3a, &quot;show T4a&quot;, &quot;color red&quot;, &quot;add cholinergic presynaptic neurons&quot; etc.) in another panel/table in the figure would be quite informative for readers. In the main text &quot;(see also Materials and methods)&quot; could be replaced with something better like: (the full sequence of queries which created this panel can be found in the Materials and methods). Also explain that the panels in Figure 3 are screenshots of the NeuroNLP window in Figure 2B, etc.</p></disp-quote><p>We added English queries in the first example (Use Case 1) and refer readers to the Materials and methods section for a full sequence of queries for the rest of the examples.</p><disp-quote content-type="editor-comment"><p>It is good having a section in the Materials and methods for each of other figures related to the main use cases/examples, but these could be tied together better also, making it clearer that the details of how the figure panels were generated can be found in the Materials and methods. Also some parts of the Materials and methods do not refer back to the figures, e.g. &quot;Model A [26], Model B [27] and Model C [28]&quot; could refer to Figure 6A, B, C etc. Small things like this would improve the readability of the paper significantly.</p><p>It might also be worth numbering the use cases/analysis types, e.g. Use Case 1-6, and adding these to subheadings to make it easier to move between the main text and Materials and methods.</p></disp-quote><p>We added Use Case 1-6 to each of the subheadings in the Results as well as in the Materials and methods section.</p><disp-quote content-type="editor-comment"><p>Overall the manuscript is a good introduction to the range of features FlyBrainLab offers and is structured such that a user can see what can be accomplished, and is given some guidance how they would achieve it themselves.</p><p>Reviewer #2:</p><p>The text is clearer and more inviting for a general audience. The enumeration of capabilities in the Introduction is effective. The Results section is structured well, displaying different use cases of FlyBrainLab. The accompanying tutorials online serve as good launching points for researchers.</p><p>Thank you to the authors for the additions in the main text, the code walkthroughs in the appendices, and the improved installation instructions. The basic tutorials are simple to follow. My only suggestion on the code side is to be more verbose in the introduction to the lamina cartridge executable circuit notebook and in the limitations of the user-side-only installation.</p></disp-quote><p>We thank the reviewer for the valuable comments and suggestions. We added more detailed instructions in the lamina cartridge tutorial, in particular, on the exact steps for starting the backend servers and creating a workspace so that the code can be readily executed. We further clarified the limitations of the user-side-only installation in the Code Availability and Installation section in Materials and methods .</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The revised version of the manuscript addresses many of the concerns previously reported. Thank you to the authors for providing much clearer information about the data that is ready to use in the FlyBrain Lab platform, how it can be used, installed and the components of the FlyBrainLab. There are still some corrections that are needed regarding the source of some of the datasets.</p><p>Throughout the paper, reference 4 (Xu et al., 2020) is used as the citation for the hemibrain dataset. This is a preprint that has been superseded by the publication in September 2020 of the peer-reviewed paper (Scheffer et al., 2020, https://doi.org/10.7554/eLife.57443). It also needs updating in GitHub (https://github.com/FlyBrainLab/Datasets#ref-1)</p></disp-quote><p>As requested, we updated all citations to the paper above.</p><disp-quote content-type="editor-comment"><p>The reference to the larval L1EM dataset also needs correcting. For example this is given as reference 2 (Berck et al., 2016). The correct reference, as correctly shown in https://github.com/FlyBrainLab/Datasets#ref-3, is Ohyama et al., 2015 (reference 69). There might be other instances in the text that use the wrong citation.</p></disp-quote><p>We corrected the citation and checked to make sure that the reference is cited correctly in the rest of the manuscript.</p><disp-quote content-type="editor-comment"><p>The section added to the beginning of the Results, which includes Figure 3, provides readers with some examples on how they can start exploring the data in the platform (published datasets) using plain English queries. However, I do not think the added Figure 3 currently presents the data in a way that makes it easy for readers to link the relevant text and figure legend that describe the connectivity, to the panels. Each of the 4 examples (a-d) displays a neuron plot (left) and a connectivity matrix (right); other than reading each of the row/column names it is not possible to link the neurons plotted on the left to the data plotted on the right. Adding a colored annotation bar or even coloring the row/column names of the connectivity matrices according to the neuron plots would certainly help, or perhaps adding some clustering.</p></disp-quote><p>In the new Figure 3, we matched the color of row/column neuron names in the adjacency matrix to the color of the visualized neurons. Note that in the interactive user interface, each neuron can be highlighted/addressed by their name. It is, however, not possible to reflect this feature in the printed version of the manuscript.</p><disp-quote content-type="editor-comment"><p>Example 2 refers to a possible direct connection between the mushroom body and the fan-shaped body (&quot;raising the question whether the two memory centers are directly connected&quot;). Some of the neurons directly connecting these 2 neuropils (and possible pathways for visual information in addition to reference 17), have been described already, in Li et al., 2020 (December 2020, https://doi.org/10.7554/eLife.62576), one of the recent papers based on the hemibrain dataset. Could the authors please rephrase?</p></disp-quote><p>We rephrased the paragraph and referenced the paper.</p></body></sub-article></article>