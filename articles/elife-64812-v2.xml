<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">64812</article-id><article-id pub-id-type="doi">10.7554/eLife.64812</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Decoding subjective emotional arousal from EEG during an immersive virtual reality experience</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-215558"><name><surname>Hofmann</surname><given-names>Simon M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0958-501X</contrib-id><email>simon.hofmann@cbs.mpg.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-108919"><name><surname>Klotzsche</surname><given-names>Felix</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3985-2481</contrib-id><email>klotzsche@cbs.mpg.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-216261"><name><surname>Mariola</surname><given-names>Alberto</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4660-1306</contrib-id><email>a.mariola@sussex.ac.uk</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-103727"><name><surname>Nikulin</surname><given-names>Vadim</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-72376"><name><surname>Villringer</surname><given-names>Arno</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-108922"><name><surname>Gaebler</surname><given-names>Michael</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4442-5778</contrib-id><email>gaebler@cbs.mpg.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Neurology, Max Planck Institute for Human Cognitive and Brain Sciences</institution><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution>Humboldt-Universität zu Berlin, Faculty of Philosophy, Berlin School of Mind and Brain</institution><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution>Sackler Centre for Consciousness Science, School of Engineering and Informatics, University of Sussex</institution><addr-line><named-content content-type="city">Brighton</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution>Sussex Neuroscience, School of Life Sciences, University of Sussex</institution><addr-line><named-content content-type="city">Brighton</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff5"><label>5</label><institution>Bernstein Center for Computational Neuroscience Berlin</institution><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Shackman</surname><given-names>Alexander</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Baker</surname><given-names>Chris I</given-names></name><role>Senior Editor</role><aff><institution>National Institute of Mental Health, National Institutes of Health</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>28</day><month>10</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e64812</elocation-id><history><date date-type="received" iso-8601-date="2020-11-11"><day>11</day><month>11</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-10-27"><day>27</day><month>10</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-10-25"><day>25</day><month>10</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.10.24.353722"/></event></pub-history><permissions><copyright-statement>© 2021, Hofmann et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Hofmann et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-64812-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-64812-figures-v2.pdf"/><abstract><p>Immersive virtual reality (VR) enables naturalistic neuroscientific studies while maintaining experimental control, but dynamic and interactive stimuli pose methodological challenges. We here probed the link between emotional arousal, a fundamental property of affective experience, and parieto-occipital alpha power under naturalistic stimulation: 37 young healthy adults completed an immersive VR experience, which included rollercoaster rides, while their EEG was recorded. They then continuously rated their subjective emotional arousal while viewing a replay of their experience. The association between emotional arousal and parieto-occipital alpha power was tested and confirmed by (1) decomposing the continuous EEG signal while maximizing the comodulation between alpha power and arousal ratings and by (2) decoding periods of high and low arousal with discriminative common spatial patterns and a long short-term memory recurrent neural network. We successfully combine EEG and a naturalistic immersive VR experience to extend previous findings on the neurophysiology of emotional arousal towards real-world neuroscience.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>Human emotions are complex and difficult to study. It is particularly difficult to study emotional arousal, this is, how engaging, motivating, or intense an emotional experience is. To learn how the human brain processes emotions, researchers usually show emotional images to participants in the laboratory while recording their brain activity. But viewing sequences of photos is not quite like experiencing the dynamic and interactive emotions people face in everyday life.</p><p>New technologies, such as immersive virtual reality, allow individuals to experience dynamic and interactive situations, giving scientists the opportunity to study human emotions in more realistic settings. These tools could lead to new insights regarding emotions and emotional arousal.</p><p>Hofmann, Klotzsche, Mariola et al. show that virtual reality can be a useful tool for studying emotions and emotional arousal. In the experiment, 37 healthy young adults put on virtual reality glasses and ‘experienced’ two virtual rollercoaster rides. During the virtual rides, Hofmann, Klotzsche, Mariola et al. measured the participants' brain activity using a technique called electroencephalography (EEG). Then, the participants rewatched their rides and rated how emotionally arousing each moment was. Three different computer modeling techniques were then used to predict the participant’s emotional arousal based on their brain activity.</p><p>The experiments confirmed the results of traditional laboratory experiments and showed that the brain’s alpha waves can be used to predict emotional arousal. This suggests that immersive virtual reality is a useful tool for studying human emotions in circumstances that are more like everyday life. This may make future discoveries about human emotions more useful for real-life applications such as mental health care.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>machine learning</kwd><kwd>affective computing</kwd><kwd>deep learning</kwd><kwd>ecological validity</kwd><kwd>naturalistic stimuli</kwd><kwd>computational affective neuroscience</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium für Bildung und Forschung</institution></institution-wrap></funding-source><award-id>13GW0206</award-id><principal-award-recipient><name><surname>Klotzsche</surname><given-names>Felix</given-names></name><name><surname>Gaebler</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004189</institution-id><institution>Max Planck Society</institution></institution-wrap></funding-source><award-id>Max Planck Society - Fraunhofer-Gesellschaft cooperation</award-id><principal-award-recipient><name><surname>Hofmann</surname><given-names>Simon M</given-names></name><name><surname>Klotzsche</surname><given-names>Felix</given-names></name><name><surname>Nikulin</surname><given-names>Vadim</given-names></name><name><surname>Villringer</surname><given-names>Arno</given-names></name><name><surname>Gaebler</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Modulations of alpha oscillations from parieto-occipital brain regions can be used to decode subjective emotional arousal in a dynamic naturalistic virtual reality experience.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>While humans almost constantly interact with complex, dynamic environments, lab-based studies typically use simplified stimuli in passive experimental situations. Trading realism for experimental control happens at the expense of the representativity of the experimental design (<xref ref-type="bibr" rid="bib20">Brunswik, 1955</xref>), that is, the degree to which effects found in the lab generalize to practical everyday-life conditions. This may be particularly true for affective phenomena like emotions.</p><sec id="s1-1"><title>Emotional arousal as a fundamental property of affective experience</title><p>Emotions are subjective, physiological, and behavioural responses to personally meaningful external stimuli (<xref ref-type="bibr" rid="bib106">Mauss and Robinson, 2009</xref>) or self-generated mental states (e.g., memories; <xref ref-type="bibr" rid="bib30">Damasio et al., 2000</xref>) and underlie our experience of the world (<xref ref-type="bibr" rid="bib73">James, 1884</xref>; <xref ref-type="bibr" rid="bib74">James, 1890</xref>; <xref ref-type="bibr" rid="bib142">Seth, 2013</xref>). Emotions are crucial for physical and mental health (<xref ref-type="bibr" rid="bib55">Gross and Muñoz, 1995</xref>) and their investigation has long been at the core of experimental psychology (<xref ref-type="bibr" rid="bib163">Wundt and Judd, 1897</xref>).</p><p>Dimensional accounts conceptualize emotions along the two axes of valence and arousal (<xref ref-type="bibr" rid="bib40">Duffy, 1957</xref>; <xref ref-type="bibr" rid="bib89">Kuppens et al., 2013</xref>; <xref ref-type="bibr" rid="bib133">Russell, 1980</xref>; <xref ref-type="bibr" rid="bib134">Russell and Barrett, 1999</xref>; <xref ref-type="bibr" rid="bib163">Wundt and Judd, 1897</xref>): valence differentiates states of pleasure and displeasure, while emotional arousal describes the degree of activation or intensity that accompanies an emotional state. [Different types of arousal have been proposed and investigated, such as sexual, autonomic, emotional (<xref ref-type="bibr" rid="bib133">Russell, 1980</xref>); also in the context of altered states of consciousness, for example, through anaesthesia or sleep. They may share psychological (e.g., increase in sensorimotor and emotional reactivity; <xref ref-type="bibr" rid="bib125">Pfaff et al., 2012</xref>) and physiological aspects (e.g., sympathetic activation) but are not synonymous. We here explicitly refer to arousal in the context of the subjective experience of emotions].</p><p>Emotions have been linked to activity in the autonomic (ANS) and the central nervous system (<xref ref-type="bibr" rid="bib29">Dalgleish, 2004</xref>). It has thereby been difficult to consistently associate individual, discrete emotion categories with specific response patterns in the ANS (<xref ref-type="bibr" rid="bib84">Kragel and Labar, 2013</xref>; <xref ref-type="bibr" rid="bib85">Kreibig, 2010</xref>; <xref ref-type="bibr" rid="bib146">Siegel et al., 2018</xref>) or in distinct brain regions (<xref ref-type="bibr" rid="bib97">Lindquist et al., 2012</xref>; but <xref ref-type="bibr" rid="bib135">Saarimäki et al., 2016</xref>). Rather, emotions seem to be dynamically implemented by sets of brain regions and bodily activations that are involved in basic, also non-emotional psychological operations (i.e., ‘psychological primitives’; <xref ref-type="bibr" rid="bib97">Lindquist et al., 2012</xref>). In this view, humans are typically in fluctuating states of pleasant or unpleasant arousal (‘core affect’; <xref ref-type="bibr" rid="bib134">Russell and Barrett, 1999</xref>; <xref ref-type="bibr" rid="bib98">Lindquist, 2013</xref>), which can be influenced by external stimuli. Emotional arousal could thereby be a ‘common currency’ to compare different stimuli or events (<xref ref-type="bibr" rid="bib98">Lindquist, 2013</xref>) and represent fundamental neural processes that underlie a variety of emotions (<xref ref-type="bibr" rid="bib159">Wilson-Mendenhall et al., 2013</xref>). It can fluctuate quickly – on the order of minutes (<xref ref-type="bibr" rid="bib88">Kuppens et al., 2010</xref>) or seconds (<xref ref-type="bibr" rid="bib111">Mikutta et al., 2012</xref>) – and has been connected to ANS activity, as measured by pupil diameter (<xref ref-type="bibr" rid="bib17">Bradley et al., 2008</xref>) or skin conductance (<xref ref-type="bibr" rid="bib6">Bach et al., 2010</xref>). At the brain level, emotional arousal was linked to lower alpha power, particularly over parietal electrodes (<xref ref-type="bibr" rid="bib100">Luft and Bhattacharya, 2015</xref>; <xref ref-type="bibr" rid="bib82">Koelstra et al., 2012</xref>). The parieto-occipital alpha rhythm, typically oscillating in the frequency range of 8–13 Hz, is the dominant EEG rhythm in awake adults with eyes closed (<xref ref-type="bibr" rid="bib9">Berger, 1929</xref>), where it varies with vigilance (<xref ref-type="bibr" rid="bib119">Olbrich et al., 2009</xref>). However, in tasks of visual processing (i.e., with eyes open), parieto-occipital alpha power was linked to active attentional processes (e.g., distractor suppression; <xref ref-type="bibr" rid="bib79">Kelly et al., 2006</xref>; <xref ref-type="bibr" rid="bib81">Klimesch, 2012</xref>) or, more generally, to functional inhibition for information gating (<xref ref-type="bibr" rid="bib75">Jensen and Mazaheri, 2010</xref>). Physiologically, alpha oscillations were associated with large-scale synchronization of neuronal activity (<xref ref-type="bibr" rid="bib21">Buzsáki, 2006</xref>) and metabolic deactivation (<xref ref-type="bibr" rid="bib112">Moosmann et al., 2003</xref>).</p><p>In sum, bodily responses interact in complex ways across situations, and activity in the brain is central for emotions and their subjective component (<xref ref-type="bibr" rid="bib7">Barrett, 2017</xref>; <xref ref-type="bibr" rid="bib142">Seth, 2013</xref>). As arousal is a fundamental property not only of emotions but of subjective experience in general (<xref ref-type="bibr" rid="bib2">Adolphs et al., 2019</xref>), an investigation of its neurophysiology, reflected in neural oscillations, is essential to understanding the biology of the mind.</p></sec><sec id="s1-2"><title>Studying emotional arousal and its neurophysiology in the lab</title><p>Studies that investigated emotions or emotional arousal in laboratory environments typically used static images. For example, more emotionally arousing relative to less emotionally arousing (e.g., neutral) pictures were associated with an event-related desynchronization, that is, a decrease in the power of alpha oscillations in posterior channels (<xref ref-type="bibr" rid="bib31">De Cesarei and Codispoti, 2011</xref>; <xref ref-type="bibr" rid="bib140">Schubring and Schupp, 2019</xref>; but <xref ref-type="bibr" rid="bib154">Uusberg et al., 2013</xref>). In a study, in which emotional arousal was induced through pictures and music, blocks of higher emotional arousal were associated with decreased alpha power compared to blocks of lower emotional arousal (<xref ref-type="bibr" rid="bib100">Luft and Bhattacharya, 2015</xref>). However, emotion-eliciting content that is repeatedly presented in trials creates an artificial experience for participants (<xref ref-type="bibr" rid="bib18">Bridwell et al., 2018</xref>); it hardly resembles natural human behaviour and its (neuro-)physiology, which unfolds over multiple continuous timescales (<xref ref-type="bibr" rid="bib71">Huk et al., 2018</xref>). Moreover, such presentations lack a sense of emotional continuity. External events often do not appear suddenly but are embedded in an enduring sequence, in which emotions build up and dissipate. Real-life scenarios also include anticipatory aspects where emotional components can be amplified or even suppressed, thus rendering the relationship between the corresponding neuronal events and subjective experience more complex than the one typically studied with randomized or partitioned presentations of visual or auditory stimuli.</p><p>Virtual reality (VR) technology – particularly immersive VR, in which the user is completely surrounded by the virtual environment – affords the creation and presentation of computer-generated scenarios that are contextually rich and engaging (<xref ref-type="bibr" rid="bib35">Diemer et al., 2015</xref>). As more naturalistic (i.e., dynamic, interactive, and less decontextualized) experiments allow to study the brain under conditions it was optimized for (<xref ref-type="bibr" rid="bib48">Gibson, 1978</xref>; <xref ref-type="bibr" rid="bib60">Hasson et al., 2020</xref>), their findings may more readily generalize to real-world circumstances and provide better models of the brain (<xref ref-type="bibr" rid="bib105">Matusz et al., 2019</xref>; <xref ref-type="bibr" rid="bib143">Shamay-Tsoory and Mendelsohn, 2019</xref>).</p><p>In this study, we aimed to link subjective emotional arousal with alpha power in a naturalistic setting. Participants completed an immersive VR experience that included virtual rollercoaster rides while their EEG was recorded. They then continuously rated their emotional arousal while viewing a replay of their previous experience (<xref ref-type="bibr" rid="bib107">McCall et al., 2015</xref>).</p></sec><sec id="s1-3"><title>Methodological challenges of naturalistic experiments</title><p>To tackle the challenges of data acquired in naturalistic settings and with continuous stimuli, we made use of recent advances in signal processing and statistical modelling: spatial filtering methods (originally developed for brain-computer interfaces [BCIs]; <xref ref-type="bibr" rid="bib14">Blankertz et al., 2008</xref>) have recently gained popularity in cognitive neuroscience (<xref ref-type="bibr" rid="bib26">Cohen, 2018</xref>; <xref ref-type="bibr" rid="bib165">Zuure and Cohen, 2020</xref>), where they have been used to analyze continuous data collected in naturalistic experiments, for example, to find inter-subject correlations in neuroimaging data of participants watching the same movie (<xref ref-type="bibr" rid="bib37">Dmochowski et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Gaebler et al., 2014</xref>).</p><p>For the present experiment, two spatial filtering methods were applied to link alpha power and subjective emotional arousal: source power comodulation (SPoC; <xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>) and common spatial patterns (CSP; <xref ref-type="bibr" rid="bib14">Blankertz et al., 2008</xref>; <xref ref-type="bibr" rid="bib126">Ramoser et al., 2000</xref>).</p><p>SPoC is a supervised regression approach, in which a target variable (here: subjective emotional arousal) guides the extraction of relevant M/EEG oscillatory components (here: alpha power). SPoC has been used to predict single-trial reaction times from alpha power in a hand motor task (<xref ref-type="bibr" rid="bib108">Meinel et al., 2016</xref>), muscular contraction from beta power (<xref ref-type="bibr" rid="bib136">Sabbagh et al., 2020</xref>), and difficulty levels of a video game from theta and alpha power (<xref ref-type="bibr" rid="bib114">Naumann et al., 2016</xref>). CSP is used to decompose a multivariate signal into components that maximize the difference in variance between distinct classes (here: periods of high and low emotional arousal). CSP thereby allows optimizing the extraction of power-based features from oscillatory signals, which can then be applied for training classifiers to solve binary or categorical prediction problems. CSP is being used with EEG for BCI (<xref ref-type="bibr" rid="bib14">Blankertz et al., 2008</xref>) or to decode workload (<xref ref-type="bibr" rid="bib141">Schultze-Kraft et al., 2016</xref>).</p><p>In addition to M/EEG-specific spatial filtering methods, non-linear machine learning methods are suited for the analysis of continuous, multidimensional recordings from naturalistic experiments. Deep neural networks transform high-dimensional data into target output variables (here: different states of emotional arousal) by finding statistical invariances and hidden representations in the input (<xref ref-type="bibr" rid="bib49">Goodfellow et al., 2016</xref>; <xref ref-type="bibr" rid="bib92">LeCun et al., 2015</xref>; <xref ref-type="bibr" rid="bib138">Schmidhuber, 2015</xref>). For time-sequential data, long short-term memory (LSTM) recurrent neural networks (RNNs) are particularly suited (<xref ref-type="bibr" rid="bib52">Greff et al., 2017</xref>; <xref ref-type="bibr" rid="bib67">Hochreiter and Schmidhuber, 1995</xref>; <xref ref-type="bibr" rid="bib68">Hochreiter and Schmidhuber, 1997</xref>). Via nonlinear gating units, the LSTM determines which information flows in and out of the memory cell in order to find long- and short-term dependencies over time. LSTMs have been successfully applied for speech recognition (<xref ref-type="bibr" rid="bib51">Graves et al., 2013</xref>), language translation (<xref ref-type="bibr" rid="bib101">Luong et al., 2015</xref>), or scene analysis in videos (<xref ref-type="bibr" rid="bib39">Donahue et al., 2015</xref>), but also to detect emotions in speech and facial expressions (<xref ref-type="bibr" rid="bib162">Wöllmer et al., 2010</xref>; <xref ref-type="bibr" rid="bib161">Wöllmer et al., 2008</xref>) or workload in EEG (<xref ref-type="bibr" rid="bib8">Bashivan et al., 2016</xref>; <xref ref-type="bibr" rid="bib64">Hefron et al., 2017</xref>). In comparison to other deep learning methods, LSTMs are ‘quick learners’ due to their efficient gradient flow and thus suitable for the continuous and sparse data recorded under naturalistic stimulation with VR.</p><p>The present study tested the hypothesis of a negative association between parieto-occipital alpha power and subjective emotional arousal under dynamic and interactive stimulation. Combining immersive VR and EEG, this study aimed to (1) induce variance in emotional arousal in a naturalistic setting and (2) capture the temporally evolving and subjective nature of emotional arousal via continuous ratings in order to (3) assess their link to oscillations of brain activity in the alpha frequency range. The link between subjective emotional arousal and alpha power was then tested by decoding the former from the latter using the three complementary analysis techniques SPoC, CSP, and LSTM.</p></sec></sec><sec id="s2" sec-type="materials|methods"><title>Materials and methods</title><sec id="s2-1"><title>Participants</title><p>Forty-five healthy young participants were recruited via the participant database at the Berlin School of Mind and Brain (an adaption of ORSEE; <xref ref-type="bibr" rid="bib53">Greiner, 2015</xref>). Previous studies on the relationship between emotional arousal and neural oscillations reported samples of 19–32 subjects (e.g., <xref ref-type="bibr" rid="bib82">Koelstra et al., 2012</xref>; <xref ref-type="bibr" rid="bib100">Luft and Bhattacharya, 2015</xref>). We recruited more participants to compensate for anticipated dropouts due to the VR setup and to ensure a robust estimate of the model performances. Inclusion criteria were right-handedness, normal or corrected-to-normal vision, proficiency in German, no (self-reported) psychiatric, or neurological diagnoses in the past 10 years, and less than 3 hr of experience with VR. Participants were requested to not drink coffee or other stimulants 1 hr before coming to the lab. The experiment took ~2.5 hr, and participants were reimbursed with 9€ per hour. They signed informed consent before their participation, and the study was approved by the Ethics Committee of the Department of Psychology at the Humboldt-Universität zu Berlin.</p></sec><sec id="s2-2"><title>Setup, stimuli, and measures</title><p>The experiment was conducted in a quiet room, in which the temperature was kept constant at 24°C.</p><sec id="s2-2-1"><title>Neurophysiology/EEG</title><p>Thirty channels of EEG activity were recorded in accordance with the international 10/20 system (<xref ref-type="bibr" rid="bib144">Sharbrough et al., 1991</xref>) using a mobile amplifier (LiveAmp32) and active electrodes (actiCap; both by BrainProducts, Gilching, Germany, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_009443">SCR_009443</ext-link>). Two additional electrooculogram (EOG) electrodes were placed below and next to the right eye to track eye movements. Data were sampled at 500 Hz with a hardware-based low-pass filter at 131 Hz and referenced to electrode FCz. The amplifier was placed on a high table in the back of the participant to minimize the pull on electrode cables and provide maximal freedom for head movements. The VR headset was placed carefully on top of the EEG cap, and impedances were brought below 10 kΩ. With the same amplifier, electrocardiography and galvanic skin responses were additionally acquired. These peripheral physiological data and the inter-individual differences in interoceptive accuracy are beyond the scope of this paper, and their results will be reported elsewhere.</p></sec><sec id="s2-2-2"><title>VR HMD</title><p>An HTC Vive head-mounted display (HMD; HTC, New Taipei, Taiwan) and headphones (AIAIAI Tracks, ApS, Copenhagen, Denmark) were placed on top of the EEG cap using small, custom-made cushions to avoid pressure artefacts and increase comfort. The HTC Vive provides stereoscopy with two 1080 × 1200-pixel OLED displays, a 110° field-of-view, and a frame rate of 90 Hz. The user’s head position is tracked using infrared light, accelerometry, and gyroscopy. Head movements were recorded by adapting scripts from <xref ref-type="bibr" rid="bib153">Thor, 2016</xref>.</p></sec><sec id="s2-2-3"><title>Immersive VR experience/stimulation</title><p>Stimulation comprised two commercially available rollercoaster rides (‘Russian VR Coasters’ by Funny Twins Games, Ekaterinburg, Russia, on Steam) that were separated by a 30 s break (during which participants kept their eyes open and looked straight): the ‘Space’ rollercoaster, a 153 s ride through planets, asteroids, and spaceships and the ‘Andes’ rollercoaster, a 97 s ride through a mountain scenery (for more details, see Figure 5 and the Appendix 1). The two rollercoaster rides were commercially available on Steam. The rollercoasters were selected for their length (to not cause physical discomfort by wearing the HMD for too long) and content (to induce variance in emotional arousal). The experience, comprising the sequence ‘Space’-break-‘Andes’, was kept constant across participants.</p></sec></sec><sec id="s2-3"><title>Self-reports</title><sec id="s2-3-1"><title>Questionnaires</title><p>At the beginning of the experiment, participants completed two arousal-related questionnaires: (1) the ‘Trait’ subscale of the ‘State-Trait Anxiety Inventory’ (STAI-T; <xref ref-type="bibr" rid="bib147">Spielberger, 1983</xref>; <xref ref-type="bibr" rid="bib148">Spielberger, 1989</xref>) and (2) the ‘Sensation Seeking’ subscale of the ‘UPPS Impulsive Behaviour Scale’ (UPPS; <xref ref-type="bibr" rid="bib139">Schmidt et al., 2008</xref>; <xref ref-type="bibr" rid="bib158">Whiteside and Lynam, 2001</xref>). Before and after the experiment, participants completed a customized version of the ‘Simulator Sickness Questionnaire’ (SSQ, <xref ref-type="bibr" rid="bib16">Bouchard et al., 2017</xref>) comprising three items from the nausea (general discomfort, nausea, dizziness) and three items from the oculomotor subscale (headache, blurred vision, difficulty concentrating) to capture potential VR side effects (<xref ref-type="bibr" rid="bib145">Sharples et al., 2008</xref>). After the experiment, participants also rated the presence and valence of their experience (the results will be reported elsewhere).</p></sec></sec><sec id="s2-4"><title>Emotional arousal</title><p>After each VR experience, participants watched a 2D recording (recorded using OBS Studio, <ext-link ext-link-type="uri" xlink:href="https://obsproject.com/">https://obsproject.com/</ext-link>) of their experience on a virtual screen (SteamVR’s ‘view desktop’ feature), that is, without removing the HMD. They recalled and continuously rated their emotional arousal by turning a dial (PowerMate USB, Griffin Technology, Corona, CA; sampling frequency: 50 Hz), with which they manipulated a vertical rating bar, displayed next to the video, ranging from low (0) to high (100) in 50 discrete steps (<xref ref-type="bibr" rid="bib107">McCall et al., 2015</xref>; see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). The exact formulation was ‘When we show you the video, please state continuously how emotionally arousing or exciting the particular moment during the VR experience was’ (German: ‘Wenn wir dir das Video zeigen, gebe bitte durchgehend an, wie emotional erregend, bzw. aufregend der jeweilige Moment während der VR Erfahrung war’). To present the playback video and the rating bar, a custom script written in Processing (v3.0) was used.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Schematic of experimental setup.</title><p>(<bold>A</bold>) The participants underwent the experience (two rollercoasters separated by a break) in immersive virtual reality (VR), while EEG was recorded. (<bold>B</bold>) They then continuously rated the level of emotional arousal with a dial viewing a replay of their experience. The procedure was completed twice, without and with head movements.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig1-v2.tif"/></fig></sec><sec id="s2-5"><title>Procedure</title><p>Participants came to the lab and filled in the pre-test questionnaires. After the torso and limb electrodes had been attached, participants completed a heartbeat guessing task (<xref ref-type="bibr" rid="bib137">Schandry, 1981</xref>) to assess inter-individual differences in interoceptive accuracy (the results of peripheral physiology and interoception will be reported elsewhere). Then, the EEG cap was attached, and the HMD was carefully placed on top of it. To prevent or minimize (e.g., movement-related) artefacts, customized cushions were placed below the straps of the VR headset to reduce the contact with the EEG sensors. In addition, the VR experience took place while seated and without full body movements (participants were asked to keep their feet and arms still during the recordings). A white grid was presented in the HMD to ensure that the participants’ vision was clear. They then completed a 10 min resting-state phase (5 min eyes open, 5 min eyes closed), before experiencing the first VR episode, which consisted of the two virtual rollercoaster rides and the intermediate break: first the ‘Space’ and then, after the break, the ‘Andes’ rollercoaster. In the subsequent rating phase, they recalled and continuously rated their emotional arousal while viewing a 2D recording of their experience. Importantly, each participant completed the VR episode (plus rating) twice: once while not moving the head (<italic>nomov</italic> condition) and once while freely moving the head (<italic>mov</italic> condition) during the VR experience. The sequence of the movement conditions was counterbalanced across participants (<italic>n</italic> = 19 with nomov condition first). At the end of the experiment, participants completed two additional questionnaires (the SUS and the questionnaire on subjective feelings of presence and valence during the virtual rollercoaster rides) before they were debriefed.</p></sec><sec id="s2-6"><title>Data analysis</title><p>To exclude effects related to the on- or offset of the rollercoasters, data recorded during the first and the last 2.5 s of each rollercoaster were removed and the inter-individually slightly variable break was cropped to 30 s. The immersive VR experience that was analysed thus consisted of two time series of 270 s length each per participant (nomov and mov).</p></sec><sec id="s2-7"><title>Self-reports</title><sec id="s2-7-1"><title>Questionnaires</title><p>Inter-individual differences as assessed by the trait questionnaires were not the focus of this study, and their results (together with the peripheral physiological and interoception data) will be reported elsewhere. The sum of the simulator sickness ratings before and after the experiment was compared using a two-sided paired <italic>t</italic>-test.</p></sec></sec><sec id="s2-8"><title>Emotional arousal</title><p>Emotional arousal ratings were resampled to 1 Hz by averaging non-overlapping sliding windows, yielding one arousal value per second. For the classification analyses, ratings were divided by a tertile split into three distinct classes of arousal ratings (low, medium, high) per participant. For the binary classification (high vs. low arousal), the medium arousal ratings were discarded.</p></sec><sec id="s2-9"><title>Neurophysiology</title><sec id="s2-9-1"><title>Preprocessing</title><p>EEG data were preprocessed and analyzed with custom MATLAB (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001622">SCR_001622</ext-link>) scripts built on the EEGLAB toolbox (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_007292">SCR_007292</ext-link>, v13.5.4b; <xref ref-type="bibr" rid="bib34">Delorme and Makeig, 2004</xref>). The preprocessing steps were applied separately for data recorded during the nomov and mov conditions (i.e., without and with head movement). Continuous data were downsampled to 250 Hz (via the ‘pop_resample.m’ method in EEGLAB) and PREP pipeline (v0.55.2; <xref ref-type="bibr" rid="bib12">Bigdely-Shamlo et al., 2015</xref>) procedures were applied for detrending (1 Hz high-pass filter, Hamming windowed zero-phase sinc FIR filter, cutoff frequency (–6 dB): 0.5 Hz, filter order: 827, transition band width: 1 Hz), line-noise removal (line frequency: 50 Hz), robust referencing to average, and detection as well as spherical interpolation of noisy channels. Due to the relatively short lengths of the time series, the default fraction of bad correlation windows (parameter ‘badTimeThreshold’, used to mark bad channels) was increased to 0.05. For all other parameters, default values of PREP were kept. On average, 2.08 and 2.47 channels per subject were interpolated in the nomov and mov condition, respectively. Data remained high-pass filtered for the further steps of the analysis. Retrospective arousal ratings were added to the data sets, labelling each second of data with an associated arousal rating used as target for the later classification and regression approaches.</p><p>ICA decomposition was used to identify and remove EEG artefacts caused by eye movements, blinks, and muscular activity. To facilitate the decomposition, ICA projection matrices were calculated on a subset of the data from which the noisiest parts had been removed. To this end, a copy of the continuous data was split into 270 epochs of 1 s length. Epochs containing absolute voltage values &gt; 100 µV in at least one channel (excluding channels that reflected eye movements, i.e., EOG channels, Fp1, Fp2, F7, F8) were deleted. Extended infomax (<xref ref-type="bibr" rid="bib94">Lee et al., 1999</xref>) ICA decomposition was calculated on the remaining parts of the data (after correcting for rank deficiency with a principal component analysis). Subjects with &gt;90 to-be-deleted epochs (33% of the data) were discarded from further analyses (nomov: <italic>n</italic> = 5; mov: <italic>n</italic> = 10). Artefactual ICA components were semi-automatically selected using the SASICA extension (<xref ref-type="bibr" rid="bib22">Chaumon et al., 2015</xref>) of EEGLAB and visual inspection. On average, 13.41 (nomov) and 10.31 (mov) components per subject were discarded. The remaining ICA weights were back-projected onto the continuous time series.</p></sec></sec><sec id="s2-10"><title>Dimensionality reduction: SSD in the (individual) alpha frequency range</title><p>Our main hypothesis was that EEG-derived power in the alpha frequency range allows the discrimination between different states of arousal. To calculate alpha power, we adopted spatio-spectral decomposition (SSD; <xref ref-type="bibr" rid="bib116">Nikulin et al., 2011</xref>) which extracts oscillatory sources from a set of mixed signals. Based on generalized eigenvalue decomposition, it finds the linear filters that maximize the signal in a specific frequency band and minimize noise in neighbouring frequency bands. Preprocessing with SSD has been previously shown to increase classification accuracy in BCI applications (<xref ref-type="bibr" rid="bib61">Haufe et al., 2014a</xref>). The alpha frequency range is typically fixed between 8 and 13 Hz. The individual alpha peak frequency, however, varies intra- and inter-individually, for example, with age or cognitive demand (<xref ref-type="bibr" rid="bib58">Haegens et al., 2014</xref>; <xref ref-type="bibr" rid="bib110">Mierau et al., 2017</xref>). To detect each participant’s individual peak of alpha oscillations for the SSD, (1) the power spectral density (PSD) of each channel was calculated using Welch’s method (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> [i.e., 250 Hz] with 50% overlap) in MATLAB (<italic>pwelch</italic> function). (2) To disentangle the power contribution of the 1/<italic>f</italic> aperiodic signal from the periodic component of interest (i.e., alpha), the MATLAB wrapper of the FOOOF toolbox (v0.1.1; <xref ref-type="bibr" rid="bib59">Haller et al., 2018</xref>; frequency range: 0–40 Hz, peak width range: 1–12 Hz, no minimum peak amplitude, threshold of two SDs above the noise of the flattened spectrum) was used. The maximum power value in the 8–13 Hz range was considered the individual alpha peak frequency <italic>α</italic><sub><italic>i</italic></sub>, on which the SSD bands of interest were defined (bandpass signal <italic>α</italic><sub><italic>i</italic></sub> ± 2 Hz, bandstop noise <italic>α</italic><sub><italic>i</italic></sub> ± 3 Hz, bandpass noise <italic>α</italic><sub><italic>i</italic></sub> ± 4 Hz).</p><p>The entire procedure was separately applied to the nomov and the mov condition to account for potential peak variability (<xref ref-type="bibr" rid="bib58">Haegens et al., 2014</xref>; <xref ref-type="bibr" rid="bib110">Mierau et al., 2017</xref>). SSD was then computed based on these peaks. A summary of the resulting individual alpha peak frequencies can be found in <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>. <xref ref-type="fig" rid="fig2">Figure 2</xref> shows the averaged power spectrum across all participants and electrodes. A clearly defined peak in the alpha frequency range is discernible for both conditions (nomov, mov) as well as for states of high and low emotional arousal.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Group averaged power spectra for the two emotional arousal levels (low, high) and head movement conditions (nomov, mov).</title><p>Thick lines represent the mean log-transformed power spectral density of all participants and electrodes. Shaded areas indicate the standard deviation of the participants. High and low emotional arousal are moments that have been rated as most (top tertile) and least arousing (bottom tertile), respectively (the middle tertile was discarded; see main text). The power spectra were produced using MATLAB’s <italic>pwelch</italic> function with the same data (after ICA correction and before spatio-spectral decomposition [SSD] filtering) and parameters as the individual alpha peak detection (see Materials and methods section for details). A tabular overview of the alpha peak frequencies of the individual participants is available as <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Selected alpha peaks (8–13 Hz) per participant and condition.</title><p>Results of FOOF computations for three different conditions: eyes-closed resting state, nomov, and mov.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-64812-fig2-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig2-v2.tif"/></fig><sec id="s2-10-1"><title>SSD components selection</title><p>The SSD components with sufficient alpha information (i.e., power in the alpha frequency range that exceeds the noise level) were selected with the following steps (see <xref ref-type="fig" rid="fig3">Figure 3</xref>):</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Schematic of the selection of individual alpha components using spatio-spectral decomposition (SSD).</title><p>(<italic>Left</italic>) 1/<italic>f</italic> estimation (dotted grey line) to detrend SSD components (solid turquoise line). (<italic>Right</italic>) After detrending the signal, components were selected, whose peak in the detrended alpha window (centred at the individual alpha peak, vertical dotted grey line) was (<bold>A</bold>) &gt; 0.35 V<sup>2</sup>/Hz (indicated by horizontal dotted red line) and (<bold>B</bold>) higher than the bigger of the two mean amplitudes of the adjacent frequency flanks (2 Hz width).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig3-v2.tif"/></fig><list list-type="order"><list-item><p>The PSD of a component was calculated using Welch’s method (<inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> [i.e., 250 Hz] with 50% overlap) implemented in SciPy (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_008058">SCR_008058</ext-link>, v1.4.1; <xref ref-type="bibr" rid="bib76">Jones et al., 2001</xref>).</p></list-item><list-item><p>The 1/<italic>f</italic> curve was fitted in the signal range between 0 and 40 Hz, excluding a ± 4 Hz window around the individual <italic>alpha peak frequency α</italic><sub><italic>i</italic></sub> of the subject <italic>i</italic>. The 1/<italic>f</italic> curve was defined (in log scale) as <inline-formula><mml:math id="inf3"><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></inline-formula> , where <italic>x</italic> is the given component in the frequency domain, <inline-formula><mml:math id="inf4"><mml:mi>a</mml:mi></mml:math></inline-formula> serves as stretch parameter, and <inline-formula><mml:math id="inf5"><mml:mi>b</mml:mi></mml:math></inline-formula> represents the slope of the 1/<italic>f</italic> curve.</p></list-item><list-item><p>After fitting these parameters, the signal was detrended with respect to the estimated 1/<italic>f</italic> curve.</p></list-item><list-item><p>Those components were selected, whose alpha peak power in the detrended alpha window (as defined in (1)) was (A) greater than zero plus a decision threshold, which was set to 0.35 <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>μ</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">H</mml:mi><mml:mi mathvariant="normal">z</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula> , and (B) higher than the mean amplitude of the adjacent frequency flanks of 2 Hz width on both sides of the window, that is, <inline-formula><mml:math id="inf7"><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>p</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>f</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>≥</mml:mo><mml:mn>1.45</mml:mn><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:math></inline-formula> (after <italic>z</italic>-scoring the detrended signal). The two criteria guaranteed the selection of components with a clearly defined alpha-amplitude peak over the noise-threshold defined by <inline-formula><mml:math id="inf8"><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig3">Figure 3</xref>).</p></list-item></list><p>Particularly the combination of SSD with narrow-band filtering in the alpha-frequency range lowers the probability of signal contamination elicited by artefact-related oscillations, which are typically strongest in frequency ranges above (e.g., muscular activity; <xref ref-type="bibr" rid="bib113">Muthukumaraswamy, 2013</xref>) or below the alpha band (e.g., skin potentials, <xref ref-type="bibr" rid="bib78">Kappenman and Luck, 2010</xref>, or eye blinks, <xref ref-type="bibr" rid="bib102">Manoilov, 2007</xref>; for a comprehensive overview, see also <xref ref-type="bibr" rid="bib22">Chaumon et al., 2015</xref>). Decoding models (SPoC, CSP, LSTM; described below) were trained on those subjects with at least four selected SSD components (26 in the nomov and 19 in the mov). On average, 7.63 of 18.81 (40.53 %) in the nomov and 5.63 of 15.22 (36.98 %) SSD components were selected in the mov condition. Importantly, SSD components had spatial topographies corresponding to occipito-parietal and fronto-central source locations, thus covering brain areas previously implicated in emotional arousal and its regulation.</p></sec></sec><sec id="s2-11"><title>Source power comodulation</title><p>To test the hypothesis that alpha power in the EEG negatively covaries with the continuous level of subjective emotional arousal, SPoC (as described in <xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>; NB: throughout the paper, ‘SPoC’ refers to SPoC<sub>λ</sub>) was applied to EEG data composed of the selected SSD components and filtered around the central individual alpha peak. Formally, SPoC is an extension of CSP (see below) for regression-like decoding of a continuous target variable. The information contained in the target variable is used to guide the decomposition of neural components that is correlated or anti-correlated with it (<xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>). SPoC has been shown to outperform more conventional approaches to relate neural time series to continuous behavioural variables (e.g., correlating power extracted in sensor space and/or after blind source separation methods), which also suffer from additional drawbacks (e.g., lack of patterns’ interpretability and lack of adherence to the M/EEG generative model; for details, see <xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>). The supervised decomposition procedure takes the variable <italic>z</italic> as target, which comprises the continuous arousal ratings (normalized and mean-centred; 270 s per participant). To reach the same temporal resolution as <italic>z</italic> (i.e., 1 Hz), EEG data were epoched into 270 consecutive segments of 1 s length. For a specific epoch <inline-formula><mml:math id="inf9"><mml:mfenced separators="|"><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> , the power of an SPoC component (<inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>X</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf11"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> corresponds the transpose of the unmixing matrix <inline-formula><mml:math id="inf12"><mml:mi>W</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf13"><mml:mi>X</mml:mi></mml:math></inline-formula> to the data matrix of <inline-formula><mml:math id="inf14"><mml:mi>e</mml:mi></mml:math></inline-formula> in SSD space) can be approximated by the variance of its signal within that time interval (<inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>). SPoC was separately applied to each participant, producing a number of components equal to the number of previously selected SSD components. The stability and significance of the extracted components was tested with a permutation approach (1000 iterations): <italic>z</italic> values were shuffled to create a surrogate target variable with randomized phase but same auto-correlation (<xref ref-type="bibr" rid="bib152">Theiler et al., 1992</xref>; adapted from the original SPoC function: <ext-link ext-link-type="uri" xlink:href="https://github.com/svendaehne/matlab_SPoC/blob/master/SPoC/spoc.m">https://github.com/svendaehne/matlab_SPoC/blob/master/SPoC/spoc.m</ext-link>; <xref ref-type="bibr" rid="bib28">Dähne, 2015</xref>, <xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>). In accordance with the primary objective of SPoC to reconstruct the target variable <italic>z,</italic> lambda values (<italic>λ,</italic> i.e., optimization criterion of SPoC: component-wise covariance between <italic>z</italic> and alpha power; sorted from most positive to most negative) and corresponding Pearson correlation values (<italic>r</italic>) between <italic>z</italic> and the estimated <italic>z<sub>est</sub></italic> (obtained via <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>X</mml:mi></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>) were then calculated for each iteration to generate a naive probability density function (i.e., null hypothesis distribution) and to estimate the probability that the correlation value that was calculated with the original target variable <italic>z</italic> was obtained by chance. Of note, <italic>z<sub>est</sub></italic> denotes the power time course of the spatially filtered signal that maximally covaries with the behavioural variable <italic>z</italic>. Depending on <italic>i</italic> (i.e., from which side of the SPoC unmixing matrix the component is chosen), <italic>z<sub>est</sub></italic> will be (maximally) positively (left side of the matrix) or (maximally) negatively (right side of the matrix) correlated with <italic>z</italic>. Given our main hypothesis of an inverse relationship between alpha power and self-reported emotional arousal, we therefore only retained, for each participant, the component with the most negative (precisely: ‘smallest’) lambda value <italic>λ</italic> (disregarding the p-value to avoid circularity; <xref ref-type="bibr" rid="bib86">Kriegeskorte et al., 2009</xref>), corresponding to the last column of the unmixing matrix <inline-formula><mml:math id="inf17"><mml:mi>W</mml:mi></mml:math></inline-formula>.</p><p>In line with our hypothesis, single participants’ p-values were then obtained by computing the number of permuted <italic>r</italic> values that were smaller than the one estimated with SPoC.</p><p>Crucially, since the extracted linear spatial filters <inline-formula><mml:math id="inf18"><mml:mi>W</mml:mi></mml:math></inline-formula> cannot be directly interpreted (<xref ref-type="bibr" rid="bib62">Haufe et al., 2014b</xref>), topographical scalp projection of the components are represented by the columns of the spatial patterns matrix <inline-formula><mml:math id="inf19"><mml:mi>A</mml:mi></mml:math></inline-formula> obtained by inverting the full matrix <inline-formula><mml:math id="inf20"><mml:mi>W</mml:mi></mml:math></inline-formula> (Figure 6).</p></sec><sec id="s2-12"><title>Common spatial patterns</title><p>To further test the hypothesis of a link between alpha power and subjective emotional arousal, we aimed to distinguish between the most and the least arousing phases of the experience by using features of the alpha bandpower of the concurrently acquired EEG signal. We followed an approach which has successfully been used in BCI research to discriminate between event- or state-related changes in the bandpower of specific frequency ranges in the EEG signal: the common spatial patterns algorithm specifies, by means of a generalized eigenvalue decomposition, a set of spatial filters to project the EEG data onto components whose bandpower maximally relates to the prevalence of one of two dichotomous states (<xref ref-type="bibr" rid="bib14">Blankertz et al., 2008</xref>; <xref ref-type="bibr" rid="bib126">Ramoser et al., 2000</xref>). In our case, we were interested in distinguishing moments that had been rated to be most (top tertile) and least arousing (bottom tertile).</p><p>Using the EEGLAB extension BCILAB (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_007013">SCR_007013</ext-link>, v1.4-devel; <xref ref-type="bibr" rid="bib83">Kothe and Makeig, 2013</xref>), data of the selected SSD components, bandpass filtered around the individual alpha peak ±2 Hz, were epoched in 1 s segments. This sample length was chosen to enable the extraction of neural features and corresponding changes in the subjective experience, while maximizing the number of samples from the sparse datasets. Epochs with mid-level arousal ratings (middle tertile) were discarded, yielding 180 epochs (90 per class) for each subject (per movement condition). To assess the classification performance, a randomized 10-fold cross-validation procedure, a common solution for sparse training data (<xref ref-type="bibr" rid="bib13">Bishop, 2006</xref>), was used. Per fold, a CSP-based feature model was calculated on the training data by decomposing the signal of the selected SSD components according to the CSP algorithm. A feature vector comprising the logarithmized variance of the four most discriminative CSP components (using two columns from each side of the eigenvalue decomposition matrix as spatial filters) was extracted per epoch. Data from the training splits were used to train a linear discriminant analysis (LDA) on these feature vectors (<xref ref-type="bibr" rid="bib42">Fisher, 1936</xref>). Covariance matrices used for calculating the LDA were regularized by applying the analytic solution implemented in BCILAB (<xref ref-type="bibr" rid="bib93">Ledoit and Wolf, 2004</xref>). The LDA model was then used to classify the feature vectors extracted from the epochs in the test split to predict the according arousal label. Average classification accuracy (defined as <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) over the 10 folds was taken as the outcome measure to assess the predictive quality of the approach. To allow a spatial interpretation of the projections, like with the SPoC components, the spatial patterns of the two most extreme CSP components (associated with the largest and smallest eigenvalue) that were used to calculate the feature vectors for the linear classification were plotted in Figure 6 (normalized and averaged across subjects per condition) and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> (per single subject and condition). Source localized patterns are shown in Figure 9.</p></sec><sec id="s2-13"><title>Sub-blocked cross-validation</title><p>For non-stationary, auto-correlated time-series data, randomized cross-validation can inflate the decoding performance (<xref ref-type="bibr" rid="bib130">Roberts et al., 2017</xref>). To assess and minimize this possibility, we tested whether a blocked cross-validation, which preserves temporal neighbourhood structures among samples, changes the classification results of the CSP analysis. To ensure balanced classes in the training set, the ‘synthetic minority oversampling technique’, which oversamples the less frequently represented class, was applied (<xref ref-type="bibr" rid="bib23">Chawla et al., 2002</xref>; as implemented in <xref ref-type="bibr" rid="bib91">Larsen, 2021</xref>). The test set was left unbalanced as oversampling of test data can invalidate the assessment of model performance (<xref ref-type="bibr" rid="bib4">Altini, 2015</xref>), and the area under the curve of the receiver operating characteristic (ROC-AUC) was used as a performance measure. To avoid homogeneous test sets (i.e., with samples from only one target class), which (1) would occur in many subjects after ‘conventional’ chronological cross-validation and (2) would preclude ROC-AUC calculation, a ‘sub-blocked’ cross-validation was used: for each subject, the dataset was split into three sub-blocks of equal length, which were then used to stratify the data assignment for a (sub-blocked) chronological 10-fold cross-validation. In this design, each fold consists of a concatenation of equally sized stretches of consecutive data samples taken from each of the sub-blocks: for example, to build the validation set in the first fold [<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, <italic>x</italic><sub>3</sub>], with <italic>x</italic><sub><italic>i</italic></sub> being the <italic>n</italic> first samples from the <italic>i</italic>th sub-block where <italic>n</italic> is the total number of samples in the dataset divided by 10 * 3 (number of folds * number of sub-blocks). Thereby the temporal neighbourhood structure among data samples is largely preserved when splitting them into training and testing sets. The (smaller) test set is still sampled from different parts of the experience, which decreases the risk of obtaining homogeneous test sets (e.g., only ‘low arousing’ sections).</p></sec><sec id="s2-14"><title>Source localization</title><p>Exact low-resolution tomography analysis (eLORETA, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_007077">SCR_007077</ext-link>; <xref ref-type="bibr" rid="bib123">Pascual-Marqui, 2007</xref>) was used to localize the sources corresponding to the component extracted via SPoC and CSP. Our pipeline was based on the work of <xref ref-type="bibr" rid="bib72">Idaji et al., 2020</xref>, who customized the eLORETA implementation of the M/EEG Toolbox of Hamburg (<ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/projects/meth/">https://www.nitrc.org/projects/meth/</ext-link>).</p><p>Our forward model was constructed via the New York Head model (<xref ref-type="bibr" rid="bib62">Haufe et al., 2014b</xref>; <xref ref-type="bibr" rid="bib63">Haufe and Ewald, 2019</xref>; <xref ref-type="bibr" rid="bib70">Huang et al., 2016</xref>) with approximately 2000 voxels and by using 28 out of 30 scalp electrodes (TP9 and TP10 were removed because they are not contained in the model). Crucially, we focused on dipoles perpendicular to the cortex. eLORETA was then used to construct a spatial filter for each voxel from the leadfield matrix, and respective sources were computed by multiplying the resultant demixing matrix with the spatial patterns <inline-formula><mml:math id="inf22"><mml:mi>A</mml:mi></mml:math></inline-formula> of the selected SPoC and CSP components. Inverse modelling was computed separately per participant and condition before it was averaged for each condition across all subjects (Figure 9).</p></sec><sec id="s2-15"><title>LSTM RNN</title><p>Deep learning models have become a useful tool to decode neural information (e.g., <xref ref-type="bibr" rid="bib3">Agrawal et al., 2014</xref>; <xref ref-type="bibr" rid="bib80">Khaligh-Razavi and Kriegeskorte, 2014</xref>). Applying a deep learning approach to the time series of EEG recordings (e.g., <xref ref-type="bibr" rid="bib8">Bashivan et al., 2016</xref>) can be achieved using LSTM RNNs (<xref ref-type="bibr" rid="bib67">Hochreiter and Schmidhuber, 1995</xref>; <xref ref-type="bibr" rid="bib68">Hochreiter and Schmidhuber, 1997</xref>). With their property to store and control relevant information over time, they can find adjacent as well as distant patterns in (time) sequential data. The LSTM analysis was implemented in the Python-based (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_008394">SCR_008394</ext-link>) deep learning library <italic>TensorFlow</italic> (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_016345">SCR_016345</ext-link>, v1.14.0; Google Inc, USA; <xref ref-type="bibr" rid="bib1">Abadi et al., 2015</xref>; <xref ref-type="bibr" rid="bib164">Zaremba et al., 2015</xref>).</p></sec><sec id="s2-16"><title>Model architecture and hyperparameter search</title><p>Deep learning models usually have a high variance due to random weight initialization, architectural choices, and hyperparameters (HPs; <xref ref-type="bibr" rid="bib47">Geman et al., 1992</xref>; but see <xref ref-type="bibr" rid="bib115">Neal et al., 2019</xref>). We here used a two-step random search (<xref ref-type="bibr" rid="bib10">Bergstra and Bengio, 2012</xref>) strategy in order to find optimal HPs, to reduce the model variance and make the search computationally feasible. First, a broad random search was applied on a random subset of 10 subjects (20 random combinations) in each condition. Then, the two best HPs per subject were taken and applied to the datasets of all subjects. Due to time constraints and computational complexity, the HP search was limited to a predefined range of settings and the model architecture was constrained to maximal two LSTM layers followed by maximal two fully connected layers (<italic>FC</italic>; <xref ref-type="bibr" rid="bib64">Hefron et al., 2017</xref>; see <xref ref-type="fig" rid="fig4">Figure 4</xref>). Each layer size <italic>ls<sub>l</sub></italic> varied between 10 and 100 nodes (<italic>ls<sub>l</sub></italic> ∈ 10, 15, 20, 25, 30, 40, 50, 65, 80, 100), and a successive layer needed to be equal or smaller in size (bottleneck architecture). The output of each layer was squashed through either rectified linear units or exponential linear units, which both allow for steeper learning curves in contrast to conventional activation functions such as sigmoid nonlinearity (<xref ref-type="bibr" rid="bib25">Clevert et al., 2016</xref>). The output of the last network layer (<italic>FC<sub>L</sub></italic>) was fed into a tangens hyperbolicus (<italic>tanh</italic>) to match the binned ratings, which were labelled with –1 or 1, respectively. We applied a mean-squared error loss to calculate the difference between the model output (i.e., the prediction) and the labels, leading to a stronger weighting of losses at the upper- or lower-class border, respectively. To control and tax too large model weights, different regularization methods (<italic>L</italic>1, <italic>L</italic>2) with different regularization strengths (Λ ∈ 0.00, 0.18, 0.36, 0.72, 1.44) were tested. Weights were optimized using <italic>Adam</italic> (learning rate: <italic>lr</italic> ∈ 1<italic>e<sup>–2</sup></italic>, 1<italic>e<sup>–3</sup></italic>, 5<italic>e<sup>–4</sup></italic>) due to its fast convergence (<xref ref-type="bibr" rid="bib104">Marti, 2015</xref>; see also <xref ref-type="bibr" rid="bib132">Ruder, 2017</xref>). The number of input components (SSD, <italic>N<sub>comp</sub></italic>: <italic>N</italic> ∈ [1, 10]) was treated as HP. The specific <italic>N<sub>comp</sub></italic> neural components were successively drawn according to the order of the SSD selection.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Schematic of the long short-term memory (LSTM) recurrent neural network (RNN).</title><p>At each training step, the LSTM cells successively slide over 250 data arrays of neural components (<italic>x</italic><sub><italic>t</italic>=0</sub>, <italic>x</italic><sub><italic>t</italic>=1</sub>,..., <italic>x</italic><sub><italic>T</italic>=249</sub>) corresponding to 1 s of the EEG recording. At each step <italic>t</italic>, the LSTM cell computes its hidden state <italic>h<sub>t</sub></italic>. Only the final LSTM output (<italic>h<sub>T</sub></italic>) at time-step <italic>T</italic> = 249 is then fed into the following fully connected (FC) layer. The outputs of all (LSTMs, FCs) but the final layer are normalized by rectified linear units (ReLU) or exponential linear units (ELU). Finally, the model prediction is extracted from the last FC layer via a tangens hyperbolicus (<italic>tanh</italic>). Note: depending on model architecture, there were one to two LSTM layers, and one to two FC layers. The hyperparameter constellations that yielded the highest accuracy for the individual participants per movement condition are available as <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Long short-term memory (LSTM) hyperparameter search per movement condition.</title><p><italic>LSTM</italic>: number of cells per layer. <italic>FC</italic>: number of hidden units in fully connected layer, before final output neuron. <italic>l.rate</italic>: learning rate. <italic>reg</italic>.: type of weight regularizer. <italic>reg. strength</italic>: respective regularization strength. <italic>activ.func</italic>: intermediate layer activation function. <italic>components</italic>: individually selected components for training after spatio-spectral decomposition (SSD) selection.</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-64812-fig4-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig4-v2.tif"/></fig></sec><sec id="s2-17"><title>Training procedure</title><p>The final dataset per subject was a three-dimensional tensor of size 270 × 250 × 10 <italic>(epochs × samples × components</italic>). If less than 10 components were extracted for a given subject, the tensor was filled with zero vectors. After some test runs and visual observation of the convergence behaviour of the learning progress, training iterations were set to 20 (i.e., the model ran 20 times through the whole training dataset). The 1 s samples were fed into the LSTM in random mini-batches of size 9 (bs = 9), since training on batches allows for faster and more robust feature learning (<xref ref-type="bibr" rid="bib132">Ruder, 2017</xref>), leading to the following input tensor at training step <italic>ts</italic>: <inline-formula><mml:math id="inf23"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>s</mml:mi><mml:mi>x</mml:mi><mml:mn>250</mml:mn><mml:mi>x</mml:mi><mml:mn>10</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> .</p></sec><sec id="s2-18"><title>Statistical evaluation</title><p>To test whether the results of the binary modelling approaches (CSP, LSTM) were statistically significantly above chance level, exact binomial tests were conducted per subject and experimental condition (nomov, mov) over all 180 epochs of the respective time series (nomov, mov). To do so, for each of the binary modelling approaches (CSP, LSTM), the predictions for the single epochs in the 10 test splits of the cross-validation were concatenated to a single vector. The proportion of correct and false predictions was then compared to a null model with prediction accuracy 0.5 (chance level). To test the average (across subjects) classification accuracies of the binary models, we calculated one-sided one-sample <italic>t-</italic>tests, comparing the mean accuracy of the respective model for both experimental conditions against the theoretical prediction accuracy of a random classifier (0.5). To test whether classification accuracies differed between the two models (CSP, LSTM) or between the experimental conditions (nomov, mov), a repeated-measures two-way ANOVA was conducted on the accuracy scores of all subjects with preprocessed data from both conditions (<italic>n</italic> = 18).</p><p>To account for potential biases due to auto-correlations in the time series which might affect the statistical evaluation of the classification model, in an additional control analysis, block permutation testing was applied to the CSP approach: to maintain a local auto-correlative structure similar to the original data in the permuted target vectors, the time series were split into 10 equally sized blocks, which were then shuffled while the internal temporal structure of each block remained intact (<xref ref-type="bibr" rid="bib160">Winkler et al., 2014</xref>). To test whether the actual decoding scores (from non-permuted data) were significantly above chance level, we assessed their percentile rank in relation to the null distributions (1000 permutations) on the single-subject level. On the group level, one-sided paired <italic>t</italic>-tests were used to compare the distribution of the actual decoding results against the distribution of the means of the null distributions per subject. Due to its high computational processing cost and duration, we did not perform permutation testing for the LSTM model.</p><p>For SPoC, in addition to the aforementioned within-participants permutation approach yielding a single p-value for each component, group-level statistics were assessed: the hypothesis of a negative correlation between alpha power and emotional arousal was tested with a one-sample, one-tailed <italic>t-</italic>test on the correlation values between <italic>z</italic> and <italic>z<sub>est</sub></italic>, which assessed whether the mean correlation value per condition was significantly lower than the average of the permuted ones.</p><p>The code for preprocessing of the data, the three prediction models, and the statistical evaluation is available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/NeVRo-study/NeVRo">https://github.com/NeVRo-study/NeVRo</ext-link>; <xref ref-type="bibr" rid="bib69">Hofmann et al., 2021</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:b3468cf3e097ca0e3895c0df3df43d0308dd7ced;origin=https://github.com/NeVRo-study/NeVRo;visit=swh:1:snp:371d20714cc61dc507acc50316bc42894bc8679c;anchor=swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5">swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5</ext-link>).</p></sec><sec id="s2-19"><title>Control analysis: excluding the break for model training</title><p>The 30 s break differed from the rollercoaster rides in visual features (e.g., static vs. dynamic input) and in arousal ratings, which were constantly relatively low during the break (see <xref ref-type="fig" rid="fig5">Figure 5</xref>). Thus, the break contributed mainly to the ‘low arousing’ class. To test whether the decoding approaches also succeed if the break section is excluded from the analysis, SPoC and CSP decoding were repeated for the data without the break, that is, the rollercoasters only (240 s in total). The LSTM approach was skipped in this control analysis due to its computational processing cost and duration, and the comparable performance with CSP in the main analysis. For the classification (CSP), the tertile split on the subjective arousal ratings was recalculated such that the class of ‘low arousal’ segments now comprises the least arousing sections of the rollercoasters. We then trained and tested the SPoC and CSP models with the procedures that were used for the original dataset (incl. the break). For maximal stringency, we used the sub-blocked cross-validation and block permutation approach to assess the performance of the CSP model. To test whether excluding the break changed the model performance, we compared the distributions of the decoding performance parameters (SPoC: Pearson correlation with target; CSP: ROC-AUC) from the data with and without the break using two-sided paired <italic>t</italic>-tests. We did this per model and movement condition.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Subjective emotional arousal ratings (movement condition).</title><p>Emotional arousal ratings of the experience (with head movement; see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for the ratings from the no-movement condition). Coloured lines: individual participants; black line: mean across participants; vertical lines (light grey): beginning of the three phases (Space Coaster, Break, Andes Coaster); vertical lines (dark grey): manually labelled salient events (for illustration). Bottom row: exemplary screenshots of the virtual reality (VR) experience. The ratings for the condition without head movement are shown in the figure supplement.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Subjective emotional arousal ratings (no-movement condition).</title><p>Emotional arousal ratings of the experience (without head movement). Coloured lines: individual participants; black line: mean across participants; vertical lines (light grey); beginning of the three phases (Space Coaster, Break, Andes Coaster); vertical lines (dark grey): manually labelled salient events (for illustration).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig5-figsupp1-v2.tif"/></fig></fig-group></sec></sec><sec id="s3" sec-type="results"><title>Results</title><sec id="s3-1"><title>Participants</title><p>Forty-five healthy young participants (22 men, M ± SD: 24.6 ± 3.1, range: 20–32 years) completed the experiment. Data from eight participants needed to be discarded due to technical problems (<italic>n</italic> = 5) or electrode malfunctioning (<italic>n</italic> = 1); one participant discontinued the experiment and another participant reported having taken psychoactive medication. The data from 37 participants entered the analysis (17 men, age: M ± SD: 25.1 ± 3.1, range: 20–31 years). After quality assurance during the EEG preprocessing, data from 26 participants in the condition with no head movement (nomov) and 19 in condition with free head movement (mov) entered the statistical analyses that included EEG data.</p></sec><sec id="s3-2"><title>Self-reports</title><sec id="s3-2-1"><title>Questionnaires</title><p>From before (M ± SD: 8.68 ± 2.82, range: 6–17) to after the experiment (M ± SD: 11.82 ± 5.24, range: 6–29), the overall simulator sickness (e.g., nausea, headache) increased significantly (<italic>t</italic>(36) = 3.72, p = 0.0007). As the trait questionnaires are not the focus of this study, their results will be reported elsewhere.</p></sec><sec id="s3-2-2"><title>Emotional arousal ratings</title><p>The retrospective emotional arousal ratings for the VR experience, averaged across all subjects and timepoints, were 46.94 ± 12.50 (M ± SD, range: 16.17–66.29) in the nomov and 50.06 ± 12.55 (M ± SD, range: 18.00–69.94) in the mov condition. Qualitatively, the emotional arousal was highest for the <italic>Andes Coaster,</italic> lower for the <italic>Space Coaster</italic>, and lowest for the break (see <xref ref-type="fig" rid="fig5">Figure 5</xref>).</p></sec></sec><sec id="s3-3"><title>Neurophysiology</title><sec id="s3-3-1"><title>SPoC</title><p>SPoC results showed that for 24/26 (92.30%) participants in the nomov and 16/19 (84.21%) participants in the mov condition (see <xref ref-type="supplementary-material" rid="fig10sdata1">Figure 10—source data 1</xref> for single-participant results), the component with the highest absolute lambda value corresponded to the one that maximized the negative correlation between <italic>z</italic> (normalized and mean-centred subjective ratings) and alpha power. Based on permutation-based testing (1000 iterations; exact p values are reported in <xref ref-type="supplementary-material" rid="fig10sdata1">Figure 10—source data 1</xref>), the negative correlation was statistically significant (p &lt; 0.05) in 8/26 (30.76%) participants for the nomov and 7/19 (36.84%) participants for the mov condition. The global mean lambda value of these components was –0.46 for the nomov (range: –1.49 to +0.08) and –0.42 for the mov condition (range: –1.49 to +0.02). The mean Pearson correlation value between the target variable <italic>z</italic> and <italic>z</italic><sub><italic>est</italic></sub> (estimated target variable) was significantly lower than the average of single participants’ permuted ones for both the nomov (M ± SD: –0.25 ± 0.12; range: –0.53 to + 0.09; <italic>t<sub>nomov</sub></italic>(25) = –3.62; p &lt; 0.01) and the mov condition (M ± SD: –0.25 ± 0.12; range: –0.52 to +0.04; <italic>t<sub>mov</sub></italic>(18) = –3.13; p &lt; 0.01).</p></sec></sec><sec id="s3-4"><title>CSP</title><p>The classifier based on CSP was able to decode significantly above chance level whether a subject experienced high or low emotional arousal during a given second of the experience. On average, the classification accuracy was 60.83% ± 7.40% (M ± SD; range: 47.22–77.78%) for the nomov, and 60.76% ± 6.58% (M ± SD; range: 48.33–71.67%) for the mov condition. Both were significantly above chance level (<italic>t<sub>nomov</sub></italic>(25) = 7.47, p<italic><sub>nomov</sub></italic> &lt; 0.001; <italic>t<sub>mov</sub></italic>(18) = 7.12, p<italic><sub>mov</sub></italic> &lt; 0.001). At the single-subject level, the classification accuracy was significantly above chance level (p &lt; 0.05) for 17/26 (65.38%) participants in the nomov, and for 12/19 (63.16%) participants in the mov condition (see <xref ref-type="supplementary-material" rid="fig10sdata1">Figure 10—source data 1</xref> for single-participant results). The spatial patterns yielded by the CSP decomposition are shown in <xref ref-type="fig" rid="fig6">Figure 6</xref> (across participants) and in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> (individual participants). Corresponding alpha power sources (located via eLORETA) are shown in Figure 9.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Spatial patterns resulting from spatio-spectral decomposition (SSD), source power comodulation (SPoC), and common spatial pattern (CSP) decomposition.</title><p>Colours represent absolute normalized pattern weights (inverse filter matrices) averaged across all subjects per condition (nomov: without head movement, mov: with head movement). Before averaging, the pattern weight vectors of each individual subject were normalized by their respective L2-norm. To avoid cancellation due to the non-polarity-aligned nature of the dipolar sources across subjects, the average was calculated from the absolute pattern weights. SSD allows the extraction of components with a clearly defined spectral peak in the alpha frequency band. Shown are the patterns associated with the four SSD components that yielded the best signal-to-noise ratio (<italic>left column</italic>). The SSD filtered signal was the input for the decoding approaches SPoC, CSP, and LSTM: SPoC adds a spatial filter, optimizing the covariance between the continuous emotional arousal ratings and alpha power. Shown here is the pattern of the component which – in line with our hypothesis – maximized the inverse relationship between emotional arousal and alpha power. CSP decomposition yielded components with maximal alpha power for low-arousing epochs and minimal for high-arousing epochs (<italic>bottom row in the CSP panel</italic>) or vice versa (<italic>upper row in the CSP panel</italic>). The high correspondence between the patterns resulting from SPoC and CSP seems to reflect that both algorithms converge to similar solutions, capturing alpha power modulations in parieto-occipital regions as a function of emotional arousal. The spatial patterns for the individual subjects are displayed in the figure supplement. (Note: as the LSTM results cannot be topographically interpreted, they are not depicted here.)</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Spatial patterns per single subject and movement condition yielded by the different spatial signal decompositions.</title><p>For spatio-spectral decomposition (SSD) the four patterns corresponding to the four highest eigenvalues among the accepted components (see Materials and methods) are displayed (note: subjects with less than four accepted SSD components were discarded for further analysis; for subjects with more than four accepted components, all of these components went into the further analyses but only the first four patterns are shown here). For source power comodulation (SPoC) the pattern associated with the component that yielded the strongest correlation between target and source power is displayed. For common spatial patterns (CSP) the patterns associated with the components that maximized power during states of low and high emotional arousal are shown.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig6-figsupp1-v2.tif"/></fig></fig-group><p>To test for potential biases from the model or the data, specifically its auto-correlative properties, we ran a control analysis for CSP using sub-blocked chronological cross-validation and block permutation for statistical evaluation on the single-subject level.</p><p>Also under these – more strict – evaluation criteria, the average decoding performance (ROC-AUC) for CSP was significantly above chance level, both in the nomov (ROC-AUC: 0.61 ± 0.09 M ± SD, range: 0.42–0.79; <italic>t</italic>(25) = 4.59, p &lt; 0.001) and in the mov condition (ROC-AUC: 0.60 ± 0.09 M ± SD, range: 0.44–0.74; <italic>t</italic>(18) = 3.27, p &lt; 0.01). On the single-subject level (as assessed by permutation tests), decoding performance was significantly (p &lt; 0.05) higher when decoding the actual, unpermuted labels compared to the block-permuted labels for 9/26 (34.62%) participants in the nomov and 5/19 (26.32%) participants in the mov condition.</p></sec><sec id="s3-5"><title>LSTM</title><p>After a random search over a constrained range of HPs, we extracted the best individual HP set per subject (see <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref> for the list of best HPs per condition). The mean classification accuracy was 59.42% ± 4.57% (M ± SD; range: 52.22–68.33%) for the nomov, and 61.29% ± 4.5 % (M ± SD; range: 53.89–71.11%) for the mov condition. Both were significantly above chance level (<italic>t<sub>nomov</sub></italic>(25) = 10.82, p<sub>nomov</sub> &lt; 0.001; <italic>t<sub>mov</sub></italic>(16) = 10.51, p<sub>mov</sub> &lt; 0.001). At the single-subject level, the classification accuracy was significantly above chance level for 16/26 (61.54%) participants in the nomov condition, and for 16/19 (84.21%) participants in the mov condition (same test as for CSP results; see <xref ref-type="supplementary-material" rid="fig10sdata1">Figure 10—source data 1</xref>).</p></sec><sec id="s3-6"><title>Comparison of model performances</title><p>As an illustration of the prediction behaviour across all three models in one participant (with high performance for all three decoding approaches), see <xref ref-type="fig" rid="fig7">Figure 7</xref>. Correlations of performances across models and experimental conditions are shown in Figure 10. The (positive) correlation between the two binary classification approaches (CSP, LSTM) was significant (after Bonferroni multiple-comparison correction), irrespective of the experimental condition (nomov, mov), meaning that subjects who could be better classified with CSP also yielded better results in the LSTM-based classification. In a repeated-measures ANOVA testing for differences in the accuracies of the two binary classification models (CSP, LSTM) and the two conditions (nomov, mov), none of the effects was significant: neither the main effect <italic>model</italic> (<italic>F</italic>(1,17) = 0.02, p = 0.904) nor the main effect <italic>condition</italic> (<italic>F</italic>(1,17) = 0.72, p = 0.408) or their interaction (<italic>F</italic>(1,17) = 1.59, p = 0.225). For a further comparison of the performances of the classification approaches, the respective confusion matrices are depicted in <xref ref-type="fig" rid="fig8">Figure 8</xref> (average across the subjects per condition and model).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Exemplary model predictions.</title><p>Predictions (turquoise line, dots) across models trained on the data of one participant in the movement condition (source power comodulation [SPoC]: normalized negative <italic>z<sub>est</sub>, here comodulation;</italic> common spatial patterns [CSP]: posterior probability; long short-term memory [LSTM]: <italic>tanh</italic> output). <italic>Top row</italic>: most negatively correlating SPoC component (for visualization we depict the normalized and mean-centred value of the rating and of the negative square root of <italic>z</italic><sub><italic>est</italic></sub>). <italic>Middle and lower row</italic>: model predictions on validation sets (across the cross-validation splits) for CSP and LSTM, respectively. The grey curvy line in each panel indicates the continuous subjective rating of the participant. Horizontal dotted lines indicate the class borders. The area between these lines is the mid-tertile which was discarded for CSP and LSTM analyses. Class membership of each rating sample (1 s) is indicated by the circles at the top and bottom of the rating. A model output falling under or above the decision boundary (db) indicates the model prediction for one over the other class, respectively. The correct or incorrect prediction is indicated by the colour of the circle (green and red, respectively), and additionally colour-coded as area between model output (turquoise) and rating.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig7-v2.tif"/></fig><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Comparison of the binary decoding approaches.</title><p>Confusion matrices of the classification accuracies for higher and lower self-reported emotional arousal using long short-term memory (LSTM) (<italic>lower row</italic>) and common spatial patterns (CSP) (<italic>upper row</italic>) in the condition without (<italic>left column</italic>) and with (<italic>right column</italic>) head movement. The data underlying this figure can be downloaded as <xref ref-type="supplementary-material" rid="fig8sdata1">Figure 8—source data 1</xref>.</p><p><supplementary-material id="fig8sdata1"><label>Figure 8—source data 1.</label><caption><title>Prediction tables of the binary decoding models.</title><p>The zip file contains a folder for each of the movement conditions (with and without head movements) with subfolders for the binary decoding approaches (common spatial patterns [CSP], long short-term memory [LSTM]). Each folder includes three types of tables with the same format (Subjects × Samples). <italic>Subjects</italic> (<italic>N</italic> varies by condition) who went into the final classification (after removals during preprocessing). <italic>Samples</italic> (<italic>N</italic> = 270) refer to the sequential seconds of the experience (total length: 270 s). Each cell contains: targetTable: the target/ground truth assigned to this sample (by binning the continuous rating). CSP: 1=Low Arousal, 2=High Arousal, NaN = Medium Arousal; LSTM: –1=Low Arousal, 1=High Arousal, 0=Medium Arousalprediction. TableProbabilities: the probability/certainty of this sample to be classified as ‘High Arousing’ (positive probabilities) or ‘Low Arousing’ (negative probabilities). predictionTable: the binarized version of the probabilities. CSP: 1=High Arousal, 0=Low Arousal, NaN = Medium Arousal, LSTM: 1=High Arousal, –1=Low Arousal, 0=Medium Arousal.</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-64812-fig8-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig8-v2.tif"/></fig></sec><sec id="s3-7"><title>Control analysis: excluding the break from model training</title><p>SPoC and CSP performed significantly above chance level also when trained and tested on data without the break section.</p><p>For CSP on data without the break, the average classification performance (ROC-AUC) was 0.57 ± 0.10 (M ± SD; range: 0.28–0.78) in the nomov and 0.59 ± 0.09 (M ± SD; range: 0.45–0.77) in the mov condition (see previous paragraph for the decoding performance with the break included). Average model performances were still significantly above chance level (means of the block permutation distributions on the single-subject level) in both movement conditions (nomov: <italic>t</italic>(25) = 2.89, p &lt; 0.01; mov: <italic>t</italic>(18) = 3.50, p &lt; 0.01). On the single-subject level, the classification performance was significantly above chance level for 3/26 (11.54%) participants in the nomov and 5/19 (26.32%) participants in the mov condition.</p><p>For SPoC on data without the break, the average Pearson correlation between <italic>z</italic> and <italic>z</italic><sub><italic>est</italic></sub> (estimated target variable) was significantly smaller (more negative) than the average of single participants’ permuted correlation values for both the nomov (M ± SD: –0.22 ± 0.08; range: –0.36 to –0.07; <italic>t</italic><sub>nomov</sub>(25) = –3.17; p &lt; 0.01) and the mov condition (M ± SD: –0.21 ± 0.07; range: –0.37 to –0.061; <italic>t</italic><sub>mov</sub>(18) = –2.53; p &lt; 0.05). On the single-subject level, 2/26 (7.69%) participants for the nomov and 7/19 (36.84%) participants for the mov condition remained statistically significant (p &lt; 0.05) after permutation-based tests.</p><p>Removing the break from the training data overall numerically decreased the decoding performances of both models. For CSP, the decrease was significant in the nomov (<italic>t</italic>(25) = 2.23, p = 0.034) and not significant in the mov condition (<italic>t</italic>(18) = 0.57, p = 0.58). For SPoC, the decrease (Pearson correlation) was not significant in both conditions (nomov: <italic>t</italic>(25) = –1.66, p = 0.108; mov: <italic>t</italic>(18) = –1.13, p = 0.269).</p></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>The general aim of this study was to capture the dynamic relationship between subjective experience and neurophysiology under naturalistic stimulation using immersive VR. The hypothesized link between EEG alpha power and self-reported emotional arousal could be confirmed by relating alpha power components to continuous retrospective ratings of emotional arousal (using SPoC) as well as by decoding states of higher and lower emotional arousal from them (using CSP and LSTMs), particularly in parieto-occipital regions. In addition to extending our knowledge about the functional anatomy of emotional arousal, these findings support previous results from classical studies and confirm them under more naturalistic conditions. They thereby pave the way for real-world scenarios and applications.</p><sec id="s4-1"><title>Physiological and psychological concomitants of emotional arousal</title><p>In studies with event-related stimulation or block designs, more emotionally arousing compared to less emotionally arousing images, videos, and sounds were associated with event-related decreases in alpha power, predominantly over parieto-occipital electrodes (<xref ref-type="bibr" rid="bib31">De Cesarei and Codispoti, 2011</xref>; <xref ref-type="bibr" rid="bib100">Luft and Bhattacharya, 2015</xref>; <xref ref-type="bibr" rid="bib140">Schubring and Schupp, 2019</xref>; <xref ref-type="bibr" rid="bib154">Uusberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib82">Koelstra et al., 2012</xref>). While such stimuli provide a high degree of experimental control in terms of low-level properties and presentation timings, the emotional experience and its neurophysiology under event-related stimulation may differ from the emotional experience in real-life settings, which is perceptually complex, multisensory, and continuously developing over time.</p><p>Our results provide evidence that the neural mechanisms reflected in modulations of alpha power – particularly in parieto-occipital regions – also bear information about the subjective emotional state of a person undergoing an immersive and emotionally arousing experience. Also fMRI studies have related brain activity in parietal cortices and emotional processing (e.g., <xref ref-type="bibr" rid="bib95">Lettieri et al., 2019</xref>). Our study thus suggests that findings from event-related, simplified stimulation generalize to more naturalistic (i.e., dynamic and interactive) settings.</p><p>Paralleling the idea of emotional arousal being a dimension of ‘core affect’ (<xref ref-type="bibr" rid="bib134">Russell and Barrett, 1999</xref>) and a psychological primitive that underlies many mental phenomena, also alpha oscillations have been connected to various psychological ‘core processes’: for instance, modulations of alpha power were linked to attention (<xref ref-type="bibr" rid="bib155">Van Diepen et al., 2019</xref>) and memory (<xref ref-type="bibr" rid="bib81">Klimesch, 2012</xref>). More generally, neural oscillations in the alpha frequency range were suggested to serve functional inhibition of irrelevant sensory input (<xref ref-type="bibr" rid="bib75">Jensen and Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="bib44">Foster and Awh, 2019</xref>) and to code for the location and the timing of task-relevant stimuli (<xref ref-type="bibr" rid="bib43">Foster et al., 2017</xref>). Such processes can be functionally linked to emotional arousal: during emotionally arousing experiences, preferred and enhanced processing of relevant sensory stimuli (e.g., indicating potential threats) is an adaptive behaviour. In line with this, modulations of alpha oscillations over parietal sensors have been linked to threat processing (<xref ref-type="bibr" rid="bib54">Grimshaw et al., 2014</xref>). Variations in emotional arousal and alpha power may, thus, have guided attention and memory formation also in our experiment: during particularly arousing parts of the rollercoaster, participants may have directed their attention to specific parts of the visual scene, for example, to foresee the end of the looping. Moreover, our inverse modelling (<xref ref-type="fig" rid="fig9">Figure 9</xref>) has also localized arousal-related alpha sources in sensorimotor cortices, which could correspond to somatic experiences typically associated with rollercoasters. Some of the averaged spatial patterns (see <xref ref-type="fig" rid="fig6">Figures 6</xref> and <xref ref-type="fig" rid="fig9">9</xref>) we observed for the SPoC- and CSP-based decoding stronger absolute weights for electrodes above right – as compared to left – cortices. Since we did not hypothesize a lateralization of the alpha effects, we refrained from statistically testing differences between the hemispheres. Similar patterns of right-lateralized alpha oscillations have also been related to arousal in major depression (<xref ref-type="bibr" rid="bib109">Metzger et al., 2004</xref>; <xref ref-type="bibr" rid="bib149">Stewart et al., 2011</xref>). However, it is unclear to which extent these effects are specific to arousal, as lateralization of alpha power has also been observed in working-memory (<xref ref-type="bibr" rid="bib124">Pavlov and Kotchoubey, 2020</xref>) and resting-state studies (<xref ref-type="bibr" rid="bib118">Ocklenburg et al., 2019</xref>). Our results motivate experimental work that will model the link between emotional arousal and alpha oscillations by systematically varying additional variables (e.g., attention, sensorimotor processing). We argue that studying such relationships in naturalistic settings allows embracing and learning statistical interdependencies that are characteristics of the real world.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Source reconstructions (exact low resolution tomography analysis [eLORETA]).</title><p>The projection of source power comodulation (SPoC) and common spatial patterns (CSP) components in source space confirms the link between emotional arousal and alpha oscillations in parieto-occipital regions. Colours represent the inversely modelled contribution of the cortical voxels to the respective spatial pattern yielded by SPoC or CSP (max: component maximizing power for epochs of high arousal; min: component minimizing power for epochs of high arousal). We applied the same normalization and averaging procedures as for the topoplots in <xref ref-type="fig" rid="fig6">Figure 6</xref>. <italic>Upper row</italic>: averaged across all subjects per condition (nomov, mov). <italic>Lower row</italic>: patterns of one individual (the same as in <xref ref-type="fig" rid="fig7">Figure 7</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig9-v2.tif"/></fig></sec><sec id="s4-2"><title>VR as a step towards a real-world neuroscience</title><p>More naturalistic experimental stimulation, for example, using immersive VR, allows to test the brain under conditions it was optimized for and thereby improve the discovery of neural features and dynamics (<xref ref-type="bibr" rid="bib48">Gibson, 1978</xref>; <xref ref-type="bibr" rid="bib60">Hasson et al., 2020</xref>). Findings from naturalistic studies can test the real-world relevance of results obtained in highly controlled, abstract laboratory settings (<xref ref-type="bibr" rid="bib105">Matusz et al., 2019</xref>; <xref ref-type="bibr" rid="bib143">Shamay-Tsoory and Mendelsohn, 2019</xref>). Challenges of using VR for more naturalistic research designs are the creation of high-quality VR content, more complex technical setups, and discomfort caused by the immersion into the virtual environment (<xref ref-type="bibr" rid="bib121">Pan and Hamilton, 2018</xref>; <xref ref-type="bibr" rid="bib156">Vasser and Aru, 2020</xref>). Despite the incongruence between VR rollercoaster-induced visual stimulation and vestibular signals, which may lead to motion sickness (<xref ref-type="bibr" rid="bib127">Reason and Brand, 1975</xref>), only one of our participants stopped the experiment because of cybersickness. This low number may result from the relatively short length of the VR experience (net length: &lt;20 min) and the professionally produced VR stimulation. Shorter exposure times (<xref ref-type="bibr" rid="bib128">Rebenitsch and Owen, 2016</xref>) and experiences that elicit stronger feelings of presence have been associated with lower levels of cybersickness (<xref ref-type="bibr" rid="bib157">Weech et al., 2019</xref>).</p><p>Combining EEG with VR provides additional challenges: the signal-to-noise ratio (SNR) can be decreased due to mechanical interference of the VR headset with the EEG cap and due to movement artefacts when the participant interacts with the virtual environment (e.g., head rotations). To ensure high data quality, we applied multiple measures to prevent, identify, reject, or correct artefacts in the EEG signal (see Materials and methods section for details). Ultimately, the performance of all three decoding models did not differ significantly for both conditions (nomov, mov). We suggest that, with appropriate quality assurance during data acquisition and analysis (leading to more data rejection/correction for mov than for nomov), EEG can be combined with immersive VR and free head movements. Other studies of mobile brain imaging, even recording outdoors and with full-body movements, came to similar conclusions (<xref ref-type="bibr" rid="bib33">Debener et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Ehinger et al., 2014</xref>; <xref ref-type="bibr" rid="bib50">Gramann et al., 2011</xref>; <xref ref-type="bibr" rid="bib151">Symeonidou et al., 2018</xref>).</p></sec><sec id="s4-3"><title>Evaluating EEG data from naturalistic experiments using complementary methods</title><p>Each of the applied decoding approaches allows for different insights and interpretations, but overall, they yield converging results.</p></sec><sec id="s4-4"><title>SPoC and CSP</title><p>SPoC and CSP share advantages that are common to most spatial filtering methods based on generalized eigenvalue decomposition, namely precise optimization policies, high speed, and interpretability. As dimensionality reduction techniques, they combine data from multiple M/EEG channels to obtain a new signal (component) with a higher SNR (<xref ref-type="bibr" rid="bib99">Lotte et al., 2018</xref>; <xref ref-type="bibr" rid="bib122">Parra et al., 2005</xref>). This aids maximizing the difference in the signal of interest between experimental conditions (<xref ref-type="bibr" rid="bib32">de Cheveigné and Parra, 2014</xref>; <xref ref-type="bibr" rid="bib129">Rivet et al., 2009</xref>) or against signals in the neighbouring frequency ranges (<xref ref-type="bibr" rid="bib116">Nikulin et al., 2011</xref>). The similarity between the two approaches (SPoC, CSP) and their interpretability becomes apparent in the resulting spatial patterns: the normalized and averaged SPoC topoplots and source localizations in both conditions (nomov, mov) resemble the ones extracted via CSP to maximize power for the low-arousal epochs of the experience (<xref ref-type="fig" rid="fig6">Figures 6</xref> and <xref ref-type="fig" rid="fig9">9</xref>). SPoC and CSP solve a similar problem here: extracting components whose power is minimal during states of high emotional arousal and maximal during states of low arousal.</p><p>This indicates that SPoC and CSP exploited similar spatial informational patterns in the input data. However, the datasets handed to the SPoC and CSP models were not identical. For the CSP analysis, only the upper and lower extreme of the arousal ratings were included (i.e. two-thirds of the data), while epochs with medium arousal ratings (i.e., one-third of the data) were excluded, whereas SPoC was trained on the full continuous data stream. There are two potential explanations for the observation that SPoC and CSP nevertheless yield similar spatial patterns: either the most relevant information was encoded in the most extreme parts of the experience, or there is a truly linear relationship between alpha power and emotional arousal that can be queried on all parts of this spectrum ranging from low to high emotional arousal.</p><p>The spatial patterns for the components gained from SSD, SPoC, and CSP exhibit discernible variance between the single subjects (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). This can be, for example, caused by physiological differences (e.g., different shapes of the skull, different cortical folding) or slightly different positioning of the EEG electrodes. The same cortical source might thereby lead to different patterns of scalp EEG in different participants. Spatial filtering procedures inverse this projection and the extracted patterns therefore also vary across subjects. Such inter-individual differences are well known for BCIs, and extensions for CSP have been suggested, which allow for a transfer of features across subjects (e.g., <xref ref-type="bibr" rid="bib24">Cheng et al., 2017</xref>). To emphasize the communalities across individual patterns and indicate the cortical areas that contributed most to decoding results, we report the averaged patterns (<xref ref-type="fig" rid="fig6">Figure 6</xref>) and the averaged results of the reconstructed cortical sources (<xref ref-type="fig" rid="fig9">Figure 9</xref>).</p><p>To test for confounds or analytic artefacts, for example, due to auto-correlations in the data, we additionally applied ‘sub-blocked’ cross-validation for model training and block permutation for statistical evaluation. Also under these more strict evaluation conditions, the average decoding performance was significantly above chance level. It is therefore unlikely that the results can be explained solely by dependencies in the data (e.g., auto-correlation) which are not explicitly modelled in the main analysis.</p><p>Moreover, to test the impact of the differences between the rollercoasters and the break, for example, regarding visual dynamics and elicited emotional arousal, on the decoding performance, SPoC and CSP analyses were repeated on the data without the break. Again, the average decoding performances decreased compared to the data with the break, but remained significantly above chance level for both head movement conditions. The decrease in decoding performance with the break removed may result from (1) less training data being available and (2) a narrower range of emotional arousal values, more similar classes (‘high arousal’ and ‘low arousal’), and therefore a more difficult distinction.</p><p>We observed a high degree of variability in decoding performance across participants (see <xref ref-type="fig" rid="fig10">Figure 10</xref>). For example, for less than 70% (and less than 35% with sub-blocked cross-validation and permutation testing) of participants, CSP yielded significant results on the single-subject level. This variability reflects the difficulty of some features and classifiers to perform equally well across subjects, which has been reported in the BCI literature (<xref ref-type="bibr" rid="bib87">Krusienski et al., 2011</xref>; <xref ref-type="bibr" rid="bib117">Nurse et al., 2015</xref>). In a supplementary analysis, we compared the classification results to a less complex logistic regression model, which was directly trained on time-frequency data from electrodes in the occipital-parietal region of interest. The model performed almost on par with CSP in the mov condition but was less sensitive in the nomov condition. Linear regression on time-frequency data in sensor space also has methodological and conceptual limitations compared to SPoC and CSP, such as underestimating sources of noise, disregarding the generative model that underlies EEG data, and consequently a limited interpretability (for details, see <xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>). We therefore did not include this analysis in the final report.</p><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Correlation of performances across methods (source power comodulation [SPoC], common spatial pattern [CSP], long short-term memory [LSTM]) and conditions (nomov: without head movement, mov: with head movement).</title><p>The model performance metrics are classification accuracy (CSP and LSTM) and correlation coefficients (SPoC; note: based on our hypothesis of an inverse relationship between emotional arousal and alpha power, more negative values indicate better predictive performance). Plots above and below the diagonal show data from the nomov (yellow axis shading, <italic>upper right</italic>) and the mov (blue axis shading, <italic>lower left</italic>) condition, respectively. Plots on the diagonal compare the two conditions (nomov, mov) for each method. In the top left corner of each panel, the result of a (Pearson) correlation test is shown. Lines depict a linear fit with the 95% confidence interval plotted in grey. The data underlying this figure can be downloaded as <xref ref-type="supplementary-material" rid="fig10sdata1">Figure 10—source data 1</xref>.</p><p><supplementary-material id="fig10sdata1"><label>Figure 10—source data 1.</label><caption><title>Decoding results per decoding approach, movement condition, and participant.</title><p>The data file contains a data frame per movement condition (nomov, mov) with following columns (for source power comodulation [SPoC] all values relate to the component with the smallest [i.e., most negative] correlation between its alpha power and the emotional arousal ratings). <italic>Subject</italic>; <italic>SPOC_LAMBDA:</italic> covariance; <italic>SPOC_CORR</italic>: Pearson correlation coefficient; <italic>SPOC_Pvalue</italic>: p-values obtained from the permutation test (see Materials and methods) on the single subject level; <italic>CSP_acc</italic> and <italic>LSTM_acc</italic>: proportion of correctly classified samples across the cross-validation folds. <italic>CSP_Pvalues</italic> and <italic>LSTM_Pvalues</italic>: p-values obtained from the exact binomial test on the single-subject level (see Materials and methods).</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-64812-fig10-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-fig10-v2.tif"/></fig></sec><sec id="s4-5"><title>LSTM</title><p>Despite having recently gained more attention with the fast progress of deep learning (e.g., more efficient hardware and software implementations), LSTMs still need to stand up to well-established models such as CSP for EEG analysis. We found that the LSTM can extract features from neural input components that reflect changes in subjective emotional arousal and that the accuracy of its predictions in both conditions (nomov, mov) matched closely the ones of CSP (see <xref ref-type="fig" rid="fig8">Figures 8</xref> and <xref ref-type="fig" rid="fig10">10</xref>). It is noteworthy that for the CSP model, the (LDA-based) classification rested on narrowly defined spectral features of the signal while for the LSTM model, the input was the signal in the time domain and the feature selection process was part of the model fitting. The strong correlation between the predictions of the two models suggests that the LSTM extracts similar information as the CSP to make its prediction, namely power. Higher accuracies may be achievable with LSTM models due to their non-convex optimization landscape. However, in our two-step HP search, we found that for each subject a range of different HP settings led to similar prediction accuracies (see <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>). Model ensembles, although computationally demanding, could further increase the robustness of the estimates (<xref ref-type="bibr" rid="bib120">Opitz and Maclin, 1999</xref>; <xref ref-type="bibr" rid="bib131">Rokach, 2010</xref>; <xref ref-type="bibr" rid="bib36">Dietterich, 2000</xref>). Although it is often stated that deep learning models require large datasets (for an empirical perspective, see <xref ref-type="bibr" rid="bib66">Hestness et al., 2017</xref>), our model, with its architecture of one to two LSTM layers followed by one to two fully connected layers, converged in less than 200 training iterations on a relatively small dataset. This quick convergence is partly due to the fast gradient flow through the memory cell of the LSTM during the weight update, which is an additional advantage of the LSTM over other RNNs (<xref ref-type="bibr" rid="bib38">Doetsch et al., 2014</xref>; <xref ref-type="bibr" rid="bib68">Hochreiter and Schmidhuber, 1997</xref>). Additionally, the spatial-spectral filtering in our study (i.e., SSD-based extraction of narrow-band alpha components) may have eased the training of the LSTM. With more data, an LSTM could be trained on raw data or longer segments of the EEG to preserve more of the continuous structure and ultimately exploit its central property, as a dynamic model, of detecting long-term dependencies in the input.</p><p>In contrast to SPoC and CSP, we did not compute explanatory topoplots or sources from the LSTM, since the analysis of predictions on input level in non-linear deep learning models constitutes a challenge in itself (i.e., ‘black box’ problem of deep learning). However, ‘explainable artificial intelligence<italic>’</italic> (XAI) is an active area of research in machine learning, aiming to open this ‘black box’. For EEG, there are attempts to create topologically informative maps in the signal space that explain the decision of simple shallow neural networks (<xref ref-type="bibr" rid="bib150">Sturm et al., 2016</xref>). Also for the more complex LSTM model, XAI methods were applied, for example, on text data (<xref ref-type="bibr" rid="bib5">Arras et al., 2017</xref>; see also <xref ref-type="bibr" rid="bib90">Lapuschkin et al., 2019</xref>). However, exploring and validating these approaches on our data was beyond the scope of this study.</p><p>In summary, we find that SPoC, CSP, and LSTM can be used to decode subjective emotional arousal from EEG acquired during a naturalistic immersive VR experience. The source of the alpha oscillations could be localized in parieto-occipital regions.</p><p>Compared to other EEG decoding paradigms (e.g., lateralized motor imagery; <xref ref-type="bibr" rid="bib65">Herman et al., 2008</xref>), the accuracy of our models was relatively low. This may be a consequence of (1) the fast-changing events in the VR experience (particularly the rollercoasters), (2) the asynchronicity of the two data streams as participants retrieved their emotional states from memory in retrospective ratings, (3) the generally high inter-individual variability in the interpretability of subjective self-reports (<xref ref-type="bibr" rid="bib15">Blascovich, 1990</xref>), and (4) the ‘single-trial’ study design and its relatively short time series. With respect to (1)–(3), people’s memory for feelings and events is susceptible to distortions and biases (<xref ref-type="bibr" rid="bib77">Kaplan et al., 2016</xref>; <xref ref-type="bibr" rid="bib96">Levine and Safer, 2002</xref>). Following <xref ref-type="bibr" rid="bib107">McCall et al., 2015</xref>, we elicited the memory recall by showing participants an audiovisual replay of their experience from their own perspective in the VR headset while recording continuous ratings. This aimed to minimize biases related to the point of view (<xref ref-type="bibr" rid="bib11">Berntsen and Rubin, 2006</xref>; <xref ref-type="bibr" rid="bib103">Marcotti and St Jacques, 2018</xref>) or timescale (e.g., <xref ref-type="bibr" rid="bib45">Fredrickson and Kahneman, 1993</xref>) during recall (as discussed in <xref ref-type="bibr" rid="bib107">McCall et al., 2015</xref>). Lastly, while our research aimed to explore the role of the alpha frequency band in the appraisal of emotional arousal (see Introduction), higher frequencies could carry additional information about the phenomenon leading to better model predictions. However, higher frequency bands also include non-neural (e.g., muscle activity-related) signals, limiting the interpretability of those results.</p></sec><sec id="s4-6"><title>Limitations</title><p>Our study has limitations that need to be considered when interpreting the results: while being engaging, emotionally arousing and tolerable for the subjects, the commercial content used for stimulation did not provide access to the source code in order to control and extract stimulus features (e.g., height or speed of the rollercoasters). In general, creating high-quality VR content is a challenge for research labs, but there are recent efforts to provide toolboxes that facilitate customized VR development and scientific experimentation in VR (e.g., <xref ref-type="bibr" rid="bib56">Grübel et al., 2017</xref>; <xref ref-type="bibr" rid="bib19">Brookes et al., 2020</xref>).</p><p>The length of the experience was chosen to minimize habituation to the stimulus and inconvenience caused by the recording setup (EEG electrodes and VR headset). This led to relatively short recording times per subject and condition. Data sparsity, however, is challenging for decoding models, which need a sufficient amount of data points for model training and evaluation, where especially larger training sets lead to more robust predictions (<xref ref-type="bibr" rid="bib66">Hestness et al., 2017</xref>). We used cross-validation, which is commonly applied in scenarios of limited data, to achieve a trade-off between training and validation data (<xref ref-type="bibr" rid="bib13">Bishop, 2006</xref>). Nevertheless, the models and results can be expected to perform more robustly with more training data.</p><p>We here confirm findings from static stimulation under more naturalistic conditions. To systematically investigate differences between approaches, a study with a within-subject design would be required. We hope that our study provides a stepping stone and motivation in this direction.</p><p>Finally, emotional arousal is a multi-faceted mind-brain-body phenomenon that involves the situated organism and its interaction with the environment. The training data for multivariate models such as the LSTM can include other modalities, such as peripheral physiological (e.g., HR, GSR) or environmental (e.g., optical flow) features. Naturalism can be further increased by sensorimotor interaction (beyond head movements) in immersive VR (<xref ref-type="bibr" rid="bib107">McCall et al., 2015</xref>) or by mobile EEG studies in real-world environments (<xref ref-type="bibr" rid="bib33">Debener et al., 2012</xref>), which, however, poses further challenges to EEG signal quality (<xref ref-type="bibr" rid="bib57">Gwin et al., 2010</xref>).</p></sec><sec id="s4-7"><title>Conclusion</title><p>We conclude that different levels of subjectively experienced emotional arousal can be decoded from neural information in naturalistic research designs. We hope that combining immersive VR and neuroimaging not only augments neuroscientific experiments but also increases the generalizability and real-world relevance of neuroscientific findings.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Software, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Software, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Software, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Formal analysis, Methodology, Supervision, Visualization, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Funding acquisition, Resources, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Formal analysis, Funding acquisition, Methodology, Project administration, Resources, Software, Supervision, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Participants signed informed consent before their participation, and the study was approved by the Ethics Committee of the Department of Psychology at the Humboldt-Universität zu Berlin (vote no. 2017-22).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-64812-transrepform1-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>We did not obtain participants' consent to release their individual data. Since our analyses focus on the single-subject level, we have only limited data which are sufficiently anonymized (e.g., summarized or averaged) to be publicly shared. Wherever possible, we provide &quot;source data&quot; to reproduce the manuscript's tables and figures (Figures 2, 4, 8 and 10). The scripts of all analyses are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/NeVRo-study/NeVRo">https://github.com/NeVRo-study/NeVRo</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5">https://archive.softwareheritage.org/swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5</ext-link>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>Thanks to Mina Jamshidi Idaji for her support on the EEG source reconstruction, to Nicolas Endres and Firat Sansal for valuable preparatory work, to Cade McCall for conceptual input on the study design, to Mert Akbal and Alireza Tarikhi for their help during data acquisition and data preprocessing, to Wojciech Samek, Klaus-Robert Müller, Frederik Harder, Kristof Schütt, Leila Arras, and Stefan Haufe for their methodological insights.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Abadi</surname><given-names>M</given-names></name><name><surname>Agarwal</surname><given-names>A</given-names></name><name><surname>Barham</surname><given-names>P</given-names></name><name><surname>Brevdo</surname><given-names>E</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Citro</surname><given-names>C</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Davis</surname><given-names>A</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name><name><surname>Devin</surname><given-names>M</given-names></name><name><surname>Ghemawat</surname><given-names>S</given-names></name><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Harp</surname><given-names>A</given-names></name><name><surname>Irving</surname><given-names>G</given-names></name><name><surname>Isard</surname><given-names>M</given-names></name><name><surname>Jia</surname><given-names>Y</given-names></name><name><surname>Jozefowicz</surname><given-names>R</given-names></name><name><surname>Kaiser</surname><given-names>L</given-names></name><name><surname>Kudlur</surname><given-names>M</given-names></name><name><surname>Zheng</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1603.04467">https://arxiv.org/abs/1603.04467</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Mlodinow</surname><given-names>L</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>What is an emotion?</article-title><source>Current Biology</source><volume>29</volume><fpage>R1060</fpage><lpage>R1064</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.09.008</pub-id><pub-id pub-id-type="pmid">31639344</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Agrawal</surname><given-names>P</given-names></name><name><surname>Stansbury</surname><given-names>D</given-names></name><name><surname>Malik</surname><given-names>J</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pixels to Voxels: Modeling Visual Representation in the Human Brain</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1407.5104">https://arxiv.org/abs/1407.5104</ext-link></element-citation></ref><ref id="bib4"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Altini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dealing with imbalanced data: Undersampling, oversampling and proper cross-validation</article-title><ext-link ext-link-type="uri" xlink:href="http://www.marcoaltini.com/2/post/2015/08/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation.html">http://www.marcoaltini.com/2/post/2015/08/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation.html</ext-link><date-in-citation iso-8601-date="2021-08-13">August 13, 2021</date-in-citation></element-citation></ref><ref id="bib5"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Arras</surname><given-names>L</given-names></name><name><surname>Montavon</surname><given-names>G</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name><name><surname>Samek</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2017">2017</year><conf-name>Explaining Recurrent Neural Network Predictions in Sentiment Analysis</conf-name><article-title>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</article-title><fpage>17</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.18653/v1/W17-5221</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bach</surname><given-names>DR</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Analytic measures for quantification of arousal from spontaneous skin conductance fluctuations</article-title><source>Ternational Journal of Psychophysiology</source><volume>76</volume><fpage>52</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2010.01.011</pub-id><pub-id pub-id-type="pmid">20144665</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>How Emotions Are Made: The Secret Life of the Brain</source><publisher-name>Houghton Mifflin Harcourt</publisher-name></element-citation></ref><ref id="bib8"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Bashivan</surname><given-names>P</given-names></name><name><surname>Rish</surname><given-names>I</given-names></name><name><surname>Yeasin</surname><given-names>M</given-names></name><name><surname>Codella</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1511.06448">https://arxiv.org/abs/1511.06448</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1929">1929</year><article-title>Über das Elektrenkephalogramm des Menschen</article-title><source>Archiv Für Psychiatrie Und Nervenkrankheiten</source><volume>87</volume><fpage>527</fpage><lpage>570</lpage><pub-id pub-id-type="doi">10.1007/BF01797193</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergstra</surname><given-names>J</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Random Search for Hyper-Parameter Optimization</article-title><source>Journal of Machine Learning Research</source><volume>13</volume><fpage>281</fpage><lpage>305</lpage></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berntsen</surname><given-names>D</given-names></name><name><surname>Rubin</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Emotion and vantage point in autobiographical</article-title><source>Cognition &amp; Emotion</source><volume>20</volume><fpage>1193</fpage><lpage>1215</lpage><pub-id pub-id-type="doi">10.1080/02699930500371190</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bigdely-Shamlo</surname><given-names>N</given-names></name><name><surname>Mullen</surname><given-names>T</given-names></name><name><surname>Kothe</surname><given-names>C</given-names></name><name><surname>Su</surname><given-names>KM</given-names></name><name><surname>Robbins</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The PREP pipeline: standardized preprocessing for large-scale EEG analysis</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>16</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00016</pub-id><pub-id pub-id-type="pmid">26150785</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern Recognition and Machine Learning</source><edition>First Edition</edition><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blankertz</surname><given-names>B</given-names></name><name><surname>Tomioka</surname><given-names>R</given-names></name><name><surname>Lemm</surname><given-names>S</given-names></name><name><surname>Kawanabe</surname><given-names>M</given-names></name><name><surname>Muller</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Optimizing Spatial filters for Robust EEG Single-Trial Analysis</article-title><source>IEEE Signal Processing Magazine</source><volume>25</volume><fpage>41</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1109/MSP.2008.4408441</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blascovich</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Individual Differences in Physiological Arousal and Perception of Arousal</article-title><source>Personality and Social Psychology Bulletin</source><volume>16</volume><fpage>665</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1177/0146167290164007</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouchard</surname><given-names>S</given-names></name><name><surname>Dumoulin</surname><given-names>S</given-names></name><name><surname>Robillard</surname><given-names>G</given-names></name><name><surname>Guitard</surname><given-names>T</given-names></name><name><surname>Klinger</surname><given-names>É</given-names></name><name><surname>Forget</surname><given-names>H</given-names></name><name><surname>Loranger</surname><given-names>C</given-names></name><name><surname>Roucaut</surname><given-names>FX</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Virtual reality compared with in vivo exposure in the treatment of social anxiety disorder: A three-arm randomised controlled trial</article-title><source>The British Journal of Psychiatry</source><volume>210</volume><fpage>276</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1192/bjp.bp.116.184234</pub-id><pub-id pub-id-type="pmid">27979818</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Miccoli</surname><given-names>L</given-names></name><name><surname>Escrig</surname><given-names>MA</given-names></name><name><surname>Lang</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The pupil as a measure of emotional arousal and autonomic activation</article-title><source>Psychophysiology</source><volume>45</volume><fpage>602</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2008.00654.x</pub-id><pub-id pub-id-type="pmid">18282202</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bridwell</surname><given-names>DA</given-names></name><name><surname>Cavanagh</surname><given-names>JF</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Nunez</surname><given-names>MD</given-names></name><name><surname>Srinivasan</surname><given-names>R</given-names></name><name><surname>Stober</surname><given-names>S</given-names></name><name><surname>Calhoun</surname><given-names>VD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Moving Beyond ERP Components: A Selective Review of Approaches to Integrate EEG and Behavior</article-title><source>Frontiers in Human Neuroscience</source><volume>12</volume><elocation-id>106</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2018.00106</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brookes</surname><given-names>J</given-names></name><name><surname>Warburton</surname><given-names>M</given-names></name><name><surname>Alghadier</surname><given-names>M</given-names></name><name><surname>Mon-Williams</surname><given-names>M</given-names></name><name><surname>Mushtaq</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Studying human behavior with virtual reality: The Unity Experiment Framework</article-title><source>Behavior Research Methods</source><volume>52</volume><fpage>455</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.3758/s13428-019-01242-0</pub-id><pub-id pub-id-type="pmid">31012061</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunswik</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>Representative design and probabilistic theory in a functional psychology</article-title><source>Psychological Review</source><volume>62</volume><fpage>193</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1037/h0047470</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Rhythms of the Brain</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaumon</surname><given-names>M</given-names></name><name><surname>Bishop</surname><given-names>DVM</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A practical guide to the selection of independent components of the electroencephalogram for artifact correction</article-title><source>Journal of Neuroscience Methods</source><volume>250</volume><fpage>47</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.02.025</pub-id><pub-id pub-id-type="pmid">25791012</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chawla</surname><given-names>NV</given-names></name><name><surname>Bowyer</surname><given-names>KW</given-names></name><name><surname>Hall</surname><given-names>LO</given-names></name><name><surname>Kegelmeyer</surname><given-names>WP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>SMOTE: Synthetic Minority Over-sampling Technique</article-title><source>Journal of Artificial Intelligence Research</source><volume>16</volume><fpage>321</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1613/jair.953</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>M</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Regularized common spatial patterns with subject-to-subject transfer of EEG signals</article-title><source>Cognitive Neurodynamics</source><volume>11</volume><fpage>173</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1007/s11571-016-9417-x</pub-id><pub-id pub-id-type="pmid">28348648</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Clevert</surname><given-names>DA</given-names></name><name><surname>Unterthiner</surname><given-names>T</given-names></name><name><surname>Hochreiter</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1511.07289">https://arxiv.org/abs/1511.07289</ext-link></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MX</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Using spatiotemporal source separation to identify prominent features in multichannel data without sinusoidal filters</article-title><source>The European Journal of Neuroscience</source><volume>48</volume><fpage>2454</fpage><lpage>2465</lpage><pub-id pub-id-type="doi">10.1111/ejn.13727</pub-id><pub-id pub-id-type="pmid">28960497</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dähne</surname><given-names>S</given-names></name><name><surname>Meinecke</surname><given-names>FC</given-names></name><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Höhne</surname><given-names>J</given-names></name><name><surname>Tangermann</surname><given-names>M</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name><name><surname>Nikulin</surname><given-names>VV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>SPoC: A novel framework for relating the amplitude of neuronal oscillations to behaviorally relevant parameters</article-title><source>NeuroImage</source><volume>86</volume><fpage>111</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.07.079</pub-id><pub-id pub-id-type="pmid">23954727</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Dähne</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><data-title>spoc.m</data-title><version designator="941a74b">941a74b</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/svendaehne/matlab_SPoC/blob/master/SPoC/spoc.m">https://github.com/svendaehne/matlab_SPoC/blob/master/SPoC/spoc.m</ext-link></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalgleish</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The emotional brain</article-title><source>Nature Reviews. Neuroscience</source><volume>5</volume><fpage>583</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1038/nrn1432</pub-id><pub-id pub-id-type="pmid">15208700</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damasio</surname><given-names>AR</given-names></name><name><surname>Grabowski</surname><given-names>TJ</given-names></name><name><surname>Bechara</surname><given-names>A</given-names></name><name><surname>Damasio</surname><given-names>H</given-names></name><name><surname>Ponto</surname><given-names>LL</given-names></name><name><surname>Parvizi</surname><given-names>J</given-names></name><name><surname>Hichwa</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Subcortical and cortical brain activity during the feeling of self-generated emotions</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>1049</fpage><lpage>1056</lpage><pub-id pub-id-type="doi">10.1038/79871</pub-id><pub-id pub-id-type="pmid">11017179</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Cesarei</surname><given-names>A</given-names></name><name><surname>Codispoti</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Affective modulation of the LPP and α-ERD during picture viewing</article-title><source>Psychophysiology</source><volume>48</volume><fpage>1397</fpage><lpage>1404</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2011.01204.x</pub-id><pub-id pub-id-type="pmid">21486291</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Cheveigné</surname><given-names>A</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Joint decorrelation, a versatile tool for multichannel data analysis</article-title><source>NeuroImage</source><volume>98</volume><fpage>487</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.05.068</pub-id><pub-id pub-id-type="pmid">24990357</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debener</surname><given-names>S</given-names></name><name><surname>Minow</surname><given-names>F</given-names></name><name><surname>Emkes</surname><given-names>R</given-names></name><name><surname>Gandras</surname><given-names>K</given-names></name><name><surname>de Vos</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How about taking a low-cost, small, and wireless EEG for a walk?</article-title><source>Psychophysiology</source><volume>49</volume><fpage>1617</fpage><lpage>1621</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2012.01471.x</pub-id><pub-id pub-id-type="pmid">23013047</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><volume>134</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diemer</surname><given-names>J</given-names></name><name><surname>Alpers</surname><given-names>GW</given-names></name><name><surname>Peperkorn</surname><given-names>HM</given-names></name><name><surname>Shiban</surname><given-names>Y</given-names></name><name><surname>Mühlberger</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The impact of perception and presence on emotional reactions: A review of research in virtual reality</article-title><source>Frontiers in Psychology</source><volume>6</volume><elocation-id>26</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2015.00026</pub-id><pub-id pub-id-type="pmid">25688218</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dietterich</surname><given-names>TG</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Ensemble Methods in Machine Learning</article-title><source>Multiple Classifier Systems</source><volume>2</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1007/3-540-45014-9_1</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dmochowski</surname><given-names>JP</given-names></name><name><surname>Sajda</surname><given-names>P</given-names></name><name><surname>Dias</surname><given-names>J</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Correlated Components of Ongoing EEG Point to Emotionally Laden Attention – A Possible Marker of Engagement?</article-title><source>Frontiers in Human Neuroscience</source><volume>6</volume><elocation-id>112</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2012.00112</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Doetsch</surname><given-names>P</given-names></name><name><surname>Kozielski</surname><given-names>M</given-names></name><name><surname>Ney</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><conf-name>Fast and Robust Training of Recurrent Neural Networks for Offline Handwriting Recognition</conf-name><article-title>2014 14th International Conference on Frontiers in Handwriting Recognition</article-title><fpage>279</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1109/ICFHR.2014.54</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Donahue</surname><given-names>J</given-names></name><name><surname>Hendricks</surname><given-names>LA</given-names></name><name><surname>Guadarrama</surname><given-names>S</given-names></name><name><surname>Rohrbach</surname><given-names>M</given-names></name><name><surname>Venugopalan</surname><given-names>S</given-names></name><name><surname>Darrell</surname><given-names>T</given-names></name><name><surname>Saenko</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><conf-name>Long-term recurrent convolutional networks for visual recognition and description</conf-name><article-title>2015 IEEE Conference on Computer Vision and Pattern Recognition</article-title><fpage>2625</fpage><lpage>2634</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2015.7298878</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duffy</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>The psychological significance of the concept of “arousal” or “activation&quot;</article-title><source>Psychological Review</source><volume>64</volume><fpage>265</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1037/h0048837</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ehinger</surname><given-names>BV</given-names></name><name><surname>Fischer</surname><given-names>P</given-names></name><name><surname>Gert</surname><given-names>AL</given-names></name><name><surname>Kaufhold</surname><given-names>L</given-names></name><name><surname>Weber</surname><given-names>F</given-names></name><name><surname>Pipa</surname><given-names>G</given-names></name><name><surname>König</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Kinesthetic and vestibular information modulate alpha activity during spatial navigation: A mobile EEG study</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>71</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00071</pub-id><pub-id pub-id-type="pmid">24616681</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1936">1936</year><article-title>The Use of Multiple Measurements in Taxonomic Problems</article-title><source>Annals of Eugenics</source><volume>7</volume><fpage>179</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1111/j.1469-1809.1936.tb02137.x</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Sutterer</surname><given-names>DW</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name><name><surname>Vogel</surname><given-names>EK</given-names></name><name><surname>Awh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Alpha-Band Oscillations Enable Spatially and Temporally Resolved Tracking of Covert Spatial Attention</article-title><source>Psychological Science</source><volume>28</volume><fpage>929</fpage><lpage>941</lpage><pub-id pub-id-type="doi">10.1177/0956797617699167</pub-id><pub-id pub-id-type="pmid">28537480</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Awh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The role of alpha oscillations in spatial attention: limited evidence for a suppression account</article-title><source>Current Opinion in Psychology</source><volume>29</volume><fpage>34</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/j.copsyc.2018.11.001</pub-id><pub-id pub-id-type="pmid">30472541</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fredrickson</surname><given-names>BL</given-names></name><name><surname>Kahneman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Duration neglect in retrospective evaluations of affective episodes</article-title><source>Journal of Personality and Social Psychology</source><volume>65</volume><fpage>45</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1037//0022-3514.65.1.45</pub-id><pub-id pub-id-type="pmid">8355141</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaebler</surname><given-names>M</given-names></name><name><surname>Biessmann</surname><given-names>F</given-names></name><name><surname>Lamke</surname><given-names>JP</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name><name><surname>Walter</surname><given-names>H</given-names></name><name><surname>Hetzer</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Stereoscopic depth increases intersubject correlations of brain networks</article-title><source>NeuroImage</source><volume>100</volume><fpage>427</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.008</pub-id><pub-id pub-id-type="pmid">24945664</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geman</surname><given-names>S</given-names></name><name><surname>Bienenstock</surname><given-names>E</given-names></name><name><surname>Doursat</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Neural Networks and the Bias/Variance Dilemma</article-title><source>Neural Computation</source><volume>4</volume><fpage>1</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1162/neco.1992.4.1.1</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>The Ecological Approach to the Visual Perception of Pictures</article-title><source>Leonardo</source><volume>11</volume><elocation-id>227</elocation-id><pub-id pub-id-type="doi">10.2307/1574154</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Deep Learning</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramann</surname><given-names>K</given-names></name><name><surname>Gwin</surname><given-names>JT</given-names></name><name><surname>Ferris</surname><given-names>DP</given-names></name><name><surname>Oie</surname><given-names>K</given-names></name><name><surname>Jung</surname><given-names>TP</given-names></name><name><surname>Lin</surname><given-names>CT</given-names></name><name><surname>Liao</surname><given-names>LD</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cognition in action: Imaging brain/body dynamics in mobile humans</article-title><source>Reviews in the Neurosciences</source><volume>22</volume><elocation-id>047</elocation-id><pub-id pub-id-type="doi">10.1515/RNS.2011.047</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>A</given-names></name><name><surname>Jaitly</surname><given-names>N</given-names></name><name><surname>Mohamed</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><conf-name>Hybrid speech recognition with deep bidirectional LSTM</conf-name><article-title>2013 IEEE Workshop on Automatic Speech Recognition &amp; Understanding</article-title><fpage>273</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1109/ASRU.2013.6707742</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greff</surname><given-names>K</given-names></name><name><surname>Srivastava</surname><given-names>RK</given-names></name><name><surname>Koutnik</surname><given-names>J</given-names></name><name><surname>Steunebrink</surname><given-names>BR</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>LSTM: A Search Space Odyssey</article-title><source>IEEE Transactions on Neural Networks and Learning Systems</source><volume>28</volume><fpage>2222</fpage><lpage>2232</lpage><pub-id pub-id-type="doi">10.1109/TNNLS.2016.2582924</pub-id><pub-id pub-id-type="pmid">27411231</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greiner</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Subject pool recruitment procedures: Organizing experiments with ORSEE</article-title><source>Journal of the Economic Science Association</source><volume>1</volume><fpage>114</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1007/s40881-015-0004-4</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grimshaw</surname><given-names>GM</given-names></name><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Corballis</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Frontal and parietal EEG asymmetries interact to predict attentional bias to threat</article-title><source>Brain and Cognition</source><volume>90</volume><fpage>76</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2014.06.008</pub-id><pub-id pub-id-type="pmid">25014408</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>JJ</given-names></name><name><surname>Muñoz</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Emotion Regulation and Mental Health</article-title><source>Clinical Psychology</source><volume>2</volume><fpage>151</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1111/j.1468-2850.1995.tb00036.x</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grübel</surname><given-names>J</given-names></name><name><surname>Weibel</surname><given-names>R</given-names></name><name><surname>Jiang</surname><given-names>MH</given-names></name><name><surname>Hölscher</surname><given-names>C</given-names></name><name><surname>Hackman</surname><given-names>DA</given-names></name><name><surname>Schinazi</surname><given-names>VR</given-names></name></person-group><year iso-8601-date="2017">2017</year><chapter-title>EVE: A Framework for Experiments in Virtual Environments</chapter-title><person-group person-group-type="editor"><name><surname>Barkowsky</surname><given-names>T</given-names></name><name><surname>Burte</surname><given-names>H</given-names></name><name><surname>Hölscher</surname><given-names>C</given-names></name><name><surname>Schultheis</surname><given-names>H</given-names></name></person-group><source>Spatial Cognition X. Spatial Cognition 2016, KogWis 2016. Lecture Notes in Computer Science</source><publisher-loc>Cham</publisher-loc><publisher-name>Springer</publisher-name><fpage>159</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-68189-4</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gwin</surname><given-names>JT</given-names></name><name><surname>Gramann</surname><given-names>K</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name><name><surname>Ferris</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Removal of Movement Artifact From High-Density EEG Recorded During Walking and Running</article-title><source>Journal of Neurophysiology</source><volume>103</volume><fpage>3526</fpage><lpage>3534</lpage><pub-id pub-id-type="doi">10.1152/jn.00105.2010</pub-id><pub-id pub-id-type="pmid">20410364</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Cousijn</surname><given-names>H</given-names></name><name><surname>Wallis</surname><given-names>G</given-names></name><name><surname>Harrison</surname><given-names>PJ</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Inter- and intra-individual variability in alpha peak frequency</article-title><source>NeuroImage</source><volume>92</volume><fpage>46</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.01.049</pub-id><pub-id pub-id-type="pmid">24508648</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haller</surname><given-names>M</given-names></name><name><surname>Donoghue</surname><given-names>T</given-names></name><name><surname>Peterson</surname><given-names>E</given-names></name><name><surname>Varma</surname><given-names>P</given-names></name><name><surname>Sebastian</surname><given-names>P</given-names></name><name><surname>Gao</surname><given-names>R</given-names></name><name><surname>Noto</surname><given-names>T</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>Shestyuk</surname><given-names>A</given-names></name><name><surname>Voytek</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Parameterizing neural power spectra</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1655</fpage><lpage>1665</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00744-x</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Goldstein</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Direct Fit to Nature: An Evolutionary Perspective on Biological and Artificial Neural Networks</article-title><source>Neuron</source><volume>105</volume><fpage>416</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.12.002</pub-id><pub-id pub-id-type="pmid">32027833</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Dähne</surname><given-names>S</given-names></name><name><surname>Nikulin</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Dimensionality reduction for the analysis of brain oscillations</article-title><source>NeuroImage</source><volume>101</volume><fpage>583</fpage><lpage>597</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.073</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Meinecke</surname><given-names>F</given-names></name><name><surname>Görgen</surname><given-names>K</given-names></name><name><surname>Dähne</surname><given-names>S</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name><name><surname>Blankertz</surname><given-names>B</given-names></name><name><surname>Bießmann</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>On the interpretation of weight vectors of linear models in multivariate neuroimaging</article-title><source>NeuroImage</source><volume>87</volume><fpage>96</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.067</pub-id><pub-id pub-id-type="pmid">24239590</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Ewald</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A simulation framework for benchmarking EEG-based brain connectivity estimation methodologies</article-title><source>Brain Topography</source><volume>32</volume><fpage>625</fpage><lpage>642</lpage><pub-id pub-id-type="doi">10.1007/s10548-016-0498-y</pub-id><pub-id pub-id-type="pmid">27255482</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hefron</surname><given-names>RG</given-names></name><name><surname>Borghetti</surname><given-names>BJ</given-names></name><name><surname>Christensen</surname><given-names>JC</given-names></name><name><surname>Kabban</surname><given-names>CMS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Deep long short-term memory structures model temporal dependencies improving cognitive workload estimation</article-title><source>Pattern Recognition Letters</source><volume>94</volume><fpage>96</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.patrec.2017.05.020</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herman</surname><given-names>P</given-names></name><name><surname>Prasad</surname><given-names>G</given-names></name><name><surname>McGinnity</surname><given-names>TM</given-names></name><name><surname>Coyle</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Comparative Analysis of Spectral Approaches to Feature Extraction for EEG-Based Motor Imagery Classification</article-title><source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source><volume>16</volume><fpage>317</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1109/TNSRE.2008.926694</pub-id><pub-id pub-id-type="pmid">18701380</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hestness</surname><given-names>J</given-names></name><name><surname>Narang</surname><given-names>S</given-names></name><name><surname>Ardalani</surname><given-names>N</given-names></name><name><surname>Diamos</surname><given-names>G</given-names></name><name><surname>Jun</surname><given-names>H</given-names></name><name><surname>Kianinejad</surname><given-names>H</given-names></name><name><surname>Patwary</surname><given-names>MMA</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Deep Learning Scaling Is Predictable, Empirically</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1712.00409">https://arxiv.org/abs/1712.00409</ext-link></element-citation></ref><ref id="bib67"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Long Short Term Memory</source><publisher-name>Elsevier</publisher-name></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Long Short-Term Memory</article-title><source>Neural Computation</source><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Hofmann</surname><given-names>SM</given-names></name><name><surname>Klotzsche</surname><given-names>F</given-names></name><name><surname>Mariola</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>NeVRo – Neuro Virtual Reality</data-title><version designator="swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5">swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:b3468cf3e097ca0e3895c0df3df43d0308dd7ced;origin=https://github.com/NeVRo-study/NeVRo;visit=swh:1:snp:371d20714cc61dc507acc50316bc42894bc8679c;anchor=swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5">https://archive.softwareheritage.org/swh:1:dir:b3468cf3e097ca0e3895c0df3df43d0308dd7ced;origin=https://github.com/NeVRo-study/NeVRo;visit=swh:1:snp:371d20714cc61dc507acc50316bc42894bc8679c;anchor=swh:1:rev:669d5c2d6c73cbb70422efb933916fe8304195b5</ext-link></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name><name><surname>Haufe</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The New York Head-A precise standardized volume conductor model for EEG source localization and tES targeting</article-title><source>NeuroImage</source><volume>140</volume><fpage>150</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.12.019</pub-id><pub-id pub-id-type="pmid">26706450</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huk</surname><given-names>A</given-names></name><name><surname>Bonnen</surname><given-names>K</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Beyond Trial-Based Paradigms: Continuous Behavior, Ongoing Neural Activity, and Natural Stimuli</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>7551</fpage><lpage>7558</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1920-17.2018</pub-id><pub-id pub-id-type="pmid">30037835</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Idaji</surname><given-names>MJ</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name><name><surname>Nolte</surname><given-names>G</given-names></name><name><surname>Maess</surname><given-names>B</given-names></name><name><surname>Villringer</surname><given-names>A</given-names></name><name><surname>Nikulin</surname><given-names>VV</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Nonlinear interaction decomposition (NID): A method for separation of cross-frequency coupled sources in human brain</article-title><source>NeuroImage</source><volume>211</volume><elocation-id>116599</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116599</pub-id><pub-id pub-id-type="pmid">32035185</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1884">1884</year><article-title>II—WHAT IS AN EMOTION?</article-title><source>Mind; a Quarterly Review of Psychology and Philosophy</source><volume>os-IX</volume><fpage>188</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1093/mind/os-IX.34.188</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1890">1890</year><source>The Pinciples of Psychology in Two Volumes</source><publisher-name>Macmillan</publisher-name></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Mazaheri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Shaping Functional Architecture by Oscillatory Alpha Activity: Gating by Inhibition</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>186</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00186</pub-id><pub-id pub-id-type="pmid">21119777</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Oliphant</surname><given-names>T</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2001">2001</year><data-title>SciPy: Open source scientific tools for Python</data-title><version designator="v0.9">v0.9</version><source>SciPy</source><ext-link ext-link-type="uri" xlink:href="https://www.scipy.org">https://www.scipy.org</ext-link></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>RL</given-names></name><name><surname>Levine</surname><given-names>LJ</given-names></name><name><surname>Lench</surname><given-names>HC</given-names></name><name><surname>Safer</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Forgetting feelings: Opposite biases in reports of the intensity of past emotion and mood</article-title><source>Emotion</source><volume>16</volume><fpage>309</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1037/emo0000127</pub-id><pub-id pub-id-type="pmid">26501929</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappenman</surname><given-names>ES</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The effects of electrode impedance on data quality and statistical significance in ERP recordings</article-title><source>Psychophysiology</source><volume>47</volume><fpage>888</fpage><lpage>904</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2010.01009.x</pub-id><pub-id pub-id-type="pmid">20374541</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>SP</given-names></name><name><surname>Lalor</surname><given-names>EC</given-names></name><name><surname>Reilly</surname><given-names>RB</given-names></name><name><surname>Foxe</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Increases in Alpha Oscillatory Power Reflect an Active Retinotopic Mechanism for Distracter Suppression During Sustained Visuospatial Attention</article-title><source>Journal of Neurophysiology</source><volume>95</volume><fpage>3844</fpage><lpage>3851</lpage><pub-id pub-id-type="doi">10.1152/jn.01234.2005</pub-id><pub-id pub-id-type="pmid">16571739</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khaligh-Razavi</surname><given-names>SM</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical Representation</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003915</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003915</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimesch</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>α-band oscillations, attention, and controlled access to stored information</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>606</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.10.007</pub-id><pub-id pub-id-type="pmid">23141428</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelstra</surname><given-names>S</given-names></name><name><surname>Muhl</surname><given-names>C</given-names></name><name><surname>Soleymani</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>J-S</given-names></name><name><surname>Yazdani</surname><given-names>A</given-names></name><name><surname>Ebrahimi</surname><given-names>T</given-names></name><name><surname>Pun</surname><given-names>T</given-names></name><name><surname>Nijholt</surname><given-names>A</given-names></name><name><surname>Patras</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>DEAP: A Database for Emotion Analysis Using Physiological Signals</article-title><source>IEEE Transactions on Affective Computing</source><volume>3</volume><fpage>18</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1109/T-AFFC.2011.15</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kothe</surname><given-names>CA</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>BCILAB: A platform for brain-computer interface development</article-title><source>Journal of Neural Engineering</source><volume>10</volume><elocation-id>056014</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2560/10/5/056014</pub-id><pub-id pub-id-type="pmid">23985960</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kragel</surname><given-names>PA</given-names></name><name><surname>Labar</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multivariate pattern classification reveals autonomic and experiential representations of discrete emotions</article-title><source>Emotion</source><volume>13</volume><fpage>681</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1037/a0031820</pub-id><pub-id pub-id-type="pmid">23527508</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreibig</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Autonomic nervous system activity in emotion: A review</article-title><source>Biological Psychology</source><volume>84</volume><fpage>394</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2010.03.010</pub-id><pub-id pub-id-type="pmid">20371374</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Simmons</surname><given-names>WK</given-names></name><name><surname>Bellgowan</surname><given-names>PSF</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Circular analysis in systems neuroscience: The dangers of double dipping</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>535</fpage><lpage>540</lpage><pub-id pub-id-type="doi">10.1038/nn.2303</pub-id><pub-id pub-id-type="pmid">19396166</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krusienski</surname><given-names>DJ</given-names></name><name><surname>Grosse-Wentrup</surname><given-names>M</given-names></name><name><surname>Galán</surname><given-names>F</given-names></name><name><surname>Coyle</surname><given-names>D</given-names></name><name><surname>Miller</surname><given-names>KJ</given-names></name><name><surname>Forney</surname><given-names>E</given-names></name><name><surname>Anderson</surname><given-names>CW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Critical issues in state-of-the-art brain–computer interface signal processing</article-title><source>Journal of Neural Engineering</source><volume>8</volume><elocation-id>025002</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2560/8/2/025002.Critical</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuppens</surname><given-names>P</given-names></name><name><surname>Oravecz</surname><given-names>Z</given-names></name><name><surname>Tuerlinckx</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Feelings change: Accounting for individual differences in the temporal dynamics of affect</article-title><source>Journal of Personality and Social Psychology</source><volume>99</volume><fpage>1042</fpage><lpage>1060</lpage><pub-id pub-id-type="doi">10.1037/a0020962</pub-id><pub-id pub-id-type="pmid">20853980</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuppens</surname><given-names>P</given-names></name><name><surname>Tuerlinckx</surname><given-names>F</given-names></name><name><surname>Russell</surname><given-names>JA</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The relation between valence and arousal in subjective experience</article-title><source>Psychological Bulletin</source><volume>139</volume><fpage>917</fpage><lpage>940</lpage><pub-id pub-id-type="doi">10.1037/a0030811</pub-id><pub-id pub-id-type="pmid">23231533</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lapuschkin</surname><given-names>S</given-names></name><name><surname>Wäldchen</surname><given-names>S</given-names></name><name><surname>Binder</surname><given-names>A</given-names></name><name><surname>Montavon</surname><given-names>G</given-names></name><name><surname>Samek</surname><given-names>W</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Unmasking Clever Hans predictors and assessing what machines really learn</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>1096</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-08987-4</pub-id><pub-id pub-id-type="pmid">30858366</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Larsen</surname><given-names>BS</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Synthetic Minority Over-sampling Technique (SMOTE)</data-title><version designator="1.0">1.0</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/dkbsl/matlab_smote/releases/tag/1.0">https://github.com/dkbsl/matlab_smote/releases/tag/1.0</ext-link></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning</article-title><source>Nature</source><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ledoit</surname><given-names>O</given-names></name><name><surname>Wolf</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A well-conditioned estimator for large-dimensional covariance matrices</article-title><source>Journal of Multivariate Analysis</source><volume>88</volume><fpage>365</fpage><lpage>411</lpage><pub-id pub-id-type="doi">10.1016/S0047-259X(03)00096-4</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>TW</given-names></name><name><surname>Girolami</surname><given-names>M</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Independent component analysis using an extended infomax algorithm for mixed subgaussian and supergaussian sources</article-title><source>Neural Computation</source><volume>11</volume><fpage>417</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1162/089976699300016719</pub-id><pub-id pub-id-type="pmid">9950738</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lettieri</surname><given-names>G</given-names></name><name><surname>Handjaras</surname><given-names>G</given-names></name><name><surname>Ricciardi</surname><given-names>E</given-names></name><name><surname>Leo</surname><given-names>A</given-names></name><name><surname>Papale</surname><given-names>P</given-names></name><name><surname>Betta</surname><given-names>M</given-names></name><name><surname>Pietrini</surname><given-names>P</given-names></name><name><surname>Cecchetti</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Emotionotopy in the human right temporo-parietal cortex</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>5568</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-13599-z</pub-id><pub-id pub-id-type="pmid">31804504</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levine</surname><given-names>LJ</given-names></name><name><surname>Safer</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Sources of Bias in Memory for Emotions</article-title><source>Current Directions in Psychological Science</source><volume>11</volume><fpage>169</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1111/1467-8721.00193</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindquist</surname><given-names>KA</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Kober</surname><given-names>H</given-names></name><name><surname>Bliss-Moreau</surname><given-names>E</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The brain basis of emotion: A meta-analytic review</article-title><source>The Behavioral and Brain Sciences</source><volume>35</volume><fpage>121</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1017/S0140525X11000446</pub-id><pub-id pub-id-type="pmid">22617651</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindquist</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Emotions Emerge from More Basic Psychological Ingredients: A Modern Psychological Constructionist Model</article-title><source>Emotion Review</source><volume>5</volume><fpage>356</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1177/1754073913489750</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lotte</surname><given-names>F</given-names></name><name><surname>Bougrain</surname><given-names>L</given-names></name><name><surname>Cichocki</surname><given-names>A</given-names></name><name><surname>Clerc</surname><given-names>M</given-names></name><name><surname>Congedo</surname><given-names>M</given-names></name><name><surname>Rakotomamonjy</surname><given-names>A</given-names></name><name><surname>Yger</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A review of classification algorithms for EEG-based brain–computer interfaces: A 10 year update</article-title><source>Journal of Neural Engineering</source><volume>15</volume><elocation-id>031005</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/aab2f2</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luft</surname><given-names>CDB</given-names></name><name><surname>Bhattacharya</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Aroused with heart: Modulation of heartbeat evoked potential by arousal induction and its oscillatory correlates</article-title><source>Scientific Reports</source><volume>5</volume><elocation-id>15717</elocation-id><pub-id pub-id-type="doi">10.1038/srep15717</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Luong</surname><given-names>T</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Le</surname><given-names>Q</given-names></name><name><surname>Vinyals</surname><given-names>O</given-names></name><name><surname>Zaremba</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><conf-name>Addressing the Rare Word Problem in Neural Machine Translation</conf-name><article-title>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</article-title><pub-id pub-id-type="doi">10.3115/v1/P15-1002</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Manoilov</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><conf-name>Eye-blinking artefacts analysis</conf-name><article-title>Proceedings of the 2007 International Conference on Computer Systems and Technologies, CompSysTech 2007</article-title><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1145/1330598.1330654</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcotti</surname><given-names>P</given-names></name><name><surname>St Jacques</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Shifting visual perspective during memory retrieval reduces the accuracy of subsequent memories</article-title><source>Memory</source><volume>26</volume><fpage>330</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1080/09658211.2017.1329441</pub-id><pub-id pub-id-type="pmid">28552030</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Marti</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><conf-name>Stochastic Optimization Methods</conf-name><article-title>International Conference on Learning Representations</article-title><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1007/978-3-662-46214-0</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matusz</surname><given-names>PJ</given-names></name><name><surname>Dikker</surname><given-names>S</given-names></name><name><surname>Huth</surname><given-names>AG</given-names></name><name><surname>Perrodin</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Are We Ready for Real-world Neuroscience?</article-title><source>Journal of Cognitive Neuroscience</source><volume>31</volume><fpage>327</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1162/jocn_e_01276</pub-id><pub-id pub-id-type="pmid">29916793</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mauss</surname><given-names>IB</given-names></name><name><surname>Robinson</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Measures of emotion: A review</article-title><source>Cognition &amp; Emotion</source><volume>23</volume><fpage>209</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1080/02699930802204677</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCall</surname><given-names>C</given-names></name><name><surname>Hildebrandt</surname><given-names>LK</given-names></name><name><surname>Bornemann</surname><given-names>B</given-names></name><name><surname>Singer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Physiophenomenology in retrospect: Memory reliably reflects physiological arousal during a prior threatening experience</article-title><source>Consciousness and Cognition</source><volume>38</volume><fpage>60</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2015.09.011</pub-id><pub-id pub-id-type="pmid">26529679</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meinel</surname><given-names>A</given-names></name><name><surname>Castaño-Candamil</surname><given-names>S</given-names></name><name><surname>Reis</surname><given-names>J</given-names></name><name><surname>Tangermann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pre-Trial EEG-Based Single-Trial Motor Performance Prediction to Enhance Neuroergonomics for a Hand Force Task</article-title><source>Frontiers in Human Neuroscience</source><volume>10</volume><elocation-id>170</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2016.00170</pub-id><pub-id pub-id-type="pmid">27199701</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Metzger</surname><given-names>LJ</given-names></name><name><surname>Paige</surname><given-names>SR</given-names></name><name><surname>Carson</surname><given-names>MA</given-names></name><name><surname>Lasko</surname><given-names>NB</given-names></name><name><surname>Paulus</surname><given-names>LA</given-names></name><name><surname>Pitman</surname><given-names>RK</given-names></name><name><surname>Orr</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>PTSD arousal and depression symptoms associated with increased right-sided parietal EEG asymmetry</article-title><source>Journal of Abnormal Psychology</source><volume>113</volume><fpage>324</fpage><lpage>329</lpage><pub-id pub-id-type="doi">10.1037/0021-843X.113.2.324</pub-id><pub-id pub-id-type="pmid">15122952</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mierau</surname><given-names>A</given-names></name><name><surname>Klimesch</surname><given-names>W</given-names></name><name><surname>Lefebvre</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>State-dependent alpha peak frequency shifts: Experimental evidence, potential mechanisms and functional implications</article-title><source>Neuroscience</source><volume>360</volume><fpage>146</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2017.07.037</pub-id><pub-id pub-id-type="pmid">28739525</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikutta</surname><given-names>C</given-names></name><name><surname>Altorfer</surname><given-names>A</given-names></name><name><surname>Strik</surname><given-names>W</given-names></name><name><surname>Koenig</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Emotions, arousal, and frontal alpha rhythm asymmetry during Beethoven’s 5th symphony</article-title><source>Brain Topography</source><volume>25</volume><fpage>423</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1007/s10548-012-0227-0</pub-id><pub-id pub-id-type="pmid">22534936</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moosmann</surname><given-names>M</given-names></name><name><surname>Ritter</surname><given-names>P</given-names></name><name><surname>Krastel</surname><given-names>I</given-names></name><name><surname>Brink</surname><given-names>A</given-names></name><name><surname>Thees</surname><given-names>S</given-names></name><name><surname>Blankenburg</surname><given-names>F</given-names></name><name><surname>Taskin</surname><given-names>B</given-names></name><name><surname>Obrig</surname><given-names>H</given-names></name><name><surname>Villringer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Correlates of alpha rhythm in functional magnetic resonance imaging and near infrared spectroscopy</article-title><source>NeuroImage</source><volume>20</volume><fpage>145</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1016/s1053-8119(03)00344-6</pub-id><pub-id pub-id-type="pmid">14527577</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muthukumaraswamy</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>High-frequency brain activity and muscle artifacts in MEG/EEG: a review and recommendations</article-title><source>Frontiers in Human Neuroscience</source><volume>7</volume><elocation-id>138</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2013.00138</pub-id><pub-id pub-id-type="pmid">23596409</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Naumann</surname><given-names>L</given-names></name><name><surname>Schultze-Kraft</surname><given-names>M</given-names></name><name><surname>Sven</surname><given-names>D</given-names></name><name><surname>Blankertz</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><conf-name>Prediction of Difficulty Levels in Video Games from Ongoing EEG</conf-name><article-title>ternational Workshop on Symbiotic Interaction</article-title><fpage>125</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-57753-1</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Neal</surname><given-names>B</given-names></name><name><surname>Mittal</surname><given-names>S</given-names></name><name><surname>Baratin</surname><given-names>A</given-names></name><name><surname>Tantia</surname><given-names>V</given-names></name><name><surname>Scicluna</surname><given-names>M</given-names></name><name><surname>Lacoste-Julien</surname><given-names>S</given-names></name><name><surname>Mitliagkas</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Modern Take on the Bias-Variance Tradeoff in Neural Networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1810.08591">https://arxiv.org/abs/1810.08591</ext-link></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikulin</surname><given-names>VV</given-names></name><name><surname>Nolte</surname><given-names>G</given-names></name><name><surname>Curio</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A novel method for reliable and fast extraction of neuronal EEG/MEG oscillations on the basis of spatio-spectral decomposition</article-title><source>NeuroImage</source><volume>55</volume><fpage>1528</fpage><lpage>1535</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.01.057</pub-id><pub-id pub-id-type="pmid">21276858</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nurse</surname><given-names>ES</given-names></name><name><surname>Karoly</surname><given-names>PJ</given-names></name><name><surname>Grayden</surname><given-names>DB</given-names></name><name><surname>Freestone</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Generalizable Brain-Computer Interface (BCI) Using Machine Learning for Feature Discovery</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0131328</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0131328</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ocklenburg</surname><given-names>S</given-names></name><name><surname>Friedrich</surname><given-names>P</given-names></name><name><surname>Schmitz</surname><given-names>J</given-names></name><name><surname>Schlüter</surname><given-names>C</given-names></name><name><surname>Genc</surname><given-names>E</given-names></name><name><surname>Güntürkün</surname><given-names>O</given-names></name><name><surname>Peterburs</surname><given-names>J</given-names></name><name><surname>Grimshaw</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Beyond frontal alpha: Investigating hemispheric asymmetries over the EEG frequency spectrum as a function of sex and handedness</article-title><source>Laterality: Asymmetries of Body, Brain and Cognition</source><volume>24</volume><fpage>505</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1080/1357650x.2018.15433</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olbrich</surname><given-names>S</given-names></name><name><surname>Mulert</surname><given-names>C</given-names></name><name><surname>Karch</surname><given-names>S</given-names></name><name><surname>Trenner</surname><given-names>M</given-names></name><name><surname>Leicht</surname><given-names>G</given-names></name><name><surname>Pogarell</surname><given-names>O</given-names></name><name><surname>Hegerl</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>EEG-vigilance and BOLD effect during simultaneous EEG/fMRI measurement</article-title><source>NeuroImage</source><volume>45</volume><fpage>319</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.11.014</pub-id><pub-id pub-id-type="pmid">19110062</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Opitz</surname><given-names>D</given-names></name><name><surname>Maclin</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Popular Ensemble Methods: An Empirical Study</article-title><source>Journal of Artificial Intelligence Research</source><volume>11</volume><fpage>169</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1613/jair.614</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>X</given-names></name><name><surname>Hamilton</surname><given-names>AF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Why and how to use virtual reality to study human social interaction: The challenges of exploring a new research landscape</article-title><source>British Journal of Psychology</source><volume>109</volume><fpage>395</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1111/bjop.12290</pub-id><pub-id pub-id-type="pmid">29504117</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parra</surname><given-names>LC</given-names></name><name><surname>Spence</surname><given-names>CD</given-names></name><name><surname>Gerson</surname><given-names>AD</given-names></name><name><surname>Sajda</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Recipes for the linear analysis of EEG</article-title><source>NeuroImage</source><volume>28</volume><fpage>326</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.05.032</pub-id><pub-id pub-id-type="pmid">16084117</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pascual-Marqui</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Discrete, 3D Distributed, Linear Imaging Methods of Electric Neuronal Activity. Part 1: Exact, Zero Error Localization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/0710.3341">https://arxiv.org/abs/0710.3341</ext-link></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlov</surname><given-names>YG</given-names></name><name><surname>Kotchoubey</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Oscillatory brain activity and maintenance of verbal and visual working memory: A systematic review</article-title><source>Psychophysiology</source><volume>5</volume><elocation-id>e13735</elocation-id><pub-id pub-id-type="doi">10.1111/psyp.13735</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfaff</surname><given-names>DW</given-names></name><name><surname>Martin</surname><given-names>EM</given-names></name><name><surname>Faber</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Origins of arousal: Roles for medullary reticular neurons</article-title><source>Trends in Neurosciences</source><volume>35</volume><fpage>468</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2012.04.008</pub-id><pub-id pub-id-type="pmid">22626543</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramoser</surname><given-names>H</given-names></name><name><surname>Müller-Gerking</surname><given-names>J</given-names></name><name><surname>Pfurtscheller</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Optimal spatial filtering of single trial EEG during imagined hand movement</article-title><source>IEEE Transactions on Rehabilitation Engineering</source><volume>8</volume><fpage>441</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1109/86.895946</pub-id><pub-id pub-id-type="pmid">11204034</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Reason</surname><given-names>JT</given-names></name><name><surname>Brand</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1975">1975</year><source>Motion Sickness</source><publisher-name>Academic press</publisher-name></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rebenitsch</surname><given-names>L</given-names></name><name><surname>Owen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Review on cybersickness in applications and visual displays</article-title><source>Virtual Reality</source><volume>20</volume><fpage>101</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1007/s10055-016-0285-9</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivet</surname><given-names>B</given-names></name><name><surname>Souloumiac</surname><given-names>A</given-names></name><name><surname>Attina</surname><given-names>V</given-names></name><name><surname>Gibert</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>xDAWN algorithm to enhance evoked potentials: application to brain-computer interface</article-title><source>IEEE Transactions on Bio-Medical Engineering</source><volume>56</volume><fpage>2035</fpage><lpage>2043</lpage><pub-id pub-id-type="doi">10.1109/TBME.2009.2012869</pub-id><pub-id pub-id-type="pmid">19174332</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberts</surname><given-names>DR</given-names></name><name><surname>Bahn</surname><given-names>V</given-names></name><name><surname>Ciuti</surname><given-names>S</given-names></name><name><surname>Boyce</surname><given-names>MS</given-names></name><name><surname>Elith</surname><given-names>J</given-names></name><name><surname>Guillera-Arroita</surname><given-names>G</given-names></name><name><surname>Hauenstein</surname><given-names>S</given-names></name><name><surname>Lahoz-Monfort</surname><given-names>JJ</given-names></name><name><surname>Schröder</surname><given-names>B</given-names></name><name><surname>Thuiller</surname><given-names>W</given-names></name><name><surname>Warton</surname><given-names>D</given-names></name><name><surname>Wintle</surname><given-names>BA</given-names></name><name><surname>Hartig</surname><given-names>F</given-names></name><name><surname>Dormann</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure</article-title><source>Ecography</source><volume>40</volume><fpage>913</fpage><lpage>929</lpage><pub-id pub-id-type="doi">10.1111/ecog.02881</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rokach</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Ensemble-based classifiers</article-title><source>Artificial Intelligence Review</source><volume>33</volume><fpage>1</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1007/s10462-009-9124-7</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ruder</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An Overview of Gradient Descent Optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1609.04747">https://arxiv.org/abs/1609.04747</ext-link></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>A circumplex model of affect</article-title><source>Journal of Personality and Social Psychology</source><volume>39</volume><fpage>1161</fpage><lpage>1178</lpage><pub-id pub-id-type="doi">10.1037/h0077714</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>JA</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Core Affect, Prototypical Emotional Episodes, and Other Things Called Emotion: Dissecting the Elephant</article-title><source>Journal of Personality and Social Psychology</source><volume>76</volume><fpage>805</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1037//0022-3514.76.5.805</pub-id><pub-id pub-id-type="pmid">10353204</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saarimäki</surname><given-names>H</given-names></name><name><surname>Gotsopoulos</surname><given-names>A</given-names></name><name><surname>Jääskeläinen</surname><given-names>IP</given-names></name><name><surname>Lampinen</surname><given-names>J</given-names></name><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Hari</surname><given-names>R</given-names></name><name><surname>Sams</surname><given-names>M</given-names></name><name><surname>Nummenmaa</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Discrete Neural Signatures of Basic Emotions</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>2563</fpage><lpage>2573</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv086</pub-id><pub-id pub-id-type="pmid">25924952</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabbagh</surname><given-names>D</given-names></name><name><surname>Ablin</surname><given-names>P</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Predictive regression modeling with MEG/EEG: From source power to signals and cognitive states</article-title><source>NeuroImage</source><volume>222</volume><elocation-id>116893</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116893</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schandry</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Heart Beat Perception and Emotional Experience</article-title><source>Psychophysiology</source><volume>18</volume><fpage>483</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1981.tb02486.x</pub-id><pub-id pub-id-type="pmid">7267933</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning in neural networks: An overview</article-title><source>Neural Networks</source><volume>61</volume><fpage>85</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2014.09.003</pub-id><pub-id pub-id-type="pmid">25462637</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>RE</given-names></name><name><surname>Gay</surname><given-names>P</given-names></name><name><surname>D’Acremont</surname><given-names>M</given-names></name><name><surname>van der Linden</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A German adaptation of the UPPS Impulsive Behavior Scale: Psychometric properties and factor structure</article-title><source>Swiss Journal of Psychology</source><volume>67</volume><fpage>107</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1024/1421-0185.67.2.107</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schubring</surname><given-names>D</given-names></name><name><surname>Schupp</surname><given-names>HT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Affective picture processing: Alpha- and lower beta-band desynchronization reflects emotional arousal</article-title><source>Psychophysiology</source><volume>56</volume><elocation-id>e13386</elocation-id><pub-id pub-id-type="doi">10.1111/psyp.13386</pub-id><pub-id pub-id-type="pmid">31026079</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultze-Kraft</surname><given-names>M</given-names></name><name><surname>Dähne</surname><given-names>S</given-names></name><name><surname>Gugler</surname><given-names>M</given-names></name><name><surname>Curio</surname><given-names>G</given-names></name><name><surname>Blankertz</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Unsupervised classification of operator workload from brain signals</article-title><source>Journal of Neural Engineering</source><volume>13</volume><elocation-id>036008</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2560/13/3/036008</pub-id><pub-id pub-id-type="pmid">27078889</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Interoceptive inference, emotion, and the embodied self</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>565</fpage><lpage>573</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.09.007</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamay-Tsoory</surname><given-names>SG</given-names></name><name><surname>Mendelsohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Real-Life Neuroscience: An Ecological Approach to Brain and Behavior Research</article-title><source>Perspectives on Psychological Science</source><volume>14</volume><fpage>841</fpage><lpage>859</lpage><pub-id pub-id-type="doi">10.1177/1745691619856350</pub-id><pub-id pub-id-type="pmid">31408614</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharbrough</surname><given-names>F</given-names></name><name><surname>Chatrian</surname><given-names>GE</given-names></name><name><surname>Luders</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>American Electroencephalographic Society Guidelines for Standard Electrode Position Nomenclature</article-title><source>Journal of Clinical Neurophysiology</source><volume>8</volume><fpage>200</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">2050819</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharples</surname><given-names>S</given-names></name><name><surname>Cobb</surname><given-names>S</given-names></name><name><surname>Moody</surname><given-names>A</given-names></name><name><surname>Wilson</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Virtual reality induced symptoms and effects (VRISE): Comparison of head mounted display (HMD), desktop and projection display systems</article-title><source>Displays</source><volume>29</volume><fpage>58</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.displa.2007.09.005</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname><given-names>EH</given-names></name><name><surname>Sands</surname><given-names>MK</given-names></name><name><surname>Van den Noortgate</surname><given-names>W</given-names></name><name><surname>Condon</surname><given-names>P</given-names></name><name><surname>Chang</surname><given-names>Y</given-names></name><name><surname>Dy</surname><given-names>J</given-names></name><name><surname>Quigley</surname><given-names>KS</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emotion fingerprints or emotion populations? A meta-analytic investigation of autonomic features of emotion categories</article-title><source>Psychological Bulletin</source><volume>144</volume><fpage>343</fpage><lpage>393</lpage><pub-id pub-id-type="doi">10.1037/bul0000128</pub-id><pub-id pub-id-type="pmid">29389177</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spielberger</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="1983">1983</year><source>Manual for the State–Trait Anxiety Inventory</source><publisher-name>Mind Garden</publisher-name></element-citation></ref><ref id="bib148"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spielberger</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="1989">1989</year><source>State–Trait Anxiety Inventory: A Comprehensive Bibliography</source><publisher-name>Consulting Psychologists Press</publisher-name></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stewart</surname><given-names>JL</given-names></name><name><surname>Towers</surname><given-names>DN</given-names></name><name><surname>Coan</surname><given-names>JA</given-names></name><name><surname>Allen</surname><given-names>JJB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The oft-neglected role of parietal EEG asymmetry and risk for major depressive disorder</article-title><source>Psychophysiology</source><volume>48</volume><fpage>82</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2010.01035.x</pub-id><pub-id pub-id-type="pmid">20525011</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sturm</surname><given-names>I</given-names></name><name><surname>Lapuschkin</surname><given-names>S</given-names></name><name><surname>Samek</surname><given-names>W</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Interpretable deep neural networks for single-trial EEG classification</article-title><source>Journal of Neuroscience Methods</source><volume>274</volume><fpage>141</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2016.10.008</pub-id><pub-id pub-id-type="pmid">27746229</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Symeonidou</surname><given-names>ER</given-names></name><name><surname>Nordin</surname><given-names>A</given-names></name><name><surname>Hairston</surname><given-names>W</given-names></name><name><surname>Ferris</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Effects of Cable Sway, Electrode Surface Area, and Electrode Mass on Electroencephalography Signal Quality during Motion</article-title><source>Sensors</source><volume>18</volume><elocation-id>1073</elocation-id><pub-id pub-id-type="doi">10.3390/s18041073</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theiler</surname><given-names>J</given-names></name><name><surname>Eubank</surname><given-names>S</given-names></name><name><surname>Longtin</surname><given-names>A</given-names></name><name><surname>Galdrikian</surname><given-names>B</given-names></name><name><surname>Doyne Farmer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Testing for nonlinearity in time series: The method of surrogate data</article-title><source>Physica D: Nonlinear Phenomena</source><volume>58</volume><fpage>77</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/0167-2789(92)90102-S</pub-id></element-citation></ref><ref id="bib153"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Thor</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>OpenVR Tracking Example</data-title><version designator="1.14.15">1.14.15</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/Omnifinity/OpenVR-Tracking-Example">https://github.com/Omnifinity/OpenVR-Tracking-Example</ext-link></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uusberg</surname><given-names>A</given-names></name><name><surname>Uibo</surname><given-names>H</given-names></name><name><surname>Kreegipuu</surname><given-names>K</given-names></name><name><surname>Allik</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>EEG alpha and cortical inhibition in affective attention</article-title><source>Ternational Journal of Psychophysiology</source><volume>89</volume><fpage>26</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2013.04.020</pub-id><pub-id pub-id-type="pmid">23643563</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Diepen</surname><given-names>RM</given-names></name><name><surname>Foxe</surname><given-names>JJ</given-names></name><name><surname>Mazaheri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The functional role of alpha-band activity in attentional processing: The current zeitgeist and future outlook</article-title><source>Current Opinion in Psychology</source><volume>29</volume><fpage>229</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1016/j.copsyc.2019.03.015</pub-id><pub-id pub-id-type="pmid">31100655</pub-id></element-citation></ref><ref id="bib156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vasser</surname><given-names>M</given-names></name><name><surname>Aru</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Guidelines for Immersive Virtual Reality in Psychological Research</article-title><source>Current Opinion in Psychology</source><volume>36</volume><fpage>71</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1016/j.copsyc.2020.04.010</pub-id></element-citation></ref><ref id="bib157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weech</surname><given-names>S</given-names></name><name><surname>Kenny</surname><given-names>S</given-names></name><name><surname>Barnett-Cowan</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Presence and Cybersickness in Virtual Reality Are Negatively Related: A Review</article-title><source>Frontiers in Psychology</source><volume>10</volume><elocation-id>158</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2019.00158</pub-id><pub-id pub-id-type="pmid">30778320</pub-id></element-citation></ref><ref id="bib158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whiteside</surname><given-names>SP</given-names></name><name><surname>Lynam</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The five factor model and impulsivity: Using a structural model of personality to understand impulsivity</article-title><source>Personality and Individual Differences</source><volume>30</volume><fpage>669</fpage><lpage>689</lpage><pub-id pub-id-type="doi">10.1016/S0191-8869(00)00064-7</pub-id></element-citation></ref><ref id="bib159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson-Mendenhall</surname><given-names>CD</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name><name><surname>Barsalou</surname><given-names>LW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural Evidence That Human Emotions Share Core Affective Properties</article-title><source>Psychological Science</source><volume>24</volume><fpage>947</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1177/0956797612464242</pub-id><pub-id pub-id-type="pmid">23603916</pub-id></element-citation></ref><ref id="bib160"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>AM</given-names></name><name><surname>Ridgway</surname><given-names>GR</given-names></name><name><surname>Webster</surname><given-names>MA</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Permutation inference for the general linear model</article-title><source>NeuroImage</source><volume>92</volume><fpage>381</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.01.060</pub-id><pub-id pub-id-type="pmid">24530839</pub-id></element-citation></ref><ref id="bib161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wöllmer</surname><given-names>M</given-names></name><name><surname>Eyben</surname><given-names>F</given-names></name><name><surname>Reiter</surname><given-names>S</given-names></name><name><surname>Schuller</surname><given-names>B</given-names></name><name><surname>Cox</surname><given-names>C</given-names></name><name><surname>Douglas-Cowie</surname><given-names>E</given-names></name><name><surname>Cowie</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Abandoning emotion classes - towards continuous emotion recognition with modelling of long-range dependencies</article-title><source>Terspeech</source><volume>2008</volume><fpage>597</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.21437/Interspeech.2008-192</pub-id></element-citation></ref><ref id="bib162"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wöllmer</surname><given-names>M</given-names></name><name><surname>Metallinou</surname><given-names>A</given-names></name><name><surname>Eyben</surname><given-names>F</given-names></name><name><surname>Schuller</surname><given-names>B</given-names></name><name><surname>Narayanan</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2010">2010</year><conf-name>Context-sensitive multimodal emotion recognition from speech and facial expression using bidirectional LSTM modeling</conf-name><article-title>TERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association, Makuhari, Chiba, Japan, September 26-30, 2010</article-title><fpage>2362</fpage><lpage>2365</lpage><pub-id pub-id-type="doi">10.21437/Interspeech.2010-646</pub-id></element-citation></ref><ref id="bib163"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wundt</surname><given-names>W</given-names></name><name><surname>Judd</surname><given-names>CH</given-names></name></person-group><year iso-8601-date="1897">1897</year><source>Outline of Psychology</source><publisher-loc>London</publisher-loc><publisher-name>Engelmann</publisher-name><pub-id pub-id-type="doi">10.1037/12908-000</pub-id></element-citation></ref><ref id="bib164"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zaremba</surname><given-names>W</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Vinyals</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Recurrent Neural Network Regularization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1409.2329">https://arxiv.org/abs/1409.2329</ext-link></element-citation></ref><ref id="bib165"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zuure</surname><given-names>MB</given-names></name><name><surname>Cohen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Narrowband multivariate source separation for semi-blind discovery of experiment contrasts</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.03.09.983635</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>Details of the rollercoasters</title><p>The ‘Space’ rollercoaster did not feature outstanding events during the ride besides two vertical spins starting around 47 and 73 s after the onset of the experience. Virtual collisions of asteroids floating through the scenery led to explosions of the celestial bodies involved, accompanied by an explosive sound. Apart from this, there were little sound effects during the space experience.</p><p>The ‘Andes’ rollercoaster included a steep drop (24 s after onset), two jumps with steep landings (31 and 67 s after onset), two passages through fires under the tracks (20 and 55 s after onset) and a looping (60 s after onset). Sound effects mimicked the sound of the waggon on the tracks, the fire, and the airflow. In the background a jingling melody was played.</p></sec><sec id="s9" sec-type="appendix"><title>Simulator sickness questions</title><p>The wording and items to assess simulator sickness were:</p><p>Please rate on a scale from 1 to 7 how much each symptom below is affecting you right now:</p><list list-type="order"><list-item><p>General discomfort</p></list-item><list-item><p>Nausea</p></list-item><list-item><p>Dizziness</p></list-item><list-item><p>Headache</p></list-item><list-item><p>Blurred vision</p></list-item><list-item><p>Difficulty concentrating.</p></list-item></list></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.64812.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Shackman</surname><given-names>Alexander</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>Hofmann et al., investigate the link between two phenomena, emotional arousal and cortical α activity. Although α activity is tightly linked to the first reports of electric activity in the brain nearly 100 years ago, a comprehensive characterization of this phenomenon is elusive. One of the reasons is that EEG, the major method to investigate electric activity in the human brain, is susceptible to motion artifacts and, thus, mostly used in laboratory settings. Here, the authors combine EEG with virtual reality (VR) to give experimental participants a roller coaster ride with high immersion. The ride, literally, leads to large ups and downs in emotional arousal, which is quantified by the subjects during a later rerun. Several different decoding methods were evaluated, and each showed above-chance levels of performance, substantiating a link between lower levels of parietal/occipital α and subjective arousal in a quasi-naturalistic setting.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.64812.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Shackman</surname><given-names>Alexander</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>König</surname><given-names>Peter</given-names></name><role>Reviewer</role><aff><institution>University Osnabrück</institution><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Decoding subjective emotional arousal from EEG during an immersive Virtual Reality experience&quot; for consideration by <italic>eLife</italic>. Your manuscript has been reviewed by 2 peer reviewers, and the evaluation has been overseen by Drs. Shackman (Reviewing Editor) and Baker (Senior Editor). The following individual involved in review of your submission has agreed to reveal their identity: Peter König (Reviewer #1).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Summary:</p><p>Hofmann et al., investigate the link between two phenomena, emotional arousal and cortical α activity. Although α activity is tightly linked to the first reports of electric activity in the brain nearly 100 years ago, a comprehensive characterization of this phenomenon is elusive. One of the reasons is that EEG, the major method to investigate electric activity in the human brain, is susceptible to motion artifacts and, thus, mostly used in laboratory settings. Here, the authors combine EEG with virtual reality (VR) to give experimental participants a roller-coaster ride with high immersion. The ride, literally, leads to large ups and downs in emotional arousal, which is quantified by the subjects during a later rerun. Three different decoding methods were evaluated (Source Power Comodulation, Common Spatial Patterns, and Long Short-Term Memory Recurrent Neural Networks), each of which demonstrated above-chance levels of performance, substantiating a link between lower levels of parietal/occipital α and subjective arousal in a quasi-naturalistic setting.</p><p>The reviewers both expressed some enthusiasm for the manuscript:</p><p>– The study is timely and makes an important contribution to our understanding of the relation of emotions and sensory processing.</p><p>– Of potentially great interest to a broad audience.</p><p>– The embedding in historic literature is excellent. I like it a lot.</p><p>– This work is notable because the roller-coaster simulation is a well-controlled, yet dynamic manipulation of arousal, and in its comparison of multiple decoding approaches (that can model the dynamics of affective responses). Indeed, this is an interesting proof of concept that shows it is possible to decode affective experience from brain activity measured during immersive virtual reality.</p><p>Major revisions:</p><p>Nevertheless, both reviewers expressed some significant concerns.</p><p>1. The result section is written as if there would be a preceding method section. But there is not. As a consequence, a large part of the results is incomprehensible without scrutinizing the method section further down. I'd suggest integrating about 2-3 pages worth of the total 17 pages method section into the result section proper. For example, you can safely assume that the majority of readers are not familiar with SPoC and CSP, might have heard of LSTM, but do not know the details relevant for the present context. Nonmov and mov conditions, well, might be guessed, but it is better to just state it. Similarly, Space coaster and Andes coaster, yeah, I just assumed that these are two different sections in the lab-amusement park. Still, make a short comment and reduce guessing.</p><p>2. Potential perceptual confounds: Decoding the emotional arousal vs. decoding break vs. ride. The emotional arousal drops drastically during the break. Ok, that's the nature of the break. However, the visual input also changes a lot during the break. This raises the possibility that the decoding emotional arousal largely rests on segmenting break vs. non-break periods by differentiating high motion visual input during the ride vs. static stimulation during the break. Figure 2 suggests some power differentiating different levels of emotional arousal within the ride intervals, but it is not really obvious. To address this issue, can you either better document and visualize the data or supply an analysis, not including the break, and just decoding variations of emotional arousal during the ride sections.</p><p>3. Temper the framing and claims to better align with the actual data and approach. The authors advocate that naturalistic experiments are needed to study emotional arousal, because &quot;static&quot; manipulations are not well-suited to capture the continuity and dynamics of arousal. This point is well-taken, but no comparisons were made between static and dynamic methods. Thus, although the work succeeds in showing it is possible to use machine learning to decode the subjective experience of arousal during virtual reality, it is not clear what new insights naturalistic manipulations and the machine learning approaches employed have to offer. Here are some suggestions for empirically evaluating the importance of dynamics in characterizing arousal:</p><p>a. Compare the effectiveness of the models developed in the present study against more conventional measures of arousal. Does a standard measure of occipital/parietal α predict subjective ratings as well as more complex models?</p><p>b. Experimentally compare correlates of arousal in static vs naturalistic manipulations. Do models trained to predict the arousal of participants during VR generalize to standard tasks and vice versa?</p><p>c. Investigate the importance of temporal dynamics in modeling arousal. LSTM models can model temporal dynamics through recurrent connections. Does disrupting this aspect of LSTM models reduce performance? Are dynamic models necessary to explain these naturalistic data?</p><p>4. The methods used to assess model performance are also a concern. Decoding models were evaluated separately for each subject using 10-fold cross-validation, and inference on performance was made using group-level statistics. Because time-series data are being decoded, if standard cross-validation was performed the results could be overly optimistic. Additionally, hyperparameters were selected to maximize model performance which can also lead to biased estimates. This is particularly problematic because overall decoding performance is not very high. Here are some suggestions for evaluating model performance:</p><p>a. Use rolling cross-validation or larger blocks to confirm that autocorrelation in EEG data and arousal ratings does not bias results.</p><p>b. Perform inference using block permutation (e.g., by iteratively scrambling consecutive blocks of subjective arousal ratings and refitting models).</p><p>c. Use nested cross-validation to optimize hyperparameters to provide a less biased estimate of performance.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.64812.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Major revisions:</p><p>1. The result section is written as if there would be a preceding method section. But there is not. As a consequence, a large part of the results is incomprehensible without scrutinizing the method section further down. I'd suggest integrating about 2-3 pages worth of the total 17 pages method section into the result section proper. For example, you can safely assume that the majority of readers are not familiar with SPoC and CSP, might have heard of LSTM, but do not know the details relevant for the present context. Nonmov and mov conditions, well, might be guessed, but it is better to just state it. Similarly, Space coaster and Andes coaster, yeah, I just assumed that these are two different sections in the lab-amusement park. Still, make a short comment and reduce guessing.</p></disp-quote><p>Given the methodological focus of the manuscript, we restructured the manuscript, moving the Methods and Materials section between the Introduction and the Results, as suggested by <italic>eLife</italic>. The models (SPoC, CSP, and LSTM) are now briefly introduced in the Introduction and detailed in the Methods section. We further made sure that the terms “Space” and “Andes” as well as “nomov” and “mov” condition are clearly introduced and explained.</p><disp-quote content-type="editor-comment"><p>2. Potential perceptual confounds: Decoding the emotional arousal vs. decoding break vs. ride. The emotional arousal drops drastically during the break. Ok, that's the nature of the break. However, the visual input also changes a lot during the break. This raises the possibility that the decoding emotional arousal largely rests on segmenting break vs. non-break periods by differentiating high motion visual input during the ride vs. static stimulation during the break. Figure 2 suggests some power differentiating different levels of emotional arousal within the ride intervals, but it is not really obvious. To address this issue, can you either better document and visualize the data or supply an analysis, not including the break, and just decoding variations of emotional arousal during the ride sections.</p></disp-quote><p>Following the reviewers’ suggestion, we ran the decoding and inference procedures (with the “sub-blocked” cross-validation, see Reviewer comment 4, and permutation procedures of the new supplementary analyses) once <italic>with</italic> and once <italic>without</italic> the data from the break. We did this for SPoC and CSP, skipping LSTM due to its computational processing cost and duration, and the comparable performance with CSP in the original analyses.</p><p>For both models (SPoC and CSP) and in both head movement conditions (nomov, mov), the decoding performance decreased for data <italic>without</italic> compared to data <italic>with</italic> the break (for CSP in the nomov condition significantly so; <italic>t</italic>(25) = 2.23, <italic>p</italic> = .034) but all previous findings remained significantly above chance. CSP results are visualized in <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>. (For comparison, <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref> shows the classification results of the linear model, logistic regression, which is introduced in Reviewer comment 3a).</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>CSP decoding performance shown as distributions of the means of the permuted null distributions (blue) over all subjects next to the distribution of the original, unpermuted decoding scores (yellow/green) on data <italic>with</italic> (left column) and <italic>without</italic> the break (right column) as well as with (lower row, “mov”) and without (upper row, “nomov”) free head movement.</title><p>One-sided paired <italic>t</italic>-tests indicate that the means of these distributions (dotted vertical lines) differ significantly, with higher performance when decoding from the unpermuted arousal ratings for all conditions (ns: not significant, *: <italic>p</italic> &lt;.05, **: <italic>p</italic> &lt;.01, ***: <italic>p</italic> &lt;.001).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-sa2-fig1-v2.tif"/></fig><p>This supplementary analysis is described and discussed in the revised manuscript as detailed below:</p><p>Methods and Materials / Data analysis / Supplementary analyses: methods:</p><p>“Excluding the break for model training</p><p>“The 30-s break differed from the rollercoaster rides in visual features (e.g., static vs dynamic input) and in arousal ratings, which were constantly relatively low during the break (see Figure 5). […]To test whether excluding the break changed the model performance, we compared the distributions of the decoding performance parameters (SPoC: Pearson correlation with target; CSP: ROC-AUC) from the data with and without the break using two-sided paired <italic>t</italic>-tests. We did this per model and movement condition.”</p><p>Results / Neurophysiology / Supplementary analyses: results:</p><p>“Excluding the break for model training</p><p>SPoC and CSP performed significantly above chance level also when trained and tested on data without the break section. […] Removing the break from the training data overall numerically decreased the decoding performances of both models. For CSP, the decrease was significant in the nomov (<italic>t</italic>(25) = 2.23, <italic>p</italic>=.034) and not significant in the mov condition (<italic>t</italic>(18) = 0.57, <italic>p</italic>=.58). For SPoC, the decrease (Pearson correlation) was not significant in both conditions (nomov: <italic>t</italic>(25) = -1.66, <italic>p</italic>=.108; mov: <italic>t</italic>(18) = -1.13, <italic>p</italic>=.269).”</p><p>Discussion:</p><p>“Moreover, to test the impact of the differences between the rollercoasters and the break, for example regarding visual dynamics and elicited emotional arousal, on the decoding performance, SPoC and CSP analyses were repeated on the data without the break. Again, the average decoding performances decreased compared to the data with the break, but remained significantly above chance level for both head movement conditions. The decrease in decoding performance with the break removed may result from (a) less training data being available and (b) a narrower range of emotional arousal values, more similar classes (&quot;high arousal&quot; and &quot;low arousal&quot;), and therefore a more difficult distinction.”</p><disp-quote content-type="editor-comment"><p>3. Temper the framing and claims to better align with the actual data and approach. The authors advocate that naturalistic experiments are needed to study emotional arousal, because &quot;static&quot; manipulations are not well-suited to capture the continuity and dynamics of arousal. This point is well-taken, but no comparisons were made between static and dynamic methods. Thus, although the work succeeds in showing it is possible to use machine learning to decode the subjective experience of arousal during virtual reality, it is not clear what new insights naturalistic manipulations and the machine learning approaches employed have to offer. Here are some suggestions for empirically evaluating the importance of dynamics in characterizing arousal:</p></disp-quote><p>Below, we detail the changes in the revised manuscript (tempering the framing) together with the additional analyses we ran. In general, we don’t want to claim that studying emotions in more naturalistic conditions works better than in static frameworks but that it <italic>also</italic> works under more naturalistic circumstances for which an increased level of face validity (i.e., generalizability towards the experience outside of the laboratory) can be assumed.</p><p>The main excerpts from the revised manuscript are:</p><p>Introduction: “This may be particularly true for affective phenomena like emotions.”</p><p>Discussion: “While such stimuli provide a high degree of experimental control in terms of low-level properties and presentation timings, the emotional experience and its neurophysiology under event-related stimulation may differ from the emotional experience in real-life settings, which is perceptually complex, multisensory, and continuously developing over time.”</p><disp-quote content-type="editor-comment"><p>a. Compare the effectiveness of the models developed in the present study against more conventional measures of arousal. Does a standard measure of occipital/parietal α predict subjective ratings as well as more complex models?</p></disp-quote><p>As a “standard measure”, we used a linear model (logistic regression) to predict the subjective level of (high vs low) emotional arousal from α power in an occipital/parietal region-of-interest (average of electrodes Pz, P3, P7, P4, P8, O1, O2, OZ): First, the EEG of each participant was filtered in the α band (±2 Hz around each participant’s α peak) via the EEGLAB (v.2019.1) ‘<italic>pop_eegfiltnew.m’</italic> function in MATLAB (v.R2019a). After a Hilbert transformation (<italic>‘hilbert.m’</italic>), α power was extracted by squaring the signal. The resulting time series was resampled to 1 Hz by averaging the power in non-overlapping 1-s epochs. To test the effect of autocorrelations in the data, training and testing of the logistic regression followed the same “sub-blocked” cross-validation regime as reported for CSP in response to Reviewer comment 4a (see below). The full logistic regression procedure was run in Python (v.3.8.5) via scikit-learn (v.0.24.1; Pedregosa et al., 2011).</p><p>On the group level, decoding performance (ROC-AUC) was significantly above chance level (1000 permutation on target labels) for both conditions when including break: nomov (<italic>t<sub>nomov</sub></italic>(25) = -3.66, <italic>p<sub>nomov</sub></italic> &lt;.001) and mov (<italic>t<sub>mov</sub></italic>(18) = -2.94, <italic>p<sub>mov</sub></italic> &lt;.01).</p><p>Conversely, when excluding the break, the decoding performance remained significant only for the mov condition (<italic>t<sub>mov</sub></italic>(18) = -2.06, <italic>p<sub>mov</sub></italic> &lt;.05), but not for the nomov condition (<italic>t<sub>nomov</sub></italic>(25) = -0.68, <italic>p<sub>nomov</sub></italic> = .493; see <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>).</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>Logistic regression decoding performance across subjects was significantly above chance level (permuted arousal ratings with 1000 permutations) in all but the condition without head movement and without the break.</title><p>(For more details, please refer to the caption of <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-sa2-fig2-v2.tif"/></fig><p>The number of participants, for which states of high and low arousal could be correctly classified with logistic regression in both head movement conditions (nomov, mov; including break) are shown and compared to CSP in <xref ref-type="table" rid="sa2table1">Author response table 1</xref>. The results further support the association between parieto-occipital α power and emotional arousal and show that logistic regression can detect this relationship.</p><table-wrap id="sa2table1" position="float"><label>Author response table 1.</label><caption><title>Number of participants, for which the level of emotional arousal (low, high) could be significantly predicted from α power (on data including break).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Significant prediction</th><th align="left" valign="top">nomov</th><th align="left" valign="top">mov</th></tr></thead><tbody><tr><td align="left" valign="top">Logistic regression</td><td align="left" valign="top">5/26</td><td align="left" valign="top">4/19</td></tr><tr><td align="left" valign="top">CSP</td><td align="left" valign="top">9/26</td><td align="left" valign="top">5/19</td></tr></tbody></table></table-wrap><p>However, logistic regression also has limitations, compared to approaches such as SPoC and CSP. Most importantly, linearly regressing power values (i) underestimates especially strong sources of noise, (ii) disregards the generative model that underlies EEG data and which describes the mapping from neural sources to recorded signals. This is because the nonlinear operator “squaring” is performed for each sensor before finding spatial weights, and (iii) makes the results difficult to interpret in neurophysiological terms due to channel-specific biases (<xref ref-type="bibr" rid="bib27">Dähne et al., 2014</xref>).</p><disp-quote content-type="editor-comment"><p>b. Experimentally compare correlates of arousal in static vs naturalistic manipulations. Do models trained to predict the arousal of participants during VR generalize to standard tasks and vice versa?</p></disp-quote><p>As mentioned above, we investigated whether findings from more static emotional stimulation (association of parieto-occipital α power and emotional arousal) extend to more naturalistic manipulations.</p><p>We agree that testing how and where there are differences between findings from naturalistic studies and from static experiments will be a very important field of study. To approach it while not changing multiple factors (e.g, task, participants, session), one would ideally acquire new data in a within-subject design that includes both a dynamic and a static emotion induction, which is – unfortunately – beyond the scope of our study.</p><p>We hope that our study serves as a stepping stone and motivation in this direction.</p><p>We added the following paragraph to the revised Limitations section:</p><p>“We here confirm findings from static stimulation under more naturalistic conditions. To systematically investigate differences between approaches, a study with a within-subject design would be required. We hope that our study provides a stepping stone and motivation in this direction.”</p><disp-quote content-type="editor-comment"><p>c. Investigate the importance of temporal dynamics in modeling arousal. LSTM models can model temporal dynamics through recurrent connections. Does disrupting this aspect of LSTM models reduce performance? Are dynamic models necessary to explain these naturalistic data?</p></disp-quote><p>Our study does not allow us to sufficiently answer whether dynamic models are necessary to explain these naturalistic data as this capacity of LSTMs is not fully taken advantage of due to the small size of our dataset. To gain enough training samples for the model from this small dataset, we split the sequences into short segments of 1-sec length, which limited the LSTM to apply its full potential and extract mid- to long-term dynamics in the EEG signal which are expected to unfold along the arousing VR experience. Moreover, switching off recurrent connections at the LSTM gating units would raise the question whether changes in decoding performance are caused by the disabled dynamic capacity, or, by modifications in the number of weights at the gating units. Despite these empirical and conceptual challenges, we agree that a systematic analysis of LSTMs and their dis/advantages for EEG analysis would be a valuable contribution. We hope that the comparison to the non-dynamic CSP and the additional analysis including the linear model (see Reviewer comment 3a) show that, in our study design, LSTMs and their capacity to model temporal dynamics were not superior.</p><p>We highlight the feature of LSTM as a dynamic model and the limitation to fully exploit this feature in our study design by adding the following fragment to the revised Discussion:</p><p>“With more data, an LSTM could be trained on raw data or longer segments of the EEG to preserve more of the continuous structure and ultimately exploit its central property, as a dynamic model, of detecting long-term dependencies in the input.”</p><disp-quote content-type="editor-comment"><p>4. The methods used to assess model performance are also a concern. Decoding models were evaluated separately for each subject using 10-fold cross-validation, and inference on performance was made using group-level statistics. Because time-series data are being decoded, if standard cross-validation was performed the results could be overly optimistic. Additionally, hyperparameters were selected to maximize model performance which can also lead to biased estimates. This is particularly problematic because overall decoding performance is not very high. Here are some suggestions for evaluating model performance:</p></disp-quote><p>The reviewers’ concrete suggestions led us to perform the control analyses detailed below. We report these in the Methods and in the Results section of the revised manuscript, together with the original results.</p><disp-quote content-type="editor-comment"><p>a. Use rolling cross-validation or larger blocks to confirm that autocorrelation in EEG data and arousal ratings does not bias results</p></disp-quote><p>We applied an adaption of rolling cross-validation (CV), “sub-blocked” CV, to the binary classification of CSP (LSTM-based analysis was skipped due to its computational processing cost and duration, and the comparable performance with CSP in the original analyses).</p><p>Please note that the originally reported performance metric accuracy (proportion of correctly classified samples) would be biased for unbalanced classes. In the supplementary analyses that we added to the manuscript, we therefore used the area under the curve of the receiver operating characteristic (ROC-AUC) instead.</p><p>The manuscript was revised accordingly in combination with reviewers’ comment 4b, which follows:</p><disp-quote content-type="editor-comment"><p>b. Perform inference using block permutation (e.g., by iteratively scrambling consecutive blocks of subjective arousal ratings and refitting models)</p></disp-quote><p>As suggested by the reviewers, we ran a supplementary analysis using block permutation to obtain assumption-free null distributions that reflect the autocorrelative nature of the data. The supplementary results for the CSP-based decoding (as reported in the revised manuscript, see above) overall support the results of the original analysis: Also when removing the break and when taking the autocorrelative structure in the data into account, our models were able to decode the levels of emotional arousal above chance level, reducing the probability that the original results are explained by artefacts or confounds.</p><p>The methods, results and discussion of the supplementary analyses (Reviewer comment 4a and b) are described in the revised manuscript as follows:</p><p>Methods and Materials / Data analysis / Supplementary analyses: methods:</p><p><bold>“</bold>Sub-blocked cross-validation and block permutation</p><p>For non-stationary, auto-correlated time-series data, randomized cross-validation can inflate the decoding performance (Roberts et al., 2017). […] On the group level, one-sided paired <italic>t</italic>-tests were used to compare the distribution of the actual decoding results against the distribution of the means of the null distributions per subject.”</p><p>Results / Neurophysiology / Supplementary analyses: results:</p><p>“Sub-blocked cross-validation and block permutation</p><p>To test for potential biases from the model or the data, specifically its auto-correlative properties, we ran the same analysis for CSP as above using sub-blocked chronological cross-validation and block permutation for statistical evaluation on the single-subject level. […] On the single-subject level (as assessed by permutation tests), decoding performance was significantly (p &lt;.05) higher when decoding the actual, unpermuted labels compared to the block-permuted labels for 9/26 (34.62 %) participants in the nomov and 5/19 (26.32 %) participants in the mov condition.”</p><p>Discussion:</p><p>“To test for confounds or analytic artefacts, for example due to autocorrelations in the data, we additionally applied “sub-blocked” cross-validation for model training and block permutation for statistical evaluation. Also under these more strict evaluation conditions, the average decoding performance was significantly above chance level. It is therefore unlikely that the results can be explained solely by dependencies in the data (e.g., autocorrelation) which are not explicitly modelled in the main analysis.“</p><disp-quote content-type="editor-comment"><p>c. Use nested cross-validation to optimize hyperparameters to provide a less biased estimate of performance</p></disp-quote><p>We agree that nested cross-validation (CV) would be the best approach to optimize hyperparameters (HPs). However, the sparse data per subject (180 samples in the classification task) was not sufficient to extract a reliable estimate of optimal HPs via nested CV, due to the negative bias (i.e., pessimistic model fit) that CV alone induces on small datasets (Section 5.1. In <ext-link ext-link-type="uri" xlink:href="https://projecteuclid.org/journals/statistics-surveys/volume-4/issue-none/A-survey-of-cross-validation-procedures-for-model-selection/10.1214/09-SS054.full">Arlot and Celisse, 2010</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2016.10.038">Varoquaux et al., 2017</ext-link>). As an alternative, we performed a random HP search on a subset of subjects (n=10), with the aim to make the found HPs more generalizable (if they lead to similar performances when applied on all subjects).</p><p>The results suggest that the model performance is relatively robust across the narrow set of HPs within subjects: <xref ref-type="fig" rid="sa2fig3">Author response image 3</xref> and 4 show the performance distributions over the narrow set of pre-selected hyperparameters <inline-formula><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the nomov and mov condition, respectively. Shown are participants, for whose data the average accuracy over HP sets in <inline-formula><mml:math id="sa2m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was (green) or was not (blue) significant: 9 out of originally 16 subjects in the nomov and 7 out of 16 subjects in the mov condition remained significant (<italic>p</italic> &lt;.05, two-sided binomial tests against chance level). Here, testing significance over the average HP set accuracy is explicitly overly conservative due to the above-mentioned negative bias of individual HP sets and potential non-convergence of the training procedure caused by random weight initialization.</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><caption><title>Accuracy over the narrow set of hyperparameter (HP) settings in the condition without free head movement (nomov).</title><p>The average accuracy of HPsets was (<italic>green</italic>) or was not (<italic>blue</italic>) significant. <italic>Orange</italic>: Binomial distribution over random trials. <italic>Black thick dotted line</italic>: Significance threshold. <italic>Red dots</italic> indicate the originally significant subjects and their best performing HP set. If the mean of the HP-set distribution (<italic>longer, dotted vertical line</italic>) passes the <italic>p</italic>-value threshold (<italic>shorter, black-dotted vertical line</italic>), the average accuracy is significant (distribution becomes <italic>green</italic>, otherwise <italic>blue</italic>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-sa2-fig3-v2.tif"/></fig><fig id="sa2fig4" position="float"><label>Author response image 4.</label><caption><title>Accuracy over the narrow set of hyperparameter (HP) settings in mov conditions.</title><p>For details, please see the caption of <xref ref-type="fig" rid="sa2fig3">Author response image 3A</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64812-sa2-fig4-v2.tif"/></fig></body></sub-article></article>