<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">08351</article-id><article-id pub-id-type="doi">10.7554/eLife.08351</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Epidemiology and Global Health</subject></subj-group><subj-group subj-group-type="heading"><subject>Medicine</subject></subj-group></article-categories><title-group><article-title>A meta-analysis of threats to valid clinical inference in preclinical research of sunitinib</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-33015"><name><surname>Henderson</surname><given-names>Valerie C</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-33486"><name><surname>Demko</surname><given-names>Nadine</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-33487"><name><surname>Hakala</surname><given-names>Amanda</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-33488"><name><surname>MacKinnon</surname><given-names>Nathalie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-33489"><name><surname>Federico</surname><given-names>Carole A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-33490"><name><surname>Fergusson</surname><given-names>Dean</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-33491"><name><surname>Kimmelman</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Studies of Translation, Ethics and Medicine Research Group, Biomedical Ethics Unit</institution>, <institution>McGill University</institution>, <addr-line><named-content content-type="city">Montréal</named-content></addr-line>, <country>Canada</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Clinical Epidemiology</institution>, <institution>Ottawa Hospital Research Institute</institution>, <addr-line><named-content content-type="city">Ottawa</named-content></addr-line>, <country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-17333"><name><surname>Teare</surname><given-names>M Dawn</given-names></name><role>Reviewing editor</role><aff><institution>University of Sheffield</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>jonathan.kimmelman@mcgill.ca</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>13</day><month>10</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e08351</elocation-id><history><date date-type="received"><day>25</day><month>04</month><year>2015</year></date><date date-type="accepted"><day>05</day><month>09</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Henderson et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Henderson et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-08351-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.08351.001</object-id><p>Poor study methodology leads to biased measurement of treatment effects in preclinical research. We used available sunitinib preclinical studies to evaluate relationships between study design and experimental tumor volume effect sizes. We identified published animal efficacy experiments where sunitinib monotherapy was tested for effects on tumor volume. Effect sizes were extracted alongside experimental design elements addressing threats to valid clinical inference. Reported use of practices to address internal validity threats was limited, with no experiments using blinded outcome assessment. Most malignancies were tested in one model only, raising concerns about external validity. We calculate a 45% overestimate of effect size across all malignancies due to potential publication bias. Pooled effect sizes for specific malignancies did not show apparent relationships with effect sizes in clinical trials, and we were unable to detect dose–response relationships. Design and reporting standards represent an opportunity for improving clinical inference.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.001">http://dx.doi.org/10.7554/eLife.08351.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.08351.002</object-id><title>eLife digest</title><p>Developing a new drug can take years, partly because preclinical research on non-human animals is required before any clinical trials with humans can take place. Nevertheless, only a fraction of cancer drugs that are put into clinical trials after showing promising results in preclinical animal studies end up proving safe and effective in human beings.</p><p>Many researchers and commentators have suggested that this high failure rate reflects flaws in the way preclinical studies in cancer are designed and reported. Now, Henderson et al. have looked at all the published animal studies of a cancer drug called sunitinib and asked how well the design of these studies attempted to limit bias and match the clinical scenarios they were intended to represent.</p><p>This systematic review and meta-analysis revealed that many common practices, like randomization, were rarely implemented. None of the published studies used ‘blinding’, whereby information about which animals are receiving the drug and which animals are receiving the control is kept from the experimenter, until after the test; this technique can help prevent any expectations or personal preferences from biasing the results. Furthermore, most tumors were tested in only one model system, namely, mice that had been injected with specific human cancer cells. This makes it difficult to rule out that any anti-cancer activity was in fact unique to that single model.</p><p>Henderson et al. went on to find evidence that suggests that the anti-cancer effects of sunitinib might have been overestimated by as much as 45% because those studies that found no or little anti-cancer effect were simply not published. Though it is known that the anti-cancer activity of the drug increases with the dose given in both human beings and animals, an evaluation of the effects of all the published studies combined did not detect such a dose-dependent response.</p><p>The poor design and reporting issues identified provide further grounds for concern about the value of many preclinical experiments in cancer. These findings also suggest that there are many opportunities for improving the design and reliability of study reports. Researchers studying certain medical conditions (such as strokes) have already developed, and now routinely implement, a set of standards for the design and reporting of preclinical research. It now appears that the cancer research community should do the same.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.002">http://dx.doi.org/10.7554/eLife.08351.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>systematic review</kwd><kwd>meta-analysis</kwd><kwd>cancer</kwd><kwd>preclinical</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd><kwd>Rat</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research (Instituts de recherche en santé du Canada)</institution></institution-wrap></funding-source><award-id>EOG 111391</award-id><principal-award-recipient><name><surname>Kimmelman</surname><given-names>Jonathan</given-names></name></principal-award-recipient></award-group><funding-statement>The funder had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.3</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Preclinical efficacy experiments testing sunitinib in animal cancer models display a lack of methodological rigour, with trim-and-fill analysis suggesting prominent publication bias that leads to an overestimation of treatment effect.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Preclinical experiments provide evidence of clinical promise, inform trial design, and establish the ethical basis for exposing patients to a new substance. However, preclinical research is plagued by poor design and reporting practices (<xref ref-type="bibr" rid="bib49">van der Worp et al., 2010</xref>; <xref ref-type="bibr" rid="bib7">Begley, 2013a</xref>; <xref ref-type="bibr" rid="bib6">Begley and Ioannidis, 2015</xref>). Recent reports also suggest that many effects in preclinical studies fail replication (<xref ref-type="bibr" rid="bib5">Begley and Ellis, 2012</xref>). Drug development efforts grounded on non-reproducible findings expose patients to harmful and inactive agents; they also absorb scarce scientific and human resources, the costs of which are reflected as higher drug prices.</p><p>Several studies have evaluated the predictive value of animal models in cancer drug development (<xref ref-type="bibr" rid="bib27">Johnson et al., 2001</xref>; <xref ref-type="bibr" rid="bib50">Voskoglou-Nomikos et al., 2003</xref>; <xref ref-type="bibr" rid="bib10">Corpet and Pierre, 2005</xref>). However, few have systematically examined experimental design—as opposed to use of specific models—and its impact on effect sizes across different malignancies (<xref ref-type="bibr" rid="bib3">Amarasingh et al., 2009</xref>; <xref ref-type="bibr" rid="bib24">Hirst et al., 2013</xref>). A recent systematic review of guidelines for limiting bias in preclinical research design was unable to identify any guidelines in oncology (<xref ref-type="bibr" rid="bib22">Henderson et al., 2013</xref>). Validity threats in preclinical oncology may be particularly important to address in light of the fact that cancer drug development has one of the highest rates of attrition (<xref ref-type="bibr" rid="bib21">Hay et al., 2014</xref>), and oncology drug development commands billions of dollars in funding each year (<xref ref-type="bibr" rid="bib2">Adams and Brantner, 2006</xref>).</p><p>In what follows, we conducted a systematic review and meta-analysis of features of design and outcomes for preclinical efficacy studies of the highly successful drug sunitinib. Sunitinib is a multi-targeted tyrosine kinase inhibitor sunitinib (SU11248, Sutent) and is licensed as monotherapy for three different malignancies (<xref ref-type="bibr" rid="bib9">Chow and Eckhardt, 2007</xref>; <xref ref-type="bibr" rid="bib43">Raymond et al., 2011</xref>). As it was introduced into clinical development around 2000 and tested against numerous malignancies, sunitinib provided an opportunity to study a large sample of preclinical studies across a broad range of malignancies—including several supporting successful translation trajectories.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Study characteristics</title><p>Our screen from database and reference searches captured 74 studies eligible for extraction, corresponding to 332 unique experiments investigating tumor volume response (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="table" rid="tbl1">Table 1</xref>, <xref ref-type="supplementary-material" rid="SD2-data">Table 1—source data 1E</xref>). Effect sizes (standardized mean difference [SMD] using Hedges' g) could not be computed for 174 experiments (52%) due to inadequate reporting (e.g., sample size not provided, effect size reported as a median, lack of error bars, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Overall, 158 experiments, involving 2716 animals, were eligible for meta-analysis. The overall pooled SMD for all extracted experiments across all malignancies was −1.8 [−2.1, −1.6] (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Mean duration of experiments used in meta-analysis (<xref ref-type="fig" rid="fig2 fig3 fig4">Figures 2–4</xref>) was 31 days (±14 days standardized deviation of the mean (SDM)).<fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.08351.003</object-id><label>Figure 1.</label><caption><title>Descriptive analysis of (<bold>A</bold>) internal, construct, and (<bold>B</bold>) external validity design elements.</title><p>External validity scores were calculated for each malignancy type tested, according to the formula: number species used + number of models used; an extra point was assigned if a malignancy type tested more than one species <italic>and</italic> more than one model.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.003">http://dx.doi.org/10.7554/eLife.08351.003</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.08351.004</object-id><label>Figure 1—source data 1.</label><caption><title>(A) Coding details for IV and CV categories.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.004">http://dx.doi.org/10.7554/eLife.08351.004</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-08351-fig1-data1-v1.docx"/></supplementary-material></p></caption><graphic xlink:href="elife-08351-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.08351.005</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Descriptive analysis of (<bold>A</bold>) internal, construct, and (<bold>B</bold>) external validity design elements for all experiments (n = 332) extracted for validity data parameters.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.005">http://dx.doi.org/10.7554/eLife.08351.005</ext-link></p></caption><graphic xlink:href="elife-08351-fig1-figsupp1-v1.tif"/></fig></fig-group><table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.08351.006</object-id><label>Table 1.</label><caption><p>Demographics of included studies</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.006">http://dx.doi.org/10.7554/eLife.08351.006</ext-link></p><p><supplementary-material id="SD2-data"><object-id pub-id-type="doi">10.7554/eLife.08351.007</object-id><label>Table 1—source data 1.</label><caption><p>(C) Search Strategies. (D) PRISMA Flow Diagram. (E) Demographics of included studies at qualitative level.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.007">http://dx.doi.org/10.7554/eLife.08351.007</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-08351-data1-v1.docx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Study level demographics</th><th>Included studies (n = 74)</th></tr></thead><tbody><tr><td colspan="2">Conflict of interest</td></tr><tr><td> Declared</td><td>19 (26%)</td></tr><tr><td colspan="2">Funding statement<xref ref-type="table-fn" rid="tblfn1">*</xref></td></tr><tr><td> Private, for-profit</td><td>44 (59%)</td></tr><tr><td> Private, not-for-profit</td><td>35 (47%)</td></tr><tr><td> Public</td><td>37 (50%)</td></tr><tr><td> Other</td><td>2 (3%)</td></tr><tr><td colspan="2">Recommended clinical testing</td></tr><tr><td> Yes</td><td>37 (50%)</td></tr><tr><td colspan="2">Publication date</td></tr><tr><td> 2003–2006</td><td>13 (18%)</td></tr><tr><td> 2007–2009</td><td>17 (23%)</td></tr><tr><td> 2010–2013</td><td>44 (59%)</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><label>*</label><p>Does not sum to 100% as many studies declared more than one funding source.</p></fn></table-wrap-foot></table-wrap><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.08351.008</object-id><label>Figure 2.</label><caption><title>Summary of pooled SMDs for each malignancy type.</title><p>Shaded region denotes the pooled standardized mean difference (SMD) and 95% confidence interval (CI) (−1.8 [−2.1, −1.6]) for all experiments combined at the last common time point (LCT).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.008">http://dx.doi.org/10.7554/eLife.08351.008</ext-link></p><p><supplementary-material id="SD3-data"><object-id pub-id-type="doi">10.7554/eLife.08351.009</object-id><label>Figure 2—source data 1.</label><caption><title>(B) Heterogeneity statistics (I<sup>2</sup>) for each malignancy sub-group.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.009">http://dx.doi.org/10.7554/eLife.08351.009</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-08351-fig2-data1-v1.docx"/></supplementary-material></p></caption><graphic xlink:href="elife-08351-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.08351.010</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Effect sizes for all included experiments (n = 158).</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.010">http://dx.doi.org/10.7554/eLife.08351.010</ext-link></p></caption><graphic xlink:href="elife-08351-fig2-figsupp1-v1.tif"/></fig></fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.08351.011</object-id><label>Figure 3.</label><caption><title>Relationship between study design elements and effect sizes.</title><p>The shaded region denotes the pooled SMD and 95% CI (−1.8 [−2.1, −1.6]) for all experiments combined at the LCT.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.011">http://dx.doi.org/10.7554/eLife.08351.011</ext-link></p></caption><graphic xlink:href="elife-08351-fig3-v1.tif"/></fig><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.08351.012</object-id><label>Figure 4.</label><caption><title>Funnel plot to detect publication bias.</title><p>Trim and fill analysis was performed on pooled malignancies, as well as the three malignancies with the greatest study volume. (<bold>A</bold>) All experiments for all malignancies (n = 182), (<bold>B</bold>) all experiments within renal cell carcinoma (RCC) (n = 35), (<bold>C</bold>) breast cancer (n = 32), and (<bold>D</bold>) colorectal cancer (n = 29). Time point was the LCT. Open circles denote original data points whereas black circles denote ‘filled’ experiments. Trim and fill did not produce an estimate in RCC; therefore, no overestimation of effect size could be found.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.012">http://dx.doi.org/10.7554/eLife.08351.012</ext-link></p></caption><graphic xlink:href="elife-08351-fig4-v1.tif"/></fig></p></sec><sec id="s2-2"><title>Design elements addressing validity threats</title><p>Effects in preclinical studies can fail clinical generalization because of bias or random variation (internal validity), a mismatch between experimental operations and the clinical scenario modeled (construct validity), or idiosyncratic causal mediators in an experimental system (external validity) (<xref ref-type="bibr" rid="bib22">Henderson et al., 2013</xref>). We extracted design elements addressing each using consensus design practices identified in a systematic review of validity threats in preclinical research (<xref ref-type="bibr" rid="bib22">Henderson et al., 2013</xref>).</p><p>Few studies used practices like blinding or randomization to address internal validity threats (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Only 6% of experiments investigated a dose–response relationship (3 or more doses). Concealment of allocation or blinded outcome assessment was never reported in studies that advanced to meta-analysis. It is worth noting that one research group employed concealed allocation and blinded assessment for the many experiments it described (<xref ref-type="bibr" rid="bib34">Maris et al., 2008</xref>). However, statistics were reported in a way that did not align with those we needed to calculate SMD. We found that 58.8% of experiments included active drug comparators, thus, facilitating interpretation of sunitinib activity (however, we note that in some of the experiments, sunitinib was an active comparator in a test of a different drug or drug combination). Construct validity practices can only be meaningfully evaluated against a particular, matched clinical trial. Nevertheless, <xref ref-type="fig" rid="fig1">Figure 1A</xref> shows that experiments predominantly relied on juvenile, female, immunocompromised mouse models, and very few animal efficacy experiments used genetically engineered cancer models (n = 4) or spontaneously arising tumors (n = 0). Malignancies generally scored low (score = 1) for addressing external validity (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), with breast cancer studies employing the greatest variety of species (n = 2) and models (n = 4).</p><p>Implementation of internal validity practices did not show clear relationships with effect sizes (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). However, sunitinib effect sizes were significantly greater when active drug comparators were present in an experiment compared to when they were not (−2.2 [−2.5, −1.9] vs −1.4 [−1.7, −1.1], p-value &lt;0.001).</p><p>Within construct validity, there was a significant difference in pooled effect size between genetically engineered mouse models and human xenograft (p-value &lt;0.0001) and allograft (p-value 0.001) model types (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). For external validity (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), malignancies tested in more and diverse experimental systems tended to show less extreme effect sizes (p &lt; 0.001).</p></sec><sec id="s2-3"><title>Evidence of publication bias</title><p>For the 158 individual experiments, 65.8% showed statistically significant activity at the experiment level (p &lt; 0.05, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), with an average sample size of 8.03 animals per treatment arm and 8.39 animals per control arm. Funnel plots for all studies (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), as well as our renal cell carcinoma (RCC) subset (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) suggest potential publication bias. Trim and fill analysis suggests an overestimation of effect size of 45% (SMD changed from −1.8 [−2.1, −1.7] to −1.3 [−1.5, −1.0]) across all indications. For high-grade glioma and breast cancer, the overestimation was 11% and 52%, respectively. However, trim and fill analysis suggested excellent symmetry for the RCC subgroup, suggesting coverage of the overall effect size and confidence intervals and not overestimation of effect size.</p></sec><sec id="s2-4"><title>Preclinical studies and clinical correlates</title><p>Every malignancy tested with sunitinib showed statistically significant anti-tumor activity (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Though we did not perform a systematic review to estimate clinical effect sizes for sunitinib against various malignancies, a perusal of the clinical literature suggests little relationship between pooled effect sizes and demonstrated clinical activity. For instance, sunitinib monotherapy is highly active in RCC patients (<xref ref-type="bibr" rid="bib36">Motzer et al., 2006a</xref>, <xref ref-type="bibr" rid="bib37">2006b</xref>) and yet showed a relatively small preclinical effect; in contrast, sunitinib monotherapy was inactive against small cell lung cancer in a phase 2 trial (<xref ref-type="bibr" rid="bib20">Han et al., 2013</xref>), but showed relatively large preclinical effects.</p><p>Using measured effect sizes at a standardized time point of 14 days after first administration (a different time point than in <xref ref-type="fig" rid="fig2 fig3 fig4">Figures 2–4</xref> to better align our evaluation of dose–response), we were unable to observe a dose–response relationship over three orders of magnitude (0.2–120 mg/kg/day) for all experiments (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). We were also unable to detect a dose–response relationship over the full dose range (4–80 mg/kg/day) tested in the RCC subset (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). The same results were observed when we performed the same analyses using the last time point in common between the experimental and control arms.<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.08351.013</object-id><label>Figure 5.</label><caption><title>Dose–response curves for sunitinib preclinical studies.</title><p>Only experiments with a once daily (no breaks) administration schedule were included in both graphs. Effect size data were taken from a standardized time point (14 days after first sunitinib administration). (<bold>A</bold>) Experiments (n = 158) from all malignancies tested failed to show a dose–response relationship. (<bold>B</bold>) A dose–response relationship was not detected for RCC (n = 24). (<bold>C</bold>) Dose–response curves reported in individual studies within the RCC subset showed dose–response patterns (blue diamond = Huang 2010a [n = 3], red square = Huang 2010d [n = 3], green triangle = Ko 2010a [n = 3], purple X = Xin 2009 [n = 3]).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08351.013">http://dx.doi.org/10.7554/eLife.08351.013</ext-link></p></caption><graphic xlink:href="elife-08351-fig5-v1.tif"/></fig></p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Preclinical studies serve an important role in formulating clinical hypotheses and justifying the advance of a new drug into clinical testing. Our meta-analysis, which included malignancies that respond to sunitinib in human beings and those that do not, raises several questions about methods and reporting practices in preclinical oncology—at least in the context of one well-established drug.</p><p>First, reporting of design elements and data was poor and inconsistent with widely recognized standards for animal studies (<xref ref-type="bibr" rid="bib30">Kilkenny et al., 2010</xref>). Indeed, 98 experiments (30% of qualitative sample) could not be quantitatively analyzed because sample sizes or measures of dispersion were not provided. Experimenters only sporadically addressed major internal validity threats and tended not to test indication-activity in more than one model and species. This finding is consistent with what others have observed in experimental stroke and other research areas (<xref ref-type="bibr" rid="bib33">Macleod et al., 2004</xref>; <xref ref-type="bibr" rid="bib48">van der Worp et al., 2005</xref>; <xref ref-type="bibr" rid="bib29">Kilkenny et al., 2009</xref>; <xref ref-type="bibr" rid="bib19">Glasziou et al., 2014</xref>). Some teams have shown a relationship between failure to address internal validity threats and exaggerated effect size (<xref ref-type="bibr" rid="bib11">Crossley et al., 2008</xref>; <xref ref-type="bibr" rid="bib44">Rooke et al., 2011</xref>); we did not observe a clear relationship. Consistent with what has been reported in stroke (<xref ref-type="bibr" rid="bib40">O'Collins et al., 2006</xref>), our findings suggest that testing in more models tends to produce smaller effect sizes. However, since a larger sample of studies will provide a more precise estimate of effect, we cannot rule out that the trends observed for external validity reflect a regression to the mean.</p><p>Second, preclinical studies for sunitinib seem to be prone to publication bias. Notwithstanding limitations on using funnel plots to detect publication bias (<xref ref-type="bibr" rid="bib32">Lau et al., 2006</xref>), our plots were highly asymmetrical. That all malignancy types tested showed statistically significant anti-cancer activity strains credulity. Others have reported that far more animal studies report statistical significance than would be expected (<xref ref-type="bibr" rid="bib51">Wallace et al., 2009</xref>; <xref ref-type="bibr" rid="bib47">Tsilidis et al., 2013</xref>), and our observations that two thirds of individual studies showed significance extends these observations.</p><p>Third, we were unable to detect a meaningful relationship between preclinical effect sizes and known clinical behavior. Although a full analysis correlating trial and preclinical effect sizes will be needed, we did not observe obvious relationships between the two. We also did not detect a dose–response effect over three orders of magnitude even within an indication—RCC—known to respond to sunitinib and even when different time points were used. It is possible that heterogeneity in cell lines or strains may have obscured the effects of dose. For example, experimenters may have delivered higher doses to xenografts known to show slow tumor growth. However, RCC patients—each of whom harbors genetically distinct tumors—show dose–response effects in trials (<xref ref-type="bibr" rid="bib16">Faivre et al., 2006</xref>) and between trials in a meta-analysis (<xref ref-type="bibr" rid="bib26">Houk et al., 2010</xref>). It is also possible that the toxicity of sunitinib may have limited the ability to demonstrate dose response, though this contradicts demonstration of dose response within studies (<xref ref-type="bibr" rid="bib1">Abrams et al., 2003</xref>; <xref ref-type="bibr" rid="bib4">Amino et al., 2006</xref>; <xref ref-type="bibr" rid="bib31">Ko et al., 2010</xref>). Finally, the tendency for preclinical efficacy studies to report drug dose, but rarely drug exposure (i.e., serum measurement of active drug), further limits the construct validity of these studies (<xref ref-type="bibr" rid="bib41">Peterson and Houghton, 2004</xref>).</p><p>One explanation for our findings is that human xenograft models, which dominated our meta-analytic sample, have little predictive value, at least in the context of receptor tyrosine kinase inhibitors. This is a possibility that contradicts other reports (<xref ref-type="bibr" rid="bib28">Kerbel, 2003</xref>; <xref ref-type="bibr" rid="bib50">Voskoglou-Nomikos et al., 2003</xref>). We disfavor this explanation in light of the suggestion of publication bias; also, xenografts should show a dose–response regardless of whether they are useful clinical models. A second explanation is that experimental methods are so varied as to mask real effects. However, we note that the observed patterns on experimental design are based purely on what was reported in ‘Materials and methods’ section. Third, experiments assessing changes in tumor volume might only be interpretable in the context of other experiments within a preclinical report, such as with mechanistic and pharmacokinetic studies. This explanation is consistent with our observation that studies testing effect along a causal pathway tended to produce smaller effect sizes. A fourth possible explanation for our findings is that the predictive value of a small number of preclinical studies was obscured by inclusion of poorly designed and executed preclinical studies in our meta-analysis. Quantitative analysis of preclinical design factors that confer greater clinical generalizability awaits side-by-side comparison with pooled effects in clinical trials. Finally, it may be that design and reporting practices are so poor in preclinical cancer research as to make interpretation of tumor volume curves useless. Or, non-reporting may be so rampant as to render meta-analysis of preclinical research impossible. If so, this raises very troubling questions for the publication economy of cancer biology: even well-designed and reported studies may be difficult to interpret if their results cannot be compared to and synthesized with other studies.</p><p>Our systematic review has several limitations. First, we relied on what authors reported in the published study. It is possible certain experimental practices, like randomization, were used but not reported in methods. Further to this, we relied only on published reports, and restriction of searches to the English language may have excluded some articles. In February of 2012, we filed a Freedom of Information Act request from the Food and Drug Administration (FDA) for additional preclinical data submitted in support of sunitinib's licensure; nearly 4 years later, the request has not been honored. Second, effect sizes were calculated using graph digitizer software from tumor volume curves: minor distortion of effect sizes may have occurred but were likely non-differential between groups. Third, subtle experimental design features—not apparent in ‘Materials and methods’ sections—may explain our failure to detect a dose–response effect. For instance, few reports provide detailed animal housing and testing conditions, perhaps leading to important inter-laboratory differences in tumor growth. It should also be emphasized that our study was exploratory in nature; findings like ours will need to be confirmed using prespecified protocols. Fourth, our study represents analysis of a single drug, and it may be our findings do not extend beyond receptor tyrosine kinase inhibitors, or sunitinib. However, many of our findings are consistent with those observed in other systematic reviews of preclinical cancer interventions (<xref ref-type="bibr" rid="bib3">Amarasingh et al., 2009</xref>; <xref ref-type="bibr" rid="bib46">Sugar et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Hirst et al., 2013</xref>). Fifth, our analysis does not directly address many design elements—like duration of experiment or choice of tissue xenograft—that are likely to bear on study validity. Finally, we acknowledge that there may be funding constraints that limit implementation of validity practices described above. We note, nevertheless, that other realms, in particular, neurology, have found ways to make such methods a mainstay.</p><p>Numerous commentators have raised concerns about the design and reporting of preclinical cancer research (<xref ref-type="bibr" rid="bib46">Sugar et al., 2012</xref>; <xref ref-type="bibr" rid="bib8">Begley, 2013b</xref>). In one report, only 11% preclinical cancer studies submitted to a major biotechnology company withstood in-house replication (<xref ref-type="bibr" rid="bib5">Begley and Ellis, 2012</xref>). The Center for Open Science and Science Exchange has initiated a project that will attempt to reproduce 50 of the highest impact papers in cancer biology published between 2010 and 2012 (<xref ref-type="bibr" rid="bib35">Morrison, 2014</xref>). In a recent commentary, Smith et al. fault many researchers for performing in vitro preclinical tests using drug levels that are clinically unachievable due to toxicity (<xref ref-type="bibr" rid="bib45">Smith and Houghton, 2013</xref>). Unaddressed preclinical validity threats like this—and the ones documented in our study—encourage futile clinical development trajectories. Many research areas, like stroke, epilepsy, and cardiology, have devised design guidelines aimed at improving the clinical generalizability of preclinical studies (<xref ref-type="bibr" rid="bib17">Fisher et al., 2009</xref>; <xref ref-type="bibr" rid="bib18">Galanopoulou et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Curtis et al., 2013</xref>; <xref ref-type="bibr" rid="bib42">Pusztai et al., 2013</xref>); and the ARRIVE guidelines (<xref ref-type="bibr" rid="bib30">Kilkenny et al., 2010</xref>) for reporting animal experiments have been taken up by numerous journals and funding bodies. Our findings provide further impetus for developing and implementing guidelines for the design, reporting, and synthesis of preclinical studies in cancer.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Literature search</title><p>To identify all in vivo animal studies testing the anti-cancer properties of sunitinib (‘efficacy studies’), we queried the following databases on 27 February 2012 using a search strategy adapted from <xref ref-type="bibr" rid="bib25">Hooijmans et al. (2010)</xref> and <xref ref-type="bibr" rid="bib13">de Vries et al. (2011)</xref>: Ovid MEDLINE In-Process &amp; Other Non-Indexed Citations and Ovid MEDLINE (dates of coverage from 1948 to 2012), EMBASE Classic and EMBASE database (dates of coverage from 1974 to 2012) and BIOSIS Previews (dates of coverage from 1969 to 2012). Search results were entered into an EndNote library and duplicates were removed. Additional citations were identified during the screening of identified articles. See <xref ref-type="supplementary-material" rid="SD2-data">Table 1—source data 1C,D</xref> for detailed search strategy and PRISMA flow diagram.</p><p>Screening was performed at citation level by two reviewers (CF and VCH), and at full-text by one reviewer (VCH). Inclusion criteria were (a) original reports or abstracts, (b) English language, (c) contained at least one experiment measuring disease response in a live, non-human animals, and (d) employed sunitinib in a control, comparator, or experimental context, (e) tested anti-cancer activity. To avoid capturing the same experiment twice, in rare cases where the same experiment was reported in different articles, the most detailed and/or recent publication was included.</p></sec><sec id="s4-2"><title>Extraction</title><p>All included studies were evaluated at the study-level, but only those with eligible experiments (e.g., those evaluating the effect of monotherapy on tumor volume and that were reported with sample sizes and error measurements) were forwarded to experiment-level extractions. We excluded experiments when they had been reported in a previous publication after specifically searching for duplicates during screening and analysis. For each eligible experiment, we extracted experimental design elements derived from a prior systematic review of validity threats in preclinical research (<xref ref-type="bibr" rid="bib22">Henderson et al., 2013</xref>).</p><p>Details regarding the coding of internal and construct validity categories are given in <xref ref-type="supplementary-material" rid="SD1-data">Figure 1—source data 1A</xref>. To score for external validity, we created an index that summed the number of species and models tested for a given malignancy and awarded an extra point if more than one species <italic>and</italic> model was tested. For example, if experiments within a malignancy tested two species and three different model types, the external validity score would be 4 (1 point for the second species, one point for the second model type, one point for the third model type, and an extra point because more than one model and species were employed).</p><p>Our primary outcome was experimental tumor volume and we extracted necessary information (sample size, mean measure of treatment effect, and SDM/SEM) to enable calculation of study and aggregate level effect sizes. Since the units of tumor volume were not always consistent between experiments, we extracted those experiments for which a reasonable proxy of tumor volume could be obtained. These included physical caliper measurements (often reported in mm<sup>3</sup> or cm<sup>3</sup>), tumor weights (often reported in mg), optical measurements made from luminescent tumor cell lines (often reported in photons/second), and fold differences in tumor volumes between the control and treatment arms. We extracted experiments of both primary and metastatic tumors, but not experiments where tumor incidence was reported. To account for these different measures of tumor volume, SMDs were calculated using Hedges' g. Hedges' g is a widely accepted standardized measure of effect in meta-analyses where units are not always identical. For experiments where more than one dose of sunitinib was tested against the same control arm, we created a pooled SMD to adjust appropriately for the multiple use of the same control group. Data were extracted at baseline (Day 0 and defined as the first day of drug administration), Day 14 (the closest measured data point to 14 days following first dose), and the last common time point (LCT) between the control group and the treatment group. The LCT was variable between experiments and the last time point for which we could calculate SMD and often represented the point at which the greatest difference was observed between the arms. Data presented graphically were extracted using the graph digitizer software GraphClick (Arizona Software). Extraction was performed by four independent and trained coders (VCH, ND, AH, and NM) using DistillerSR. There was a 12% double-coding overlap to minimize inter-rater heterogeneity and prevent coder drift. Discrepancies in double coding were reconciled through discussion, and if necessary, by a third coder. The gross agreement rate before reconciliation for all double-coded studies was 83%.</p></sec><sec id="s4-3"><title>Meta-analysis</title><p>Effect sizes were calculated as SMDs using Hedges' g with 95% confidence intervals. Pooled effect sizes were calculated using a random effects model employing the <xref ref-type="bibr" rid="bib14">DerSimonian and Laird (1986)</xref> method, in OpenMeta[Analyst] (<xref ref-type="bibr" rid="bib51">Wallace et al., 2009</xref>). We also calculated heterogeneity within each malignancy using I<sup>2</sup> statistics (<xref ref-type="supplementary-material" rid="SD3-data">Figure 2—source data 1B</xref>). To assess the predictive value of preclinical studies in our sample, we calculated pooled effect sizes for each type of malignancy. Subgroup analyses were performed for each validity element. p-values were calculated by a two-sided independent group T-test. Statistical significance was set at a p-value &lt;0.05; as this was an exploratory study we did not adjust for multiple analyses.</p><p>Funnel plots to assess publication bias and Duval and Tweedie's trim and fill estimates were generated using Comprehensive Meta Analyst software (<xref ref-type="bibr" rid="bib15">Dietz et al., 2014</xref>). Funnel plots were created for all experiments in aggregate, and for the three indications for which greater than 20 experiments were analyzable.</p><p>Dose–response curves are a widely used tool for testing the strength of causal relationships (<xref ref-type="bibr" rid="bib23">Hill, 1965</xref>), and if preclinical studies indicate real drug-responses, we should be able to detect a dose–response effect across different experiments. Dose–response relationships were found in post-analysis of sunitinib clinical studies in metastatic RCC and Gastrointestinal stromal tumour (GIST) (<xref ref-type="bibr" rid="bib26">Houk et al., 2010</xref>). We tested for all indications in aggregate, as well as for RCC, an indication known to respond to sunitinib in human beings (<xref ref-type="bibr" rid="bib36">Motzer et al., 2006a</xref>, <xref ref-type="bibr" rid="bib37">2006b</xref>, <xref ref-type="bibr" rid="bib38">2009</xref>). To eliminate variation at the LCT between treatment and control arms, dose–response curves were created using data from a time point 14 days from the initiation of sunitinib treatment. Experiments with more than one treatment arm were not pooled as in other analyses, but expanded out so that each treatment arm (with it's respective dose) could be plotted properly. As we were unable to find experiments that reported drug exposure (e.g., drug serum levels), we calculated pooled effect sizes in OpenMeta[Analyst] and plotted against dose. To avoid the confounding effect of discontinuous dosing, we included only experiments that used a regular administration schedule without breaks (i.e., sunitinib administered at a defined dose once a day instead of experiments where sunitinib was dosed more irregularly or only once).</p><p>As this meta-analysis was exploratory and involved development of methodology, we did not prospectively register a protocol.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>Dan G Hackam, Jeremy Grimshaw, Malcolm Smith, Elham Sabri, Benjamin Carlisle.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>VCH, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con7"><p>JK, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>ND, Acquisition of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>AH, Acquisition of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con4"><p>NMK, Acquisition of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con5"><p>CAF, Acquisition of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con6"><p>DF, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anonymous</surname></name></person-group><year>2014</year><article-title>Budgets up at NIH, NCI, and FDA</article-title><source>Cancer Discovery</source><volume>4</volume><fpage>263</fpage><pub-id pub-id-type="doi">10.1158/2159-8290.CD-NB2014-016</pub-id></element-citation></ref><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrams</surname><given-names>TJ</given-names></name><name><surname>Murray</surname><given-names>LJ</given-names></name><name><surname>Pesenti</surname><given-names>E</given-names></name><name><surname>Holway</surname><given-names>VW</given-names></name><name><surname>Colombo</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>LB</given-names></name><name><surname>Cherrington</surname><given-names>JM</given-names></name><name><surname>Pryer</surname><given-names>NK</given-names></name></person-group><year>2003</year><article-title>Preclinical evaluation of the tyrosine kinase inhibitor SU11248 as a single agent and in combination with ‘standard of care’ therapeutic agents for the treatment of breast cancer</article-title><source>Molecular Cancer Therapeutics</source><volume>2</volume><fpage>1011</fpage><lpage>1021</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>CP</given-names></name><name><surname>Brantner</surname><given-names>VV</given-names></name></person-group><year>2006</year><article-title>Estimating the cost of new drug development: is it really 802 million dollars?</article-title><source>Health Affairs</source><volume>25</volume><fpage>420</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1377/hlthaff.25.2.420</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amarasingh</surname><given-names>S</given-names></name><name><surname>Macleod</surname><given-names>MR</given-names></name><name><surname>Whittle</surname><given-names>IR</given-names></name></person-group><year>2009</year><article-title>What is the translational efficacy of chemotherapeutic drug research in neuro-oncology? A systematic review and meta-analysis of the efficacy of BCNU and CCNU in animal models of glioma</article-title><source>Journal of Neuro-Oncology</source><volume>91</volume><fpage>117</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1007/s11060-008-9697-z</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amino</surname><given-names>N</given-names></name><name><surname>Ideyama</surname><given-names>Y</given-names></name><name><surname>Yamano</surname><given-names>M</given-names></name><name><surname>Kuromitsu</surname><given-names>S</given-names></name><name><surname>Tajinda</surname><given-names>K</given-names></name><name><surname>Samizu</surname><given-names>K</given-names></name><name><surname>Hisamichi</surname><given-names>H</given-names></name><name><surname>Matsuhisa</surname><given-names>A</given-names></name><name><surname>Shirasuna</surname><given-names>K</given-names></name><name><surname>Kudoh</surname><given-names>M</given-names></name><name><surname>Shibasaki</surname><given-names>M</given-names></name></person-group><year>2006</year><article-title>YM-359445, an orally bioavailable vascular endothelial growth factor receptor-2 tyrosine kinase inhibitor, has highly potent antitumor activity against established tumors</article-title><source>Clinical Cancer Research</source><volume>12</volume><fpage>1630</fpage><lpage>1638</lpage><pub-id pub-id-type="doi">10.1158/1078-0432.CCR-05-2028</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begley</surname><given-names>CG</given-names></name></person-group><year>2013a</year><article-title>Six red flags for suspect work</article-title><source>Nature</source><volume>497</volume><fpage>433</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1038/497433a</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begley</surname><given-names>CG</given-names></name></person-group><year>2013b</year><article-title>An unappreciated challenge to oncology drug discovery: pitfalls in preclinical research</article-title><source>American Society of Clinical Oncology Educational Book</source><volume>2013</volume><fpage>466</fpage><lpage>468</lpage><pub-id pub-id-type="doi">10.1200/EdBook_AM.2013.33.466</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begley</surname><given-names>CG</given-names></name><name><surname>Ellis</surname><given-names>LM</given-names></name></person-group><year>2012</year><article-title>Drug development: raise standards for preclinical cancer research</article-title><source>Nature</source><volume>483</volume><fpage>531</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/483531a</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begley</surname><given-names>CG</given-names></name><name><surname>Ioannidis</surname><given-names>JP</given-names></name></person-group><year>2015</year><article-title>Reproducibility in science: improving the standard for basic and preclinical research</article-title><source>Circulation Research</source><volume>116</volume><fpage>116</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1161/CIRCRESAHA.114.303819</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chow</surname><given-names>LQ</given-names></name><name><surname>Eckhardt</surname><given-names>SG</given-names></name></person-group><year>2007</year><article-title>Sunitinib: from rational design to clinical efficacy</article-title><source>Journal of Clinical Oncology</source><volume>25</volume><fpage>884</fpage><lpage>896</lpage><pub-id pub-id-type="doi">10.1200/JCO.2006.06.3602</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corpet</surname><given-names>DE</given-names></name><name><surname>Pierre</surname><given-names>F</given-names></name></person-group><year>2005</year><article-title>How good are rodent models of carcinogenesis in predicting efficacy in humans? A systematic review and meta-analysis of colon chemoprevention in rats, mice and men</article-title><source>European Journal of Cancer</source><volume>41</volume><fpage>1911</fpage><lpage>1922</lpage><pub-id pub-id-type="doi">10.1016/j.ejca.2005.06.006</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crossley</surname><given-names>NA</given-names></name><name><surname>Sena</surname><given-names>E</given-names></name><name><surname>Goehler</surname><given-names>J</given-names></name><name><surname>Horn</surname><given-names>J</given-names></name><name><surname>van der Worp</surname><given-names>B</given-names></name><name><surname>Bath</surname><given-names>PM</given-names></name><name><surname>Macleod</surname><given-names>M</given-names></name><name><surname>Dirnagl</surname><given-names>U</given-names></name></person-group><year>2008</year><article-title>Empirical evidence of bias in the design of experimental stroke studies: a metaepidemiologic approach</article-title><source>Stroke</source><volume>39</volume><fpage>929</fpage><lpage>934</lpage><pub-id pub-id-type="doi">10.1161/STROKEAHA.107.498725</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curtis</surname><given-names>MJ</given-names></name><name><surname>Hancox</surname><given-names>JC</given-names></name><name><surname>Farkas</surname><given-names>A</given-names></name><name><surname>Wainwright</surname><given-names>CL</given-names></name><name><surname>Stables</surname><given-names>CL</given-names></name><name><surname>Saint</surname><given-names>DA</given-names></name><name><surname>Clements-Jewery</surname><given-names>H</given-names></name><name><surname>Lambiase</surname><given-names>PD</given-names></name><name><surname>Billman</surname><given-names>GE</given-names></name><name><surname>Janse</surname><given-names>MJ</given-names></name><name><surname>Pugsley</surname><given-names>MK</given-names></name><name><surname>Ng</surname><given-names>GA</given-names></name><name><surname>Roden</surname><given-names>DM</given-names></name><name><surname>Camm</surname><given-names>AJ</given-names></name><name><surname>Walker</surname><given-names>MJ</given-names></name></person-group><year>2013</year><article-title>The Lambeth Conventions (II): guidelines for the study of animal and human ventricular and supraventricular arrhythmias</article-title><source>Pharmacology &amp; Therapeutics</source><volume>139</volume><fpage>213</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/j.pharmthera.2013.04.008</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vries</surname><given-names>RB</given-names></name><name><surname>Hooijmans</surname><given-names>CR</given-names></name><name><surname>Tillema</surname><given-names>A</given-names></name><name><surname>Leenaars</surname><given-names>M</given-names></name><name><surname>Ritskes-Hoitinga</surname><given-names>M</given-names></name></person-group><year>2011</year><article-title>A search filter for increasing the retrieval of animal studies in Embase</article-title><source>Laboratory Animals</source><volume>45</volume><fpage>268</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1258/la.2011.011056</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DerSimonian</surname><given-names>R</given-names></name><name><surname>Laird</surname><given-names>N</given-names></name></person-group><year>1986</year><article-title>Meta-analysis in clinical trials</article-title><source>Contemporary Clinical Trials</source><volume>7</volume><fpage>177</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1016/0197-2456(86)90046-2</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dietz</surname><given-names>G</given-names></name><name><surname>Dahabreh</surname><given-names>IJ</given-names></name><name><surname>Gurevitch</surname><given-names>J</given-names></name><name><surname>Lajeunesse</surname><given-names>MJ</given-names></name><name><surname>Schmid</surname><given-names>CH</given-names></name><name><surname>Trikalinos</surname><given-names>TA</given-names></name><name><surname>Wallace</surname><given-names>BC</given-names></name></person-group><year>2014</year><source>OpenMEE: software for ecological and evolutionary meta-analysis</source></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faivre</surname><given-names>S</given-names></name><name><surname>Delbaldo</surname><given-names>C</given-names></name><name><surname>Vera</surname><given-names>K</given-names></name><name><surname>Robert</surname><given-names>C</given-names></name><name><surname>Lozahic</surname><given-names>S</given-names></name><name><surname>Lassau</surname><given-names>N</given-names></name><name><surname>Bello</surname><given-names>C</given-names></name><name><surname>Deprimo</surname><given-names>S</given-names></name><name><surname>Brega</surname><given-names>N</given-names></name><name><surname>Massimini</surname><given-names>G</given-names></name><name><surname>Armand</surname><given-names>JP</given-names></name><name><surname>Scigalla</surname><given-names>P</given-names></name><name><surname>Raymond</surname><given-names>E</given-names></name></person-group><year>2006</year><article-title>Safety, pharmacokinetic, and antitumor activity of SU11248, a novel oral multitarget tyrosine kinase inhibitor, in patients with cancer</article-title><source>Journal of Clinical Oncology</source><volume>24</volume><fpage>25</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1200/JCO.2005.02.2194</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>M</given-names></name><name><surname>Feuerstein</surname><given-names>G</given-names></name><name><surname>Howells</surname><given-names>DW</given-names></name><name><surname>Hurn</surname><given-names>PD</given-names></name><name><surname>Kent</surname><given-names>TA</given-names></name><name><surname>Savitz</surname><given-names>SI</given-names></name><name><surname>Lo</surname><given-names>EH</given-names></name><collab>STAIR Group</collab></person-group><year>2009</year><article-title>Update of the stroke therapy academic industry roundtable preclinical recommendations</article-title><source>Stroke</source><volume>40</volume><fpage>2244</fpage><lpage>2250</lpage><pub-id pub-id-type="doi">10.1161/STROKEAHA.108.541128</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galanopoulou</surname><given-names>AS</given-names></name><name><surname>Buckmaster</surname><given-names>PS</given-names></name><name><surname>Staley</surname><given-names>KJ</given-names></name><name><surname>Moshé</surname><given-names>SL</given-names></name><name><surname>Perucca</surname><given-names>E</given-names></name><name><surname>Engel</surname><given-names>J</given-names><suffix>Jr</suffix></name><name><surname>Löscher</surname><given-names>W</given-names></name><name><surname>Noebels</surname><given-names>JL</given-names></name><name><surname>Pitkänen</surname><given-names>A</given-names></name><name><surname>Stables</surname><given-names>J</given-names></name><name><surname>White</surname><given-names>HS</given-names></name><name><surname>O'Brien</surname><given-names>TJ</given-names></name><name><surname>Simonato</surname><given-names>M</given-names></name><collab>American Epilepsy Society Basic Science Committee And The International League Against Epilepsy Working Group On Recommendations For Preclinical Epilepsy Drug Discovery</collab></person-group><year>2012</year><article-title>Identification of new epilepsy treatments: issues in preclinical methodology</article-title><source>Epilepsia</source><volume>53</volume><fpage>571</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1111/j.1528-1167.2011.03391.x</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasziou</surname><given-names>P</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Bossuyt</surname><given-names>P</given-names></name><name><surname>Boutron</surname><given-names>I</given-names></name><name><surname>Clarke</surname><given-names>M</given-names></name><name><surname>Julious</surname><given-names>S</given-names></name><name><surname>Michie</surname><given-names>S</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Wager</surname><given-names>E</given-names></name></person-group><year>2014</year><article-title>Reducing waste from incomplete or unusable reports of biomedical research</article-title><source>Lancet</source><volume>383</volume><fpage>267</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/S0140-6736(13)62228-X</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>JY</given-names></name><name><surname>Kim</surname><given-names>HY</given-names></name><name><surname>Lim</surname><given-names>KY</given-names></name><name><surname>Han</surname><given-names>JH</given-names></name><name><surname>Lee</surname><given-names>YJ</given-names></name><name><surname>Kwak</surname><given-names>MH</given-names></name><name><surname>Kim</surname><given-names>HJ</given-names></name><name><surname>Yun</surname><given-names>T</given-names></name><name><surname>Kim</surname><given-names>HT</given-names></name><name><surname>Lee</surname><given-names>JS</given-names></name></person-group><year>2013</year><article-title>A phase II study of sunitinib in patients with relapsed or refractory small cell lung cancer</article-title><source>Lung Cancer</source><volume>79</volume><fpage>137</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.lungcan.2012.09.019</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hay</surname><given-names>M</given-names></name><name><surname>Thomas</surname><given-names>DW</given-names></name><name><surname>Craighead</surname><given-names>JL</given-names></name><name><surname>Economides</surname><given-names>C</given-names></name><name><surname>Rosenthal</surname><given-names>J</given-names></name></person-group><year>2014</year><article-title>Clinical development success rates for investigational drugs</article-title><source>Nature Biotechnology</source><volume>32</volume><fpage>40</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1038/nbt.2786</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>VC</given-names></name><name><surname>Kimmelman</surname><given-names>J</given-names></name><name><surname>Fergusson</surname><given-names>D</given-names></name><name><surname>Grimshaw</surname><given-names>JM</given-names></name><name><surname>Hackam</surname><given-names>DG</given-names></name></person-group><year>2013</year><article-title>Threats to validity in the design and conduct of preclinical efficacy studies: a systematic review of guidelines for in vivo animal experiments</article-title><source>PLOS Medicine</source><volume>10</volume><fpage>e1001489</fpage><pub-id pub-id-type="doi">10.1371/journal.pmed.1001489</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>AB</given-names></name></person-group><year>1965</year><article-title>The environment and disease: association or causation?</article-title><source>Proceedings of the Royal Society of Medicine</source><volume>58</volume><fpage>295</fpage><lpage>300</lpage></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirst</surname><given-names>TC</given-names></name><name><surname>Vesterinen</surname><given-names>HM</given-names></name><name><surname>Sena</surname><given-names>ES</given-names></name><name><surname>Egan</surname><given-names>KJ</given-names></name><name><surname>Macleod</surname><given-names>MR</given-names></name><name><surname>Whittle</surname><given-names>IR</given-names></name></person-group><year>2013</year><article-title>Systematic review and meta-analysis of temozolomide in animal models of glioma: was clinical efficacy predicted?</article-title><source>British Journal of Cancer</source><volume>108</volume><fpage>64</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1038/bjc.2012.504</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hooijmans</surname><given-names>CR</given-names></name><name><surname>Tillema</surname><given-names>A</given-names></name><name><surname>Leenaars</surname><given-names>M</given-names></name><name><surname>Ritskes-Hoitinga</surname><given-names>M</given-names></name></person-group><year>2010</year><article-title>Enhancing search efficiency by means of a search filter for finding all studies on animal experimentation in PubMed</article-title><source>Laboratory Animals</source><volume>44</volume><fpage>170</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1258/la.2010.009117</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houk</surname><given-names>BE</given-names></name><name><surname>Bello</surname><given-names>CL</given-names></name><name><surname>Poland</surname><given-names>B</given-names></name><name><surname>Rosen</surname><given-names>LS</given-names></name><name><surname>Demetri</surname><given-names>GD</given-names></name><name><surname>Motzer</surname><given-names>RJ</given-names></name></person-group><year>2010</year><article-title>Relationship between exposure to sunitinib and efficacy and tolerability endpoints in patients with cancer: results of a pharmacokinetic/pharmacodynamic meta-analysis</article-title><source>Cancer Chemotherapy and Pharmacology</source><volume>66</volume><fpage>357</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1007/s00280-009-1170-y</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>JI</given-names></name><name><surname>Decker</surname><given-names>S</given-names></name><name><surname>Zaharevitz</surname><given-names>D</given-names></name><name><surname>Rubinstein</surname><given-names>LV</given-names></name><name><surname>Venditti</surname><given-names>JM</given-names></name><name><surname>Schepartz</surname><given-names>S</given-names></name><name><surname>Kalyandrug</surname><given-names>S</given-names></name><name><surname>Christian</surname><given-names>M</given-names></name><name><surname>Arbuck</surname><given-names>S</given-names></name><name><surname>Hollingshead</surname><given-names>M</given-names></name><name><surname>Sausville</surname><given-names>EA</given-names></name></person-group><year>2001</year><article-title>Relationships between drug activity in NCI preclinical in vitro and in vivo models and early clinical trials</article-title><source>British Journal of Cancer</source><volume>84</volume><fpage>1424</fpage><lpage>1431</lpage><pub-id pub-id-type="doi">10.1054/bjoc.2001.1796</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerbel</surname><given-names>RS</given-names></name></person-group><year>2003</year><article-title>Human tumor xenografts as predictive preclinical models for anticancer drug activity in humans: better than commonly perceived-but they can be improved</article-title><source>Cancer Biology &amp; Therapy</source><volume>2</volume><supplement>(4 Suppl 1)</supplement><fpage>S134</fpage><lpage>S139</lpage></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kilkenny</surname><given-names>C</given-names></name><name><surname>Browne</surname><given-names>WJ</given-names></name><name><surname>Cuthill</surname><given-names>IC</given-names></name><name><surname>Emerson</surname><given-names>M</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><year>2010</year><article-title>Improving bioscience research reporting: the ARRIVE guidelines for reporting animal research</article-title><source>PLOS Biology</source><volume>8</volume><fpage>e1000412</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.1000412</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kilkenny</surname><given-names>C</given-names></name><name><surname>Parsons</surname><given-names>N</given-names></name><name><surname>Kadyszewski</surname><given-names>E</given-names></name><name><surname>Festing</surname><given-names>MF</given-names></name><name><surname>Cuthill</surname><given-names>IC</given-names></name><name><surname>Fry</surname><given-names>D</given-names></name><name><surname>Hutton</surname><given-names>J</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><year>2009</year><article-title>Survey of the quality of experimental design, statistical analysis and reporting of research using animals</article-title><source>PLOS ONE</source><volume>4</volume><fpage>e7824</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0007824</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ko</surname><given-names>JS</given-names></name><name><surname>Rayman</surname><given-names>P</given-names></name><name><surname>Ireland</surname><given-names>J</given-names></name><name><surname>Swaidani</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>G</given-names></name><name><surname>Bunting</surname><given-names>KD</given-names></name><name><surname>Rini</surname><given-names>B</given-names></name><name><surname>Finke</surname><given-names>JH</given-names></name><name><surname>Cohen</surname><given-names>PA</given-names></name></person-group><year>2010</year><article-title>Direct and differential suppression of myeloid-derived suppressor cell subsets by sunitinib is compartmentally constrained</article-title><source>Cancer Research</source><volume>70</volume><fpage>3526</fpage><lpage>3536</lpage><pub-id pub-id-type="doi">10.1158/0008-5472.CAN-09-3278</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>J</given-names></name><name><surname>Ioannidis</surname><given-names>JP</given-names></name><name><surname>Terrin</surname><given-names>N</given-names></name><name><surname>Schmid</surname><given-names>CH</given-names></name><name><surname>Olkin</surname><given-names>I</given-names></name></person-group><year>2006</year><article-title>The case of the misleading funnel plot</article-title><source>BMJ</source><volume>333</volume><fpage>597</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1136/bmj.333.7568.597</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macleod</surname><given-names>MR</given-names></name><name><surname>O'Collins</surname><given-names>T</given-names></name><name><surname>Howells</surname><given-names>DW</given-names></name><name><surname>Donnan</surname><given-names>GA</given-names></name></person-group><year>2004</year><article-title>Pooling of animal experimental data reveals influence of study design and publication bias</article-title><source>Stroke</source><volume>35</volume><fpage>1203</fpage><lpage>1208</lpage><pub-id pub-id-type="doi">10.1161/01.STR.0000125719.25853.20</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>JM</given-names></name><name><surname>Courtright</surname><given-names>J</given-names></name><name><surname>Houghton</surname><given-names>PJ</given-names></name><name><surname>Morton</surname><given-names>CL</given-names></name><name><surname>Kolb</surname><given-names>EA</given-names></name><name><surname>Lock</surname><given-names>R</given-names></name><name><surname>Tajbakhsh</surname><given-names>M</given-names></name><name><surname>Reynolds</surname><given-names>CP</given-names></name><name><surname>Keir</surname><given-names>ST</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name></person-group><year>2008</year><article-title>Initial testing (stage 1) of sunitinib by the pediatric preclinical testing program</article-title><source>Pediatric Blood &amp; Cancer</source><volume>51</volume><fpage>42</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1002/pbc.21535</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname><given-names>SJ</given-names></name></person-group><year>2014</year><article-title>Time to do something about reproducibility</article-title><source>eLife</source><volume>3</volume><fpage>e03981</fpage><pub-id pub-id-type="doi">10.7554/eLife.03981</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motzer</surname><given-names>RJ</given-names></name><name><surname>Hutson</surname><given-names>TE</given-names></name><name><surname>Tomczak</surname><given-names>P</given-names></name><name><surname>Michaelson</surname><given-names>MD</given-names></name><name><surname>Bukowski</surname><given-names>RM</given-names></name><name><surname>Oudard</surname><given-names>S</given-names></name><name><surname>Negrier</surname><given-names>S</given-names></name><name><surname>Szczylik</surname><given-names>C</given-names></name><name><surname>Pili</surname><given-names>R</given-names></name><name><surname>Bjarnason</surname><given-names>GA</given-names></name><name><surname>Garcia-del-Muro</surname><given-names>X</given-names></name><name><surname>Sosman</surname><given-names>JA</given-names></name><name><surname>Solska</surname><given-names>E</given-names></name><name><surname>Wilding</surname><given-names>G</given-names></name><name><surname>Thompson</surname><given-names>JA</given-names></name><name><surname>Kim</surname><given-names>ST</given-names></name><name><surname>Chen</surname><given-names>I</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Figlin</surname><given-names>RA</given-names></name></person-group><year>2009</year><article-title>Overall survival and updated results for sunitinib compared with interferon alfa in patients with metastatic renal cell carcinoma</article-title><source>Journal of Clinical Oncology</source><volume>27</volume><fpage>3584</fpage><lpage>3590</lpage><pub-id pub-id-type="doi">10.1200/JCO.2008.20.1293</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motzer</surname><given-names>RJ</given-names></name><name><surname>Michaelson</surname><given-names>MD</given-names></name><name><surname>Redman</surname><given-names>BG</given-names></name><name><surname>Hudes</surname><given-names>GR</given-names></name><name><surname>Wilding</surname><given-names>G</given-names></name><name><surname>Figlin</surname><given-names>RA</given-names></name><name><surname>Ginsberg</surname><given-names>MS</given-names></name><name><surname>Kim</surname><given-names>ST</given-names></name><name><surname>Baum</surname><given-names>CM</given-names></name><name><surname>DePrimo</surname><given-names>SE</given-names></name><name><surname>Li</surname><given-names>JZ</given-names></name><name><surname>Bello</surname><given-names>CL</given-names></name><name><surname>Theuer</surname><given-names>CP</given-names></name><name><surname>George</surname><given-names>DJ</given-names></name><name><surname>Rini</surname><given-names>BI</given-names></name></person-group><year>2006a</year><article-title>Activity of SU11248, a multitargeted inhibitor of vascular endothelial growth factor receptor and platelet-derived growth factor receptor, in patients with metastatic renal cell carcinoma</article-title><source>Journal of Clinical Oncology</source><volume>24</volume><fpage>16</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1200/JCO.2005.02.2574</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motzer</surname><given-names>RJ</given-names></name><name><surname>Rini</surname><given-names>BI</given-names></name><name><surname>Bukowski</surname><given-names>RM</given-names></name><name><surname>Curti</surname><given-names>BD</given-names></name><name><surname>George</surname><given-names>DJ</given-names></name><name><surname>Hudes</surname><given-names>GR</given-names></name><name><surname>Redman</surname><given-names>BG</given-names></name><name><surname>Margolin</surname><given-names>KA</given-names></name><name><surname>Merchan</surname><given-names>JR</given-names></name><name><surname>Wilding</surname><given-names>G</given-names></name><name><surname>Ginsberg</surname><given-names>MS</given-names></name><name><surname>Bacik</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>ST</given-names></name><name><surname>Baum</surname><given-names>CM</given-names></name><name><surname>Michaelson</surname><given-names>MD</given-names></name></person-group><year>2006b</year><article-title>Sunitinib in patients with metastatic renal cell carcinoma</article-title><source>JAMA</source><volume>295</volume><fpage>2516</fpage><lpage>2524</lpage><pub-id pub-id-type="doi">10.1001/jama.295.21.2516</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Collins</surname><given-names>VE</given-names></name><name><surname>Macleod</surname><given-names>MR</given-names></name><name><surname>Donnan</surname><given-names>GA</given-names></name><name><surname>Horky</surname><given-names>LL</given-names></name><name><surname>van der Worp</surname><given-names>BH</given-names></name><name><surname>Howells</surname><given-names>DW</given-names></name></person-group><year>2006</year><article-title>1,026 experimental treatments in acute stroke</article-title><source>Annals of Neurology</source><volume>59</volume><fpage>467</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1002/ana.20741</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>JK</given-names></name><name><surname>Houghton</surname><given-names>PJ</given-names></name></person-group><year>2004</year><article-title>Integrating pharmacology and in vivo cancer models in preclinical and clinical drug development</article-title><source>European Journal of Cancer</source><volume>40</volume><fpage>837</fpage><lpage>844</lpage><pub-id pub-id-type="doi">10.1016/j.ejca.2004.01.003</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pusztai</surname><given-names>L</given-names></name><name><surname>Hatzis</surname><given-names>C</given-names></name><name><surname>Andre</surname><given-names>F</given-names></name></person-group><year>2013</year><article-title>Reproducibility of research and preclinical validation: problems and solutions</article-title><source>Nature Reviews Clinical Oncology</source><volume>10</volume><fpage>720</fpage><lpage>724</lpage><pub-id pub-id-type="doi">10.1038/nrclinonc.2013.171</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raymond</surname><given-names>E</given-names></name><name><surname>Dahan</surname><given-names>L</given-names></name><name><surname>Raoul</surname><given-names>JL</given-names></name><name><surname>Bang</surname><given-names>YJ</given-names></name><name><surname>Borbath</surname><given-names>I</given-names></name><name><surname>Lombard-Bohas</surname><given-names>C</given-names></name><name><surname>Valle</surname><given-names>J</given-names></name><name><surname>Metrakos</surname><given-names>P</given-names></name><name><surname>Smith</surname><given-names>D</given-names></name><name><surname>Vinik</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>JS</given-names></name><name><surname>Hörsch</surname><given-names>D</given-names></name><name><surname>Hammel</surname><given-names>P</given-names></name><name><surname>Wiedenmann</surname><given-names>B</given-names></name><name><surname>Van Cutsem</surname><given-names>E</given-names></name><name><surname>Patyna</surname><given-names>S</given-names></name><name><surname>Lu</surname><given-names>DR</given-names></name><name><surname>Blanckmeister</surname><given-names>C</given-names></name><name><surname>Chao</surname><given-names>R</given-names></name><name><surname>Ruszniewski</surname><given-names>P</given-names></name></person-group><year>2011</year><article-title>Sunitinib malate for the treatment of pancreatic neuroendocrine tumors</article-title><source>The New England Journal of Medicine</source><volume>364</volume><fpage>501</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1056/NEJMoa1003825</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rooke</surname><given-names>ED</given-names></name><name><surname>Vesterinen</surname><given-names>HM</given-names></name><name><surname>Sena</surname><given-names>ES</given-names></name><name><surname>Egan</surname><given-names>KJ</given-names></name><name><surname>Macleod</surname><given-names>MR</given-names></name></person-group><year>2011</year><article-title>Dopamine agonists in animal models of Parkinson's disease: a systematic review and meta-analysis</article-title><source>Parkinsonism &amp; Related Disorders</source><volume>17</volume><fpage>313</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1016/j.parkreldis.2011.02.010</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Houghton</surname><given-names>P</given-names></name></person-group><year>2013</year><article-title>A proposal regarding reporting of in vitro testing results</article-title><source>Clinical Cancer Research</source><volume>19</volume><fpage>2828</fpage><lpage>2833</lpage><pub-id pub-id-type="doi">10.1158/1078-0432.CCR-13-0043</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugar</surname><given-names>E</given-names></name><name><surname>Pascoe</surname><given-names>AJ</given-names></name><name><surname>Azad</surname><given-names>N</given-names></name></person-group><year>2012</year><article-title>Reporting of preclinical tumor-graft cancer therapeutic studies</article-title><source>Cancer Biology &amp; Therapy</source><volume>13</volume><fpage>1262</fpage><lpage>1268</lpage><pub-id pub-id-type="doi">10.4161/cbt.21782</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsilidis</surname><given-names>KK</given-names></name><name><surname>Panagiotou</surname><given-names>OA</given-names></name><name><surname>Sena</surname><given-names>ES</given-names></name><name><surname>Aretouli</surname><given-names>E</given-names></name><name><surname>Evangelou</surname><given-names>E</given-names></name><name><surname>Howells</surname><given-names>DW</given-names></name><name><surname>Al-Shahi Salman</surname><given-names>R</given-names></name><name><surname>Macleod</surname><given-names>MR</given-names></name><name><surname>Ioannidis</surname><given-names>JP</given-names></name></person-group><year>2013</year><article-title>Evaluation of excess significance bias in animal studies of neurological diseases</article-title><source>PLOS Biology</source><volume>11</volume><fpage>e1001609</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.1001609</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Worp</surname><given-names>HB</given-names></name><name><surname>de Haan</surname><given-names>P</given-names></name><name><surname>Morrema</surname><given-names>E</given-names></name><name><surname>Kalkman</surname><given-names>CJ</given-names></name></person-group><year>2005</year><article-title>Methodological quality of animal studies on neuroprotection in focal cerebral ischaemia</article-title><source>Journal of Neurology</source><volume>252</volume><fpage>1108</fpage><lpage>1114</lpage><pub-id pub-id-type="doi">10.1007/s00415-005-0802-3</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Worp</surname><given-names>HB</given-names></name><name><surname>Howells</surname><given-names>DW</given-names></name><name><surname>Sena</surname><given-names>ES</given-names></name><name><surname>Porritt</surname><given-names>MJ</given-names></name><name><surname>Rewell</surname><given-names>S</given-names></name><name><surname>O'Collins</surname><given-names>V</given-names></name><name><surname>Macleod</surname><given-names>MR</given-names></name></person-group><year>2010</year><article-title>Can animal models of disease reliably inform human studies?</article-title><source>PLOS Medicine</source><volume>7</volume><fpage>e1000245</fpage><pub-id pub-id-type="doi">10.1371/journal.pmed.1000245</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voskoglou-Nomikos</surname><given-names>T</given-names></name><name><surname>Pater</surname><given-names>JL</given-names></name><name><surname>Seymour</surname><given-names>L</given-names></name></person-group><year>2003</year><article-title>Clinical predictive value of the in vitro cell line, human xenograft, and mouse allograft preclinical cancer models</article-title><source>Clinical Cancer Research</source><volume>9</volume><fpage>4227</fpage><lpage>4239</lpage></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallace</surname><given-names>BC</given-names></name><name><surname>Schmid</surname><given-names>CH</given-names></name><name><surname>Lau</surname><given-names>J</given-names></name><name><surname>Trikalinos</surname><given-names>TA</given-names></name></person-group><year>2009</year><article-title>Meta-analyst: software for meta-analysis of binary, continuous and diagnostic data</article-title><source>BMC Medical Research Methodology</source><volume>9</volume><fpage>80</fpage><pub-id pub-id-type="doi">10.1186/1471-2288-9-80</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.08351.014</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Teare</surname><given-names>M Dawn</given-names></name><role>Reviewing editor</role><aff><institution>University of Sheffield</institution>, <country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for submitting your work entitled “A Meta-Analysis of Validity Threats and Clinical Correlates in Preclinical Research of Sunitinib” for peer review at <italic>eLife</italic>. Your submission has been favorably evaluated by Prabhat Jha (Senior Editor) and three reviewers, one of whom, Dawn Teare, is a member of our Board of Reviewing Editors. The other two reviewers, Carlijn Hooijmans and Glenn Begley, have agreed to share their identity.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The authors describe a meta-analysis of preclinical studies performed with sunitinib. Their analysis found poor scientific methodology with for example lack of blinding, lack of evidence of power calculations and likely bias in over-reporting of positive results. It provides objective evidence to support claims that have been made by others. This is an important and valuable contribution. It addresses an issue of increasing scientific and societal importance.</p><p>Essential revisions:</p><p>1) The dose response analysis needs revision. The systematic review has collected the data from animal research but I cannot see where the clinical outcome data comes from. In fact I do not see any clinical data. Is the assumption that the clinical data does show a dose response? I find the lack of a dose response rather curious in that presumably individual studies did report an effect but somehow there is heterogeneity between the studies and hence this reduces to a random scatter? There appear to be a lot of points in <xref ref-type="fig" rid="fig5">Figure 5A</xref> but I cannot easily see how many studies were eligible for the dose-response. I also do not understand the statistical analysis going along with <xref ref-type="fig" rid="fig5">Figure 5</xref>. What sort of curve/line is being fitted? What role does the two-group <italic>t</italic>-test have in a dose response analysis? The line drawn on the figure appears to be a straight line. I think this section needs to be more clearly written.</p><p>2) It would be very helpful for the authors to comment on the number of studies that reported drug exposure rather than drug dose. It is common for preclinical studies to report the intended drug dose, but without reference to the actual levels of drug attained. Assessment of drug levels confirms (i) that drug was actually administered and (ii) to the intended cohort. Moreover, it is frequently the case that when levels rather than dose are examined, it is evident that the levels achieved in rodents are not tolerated in humans. This has specifically been recognized for sunitinib and is an additional explanation for the disconnection between preclinical versus clinical effectiveness.</p><p>3) It would also be helpful if the authors could comment on the number of studies that included a positive control. While sunitinib may have had activity, without a positive control it is difficult to place that activity into context. Was the efficacy comparable or greater than that seen with another known active agent?</p><p>4) It would be beneficial to understand how many of the studies used an appropriate statistical test when analyzing their data.</p><p>5) The authors did not comment on the ARRIVE Guidelines for pharmacology studies. These should be discussed (cited in Begley and Ioannidis., Reproducibility in Science. Improving the Standard for Basic and Preclinical Research., Circulation Research., 2015; 116: 116-126.)</p><p>6) The authors should check that their references are correctly cited. For example, the statement (in the Introduction) “A recent systematic review of guidelines for limiting bias in preclinical research design was unable to identify any guidelines in oncology (<xref ref-type="bibr" rid="bib20">Han et al., 2013</xref>)” is not supported by <xref ref-type="bibr" rid="bib20">Han et al., 2013</xref>.</p><p>7) The observation that “Our findings suggest that testing in more models tends to produce smaller effect sizes” has also been made previously (cited in <xref ref-type="bibr" rid="bib6">Begley and Ioannidis, 2015</xref>).</p><p>8) Why did the authors of this review decide a) to include only papers published in English b) not to retrieve data via contacting the authors of the original papers? The authors conclude that there is a substantial risk on publication bias. But it might be possible that the observed risk on publication bias could have been much smaller when the authors contacted the authors for missing data and included also papers published in languages other than English.</p><p>9) In this review, the outcome measure of interest needs a more detailed description in the Material and methods section. In the subsection “Extraction,” the authors state that they are only interested in tumor volume (“[…] those evaluating the effect of monotherapy on tumor volume”), whereas the Abstract and Introduction talk about tumor growth (which is a much broader term). Did the authors only assess tumor volume of primary tumors? Or did they include the volumes of metastases in the body as well? Did the authors include studies in which the weight of tumors and metastases were assessed? And what about tumor incidence? The authors also state: “[…] To account for different measures of tumor growth”; which measures of tumor growth did they include?</p><p>10) More details are needed in the Materials and methods concerning the meta analyses:</p><p>a) Are data pooled in case tumor volume was determined in various regions of the body within one experiment?</p><p>Are the data pooled in the overall analyses (<xref ref-type="fig" rid="fig3">Figure 3</xref>) when results were assessed at various time points?</p><p>b) In animal studies the same control group is often used for multiple experimental. Did the authors correct for multiple use of the control groups?</p><p>c) What was the minimum group size to allow subgroup analyses?</p><p>11) The authors should report group sizes of all subgroups (also in figures; e.g. <xref ref-type="fig" rid="fig3">Figure 3</xref>), and take group size into account when interpreting the results.</p><p>12) The authors should report heterogeneity statistics (for example I<sup>2</sup>), and take these results into account when interpreting the data.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.08351.015</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions</italic>:</p><p><italic>1) The dose response analysis needs revision. The systematic review has collected the data from animal research but I cannot see where the clinical outcome data comes from. In fact I do not see any clinical data. Is the assumption that the clinical data does show a dose response? I find the lack of a dose response rather curious in that presumably individual studies did report an effect but somehow there is heterogeneity between the studies and hence this reduces to a random scatter? There appear to be a lot of points in</italic> <xref ref-type="fig" rid="fig5"><italic>Figure 5A</italic></xref> <italic>but I cannot easily see how many studies were eligible for the dose-response. I also do not understand the statistical analysis going along with</italic> <xref ref-type="fig" rid="fig5"><italic>Figure 5</italic></xref><italic>. What sort of curve/line is being fitted? What role does the two-group</italic> t<italic>-test have in a dose response analysis? The line drawn on the figure appears to be a straight line. I think this section needs to be more clearly written</italic>.</p><p>Dose response is discussed twice in the manuscript. First it appears when we report the fraction of studies that tested a dose response. Here, our emphasis is on dose response testing as a means of enhancing the internal validity of claims regarding clinical promise. The second mention is at the end of our Results section. There, the dose-response analysis was not meant to compare our preclinical results directly with sunitinib clinical data (although a dose-response relationship in GIST and mRCC has been demonstrated by others – see below). Our premise was that preclinical studies should demonstrate a dose-response relationship in the absence of overwhelming inter-experimental heterogeneity and publication bias. This premise was based on the known dose response in human beings, and the fact that dose-response was shown within individual preclinical experiments. The reviewers have interpreted our point correctly: our inability to show a clear dose-response after pooling all results raises some concerns about the predictive value of studies included in our meta-analysis.</p><p>Regarding sample size, there are 158 data points in <xref ref-type="fig" rid="fig5">Figure 5A</xref>. Each data point represents a single experiment or sub-experiment (in cases where one experiment had more than one treatment arm with a defined dose). Inclusion into the dose-response analysis required experiments or sub-experiments to have used a regular dosing schedule (i.e. sunitinib administered at a defined dose once a day instead of experiments where sunitinib was dosed more irregularly or only once). These inclusion criteria led to 26 experiments or sub-experiments to be excluded. It is worth reiterating that the number of data points possible in our dose-response analysis for all malignancies was 183. This number differs from the total number of data points possible in our other analyses, where we calculated a weighted average of the SMDs and 95% CIs in the cases of experiments that had more than one treatment arm.</p><p>Regarding the curve we fitted, we believe our simple regression (calculated using the linear regression function in Excel) is sound for descriptive purposes and assessing a simple relationship between doses. Our intent was simply to judge the presence or absence of an expected positive correlation between effect and increasing dose rather than identifying precise dose-response curves.</p><p>Regarding the source of clinical outcome data, we think this confusion stems from a poor choice of title, which we changed to “A Meta-Analysis of Threats to Valid Clinical Inference in Preclinical Research of Sunitinib”.</p><p>We modified the manuscript as follows:</p><p>We enhanced the description of dose response in Methods, Results, and Discussion sections. We also cite Houk et al (PMID: 19967539) to show that a dose-response relationship was found in GIST and mRCC in clinical studies. This citation helps support our assertion that the absence of a dose-response in preclinical models (especially when RCC was analyzed alone) is odd.</p><p>We also removed the two-group <italic>t</italic>-test, which was a remnant of a previous draft and out of place.</p><p>We made some edits to figure legend, as well as Methods section, to explain more clearly how (and why) we performed dose response curves, as well as the number of experiments included in them.</p><p><italic>2) It would be very helpful for the authors to comment on the number of studies that reported drug exposure rather than drug dose. It is common for preclinical studies to report the intended drug dose, but without reference to the actual levels of drug attained. Assessment of drug levels confirms (i) that drug was actually administered and (ii) to the intended cohort. Moreover, it is frequently the case that when levels rather than dose are examined, it is evident that the levels achieved in rodents are not tolerated in humans. This has specifically been recognized for sunitinib and is an additional explanation for the disconnection between preclinical versus clinical effectiveness</italic>.</p><p>We agree that reporting drug exposure (and measured serum levels of drug in experimental animals) would be the optimal measurement upon which to construct dose-response curves and to later correlate with clinical data. Unfortunately, these measurements were rarely included within tumour volume experiments we extracted. Indeed, this comment prompted us to reexamine the first 20% of studies in our sample and we found no instances where levels were measured instead of dose. We had included 4 studies that included serum measurements of sunitinib post-dosing (PK). However, none of these serum levels were taken during efficacy experiments; they were only performed in studies to correlate with molecular data (e.g. FLT3 expression levels).</p><p>We protocolized and standardized eligibility criteria and dose exposure measurement to reduce variability inherent with using dose, given that drug serum levels were not available to us. For instance, in dose response analysis, we only included experiments where the dose was clearly stated and was administered once per day (as opposed to more complex or variable dosing schedules). Additionally, we used a common time point between experiments (14 days after the first day of drug administration).</p><p>The difficulty we faced constructing a robust measure of drug exposure and effect further highlights the poor reporting practices in preclinical research and the need for improvement in this regard.</p><p>In light of the above, we made the following modifications to the manuscript:</p><p>We added a statement in the Methods section as to why we used dose instead of drug exposure (“As we were unable to find experiments that reported drug exposure (e.g. drug serum levels), we calculated pooled effect sizes in OpenMeta[Analyst] and plotted against dose”).</p><p>We also added a statement in the Discussion section stating “the tendency for preclinical efficacy studies to report drug dose, but rarely drug exposure (i.e. serum measurement of active drug), further limits the construct validity of these studies,” and we buttressed this with a new reference (Peterson et al., 2004).</p><p><italic>3) It would also be helpful if the authors could comment on the number of studies that included a positive control. While sunitinib may have had activity, without a positive control it is difficult to place that activity into context. Was the efficacy comparable or greater than that seen with another known active agent?</italic></p><p>We agree that efficacy data are difficult to make sense of absent positive controls. Examining our dataset, we found that 93/158 experiments included in the meta-analysis included an active comparator drug arm. Note that we do not use the term “positive control” strictly here, as sometimes sunitinib was being the positive control in a study of a newer drug.</p><p>We inserted two sentences to the subsection “Design Elements Addressing Validity Threats” describing the frequency of active drug comparators in experiments, and the relationship between their inclusion and reported effect sizes.</p><p><italic>4) It would be beneficial to understand how many of the studies used an appropriate statistical test when analyzing their data</italic>.</p><p>We agree this would be a useful analysis but it is beyond the scope of this paper. To address appropriateness adequately we would need raw subject data, subject flow, protocols, and analytical plans. While some issues are black and white, many are nuanced/subjective and require complete background info. Instead, we focused our energies in the validity criteria identified in our PLoS Medicine systematic review of preclinical design guidelines.</p><p><italic>5) The authors did not comment on the ARRIVE Guidelines for pharmacology studies. These should be discussed (cited in Begley and Ioannidis., Reproducibility in Science. Improving the Standard for Basic and Preclinical Research., Circulation Research., 2015; 116: 116-126</italic>.<italic>)</italic></p><p>We heartily agree that citing ARRIVE is important for this audience and we’ve now cited and singled it out for mention at the end of the Discussion. We also added a reference to the Circulation Research article, which provides a nice overview of reproducibility challenges. We also took this occasion to mention the Center for Open Science Reproducibility Project: Cancer Biology.</p><p><italic>6) The authors should check that their references are correctly cited. For example, the statement (in the Introduction) “A recent systematic review of guidelines for limiting bias in preclinical research design was unable to identify any guidelines in oncology (</italic><xref ref-type="bibr" rid="bib20"><italic>Han et al., 2013</italic></xref><italic>)” is not supported by</italic> <xref ref-type="bibr" rid="bib20"><italic>Han et al., 2013</italic></xref>.</p><p>Thanks to the reviewers for catching this. It has now been corrected.</p><p><italic>7) The observation that “Our findings suggest that testing in more models tends to produce smaller effect sizes” has also been made previously (cited in</italic> <xref ref-type="bibr" rid="bib6"><italic>Begley and Ioannidis, 2015</italic></xref><italic>)</italic>.</p><p>Thank you. We now cite the Circulation article (see above). For this particular claim, the referees are correct – this has been suggested before – in particular by CAMARADES. We now cite the paper (O’Collins et al, Annals Neurol, 2006).</p><p><italic>8) Why did the authors of this review decide a) to include only papers published in English b) not to retrieve data via contacting the authors of the original papers? The authors conclude that there is a substantial risk on publication bias. But it might be possible that the observed risk on publication bias could have been much smaller when the authors contacted the authors for missing data and included also papers published in languages other than English</italic>.</p><p>This was decided mainly on feasibility and funding constraints. We did not have a budget to both identify relevant expertise and to translate articles. Contacting authors for additional data would pull in experiments and findings that have not been subject to peer review. Our experience contacting drug companies for missing data does not lead us to think this would have been a productive use of our time. We did, however, attempt to obtain Sugen/Pfizer’s preclinical dataset from FDA by filing a Freedom of Information Act. The FOIA was submitted in February of 2012, around the time the grant received funding. The 3-year grant ended in 2015, with the FOIA request not yet honoured. We added a sentence in the Discussion stating this as a limitation.</p><p><italic>9) In this review, the outcome measure of interest needs a more detailed description in the Material and methods section. In the subsection “Extraction,” the authors state that they are only interested in tumor volume (“[…] those evaluating the effect of monotherapy on tumor volume”), whereas the Abstract and Introduction talk about tumor growth (which is a much broader term). Did the authors only assess tumor volume of primary tumors? Or did they include the volumes of metastases in the body as well? Did the authors include studies in which the weight of tumors and metastases were assessed? And what about tumor incidence? The authors also state</italic>: <italic>“[…] To account for different measures of tumor growth”; which measures of tumor growth did they include?</italic></p><p>We expanded the Methods section to reflect the reviewers’ queries. For instance, we changed our broad references to “tumour growth” into references to tumour volume measurements (which is what we were extracting). We also provide a more detailed description of outcome measurement (see, for example, text beginning “Our primary outcome was experimental […]”, in the subsection “Extraction”).</p><p><italic>10) More details are needed in the Materials and methods concerning the meta analyses</italic>.</p><p><italic>a) Are data pooled in case tumor volume was determined in various regions of the body within one experiment?</italic></p><p>We were a bit unsure what the reviewers mean by “various regions of the body within one experiment”. We did not encounter studies where tumors were injected into more than one location within a single experiment. Perhaps the referees are referring to inter-experimental variability in tumour implantation site (e.g. experimental renal tumour injected subcutaneously into the hindleg vs. injected orthotopically into the renal capsule of the mouse). If this is the case, we did record this information (as to whether the tumour implantation site was heterotopic, orthotopic, or systemic), but we did not perform separate analyses according to this variable. Our concern is that doing so would divide our sample into slices too thin to enable analysis. If referees think it useful we would be happy to add a sentence or two about the use orthotopic vs. heterotopic models in our sample of experiments.</p><p><italic>Are the data pooled in the overall analyses (</italic><xref ref-type="fig" rid="fig3"><italic>Figure 3</italic></xref><italic>) when results were assessed at various time points?</italic></p><p>We clarified information of our time points to the Methods (in the subsection “Extraction”). We also clarified which time point was used for which analysis in the Results section and in each figure legend. As explained in the subsection “Study Characteristics”, the mean number of days in last common timepoint (LCT) was 31 days (± 14 days SDM).</p><p><italic>b) In animal studies the same control group is often used for multiple experimental. Did the authors correct for multiple use of the control groups?</italic></p><p>Indeed, we did adjust. In cases where multiple arms of treatment were reported versus the same control, a pooled estimate of the treatment arms was calculated using the inverse variance approach and then compared to the single control to produce an SMD estimate and 95% CIs.</p><p><italic>c) What was the minimum group size to allow subgroup analyses?</italic></p><p>We did not specify a minimum group size for meta-analysis. Instead we presented all available data. The goal of subgroup analyses in meta-analysis is to present all available data relevant to the strata even if just 1 experiment, thus a minimum subgroup size is not as relevant. Now that we have integrated sample sizes into our figures more clearly, readers can perhaps make their own judgments.</p><p><italic>11) The authors should report group sizes of all subgroups (also in figures; e.g.</italic> <xref ref-type="fig" rid="fig3"><italic>Figure 3</italic></xref><italic>), and take group size into account when interpreting the results</italic>.</p><p>We converted <xref ref-type="fig" rid="fig3">Figure 3</xref> to forest plots and have included the subgroup sizes.</p><p><italic>12) The authors should report heterogeneity statistics (for example I</italic><sup><italic>2</italic></sup><italic>), and take these results into account when interpreting the data</italic>.</p><p>The primary purpose of our paper was to evaluate potential sources of methodological and pre-clinical heterogeneity through pre-specified items of internal, external, and construct validity. We now report I<sup>2</sup> statistics but we must note that we (and others – e.g. Paul SR, Donner A., Small sample performance of tests of homogeneity of odds ratios in k 2×2 tables., Stat Med 1992; 11: 159-65; Hardy RJ, Thompson SG., Detecting and describing heterogeneity in meta-analysis., Stat Med 1998; 17: 841-56) are somewhat skeptical about the value of heterogeneity statistics due to their extreme sensitivity in the presence of a small number of studies. As the referees will see, heterogeneity statistics, as expected, within each malignancy was generally high (see <xref ref-type="supplementary-material" rid="SD3-data">Figure 2–source data 1B</xref>), with some notable exceptions (e.g. high-grade glioma, prostate cancer). By design, our study sheds light on possible sources of methodological heterogeneity (i.e. <xref ref-type="fig" rid="fig3">Figure 3</xref>) and we have incorporated such observations in our interpretation and conclusions.</p></body></sub-article></article>