<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">106140</article-id><article-id pub-id-type="doi">10.7554/eLife.106140</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106140.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Rhythmic sampling and competition of target and distractor in a motion detection task</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Xiong</surname><given-names>Changhao</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-2766-8373</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Petro</surname><given-names>Nathan M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7553-4459</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Bo</surname><given-names>Ke</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3286-7891</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Cui</surname><given-names>Lihan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7722-3550</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Keil</surname><given-names>Andreas</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4064-1924</contrib-id><email>akeil@ufl.edu</email><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Ding</surname><given-names>Mingzhou</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1024-3503</contrib-id><email>mding@bme.ufl.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02y3ad647</institution-id><institution>J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida</institution></institution-wrap><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01q9r1072</institution-id><institution>Institute for Human Neuroscience, Boys Town National Research Hospital</institution></institution-wrap><addr-line><named-content content-type="city">Boys Town</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/049s0rh22</institution-id><institution>Department of Psychological and Brain Science, Dartmouth College</institution></institution-wrap><addr-line><named-content content-type="city">Hanover</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02y3ad647</institution-id><institution>Department of Psychology, University of Florida</institution></institution-wrap><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>O'Connell</surname><given-names>Redmond G</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02tyrky19</institution-id><institution>Trinity College Dublin</institution></institution-wrap><country>Ireland</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Luo</surname><given-names>Huan</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>07</day><month>11</month><year>2025</year></pub-date><volume>14</volume><elocation-id>RP106140</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2025-02-05"><day>05</day><month>02</month><year>2025</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2025-02-05"><day>05</day><month>02</month><year>2025</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.09.26.615254"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-04-24"><day>24</day><month>04</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106140.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-09-08"><day>08</day><month>09</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106140.2"/></event></pub-history><permissions><copyright-statement>© 2025, Xiong, Petro et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Xiong, Petro et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-106140-v1.pdf"/><abstract><p>It has been suggested that the visual system samples attended information rhythmically. Does rhythmic sampling also apply to distracting information? How do attended information and distracting information compete temporally for neural representations? We recorded electroencephalography (EEG) from participants who detected instances of coherent motion in a random-dot kinematogram (RDK; the target), overlayed on different categories (pleasant, neutral, and unpleasant) of affective images from the International Affective Picture System (IAPS) (the distractor). The moving dots were flickered at 4.29 Hz, whereas the IAPS pictures were flickered at 6 Hz. The time course of EEG spectral power at 4.29 Hz was taken to index the temporal dynamics of target processing. The spatial pattern of the EEG spectral power at 6 Hz was similarly extracted and subjected to a moving-window MVPA decoding analysis to index the temporal dynamics of processing pleasant, neutral, or unpleasant distractor pictures. We found that (1) both target processing and distractor processing exhibited rhythmicity at ~1 Hz and (2) the phase difference between the two rhythmic time courses was related to task performance, i.e., relative phase closer to π predicted a higher rate of coherent motion detection whereas relative phase closer to 0 predicted a lower rate of coherent motion detection. These results suggest that (1) in a target-distractor scenario, both attended and distracting information were sampled rhythmically and (2) the more target sampling and distractor sampling were separated in time within a sampling cycle, the less distraction effects were observed, both at the neural and the behavioral level.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>attention</kwd><kwd>rhythmic sampling</kwd><kwd>distractor</kwd><kwd>EEG</kwd><kwd>SSVEP</kwd><kwd>multivariate pattern analysis</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/021nxhr62</institution-id><institution>U.S. National Science Foundation</institution></institution-wrap></funding-source><award-id>BCS2318886</award-id><principal-award-recipient><name><surname>Keil</surname><given-names>Andreas</given-names></name><name><surname>Ding</surname><given-names>Mingzhou</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/021nxhr62</institution-id><institution>U.S. National Science Foundation</institution></institution-wrap></funding-source><award-id>BCS2318984</award-id><principal-award-recipient><name><surname>Keil</surname><given-names>Andreas</given-names></name><name><surname>Ding</surname><given-names>Mingzhou</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 MH125615</award-id><principal-award-recipient><name><surname>Keil</surname><given-names>Andreas</given-names></name><name><surname>Ding</surname><given-names>Mingzhou</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Spatially and temporally overlapping target and distractor are both rhythmically sampled at ~1 Hz, and the phase relationship between target sampling and distractor sampling predicts behavior.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Sustained visual attention is required in many real-life situations such as driving a vehicle or operating machinery and is characterized by limited capacity; not all information available to the visual system can be processed in-depth. Recent work has suggested that to manage the limited capacity problem, the visual system samples the attended information in a rhythmic fashion, mediated by low-frequency intrinsic brain oscillations (<xref ref-type="bibr" rid="bib14">Chota et al., 2022</xref>; <xref ref-type="bibr" rid="bib20">Dugué et al., 2015</xref>; <xref ref-type="bibr" rid="bib21">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Fiebelkorn et al., 2018</xref>; <xref ref-type="bibr" rid="bib23">Fiebelkorn and Kastner, 2019</xref>; <xref ref-type="bibr" rid="bib30">Helfrich et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Michel et al., 2022</xref>; <xref ref-type="bibr" rid="bib55">Re et al., 2019</xref>; <xref ref-type="bibr" rid="bib63">VanRullen, 2013</xref>; <xref ref-type="bibr" rid="bib65">Zalta et al., 2020</xref>). In this view, the cycle of a low-frequency intrinsic brain oscillation can be divided into two phases: a high excitability phase and a low excitability phase. When a stimulus occurs during the high excitability phase, behavioral performance tends to be better than average; conversely, if the stimulus occurs during the low excitability phase, performance is generally worse than average (<xref ref-type="bibr" rid="bib42">Lakatos et al., 2008</xref>; <xref ref-type="bibr" rid="bib63">VanRullen, 2013</xref>). Behavioral performance may thus exhibit rhythmic fluctuations at the frequency of the aforementioned low-frequency intrinsic brain oscillation. One paradigm that has been used to test the idea of rhythmic visual sampling is the cue-target paradigm (<xref ref-type="bibr" rid="bib52">Posner, 1980</xref>; <xref ref-type="bibr" rid="bib53">Posner et al., 1987</xref>; <xref ref-type="bibr" rid="bib54">Posner et al., 1988</xref>). The cue at the beginning of each trial, in addition to providing instructions on how the impending target stimulus should be responded to, helps to reset the phase of the low-frequency intrinsic oscillation such that all the trials start at approximately the same phase. By varying the stimulus onset asynchrony (SOA) between the cue and the target, one obtains the behavioral response (e.g. accuracy and/or reaction time) as a function of the SOA. The rhythmic nature and the frequency of this function can then be assessed by applying time-domain and/or spectral-domain analysis.</p><p>When attending to one object in isolation, the frequency of rhythmic sampling tends to be in the high theta or low alpha frequency range, i.e., around 8 Hz (<xref ref-type="bibr" rid="bib21">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib58">Senoussi et al., 2019</xref>; <xref ref-type="bibr" rid="bib62">van der Werf et al., 2023</xref>). When attention is directed to multiple objects in the environment, it has been suggested that rather than sampling all the objects simultaneously, the brain samples the objects in a serial fashion (<xref ref-type="bibr" rid="bib15">Cohen et al., 1990</xref>; <xref ref-type="bibr" rid="bib64">Wyart et al., 2012</xref>). This would then lead to a slower rhythmic sampling of any given object, in the low range of the theta frequency band, i.e., around 4 Hz (<xref ref-type="bibr" rid="bib60">Thigpen et al., 2019</xref>). For example, when participants were cued to attend one visual hemifield but were asked to detect the appearance of a weak stimulus in either the cued or the uncued visual hemifield, the rhythmic detection rate for the target appearing in a given visual hemifield decreased from 8 Hz to 4 Hz (<xref ref-type="bibr" rid="bib14">Chota et al., 2022</xref>; <xref ref-type="bibr" rid="bib21">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib63">VanRullen, 2013</xref>). Interestingly, when the detection rate functions of the cued and uncued targets were compared, a 180-degree relative phase was apparent, suggesting that the visual system indeed sampled the two visual hemifields in a serial, alternating fashion (<xref ref-type="bibr" rid="bib21">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib35">Jiang et al., 2024</xref>). In another example, two spatially overlapping clouds of moving dots, one in red color and the other in blue color, moved in orthogonal directions (<xref ref-type="bibr" rid="bib55">Re et al., 2019</xref>), and the participant was cued to attend both the red dots and the blue dots and instructed to report the change in either the red dots or the blue dots as soon as it occurred. When there was only one cloud of moving dots, the detection accuracy exhibited rhythmic fluctuations as a function of the SOA at a frequency around 8 Hz. When both clouds of moving dots were present, rhythmic fluctuations in the accuracy of detecting changes in a given cloud of moving dots were again identified, and the sampling frequency was reduced to 4 Hz. In this case, however, no apparent 180-degree relative phase between the rhythmic behavioral response functions to the red and blue dots was found, suggesting that there was no serial, alternating sampling between the two attended objects if they appeared at the same spatial location.</p><p> The real world visual environment contains both task-relevant information (target) and task-irrelevant (distractor) information. It is well established that in the presence of a distractor, the processing of the target is negatively impacted, leading to reduced task performance (<xref ref-type="bibr" rid="bib45">Lavie, 2005</xref>; <xref ref-type="bibr" rid="bib50">Murphy et al., 2016</xref>). This implies that the distractor, despite the need for it to be suppressed by the brain’s executive control system (<xref ref-type="bibr" rid="bib36">Kastner et al., 1998</xref>; <xref ref-type="bibr" rid="bib37">Kastner et al., 1999</xref>; <xref ref-type="bibr" rid="bib39">Kastner and Pinsk, 2004</xref>; <xref ref-type="bibr" rid="bib57">Seidl et al., 2012</xref>; <xref ref-type="bibr" rid="bib38">Kastner and Ungerleider, 2000</xref>), is nevertheless processed in the brain, and the competition between the target and the distractor at the neural representational level causes the detriment in behavioral performance. Does the rhythmic sampling theory extend to the target-distractor scenario? If so, what is the temporal relationship between the rhythmic sampling of attended vs distracting stimuli? These questions have hitherto not been addressed. Part of the reason is that the majority of the studies on rhythmic environmental sampling focuses on behavioral evidence, e.g., rhythmicity in the aforementioned performance-vs-SOA function (<xref ref-type="bibr" rid="bib23">Fiebelkorn and Kastner, 2019</xref>; <xref ref-type="bibr" rid="bib43">Landau and Fries, 2012</xref>). Since the distractor is not responded to, its sampling by the visual system cannot be inferred purely on the basis of response behavior, and consequently, it is also not possible to study how the target and the distractor might compete for neural representations purely behaviorally.</p><p> In this study, we addressed these limitations by recording neural activities and investigating rhythmic sampling during a target-distractor scenario using steady-state visual evoked potential (SSVEP) frequency tagging. The stimuli were a cloud of randomly moving dots (the target) superimposed on emotional images from the International Affective Picture System (IAPS; <xref ref-type="bibr" rid="bib44">Lang et al., 1997</xref>) (the distractor). The target and the distractor were flickered at two different frequencies for an extended duration of ~12 s. The participants were asked to focus on the randomly moving dots and report the number of times the dots moved coherently. In this paradigm, the onset of the stimulus array is the event that resets the phase of the putative low-frequency brain oscillation underlying rhythmic sampling, and the time from the stimulus array onset, referred to as time-from-onset (TFO), is analogous to the SOA in the traditional cue-target paradigm. It is worth noting that, although this paradigm has been used extensively in studies of target-distractor competition with electroencephalography (EEG) (<xref ref-type="bibr" rid="bib32">Hindi Attar and Müller, 2012</xref>; <xref ref-type="bibr" rid="bib49">Müller et al., 2008</xref>), it has not yet been examined in the context of rhythmic sampling. Aided by frequency tagging, from the EEG data, we extracted neural representations of target and distractor processing separately as a function of TFO. By examining the rhythmicity of these representations as functions of TFO and the phase relationship between these functions, we assessed (1) whether the target and the distractor were sampled rhythmically and (2) how their temporal competition for neural representations impacted behavioral performance.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>EEG data were collected from 27 subjects performing a sustained attention task. The paradigm is shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. The stimulus consisted of a random-dot kinematogram (RDK; the target) overlayed on different categories (pleasant, neutral, and unpleasant) of affective images from the IAPS (the distractor). The moving dots were flickered at 4.29 Hz, whereas the IAPS pictures were flickered at 6 Hz. The participant was instructed to detect brief episodes of coherent motion (0, 1, or 2) and report the number of such episodes at the end of the trial; each trial lasted ~12 s. Depending on the emotional category of the distracting images, the trials were divided into pleasant trials (28), neutral trials (28), and unpleasant trials (28). Each participant performed 84 trials.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental paradigm and general approach for electroencephalography (EEG) data analysis.</title><p>(<bold>A</bold>) Motion detection task. Randomly moving dots flickered at 4.29 Hz (target) were superimposed in International Affective Picture System (IAPS) images flickered at 6 Hz (distractor). Participants detected brief episodes of coherent motion. (<bold>B</bold>) Target-specific signals and distractor-specific signals were estimated and subjected to (1) whole trial analysis and (2) moving window analysis. MVPA decoding analysis was done using an ‘ERP’ decoding method. See Materials and methods for more details.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-fig1-v1.tif"/></fig><sec id="s2-1"><title>Behavioral analysis</title><p>The overall coherent motion detection accuracy was 55.73% ± 2.94%, with that for pleasant, neutral, and unpleasant trials being 55.67% ± 2.76%, 55.03% ± 3.10%, and 56.48% ± 3.61%, respectively. A one-way ANOVA found no significant difference in behavioral performance between the three types of trials (F<sub>2, 78</sub> = 0.053, p=0.949), suggesting that the three types of distractors exerted similar distracting influence on the detection of coherent motion, irrespective of their emotional significance.</p></sec><sec id="s2-2"><title>SSVEP analysis at the whole trial level</title><p>The grand average SSVEP at Oz and its Fourier spectrum are shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. From <xref ref-type="fig" rid="fig2">Figure 2B</xref>, spectral peaks corresponding to the flicker frequencies of 4.29 Hz (target) and 6 Hz (distractor) are clearly seen. Filtering the SSVEP between 4.29–0.5 Hz and 4.29+0.5 Hz yielded the signal specific to target processing, whereas filtering the SSVEP between 6–0.5 Hz and 6+0.5 Hz yielded the signal specific to distractor processing. Averaging target amplitude and distractor amplitude across all electrodes, the 4.29 Hz amplitude was significantly greater than the 6 Hz amplitude (p=2.6 × 10<sup>–4</sup>); see <xref ref-type="fig" rid="fig2">Figure 2C</xref>. SSVEP amplitude topographies for target and distractor in <xref ref-type="fig" rid="fig2">Figure 2D</xref> showed that the strongest response for both frequencies was concentrated in the occipital channels. In <xref ref-type="fig" rid="fig2">Figure 2E</xref>, we assessed the relationship between SSVEP amplitude and task performance. Across participants, there was no correlation between target SSVEP amplitude and task performance (p=0.7536); see <xref ref-type="fig" rid="fig2">Figure 2E</xref>, left. The SSVEP amplitude of the distractor has a slight negative correlation with task performance, indicating that the stronger the distractor processing, the worse the performance, but it is not statistically significant (p=0.1896).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Steady-state visual evoked potential (SSVEP) analysis at the whole trial level.</title><p>(<bold>A</bold>) Grand average SSVEP at Oz. (<bold>B</bold>) Fourier spectrum of the data in A. (<bold>C</bold>) Target amplitude across all electrodes is significantly larger than distractor amplitude at p=2.6 × 10<sup>–4</sup>. (<bold>D</bold>) Topographical distributions of target and distractor amplitude. (<bold>E</bold>) Correlation between target SSVEP amplitude and task performance (left) and between distractor SSVEP amplitude and task performance (right). Both correlation values are not significant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-fig2-v1.tif"/></fig></sec><sec id="s2-3"><title>MVPA at the whole trial level</title><p>Our previous work has shown that IAPS pictures from different emotion categories evoke distinct spatial patterns in EEG which can be decoded using machine-learning-based MVPA methods (<xref ref-type="bibr" rid="bib10">Bo et al., 2022</xref>). If we were able to decode the emotion categories of the distractor from the spatial patterns of the 6 Hz SSVEP amplitude, the decoding accuracy can then be used to indicate the strength of the distractor representation in the brain, complementing the 6 Hz SSVEP amplitude considered earlier. The decoding was done between different types of emotion trials (e.g. pleasant vs neutral) using an ‘ERP’ decoding method (<xref ref-type="bibr" rid="bib6">Bae and Luck, 2019</xref>). See <xref ref-type="fig" rid="fig1">Figure 1B</xref> and Materials and methods for more details. As shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref>, for pleasant vs neutral, unpleasant vs neutral, and unpleasant vs neutral, the pairwise decoding accuracy was 57.86% ± 9.86%, 55.14% ± 8.17%, and 59.45% ± 9.73%, respectively, which were all significantly above the chance level of 50% at p=3.2 × 10<sup>–4</sup>, p=3.0 × 10<sup>–3</sup>, and p=3.0 × 10<sup>–5</sup>, respectively. As shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref>, the three-way decoding accuracy was found to be 41.09% ± 6.25%, which is again significantly above chance level of 33.33% at p=3.9 × 10<sup>–7</sup>. Similar to distractor SSVEP amplitude, no correlation was found between distractor decoding accuracy and task performance; see <xref ref-type="fig" rid="fig3">Figure 3C</xref>. Also, in order to verify that the distractor decoding accuracy and the distractor amplitude were independent indices of distractor processing, we correlated the two across participants. As <xref ref-type="fig" rid="fig3">Figure 3D</xref> shows, no correlation was found, suggesting that the two quantities provided complementary characterization of distractor processing (also see Appendix 1—figure 3).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>MVPA decoding analysis of distractor processing at the whole trial level.</title><p>(<bold>A</bold>) Pairwise decoding accuracies between pleasant vs neutral, unpleasant vs neutral, and pleasant vs unpleasant are 57.86% ± 9.86%, 55.14% ± 8.17%, and 59.45% ± 9.73%, respectively, which are all significantly above chance level of 50% (red dashed line) at p=3.2 × 10<sup>–4</sup>, p=3.0 × 10<sup>–3</sup>, and p=3.0 × 10<sup>–5</sup>. (<bold>B</bold>) Three-way decoding accuracy is 41.09% ± 6.25%, which is significantly higher than the chance level of 33% (red dashed line) at p=3.9 × 10<sup>–7</sup>. (<bold>C</bold>) Decoding accuracy vs task performance. The correlation of r=–0.0313 (p=0.8769) is not significant. (<bold>D</bold>) Distractor decoding accuracy vs distractor steady-state visual evoked potential (SSVEP) amplitude. The correlation of r=0.1531 (p=0.4458) is not significant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-fig3-v1.tif"/></fig></sec><sec id="s2-4"><title>Moving window analysis of target and distractor processing</title><p>To examine the temporal dynamics of target processing, the target SSVEP amplitude time series was obtained using the moving window approach, where the window duration was 0.5 s and the step size 0.25 s. Fourier analysis was then applied to assess the rhythmicity of the time series. The results of these analyses for one representative participant are shown in <xref ref-type="fig" rid="fig4">Figure 4Ai</xref>. The rhythmic nature of target processing is apparent with a spectral peak at ~1 Hz. Across all participants, the averaged Fourier spectrum is shown in <xref ref-type="fig" rid="fig4">Figure 4Aii</xref>, where the frequency of the spectral peak was found to be 1.08±0.11 Hz. These results supported the idea that the attended target was sampled rhythmically with a sampling frequency at ~1 Hz (delta frequency band).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Temporal dynamics of target and distractor processing.</title><p>(<bold>A</bold>) (<bold>i</bold>) Target amplitude time series from the moving window approach for a representative subject (left) and its Fourier spectrum (right). (<bold>A</bold>) (ii) The average target amplitude spectrum across 27 subjects. (<bold>B</bold>) (<bold>i</bold>) Distractor decoding accuracy time series from the moving window approach for a representative subject (left) and its Fourier spectrum (right). (<bold>B</bold>) (ii) The average distractor decoding accuracy spectrum across 27 subjects.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-fig4-v1.tif"/></fig><p>To examine the temporal dynamics of distractor processing, three-way MVPA decoding was performed for the three types of emotion trials using the moving window approach with the same window duration and step; see <xref ref-type="fig" rid="fig1">Figure 1A</xref> and Materials and methods for more details. The three-way decoding accuracy time series and the Fourier spectrum from one representative participant are shown in <xref ref-type="fig" rid="fig4">Figure 4Bi</xref>. The rhythmic nature of the decoding accuracy time series is again apparent, and the spectral peak is at ~1 Hz. Across all participants, the averaged spectrum is shown in <xref ref-type="fig" rid="fig4">Figure 4Bii</xref>, where the peak frequency was determined to be 1.08±0.11 Hz. These results supported the idea that the distractor was also sampled rhythmically with a sampling frequency at ~1 Hz (delta frequency band).</p></sec><sec id="s2-5"><title>Target-distractor competition and task performance</title><p>As shown above, the present evidence suggests that both the target and the distractor were sampled rhythmically, at ~1 Hz. Since the sampling frequency was approximately the same for the two rhythmic time series, the relative phase between them can then be assessed, which characterizes the temporal relationship between the sampling of target and distractor. <xref ref-type="fig" rid="fig5">Figure 5A</xref> shows the distribution of the relative phase for all participants (mean relative phase = 0.51 ± 0.31π). A Kolmogorov-Smirnov (K-S) test was applied to the relative phase distribution to see whether it departed from the uniform distribution (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). A K-S statistic of 0.10 showed that the relative phase distribution is not different from the uniform distribution at p=0.92, suggesting that there was no systematic relative phase between rhythmic samplings of target vs distractor across participants.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Target-distractor competition analysis.</title><p>(<bold>A</bold>) Phase polar histogram for the relative phase between target processing time series and distractor processing time series (1 Hz). The average relative phase is 0.51π. (<bold>B</bold>) Kolmogorov-Smirnov test showed that the relative phase distribution is not different from uniform distribution. (<bold>C</bold>) Temporal relationship between target processing and distractor processing for (<bold>i</bold>) a high performer (accuracy = 83.84%; relative phase = 0.877π) and (ii) a low performer (accuracy = 33.33%; relative phase = 0.053π). (<bold>D</bold>) Task performance vs 1 Hz relative phase. The significant positive correlation (r=0.6041, p=0.0008) indicated that the more separated the target and distractor sampling within the 1 Hz oscillation cycle, the better the behavioral performance. CDF: cumulative distribution function.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-fig5-v1.tif"/></fig><p>Since simultaneously presented target and distractor compete for neural representations and the stronger the competition, the worse the task performance, one may expect that if the target sampling and the distractor sampling are well separated in time, namely, if they occur in opposite phases of the 1 Hz brain oscillation, the competition will be minimized, and the task performance will be maximized. Conversely, if the target and the distractor were sampled during the same phase within the 1 Hz cycle, the target-distractor competition will be maximized, and the task performance will be minimized. This notion is tested in <xref ref-type="fig" rid="fig5">Figure 5C</xref>, using data from a high-performing participant (accuracy = 84.34%) and a low-performing participant (accuracy = 33.33%). Here, the target processing time series and the distractor processing time series were z-scored so they can be displayed in the same graph. In the high performer, the two time courses are highly anticorrelated (relative phase is around π), indicating that the target and the distractor were sampled in opposite parts of the cycle, while for the low performer, the two time courses are highly correlated (relative phase is around 0), indicating that the target and the distractor were sampled in the same part of the cycle. Across all participants, as shown in <xref ref-type="fig" rid="fig5">Figure 5D</xref>, a significant positive correlation between relative phase and task performance was observed (r=0.6041, p=0.0008), suggesting that the more the target sampling and the distractor sampling are separated in time (i.e. in opposite phases of the cycle), the less the interference between target and distractor processing, the better the task performance.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In natural vision, task-relevant information (the target) and task-irrelevant information (the distractor) often appear at the same time, and often overlap in visual space. The distractor information, upon entering the nervous system, interferes with the neural representations of task-relevant information, causing degraded task performance (<xref ref-type="bibr" rid="bib19">Deweese et al., 2016</xref>). In this study, we examined the temporal dynamics of target and distractor processing during sustained visual attention by analyzing EEG data from an SSVEP paradigm in which random moving dots (target) flickered at one frequency were superimposed on IAPS pictures (distractor) flickered at another frequency. In particular, we tested whether rhythmic sampling applied to distracting information and how target-distractor competition affected behavior. The results showed that (1) distractor information (i.e. IAPS pictures from different emotion categories) can be decoded from the distributed patterns of scalp EEG, (2) both the target and the distractor are sampled rhythmically with the same sampling frequency of ~1 Hz (delta frequency band), and (3) the more negative (i.e. closer to 180 degrees) the phase relationship between the sampling of the target and that of the distractor, i.e., the more temporally separated between target sampling and distractor sampling within a sampling cycle, the better the behavioral performance.</p><sec id="s3-1"><title>Rhythmic sampling of attended and ignored information</title><p>Previous studies have investigated how attended information is temporally sampled using the cue-target paradigm. In particular, if some behavioral measures such as the stimulus detection accuracy or reaction time are found to be a periodic function of the time between the cue and the target, i.e., the stimulus-onset asynchrony or SOA, then it is taken as evidence in support of rhythmic sampling. If there is only one attended target, the frequency of rhythmic sampling tends to fall in the upper end of the theta frequency band (~8 Hz) (<xref ref-type="bibr" rid="bib12">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib34">Huang and Luo, 2020</xref>; <xref ref-type="bibr" rid="bib33">Huang et al., 2015</xref>; <xref ref-type="bibr" rid="bib63">VanRullen, 2013</xref>). When there are more than one attended targets in the environment, each target is again sampled rhythmically, but the sampling frequency is slower, often falling in the lower end of the theta frequency band (~4 Hz) (<xref ref-type="bibr" rid="bib21">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib43">Landau and Fries, 2012</xref>; <xref ref-type="bibr" rid="bib55">Re et al., 2019</xref>). When the attended targets appear in different visual hemifields, an alternating sampling strategy was observed, evidenced by the 180-degree phase relationship between the two behavioral time courses (<xref ref-type="bibr" rid="bib14">Chota et al., 2022</xref>; <xref ref-type="bibr" rid="bib22">Fiebelkorn et al., 2018</xref>).</p><p> How distractors are temporally sampled has not been investigated to date. One of the reasons is that distractors do not elicit behavioral responses, and as such, a pure behavioral approach is not able to address this question. We overcame the problem by recording EEG in an SSVEP paradigm in which the target and the distractor overlapped in space and time and flickered at different frequencies, a method referred to as frequency tagging. Separately extracting the EEG signals underlying the neural response to the target and that to the distractor according to their flickering frequencies (4.29 Hz for target and 6 Hz for distractor), we found that at the whole trial level, target processing exhibited higher SSVEP amplitude than distractor processing, and for both target and distractor processing, the signal power is maximal at the posterior channels. Cognizant of the possibility that the power at 4.29 Hz may leak into neighboring frequency bands where the power is weaker (see Appendix 1—figures 4), instead of using the 6 Hz SSVEP amplitude to quantify distractor processing, we adopted the MVPA decoding approach to quantify the distractor processing by leveraging the previous finding that different categories of emotional images evoked different patterns of neural responses in scalp EEG (<xref ref-type="bibr" rid="bib10">Bo et al., 2022</xref>). This led us to construct classifiers that took the 6 Hz SSVEP amplitude across all electrodes as input to decode the spatial patterns evoked by different categories of emotional distractors, with higher classification or decoding accuracy taken to indicate stronger distractor processing. At the whole trial level, the observed above-chance decoding accuracy suggested that the distractor information is present in the brain and could be revealed and quantified by combining machine learning with distractor-specific scalp EEG.</p><p>Prior studies of visual environmental sampling used the cue-target paradigm in which the cue serves both to instruct the participant on how the target should be responded to and to reset the brain oscillation mediating the rhythmic visual sampling (<xref ref-type="bibr" rid="bib40">Kayser, 2009</xref>). In our paradigm, the resetting was prompted by the onset of the compound stimulus array. The time elapsed after the stimulus array onset, referred to as TFO here, plays the role of the SOA in the cue-target paradigm. To index the temporal dynamics of target and distractor processing, we applied a moving window approach, in which the window duration was 0.5 s, and the step size was 0.25 s. Within each window, the 4.29 Hz SSVEP amplitude was taken to index target processing and the accuracy of decoding different categories of emotional distractors based on the 6 Hz SSVEP amplitude pattern was taken to index distractor processing. Plotting these two indices as functions of TFO, we assessed the temporal dynamics of target and distractor processing. The results revealed that both the target and the distractor were sampled rhythmically with the same sampling frequency of ~1 Hz (delta frequency band), which is considerably slower than those reported in previous studies (<xref ref-type="bibr" rid="bib55">Re et al., 2019</xref>) in which the sampling frequency tends to fall in the theta frequency band (4–8 Hz).</p><p>Delta oscillations (0.5–3.5 Hz), traditionally associated with deep sleep and homeostatic processes (<xref ref-type="bibr" rid="bib3">Amzica and Steriade, 1998</xref>; <xref ref-type="bibr" rid="bib24">Franken et al., 2001</xref>; <xref ref-type="bibr" rid="bib25">Franken and Dijk, 2024</xref>; <xref ref-type="bibr" rid="bib26">Frohlich et al., 2021</xref>; <xref ref-type="bibr" rid="bib61">Torres-Herraez et al., 2022</xref>), are being increasingly recognized for their role in a variety of cognitive functions (<xref ref-type="bibr" rid="bib7">Basar et al., 1999</xref>; <xref ref-type="bibr" rid="bib8">Başar et al., 2001</xref>; <xref ref-type="bibr" rid="bib9">Başar-Eroglu et al., 1992</xref>). In the auditory domain, rhythmic sampling of an auditory scene is shown to be mediated by delta oscillations (<xref ref-type="bibr" rid="bib41">Kubetschek and Kayser, 2021</xref>; <xref ref-type="bibr" rid="bib48">Morillon et al., 2019</xref>). Our findings suggest that similar mechanisms could also operate in the visual domain. In a recent study, when observers directed temporal attention to one of two sequential grating targets with predictable timing, the steady-state visual evoked response of the flashing target was modulated at 2 Hz (<xref ref-type="bibr" rid="bib18">Denison et al., 2022</xref>), which falls in the delta frequency band. In addition, extensive evidence has shown that expecting a stimulus, which is known to require the deployment of attentional resources, engages delta oscillations (<xref ref-type="bibr" rid="bib4">Arnal et al., 2011</xref>; <xref ref-type="bibr" rid="bib5">Arnal et al., 2015</xref>; <xref ref-type="bibr" rid="bib11">Breska and Deouell, 2017</xref>; <xref ref-type="bibr" rid="bib16">Cravo et al., 2013</xref>; <xref ref-type="bibr" rid="bib42">Lakatos et al., 2008</xref>; <xref ref-type="bibr" rid="bib56">Schroeder and Lakatos, 2009</xref>; <xref ref-type="bibr" rid="bib59">Stefanics et al., 2010</xref>). Delta oscillations were also involved in mechanisms that synchronize distributed regions within functional neural networks in supporting cognitive control (<xref ref-type="bibr" rid="bib29">Helfrich et al., 2017</xref>; <xref ref-type="bibr" rid="bib31">Helfrich et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">Helfrich and Knight, 2016</xref>). The spatially overlapping target and distractor in our paradigm places high demand on the brain’s cognitive control system, shown recently to be operating in the delta frequency band (<xref ref-type="bibr" rid="bib51">Pagnotta et al., 2024</xref>), which could be another reason underlying the observed mediation by delta oscillations in the rhythmic sampling of the target-distractor environment.</p></sec><sec id="s3-2"><title>Phase relationship between target and distractor sampling and its functional significance</title><p>As mentioned earlier, when two attended objects are presented simultaneously in different visual hemifields, the visual system tends to sample them in a serial, alternating fashion, as evidenced by two rhythmic behavioral time series exhibiting a 180-degree relative phase (antiphase) (<xref ref-type="bibr" rid="bib18">Denison et al., 2022</xref>; <xref ref-type="bibr" rid="bib21">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib47">Mo et al., 2019</xref>). When two attended objects overlap in space, however, this alternating sampling pattern is not observed, and the relative phase between the two rhythmic behavioral time series appears to be uniformly distributed across participants (<xref ref-type="bibr" rid="bib55">Re et al., 2019</xref>). In our experimental design, the target and the distractor overlapped in space, which is a configuration known to maximize the distraction effect, and the relative phase between the rhythmic samplings of the target and the distractor is also uniformly distributed across participants. Thus, regardless of the behavioral relevance of the two superimposed stimuli, there is no preferred phase relationship between their samplings at the population level.</p><p>Although a clear phase relationship between the target sampling and the distractor sampling is absent at the population level, the relative phase between the two time series may nonetheless have functional significance. In particular, when the target sampling and the distractor sampling occur in opposite phases of a sampling cycle, i.e., when they are 180 degrees out of phase, the interference should be minimized, and consequently, the task performance should be maximized. On the contrary, when the target sampling and the distractor sampling occur in the same phase of a sampling cycle, i.e., when the target and the distractor are sampled at the same time, the interference should be maximized, and the task performance should be minimized. Our results supported this hypothesis. Specifically, we showed that there was a positive correlation between the relative phase of the target and distractor sampling time series and the behavioral performance, namely, the greater the relative phase between the two time series, the higher the rate of correctly detecting the instances of coherent motion in the moving dots (attended target). The additional significance of this finding can be understood by considering the analysis results at the whole trial level. One may expect that at the whole trial level, the stronger the distractor representation indexed by higher decoding accuracy, the worse the task performance. This turned out to be not the case. As shown in <xref ref-type="fig" rid="fig3">Figure 3D</xref>, the distractor decoding accuracy at the whole trial level was not correlated with task performance, nor was the overall power of the target evoked activity at the whole trial level. Thus, what we found should be considered a new mechanism underlying the competition between distractor and target. In this mechanism, the key is not how well the target and the distractor are each represented but how their respective rhythmic sampling aligns over time: The more target sampling and distractor sampling are separated in time, the less direct competition between the two, the better the attended information is processed, and the better the behavioral performance.</p></sec><sec id="s3-3"><title>Signal processing considerations</title><p>First, when the amplitude of a periodic signal with a frequency f is modulated at 1 Hz, we should observe sidebands at f<italic>+</italic>1 and f<italic>–</italic>1 Hz in the Fourier spectrum of the signal. These sidebands are not clearly seen in the Fourier spectrum of the SSVEP time series (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). We investigated the underlying reason in Appendix 1. The starting point is the observation that biological data is noisy. The SSVEP from the subjects contains a varying amount of noise quantified by the signal-to-noise ratio (SNR). We showed using both simulations and actual data that when the SNR is high, the sidebands are visible, whereas when the SNR is low, the sidebands are indistinguishable from the noise floor (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). The majority of our subjects have low SNR for observing sidebands. This is why the sidebands in the Fourier spectrum in <xref ref-type="fig" rid="fig2">Figure 2B</xref> are not readily identifiable. Second, when a 4.29 Hz periodic component and a 6 Hz component are combined, one should observe a beating frequency at 1.71 Hz. This beating frequency is clearly seen in the Fourier spectra of the amplitude envelope of the SSVEP in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. However, this spectral peak is secondary to a much stronger spectral peak occurring at ~1 Hz, which cannot be explained from a pure signal processing perspective (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref> for further investigation). This suggests that the 1 Hz amplitude modulation of the SSVEP amplitude, as well as decoding accuracy time series, is of an endogenous origin and represents the frequency of the rhythmic sampling of the environment by the visual attention system in our paradigm. Third, we tested the effect of moving window parameters on the temporal dynamics of target and distractor processing. Using a 0.1 s window length and a 0.05 s step size (<xref ref-type="fig" rid="app1fig6">Appendix 1—figures 5</xref> and <xref ref-type="fig" rid="app1fig5">6</xref>) and applying the window-free Hilbert transform method (<xref ref-type="fig" rid="app1fig7">Appendix 1—figures 7</xref> and <xref ref-type="fig" rid="app1fig8">8</xref>), we found the same results as those reported in the main manuscript, suggesting that the ~1 Hz rhythmic sampling and the phase-related target-distractor competition are robust findings. Fourth, to further test the robustness of the decoding results, we implemented a random permutation procedure. <xref ref-type="fig" rid="app1fig9">Appendix 1—figure 9</xref> shows the results based on 1000 permutations. For each of the three pairwise classifications—pleasant vs neutral, unpleasant vs. neutral, and pleasant vs. unpleasant—as well as the three-way classification, the actual decoding accuracies fall far outside the null-hypothesis distribution (p&lt;0.001), and the effect sizes are extremely large.</p></sec><sec id="s3-4"><title>Limitations</title><p>First, the experimental paradigm lacked a no-distractor baseline condition. The SSVEP amplitude of the target at the whole trial level thus reflected the combined effect of the stimulus parameters (e.g. contrast of the moving dots), as well as attention. However, the time course of the target SSVEP amplitude within a trial, derived from the moving window analysis, reflected the temporal fluctuations of target processing, since the stimulus parameters remained the same during the trial. Second, target processing and distractor processing are quantified differently: SSVEP amplitude for the former and decoding accuracy for the latter. However, using SSVEP amplitude to quantify target processing is a well-established approach, and given that decoding is between different classes of distractors, we are also confident that the decoding accuracy reflects distractor processing. For comparing the two, we normalized each time course to make them dimensionless and then computed correlations. Third, no fusion was attempted between simultaneously recorded EEG and fMRI. However, given that this study concerns the temporal dynamics of target and distractor processing, it is felt that fMRI data, which is known to possess low temporal resolution, has limited potential to contribute.</p></sec><sec id="s3-5"><title>Summary</title><p>In this work, we reported two main findings: (1) in sustained visual attention under distraction, both the distractor and the target are sampled rhythmically, with the sampling frequency being ~1 Hz (i.e. in the delta frequency band) and (2) the temporal relationship between the distractor sampling and the target sampling is a significant factor underlying task performance with a more antiphase relationship giving rise to better behavioral performance. To further illustrate the importance of the second finding, we note that neither target nor distractor processing strength at the whole trial level correlates with behavioral accuracy. These results extend the rhythmic sampling theory to distractor processing and provide further support for the important role of low-frequency brain oscillations in organizing cognitive operations. They also demonstrate the utility of applying machine learning methods in uncovering the temporal dynamics of sustained attention in target-distractor scenarios.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>The experimental protocol was approved by the Institutional Review Board of the University of Florida. Thirty undergraduate students from the University of Florida gave written informed consent and participated in the experiment to earn credit in an introductory psychology course. Because the EEG data were recorded inside the MRI scanner (simultaneous EEG-fMRI), participants underwent screening for ferromagnetic implants, claustrophobia, and personal or family history of epilepsy or photic seizures. Female participants were also administered a pregnancy test before participation. Three participants were excluded due to excessive movements during recording. The EEG data from n=27 participants (18 women, 9 men, mean age = 19.2 ± 1.1 years) were analyzed and reported here.</p></sec><sec id="s4-2"><title>Stimuli</title><p>The stimulus comprised an RDK overlaid on affective images selected from the IAPS database. The RDK consisted of 175 yellow dots randomly distributed within a circular aperture in the center of the screen, with each dot spanning &lt;0.5 degrees of visual angle. The IAPS images portrayed three broad categories of emotions: pleasant, neutral, and unpleasant. They were similar in overall composition and rated complexity and matched in picture file size to minimize confounds across categories. The stimulus was presented on a 30-inch MR-compatible LCD monitor placed approximately 230 cm from the participant’s head outside the bore of the MRI scanner. A white fixation dot was displayed at the center of the screen throughout the experiment.</p></sec><sec id="s4-3"><title>Procedure</title><p>See <xref ref-type="fig" rid="fig1">Figure 1A</xref> for the schematic illustration of the experimental task. After 5–11 s of fixation, the participant was presented the compound stimulus array consisting of the randomly moving dots (RDK) superimposed on the IAPS pictures for a duration of 11.667 s. The moving dots and the background pictures were flickered on and off at 4.29 Hz and 6 Hz, respectively. For each 4.29 Hz flicker cycle, the moving dots were displayed for 100 ms, which was followed by a 133 ms off period. Similarly, for each 6 Hz flicker cycle, the IAPS background picture was shown for 100 ms and followed by a 66.7 ms off period. During each on-off cycle, the moving dots in the RDK were randomly displaced by 0.3 degrees of visual angle in either random directions or one coherent direction. Coherent motion instances lasted for four on-off cycles (933 ms) and appeared once in 39 trials (13 trials per emotion condition) or twice in 4 trials. The remaining 41 trials contained no instances of coherent motion. Each trial lasted 11.667 s (50 moving dot cycles and 70 IAPS background picture cycles). The coherent motion instances occurred in the interval between 2.3 s and 10.4 s post stimulus array onset. The participant was asked to fixate on the central white dot during the trial, to monitor the motion coherence of the random dots, and report the number of coherent motion instances at the end of the trial. Both the number of coherent motion instances and the underlying emotion category of IAPS image were randomized in each trial. A total of 42 IAPS pictures were equally divided into three content categories based on valence: pleasant (erotic couples), neutral (workplace people), or unpleasant (bodily mutilation). Depending on the emotion category of the IAPS picture used in a given trial, the trials are referred to as pleasant, neutral, and unpleasant trials. There was a total of 84 trials: 28 pleasant trials, 28 unpleasant trials, and 28 neutral trials, and each picture was used twice during the experiment.</p></sec><sec id="s4-4"><title>EEG data collection and preprocessing</title><p>EEG data was recorded using a 32-channel MR-compatible EEG recording system (Brain Products, Germany). The system was synchronized to the internal clock of the scanner to facilitate the subsequent scanner noise removal. Thirty-one Ag/AgCl electrodes were placed on the scalp according to the 10–20 system via an elastic cap. One additional electrode was located on the participant’s upper back to record the electrocardiogram (ECG). Electrode FCz was used as the reference during recording. Impedances were kept below 20 kΩ for all scalp electrodes and below 50 kΩ for the ECG electrode, as suggested by the manufacturer. EEG data was digitized at 16-bit resolution and sampled at 5 kHz with a 0.1–250 Hz (3 dB point) bandpass filter applied online (Butterworth, 18 dB/octave roll off). The digitized data was transferred to a laptop computer via a fiber-optic cable.</p><p>Artifact removal from EEG data, specifically the removal of magnetic gradient and cardioballistic artifacts, was conducted using the Brain Vision Analyzer 2.0 software (Brain Products GmbH). The elimination of magnetic gradient artifacts was based on an algorithm initially proposed by <xref ref-type="bibr" rid="bib2">Allen et al., 2000</xref>. The process involves the creation of an artifact template through averaging EEG data over 41 consecutive fMRI volumes, which was subsequently subtracted from the EEG recordings. Additionally, cardioballistic artifacts were removed by employing a technique developed by <xref ref-type="bibr" rid="bib1">Allen et al., 1998</xref>, in which R peaks were detected via the EKG electrode, and a corrective template was computed from 21 successive heart beats and subtracted from the EEG data.</p><p>Subsequent to scanner artifact removal, data was downsampled to 500 Hz and exported into EEGLab software (<xref ref-type="bibr" rid="bib17">Delorme and Makeig, 2004</xref>). The data underwent further filtering using a 0.1–40 Hz band-pass Butterworth filter. Independent components analysis was applied to remove components associated with eye blinks, horizontal eye movements, and residual cardioballistic artifacts. The data were then converted to the average reference.</p></sec><sec id="s4-5"><title>EEG data analysis</title><sec id="s4-5-1"><title>Overview</title><p>According to the task design, the IAPS pictures were behaviorally irrelevant and thus the distractor to be ignored, while the moving dots were behaviorally relevant and thus the target to be attended. To minimize the transient effect resulting from the stimulus array onset and the possible effect resulting from anticipating the end of a trial, the EEG data from the beginning and the end of a trial were discarded, namely, the analyzed EEG data came from the period from 2 to 11 s post array onset, which contained the period from 2.3 to 10.4 s post stimulus array onset during which instances of coherent motion in the moving dots took place.</p></sec><sec id="s4-5-2"><title>Quantifying target processing</title><p>The moving dots were flickered at 4.29 Hz. For a given type of emotion trials (i.e. pleasant, neutral, or unpleasant), the SSVEP was computed by averaging all the trials within the type. Filtering the SSVEP between 4.29–0.5 Hz and 4.29+0.5 Hz yielded the data specific for target processing. Obtaining the magnitude of the band-pass filtered data at the whole trial level allowed the assessment of the overall strength of target processing; see <xref ref-type="fig" rid="fig1">Figure 1B</xref>. To assess target processing as a function of TFO, i.e., the temporal dynamics of target processing, the magnitude of the band-passed filtered data was obtained using a moving window approach, where the window duration was 0.5 s and the step size was 0.25 s. See <xref ref-type="fig" rid="fig1">Figure 1B</xref> for illustration.</p></sec><sec id="s4-5-3"><title>Quantifying distractor processing</title><p>The IAPS pictures were flickered at 6 Hz. Band-pass filtering the EEG data between 6–0.5 Hz and 6+0.5 Hz resulted in signals that were specific to distractor processing. Following a recent study where we showed that the emotion category of IAPS pictures can be decoded from scalp EEG data using the MVPA method (<xref ref-type="bibr" rid="bib10">Bo et al., 2022</xref>), we assessed distractor processing using an MVPA decoding approach at the whole trial level, as well as at the level of moving windows. The MVPA analysis was conducted with the linear support vector machine (SVM) method as implemented in the LibSVM package (<ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">http://www.csie.ntu.edu.tw/~cjlin/libsvm/</ext-link>) (<xref ref-type="bibr" rid="bib13">Chang and Lin, 2011</xref>). The decoding was between two types of emotion trials (e.g. pleasant vs neutral) or between all three types of emotion trials based on a one-vs-all strategy. Above-chance decoding accuracy (50% for pairwise decoding and 33.3% for three-way decoding) is taken to indicate distractor processing in the brain with higher decoding accuracy indicating stronger distractor processing. For both the whole trial and moving window analysis, the trials from each of the three different emotional categories were divided into three subsets of trials randomly. We averaged the trials within each subset to yield the subset SSVEP. For the whole trial analysis, we calculated the 6 Hz SSVEP over the whole trial, whereas for the moving window analysis, the 6 Hz SSVEP amplitude was obtained for each 0.5 s analysis window. For the decoding strategy, the SSVEP amplitude from the two subsets within each emotion category served as training data for constructing an SVM classifier, while the SSVEP amplitude from the third subset was used as testing data for calculating decoding accuracy. This process was iterated 100 times to ensure the stability of the decoding result, and the average of the decoding accuracy values was analyzed and reported (<xref ref-type="bibr" rid="bib6">Bae and Luck, 2019</xref>; <xref ref-type="bibr" rid="bib27">Haxby et al., 2014</xref>; <xref ref-type="bibr" rid="bib66">Zhang et al., 2024</xref>). See <xref ref-type="fig" rid="fig1">Figure 1B</xref> for an illustration of the method.</p></sec><sec id="s4-5-4"><title>Quantifying the relationship between target and distractor processing</title><p>To investigate the temporal relationship between target processing and distractor processing, we calculated the phase relationship between the target amplitude time series from the moving window approach which quantified the temporal fluctuation of the strength of target processing and the distractor decoding accuracy time series which quantified the temporal fluctuation of the strength of distractor processing. To investigate the effect of temporal competition between target processing and distractor processing, we correlated the relative phase relationship between the target processing time series and the distractor processing time series with behavioral performance.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation</p></fn><fn fn-type="con" id="con3"><p>Resources, Data curation, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con4"><p>Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con5"><p>Resources, Data curation, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Supervision, Investigation, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The experimental protocol was approved by the Institutional Review Board of the University of Florida. All participants gave written informed consent before participating in the study.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-106140-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data used in this study have been uploaded at Dryad and can be accessed via the link: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.xd2547dw5">https://doi.org/10.5061/dryad.xd2547dw5</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Xiong</surname><given-names>C</given-names></name><name><surname>Petro</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>RDK-IAPS paradigm EEG, target vs distractor</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.xd2547dw5</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by NSF grants BCS2318886 and BCS2318984 and NIH grant R01 MH125615.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>PJ</given-names></name><name><surname>Polizzi</surname><given-names>G</given-names></name><name><surname>Krakow</surname><given-names>K</given-names></name><name><surname>Fish</surname><given-names>DR</given-names></name><name><surname>Lemieux</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Identification of EEG events in the MR scanner: the problem of pulse artifact and a method for its subtraction</article-title><source>NeuroImage</source><volume>8</volume><fpage>229</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0361</pub-id><pub-id pub-id-type="pmid">9758737</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>PJ</given-names></name><name><surname>Josephs</surname><given-names>O</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A method for removing imaging artifact from continuous EEG recorded during functional MRI</article-title><source>NeuroImage</source><volume>12</volume><fpage>230</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1006/nimg.2000.0599</pub-id><pub-id pub-id-type="pmid">10913328</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amzica</surname><given-names>F</given-names></name><name><surname>Steriade</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Electrophysiological correlates of sleep delta waves</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>107</volume><fpage>69</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/s0013-4694(98)00051-0</pub-id><pub-id pub-id-type="pmid">9751278</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Giraud</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Transitions in neural oscillations reflect prediction errors generated in audiovisual speech</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>797</fpage><lpage>801</lpage><pub-id pub-id-type="doi">10.1038/nn.2810</pub-id><pub-id pub-id-type="pmid">21552273</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Doelling</surname><given-names>KB</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Delta-Beta coupled oscillations underlie temporal prediction accuracy</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3077</fpage><lpage>3085</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu103</pub-id><pub-id pub-id-type="pmid">24846147</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bae</surname><given-names>GY</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Decoding motion direction using the topography of sustained ERPs and alpha oscillations</article-title><source>NeuroImage</source><volume>184</volume><fpage>242</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.09.029</pub-id><pub-id pub-id-type="pmid">30223063</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basar</surname><given-names>E</given-names></name><name><surname>Basar-Eroglu</surname><given-names>C</given-names></name><name><surname>Karakas</surname><given-names>S</given-names></name><name><surname>Schürmann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Oscillatory brain theory: a new trend in neuroscience</article-title><source>IEEE Engineering in Medicine and Biology Magazine</source><volume>18</volume><fpage>56</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1109/51.765190</pub-id><pub-id pub-id-type="pmid">10337564</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Başar</surname><given-names>E</given-names></name><name><surname>Başar-Eroglu</surname><given-names>C</given-names></name><name><surname>Karakaş</surname><given-names>S</given-names></name><name><surname>Schürmann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Gamma, alpha, delta, and theta oscillations govern cognitive processes</article-title><source>International Journal of Psychophysiology</source><volume>39</volume><fpage>241</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/s0167-8760(00)00145-8</pub-id><pub-id pub-id-type="pmid">11163901</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Başar-Eroglu</surname><given-names>C</given-names></name><name><surname>Başar</surname><given-names>E</given-names></name><name><surname>Demiralp</surname><given-names>T</given-names></name><name><surname>Schürmann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>P300-response: possible psychophysiological correlates in delta and theta frequency channels. A review</article-title><source>International Journal of Psychophysiology</source><volume>13</volume><fpage>161</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/0167-8760(92)90055-g</pub-id><pub-id pub-id-type="pmid">1399755</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bo</surname><given-names>K</given-names></name><name><surname>Cui</surname><given-names>L</given-names></name><name><surname>Yin</surname><given-names>S</given-names></name><name><surname>Hu</surname><given-names>Z</given-names></name><name><surname>Hong</surname><given-names>X</given-names></name><name><surname>Kim</surname><given-names>S</given-names></name><name><surname>Keil</surname><given-names>A</given-names></name><name><surname>Ding</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Decoding the temporal dynamics of affective scene processing</article-title><source>NeuroImage</source><volume>261</volume><elocation-id>119532</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119532</pub-id><pub-id pub-id-type="pmid">35931307</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breska</surname><given-names>A</given-names></name><name><surname>Deouell</surname><given-names>LY</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural mechanisms of rhythm-based temporal prediction: Delta phase-locking reflects temporal predictability but not rhythmic entrainment</article-title><source>PLOS Biology</source><volume>15</volume><elocation-id>e2001665</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2001665</pub-id><pub-id pub-id-type="pmid">28187128</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spontaneous EEG oscillations reveal periodic sampling of visual attention</article-title><source>PNAS</source><volume>107</volume><fpage>16048</fpage><lpage>16053</lpage><pub-id pub-id-type="doi">10.1073/pnas.1004801107</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Lin</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>LIBSVM: A library for support vector machines</article-title><source>ACM Transactions on Intelligent Systems and Technology</source><volume>2</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1145/1961189.1961199</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chota</surname><given-names>S</given-names></name><name><surname>Leto</surname><given-names>C</given-names></name><name><surname>van Zantwijk</surname><given-names>L</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Attention rhythmically samples multi-feature objects in working memory</article-title><source>Scientific Reports</source><volume>12</volume><elocation-id>14703</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-022-18819-z</pub-id><pub-id pub-id-type="pmid">36038570</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Dunbar</surname><given-names>K</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>On the control of automatic processes: a parallel distributed processing account of the Stroop effect</article-title><source>Psychological Review</source><volume>97</volume><fpage>332</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.97.3.332</pub-id><pub-id pub-id-type="pmid">2200075</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cravo</surname><given-names>AM</given-names></name><name><surname>Rohenkohl</surname><given-names>G</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Temporal expectation enhances contrast sensitivity by phase entrainment of low-frequency oscillations in visual cortex</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>4002</fpage><lpage>4010</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4675-12.2013</pub-id><pub-id pub-id-type="pmid">23447609</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><volume>134</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Denison</surname><given-names>RN</given-names></name><name><surname>Tian</surname><given-names>KJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Anticipatory and evoked visual cortical dynamics of voluntary temporal attention</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.11.18.517084</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deweese</surname><given-names>MM</given-names></name><name><surname>Müller</surname><given-names>M</given-names></name><name><surname>Keil</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Extent and time-course of competition in visual cortex between emotionally arousing distractors and a concurrent task</article-title><source>The European Journal of Neuroscience</source><volume>43</volume><fpage>961</fpage><lpage>970</lpage><pub-id pub-id-type="doi">10.1111/ejn.13180</pub-id><pub-id pub-id-type="pmid">26790572</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname><given-names>L</given-names></name><name><surname>Marque</surname><given-names>P</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Theta oscillations modulate attentional search performance periodically</article-title><source>Journal of Cognitive Neuroscience</source><volume>27</volume><fpage>945</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00755</pub-id><pub-id pub-id-type="pmid">25390199</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Saalmann</surname><given-names>YB</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rhythmic sampling within and between objects despite sustained attention at a cued location</article-title><source>Current Biology</source><volume>23</volume><fpage>2553</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.10.063</pub-id><pub-id pub-id-type="pmid">24316204</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Pinsk</surname><given-names>MA</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A dynamic interplay within the frontoparietal network underlies rhythmic spatial attention</article-title><source>Neuron</source><volume>99</volume><fpage>842</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.038</pub-id><pub-id pub-id-type="pmid">30138590</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A rhythmic theory of attention</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>87</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.11.009</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franken</surname><given-names>P</given-names></name><name><surname>Chollet</surname><given-names>D</given-names></name><name><surname>Tafti</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The homeostatic regulation of sleep need is under genetic control</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>2610</fpage><lpage>2621</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-08-02610.2001</pub-id><pub-id pub-id-type="pmid">11306614</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franken</surname><given-names>P</given-names></name><name><surname>Dijk</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Sleep and circadian rhythmicity as entangled processes serving homeostasis</article-title><source>Nature Reviews. Neuroscience</source><volume>25</volume><fpage>43</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1038/s41583-023-00764-z</pub-id><pub-id pub-id-type="pmid">38040815</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frohlich</surname><given-names>J</given-names></name><name><surname>Toker</surname><given-names>D</given-names></name><name><surname>Monti</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Consciousness among delta waves: a paradox?</article-title><source>Brain</source><volume>144</volume><fpage>2257</fpage><lpage>2277</lpage><pub-id pub-id-type="doi">10.1093/brain/awab095</pub-id><pub-id pub-id-type="pmid">33693596</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding neural representational spaces using multivariate pattern analysis</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>435</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062012-170325</pub-id><pub-id pub-id-type="pmid">25002277</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich</surname><given-names>RF</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Oscillatory dynamics of prefrontal cognitive control</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>916</fpage><lpage>930</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.09.007</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich</surname><given-names>RF</given-names></name><name><surname>Huang</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>G</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Prefrontal cortex modulates posterior alpha oscillations during top-down guided visual perception</article-title><source>PNAS</source><volume>114</volume><fpage>9457</fpage><lpage>9462</lpage><pub-id pub-id-type="doi">10.1073/pnas.1705965114</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich</surname><given-names>RF</given-names></name><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Szczepanski</surname><given-names>SM</given-names></name><name><surname>Lin</surname><given-names>JJ</given-names></name><name><surname>Parvizi</surname><given-names>J</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural mechanisms of sustained attention are rhythmic</article-title><source>Neuron</source><volume>99</volume><fpage>854</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.032</pub-id><pub-id pub-id-type="pmid">30138591</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich</surname><given-names>RF</given-names></name><name><surname>Breska</surname><given-names>A</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural entrainment and network resonance in support of top-down guided attention</article-title><source>Current Opinion in Psychology</source><volume>29</volume><fpage>82</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.copsyc.2018.12.016</pub-id><pub-id pub-id-type="pmid">30690228</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hindi Attar</surname><given-names>C</given-names></name><name><surname>Müller</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Selective attention to task-irrelevant emotional distractors is unaffected by the perceptual load associated with a foreground task</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e37186</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0037186</pub-id><pub-id pub-id-type="pmid">22649513</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Behavioral oscillation in priming: competing perceptual predictions conveyed in alternating theta-band rhythms</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>2830</fpage><lpage>2837</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4294-14.2015</pub-id><pub-id pub-id-type="pmid">25673869</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Saliency-based rhythmic coordination of perceptual predictions</article-title><source>Journal of Cognitive Neuroscience</source><volume>32</volume><fpage>201</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01371</pub-id><pub-id pub-id-type="pmid">30633602</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>He</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The adaptive flexibility of rhythmic attentional sampling in attending to multiple targets</article-title><source>Journal of Experimental Psychology. General</source><volume>153</volume><fpage>26</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1037/xge0001468</pub-id><pub-id pub-id-type="pmid">37707471</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>S</given-names></name><name><surname>De Weerd</surname><given-names>P</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Mechanisms of directed attention in the human extrastriate cortex as revealed by functional MRI</article-title><source>Science</source><volume>282</volume><fpage>108</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1126/science.282.5386.108</pub-id><pub-id pub-id-type="pmid">9756472</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>S</given-names></name><name><surname>Pinsk</surname><given-names>MA</given-names></name><name><surname>De Weerd</surname><given-names>P</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Increased activity in human visual cortex during directed attention in the absence of visual stimulation</article-title><source>Neuron</source><volume>22</volume><fpage>751</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)80734-5</pub-id><pub-id pub-id-type="pmid">10230795</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>S</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Mechanisms of visual attention in the human cortex</article-title><source>Annual Review of Neuroscience</source><volume>23</volume><fpage>315</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.315</pub-id><pub-id pub-id-type="pmid">10845067</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>S</given-names></name><name><surname>Pinsk</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Visual attention as a multilevel selection process</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>4</volume><fpage>483</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.3758/CABN.4.4.483</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Phase resetting as a mechanism for supramodal attentional control</article-title><source>Neuron</source><volume>64</volume><fpage>300</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.10.022</pub-id><pub-id pub-id-type="pmid">19914178</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kubetschek</surname><given-names>C</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Delta/Theta band EEG activity shapes the rhythmic perceptual sampling of auditory scenes</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>2370</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-82008-7</pub-id><pub-id pub-id-type="pmid">33504860</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Karmos</surname><given-names>G</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Ulbert</surname><given-names>I</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Entrainment of neuronal oscillations as a mechanism of attentional selection</article-title><source>Science</source><volume>320</volume><fpage>110</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1126/science.1154735</pub-id><pub-id pub-id-type="pmid">18388295</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landau</surname><given-names>AN</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attention samples stimuli rhythmically</article-title><source>Current Biology</source><volume>22</volume><fpage>1000</fpage><lpage>1004</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.03.054</pub-id><pub-id pub-id-type="pmid">22633805</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Lang</surname><given-names>PJ</given-names></name><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Cuthbert</surname><given-names>BN</given-names></name></person-group><year iso-8601-date="1997">1997</year><source>International affective picture system (IAPS): Technical manual and affective ratings</source><publisher-name>NIMH Center for the Study of Emotion and Attention</publisher-name></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lavie</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Distracted and confused?: Selective attention under load</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>75</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.12.004</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michel</surname><given-names>R</given-names></name><name><surname>Dugué</surname><given-names>L</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Distinct contributions of alpha and theta rhythms to perceptual and attentional sampling</article-title><source>The European Journal of Neuroscience</source><volume>55</volume><fpage>3025</fpage><lpage>3039</lpage><pub-id pub-id-type="doi">10.1111/ejn.15154</pub-id><pub-id pub-id-type="pmid">33609313</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mo</surname><given-names>C</given-names></name><name><surname>Lu</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>B</given-names></name><name><surname>Jia</surname><given-names>J</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name><name><surname>Fang</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Competing rhythmic neural representations of orientations during concurrent attention to multiple orientation features</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>5264</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-13282-3</pub-id><pub-id pub-id-type="pmid">31748562</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morillon</surname><given-names>B</given-names></name><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Keitel</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Prominence of delta oscillatory rhythms in the motor cortex and their relevance for auditory and speech perception</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>107</volume><fpage>136</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2019.09.012</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Müller</surname><given-names>MM</given-names></name><name><surname>Andersen</surname><given-names>SK</given-names></name><name><surname>Keil</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Time course of competition for visual processing resources between emotional pictures and foreground task</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>1892</fpage><lpage>1899</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm215</pub-id><pub-id pub-id-type="pmid">18063562</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>G</given-names></name><name><surname>Groeger</surname><given-names>JA</given-names></name><name><surname>Greene</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Twenty years of load theory—Where are we now, and where should we go next?</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>1316</fpage><lpage>1340</lpage><pub-id pub-id-type="doi">10.3758/s13423-015-0982-5</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pagnotta</surname><given-names>MF</given-names></name><name><surname>Riddle</surname><given-names>J</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Multiplexed levels of cognitive control through delta and theta neural oscillations</article-title><source>Journal of Cognitive Neuroscience</source><volume>36</volume><fpage>916</fpage><lpage>935</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_02124</pub-id><pub-id pub-id-type="pmid">38319885</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Orienting of attention</article-title><source>The Quarterly Journal of Experimental Psychology</source><volume>32</volume><fpage>3</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1080/00335558008248231</pub-id><pub-id pub-id-type="pmid">7367577</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name><name><surname>Inhoff</surname><given-names>AW</given-names></name><name><surname>Friedrich</surname><given-names>FJ</given-names></name><name><surname>Cohen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Isolating attentional systems: A cognitive-anatomical analysis</article-title><source>Psychobiology</source><volume>15</volume><fpage>107</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.3758/BF03333099</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name><name><surname>Fox</surname><given-names>PT</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Localization of cognitive operations in the human brain</article-title><source>Science</source><volume>240</volume><fpage>1627</fpage><lpage>1631</lpage><pub-id pub-id-type="doi">10.1126/science.3289116</pub-id><pub-id pub-id-type="pmid">3289116</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Re</surname><given-names>D</given-names></name><name><surname>Inbar</surname><given-names>M</given-names></name><name><surname>Richter</surname><given-names>CG</given-names></name><name><surname>Landau</surname><given-names>AN</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Feature-based attention samples stimuli rhythmically</article-title><source>Current Biology</source><volume>29</volume><fpage>693</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.01.010</pub-id><pub-id pub-id-type="pmid">30744973</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Low-frequency neuronal oscillations as instruments of sensory selection</article-title><source>Trends in Neurosciences</source><volume>32</volume><fpage>9</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2008.09.012</pub-id><pub-id pub-id-type="pmid">19012975</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seidl</surname><given-names>KN</given-names></name><name><surname>Peelen</surname><given-names>MV</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural evidence for distracter suppression during visual search in real-world scenes</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>11812</fpage><lpage>11819</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1693-12.2012</pub-id><pub-id pub-id-type="pmid">22915122</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Senoussi</surname><given-names>M</given-names></name><name><surname>Moreland</surname><given-names>JC</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Dugué</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Attention explores space periodically at the theta frequency</article-title><source>Journal of Vision</source><volume>19</volume><elocation-id>22</elocation-id><pub-id pub-id-type="doi">10.1167/19.5.22</pub-id><pub-id pub-id-type="pmid">31121012</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stefanics</surname><given-names>G</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Hernádi</surname><given-names>I</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Ulbert</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Phase entrainment of human delta oscillations can mediate the effects of expectation on reaction speed</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>13578</fpage><lpage>13585</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0703-10.2010</pub-id><pub-id pub-id-type="pmid">20943899</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thigpen</surname><given-names>N</given-names></name><name><surname>Petro</surname><given-names>NM</given-names></name><name><surname>Oschwald</surname><given-names>J</given-names></name><name><surname>Oberauer</surname><given-names>K</given-names></name><name><surname>Keil</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Selection of visual objects in perception and working memory one at a time</article-title><source>Psychological Science</source><volume>30</volume><fpage>1259</fpage><lpage>1272</lpage><pub-id pub-id-type="doi">10.1177/0956797619854067</pub-id><pub-id pub-id-type="pmid">31322983</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torres-Herraez</surname><given-names>A</given-names></name><name><surname>Watson</surname><given-names>TC</given-names></name><name><surname>Rondi-Reig</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Delta oscillations coordinate intracerebellar and cerebello-hippocampal network dynamics during sleep</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>2268</fpage><lpage>2281</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1479-21.2021</pub-id><pub-id pub-id-type="pmid">35091502</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Werf</surname><given-names>OJ</given-names></name><name><surname>Schuhmann</surname><given-names>T</given-names></name><name><surname>de Graaf</surname><given-names>T</given-names></name><name><surname>Ten Oever</surname><given-names>S</given-names></name><name><surname>Sack</surname><given-names>AT</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Investigating the role of task relevance during rhythmic sampling of spatial locations</article-title><source>Scientific Reports</source><volume>13</volume><elocation-id>12707</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-023-38968-z</pub-id><pub-id pub-id-type="pmid">37543646</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual attention: a rhythmic process?</article-title><source>Current Biology</source><volume>23</volume><fpage>R1110</fpage><lpage>R1112</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.11.006</pub-id><pub-id pub-id-type="pmid">24355791</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Scholl</surname><given-names>J</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rhythmic fluctuations in evidence accumulation during decision making in the human brain</article-title><source>Neuron</source><volume>76</volume><fpage>847</fpage><lpage>858</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.015</pub-id><pub-id pub-id-type="pmid">23177968</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zalta</surname><given-names>A</given-names></name><name><surname>Petkoski</surname><given-names>S</given-names></name><name><surname>Morillon</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Natural rhythms of periodic temporal attention</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>1051</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-14888-8</pub-id><pub-id pub-id-type="pmid">32103014</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>G</given-names></name><name><surname>Carrasco</surname><given-names>CD</given-names></name><name><surname>Winsler</surname><given-names>K</given-names></name><name><surname>Bahle</surname><given-names>B</given-names></name><name><surname>Cong</surname><given-names>F</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Assessing the effectiveness of spatial PCA on SVM-based decoding of EEG data</article-title><source>NeuroImage</source><volume>293</volume><elocation-id>120625</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2024.120625</pub-id><pub-id pub-id-type="pmid">38704056</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><p>In this appendix, we considered several issues related to this study: (1) signal processing issues underlying the spectral analysis of various time series data, (2) quantifying distractor processing with MVPA decoding, (3) effect of moving window parameters, and (4) robustness of decoding analysis.</p><sec sec-type="appendix" id="s8"><title>Signal processing issues</title><p>The power of the 4.29 Hz (the target) and 6 Hz (the distractor) signals are both modulated at around 1 Hz. In the Fourier spectrum, the sidebands should be visible at around 3.29 Hz and 5.29 Hz (4.29 Hz±1 Hz), as well as at around 5 Hz and 7 Hz (6 Hz±1 Hz). However, there are no clear peaks visible at these frequencies from <xref ref-type="fig" rid="fig2">Figure 2B</xref>. We examine the reason here.</p><p>For clean sinusoidal signals with periodic amplitude modulation, we should observe sidebands. However, biological data is noisy, and the SSVEP from each subject shows significant variability in SNR (see definition below). SNR determines whether we can observe sideband frequencies or not. We demonstrate this point first through simulation and then on our data.</p></sec><sec sec-type="appendix" id="s9"><title>Simulation</title><p>Simulated signals were generated by adding a 4.29 Hz component and a 6 Hz component together. These were the same frequency components as in our experiment and also, similar to what we observed in the data, the magnitude of the 6 Hz component was made ½ that of the 4.29 Hz component. We then modulated the amplitude of these components at 1 Hz (the same as that observed in our data). The time course is shown in the left panel of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>. In the right panel of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, we showed the Fourier spectrum, where the sidebands for both the 4.29 Hz component (at 3.29 Hz and 5.29 Hz) and the 6 Hz component (at 5 Hz and 7 Hz) are clearly seen. Note that there was no noise in this case.</p><p>Next, we added noise to the same signal. The SNR is defined as:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>⋅</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle SNR_{dB}=10\cdot log_{10}\frac{P_{signal}}{P_{noise}}$$\end{document}</tex-math></alternatives></disp-formula></p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Simulation results.</title><p>(<bold>A</bold>) The signal containing a 4.29 Hz component and a 6 Hz component where the 6 Hz signal’s magnitude is about half that of the 4.29 Hz signal. The amplitude is modulated at 1 Hz. No noise is added. (<bold>B</bold>) Low level of noise is added to the signal in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>, where the signal-to-noise ratio (SNR) = 12.72 dB. Sidebands are still seen. (<bold>C</bold>) Middle level of noise is added to the signal in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref> where the SNR = 5.38 dB. Sidebands become difficult to see. (<bold>D</bold>) High level of noise is added to the signal in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref> where the SNR = 2.24 dB, sidebands become more indistinguishable from the noise floor. Red dots indicate the location of the main frequency components and the locations where the sidebands should appear.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig1-v1.tif"/></fig><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Experimental data.</title><p>(<bold>A</bold>) The time course of the steady-state visual evoked potential (SSVEP) and its Fourier spectrum from a subject with high signal-to-noise ratio (SNR). The sidebands can be observed. (<bold>B</bold>) The time course and its Fourier spectrum from a subject with low SNR. The sidebands are indistinguishable from the noise floor. (<bold>C</bold>) The averaged Fourier spectrum from five highest SNR subjects and five lowest SNR subjects. Again, for subjects with high SNR, the sidebands are identifiable, whereas for subjects with low SNR, the sidebands are not identifiable.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig2-v1.tif"/></fig><p>where the signal power is defined to be the average Fourier power within 3.8–4.8 Hz and 5.5–6.5 Hz and the noise power is the average Fourier power within 0–3 Hz and 7–10 Hz. <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B</xref>, <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1C</xref>, and <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1D</xref> show the results after adding progressively more noise to the simulated signal. When the noise level is low, e.g., SNR = 12.72 dB (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B</xref>), the sidebands are still clearly visible, as shown in the right panel of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B</xref>, although they are not as prominent as in the right panel of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>. When more noise is added, as shown in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1C</xref>, where SNR = 5.38 dB, which is similar to what we see in a typical high SNR subject in our data, the sidebands are beginning to become indistinguishable from the noise floor. <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1D</xref> shows a case when an even higher level of noise is added, e.g., SNR = 2.24 dB, the sidebands become even more indistinguishable from the noise floor.</p></sec><sec sec-type="appendix" id="s10"><title>Experimental data</title><p>Now we demonstrate the impact of SNR on sidebands in experimental data. <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2A and B</xref> compares two subjects, one with relatively high and the other relatively low SNRs, respectively. For the subject with high SNR, the sidebands are still somewhat distinguishable from the noise floor, whereas for the subject with lower SNR, the sidebands are no longer visible. In <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2C</xref>, we averaged the Fourier spectra of the five subjects with the highest SNR and that of the five subjects with the lowest SNR, and the results again indicate that SNR plays a major role in determining whether the sidebands can be seen or not. For the Fourier spectrum averaged across all subjects, which is the figure shown in the manuscript, because of the influence of low SNR subjects, the sidebands are not clearly visible.</p></sec><sec sec-type="appendix" id="s11"><title>Decoding distractors</title><p>In the SSVEP literature, signal amplitude at the flicker frequency is the main variable for quantifying the processing of the flickering stimulus. In this work, we treated the scalp pattern of the signal amplitude at the distractor flicker frequency as input features and subjected them to decoding analysis. Below we show that the decoding accuracy is a more suitable variable for quantifying distractor processing.</p><sec sec-type="appendix" id="s11-1"><title>Whole trial analysis</title><p>The target amplitude (4.29 Hz) and the distractor amplitude (6 Hz) were extracted from each subject and displayed in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3A</xref>. The strong correlation suggests that there is significant power leakage from the stronger target frequency into the weaker distractor frequency. However, when the target amplitude and distractor decoding accuracy are plotted, no correlation was found, as shown in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3B</xref>, suggesting that the target amplitude has no influence on distractor decoding accuracy.</p><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Steady-state visual evoked potential (SSVEP) amplitude analysis at the whole trial level.</title><p>(<bold>A</bold>) Target amplitude vs distractor amplitude, where the correlation is r=0.7992 (p=0.000006), suggesting the 6 Hz signal amplitude is strongly influenced by the 4.29 Hz signal amplitude. (<bold>B</bold>) Target amplitude vs distractor decoding accuracy, where the correlation is r=0.0536 (p=0.7908), suggesting that the decoding accuracy as an index of distractor processing is not influenced by the 4.29 Hz target amplitude.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig3-v1.tif"/></fig></sec><sec sec-type="appendix" id="s11-2"><title>Moving window analysis</title><p>Similar results can be observed at the moving window level. The target amplitude time series and the distractor amplitude time series were extracted from each subject and the relationship between the two time series assessed. The relative phase is also correlated with behavior. <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4A</xref> shows that the relative phase is narrowly distributed around 0.23±0.05π, which is confirmed by the K-S statistic of 0.46 in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4B</xref>, demonstrating that the relative phase distribution is significantly different from the uniform distribution at p=0.00001. This means that the power leakage from the target time series impacts the distractor time series, making it nearly phase locked to the target time series. It is not surprising that the relative phase between the two amplitude time series does not predict task performance (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4C</xref>).</p><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Moving window analysis.</title><p>(<bold>A</bold>) The relative phase between the target amplitude time series and the distractor amplitude time series. (<bold>B</bold>) Kolmogorov-Smirnov test showed that the relative phase distribution is significantly different from the uniform distribution. (<bold>C</bold>) Relative phase vs task performance. r=0.1940 (p=0.3322) means that there is no significant correlation between amplitude relative phase and task performance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig4-v1.tif"/></fig><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Temporal dynamics of target and distractor processing with 0.1 s window length and 0.05 s step size.</title><p>(<bold>A</bold>) (<bold>i</bold>) Target processing time series from the moving window approach for a representative subject (left) and its Fourier spectrum (right). (<bold>A</bold>) (ii) The average Fourier spectrum across 27 subjects. (<bold>B</bold>) (<bold>i</bold>) Distractor processing time series from the moving window approach for a representative subject (left) and its Fourier spectrum (right). (<bold>B</bold>) (<bold>ii</bold>) The average Fourier spectrum across 27 subjects.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig5-v1.tif"/></fig></sec></sec><sec sec-type="appendix" id="s12"><title>Effect of moving window parameters</title><p>We redid the moving window analysis using a different set of windowing parameters, e.g., a 0.1 s sliding window length with a 0.05 s step size. <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref> demonstrates that the strength of both target and distractor processing fluctuates around ~1 Hz, both at the individual and group levels. Additionally, <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> shows that the relative phase between target and distractor processing time series exhibits a uniform distribution across subjects. For the relationship between relative phase and behavior, <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> illustrates two representative cases: a high-performing subject with 84.34% task accuracy exhibited a relative phase of 0.9483π, while a low-performing subject with 30.95% accuracy showed a phase of 0.29π. At the group level, a significant positive correlation between relative phase and task performance was found (r=0.6343, p=0.0004), as shown in <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>. All these results, aligning closely with our original findings, suggest that the conclusions are not dependent on windowing parameters.</p><p>To further validate our findings, we also employed the Hilbert transform to extract amplitude envelopes of the target and distractor signals on a time-point-by-time-point basis, providing a window-free estimate of signal strength (<xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref> and <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>). The results remain consistent with both the original findings and the new sliding window analyses (above). <xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref> reveals ~1 Hz fluctuations in target and distractor processing at both individual and group levels. <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref> confirms a uniform distribution of the relative phase. As shown in <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>, the relative phase was 0.9567π for a high-performing subject (84.34% accuracy) and 0.2247π for a low-performing subject (28.57% accuracy). At the group level, a significant positive correlation was again observed between relative phase and task performance (r=0.4020, p=0.0376), as shown in <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>.</p></sec><sec sec-type="appendix" id="s13"><title>Robustness of decoding analysis</title><p>To test robustness of the decoding analysis, we implemented a random permutation procedure in which trial labels were randomly shuffled to construct a null-hypothesis distribution of decoding accuracy. We then compared the decoding accuracy from the actual data to this distribution. <xref ref-type="fig" rid="app1fig9">Appendix 1—figure 9</xref> shows the results based on 1000 permutations. For each of the three pairwise classifications—pleasant vs neutral, unpleasant vs neutral, and pleasant vs unpleasant—as well as the three-way classification, the actual decoding accuracies fall far outside the null-hypothesis distribution (p&lt;0.001), and the effect sizes are extremely large. These findings indicate that the observed decoding accuracies are statistically significant and robust in terms of both statistical inference and effect size.</p><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Target-distractor competition analysis with 0.1 s window length and 0.05 s step size.</title><p>(<bold>A</bold>) Phase polar histogram for the relative phase between target process time series and distractor processing time series (1 Hz). The average relative phase is 0.44π. (<bold>B</bold>) Kolmogorov-Smirnov test showed that the relative phase distribution is not different from uniform distribution. (<bold>C</bold>) Temporal relationship between target processing and distractor processing for (<bold>i</bold>) a high performer (accuracy=83.84%; relative phase=0.9483π) and (<bold>ii</bold>) a low performer (accuracy=30.95%; relative phase=0.29π). (<bold>D</bold>) Task performance vs 1 Hz relative phase. The significant positive correlation (r=0.6343, p=0.0004) means that the more separated the target and distractor sampling within the 1 Hz oscillation cycle, the better the behavioral performance. CDF: cumulative distribution function</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig6-v1.tif"/></fig><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Temporal dynamics of target and distractor processing with Hilbert transformed target and distractor processing time series.</title><p>(<bold>A</bold>) (<bold>i</bold>) Target processing time series from a representative subject (left) and its Fourier spectrum (right). (<bold>A</bold>) (<bold>ii</bold>) The average spectrum across 27 subjects. (<bold>B</bold>) (<bold>i</bold>) Distractor processing time series for a representative subject (left) and its Fourier spectrum (right). (<bold>B</bold>) (<bold>ii</bold>) The average spectrum across 27 subjects.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig7-v1.tif"/></fig><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Target-distractor competition analysis with Hilbert transformed target and distractor processing time series.</title><p>(<bold>A</bold>) Phase polar histogram for the relative phase between target process time series and distractor processing time series (1 Hz). The average relative phase is 0.63π. (<bold>B</bold>) Kolmogorov-Smirnov test showed that the relative phase distribution is not different from uniform distribution. (<bold>C</bold>) Temporal relationship between target processing and distractor processing for (<bold>i</bold>) a high performer (accuracy=83.84%; relative phase=0.9567π) and (<bold>ii</bold>) a low performer (accuracy=28.57%; relative phase=0.2247π). (<bold>D</bold>) Task performance vs 1 Hz relative phase. The significant positive correlation (r=0.4020, p=0.0376) means that the more separated the target and distractor sampling within the 1 Hz oscillation cycle, the better the behavioral performance. CDF: cumulative distribution function.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig8-v1.tif"/></fig><fig id="app1fig9" position="float"><label>Appendix 1—figure 9.</label><caption><title>Comparison of actual decoding accuracy against the distribution of random permutation decoding accuracy.</title><p>Random permutation decoding accuracy from (<bold>A</bold>) pleasant vs neutral, (<bold>B</bold>) unpleasant vs neutral, (<bold>C</bold>) pleasant vs unpleasant, and (<bold>D</bold>) three-way. In all four conditions, the actual decoding accuracy is significantly above chance level at p&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-app1-fig9-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106140.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>O'Connell</surname><given-names>Redmond G</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Trinity College Dublin</institution><country>Ireland</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>This work presents <bold>important</bold> information on rhythmicity of overlapping target and distractor processing and how this affects behaviour. The methods are, in general, clearly laid out and defensible, with several supplementary analyses leading to a <bold>solid</bold> base of evidence for their claims.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106140.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Using a combination of EEG and behavioural measurements, the authors investigate the degree to which processing of spatially-overlapping targets (coherent motion) and distractors (affective images) are sampled rhythmically and how this affects behaviour. They found that both target processing (via measurement of amplitude modulations of SSVEP amplitude to target frequency) and distractor processing (via MVPA decoding accuracy of bandpassed EEG relative to distractor SSVEP frequency) displayed a pronounced rhythm at ~1Hz, time-locked to stimulus onset. Furthermore, the relative phase of this target/distractor sampling predicted accuracy of coherent motion detection across participants.</p><p>Strengths:</p><p>- The authors are addressing a very interesting question with respect to sampling of targets and distractors, using neurophysiological measurements to their advantage in order to parse out target and distractor processing.</p><p>- The general EEG analysis pipeline is sensible and well-described.</p><p>- The main result of rhythmic sampling of targets and distractors is striking and very clear even on a participant-level.</p><p>- The authors have gone to quite a lot of effort to ensure the validity of their analyses, especially in the Supplementary Material.</p><p>- It is incredibly striking how the phase of both target and distractor processing are so aligned across trials for a given participant. I would have thought that any endogenous fluctuation in attention or stimulus processing like that would not be so phase aligned. I know there is literature on phase resetting in this context, the results seem very strong here and it is worth noting. The authors have performed many analyses to rule out signal processing artifacts, e.g. the sideband and beating frequency analyses.</p><p>Weaknesses:</p><p>- In general, the representation of target and distractor processing is a bit of a reach. Target processing is represented by SSVEP amplitude, which is going to most likely be related to the contrast of the dots, as opposed to representing coherent motion energy which is the actual target. These may well be linked (e.g. greater attention to the coherent motion task might increase SSVEP amplitude) but I would call it a limitation of the interpretation. Decoding accuracy of emotional content makes sense as a measure of distractor processing, and the supplementary analysis comparing target SSVEP amplitude to distractor decoding accuracy is duly noted. Overall, this limitation remains and has been noted in the Limitations section.</p><p>- Then comparing SSVEP amplitude to emotional category decoding accuracy feels a bit like comparing apples with oranges. They have different units and scales and reflect probably different neural processes. Is the result the authors find not a little surprising in this context? This relationship does predict performance and is thus intriguing, but I think this methodological aspect needs to be discussed further. For example, is the phase relationship with behaviour a result of a complex interaction between different levels of processing (fundamental contrast vs higher order emotional processing)? Again, this has been noted in the Limitations section, but changing the data to z-scores doesn't really take care of the conceptual issue, i.e. that on-screen contrast changes would necessarily be distracting during emotional category decision-making.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106140.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In this study, Xiong et al. investigate whether rhythmic sampling - a process typically observed in the attended processing of visual stimuli - extends to task-irrelevant distractors. By using EEG with frequency tagging and multivariate pattern analysis (MVPA), they aimed to characterize the temporal dynamics of both target and distractor processing and examine whether these processes oscillate in time. The central hypothesis is that target and distractor processing occur rhythmically, and the phase relationship between these rhythms correlates with behavioral performance.</p><p>Major Strengths</p><p>(1) The extension of rhythmic attentional sampling to include distractors is a novel and interesting question.</p><p>(2) The decoding of emotional distractor content using MVPA from SSVEP signals is an elegant solution to the problem of assessing distractor engagement in the absence of direct behavioral measures.</p><p>(3) The finding that relative phase (between 1 Hz target and distractor processes) predicts behavioral performance is compelling.</p><p>Major Weaknesses and Limitations</p><p>(1) The central claim of 1 Hz rhythmic sampling is insufficiently validated. The windowing procedure (0.5s windows with 0.25s step) inherently restricts frequency resolution, potentially biasing toward low-frequency components like 1 Hz. Testing different window durations or providing controls would significantly strengthen this claim.</p><p>(2) The study lacks a baseline or control condition without distractors. This makes it difficult to determine whether the distractor-related decoding signals or the 1 Hz effect reflect genuine distractor processing or more general task dynamics.</p><p>(3) The pairwise decoding accuracies for distractor categories hover close to chance (~55%), raising concerns about robustness. While statistically above chance, the small effect sizes need careful interpretation, particularly when linked to behavior.</p><p>(4) Neither target nor distractor signal strength (SSVEP amplitude) correlates with behavioral accuracy. The study instead relies heavily on relative phase, which-while interesting-may benefit from additional converging evidence.</p><p>(5) Phase analysis is performed between different types of signals hindering their interpretability (time-resolved SSVEP amplitude and time-resolved decoding accuracy).</p><p>The authors largely achieved their stated goal of assessing rhythmic sampling of distractors. However, the conclusions drawn - particularly regarding the presence of 1 Hz rhythmicity - rest on analytical choices that should be scrutinized further. While the observed phase-performance relationship is interesting and potentially impactful, the lack of stronger and convergent evidence on the frequency component itself reduces confidence in the broader conclusions.</p><p>If validated, the findings will advance our understanding of attentional dynamics and competition in complex visual environments. Demonstrating that ignored distractors can be rhythmically sampled at similar frequencies to targets has implications for models of attention and cognitive control. However, the methodological limitations currently constrain the paper's impact.</p><p>Additional Considerations</p><p>• The use of EEG-fMRI is mentioned but not leveraged. If BOLD data were collected, even exploratory fMRI analyses (e.g., distractor modulation in visual cortex) could provide valuable converging evidence.</p><p>• In turn, removal of fMRI artifacts might introduce biases or alter the data. For instance, the authors might consider investigating potential fMRI artifact harmonics around 1 Hz to address concerns regarding induced spectral components.</p><p>Comments on revisions:</p><p>The authors have addressed my previous points, and the manuscript is substantially improved. The key methodological clarifications have been incorporated, and the interpretation of findings has been appropriately moderated. I have no further major concerns.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106140.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Xiong</surname><given-names>Changhao</given-names></name><role specific-use="author">Author</role><aff><institution>University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Petro</surname><given-names>Nathan M</given-names></name><role specific-use="author">Author</role><aff><institution>Boys Town National Research Hospital</institution><addr-line><named-content content-type="city">Boys Town</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Bo</surname><given-names>Ke</given-names></name><role specific-use="author">Author</role><aff><institution>Dartmouth College</institution><addr-line><named-content content-type="city">Hanover</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Cui</surname><given-names>Lihan</given-names></name><role specific-use="author">Author</role><aff><institution>University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Keil</surname><given-names>Andreas</given-names></name><role specific-use="author">Author</role><aff><institution>University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Ding</surname><given-names>Mingzhou</given-names></name><role specific-use="author">Author</role><aff><institution>J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews</p><disp-quote content-type="editor-comment"><p><bold>Reviewer 1:</bold></p><p>(1) In general, the representation of target and distractor processing is a bit of a reach. Target processing is represented by SSVEP amplitude, which is most likely going to be related to the contrast of the dots, as opposed to representing coherent motion energy, which is the actual target. These may well be linked (e.g., greater attention to the coherent motion task might increase SSVEP amplitude), but I would call it a limitation of the interpretation. Decoding accuracy of emotional content makes sense as a measure of distractor processing, and the supplementary analysis comparing target SSVEP amplitude to distractor decoding accuracy is duly noted.</p></disp-quote><p>We agree with the reviewer. The SSVEP amplitude of the target at the whole trial level indeed reflected the combined effect of the stimulus parameters (e.g., contrast of the moving dots) as well as attention. However, the time course of the target SSVEP amplitude within a trial, derived from the moving window analysis, reflected the temporal fluctuations of target processing, since the stimulus parameters remained the same during the trial. We now make this clearer in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>(2) Comparing SSVEP amplitude to emotional category decoding accuracy feels a bit like comparing apples with oranges. They have different units and scales and probably reflect different neural processes. Is the result the authors find not a little surprising in this context? This relationship does predict performance and is thus intriguing, but I think this methodological aspect needs to be discussed further. For example, is the phase relationship with behaviour a result of a complex interaction between different levels of processing (fundamental contrast vs higher order emotional processing)?</p></disp-quote><p>Traditionally, the SSVEP amplitude at the distractor frequency is used to quantify distractor processing. Given that the target SSVEP amplitude is stronger than that of the distractor, it is possible that the distractor SSVEP amplitude is contaminated by the target SSVEP amplitude due to spectral power leakage; see Figure S4 for a demonstration of this. Because of this issue we therefore introduced the use of decoding accuracy as an index of distractor processing. The lack of correlation between the distractor SSVEP amplitude and the distractor decoding accuracy, although it is kind of like comparing apples with oranges as pointed out by the reviewer, serves the purpose of showing that these two measures are not co-varying, and the use of decoding accuracy is free from the influence of the distractor SSVEP amplitude which is influenced by the target SSVEP amplitude. Also, to address the apples-vs-oranges issue, the correlation was computed on normalized time series, in which a z-score time series replaced the original time series so that the correlated variables are dimensionless. Regarding the question of assessing the relation between behavior and different levels of processing, we do not have means to address it, given that we are not able to empirically separate the effects of stimulus parameters versus attention.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer 2:</bold></p><p>(1) Incomplete Evidence for Rhythmicity at 1 Hz: The central claim of 1 Hz rhythmic sampling is insufficiently validated. The windowing procedure (0.5s windows with 0.25s step) inherently restricts frequency resolution, potentially biasing toward low-frequency components like 1 Hz. Testing different window durations or providing controls would significantly strengthen this claim.</p></disp-quote><p>We appreciate the reviewer’s insightful suggestion. In response, we tested different windowing parameters, e.g., 0.1s sliding window with a 0.05s step size. Figure S5 demonstrates that the strength of both target and distractor processing fluctuates around ~1 Hz, both at the individual and group levels. Additionally, Figures S6(A) and S6(B) show that the relative phase between target and distractor processing time series exhibits a uniform distribution across subjects. In terms of the relation between relative phase and behavior, Figure S6(C) illustrates two representative cases: a high-performing subject with 84.34% task accuracy exhibited a relative phase of 0.9483π (closer to π), while a low-performing subject with 30.95% accuracy showed a phase of 0.29π close to 0. At the group level, a significant positive correlation between relative phase and task performance was found (r = 0.6343, p = 0.0004), as shown in Figure S6(D). All these results, aligning closely with our original findings (0.5s window length and 0.25s step size), suggest that the conclusions are not dependent on windowing parameters. We discuss these results in the revised manuscript.</p><p>To further validate our findings, we also employed the Hilbert transform to extract amplitude envelopes of the target and distractor signals on a time-point-by-time-point basis, providing a window-free estimate of signal strength (Figures R3 and R4). The results remain consistent with both the original findings and the new sliding window analyses (Figure S6). Specifically, Figure S7 reveals ~1 Hz fluctuations in target and distractor processing at both individual and group levels. Figures S8(A) and S8(B) confirm a uniform distribution of the relative phase across subjects. In Figure S8(C), the relative phase was 0.9567π for a high-performing subject (84.34% accuracy) and 0.2247π for a low-performing subject (28.57% accuracy). At the group level, a significant positive correlation was again observed between relative phase and task performance (r = 0.4020, p = 0.0376), as shown in Figure S8(D).</p><disp-quote content-type="editor-comment"><p>(2) No-Distractor Control Condition: The study lacks a baseline or control condition without distractors. This makes it difficult to determine whether the distractor-related decoding signals or the 1 Hz effect reflect genuine distractor processing or more general task dynamics.</p></disp-quote><p>The lack of a no-distractor control condition is certainly a limitation and will be acknowledged as such in the revised manuscript. However, given that our decoding results are between two different classes of distractors, we are confident that they reflect distractor processing.</p><disp-quote content-type="editor-comment"><p>(3) Decoding Near Chance Levels: The pairwise decoding accuracies for distractor categories hover close to chance (~55%), raising concerns about robustness. While statistically above chance, the small effect sizes need careful interpretation, particularly when linked to behavior.</p></disp-quote><p>This is an important point. To test robustness, we have implemented a random permutation procedure in which trial labels were randomly shuffled to construct a nullhypothesis distribution for decoding accuracy. We then compared the decoding accuracy from the actual data to this distribution. Figure S9 shows the results based on 1,000 permutations. For each of the three pairwise classifications—pleasant vs. neutral, unpleasant vs. neutral, and pleasant vs. unpleasant—as well as the three-way classification, the actual decoding accuracies fall far outside the null-hypothesis distribution (p &lt; 0.001), and the effect size in all four cases is extremely large. These findings indicate that the observed decoding accuracies are statistically significant and robust in terms of both statistical inference and effect size.</p><disp-quote content-type="editor-comment"><p>(4) No Clear Correlation Between SSVEP and Behavior: Neither target nor distractor signal strength (SSVEP amplitude) correlates with behavioral accuracy. The study instead relies heavily on relative phase, which - while interesting - may benefit from additional converging evidence.</p></disp-quote><p>We felt that what the reviewer pointed out is actually the main point of our study, namely, it is not the target or distractor strength over the whole trial that matters for behavior, it is their temporal relationship within the trial that matters for behavior. This reveals a novel neuroscience principle that has not been reported in the past. We have stressed this point further in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>(5) Phase-analysis: phase analysis is performed between different types of signals hindering their interpretability (time-resolved SSVEP amplitude and time-resolved decoding accuracy).</p></disp-quote><p>The time-resolved SSVEP amplitude is used to index the temporal dynamics of target processing whereas the time-resolved decoding accuracy is used to index the temporal dynamics of distractor processing. As such, they can be compared, using relative phase for example, to examine how temporal relations between the two types of processes impact behavior. This said, we do recognize the reviewer’s concern that these two processes are indexed by two different types of signals. We thus normalized each time course using zscoring, making them dimensionless, and then computed the temporal relations between them.</p><disp-quote content-type="editor-comment"><p>Appraisal of Aims and Conclusions:</p><p>The authors largely achieved their stated goal of assessing rhythmic sampling of distractors. However, the conclusions drawn - particularly regarding the presence of 1 Hz rhythmicity - rest on analytical choices that should be scrutinized further. While the observed phaseperformance relationship is interesting and potentially impactful, the lack of stronger and convergent evidence on the frequency component itself reduces confidence in the broader conclusions.</p><p>Impact and Utility to the Field:</p><p>If validated, the findings will advance our understanding of attentional dynamics and competition in complex visual environments. Demonstrating that ignored distractors can be rhythmically sampled at similar frequencies to targets has implications for models of attention and cognitive control. However, the methodological limitations currently constrain the paper's impact.</p></disp-quote><p>Thanks for these comments and positive assessment of our work’s potential implications and impact. As indicated above, in the revision process, we have carried out a number of additional analyses, some suggested by the reviewers, and the results of the additional analyses, now included in the Supplementary Materials, served to further validate the main findings and strengthen our conclusions.</p><disp-quote content-type="editor-comment"><p>Additional Context and Considerations:</p><p>(1) The use of EEG-fMRI is mentioned but not leveraged. If BOLD data were collected, even exploratory fMRI analyses (e.g., distractor modulation in visual cortex) could provide valuable converging evidence.</p></disp-quote><p>Indeed, leveraging fMRI data in EEG studies would be very beneficial, as has been demonstrated in our previous work. However, given that this study concerns the temporal relationship between target and distractor processing, it is felt that fMRI data, which is known to possess low temporal resolution, has limited potential to contribute. We will be exploring this rich dataset in other ways in the future, where we will be integrating the two modalities for more insights that are not possible with either modality used alone.</p><fig id="sa3fig1" position="float"><label>Author response image 1.</label><caption><title>Appyling moving window analysis (0. 02s window duration and 0.01 step size) to a different EEG-fMRI dataset.</title><p>(<bold>A</bold>) The amplitude time series of the 4.29 Hz component and the Fourier spectrum. (<bold>B</bold>) The group level Fourier spectrum. At both individual and group level, no 1 Hz modulation is observed, suggesting that the 1 Hz modulation observed in our data is not introduced by the artifact removal procedure.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106140-sa3-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(2) In turn, removal of fMRI artifacts might introduce biases or alter the data. For instance, the authors might consider investigating potential fMRI artifact harmonics around 1 Hz to address concerns regarding induced spectral components.</p></disp-quote><p>We have done extensive work in the area of simultaneous EEG-fMRI and have not encountered artifacts with a 1Hz rhythmicity. Our scanner artifact removal procedure is very standardized. As such, it stands to reason that if the 1Hz rhythmicity observed here results from the artifact removal process, it should also be present in other datasets where the same preprocessing steps were implemented. We tested this using another EEG-fMRI dataset (Rajan et al., 2019) . Author response image 1 shows that the EEG power time series of the new dataset doesn't have 1 Hz rhythmicity, whether at the individual level or at the group level, suggesting that the 1 Hz rhythmicity reported in the manuscript is not coming from the removal of the scanner artifacts, but instead reflects true rhythmic sampling of stimulus information. Also, the fact that the temporal relations between target processing and distractor processing at 1Hz impact behavior is another indication that the 1Hz rhythmicity is a neuroscientific effect, not an artifact.</p><p>References</p><p>Rajan, A., Siegel, S. N., Liu, Y., Bengson, J., Mangun, G. R., &amp; Ding, M. (2019). Theta Oscillations Index Frontal Decision-Making and Mediate Reciprocal Frontal–Parietal Interactions in Willed Attention. Cerebral Cortex, 29(7), 2832–2843. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhy149">https://doi.org/10.1093/cercor/bhy149</ext-link></p></body></sub-article></article>