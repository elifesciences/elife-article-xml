<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">57261</article-id><article-id pub-id-type="doi">10.7554/eLife.57261</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Curvature domains in V4 of macaque monkey</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-199674"><name><surname>Hu</surname><given-names>Jia Ming</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5306-445X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181139"><name><surname>Song</surname><given-names>Xue Mei</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181138"><name><surname>Wang</surname><given-names>Qiannan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-158625"><name><surname>Roe</surname><given-names>Anna Wang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4146-9705</contrib-id><email>annawang@zju.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Neurology of the Second Affiliated Hospital, Interdisciplinary Institute of Neuroscience and Technology, School of Medicine, Zhejiang University</institution><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution>Key Laboratory for Biomedical Engineering, of Ministry of Education, Zhejiang University</institution><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution>Division of Neuroscience, Oregon National Primate Research Center, Oregon Health &amp; Science University</institution><addr-line><named-content content-type="city">Beaverton</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>19</day><month>11</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e57261</elocation-id><history><date date-type="received" iso-8601-date="2020-03-26"><day>26</day><month>03</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-11-18"><day>18</day><month>11</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Hu et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Hu et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-57261-v2.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="article-reference" xlink:href="10.7554/eLife.57502"/><abstract><p>An important aspect of visual object recognition is the ability to perceive object shape. Two basic components of complex shapes are straight and curved contours. A large body of evidence suggests a modular hierarchy for shape representation progressing from simple and complex orientation in early areas V1 and V2, to increasingly complex stages of curvature representation in V4, TEO, and TE. Here, we reinforce and extend the concept of modular representation. Using intrinsic signal optical imaging in Macaque area V4, we find sub-millimeter sized modules for curvature representation that are organized from low to high curvatures as well as domains with complex curvature preference. We propose a possible ‘curvature hypercolumn’ within V4. In combination with previous studies, we suggest that the key emergent functions at each stage of cortical processing are represented in systematic, modular maps.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>V4</kwd><kwd>curvature</kwd><kwd>hypercolumn</kwd><kwd>optical imaging</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund4"><funding-source><institution-wrap><institution>National Key R &amp; D Program of China</institution></institution-wrap></funding-source><award-id>2018YFA0701400</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>8191101288</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31627802</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>81430010</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>The Fundamental Research Funds for the Central Universities</institution></institution-wrap></funding-source><award-id>2019XZZX003-20</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution>The Fundamental Research Funds for the Central Universities</institution></institution-wrap></funding-source><award-id>2020FZZX001-05</award-id><principal-award-recipient><name><surname>Song</surname><given-names>Xue Mei</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>There is a systematic functional organization for curvature representation in area V4 where specific curvatures are encoded by unique values (modules) from the set of systematically represented values.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Recognizing the shapes of objects requires information about local contour features, such as orientation and curvature. The encoding of contour orientation in the visual system begins in primary visual cortex (V1) with neurons selective for the orientation of visual contours, and, in the second visual area (V2), with neurons selective for cue-invariant contour orientation (that is, independent of whether contours are defined by luminance, motion, color, or depth cues). These two functions are first embodied in the ‘<italic>orientation domain</italic>’ in V1 (<xref ref-type="bibr" rid="bib17">Hubel and Wiesel, 1968</xref>; <xref ref-type="bibr" rid="bib3">Blasdel and Salama, 1986</xref>; <xref ref-type="bibr" rid="bib12">Grinvald et al., 1986</xref>) and the <italic>‘higher order orientation domain’</italic> in V2 (<xref ref-type="bibr" rid="bib31">Ramsden et al., 2001</xref>; <xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>). These signature domains in V1 and V2 mark initial computational elements of shape representation.</p><p>We investigate whether there are functional domains representing contour curvature in area V4 of macaque monkey visual cortex, an important intermediate stage of shape encoding. Although both V2 (<xref ref-type="bibr" rid="bib13">Hegdé and Van Essen, 2003</xref>; <xref ref-type="bibr" rid="bib18">Ito and Komatsu, 2004</xref>; <xref ref-type="bibr" rid="bib1">Anzai et al., 2007</xref>) and V4 are considered intermediate stages of shape representation, a greater body of neural (<xref ref-type="bibr" rid="bib26">Pasupathy and Connor, 2001</xref>; <xref ref-type="bibr" rid="bib14">Hegdé and Van Essen, 2007</xref>; <xref ref-type="bibr" rid="bib24">Nandy et al., 2016</xref>) and computational modeling (<xref ref-type="bibr" rid="bib22">Murphy and Finkel, 2007</xref>; <xref ref-type="bibr" rid="bib30">Pospisil et al., 2018</xref>; <xref ref-type="bibr" rid="bib35">Wei et al., 2018</xref>) evidence points to area V4 as a locus of curvature information processing. V4 neurons are responsive to contour curvature and can be selective for degree of curvature and orientation of curvature (<xref ref-type="bibr" rid="bib26">Pasupathy and Connor, 2001</xref>; <xref ref-type="bibr" rid="bib24">Nandy et al., 2016</xref>). However, it is unknown whether such neuronal responses are organized in any way akin to orientation maps in V1 and V2. Previous studies have shown the functional organization of V4 comprises alternating bands of ‘orientation’ and ‘color’ preference (<xref ref-type="bibr" rid="bib34">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib20">Li et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Ghose and Ts'o, 2017</xref>), as well as organization for disparity defined orientation (<xref ref-type="bibr" rid="bib9">Fang et al., 2019</xref>), motion direction (<xref ref-type="bibr" rid="bib20">Li et al., 2013</xref>), and spatial frequency (<xref ref-type="bibr" rid="bib21">Lu et al., 2018</xref>), but maps for curvature organization have not been demonstrated. Here, we hypothesized that orientation bands in V4 are regions of shape representation that include both orientation and curvature domains.</p><p>We used intrinsic signal optical imaging, a method that is well-suited for studying functional domain responses, to examine curvature response in monkey V4. We hypothesized that curvature domains would meet the following criteria: (1) <italic>Band location in V4:</italic> We predicted that curvature domains would be located within the’ orientation bands’ and not the ‘color’ bands. (2) <italic>Distinct response preference</italic>: We expected that curvature domains should prefer curved stimuli over straight stimuli, and, furthermore, would exhibit selectivity for different degrees of curvature (from low to high) or different orientations of a curve (from 0° to 360°). (2) <italic>Curvature maps</italic>: Just as orientation and color domains have distinct maps, we predicted that curvature domains should have systematic representation for curvature degree and curvature orientation. (3) <italic>Response consistency</italic>: We also predicted that curvature domains would exhibit similar response to curved gratings and curved lines of similar curvature. (4) <italic>Hypercolumn</italic>: Finally, we sought evidence for the possibility of a curvature hypercolumn within V4. Our data suggest that there is a systematic ‘curvature map’ within V4. While curvature domains have previously been identified within V4 (<xref ref-type="bibr" rid="bib36">Yue et al., 2014</xref>), this study shows such systematic maps at domain scale.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>General approach</title><p>Our approach is to understand the functional organization of curvature response in V4. We approached this study from a global to local scale in V4 by testing several predictions. First, we hypothesized that, as part of the shape encoding network, curvature domains would fall within the V4 ‘orientation bands’ rather than the ‘color bands’. Furthermore, within the orientation bands, curvature domains should be spatially distinct from the straight orientation domains. Second, analogous to the organization of orientation domains in V1, we predicted that curvature maps would represent curvature degree and curvature orientation in a systematic way. Third, if response is truly selective for curvature, curvature domains should exhibit the same selectivity for curvature content despite differences in detail (e.g. curved gratings vs curved lines). Fourth, we probed the hypothesis that a curvature hypercolumn exists in V4. This concept predicts that a local (e.g. ~1 degree) region of V4 should represent a range of curvature degrees and orientations. We present our findings below and provide a proposal for a curvature hypercolumn in V4.</p></sec><sec id="s2-2"><title>Curvature domains exist</title><p>Using intrinsic optical imaging, we imaged V4 in three hemispheres of two anesthetized macaque monkeys (27 sessions). In addition to conventional straight gratings, we designed curvature stimuli composed of sinusoidal curved gratings (<xref ref-type="fig" rid="fig1">Figure 1</xref>) with curvatures ranging from low to high. This stimulus (4 deg in size) comprises a central region (~1 deg) which contains the primary curvature content, while the flanking regions are relatively straight. Below, we will provide evidence that curvature response is attributed to this central region. As shown in <xref ref-type="table" rid="table1">Table 1</xref>, almost all experiments described in this study were conducted in at least two cases. Consistent with previous studies (<xref ref-type="bibr" rid="bib34">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib20">Li et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Ghose and Ts'o, 2017</xref>), alternating regions (bands) of color preference vs. orientation preference were observed in V4, with small regions of overlap between bands (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). To precisely place our visual stimuli, we also mapped the retinotopy of V4 cortex using 0.2° horizontal and vertical lines and placed the center of visual stimuli (4° in size) on the monitor (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, see Materials and methods). We then zoomed in and obtained functional maps of V4. We used oriented achromatic and isoluminant color gratings to obtain maps for orientation (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), color (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), and high vs. low spatial frequency (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). For all maps, the locations of functional domains were determined by t-value maps (t-map, two-tailed t test, p&lt;0.01) which were calculated by comparing, pixel by pixel, the responses between two different conditions. Timecourses were examined to compare magnitudes of response of statistically significant domains.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Case list.</title></caption><table frame="hsides" rules="groups"><thead><tr><th/><th/><th>Case 1</th><th>Case 2</th><th>Case 3</th></tr></thead><tbody><tr><td>Curvature vs. straight map</td><td>Three cases <break/>(from three hemispheres of two animals)</td><td><xref ref-type="fig" rid="fig2">Figure 2C</xref> and <xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5B</xref></td><td><xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4F,G</xref> and <xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5C,D</xref></td><td><xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6B</xref></td></tr><tr><td>Curvature domain mask</td><td>Three cases</td><td><xref ref-type="fig" rid="fig2">Figure 2G</xref> red pixels</td><td><xref ref-type="fig" rid="fig5">Figure 5A</xref> right panel</td><td><xref ref-type="fig" rid="fig6">Figure 6D</xref></td></tr><tr><td>Curvature degree map</td><td>Three cases</td><td><xref ref-type="fig" rid="fig3">Figure 3</xref></td><td><xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A and B</xref></td><td><xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref></td></tr><tr><td>Curvature orientation map</td><td>Three cases</td><td><xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2C,D</xref></td><td><xref ref-type="fig" rid="fig4">Figure 4</xref> and 6A</td><td><xref ref-type="fig" rid="fig6">Figure 6D</xref></td></tr><tr><td>Response consistency (curvature orientation)</td><td>Two cases <break/>(from two hemispheres of two animals)</td><td>NA</td><td><xref ref-type="fig" rid="fig6">Figure 6A–C</xref></td><td><xref ref-type="fig" rid="fig6">Figure 6D–F</xref></td></tr><tr><td>Scrambled response</td><td>One case</td><td>NA</td><td>NA</td><td><xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref></td></tr><tr><td>Data used for response amplitude calculation</td><td colspan="4">Cases 1 and 3 are from the same monkey. <break/>Response to color (Case 1: 50 trials; Case 2: 70 trials; Case 3: 50 trials with two different orientations) <break/>Response to high SF (Case 1: 80 trials; Case 2: 120 trials; Case 3: 100 trials with four different orientations) <break/>Response to 0, 45, 90, 135 (Case 1: 30 trials; Case 2: 30 trials; Case 3: 30 trials with the corresponding optimal orientations) <break/>Response to curvature grating (Case 1: 240 trials; Case 2: 240 trials; Case 3: 240 trials with four different curvature orientations and two different curvature degrees, a/b ratio 2 and 5) <break/>Response to flashed curvature (Case 2: 60 trials with two different curvature orientations; Case 3: 120 trials with four different curvature orientations) <break/>Number of pixels related to color domain (Case 1: 34986; Case 2: 10886; Case 3: 22560) <break/>Number of pixels related to high SF domain (Case 1: 31,480; Case 2: 10,687; Case 3: 29,757) <break/>Number of pixels related to 0, 45, 90, 135 orientation domain (Case 1: 33,676, 47,501, 51,798, 43,837; Case 2: 8225, 10,243, 4712, 8891; Case 3: 38,362, 31,651, 41,822, 41,466) <break/>Number of pixels related to curvature domain (Case 1: 30,215; Case 2: 18,209; Case 3: 24,351)</td></tr></tbody></table></table-wrap><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Curvature grating stimuli.</title><p>(<bold>A</bold>) Calculation of curvature index. Width is half of the ellipse width. (<bold>B</bold>) Constructing curvature grating by periodic repeat. One low (index = 2) and one high (index = 5) curvature grating shown. (<bold>C</bold>) Luminance profiles of different stimuli in different directions. The profiles at the vertical axis (arrows at top, profile at right) of the two stimuli are similar, but differ in the horizontal axis (arrow at left, profiles below). The higher the curvature degree, the higher the spatial frequency towards the edge of the stimulus. Red square: central region, blue rectangle: flanking regions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig1-v2.tif"/></fig><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Curvature domains exist and are distinct.</title><p>(<bold>A</bold>) View of cortical surface in Case 1. Dotted box: region shown in B-I. L.S., lunate sulcus. S.T.S., superior temporal sulcus, A, anterior, L, lateral. B-I: Case 1. (<bold>B</bold>) Color-coded orientation preference map. White dashed lines: approximate borders between color and orientation bands. (<bold>C</bold>) Curvature map: all curved minus all straight gratings. (<bold>D</bold>) Color preference map. (<bold>E</bold>) High spatial frequency preference map (4 cycle/deg vs. 0.5 cycle/deg). (<bold>F</bold>) Curvature domains (gray patches, two-tailed t-test, p&lt;0.01) superimposed on iso-orientation contours. (<bold>G-I</bold>) Overlay of curvature domains (red) and G: color domains (green, from D), H: high spatial frequency domains (green, from E), I: all orientation domains (green). (<bold>J</bold>) Response time courses of curvature domains from Case 1 (left), Case 2 (middle), and Case 3 (right). Red lines: preferred stimuli. Gray lines: non-preferred stimuli. (<bold>K</bold>) Response time courses of curvature domains to flashed curved lines. Red timecourses: flashed curved lines. Gray timecourses: flashed straight lines. (<bold>L</bold>) Summary of response amplitudes for color (Col), high spatial frequency (HSF), orientation (0°, 45°, 90°, 135°), and curvature (Cur) domains shown in <bold>J</bold>, <bold>K</bold>. Gray: straight grating. Red: Curved grating. Black: optimal stimulus responses (except for Cur). For Cur, optimal response was to curved gratings (red) and to flashed curved lines (hatched red). Scale bar: 1 mm. Error bars: SEM (timecourses in <bold>J</bold>, <bold>K</bold>), SD (histogram in L).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Large field of view of functional maps in Cases 1–3.</title><p>Color (left column) and orientation (middle column) maps in V1, V2, and V4. Third column: overlay of color preferring (green) and orientation selective pixels (red). White dotted lines: lunate sulcus (LS) and superior temporal sulcus (STS). For all maps, the locations of functional domains were determined by t-value maps (t-map, two-tailed t test, p&lt;0.01) which were calculated by comparing, pixel by pixel, the responses between two different conditions (A: color vs. achromatic, B: 45° vs. 135°). Case 2: some of cortex in V1 was out of focus in initial session. Map obtained from another session shows clear color and orientation maps in V1. Scale bar: 1 mm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>V1/V2 and V4 represent different retinotopic locations in the same field of view.</title><p>Case 1 (<bold>A–F</bold>), Case 2 (<bold>G–L</bold>), Case 3 (<bold>M</bold>). A, G. The center of the 4 deg curvature grating (1 deg size red square in A, <bold>G</bold>) is centered on the field of view in V4 [red oval in B (flashed line at x = 0), H, M (flashed 1 deg square)], as determined by the mapping of vertical (<bold>C, I</bold>) and horizontal (<bold>D, J</bold>) dotted lines (shown in A, <bold>G</bold>) [note the lack of V1 activation]. The region of V1 visible within the same field of view (posterior to lunate) represents a different retinotopic location (green square in A, G; green oval in B, <bold>H</bold>), as determined by the mapping of vertical (<bold>E, K</bold>) and horizontal (<bold>F, L</bold>) dotted lines (shown in A, <bold>G</bold>). Thus, it was not possible to image the response to the central curvature stimulus in both V1 and V4 simultaneously. Dotted line (line width: 0.2 degrees. Drift direction: along the line) for retinotopic mapping. Xn, Yn: dotted line position (in n degrees) over center of curvature stimulus. M. Retinotopic mapping example from Case 3. For subdomain analysis, we focused on the regions outlined by these red dashed ovals (corresponding to the central 1 deg region).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Relationship between curvature domain and low SF domain.</title><p>Based on our results, curvature domains and low SF domains are largely separated (curvature domain: orange region; low SF domain: blue region).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Low and high curvature maps are highly overlapped (two Cases across two sessions).</title><p>Maps of low vs. high curvature. (<bold>A-B</bold>) Stimuli with low (A, Length/width = 2) vs. high (B, Length/width = 5) curvature degrees. These are compared with straight orientation gratings of the same SF. C-G: subtracted curvature maps for Case 1 (<bold>C,F</bold>) and Case 2 (<bold>D,G</bold>). (<bold>E, H</bold>) Overlay of low vs. high T maps (p&lt;0.01). Blue: low SF. Orange: high SF. Scale bar: 1 mm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp4-v2.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>Stability of curvature response across different days.</title><p>Maps of all curvature minus all straight. <bold>A</bold> and <bold>B</bold> (Case 1), and <bold>C</bold> and <bold>D</bold> (Case 2) imaged on different days. Red dots: corresponding curvature domains imaged on different days. Scale bar: 1 mm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp5-v2.tif"/></fig><fig id="fig2s6" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 6.</label><caption><title>Imaging of curvature responses and scrambled map in the same cortical region (from Case 3).</title><p>(<bold>A</bold>) Scrambled version of a curvature grating created by dividing the grating (each frame) into 64 subunits and rearranging the subunits randomly. (<bold>B</bold>) Curvature map (curvature vs. straight). (<bold>C</bold>) Scrambled map (Scrambled vs. Straight, The scrambled stimuli consist of patterns of scrambled patches whose elements are randomly changing frame by frame across time). Scale bar: 1 mm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp6-v2.tif"/></fig><fig id="fig2s7" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 7.</label><caption><title>Supporting graphs for <xref ref-type="fig" rid="fig2">Figure 2L</xref>.</title><p>Red lines: preferred stimuli for each domain type. Gray lines, black lines: non-preferred stimuli (see insets next to each graph). (<bold>A</bold>) Color domains exhibit robust response to isoluminant color gratings (red line) but weak response to achromatic gratings (gray lines: straight gratings, black lines: curved gratings). (<bold>B</bold>) High spatial frequency domains responded strongly to achromatic gratings of high spatial frequency (red lines) but poorly to low spatial frequency gratings (either straight, gray lines, or curved, black lines). Note that, both color domains and high spatial frequency domains exhibited poor responses to curvature stimuli. (color mean dR/R = 6.8 × 10<sup>−6</sup>; HSF mean dR/R = 1.5 × 10<sup>−6</sup>). (<bold>C-F</bold>) Orientation domains (0°, 45°, 90°, 135°) exhibited strongest response to gratings of their respective optimal orientations (red line), relative suppression to gratings of orthogonal orientation (top gray line), and weak responses to other straight orientations (other gray lines). In comparison, they displayed relatively little response to curved gratings (black lines) (Wilcoxon test, p&lt;10<sup>−5</sup> for each of the four optimal orientation responses compared to response to all four curvatures summed).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp7-v2.tif"/></fig><fig id="fig2s8" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 8.</label><caption><title>Straight orientation domains and high spatial frequency domains exhibit weak responses to single curved lines.</title><p>Peak responses for high spatial frequency (HSF), orientation (Case 2: 0°, 90°; Case3: 0°, 45°, 90°, 135°), and curvature (Cur) domains in Case 2 (<bold>A</bold>) and Case 3 (<bold>B</bold>) to flashed lines. Light gray: straight lines. Red: curved lines. Gray: Optimal straight lines. Error bars: SD.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp8-v2.tif"/></fig><fig id="fig2s9" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 9.</label><caption><title>Neurons in curvature domains prefer curvature.</title><p>(<bold>A</bold>) A single electrode targeting a curvature domain in V4 (Case 3). (<bold>B</bold>) Positions of all three penetrations on the curvature map (all curve minus all straight). (<bold>C</bold>) Straight stimuli and curved stimuli used for straight and curvature orientation tuning. (<bold>D</bold>) Straight (light gray) and Curvature (dark gray) orientation tuning of a single unit. This neuron exhibited strong responses to one particular curvature orientation. The stimulus size (upper: 4 degrees, lower: 2 degrees) does not affect the tuning profile. Dashed lines: average firing rates to straight gratings (gray) and curved gratings (black). (<bold>E</bold>) Comparison between averaged responses to curvature and to straight gratings. 26 units (19 single units and 7 multi-units from three penetrations in three experimental sessions. For 14 units, the stimulus sizes are 3 degrees; for the other 12 units, the stimulus sizes are 4 degrees). On average, these neurons prefer curvature to straight stimuli.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp9-v2.tif"/></fig><fig id="fig2s10" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 10.</label><caption><title>Curvature domains were not observed in V1.</title><p>Field of view over V1. (<bold>A</bold>) Ocular dominance columns acquired by presenting monocular oriented stimuli one degree in size (by summing responses across four orientations). Red dashed line: activated V1 region. (<bold>B</bold>) Cortical response comparison between curved and straight stimuli (stimulus size: four degrees, from the same experiment session). These stimuli shared the same center locations as shown in <bold>A</bold>. Within the central 1 deg region (within red dashed line, corresponding to location of central red square), there was no obvious preference or response pattern for curvature over straight. Differences only appeared in response to the flanks of the stimulus (outside the red dotted line), perhaps due to different spatial frequencies between flanking regions of the straight and curvature stimuli. (<bold>C, D</bold>) Orientation maps acquired with the straight stimuli in <bold>B</bold>. White dotted lines: lunate sulcus (L.S.).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp10-v2.tif"/></fig><fig id="fig2s11" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 11.</label><caption><title>Very little V2 is available on surface.</title><p>Location of V1/V2 border revealed by ocular dominance mapping (three cases). White dashed line: lunate sulcus. Red dashed line: V1/V2 border.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp11-v2.tif"/></fig><fig id="fig2s12" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 12.</label><caption><title>Curvature domains are not pinwheel centers.</title><p>(<bold>A-B</bold>: Case 1, C-D: Case 3). (<bold>A, C</bold>) Orientation map from two cases (A: Case 1, C: Case 3). Different colors represent different orientation preferences. Only the pixels that can distinguished two orthogonal orientations (responses comparison between two orthogonal conditions, two tailed t test, p&lt;0.01) and show significant responses (compared with blank condition, two tailed t test, p&lt;0.01) were kept. (<bold>B, D</bold>). Locations of curvature domains (orange) and orientation domains (blue). Blue dots: pinwheel centers of orientation domains. Most of the curvature domains are not close to orientation pinwheel centers. (<bold>E</bold>) Response timecourse of pinwheel centers from these two cases. Gray lines: responses to straight gratings (four orientations). Black lines: responses to curvatures (four orientations).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp12-v2.tif"/></fig><fig id="fig2s13" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 13.</label><caption><title>Curvature domains can not be fully explained by end-stopping.</title><p>(<bold>A</bold>) Suppression domains: Subtraction image in response to small (1°, dark pixels) minus large (4°, light pixels) horizontal grating stimuli. (<bold>B</bold>) Curvature domains: Curvature map: all curved minus all straight. (<bold>C</bold>) Overlay: Locations of curvature domains (orange, from B, two tailed t test, p&lt;0.01) and small size preferring domains (blue, from A, two tailed t test, p&lt;0.01). There are overlapping and non-overlapping pixels between these two sets of pixels (overlapping: 33.3%, non-overlapping: 66.7%). (<bold>D</bold>) Response timecourses of curvature domains show poor response to small straight gratings (gray line square dot), slightly better response to large straight gratings (gray line round dot), and far better response to curvature gratings (black lines).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig2-figsupp13-v2.tif"/></fig></fig-group><p>We then examined response in V4 to straight vs. curved stimuli, consisting of moving curved (<xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>) sinusoidal gratings (four straight orientations: 0°, 45°, 90°, 135°; four curved orientations: curved up, curved down, curved left, curved right), and flashed single curved (curved up, curved down) or straight lines (horizontal, vertical) (see insets in <xref ref-type="fig" rid="fig2">Figure 2J and K</xref>). To examine preference for curvature over straight gratings, we subtracted curvature (sum of all four curvature grating maps) minus straight (sum of all four straight grating maps), revealing dark (curvature preferring) domains (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, two-tailed t test, p&lt;0.01). These curvature maps were distinct from (straight) orientation maps (overlay of curvature and straight shown in <xref ref-type="fig" rid="fig2">Figure 2I</xref>). For simplicity of terminology, we will refer to these curvature vs. straight preferring domains as ‘curvature domains’.</p><p>If these domains are indeed curvature domains, we predicted that they should be located within the ‘orientation bands’ and should be spatially distinct from straight orientation maps. We found that curvature domains (<xref ref-type="fig" rid="fig2">Figure 2G–I</xref>, red pixels) were distinct from color domains (<xref ref-type="fig" rid="fig2">Figure 2G</xref>, green pixels); they were also distinct from high spatial frequency domains (<xref ref-type="fig" rid="fig2">Figure 2H</xref>, green pixels), suggesting that these curvature responses are not simply due to the high spatial frequency components of the curved grating. Note also that these curvature domains have little overlap with low spatial frequency domains (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). In addition, as predicted, the curvature domains fell largely within the orientation band and were in close proximity to the straight orientation domains (<xref ref-type="fig" rid="fig2">Figure 2I</xref>, green pixels). As shown by the yellow pixels (locations of overlap), there is limited overlap between color and curvature domains (overlay in <xref ref-type="fig" rid="fig2">Figure 2G</xref>, Case 1, 4.9% overlap; all three cases, 5.7% overlap) and between high spatial frequency and curvature domains (overlay in <xref ref-type="fig" rid="fig2">Figure 2H</xref>, Case 1, 26.1% overlap; all three cases, 13.9% overlap). However, there is much greater overlap between curvature and orientation domains (<xref ref-type="fig" rid="fig2">Figure 2I</xref>, Case 1, 54.9% overlap; all three cases, 43.0% overlap), raising the possibility that curvature and orientation domains are different components of a shape information processing architecture. When overlaid on outlines of orientation domains, curvature domains appear distinct from orientation domains, and have a semi-regular distribution within the orientation band (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, color: iso-orientation contours, gray patches: curvature domains). Similar modular curvature vs. straight preference maps were obtained in the other two cases (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>: Case 2; <xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>: Case 3).</p><p>Note that these curved grating stimuli were generated by periodically repeating an elliptical contour (see <xref ref-type="fig" rid="fig1">Figure 1</xref>, Materials and methods), resulting in, for high curvature gratings, high spatial frequency content in the flanks of the stimulus. If the curvature response was primarily due to high spatial frequency, then the curvature map and the high spatial frequency preference should have high overlap. However, this was not observed (<xref ref-type="fig" rid="fig2">Figure 2H</xref>), suggesting it is unlikely that the curvature response is primarily due to high spatial frequency content. We also examined the difference between high curvature degree and low curvature degree gratings, which have different spatial frequency content; as these maps are quite similar (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>), it is unlikely that curvature domain response is due to spatial frequency content. We also observed that maps were stable over time, indicating these maps are unlikely to be artifactual (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). Furthermore, examination of images obtained in response to scrambled curved gratings minus straight gratings did not result in structured maps (<xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>), suggesting that, when compared with straight gratings, it is not the presence of multiple orientations or multiple spatial frequencies alone that produced structured maps. In addition, the sizes of curvature domains (mean = 434 μm for all three cases) fall within the 200–500 μm range of functional domain sizes in V4 (<xref ref-type="bibr" rid="bib34">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib20">Li et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Ghose and Ts'o, 2017</xref>). These data thus suggest that curvature maps are not artifactual and are distinct from previously described functional maps in V4.</p><p>We further examined selectivity of response of curvature domains by comparing magnitude of reflectance change in response to curved vs. straight grating stimuli. Reflectance change timecourses were typical of cortical intrinsic signals in V4, characterized by 2–3 s peak times and 0.01–0.03% amplitudes. As expected (<xref ref-type="fig" rid="fig2">Figure 2L</xref>, Col), color domains exhibited robust response to isoluminant color gratings (black) but weak response to achromatic gratings (gray); and failed to distinguished curved (red) vs straight (gray) gratings (Wilcoxon test, p=0.06, all three cases). Similarly (<xref ref-type="fig" rid="fig2">Figure 2L</xref>, HSF), high spatial frequency preference domains responded strongly to achromatic gratings of high spatial frequency (black) but poorly to low spatial frequency gratings (gray); and failed to distinguish curved (red) vs. straight (gray) gratings (high spatial frequency domains, p=0.77, all three cases) (see <xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7</xref> for supporting graphs). These analyses indicate that curvature processing is not subserved by color or high spatial frequency domains.</p><p>We also found that preferences of orientation domains and curvature domains were distinct. As expected (<xref ref-type="fig" rid="fig2">Figure 2L</xref>, 0°, 45°, 90°, 135°), <italic>straight orientation domains</italic> exhibited strongest response to gratings of their respective optimal orientations (black), weak responses to other straight orientations (gray), and weak response to curved gratings (red). <italic>Curvature domains</italic>, in contrast, exhibited strong preference for curvature stimuli. As shown in <xref ref-type="fig" rid="fig2">Figure 2J</xref> left, timecourses of curvature domains revealed strongest amplitudes for curvature gratings (red lines, Case 1), but relatively weak response to straight gratings (gray lines). Similar preferences are evident for both Case 2 (middle) and Case 3 (right). This is quantitatively summarized in (<xref ref-type="fig" rid="fig2">Figure 2L</xref>, Cur, red).</p><p>To further test whether this differential response is due to curvature, in two cases, we examined response to flashed curved and straight lines. As shown in <xref ref-type="fig" rid="fig2">Figure 2K</xref>, using the same pixels from which significant curved grating responses were obtained, we found that response of curvature domains to single flashed curved lines (red lines) was significantly greater than that to single straight lines (gray lines). Thus, curvature domains displayed preference for curved over straight contours for both grating and line stimuli, supporting a curvature-specific response. This curved line response is quantitatively summarized in (<xref ref-type="fig" rid="fig2">Figure 2L</xref>, Cur, red hatch). [Note that, in comparison, straight orientation domains and high spatial frequency domains exhibited weak responses to flashed curved lines (<xref ref-type="fig" rid="fig2s8">Figure 2—figure supplement 8</xref>)].</p><p>To summarize (<xref ref-type="fig" rid="fig2">Figure 2L</xref>), each of the color domains (Col), high spatial frequency domains (HSF), and orientation domains (0°, 45°, 90°, 135°) exhibit preference for their respective optimal stimulus (black bars), one which far exceeds response to curved gratings (red bars) (black vs red bars, Wilcoxon test, p&lt;0.0001). Likewise, curvature domains (Cur) exhibit strong preference for curved gratings (large red bar) and curved lines (hatched red bar) and little response to straight gratings (gray bar). The degree of preference for curvature (Cur red vs gray) parallels the degree of preference of color, high spatial frequency, and orientation domains in V4 for their respective optimal stimulus (black vs gray, black vs red). These data show that (1) curvature domains are strongly selective for curvature stimuli and (2) non-curvature domains exhibit minimal response to curvature stimuli. Thus, curvature domains in V4 exhibit response preferences that are selective for curvature (compared to straight, color, high spatial frequency) and are maintained across two types of curvature stimulus (gratings and lines). Evidence from electrophysiological recording also show the predominance of curvature preference neurons in these domains (<xref ref-type="fig" rid="fig2s9">Figure 2—figure supplement 9</xref>). These curvature preferring domains were not observed in V1 (one case shown in <xref ref-type="fig" rid="fig2s10">Figure 2—figure supplement 10</xref>), consistent with previous studies (<xref ref-type="bibr" rid="bib36">Yue et al., 2014</xref>; <xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>). As V2 in these cases was not available on the operculum (<xref ref-type="fig" rid="fig2s11">Figure 2—figure supplement 11</xref>), we have no data on V2.</p></sec><sec id="s2-3"><title>Mapping types of curvature</title><p>We predicted the global organization of curvature representation should systematically shift with changing curvature degree and with changing curvature orientation. To address this global question, we first tested whether the response pattern would vary with changes of curvature features. We conducted cross-correlation of images obtained with different curvature degrees and with different curvature orientations. By examining correlations between images, we expected that increasing stimulus similarity should predict increasing map similarity. In this section, we show that this prediction is met. In the next section, we zoom in on a small location region to study the local organization more closely.</p><sec id="s2-3-1"><title>Low to high curvature maps</title><p>To examine whether there could be a change of curvature domains representing low to high curvatures, we designed a series of curved gratings from low to high curvature (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, upwards: 1–6; downwards: 7–12, Case 1; <xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>) and presented these stimuli in two cases. Maps obtained in response to these curvature stimuli exhibited regular structure and domain size consistent with functional maps (see <xref ref-type="fig" rid="fig3">Figure 3A</xref>). To examine the possibility of a low to high curvature gradient, we conducted cross correlations between pairs of these images (see Materials and methods). We reasoned that, if a gradient of curvature degree exists, then there should be a gradually changing map similarity as curvature degree changes. Correlation values ranged from 0 (no correlation or minor negative correlation, blue) to 1 (two maps are identical, red) (see color bar). To give the reader an idea of what high map correlations values are, the range of correlation values for four straight orientation maps in V4 shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>; matched orientation correlations range from 0.66 to 0.9 (yellow, orange, red values). As shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref>, higher correlation values tended to occur between curvature maps of similar curvature degree (orange and yellow squares in upper left quadrant and lower right quadrant) and lower correlation values between those of dissimilar curvature degree (green and blue squares in upper left quadrant and lower right quadrant). Within this correlation matrix, the lowest correlation values were obtained between opposing curvatures (upper right quadrant and lower left quadrant) and between curved and straight stimuli (rightmost column). High correlation values were obtained between adjacent 1 or two curvatures (orange and yellow boxes) (e.g compare values between pairs 2–3, 3–4); correlation values dropped off with increasing differences in degree of curvature (green and blue boxes) (e.g. 2–3, 2–4, 2–5). This relationship is plotted in <xref ref-type="fig" rid="fig3">Figure 3C</xref> for each of the 6 Curved Up (top graph) and 6 Curved Down (bottom graph) curvature degrees (e.g. <xref ref-type="fig" rid="fig3">Figure 3C</xref> top graph red circles: show declining correlation with curvature difference). This declining correlation with curvature difference suggests the presence of a shifting map of curvature degree. Similar results were obtained in a second case (Case 2, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A–B</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Systematic maps of curvature degree.</title><p>(<bold>A</bold>) Maps of different curvature degrees. Each map is one curvature minus average of all straight gratings (Case 1). 1–6 and 7–12: upwards and downwards curvatures, respectively, from low to high curvature preference, 13: straight grating. Red dotted square marks the region that is further analyzed in <xref ref-type="fig" rid="fig7">Figure 7A,B</xref>. Correlation values for pairs of curvature response maps (from A). Color bar: high (red) to low (blue) correlation values. (<bold>C</bold>) The more similar the curvature the greater the correlation value. X axis: curvature degree difference. Y axis: correlation value. Color symbols: correlation value for each curvature above with respect to its curvature degree distances (each fit with matching color line; regression values are shown on the right). The fitted lines are not meant to indicate linear fits; rather, they help to see the trends. Scale bar, 1 mm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Correlation values between pairs of straight orientation maps obtained in three different runs (from Case 1).</title><p>These values are provided to give reader an idea of what high map correlations values are. When results from different runs are compared, only maps of similar orientation have high (orange, yellow) correlation values, while non-matching orientations produce low (blue) values. Color bar: correlation values (high, red, to low, blue) for pairs of maps. Note that negative values often occur for orthogonal orientations and are weaker in magnitude than positive values.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Systematic maps of curvature degree and curvature orientation in other cases.</title><p>(<bold>A</bold>) Case 2: Maps of different curvature degrees. (<bold>B</bold>) Correlation values for pairs of curvature response maps (from A). The more similar the curvature, the greater the correlation value (from B). (<bold>C</bold>) Case 1: Imaging maps of different curvature orientations. (<bold>D</bold>) Correlation values for pairs of curvature response maps (from C). Curvatures with the same orientation have greater correlation values (from D). Error bar: SEM. Scale bar: 1 mm. The correlation values are calculated based on the full data set (n=30 trials).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig3-figsupp2-v2.tif"/></fig></fig-group></sec><sec id="s2-3-2"><title>Curvature orientation maps</title><p>In another experiment (<xref ref-type="fig" rid="fig4">Figure 4A,B</xref>, Case 2), we used four <italic>orientations of curvature</italic> (curved upwards, downwards, leftwards, and rightwards), each at low curvature (1-4) and high curvature (5-8). Similar to maps for straight orientation (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), we expected stronger correlation between maps of similar curvature orientation and lower correlation for dissimilar orientations. This expectation was supported by computed correlation indices for pairs of images (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). These correlation values illustrate that high correlation values (orange, yellow) occur only between curvature gratings of the same orientation (e.g. 1–5, 2–6), and low correlation values occur between curvatures of different orientations (green boxes in columns 1–8, e.g. 1–2, 3–4). The finding that the low correlation values occur between these curved and straight gratings (columns 9–12) supports the distinctness of straight vs. curved contour representation. Similar results were obtained in a second case (Case 1, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2C–D</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Systematic maps of curvature orientation.</title><p>(<bold>A</bold>) Imaging results of the responses to different curvature orientations. Maps of curvature minus average of straight gratings (Case 2). 1–4: low curvature degree, a/b ratio = 2, 5–8: high curvature degree, a/b ratio = 5. 1,5: upwards. 2,6: downwards. 3,7: leftwards. 4,8: rightwards. 9–12: straight. (<bold>B</bold>) Enlarged view of the cortical region outlined by red dotted box in <bold>A</bold>. (<bold>C</bold>) Correlation values for pairs of maps (from A). Maps of similar curvature orientation have high correlation values, while those with different curvature orientations have low correlation values. Colors code correlation values (high, red, to low, blue, see color bar).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig4-v2.tif"/></fig></sec><sec id="s2-3-3"><title>Mapping central part of curvature grating</title><p>To more precisely study the organization within curvature domains, we then focused on the cortical region of V4 representing the center of the curvature stimuli (the region of high curvature content, ~1 deg). As shown in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, using thin vertical and horizontal lines, we determined the retinotopic representation of V4 within the imaged field of view. The curvature stimulus was then centered precisely on this location. Note that the region of V1 visible in the same field of view represents a shifted topographic location, so we were unable to map response to the curvature stimulus in both V1 and V4 simultaneously. In these cases, V2 was buried in the lunate sulcus and was not visible.</p></sec><sec id="s2-3-4"><title>Organizations within curvature domains</title><p>By focusing on the region representing the central part of the curvature stimulus, we were able to discern subdomains of high curvature vs. low curvature preference and largely non-overlapping subdomains of opposing curvature orientation. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows that curvature domains (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, Case one and Case 2, white pixels: curvature vs. straight) contain subregions of high curvature preference (red pixels: high curvature vs. low curvature). This is shown by preference (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, Case 1) for high (dark red lines) over low (light red lines) curvature and even weaker response to straight gratings (gray lines). Moreover, the response magnitudes of these subregions gradually diminish with curvature degree difference (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, dark to light lines plot responses of high to low curvature; left: upwards curvature, right: downwards curvature). Thus, there are high curvature subdomains within curvature domains (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), and curvature subdomains exhibit graded response to curvature degree (<xref ref-type="fig" rid="fig5">Figure 5B,C</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Subregions of high curvature preference.</title><p>(<bold>A</bold>) Curvature preferring pixels. Red pixels: high curvature preferring pixels (high curvature vs. Low curvature, a/b ratio = 5 vs. 2, all four orientations, two-tailed t-test, p&lt;0.01). White pixels: (curvature vs. straight). (Case 1: left, Case 2: right, two-tailed t-test, p&lt;0.01). (<bold>B</bold>) High curvature subdomains (red pixels in <bold>A</bold>, Case 1) prefer high curvature (dark red lines, four orientations, a/b ratio = 5) over low curvature (light red lines, four orientations, a/b ratio = 2), and straight lines (Gray lines, four orientations). (<bold>C</bold>) Timecourses of response to 4 degrees of curvature (from high to low, darkest to lightest gray). Scale bar, 1 mm. Error bar: SEM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig5-v2.tif"/></fig><p><xref ref-type="fig" rid="fig6">Figure 6</xref> illustrates the finding that paired opposing curvature orientations occupy roughly complementary positions within the curvature domains. An example of an UP/DOWN pair is shown (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). <xref ref-type="fig" rid="fig6">Figure 6B,C</xref> show that pixels that prefer upwards maintain their preference across curved gratings (6B) and two degrees of curved lines (6C). This is also true for downwards pixels (6B,C). A similar result is shown in <xref ref-type="fig" rid="fig6">Figure 6D–F</xref> (Case 3). For four curvature orientations, upwards/downwards (<xref ref-type="fig" rid="fig6">Figure 6D</xref> left panel) and leftwards/rightwards (<xref ref-type="fig" rid="fig6">Figure 6D</xref> right panel) pairs occupy roughly complementary regions within the curvature domains. These preferences are maintained across curved grating and curved line stimuli. Additionally, the graded response for each of the four orientations suggests the presence of a curvature orientation organization (see below). These results reinforce the presence and selectivity of curvature orientation domains. We note that this complementarity is not absolute. Within the curvature domains, the average percentage of pixels responsive to two opposite orientations (overlapped pixels vs. all colored pixels) was 22.4% (Case 1: 32.1%; Case 2: 14.9%; Case 3: 20.3%).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Organization of curvature orientation representation in V4 curvature domains (<bold>A-C</bold>: Case 2, <bold>D-F</bold>: Case 3).</title><p>(<bold>A</bold>) Curvature orientation maps (Case 2). White pixels: curvature vs. straight (two-tailed t test, p&lt;0.01). Red pixels: significantly activated by different curvature orientations (compared to average of four straight orientations, two tailed t-test, p&lt;0.01). There are overlapping as well as non-overlapping pixels between two opposite orientations. (<bold>B</bold>) Response timecourses of red pixels in A to curved gratings. (<bold>C</bold>) Response timecourses of the same red pixels in A to curved single lines. Orange lines: responses to up curvature, Blue lines: responses to down curvatures. For flashed curved lines, we used two different curvature degrees. (<bold>D</bold>) Curvature orientation maps (Case 3). White pixels: curvature vs. straight (two-tailed t test, p&lt;0.01). Colored pixels: significantly activated by different curvature orientations. (<bold>E</bold>) Response timecourses of colored pixels in maps above to curved gratings. (<bold>F</bold>) Response timecourses of colored pixels in maps above to single flashed curved lines. Black lines: response timecourses to upwards curvature. Dark gray lines: response timecourses to leftwards curvature. Gray lines: response timecourses to downwards curvature. Light gray lines: response timecourses to rightwards curvature. Comparison of E and F graphs show that the orientation of the best curved grating response matches that of the best curved line response (gray timecourses). Scale bar: 1 mm. Error bar: SEM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig6-v2.tif"/></fig></sec></sec><sec id="s2-4"><title>Organization of curvature representation</title><p>Given that there are indications of shifting maps for curvature degree, we examined whether we could discern any systematic relationship between domains for straight orientation and curvature degree. We hypothesized that in some parts of V4, there is a gradual shift from straight to curved representation. In another experimental session, as shown in <xref ref-type="fig" rid="fig7">Figure 7A</xref> (Case 1), within the central region of curvature representation, we obtained (at a single orientation) curvature minus straight orientation maps to different degrees of curvature. Within this region, there appear to be several progressions of straight to curved domains (four straight-to-UP and four straight-to-DOWN). Overlays of these maps are summarized in <xref ref-type="fig" rid="fig7">Figure 7B</xref> (left panel, top row: UP overlays, bottom row: DOWN overlays; white regions: curvature domains). A subset of these overlays are shown in <xref ref-type="fig" rid="fig7">Figure 7B</xref> (middle and right panels. UP: top row, DOWN: bottom row). The middle panels isolate straight orientation domains (blue) and the nearest curvature domains (from straight to high curvature, color code at top) (domain clusters are separated for clarity). The right panels demarcate the center of each domain with a color-coded dot (center of mass). We observed a spatial progression from the center of the straight orientation domain (blue dot in center of blue dotted line) to low curvature domain (blue-oranges) to high curvature domain (orange); these colored dots are connected by a line (shaded from blue to orange) to illustrate the progression. Four examples of such progressions for Up are shown in the top panel and four progressions for Down in the bottom panel. Progressions arising from a single orientation domain can lead to two different curvature domains (e.g. UP: leftmost orientation domain, Down: rightmost orientation domain). Additional examples are shown in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>. These progressions suggest a possible systematic contour representation in V4.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Functional organization of curvature in V4.</title><p>(<bold>A</bold>) Maps of different stimuli minus average of straight gratings (Case 1). Top row: upwards curvatures, bottom row: downwards curvatures. Leftmost: horizontal gratings. (<bold>B</bold>) Maps of progressions from straight to curved representation. Top row: responses to upwards curvatures (Up). Bottom row: responses to downwards curvatures (Down). <italic>Left panels:</italic> activated regions (two-tailed t-test, p&lt;0.01) corresponding to different curvature stimuli. White regions: curvature domains. Color code: high (orange) to low (blue). <italic>Middle panels:</italic> activated regions corresponding (two-tailed t test, p&lt;0.01, curved vs. average of straight) to respective curvature degrees are outlined by different colors (domain clusters are separated for clarity). Color code (at top): high (orange) to low (blue). [Note that the two leftmost domain progressions in Up panel are associated with the same orientation domain but are separated for clarity.] <italic>Right panels:</italic> Location of the activation center of each domain (indicated by colored dot). White regions: curvature domains. Blue dotted lines: horizontal orientation domains. Shifting progressions from straight orientation (blue dot) to low curvature (blue-orange dot) to high curvature (orange dot) are observed, as indicated by colored line (shaded from blue to orange). (<bold>C</bold>) Regions that were significantly activated (two-tailed t test, p&lt;0.01) by corresponding stimuli (from Case 1). Red dots: centers of mass. (<bold>D</bold>) We measured the distance between each curvature domain activation center of mass and its corresponding straight orientation domain center of mass (a/b rations: 1, 2, 4, 5, 7, 10 in Case 1, eight progressions). Gray dots and lines: results from different progressions, black dots: averaged across all eight progressions. Error bar, SD. (<bold>E</bold>) Summary of curvature domain findings. Left: curvature degree progressions, Right: presence of curvature domains and complex curvature domains. Gray oval: curvature domains.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Diversity of curvature domain organization (<bold>A-D</bold>: Case 2, <bold>E-H</bold>: Case 3).</title><p>(<bold>A</bold>) In Case 2, we examined maps of horizontal straight to curved domains; the three straight domains are marked 1–3. (<bold>B</bold>) Curvature domains associated with Domain one and Domain two are outlined (Domain 2 associated with two progressions, one UP and one DOWN). The corresponding centers of mass are marked by colored circles (same as in <xref ref-type="fig" rid="fig7">Figure 7</xref>). White regions: curvature domains. (<bold>D</bold>) We measured the distance between each curvature domain activation center of mass and its straight orientation domain center of mass (a/b ratios: 1, 2, 4, 5, 7, 10; four progressions). Gray dots and lines: results from different progressions in B, black dots and lines: averaged across all three progressions in <bold>B</bold>. Error bar: SD. (<bold>E</bold>) In Case 3, we examined progressions of horizontal (1, 3, 5) and of vertical (2) straight to curved domains. (<bold>F, H</bold>) Same conventions as <bold>B</bold>, <bold>D</bold>. (<bold>F</bold>) Domains 1,3,5 are UP, DOWN, UP progressions, respectively. Domain 2 has two progressions for LEFT and two progressions for RIGHT; thus, it was associated with a total of four progressions. (<bold>H</bold>) a/b rations: 1, 5, 10; eight progressions. Gray dots and lines: results from different progressions in F, black dots and lines: averaged across all seven progressions in <bold>F</bold>. (<bold>C, G</bold>) Two examples of progressions that did not show domain shifts. <bold>C</bold> from Case 2: the curvature domains are highly overlapped and spatially separate from the straight orientation domain (dotted blue line) (dotted gray line in D); G from Case 3: the curvature domains and the straight orientation domain overlie the same position (dotted gray line in H).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig7-figsupp1-v2.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Curvature domain response is not due to component orientation response.</title><p>We compared the curvature response to three prominent component responses (0, 45, 135 deg as revealed by Fourier 2D transform). Three reasons why it is unlikely that curvature domain response is due to component response: (1) Curvature domains and orientation domains are spatially distinct (2) Curvature domains respond weakly to component orientations (by roughly an order of magnitude) and (3) orientation domains are weakly activated by curvature stimuli, only curvature domains show strong response (<bold>A-D</bold>: Case 1, <bold>E-G</bold>: Case 3). (<bold>A</bold>) Component orientations in the stimuli. Central (red) and flanking parts (blue) of the curvature stimuli. (<bold>B</bold>) Functional domains from the FOV in <xref ref-type="fig" rid="fig7">Figure 7E</xref> (red dotted rectangle). From left to right: curvature domains (all curved minus all straight), 0 deg, 45 deg, 135 deg orientation domains. (<bold>C, D</bold>) Response timecourses. In each of the curvature panels, these red lines correspond to the three orientations (horizontal, 45, 135). In each of the orientation panels, red lines correspond to the optimal orientations of the orientation domains (shown in the corner of each panel). The gray lines correspond to the identified curvature stimuli. (<bold>E</bold>) Functional domains. From left to right: curvature domains (all curved minus all straight), 90 deg, 45 deg domains, 135 deg orientation domains. (<bold>F, G</bold>) Response timecourses. Gray lines: see legend at left. Red lines: see legend within graph. Not due to a weighted sum. To do a quick calculation of a weighted sum of 0, 45, 135 orientation response. For upwards curvature (from C, a/b ratio = 7), Response<sub>0</sub> = −0.0026%, Response<sub>45</sub> = −0.0027%, Response<sub>135</sub> = 0.0006%, Wi = 1/3, Response = −0.0016%, much weaker (by almost an order of magnitude) than the response in curvature domains −0.0115% (responses were calculated by average of the response amplitudes from the last 10 frames). While we are not able to test the weighted sum of all possible orientations, at least with this simple test, we do not see any indication of component summation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-fig7-figsupp2-v2.tif"/></fig></fig-group><p>To further examine the details of these progressions, we analyzed the distances between each straight orientation domain and the nearest (same orientation) curvature domains. Specifically, starting from a straight orientation domain (n = 8), we selected the nearest domain of each curvature condition (shown in <xref ref-type="fig" rid="fig7">Figure 7B</xref>) and measured the distances between center of mass of each domain and that of the straight domain (leftmost panel in <xref ref-type="fig" rid="fig7">Figure 7C</xref>). These values are plotted in <xref ref-type="fig" rid="fig7">Figure 7D</xref> (gray lines). This reveals that the curvature preference domains generally progress from low to high curvature with distance across the cortex. Note that some parts of these curvature sequences shift and other parts do not appear to shift. However, on average (black line), across these eight straight-to-curved sequences, there is a general trend of greater distance with increasing curvature. We conducted this analysis for the other two cases (shown in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Case 2 shows three progressions with a similar tendency to shift (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1B</xref>) and one without shifts (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1C</xref>) (graphed in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1D</xref>). Case 3 shows seven progressions with shifts (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1F</xref>), and one without (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1G</xref>) (graphed in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1H</xref>). In total across the three cases, on average, there is a general overall tendency for straight-to-curved domains to exhibit spatial shifts. However, there are some domains with broad curvature preference. This suggests the presence of a diversity in organization, indicating that curvature representation in V4 is complex.</p><sec id="s2-4-1"><title>Curvature domains are not orientation pinwheel centers or sums of orientation components</title><p>We considered the possibility that curvature responses could be due to activation of a mixture of oriented responses, such as that found at orientation pinwheel centers. As shown in two cases in <xref ref-type="fig" rid="fig2s12">Figure 2—figure supplement 12</xref> (Case 1: A-B, Case 2: C-D), the curvature domains (orange regions) do not co-localize with orientation pinwheel centers (blue dots). In fact, most of the pinwheel centers are outside the curvature domains entirely. Moreover, as shown by the responses of pinwheel centers to straight and curved stimuli (<xref ref-type="fig" rid="fig2s12">Figure 2—figure supplement 12E</xref>), the pinwheel center responses to curvatures are weak and do not distinguish curvature from straight (Wilcoxon test, p=0.13). This makes it unlikely for pinwheel centers to be locations of curvature response. We also considered the possibility that curvature responses are simply a weighted sum of responses to component orientations. This is unlikely because (1) the straight orientation domains are spatially distinct from the curvature domains (<xref ref-type="fig" rid="fig2">Figure 2</xref>). And (2) our analysis of response to component orientations compared with response to curvature shows that curvature domain response to straight component orientations is weak (smaller by roughly an order of magnitude) (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>).</p></sec><sec id="s2-4-2"><title>Curvature domains are not end-stopping domains</title><p>There is strong support for the role of end-stopped cells in curvature representation (<xref ref-type="bibr" rid="bib16">Hubel and Wiesel, 1965</xref>; <xref ref-type="bibr" rid="bib15">Hubel and Livingstone, 1987</xref>; <xref ref-type="bibr" rid="bib8">Dobbins et al., 1987</xref>; <xref ref-type="bibr" rid="bib32">Sceniak et al., 2001</xref>). The rationale is that straight contours extend into the RF end zones leading to suppression, while curved contours do not, making end-stopped neurons ideal ‘not straight’ candidates for encoding curvature. Electrophysiological study of single unit responses to curvature gratings in V4 finds strong correlation between curvature preference and strength of end-stopping (<xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>). Thus, this study suggests response to these two parameters in V4 are indistinguishable, raising the possibility that the curvature domains recorded here actually represent end-stopping response.</p><p>We feel this is unlikely. End-stopping, while an essential contributer to curvature computation, is not sufficient for all curvature encoding. As supported by previous studies in V4 (<xref ref-type="bibr" rid="bib23">Nandy et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Nandy et al., 2016</xref>), the curvature selectivity displayed by many V4 neurons can also be caused by other properties (e.g. complex structures of receptive field). While end-stopped cells may contribute to the curvature domain responses recorded here, curvature domains <italic>are not equal to</italic> end-stopping domains. As shown in <xref ref-type="fig" rid="fig2s13">Figure 2—figure supplement 13</xref>, comparison of end-stopping maps (1 deg vs 4 deg straight gratings) and curvature maps reveal that they are distinct. <xref ref-type="fig" rid="fig2s13">Figure 2—figure supplement 13C</xref> (overlay of A, end-stopping map and B, curvature map) illustrates that there are some regions of overlap (~33.3%), but 66.7% of domains are in spatially distinct locations. Moreover, quantification of curvature-preferring pixels (<xref ref-type="fig" rid="fig2s13">Figure 2—figure supplement 13D</xref>) reveals that, while there is a preference for the small over the large straight stimulus (compare two light gray lines), the responses to straight stimuli are still weaker than that to curved (black lines). This suggests that, in V4, curvature domains are not simply end-stopped domains.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Summary</title><p>In summary, we provide evidence for the existence of curvature domains in V4 and show that there is a systematic map of curvature representation in V4. To the organization of curvature representation within V4, we designed stimuli that spanned curvature degree and curvature orientations. Instead of using shapes with complex structures such as hyperbolic/polar gratings (<xref ref-type="bibr" rid="bib13">Hegdé and Van Essen, 2003</xref>) or forms composed of multiple corners and lines (<xref ref-type="bibr" rid="bib27">Pasupathy and Connor, 2002</xref>; <xref ref-type="bibr" rid="bib5">Brincat and Connor, 2004</xref>), these were stimuli with relatively simple curvature content (similar to <xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>). The gradations of curvature degree across our stimulus set revealed that response preference is spatially mapped in certain parts of V4 (from straight to highly curved, <xref ref-type="fig" rid="fig7">Figure 7B</xref> and <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1B,F</xref>). We showed that maps for curvature are distinct from those for straight orientation, color, high spatial frequency, orientation pinwheels, and end-stopping. These maps also have the spatial appearance of organized functional maps in terms of domain size and distribution. We find curvature domains exhibit selectivity for degree of curvature (low to high), one which maps in a spatially shifting manner in V4. These progressions are not necessarily linear, as indicated by the distance changes related to curvature degree (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1D,H</xref>). In addition to these curvature degree progressions, other types of spatial organizations were also observed (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1C,G</xref>). Similarity of response preference across both curved gratings and single curved lines provide further evidence for curvature selectivity rather than some other aspect of these stimuli.</p></sec><sec id="s3-2"><title>Hypercolumn model</title><p> While the overall spatial relationship between straight and curved features will take additional study to fully establish, given the data at hand, we propose the model shown in <xref ref-type="fig" rid="fig7">Figure 7E</xref>. We suggest that straight (large gray square) and curved (large gray oval) regions in V4 co-exist and occupy roughly complementary territory within the ‘orientation bands’ of V4. Within the curvature domains, there are multiple types of organizations, characterized by sequences of curvature degree as well as domains with complex curvature preference. To our knowledge, no previous study has provided evidence suggesting that curvature is a basis for a hypercolumn in V4. This framework will need to be further tested in future studies.</p></sec><sec id="s3-3"><title>Testing other possible interpretations</title><sec id="s3-3-1"><title>Unlikely to be primarily component orientation responses</title><p>We tested the possibilities that the curvature preference domains are actually responses to the weighted sum of component straight orientations. However, we found little support for this: the weighted sum of three primary components produced responses that were an order or magnitude weaker than to the curved stimulus (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). Scrambled stimuli which contain straight components failed to produce structured maps (<xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>). And orientation pinwheels, which contain many straight component responses, were at locations quite distinct from the curvature domains (<xref ref-type="fig" rid="fig2s12">Figure 2—figure supplement 12</xref>). Neither did our data support the possibility that curvature domains are end-stopping domains (<xref ref-type="bibr" rid="bib10">Ghose and Ts'o, 1997</xref>), as these mapped to spatially distinct locations (<xref ref-type="fig" rid="fig2s13">Figure 2—figure supplement 13</xref>). Thus, it does not appear that curvature domain responses are due to a simple linear combination of local orientation domain responses, but result from a non-linear (perhaps multi-step) integration of straight oriented inputs.</p></sec><sec id="s3-3-2"><title>Unlikely to be high spatial frequency domains</title><p>We consider the possibility that the curvature responses are actually responses to the high spatial frequency aspects of the curvature gratings. Based on curvature stimuli used in <xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>, we designed curvature gratings composed of ellipsoid curves repeated sinusoidally. As shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>, different stimuli with different degrees of curvature created in this fashion have common spatial frequency along the center axis. Towards the flanks of the stimulus, especially for higher curvature, the grating has higher SF content than that on the central axis. However, several observations make our results inconsistent with the hypothesis that these results are due primarily to these high SF aspects of the stimuli. (1) High spatial frequency maps in V4 (first reported by <xref ref-type="bibr" rid="bib21">Lu et al., 2018</xref>) differed from curvature maps (<xref ref-type="fig" rid="fig1">Figure 1H and L</xref>). On average, less than 15% overall from three cases exhibited overlap between high spatial frequency domains and curvature domains. (2) Similar maps were obtained to gratings with different degrees of curvature (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). If the results were due primarily to spatial frequency content, the maps resulting from high and low curvature gratings should differ. (3) Similar maps were obtained to gratings and single lines of the same curvature (<xref ref-type="fig" rid="fig2">Figure 2K,L</xref>, <xref ref-type="fig" rid="fig6">Figure 6</xref>), although gratings and single lines have different spatial frequency contents. (4) Maps obtained in response to scrambled curvature stimuli (which also contain high spatial frequencies but lack the structural curvature information) failed to produce curvature maps. Thus, while we have not excluded all possibilities, we believe that the bulk of the evidence provides a consistent view. Note also that these curvature domains have little overlap with low spatial frequency domains (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>), further indicating that a representation of curvature and spatial frequency content are distinct.</p></sec><sec id="s3-3-3"><title>Unlikely to be end-stopping domains</title><p>As previous studies suggested, size tuning or end stopping may play an important role in curvature detection (<xref ref-type="bibr" rid="bib16">Hubel and Wiesel, 1965</xref>; <xref ref-type="bibr" rid="bib8">Dobbins et al., 1987</xref>) and is not independent from curvature preference features (<xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>). However, other studies have suggested neurons with complex receptive field structures may also account for curvature preferences (<xref ref-type="bibr" rid="bib23">Nandy et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Nandy et al., 2016</xref>). For this reason, while end-stopping likely contributes to curvature response, there are also other relevant parameters contributing to curvature response. (1) Surround suppressed and curvature domains are not the same: Similar to previous studies (<xref ref-type="bibr" rid="bib10">Ghose and Ts'o, 1997</xref>), we found there were size sensitive regions in V4 (Case 2, <xref ref-type="fig" rid="fig2s13">Figure 2—figure supplement 13A</xref>). However, while there was some overlap, the size sensitive regions were on the whole spatially distinct from the curvature domains (compare <xref ref-type="fig" rid="fig2s13">Figure 2—figure supplement 13A and B</xref>, overlay in C). (2) Weak response to small stimuli. Responses of curvature domains to small stimuli were weak in comparison to response to curvature stimuli (<xref ref-type="fig" rid="fig2s13">Figure 2—figure supplement 13D</xref>), suggesting weak end-stopping. Therefore curvature response can not be fully explained by strong responses to end-stopping. (3) In addition, if end-stopping was the only factor that matters, curvatures with opposite orientations would densely overlap, which is not the case (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Thus curvature preference response in V4 is not due to end-stopping alone.</p></sec></sec><sec id="s3-4"><title>Curvature domains are signature modules of V4</title><p>Our results are bolstered by another recent study which also reports the presence of curvature domains in V4 (<xref ref-type="bibr" rid="bib33">Tang et al., 2020</xref>). Using stimuli that included simple shapes (e.g. circles vs triangles) and shape components, the authors also report that curvature domains are distinct from orientation domains and color domains, and are absent in V1 and V2. Using two-photon imaging, the authors found neurons in curvature domains respond to a diversity of curved shapes and curve parts, and exhibit weak response to straight lines and corners. Within a curvature domain, they find subclusters of neurons with similar shape or curve part preference. Interestingly, some clusters exhibit preference for shapes (circles) over shape parts (curved portions of circles), raising the possibility that some domains in V4 may represent simple shapes. While the authors did not systematically explore the organization of curvature degree or curvature orientation, this elegant study further reinforces the concept that curvature domains are a primary feature of V4 organization.</p><sec id="s3-4-1"><title>Significance of modules—cortical modules represent key transformational stages in the visual hierarchy</title><p>We are excited that the combination of MRI (<xref ref-type="bibr" rid="bib25">Op de Beeck et al., 2008</xref>; <xref ref-type="bibr" rid="bib29">Popivanov et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Yue et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Bao et al., 2020</xref>), optical imaging (<xref ref-type="bibr" rid="bib10">Ghose and Ts'o, 1997</xref>; <xref ref-type="bibr" rid="bib34">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Lu et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Jiang et al., 2019</xref>; this study; <xref ref-type="bibr" rid="bib33">Tang et al., 2020</xref>), and two-photon (<xref ref-type="bibr" rid="bib19">Jiang et al., 2019</xref>; <xref ref-type="bibr" rid="bib33">Tang et al., 2020</xref>) scale studies are providing a functional organizational view of shape processing in the ventral visual pathway. While there is much yet unknown about curvature and shape representation, there is enough to see a sketch of the organizational hierarchy. By conducting fMRI mapping in response to a large array of stimuli containing curved (rounded, spheres, faces) vs rectilinear (square shapes, pyramid arrays, buildings) objects, <xref ref-type="bibr" rid="bib36">Yue et al., 2014</xref> reported the presence of three ~ 1–2 cm-sized curvature patches in the temporal lobe of macaque. These patches revealed a hierachy of increasing curvature complexity from the ‘posterior curvature-biased patch’ in near-foveal V4 (PCP), to a middle curvature-biased patch (MCP) in posterior STS, to an anterior curvature-biased patch (ACP) in anterior TE.</p><p>The region of V4 studied here corresponds well with Yue et al’s PCP patch. Here, zooming in to the several mm scale, we find 200–500 μm-sized curvature degree and curvature orientation domains within (what is likely) Yue’s PCP patch (see Yue <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>). Consistent with the lack of curvature response in V1, V2 (<xref ref-type="bibr" rid="bib36">Yue et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Hegdé and Van Essen, 2007</xref>; <xref ref-type="bibr" rid="bib28">Ponce et al., 2017</xref>), we found little evidence for curvature response preference in V1. Thus, much as V1 is considered the ‘orientation-emergent’ area, and V2 the ‘cue-invariant orientation-emergent’ area, we concur with the view that V4 is the ‘curvature-emergent’ area. Integration of signals from V4 curvature domains are likely to contribute to additional levels of systematic maps associated with lower (MCP, PFP) and higher (ACP, AFP) order object, face, and body patch representations (<xref ref-type="bibr" rid="bib2">Bao et al., 2020</xref>). We predict that these higher level patches will also contain systematic columnar maps.</p></sec></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Data was acquired from three hemispheres of two adult macaque monkeys (one male and one female, Macaca mulatta). All procedures were performed in accordance with the National Institutes of Health Guidelines and were approved by the Zhejiang University Institutional Animal Care and Use Committee.</p><sec id="s4-1"><title>Animal preparation</title><p>Chronic optical chambers were implanted above the area V4d containing lunate sulcus, superior temporal sulcus (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>) as described previously (<xref ref-type="bibr" rid="bib20">Li et al., 2013</xref>). The only difference is that we used transparent glass instead of a nylon chamber. The eccentricity of the visual field corresponding to the exposed V4/V2/V1 was 0–5°. Following the craniotomy surgery, optical images were collected during which basic functional maps as well as curvature responses of V4 were obtained. Monkeys were artificially ventilated and anesthetized with propofol (induction 5–10 mg/kg, maintenance 5–10 mg/kg/hr, i.v.) and isoflurane (0.5–1.5%). Anesthetic depth was assessed continuously via monitoring heart rate, end-tidal CO<sub>2</sub>, blood oximetry, and eeg. Rectal temperature was maintained at around 38C°. Animals were paralyzed (vecuronium bromide, induction 0.25 mg/kg, maintenance 0.05–0.1 mg/kg/hr, i.v.) and respirated. Pupils were dilated (atropine sulfate 1%) and eyes were fitted with contact lenses of appropriate curvature to focus on a stimulus screen 57 cm from the eyes.</p></sec><sec id="s4-2"><title>Visual stimuli for optical imaging</title><p>Visual stimuli were created using ViSaGe (Cambridge Research Systems Ltd.) and displayed on a calibrated 27-inch monitor (Philips 272G5D) running at 60 Hz refresh rate. The luminance for white stimuli was 206.52 cd/m<sup>2</sup> and black was 0.50 cd/m<sup>2</sup>. Full-Screen visual grating stimuli were used to locate color preference domains in V4. Red/green isoluminance and black-white sine-wave drifting grating stimuli were presented at two different orientations (45° and 135°) with the same spatial frequency (0.5 or one cycles/°), temporal frequency (2 or 4 Hz) and mean luminance level. To acquire orientation maps and spatial frequency (SF) maps, gratings with four different orientations (0°, 45°, 90°, 135°, see <xref ref-type="fig" rid="fig2">Figure 2J</xref>) and two different SFs (0.5, 4 cycles/deg) were presented.</p><p>Curvature stimuli were designed based on the formula of ellipse, X<sup>2</sup>/a<sup>2</sup> + Y<sup>2</sup>/b<sup>2</sup> = 1, where a and b represent the length of the long axis and short axis, respectively. Different a/b ratios were used (2, 5, see <xref ref-type="fig" rid="fig5">Figure 5B</xref>; 1, 4, 7, 10, see <xref ref-type="fig" rid="fig5">Figure 5C</xref>) to create different curvature degrees. The ellipses (see <xref ref-type="fig" rid="fig1">Figure 1</xref>) were cropped and duplicated to generate a curvature grating template. SF (along the long axis) of the curvature stimuli was varied by changing the spacing of the curves. The curvature grating was drifted by moving the stimulus window along the curved grating template (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). Drifting straight gratings were also created by this process and had the same luminance, drift speed, and spatial frequency (at center axis of curvature) as curvature stimuli. For curvature maps, the position of the stimuli on the monitor was first determined. As a control for curvature, scrambled versions of a curvature grating were created by dividing the grating into 64 subunits and randomly rearranging the locations of these subunits (<xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6A</xref>).</p><sec id="s4-2-1"><title>Retinotopic mapping</title><p>As we used vecuronium bromide during the experiment, the two eyes did not look at the same position of the monitor, thus for curvature mapping, we covered one eye and only presented the curvature stimuli to one eye. In every experiment session, we first mapped the RF location of V4 region and presented the stimuli at that location (~1–5 deg eccentricity in V4). For placement of stimuli on the monitor, we mapped the retinotopy of V4 using a series of 0.2° width horizontal or vertical dashed lines (SF = 1 cycles/°) located at different positions to determine the stimulus center (locating the stimulus center at the imaged V4 center, <xref ref-type="bibr" rid="bib20">Li et al., 2013</xref>, also see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). As the receptive field sizes of V4 neurons at our recording position are around 3–5 degrees (<xref ref-type="bibr" rid="bib6">Chen et al., 2014</xref>), our stimuli were set to 4° and presented monocularly during the experiment. Flashed curved lines were also 4° in size (for each line, the length was 4°). The center of straight lines or the vertex of curved lines were fixed at the position that we chose during the retinotopic mappings. The stimuli were presented at 4 or 8 Hz interleaved with black screen.</p></sec></sec><sec id="s4-3"><title>Optical imaging</title><p>The brain was imaged through the implanted glass. Images of cortical reflectance changes (intrinsic hemodynamic signals) corresponding to local cortical activity were acquired (Imager 3001, Optical Imaging Inc, German town, NY) with 632 nm illumination. Image size was 1080 × 1308 pixels representing 14.4 × 17.4 (case 2) or 8.7 × 10.5 (cases 1 and 3) mm field of view (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Visual stimuli were presented in a random order. Each stimulus was presented for 3.5 (for color and high spatial frequency stimuli) or 4.5 (curvature and corresponding straight stimuli) seconds. The imaging data were stored in a block fashion. Each block contained the imaging data recorded from all the stimulus conditions (presented one time). For functional domains, each stimulus was presented at least 30 times. For retinotopic mapping, each stimulus was presented 10 times. Imaging started 0.5 s before the stimulus onset and ended till the stimulus offset with a sampling rate of 4 Hz. In V4, cortical fields of view were ~1–5 deg eccentricity; in V1, locations were at about 1–2 deg eccentricity. For all three cases, very little V2 was available on the surface and so was unavailable for imaging (see <xref ref-type="fig" rid="fig2s11">Figure 2—figure supplement 11</xref>).</p></sec><sec id="s4-4"><title>Map-guided cell recording</title><p>Under a surgical microscope, a tungsten microelectrode (impedance 1–4 MU at 1 kHz, FHC) was lowered into the cortex (manipulator: Narishige MO-10) targeting the center of a curvature domain. Neural activity was amplifified at 1 k or 10 k gain (Model 1800, A-M Systems) and digitized at a sampling rate of 30 kHz (Blackrock microsystems). Each stimulus was normally tested for 15–30 trials.</p></sec><sec id="s4-5"><title>Data analysis</title><sec id="s4-5-1"><title>Functional maps</title><p>With the following formula, <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we assessed the response differences between two comparison groups. <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are the mean dR/R values (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>d</mml:mi><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>8</mml:mn><mml:mo>−</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, R<sub>8-16</sub> is the averaged response from frame 8 to 16, R<sub>1-3</sub> is the averaged response from frames 1 to 3) in the two compared conditions of pixel i, respectively, N is the number of trials, and S<sub>i</sub> is the standard deviation of <inline-formula><mml:math id="inf5"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Color preference maps were obtained by comparing red/green and white/black grating images, spatial frequency maps by comparing high and low spatial frequency images, and orientation maps by comparing two orthogonal orientation images (0° vs. 90° or 45° vs. 135°). For curvature maps, we compared the sum of curved gratings with the sum of straight gratings (four orientations: 0°, 45°, 90°, 135°). For single condition maps, we compared the selected condition with the averaged of straight gratings (four orientations: 0°, 45°, 90°, 135°). Maps were high-pass filtered (Gaussian filter, 10 pixel diameter) and low-frequency noise was reduced by convolving the map with a 100–150 pixel diameter circular filter and subtracted from the original maps. The orientation preference angle maps were calculated based on the single condition maps, and each pixels were assigned with a unique color to represent the preferred orientation (<xref ref-type="bibr" rid="bib4">Bosking et al., 1997</xref>).</p></sec><sec id="s4-5-2"><title>Locating positions of functional domains</title><p>Functional domains were identified by selecting the pixels with significant dR/R difference (two-tailed t test, p&lt;0.01) between two comparison conditions (color domains, red/green versus white/black, ∆dR/R &lt; 0; high spatial frequency domains, high spatial frequency versus low spatial frequency, ∆dR/R &lt; 0; 0° orientation domain, 0° versus 90°, ∆dR/R &lt; 0; 45° orientation domain, 45° versus 135°, ∆dR/R &lt; 0; 90° orientation domain, 90° versus 0°, ∆dR/R &lt; 0; 135° orientation domain, 135° versus 45°, ∆dR/R &lt; 0; Curvature domains, curved gratings versus straight gratings, ∆dR/R &lt; 0). In addition to t-test, pixels that belong to curvature domains were further assessed by one-way ANOVA (curved stimuli versus straight stimuli, p&lt;0.05 with post-hoc Tukey Kramer correction) test. Domain size was calculated as size = πR<sup>2</sup>, where area size is the size of each separated patch (pixel number ×area of each pixel), R is the average of long and short axis of patch. Patches smaller than 0.2 mm (diameter) were excluded from this analysis, as the reliability of these small patches is less secure. For each activated region, the geometrical center was calculated as its activation center (see <xref ref-type="fig" rid="fig7">Figure 7</xref>).</p></sec><sec id="s4-5-3"><title>Timecourse</title><p>For time courses, the value of each pixel was calculated first using the following functions: dR/R=(Fx-F0)/F0, where F0 is the average reflectance value of the first two frames (taken before visual stimuli onset), Fx is the reflectance value corresponding to frame X (X = 1, 2, 3...). To examine the response of a domain, we generated domain timecourses by averaging timecourse of all significant pixels within the domain (compared to blank, p&lt;0.01, two-tailed t test; see <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig5">5</xref>–<xref ref-type="fig" rid="fig7">7</xref>). To compare the responses of a domain to two stimulus conditions, we conducted a nonparametric test (Wilcoxon test, see <xref ref-type="fig" rid="fig2">Figure 2L</xref>) for values within frames 9–18. For some comparisons, the average of response groups were compared (e.g. all curved vs all straight).</p></sec><sec id="s4-5-4"><title>Similarity</title><p>To evaluate the similarity between two single condition maps, we extract the responses in the imaged area V4 (regions that could be activated by curvature stimuli during the experiment) and calculated the correlation coefficient values between the two response maps (see <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>). To evaluate the relationship between curvature degree difference and response similarity, we use the Regression function from Matlab. In this analysis, we use the condition number to represent the relative curvature degree of each curvature (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). The curvature degree difference is based on the relative distance between two curvature degrees.</p></sec><sec id="s4-5-5"><title>Statistical analysis</title><p>For all statistical comparisons of functional maps, we use two-tailed t test or ANOVA. We used the Wilcoxon rank sum for the comparisons between response amplitudes in two conditions when data failed to show a normal distribution.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This research was conducted at Zhejiang University and was supported by the National Key R &amp; D Program of China (2018YFA0701400 to AWR), the National Natural Science Foundation of China (8191101288, 31627802, 81430010 to AWR), and the Fundamental Research Funds for the Central Universities (2019XZZX003-20 to AWR, 2020FZZX001-05 to SXM). No US funds (NIH, OHSU) were used to support these experiments or preparation of this manuscript.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Investigation, Writing - original draft</p></fn><fn fn-type="con" id="con3"><p>Investigation</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Validation, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: All procedures were performed in accordance with the National Institutes of Health Guidelines and were approved by the Zhejiang University Institutional Animal Care and Use Committee with the approved protocols (Permit Number:zju20160242).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-57261-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting files.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anzai</surname> <given-names>A</given-names></name><name><surname>Peng</surname> <given-names>X</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neurons in monkey visual area V2 encode combinations of orientations</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1313</fpage><lpage>1321</lpage><pub-id pub-id-type="doi">10.1038/nn1975</pub-id><pub-id pub-id-type="pmid">17873872</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname> <given-names>P</given-names></name><name><surname>She</surname> <given-names>L</given-names></name><name><surname>McGill</surname> <given-names>M</given-names></name><name><surname>Tsao</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A map of object space in primate inferotemporal cortex</article-title><source>Nature</source><volume>583</volume><fpage>103</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2350-5</pub-id><pub-id pub-id-type="pmid">32494012</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blasdel</surname> <given-names>GG</given-names></name><name><surname>Salama</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Orientation selectivity, preference, and continuity in monkey striate cortex</article-title><source>Nature</source><volume>321</volume><fpage>579</fpage><lpage>585</lpage></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosking</surname> <given-names>WH</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>Schofield</surname> <given-names>B</given-names></name><name><surname>Fitzpatrick</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>2112</fpage><lpage>2127</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-06-02112.1997</pub-id><pub-id pub-id-type="pmid">9045738</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brincat</surname> <given-names>SL</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Underlying principles of visual shape selectivity in posterior inferotemporal cortex</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>880</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1038/nn1278</pub-id><pub-id pub-id-type="pmid">15235606</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Yan</surname> <given-names>Y</given-names></name><name><surname>Gong</surname> <given-names>X</given-names></name><name><surname>Gilbert</surname> <given-names>CD</given-names></name><name><surname>Liang</surname> <given-names>H</given-names></name><name><surname>Li</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Incremental integration of global contours through interplay between visual cortical Areas</article-title><source>Neuron</source><volume>82</volume><fpage>682</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.03.023</pub-id><pub-id pub-id-type="pmid">24811385</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An orientation map for motion boundaries in macaque V2</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>279</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu235</pub-id><pub-id pub-id-type="pmid">25260703</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dobbins</surname> <given-names>A</given-names></name><name><surname>Zucker</surname> <given-names>SW</given-names></name><name><surname>Cynader</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Endstopped neurons in the visual cortex as a substrate for calculating curvature</article-title><source>Nature</source><volume>329</volume><fpage>438</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1038/329438a0</pub-id><pub-id pub-id-type="pmid">3657960</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Ma</surname> <given-names>H</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>An orientation map for Disparity-Defined edges in area V4</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>666</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx348</pub-id><pub-id pub-id-type="pmid">29329408</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghose</surname> <given-names>GM</given-names></name><name><surname>Ts'o</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Form processing modules in primate area V4</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>2191</fpage><lpage>2196</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.4.2191</pub-id><pub-id pub-id-type="pmid">9114265</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghose</surname> <given-names>GM</given-names></name><name><surname>Ts'o</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Integration of color, orientation, and size functional domains in the ventral pathway</article-title><source>Neurophotonics</source><volume>4</volume><elocation-id>031216</elocation-id><pub-id pub-id-type="doi">10.1117/1.NPh.4.3.031216</pub-id><pub-id pub-id-type="pmid">28573155</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grinvald</surname> <given-names>A</given-names></name><name><surname>Lieke</surname> <given-names>E</given-names></name><name><surname>Frostig</surname> <given-names>RD</given-names></name><name><surname>Gilbert</surname> <given-names>CD</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Functional architecture of cortex revealed by optical imaging of intrinsic signals</article-title><source>Nature</source><volume>324</volume><fpage>361</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.1038/324361a0</pub-id><pub-id pub-id-type="pmid">3785405</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hegdé</surname> <given-names>J</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Strategies of shape representation in macaque visual area V2</article-title><source>Visual Neuroscience</source><volume>20</volume><fpage>313</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1017/S0952523803203102</pub-id><pub-id pub-id-type="pmid">14570253</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hegdé</surname> <given-names>J</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A comparative study of shape representation in macaque visual Areas v2 and v4</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>1100</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl020</pub-id><pub-id pub-id-type="pmid">16785255</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Segregation of form, color, and Stereopsis in primate area 18</article-title><source>The Journal of Neuroscience</source><volume>7</volume><fpage>3378</fpage><lpage>3415</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-11-03378.1987</pub-id><pub-id pub-id-type="pmid">2824714</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Receptive fields and functional architecture in two nonstriate visual Areas (18 and 19) OF the cat</article-title><source>Journal of Neurophysiology</source><volume>28</volume><fpage>229</fpage><lpage>289</lpage><pub-id pub-id-type="doi">10.1152/jn.1965.28.2.229</pub-id><pub-id pub-id-type="pmid">14283058</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Receptive fields and functional architecture of monkey striate cortex</article-title><source>The Journal of Physiology</source><volume>195</volume><fpage>215</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1968.sp008455</pub-id><pub-id pub-id-type="pmid">4966457</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Komatsu</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Representation of angles embedded within contour stimuli in area V2 of macaque monkeys</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>3313</fpage><lpage>3324</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4364-03.2004</pub-id><pub-id pub-id-type="pmid">15056711</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jiang</surname> <given-names>R</given-names></name><name><surname>i M</surname> <given-names>L</given-names></name><name><surname>Tang</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Discrete neural clusters encode orientation, curvature and 761 corners in macaque V4</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/808907</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A motion direction preference map in monkey V4</article-title><source>Neuron</source><volume>78</volume><fpage>376</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.024</pub-id><pub-id pub-id-type="pmid">23622068</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname> <given-names>Y</given-names></name><name><surname>Yin</surname> <given-names>J</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Gong</surname> <given-names>H</given-names></name><name><surname>Liu</surname> <given-names>Y</given-names></name><name><surname>Qian</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>X</given-names></name><name><surname>Liu</surname> <given-names>R</given-names></name><name><surname>Andolina</surname> <given-names>IM</given-names></name><name><surname>Wang</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Revealing detail along the visual hierarchy: neural clustering preserves acuity from V1 to V4</article-title><source>Neuron</source><volume>98</volume><fpage>417</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.009</pub-id><pub-id pub-id-type="pmid">29606580</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>TM</given-names></name><name><surname>Finkel</surname> <given-names>LH</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Shape representation by a network of V4-like cells</article-title><source>Neural Networks</source><volume>20</volume><fpage>851</fpage><lpage>867</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2007.06.004</pub-id><pub-id pub-id-type="pmid">17884335</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nandy</surname> <given-names>AS</given-names></name><name><surname>Sharpee</surname> <given-names>TO</given-names></name><name><surname>Reynolds</surname> <given-names>JH</given-names></name><name><surname>Mitchell</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The fine structure of shape tuning in area V4</article-title><source>Neuron</source><volume>78</volume><fpage>1102</fpage><lpage>1115</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.04.016</pub-id><pub-id pub-id-type="pmid">23791199</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nandy</surname> <given-names>AS</given-names></name><name><surname>Mitchell</surname> <given-names>JF</given-names></name><name><surname>Jadi</surname> <given-names>MP</given-names></name><name><surname>Reynolds</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neurons in macaque area V4 are tuned for complex Spatio-Temporal patterns</article-title><source>Neuron</source><volume>91</volume><fpage>920</fpage><lpage>930</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.026</pub-id><pub-id pub-id-type="pmid">27499085</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Op de Beeck</surname> <given-names>HP</given-names></name><name><surname>Deutsch</surname> <given-names>JA</given-names></name><name><surname>Vanduffel</surname> <given-names>W</given-names></name><name><surname>Kanwisher</surname> <given-names>NG</given-names></name><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A stable topography of selectivity for unfamiliar shape classes in monkey inferior temporal cortex</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>1676</fpage><lpage>1694</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm196</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasupathy</surname> <given-names>A</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Shape representation in area V4: position-specific tuning for boundary conformation</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>2505</fpage><lpage>2519</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.5.2505</pub-id><pub-id pub-id-type="pmid">11698538</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasupathy</surname> <given-names>A</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Population coding of shape in area V4</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>1332</fpage><lpage>1338</lpage><pub-id pub-id-type="doi">10.1038/972</pub-id><pub-id pub-id-type="pmid">12426571</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce</surname> <given-names>CR</given-names></name><name><surname>Hartmann</surname> <given-names>TS</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>End-Stopping predicts curvature tuning along the ventral stream</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>648</fpage><lpage>659</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2507-16.2016</pub-id><pub-id pub-id-type="pmid">28100746</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popivanov</surname> <given-names>ID</given-names></name><name><surname>Jastorff</surname> <given-names>J</given-names></name><name><surname>Vanduffel</surname> <given-names>W</given-names></name><name><surname>Vogels</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Tolerance of macaque middle STS body patch neurons to shape-preserving stimulus transformations</article-title><source>Journal of Cognitive Neuroscience</source><volume>27</volume><fpage>1001</fpage><lpage>1016</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00762</pub-id><pub-id pub-id-type="pmid">25390202</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pospisil</surname> <given-names>DA</given-names></name><name><surname>Pasupathy</surname> <given-names>A</given-names></name><name><surname>Bair</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>'Artiphysiology' reveals V4-like shape tuning in a deep network trained for image classification</article-title><source>eLife</source><volume>7</volume><elocation-id>e38242</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.38242</pub-id><pub-id pub-id-type="pmid">30570484</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramsden</surname> <given-names>BM</given-names></name><name><surname>Hung</surname> <given-names>CP</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Real and illusory contour processing in area V1 of the primate: a cortical balancing act</article-title><source>Cerebral Cortex</source><volume>11</volume><fpage>648</fpage><lpage>665</lpage><pub-id pub-id-type="doi">10.1093/cercor/11.7.648</pub-id><pub-id pub-id-type="pmid">11415967</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sceniak</surname> <given-names>MP</given-names></name><name><surname>Hawken</surname> <given-names>MJ</given-names></name><name><surname>Shapley</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Visual spatial characterization of macaque V1 neurons</article-title><source>Journal of Neurophysiology</source><volume>85</volume><fpage>1873</fpage><lpage>1887</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.85.5.1873</pub-id><pub-id pub-id-type="pmid">11353004</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname> <given-names>R</given-names></name><name><surname>Song</surname> <given-names>Q</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Zhang</surname> <given-names>R</given-names></name><name><surname>Cai</surname> <given-names>X</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Curvature-processing domains in primate V4</article-title><source>eLife</source><volume>9</volume><elocation-id>e57502</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57502</pub-id><pub-id pub-id-type="pmid">33211007</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanigawa</surname> <given-names>H</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional organization for color and orientation in macaque V4</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1542</fpage><lpage>1548</lpage><pub-id pub-id-type="doi">10.1038/nn.2676</pub-id><pub-id pub-id-type="pmid">21076422</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname> <given-names>H</given-names></name><name><surname>Dong</surname> <given-names>Z</given-names></name><name><surname>Wang</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>V4 shape features for contour representation and object detection</article-title><source>Neural Networks</source><volume>97</volume><fpage>46</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2017.09.010</pub-id><pub-id pub-id-type="pmid">29080474</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yue</surname> <given-names>X</given-names></name><name><surname>Pourladian</surname> <given-names>IS</given-names></name><name><surname>Tootell</surname> <given-names>RB</given-names></name><name><surname>Ungerleider</surname> <given-names>LG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Curvature-processing network in macaque visual cortex Curvature-processing network in macaque visual cortex</article-title><source>PNAS</source><volume>111</volume><fpage>E3467</fpage><lpage>E3475</lpage><pub-id pub-id-type="doi">10.1073/pnas.1412616111</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.57261.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Das</surname><given-names>Aniruddha</given-names> </name><role>Reviewer</role><aff><institution>Columbia</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Connor</surname><given-names>Ed</given-names> </name><role>Reviewer</role><aff><institution>Johns Hopkins University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Curvature is a fundamental component of our ability to recognise and discriminate visual objects and therefore interact with the world around us. This optical imaging study compellingly demonstrates a systematic functional architecture of specialised domains for processing and representing curvature in the visual cortex of primates, in particular visual area V4. This finding has profound implications for our understanding of how primates perceive and recognise shape.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Curvature domains in V4 of Macaque Monkey&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Aniruddha Das (Reviewer #2); Ed Connor (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that substantial additional analyses are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>In this manuscript, Hu and colleagues investigate the functional organisation of important elements for representing object shape in the primate brain. Their focus of investigation is the mapping of curvature in extrastriate visual area V4, an area in which there is substantial evidence for neurons representing intermediate visual features that are more complex than the representations of single orientation in receptive fields of V1 and V2. The authors show that there are clearly regions of V4 that are activated better by curvature stimuli than traditional single orientation stimuli and thus provide potentially exciting and novel data about organization of curvature orientation in area V4. Curvature tuning is widely regarded as a major step toward complex shape perception that arises specifically in V4, the third stage in primate ventral pathway.</p><p>However, there are some major concerns about the scope and specificity of the presented data and data analyses as well as the discussion of the results, which currently limit the ability of the reader to fully appreciate to what extent the organisation for curvature: (a) is truly specialised across V4; (b) cannot be explained by end stopped cells, clustering of orientation-tuning or size tuning; and (c) is distinct from the neuronal properties found in earlier visual areas V1 and V2. In general, we suggest the authors present their entire dataset, use the same analyses across the full range of imaging data from V4 and potentially extend to V1 and V2, and use statistical measures to analyse the responses around curvature clusters and pin wheels to establish the existence of gradients for curvature parameters. More detailed comments and suggestions are presented below. We think that these revisions and additional analyses should bring out the evidence of a specialised, spatially organized representation of curvature more clearly.</p><p>Essential revisions:</p><p>1) Additional analyses to strengthen the case for specialised curvature organisation in V4.</p><p>In some parts of the paper (Figures 3 and 5), the authors rely on pixel-wise correlation as a proxy for mapping. But pixel correlation conveys no information about spatial organization, and high correlations are equally compatible with entirely random organization of signals. For example, any pattern (even a scramble) is likely to preferentially activate some neurons by chance and therefore some pattern of activation across the cortex (e.g. Figure 2—figure supplement 6C). If a different pattern (like another scrambled) is presented it is likely that a different pattern is obtained, and if I do any kind of morphing between these images, I am necessarily going to gradually shift the pattern of activation from one to the other. But this says little about the nature of representation. There is also an issue of map noise: within condition consistency is often below 0.7, and it's not clear why.</p><p>Only graphical analysis of images showing spatial clustering of similar tuning, spatial relationships between clusters, and/or spatial gradients of tuning changes are meaningful for understanding mapping, and this paper only gets to that stage in Figure 7, and even then only for one relatively small region of one case. The critical results shown there (and the corresponding but unanalyzed results in Figures 6A and S9A,B) are the only convincing evidence of organization within V4 curvature domains, and that organization in turn is the most convincing evidence that curvature per se is represented rather than something correlated with curvature.</p><p>Even these plots confound two phenomena. One phenomenon appears to be true clustering of curvature direction tuning. The strongest prediction for curvature direction tuning is that opposite directions (differing by 180 degrees) should be the most separated. This is clearest, surprisingly, in Figures S9A and B, where regions tuned for the up direction are largely complementary to regions tuned for down. This convinces me that the authors have observed organization for curvature direction, and this case in particular deserves to be featured in the main text and analyzed as in Figure 7.</p><p>In contrast, especially in Figures 6 and 7, there are many regions where the responses to opposite directions are largely overlapping, and instead it is directions that are 90 degrees different that are most complementary. In those cases, the same straight to curved gradients will be observed for two opposite directions (as is the case for the central three gradients in Figure 7C). The simplest interpretation of this is tuning for component orientations, because curved gratings, especially in the higher curvature domain, share component orientations across 180 degree differences, but have distinct orientations across 90 degree differences. A more complex interpretation, but one supported by previous literature, is that some domains imaged here represent contours with multiple curvatures. This would be consistent with findings that many V4 neurons represent contour fragments containing multiple curvature directions (Pasupathy and Connor, 2001; Carlson et al., 2011). These are frequently curvatures with opposite directions, since many contour fragments contain adjoining convex and concave curves, which out of geometric necessity tend to point in opposite directions. In this sense, the three gradients in the center of 7C, and similar gradients (not analyzed) in Figure 6 may reflect the geometric structure of the natural world.</p><p>Our strong suggestion would be to analyze all the available imaging regions across V4 (not just individual cases or smaller regions within cases) with the analyses in Figure 7, making clear distinctions between gradients that are specific to a single curvature direction and those that overlap for two curvature directions, and discussing possible interpretations of the latter case.</p><p>2) Additional analyses to elucidate the functional nature of curvature domains and the &quot;pinwheel&quot; structures.</p><p>The lack of single unit data here is problematic, especially given the authors' model, because a curvature &quot;region&quot;, especially given its proximity to similar orientation regions, could simply be comprised of a mix of oriented cells with no individual cells showing curvature sensitivity. Looking at Figure 5, all curvatures are somewhat correlated with each other and with many orientations; this is clearly not the case for orientation in which there is basically no overlap between orientations. The model the authors present relies on the proximity of (and overlap between) curvature and orientation regions, but a &quot;multi-orientation&quot; region that includes individual neurons with a diversity of orientations tunings, but has no neurons with actual curvature preferences, would be equally plausible and consistent.</p><p>Because there is no single unit data, the regions of &quot;curvature&quot; activation could simply result from the co-activation of classically oriented cells (especially near pinwheel centers where such cells are likely to be colocalized). The authors are concerned that the presence of high spatial frequencies in the curvature stimuli is a confound, but there's no attempt to control for the increase in orientation content with curvature. Strong curvature contains a number of orientations, and we would therefore expect to activate multiple orientation columns, but this is not controlled for.</p><p>We believe it would be straightforward to control for: on a pixel-by-pixel basis see how responses to a curve could be explained by a weighted sum of the responses to the orientations that it contains. For example, small curvature responses should be similar to single orientation responses, while high curvature responses should be explainable by a mix of orientation responses (which according to map correlation data seems very reasonable). And an exact weighting of what orientations are present in a given curvature stimulus, can be done by looking at the 2-d Fourier transform of the stimulus.</p><p>Also, a similar analysis to that described in (point 1 above / Figure 7 of the manuscript) should be done to look for pinwheel structures, i.e. with overlapping contour maps and with gradient lines, and with clear presentation of the statistical significance of gradients presented prominently in the main paper. This may support the idea of pinwheel structures for curvature direction, in a way that would be graphically and statistically convincing. In contrast, the basis for the pinwheel maps in Figure 7D is unclear, so they are not appropriate for inclusion as presented. Even if pinwheels cannot be clearly identified, and if not all images show clear clustering for tuning, the main point of the paper would be established.</p><p>3) Extending analyses to available imaging data beyond V4 to strengthen the case that the organisation for curvature in V4 is different from functional representations in V1 and V2.</p><p>We were wondering why V1 and V2 were excluded. It looks like the authors are throwing out 2/3 of the data, and a vital component to making the case that there's something &quot;special&quot; going on in V4 is comparing it to other areas. On a similar note, V1 in case 2 looks problematic: there's no blob like activation of color and orientation columns aren't obvious (especially compared to the textbook examples shown in cases 1 and 3). Another exclusion issue: Figures 2 3, and 5 place letters so they obscure a substantial fraction of the imaged region.</p><p>A number of pertinent experimental details are also missing: there are 3 animals, but how many sessions, are there analyses in which the observations of multiple sessions are combined, and are there comparisons being made across sessions? Are stimuli presented binocularly? What are the RF locations of the V1, V2, and V4 regions?</p><p>Please extend the central analysis applied to V4 to V2 and V1 data and complete the requested information.</p><p>4) Discussing the results in the context of previous findings for single neuron tuning to show more clearly what other interpretations of the presented results are possible or can be rejected.</p><p>The curvature maps appear convincing: there are clearly regions of neurons that are activated better by curvature stimuli than traditional single orientation stimuli. However a simple explanation, dating back to 1965, of this would be the presence of end-stopped and surround suppression, and this is not addressed. The historical context seems a little off here; Livingstone's findings of 2017 are cited, but somehow Hubel and Wiesel, who in 1965 (J Neurophysiol) suggested that end-stopped, length tuned neurons could be useful for curvature detection, is omitted. There was a nice explicit model of how that could happen by Dobbins et al. in 1987 (Nature). But the manuscript makes no reference to any size tuning or surround suppression, and how that, in combination with classic orientation tuning, could create a cell that responds vigorously to curvature. This is even a greater concern given the well-established prevalence of size tuning, both electrophysiologically (1987) and with optical imaging (1997), in area V4. This has a huge impact on both novelty and interpretability; if you have a region of surround suppression (which we know exist) and it overlaps with an orientation region, there's a &quot;curvature&quot; region in that it will respond to a curve better than extended straight line or grating. But I would argue it's not a &quot;curvature&quot; region, since a short bar or grating without any curvature is actually the optimal stimulus. The absence of any reports of eccentricity or size tuning measurements does not install confidence that this is not what is responsible for these observations.</p><p>We think a clearer discussion of these issues would be important for the paper.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your article &quot;Curvature domains in V4 of Macaque Monkey&quot; for consideration by <italic>eLife</italic>. Your revised article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Aniruddha Das (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require a modest amount of additional new analysis/data, as they do with your paper, we are asking that the manuscript be revised to either limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Our expectation is that the authors will eventually carry out the additional experiments and report on how they affect the relevant conclusions either in a preprint on bioRxiv or medRxiv, or if appropriate, as a Research Advance in <italic>eLife</italic>, either of which would be linked to the original paper.</p><p>Summary:</p><p>In this manuscript, Hu and colleagues investigate the functional organisation of important elements for representing object shape in the primate brain. Their focus of investigation is the mapping of curvature in extrastriate visual area V4, an area in which there is substantial evidence for neurons representing intermediate visual features that are more complex than the representations of single orientation in receptive fields of V1 and V2. The authors show that there are clearly regions of V4 that are activated better by curvature stimuli than traditional single orientation stimuli and thus provide potentially exciting and novel data about organization of curvature orientation in area V4. Curvature tuning is widely regarded as a major step toward complex shape perception that arises specifically in V4, the third stage in primate ventral pathway.</p><p>Revisions for this paper:</p><p>The manuscript is largely improved, and the authors have effectively addressed some of the major concerns raised in the initial submission. For instance, the authors addressed the concern that the curvature is fully accounted for by end stopping / surround suppression. They show that short straight lines poorly stimulate “curvature” regions and that “end stopped” patches are substantially distinct from “curvature” patches even though they overlap partially (Figure 2—figure supplement 13). Additionally, while showing that end stopping and curvature are not identical, the authors are careful in stating that end stopping could play an important role in curvature processing. But an important concern appears incompletely addressed. The evidence for the curvature specific domains is strong and novel, however the reviewers felt that the claims regarding the specialised architecture of these domains, namely the ordered, gradual representation of different degrees of curvature and the existence of pinwheels have not been fully supported by the presented results. We suggest either addressing the additional evidence suggested in revisions or tempering these claims and addressing these issues in a subsequent, linked publication.</p><p>1) One issue that is not satisfactorily addressed is “curvature pinwheels”. The authors make a point of proposing that pinwheel structure is fundamental to the organization of maps like orientation (in V1) and curvature (V4). While that proposal could arguably be made for V1 (Li, 2019) the authors' own evidence here suggests that pinwheels might be a red herring for curvature in V4.</p><p>a) The authors only show pinwheels in one data set (Figure 7B(right hand panel). And there too only the single pinwheel in the upper curvature patch looks reasonable. In the lower curvature patch the upper pinwheel lies very close to the edge of the curvature region making the classification problematic given the ~250-micron FWHM spatial resolution of intrinsic signal optical imaging (Polimeni, PNAS 2005).</p><p>b) More importantly, the most striking characteristic in the “curvature orientation” maps appears to be the high degree of overlap between regions of opposite curvature direction (Figure 6D). The net “curvature orientation” vector in these regions of overlap are presumably close to zero vector length. The maps (e.g. Figure 7B) with saturated colors are thus likely misleading as the real pattern likely involves not point singularities of “curvature orientation” (“pinwheels”) but large overlap patches of poor net “curvature orientation” with short “curvature orientation”-specific extensions outwards. Notably the authors did not show “curvature-orientation” contour maps, quantify the local orientation gradient and test it for significance to support their proposal of pinwheels. It is likely that the signal to noise in such maps would be very low.</p><p>c) In the Discussion, it may be worth considering if the pattern of large patches of overlap with orientation-specific extensions may be the dominant topological motif, rather than trying to squeeze the map into a straitjacket of pinwheels.</p><p>2) With respect to the gradual shift in curvature maps, the response to the point of of pixel-wise map correlation was not adequate: the authors' response states that it merely establishes a curvature map, but any superposition of single condition domains, or differential analysis between different curvatures, establishes this. The manuscript says something more: there is a shifting map, implying some sort of continuity of representation. As stated in the previous comments, this strikes us as poor logic: if we take a low frequency, chromatic, linear grating, at one extreme, and a high frequency achromatic curve at another, the two activation maps will look different, and if I do a pixel wise morphing between those two stimuli that doesn't know anything about high level attributes like color, curvature, and SF, I necessarily have to create activation maps that look intermediate. It may be that subtle non-continuities, like fractures and pinwheels, in functional maps will make the change in correlations non-linear, but I'm not even sure of that. In other words, this analysis has to succeed, and is therefore, at least as it is presented, uninformative. If the authors are interested in the regularity or periodicity of representations, that a correlation analysis of cortical distance vs representational distance, seems more appropriate. For example, the spatial correlation of curvature preference on a pixel-wise basis, or between &quot;centers&quot; of domains. But, on the basis of what is presented, we are not sure how that is actually going turn out. For example, Figure 7 seems to show that 3/4 of the center of masses of &quot;up&quot; and &quot;down&quot; curvatures are basically on top of one another.</p><p>Revisions expected in follow-up work:</p><p>The reviewers felt that the claims regarding the specialised architecture of these domains, namely the ordered, gradual representation of different degrees of curvature and the existence of pinwheels have not been fully supported by the presented results. We suggest either addressing the additional evidence suggested in revisions or tempering these claims and addressing these issues in a subsequent, linked publication. See previous section for details.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.57261.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Additional analyses to strengthen the case for specialised curvature organisation in V4.</p><p>In some parts of the paper (Figures 3 and 5), the authors rely on pixel-wise correlation as a proxy for mapping. But pixel correlation conveys no information about spatial organization, and high correlations are equally compatible with entirely random organization of signals. For example, any pattern (even a scramble) is likely to preferentially activate some neurons by chance and therefore some pattern of activation across the cortex (e.g. Figure 2—figure supplement 6C). If a different pattern (like another scrambled) is presented it is likely that a different pattern is obtained, and if I do any kind of morphing between these images, I am necessarily going to gradually shift the pattern of activation from one to the other. But this says little about the nature of representation. There is also an issue of map noise: within condition consistency is often below 0.7, and it's not clear why.</p></disp-quote><p>Correlations between pairs of curvature stimuli:</p><p>1) 0.7 is not low. As shown in Figure 3—figure supplement 1, the comparisons of matched straight orientation maps, which are the best possible correlation indices, range from 0.66 to 0.9. In Figures 3 and 4 (previous Figures 3 and 5), the values for matched curvature maps, based on correlation between two conditions, also fall within this range (0.68-0.91). In our preparations, with the signal sizes recorded in V4 under anesthesia, and with data collected over hours of time, these values are typical. Figure 3—figure supplement 1 provides a benchmark by which to evaluate the value of the correlations. These values have now been incorporated in text.</p><p>2) Correlation values are related to curvature content. We agree with the reviewer that, in principle, correlations can result from non-curvature related responses, and even scrambled responses. However, here, we start with the observation that maps are differentially responsive to different degrees of curvature grating (curvature degree, Figure 3; curvature orientation, Figure 4). Then we show that these maps are systematically shifting using map correlations. We spend the rest of the manuscript providing additional support that these maps are truly curvature-specific responses. When considered in its entirety, our data supports the existence of curvature maps in V4.</p><disp-quote content-type="editor-comment"><p>Only graphical analysis of images showing spatial clustering of similar tuning, spatial relationships between clusters, and/or spatial gradients of tuning changes are meaningful for understanding mapping, and this paper only gets to that stage in Figure 7, and even then only for one relatively small region of one case. The critical results shown there (and the corresponding but unanalyzed results in Figures 6A and S9A,B) are the only convincing evidence of organization within V4 curvature domains, and that organization in turn is the most convincing evidence that curvature per se is represented rather than something correlated with curvature.</p></disp-quote><p>Paper organization: In response to the general critique that the maps for curvature domains come late in the paper, we think it is worthwhile to explain our general strategy. Our approach was to understand the organization of curvature response from global to local scale in V4. (1) We first show that response to curvature (preference for the curvature stimulus over the straight stimulus) falls within the “orientation bands” and not the “color” bands, and “curvature” domains are distinct from orientation domains. This finding alone is new (Figure 2). (2) We then examine, at the domain map scale, the organization and relationship with straight orientation maps. This provided some support for the possibility that responses might be related to curvature degree (Figures 3: Case 1, S11: Case 2, shifting correlations related to curvature degree) or to curvature orientation (new Figures 4: Case 2, S11: Case 1, higher when matched). Based on these global signals, V4 can distinguish different curvature degrees and curvature orientations. (3) To further examine whether these correlations are due to the curvature content, we analyzed the topographic region of V4 corresponding to the central (~1 degree) of the curvature stimulus (total stimulus size is 4 deg), which is the part with high curvature content. This revealed substructure within the putative curvature domains with preferential response for curvature degree and orientation (Figures 5, 6). (4) Finally, we made an attempt to provide some hypothesis about the global organization of curvature representation (Figure 7G). We concluded that, when taken all together, our data are consistent with the hypothesis that there is a systematic “curvature map” within V4. This is the first study showing such systematic maps at domain scale (cf. Yue et al., 2014, showed large regions responsive to curvature but did not report maps for curvature degree or curvature orientation. Tang et al: we recently learned of this study under review at e<italic>Life</italic> and have cited this study).This strategy is now described in the beginning of the Results under “General Approach”.</p><disp-quote content-type="editor-comment"><p>Even these plots confound two phenomena. One phenomenon appears to be true clustering of curvature direction tuning. The strongest prediction for curvature direction tuning is that opposite directions (differing by 180 degrees) should be the most separated. This is clearest, surprisingly, in Figures S9A and B, where regions tuned for the up direction are largely complementary to regions tuned for down. This convinces me that the authors have observed organization for curvature direction, and this case in particular deserves to be featured in the main text and analyzed as in Figure 7.</p></disp-quote><p>Adding Figure S9 to main text: complementary representation of up/down orientation: As the reviewers suggest, we have now added Figure S9 to Figure 6 (the new Figure 6A-C), and describe it in the main text. Figure 6A illustrates a region where opposing orientations (illustrated with both curved gratings and curved lines) are largely non overlapping. Figure 6A-C is now described in the text.</p><disp-quote content-type="editor-comment"><p>In contrast, especially in Figures 6 and 7, there are many regions where the responses to opposite directions are largely overlapping, and instead it is directions that are 90 degrees different that are most complementary. In those cases, the same straight to curved gradients will be observed for two opposite directions (as is the case for the central three gradients in Figure 7C). The simplest interpretation of this is tuning for component orientations, because curved gratings, especially in the higher curvature domain, share component orientations across 180 degree differences, but have distinct orientations across 90 degree differences. A more complex interpretation, but one supported by previous literature, is that some domains imaged here represent contours with multiple curvatures. This would be consistent with findings that many V4 neurons represent contour fragments containing multiple curvature directions (Pasupathy and Connor, 2001; Carlson et al., 2011). These are frequently curvatures with opposite directions, since many contour fragments contain adjoining convex and concave curves, which out of geometric necessity tend to point in opposite directions. In this sense, the three gradients in the center of 7C, and similar gradients (not analyzed) in Figure 6 may reflect the geometric structure of the natural world.</p><p>Curvature domain response not due to component orientations. Our evidence suggests these curvature responses are difficult to attribute simply to component orientations. We test this by examining whether curvature domains exhibit strong response to the 0,45,135 deg components of the curvature stimulus. In Figure 7—figure supplement 2A-D, we show that, while there are locations with robust response to straight stimuli (red lines in B,C: 0,45,135 graphs), the curvature domains exhibit little response to component straight stimuli. Instead, they show strong response only to curvatures; these responses are graded with changing curvature degree (dark to light gray lines). This suggests that the curvature response is not primarily a response to components of the curve. We also show (see “Not due to weighted sum” below) that the curvature response is not a weighted sum of straight responses. We have added text in Results under “Curvature domains are not pinwheel centers or sums of orientation components”.</p></disp-quote><p>Some V4 domains may represent contours with multiple curvatures or other invariant responses.</p><p>As the reviewer states, V4 neurons can represent contour fragments containing multiple curvature orientations (Pasupathy and Connor, 2001; Carlson et al., 2011). In this paper, we have taken an initial look at the organizations related to simple curvature degree and curvature orientation. We do not understand nor have we explored other possible combinations of different curvature response that may exist in V4. We believe that there may be higher order integrations reflecting combinations of curvatures or cue-invariant curvature response or even simple shapes (cf Tang et al. submitted). This parallels our thinking in V2, where there may be distinct domains responsive to single cue (e.g. motion dot borders) vs invariant multi-cue (e.g. regardless of which type of cue) border domains (Ramsden et al., 2015). Such possibilities will require further study.</p><p>There are indications within our data of possible higher order responses that are activated by different combinations of curvature orientations. For example, we illustrate locations where pixels are responsive to both upwards and downwards or both leftwards and rightwards curvature orientations (new Figure 6D brown regions). The percentage of such overlapping pixels is relatively small (overlapping pixels vs. all colored pixels was on average 22.4%; Case 1: 32.1%; Case 2: 14.9%; Case 3: 20.3%). Thus, although there were “complex” pixels responsive to multiple orientations, representation of opposing curvature orientations was mostly non-overlapping.</p><p>In sum, we believe that the organization is likely to contain further complexity and requires further study. We indeed embrace the idea that representation of convex and concave “shape fragments” may derive from statistics of natural stimuli (e.g. David et al., 2004 J Neurosci; Movshon and Simoncelli, 2015). Hebbian-based principles may lead to establishment of systematic domain-based maps that reflect statistics of the natural environment. Such domain diversity would be consistent with a mid-tier stage of shape representation.</p><disp-quote content-type="editor-comment"><p>Our strong suggestion would be to analyze all the available imaging regions across V4 (not just individual cases or smaller regions within cases) with the analyses in Figure 7, making clear distinctions between gradients that are specific to a single curvature direction and those that overlap for two curvature directions, and discussing possible interpretations of the latter case.</p></disp-quote><p>As we mentioned above, our strategy was to focus on the region responsive to the central curvature part of our stimulus. Figures 4-7 are focused on this central representation. As shown in Figure 7—figure supplement 2A, we purposely focused on the central region (~1 deg, red box) of the 4 deg curvature stimulus. This is the region that contains the greatest changing curvature across curvature degree stimuli. In addition, the central region experiences relatively constant curvature orientation and spatial frequency across conditions, unlike the flanking parts of the stimulus (blue box), which contain large spatial frequency and orientation differences across conditions). Thus, the non-central regions are distinct in that they contain relatively straight components and a broader mixture of orientations and spatial frequencies across conditions. This has been clarified in Results under “General Approach” and “the central ~1 deg representation” stated where appropriate in the text.</p><p>V1/V2 and V4 represent different retinotopic locations in the same field of view. In each experiment, we identified cortical location corresponding to central ~1 deg of the stimulus. To determine the region of cortex corresponding to this central region, we first mapped, monocularly, the RF location of the V4 region (Figure 2—figure supplement 2), using vertical and horizontal 0.2° wide bars (vertical: different x; horizontal: different y, Figure 2—figure supplement 2A,G,M). In each case, the central ~1 deg stimulus covered a cortical area roughly ~4-5mm in diameter; we therefore evaluated curvature response from this small region. In some experiment sessions, we also presented a flashed white square (size=1°) at the determined V4 center (X0, Y0) to estimate the coverage area of the central part of the stimulus (See Figure 2—figure supplement 2H and M). This is now explicitly stated in text and retinotopic mapping methods described in text and Materials and methods under “Retinotopic mapping”.</p><disp-quote content-type="editor-comment"><p>2) Additional analyses to elucidate the functional nature of curvature domains and the &quot;pinwheel&quot; structures.</p><p>The lack of single unit data here is problematic, especially given the authors' model, because a curvature &quot;region&quot;, especially given its proximity to similar orientation regions, could simply be comprised of a mix of oriented cells with no individual cells showing curvature sensitivity. Looking at Figure 5, all curvatures are somewhat correlated with each other and with many orientations; this is clearly not the case for orientation in which there is basically no overlap between orientations. The model the authors present relies on the proximity of (and overlap between) curvature and orientation regions, but a &quot;multi-orientation&quot; region that includes individual neurons with a diversity of orientations tunings, but has no neurons with actual curvature preferences, would be equally plausible and consistent.</p><p>Because there is no single unit data, the regions of &quot;curvature&quot; activation could simply result from the co-activation of classically oriented cells (especially near pinwheel centers where such cells are likely to be colocalized). The authors are concerned that the presence of high spatial frequencies in the curvature stimuli is a confound, but there's no attempt to control for the increase in orientation content with curvature. Strong curvature contains a number of orientations, and we would therefore expect to activate multiple orientation columns, but this is not controlled for.</p></disp-quote><p>Curvature domains are not pinwheel centers. The reviewer raises a good point, concerning the possibility that curvature responses could be due to activation of a mixture of oriented responses, such as that found at orientation pinwheel centers. (1) As shown in the following figure (new Figure 2—figure supplement 12), the curvature domains (orange regions) do not co-localize with orientation pinwheel centers (blue dots). In fact, most of the pinwheel centers are outside the curvature domains entirely. (2) Moreover, as shown by the responses of pinwheel centers to straight and curved stimuli (E), the pinwheel center responses to curvatures are weak and do not distinguish curvature from straight (Wilcoxon test, p=0.13). This makes it unlikely for pinwheel centers to be locations of curvature response. We have added text in Results under “Curvature domains are not pinwheel centers or sums of orientation components”.</p><p>Lack of electrophysiology: Given the time-consuming nature of our optical imaging data collection, we were not able to focus on electrophysiological characterization. As the goal of this study was to evaluate the functional organization of V4, we focused our efforts on collecting optical imaging data. However, we did collect a small number of units. During imaging of Case 3, we targeted a few penetrations to curvature domains (Figure 2—figure supplement 9). Although the number of neurons recorded is small, our data are consistent with the curvature maps. We found that single-unit and multi-unit responses (n=26) in curvature domains (n=3) preferred curvature stimuli over straight stimuli and exhibited weak responses to straight stimuli. This suggests that curvature domains are not simply comprised of a mix of orientation cells. This is now described in the text.</p><disp-quote content-type="editor-comment"><p>We believe it would be straightforward to control for: on a pixel-by-pixel basis see how responses to a curve could be explained by a weighted sum of the responses to the orientations that it contains. For example, small curvature responses should be similar to single orientation responses, while high curvature responses should be explainable by a mix of orientation responses (which according to map correlation data seems very reasonable). And an exact weighting of what orientations are present in a given curvature stimulus, can be done by looking at the 2-d Fourier transform of the stimulus.</p></disp-quote><p>Not due to a weighted sum. According to reviewers’ comments, we show the cortical responses to the orientations in different curvature stimuli. As shown in the Figures 7—figure supplement 2B-D, the stimuli with low curvature degrees tend to be similar to the single orientation responses. However, for high curvature degrees, the responses of orientation domains were weak, only curvature domains show strong response. Thus the high curvature responses in curvature domains cannot be explained simply by a weighted sum of these orientation responses (2D fourier transform revealed that there are orientation components around 45° and 135° in the curvature stimuli, Figure 7—figure supplement 2A). To do a quick calculation of a weighted sum of these orientation responses, we chose the responses of 0, 45, 135 orientation domains (as these domains cover the range of the orientations in the curvature stimuli). , here Response is the weighted sum of these orientation responses, Response<sub>i</sub> represents the response of corresponding orientation domain (i=0, 45, 135) to curvature, Wi represents the weight of different orientations, here we consider these orientations contribute equally, thus Wi=1/3. For upwards curvature (from Figure 7—figure supplement 2C, a/b ratio=7), Response<sub>0</sub>=-0.0026%, Response<sub>45</sub>=-0.0027%, Response<sub>135</sub>=0.0006%, Wi=1/3, Response=-0.0016%, much weaker (by almost an order of magnitude) than the response in curvature domains -0.0115% (responses were calculated by average of the response amplitudes from the last 10 frames). While we are not able to test the weighted sum of all possible orientations, at least with this simple test, we do not see any indication of component summation. We have added text in Results under “Curvature domains are not pinwheel centers or sums of orientation components” and in Discussion.</p><p>In summary: We focused on the regions corresponding to the central ~1 deg of the stimuli (where curvature content changes the most across stimuli). (1) We find that the curvature responses are not due to the component orientation signals, as these are located in the orientation domains. In domains with response to high curvature, the responses to orientation are very weak (Figure 7—figure supplement 2). (2) Orientation pinwheel centers and curvature domains are in different spatial locations (Figure 2—figure supplement 12). Orientation pinwheel centers and curvature domains had different response preferences: pinwheels failed to distinguish between curvature and straight, and their responses to curvatures are weak (Figure 2—figure supplement 9). (3) Electrophysiological recordings in curvature domains show that, at least in the small sample of penetrations, neurons predominantly prefer curvature. Thus the responses here are more likely due to the curvature content rather than orientation component features. Substantial text has been added in Discussion under “Testing other possible interpretations”.</p><disp-quote content-type="editor-comment"><p>Also, a similar analysis to that described in (point 1 above / Figure 7 of the manuscript) should be done to look for pinwheel structures, i.e. with overlapping contour maps and with gradient lines, and with clear presentation of the statistical significance of gradients presented prominently in the main paper. This may support the idea of pinwheel structures for curvature direction, in a way that would be graphically and statistically convincing. In contrast, the basis for the pinwheel maps in Figure 7D is unclear, so they are not appropriate for inclusion as presented. Even if pinwheels cannot be clearly identified, and if not all images show clear clustering for tuning, the main point of the paper would be established.</p></disp-quote><p>We agree that the data regarding potential pinwheels is not sufficient and have now removed any mention of curvature pinwheels from the paper.</p><disp-quote content-type="editor-comment"><p>3) Extending analyses to available imaging data beyond V4 to strengthen the case that the organisation for curvature in V4 is different from functional representations in V1 and V2.</p><p>We were wondering why V1 and V2 were excluded. It looks like the authors are throwing out 2/3 of the data, and a vital component to making the case that there's something &quot;special&quot; going on in V4 is comparing it to other areas. On a similar note, V1 in case 2 looks problematic: there's no blob like activation of color and orientation columns aren't obvious (especially compared to the textbook examples shown in cases 1 and 3). Another exclusion issue: Figures 2 3, and 5 place letters so they obscure a substantial fraction of the imaged region.</p></disp-quote><p>Clear V1 responses in Case 2. The reviewers ask about the unclear responses in V1 from Case 2 (Figure 2—figure supplement 1D, E). In this case, the cortex underneath the coverglass was not flat, resulting in a band of cortex that was out of the plane of focus. However, distinct blob maps (Figure 2—figure supplement 1D) and some orientation maps (Figure 2—figure supplement 1E) were obtained in V1. In other sessions, we obtained strong V1 response in this Case (see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>).</p><fig id="sa2fig1"><label>Author response image 1.</label><caption><title>Clear functional maps of Case 2 from a different experiment session.</title><p>A. Color map. B. Orientation map.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57261-resp-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>A number of pertinent experimental details are also missing: there are 3 animals, but how many sessions, are there analyses in which the observations of multiple sessions are combined, and are there comparisons being made across sessions? Are stimuli presented binocularly? What are the RF locations of the V1, V2, and V4 regions?</p></disp-quote><p>Missing Details. (1) We did 27 experimental sessions on three hemispheres of two monkeys. Text has been added. We conducted 6-12 sessions in each hemisphere. Each experimental session was focused on answering different questions. (2) We did obtain repeats of some maps. For example, in Figure 2—figure supplement 5, we compared the curvature maps in two different experiment sessions from the same hemisphere. The maps are consistent across time. Text has been added. (3) As we used vecuronium bromide during the experiment, the two eyes did not look at the same position of the monitor, thus for curvature mapping, we covered one eye and only presented the curvature stimuli to one eye. Described in Materials and methods. (4) In every experiment session, we first mapped the RF location of V4 region and presented the stimuli at that location (~1-5 deg eccentricity in V4). For V1, locations were at about 1-2 deg eccentricity (see Figure 2 — figure supplement1). We did not have much V2 available on the surface in these cases (see Figure 2—figure supplement 11). We have now incorporate this into the Materials and methods.</p><disp-quote content-type="editor-comment"><p>Please extend the central analysis applied to V4 to V2 and V1 data and complete the requested information.</p></disp-quote><p>V2 not available on surface. In these three cases, there is limited amount of V2 on the surface; most of V2 is buried within the lunate sulcus (Figure 2—figure supplement 11). Thus we do not have data from V2. Text has been added.</p><p>Most of V1 not imaged due to retinotopic mismatch: See Figure 2—figure supplement 2.</p><p>V1 does not contain curvature domains. We examined whether V1 contains curvature maps. In two experimental sessions from Case 3 (see Figure 2—figure supplement 10), we positioned the stimulus center over the exposed V1. We first determined the visuotopic location by mapping a 1 deg stimulus (Figure 2—figure supplement 10A, red dotted line, position of stimulus differs by ~1 deg in Experiment 1 and Experiment 2). In both experimental sessions, when the 4 deg curvature stimulus was centered over this location, V1 failed to show any significant preference for curvature over straight (Figure 2—figure supplement 10B). So, this suggests that, unlike V4, V1 does not contain curvature domains; this finding is consistent with previous studies (Yue et al., 2014; Ponce et al., 2017). Text has been added.</p><disp-quote content-type="editor-comment"><p>4) Discussing the results in the context of previous findings for single neuron tuning to show more clearly what other interpretations of the presented results are possible or can be rejected.</p><p>The curvature maps appear convincing: there are clearly regions of neurons that are activated better by curvature stimuli than traditional single orientation stimuli. However a simple explanation, dating back to 1965, of this would be the presence of end-stopped and surround suppression, and this is not addressed. The historical context seems a little off here; Livingstone's findings of 2017 are cited, but somehow Hubel and Wiesel, who in 1965 (J Neurophysiol) suggested that end-stopped, length tuned neurons could be useful for curvature detection, is omitted. There was a nice explicit model of how that could happen by Dobbins et al. in 1987 (Nature). But the manuscript makes no reference to any size tuning or surround suppression, and how that, in combination with classic orientation tuning, could create a cell that responds vigorously to curvature. This is even a greater concern given the well-established prevalence of size tuning, both electrophysiologically (1987) and with optical imaging (1997), in area V4. This has a huge impact on both novelty and interpretability; if you have a region of surround suppression (which we know exist) and it overlaps with an orientation region, there's a &quot;curvature&quot; region in that it will respond to a curve better than extended straight line or grating. But I would argue it's not a &quot;curvature&quot; region, since a short bar or grating without any curvature is actually the optimal stimulus. The absence of any reports of eccentricity or size tuning measurements does not install confidence that this is not what is responsible for these observations.</p></disp-quote><p>End-stopping and surround suppression are not sufficient to explain all the curvature responses. We appreciate the reviewer for raising the important question of whether size tuning may contribute to curvature preference response. As previous studies suggested, size tuning or end stopping may play an important role in curvature detection (Hubel and Wiesel, 1965; Dobbins et al., 1987) and is not independent from curvature preference features (Ponce et al., 2017). However other studies have suggested neurons with complex receptive field structures may also account for curvature preferences (Nandy et al., 2013, 2016). For this reason, while end-stopping likely contributes to curvature response, there are also other relevant parameters contributing to curvature response. (1) Surround suppressed and curvature domains are not the same: Similar to previous studies (Ghose and Ts'o, 1997), we found there were size sensitive regions in V4 (Case 2, Figure 2—figure supplement 13A). However, while there was some overlap, the size sensitive regions were on the whole spatially distinct from the curvature domains (compare Figure 2—figure supplement 13A and B, overlay in Figure 2—figure supplement 13C). (2) Weak response to small stimuli. Responses of curvature domains to small stimuli were weak in comparison to response to curvature stimuli (Figure 2—figure supplement 13D), suggesting weak end-stopping. Therefore curvature response cannot be fully explained by strong responses to end-stopping. (3) In addition, if end-stopping was the only factor that matters, curvatures with opposite orientations would densely overlap, which is not the case (Figure 6). Thus curvature preference response in V4 is not due to end-stopping alone. This is now described in Results under “Curvature domains are not end-stopping domains” and in Discussion under “Unlikely to be end-stopping domains”.</p><p>The curvature domain is based on curvature preference, not on surround suppression or end-stopping. The reviewer suggests that the imaged response to a curve may actually be a response to a short bar. We show in Figure 2—figure supplement 13 that this is not the case. The response to the small stimulus (“short bar”) is not strongly relative to the curvature response. While it is possible that some “curvature domains” may be termed “end-stopped domains” (i.e. regions of overlap in Figure 2—figure supplement 13C, 33.3% of orange pixels), at least some curvature domains exhibit poor end-stopping and are consistent with “curvature domain” (66.7% of orange pixels).</p><disp-quote content-type="editor-comment"><p>We think a clearer discussion of these issues would be important for the paper.</p></disp-quote><p>We have now completely rewritten this section and provided a more in depth discussion. It now includes a more in depth summary and the hypercolumn model (Figure 7E) has been moved to discussion. A new section entitled “Testing other possible interpretations” discusses possible contributions from component orientation, high spatial frequency, and end-stopping responses. Relationship of our findings with other studies is now expanded. In addition, we describe the significance of this work as providing a columnar hierarchy for shape representation.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Revisions for this paper:</p><p>The manuscript is largely improved, and the authors have effectively addressed some of the major concerns raised in the initial submission. For instance, ehe authors addressed the concern that the curvature is fully accounted for by end stopping / surround suppression. They show that short straight lines poorly stimulate “curvature” regions and that “end stopped” patches are substantially distinct from “curvature” patches even though they overlap partially (Figure 2—figure supplement 13). Additionally, while showing that end stopping and curvature are not identical, the authors are careful in stating that end stopping could play an important role in curvature processing. But an important concern appears incompletely addressed. The evidence for the curvature specific domains is strong and novel, however the reviewers felt that the claims regarding the specialised architecture of these domains, namely the ordered, gradual representation of different degrees of curvature and the existence of pinwheels have not been fully supported by the presented results. We suggest either addressing the additional evidence suggested in revisions or tempering these claims and addressing these issues in a subsequent, linked publication.</p><p>1) One issue that is not satisfactorily addressed is “curvature pinwheels”. The authors make a point of proposing that pinwheel structure is fundamental to the organization of maps like orientation (in V1) and curvature (V4). While that proposal could arguably be made for V1 (Li, 2019) the authors' own evidence here suggests that pinwheels might be a red herring for curvature in V4.</p><p>a) The authors only show pinwheels in one data set (Figure 7B(right hand panel). And there too only the single pinwheel in the upper curvature patch looks reasonable. In the lower curvature patch the upper pinwheel lies very close to the edge of the curvature region making the classification problematic given the ~250-micron FWHM spatial resolution of intrinsic signal optical imaging (Polimeni, PNAS 2005).</p></disp-quote><p>We agree that the data regarding potential pinwheels is not sufficient and have now removed any mention of pinwheels from the paper.</p><disp-quote content-type="editor-comment"><p>b) More importantly, the most striking characteristic in the “curvature orientation” maps appears to be the high degree of overlap between regions of opposite curvature direction (Figure 6D). The net “curvature orientation” vector in these regions of overlap are presumably close to zero vector length. The maps (e.g. Figure 7B) with saturated colors are thus likely misleading as the real pattern likely involves not point singularities of “curvature orientation” (“pinwheels”) but large overlap patches of poor net “curvature orientation” with short “curvature orientation”-specific extensions outwards. Notably the authors did not show “curvature-orientation” contour maps, quantify the local orientation gradient and test it for significance to support their proposal of pinwheels. It is likely that the signal to noise in such maps would be very low.</p></disp-quote><p>Yes, we agree with the reviewer’s assessment. We removed Figure 7A-D and revised the summary figure in Figure 7E.</p><disp-quote content-type="editor-comment"><p>c) In the Discussion, it may be worth considering if the pattern of large patches of overlap with orientation-specific extensions may be the dominant topological motif, rather than trying to squeeze the map into a straitjacket of pinwheels.</p></disp-quote><p>Yes, we agree. We have simplified the model (Figure 7E) to reflect the data that we present. These include basic curvature domains, the presence of curvature degree progressions, and potential highly overlapped complex curvature domains.</p><disp-quote content-type="editor-comment"><p>2) With respect to the gradual shift in curvature maps, the response to the point of of pixel-wise map correlation was not adequate: the authors' response states that it merely establishes a curvature map, but any superposition of single condition domains, or differential analysis between different curvatures, establishes this. The manuscript says something more: there is a shifting map, implying some sort of continuity of representation. As stated in the previous comments, this strikes us as poor logic: if we take a low frequency, chromatic, linear grating, at one extreme, and a high frequency achromatic curve at another, the two activation maps will look different, and if I do a pixel wise morphing between those two stimuli that doesn't know anything about high level attributes like color, curvature, and SF, I necessarily have to create activation maps that look intermediate. It may be that subtle non-continuities, like fractures and pinwheels, in functional maps will make the change in correlations non-linear, but I'm not even sure of that. In other words, this analysis has to succeed, and is therefore, at least as it is presented, uninformative. If the authors are interested in the regularity or periodicity of representations, that a correlation analysis of cortical distance vs representational distance, seems more appropriate. For example, the spatial correlation of curvature preference on a pixel-wise basis, or between &quot;centers&quot; of domains. But, on the basis of what is presented, we are not sure how that is actually going turn out. For example, Figure 7 seems to show that 3/4 of the center of masses of &quot;up&quot; and &quot;down&quot; curvatures are basically on top of one another.</p></disp-quote><p>We agree with the reviewer that a simple correlation analysis as presented in not sufficient to infer a systematic progression of shifting curvature domains. We have now added, as the reviewer suggested, analyses of the distances in Figure 7 (Case 1) and in Figure 7—figure supplement 1 (Cases 2 and 3). For each case, we focused on the regions that corresponded to the central ~1 deg of the stimulus; we analyzed all the straight domains and the corresponding curvature domains (with same orientation). Starting from a straight orientation domain, we selected the nearest domain of each adjacent condition (shown in Figure 7B) and measured the distances between center of mass of each domain and that of the straight domain (leftmost panel in Figure 7C). These values are plotted in Figure 7D. This illustrates that the curvature preference domains generally progress from low to high curvature with distance across the cortex. It is informative that the progression is not necessarily linear, a point we bring up in Discussion. We also do not suggest that this indicates any continuity of representation, merely that there is a generally increasing distance with curvature change. We thank the reviewer for suggesting this analysis. We also add in the legends of Figure 3 that the fitted lines are not meant to indicate linear fits; rather, they help the reader see the trends of the different groups of points. Analyses of the two other cases are shown in Figure 7—figure supplement 1.</p><p>In addition, we also observed examples of a clear separation between straight response and curvature response (Figure 7—figure supplement 1C) and domains of broad curvature degree preference (Figure 7—figure supplement 1G). Thus, not all curvature domains are organized in progressions.</p><p>In total across the 3 cases, on average, there is a general overall tendency for straight-to-curved domains to exhibit spatial shifts. However, there are some domains with broad curvature preference. This suggests the presence of a diversity in organization, indicating that curvature representation in V4 is complex.</p></body></sub-article></article>