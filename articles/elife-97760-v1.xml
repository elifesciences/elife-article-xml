<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">97760</article-id><article-id pub-id-type="doi">10.7554/eLife.97760</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.97760.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Effort drives saccade selection</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Koevoet</surname><given-names>Damian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9395-6524</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Van Zantwijk</surname><given-names>Laura</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Naber</surname><given-names>Marnix</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Mathôt</surname><given-names>Sebastiaan</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>van der Stigchel</surname><given-names>Stefan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5918-3521</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Strauch</surname><given-names>Christoph</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6380-8635</contrib-id><email>c.strauch@uu.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04pp8hn57</institution-id><institution>Experimental Psychology, Helmholtz Institute, Utrecht University</institution></institution-wrap><addr-line><named-content content-type="city">Utrecht</named-content></addr-line><country>Netherlands</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/012p63287</institution-id><institution>Department of Psychology, University of Groningen</institution></institution-wrap><addr-line><named-content content-type="city">Groningen</named-content></addr-line><country>Netherlands</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/006w34k90</institution-id><institution>Stanford University, Howard Hughes Medical Institute</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/006w34k90</institution-id><institution>Stanford University, Howard Hughes Medical Institute</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>07</day><month>04</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP97760</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-03-20"><day>20</day><month>03</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-03-23"><day>23</day><month>03</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.02.06.579052"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-05-17"><day>17</day><month>05</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97760.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-02-28"><day>28</day><month>02</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97760.2"/></event></pub-history><permissions><copyright-statement>© 2024, Koevoet et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Koevoet et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-97760-v1.pdf"/><abstract><p>What determines where to move the eyes? We recently showed that pupil size, a well-established marker of effort, also reflects the effort associated with making a saccade (‘saccade costs’). Here, we demonstrate saccade costs to critically drive saccade selection: when choosing between any two saccade directions, the least costly direction was consistently preferred. Strikingly, this principle even held during search in natural scenes in two additional experiments. When increasing cognitive demand experimentally through an auditory counting task, participants made fewer saccades and especially cut costly directions. This suggests that the eye-movement system and other cognitive operations consume similar resources that are flexibly allocated among each other as cognitive demand changes. Together, we argue that eye-movement behavior is tuned to adaptively minimize saccade-inherent effort.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>On average, we move our eyes three times per second. Where we decide to look next is one of the most frequent choices that our brains make, but how does the brain know where to look? Previous work has established that we tend to look towards elements that ‘pop out’ visually, are relevant for our goals, or places that have previously provided us with information. However, a lot of eye movement behavior cannot be explained by these factors.</p><p>Koevoet, Strauch et al. wanted to better understand how our brains decide where to look next. The researchers hypothesized that the ‘cost’ of eye movements (the brain has to compute the visual consequences of the eyes moving in a certain way) might influence where we look. To save resources, more ‘affordable’ eye movements may be preferred over costly ones.</p><p>To test this hypothesis, Koevoet, Strauch et al. measured the effort of eye movements by looking at the pupil size before an eye movement is made. A larger pupil size indicates more effort is required to prepare the movement. The measurements showed that the cost of eye movements depended on the direction of the eye movement, and that affordable ones were chosen over more costly ones. These findings indicate that effort drives where eyes move, supporting the more general idea that the brain is highly efficient with its resources.</p><p>Koevoet, Strauch et al.’s experiments show that cost predicts where the eyes will move. Future studies should explore where and how the brain stores and uses this information to make decisions, and how cost is integrated with other established factors that drive where we look.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>effort</kwd><kwd>cost</kwd><kwd>saccade selection</kwd><kwd>pupil size</kwd><kwd>decision-making</kwd><kwd>humans</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/863732</award-id><principal-award-recipient><name><surname>Koevoet</surname><given-names>Damian</given-names></name><name><surname>van der Stigchel</surname><given-names>Stefan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Humans optimize effort expenditure even at the level of eye movements by choosing affordable eye movements over costly alternatives and adjusting gaze behavior based on task demands.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Humans make fast, ballistic eye movements, called saccades, to explore the rich visual world (<xref ref-type="bibr" rid="bib49">Findlay and Gilchrist, 2003</xref>). Saccades are executed approximately three to four times per second (<xref ref-type="bibr" rid="bib65">Henderson, 2003</xref>; <xref ref-type="bibr" rid="bib64">Henderson and Hollingworth, 1998</xref>). Where to saccade is, therefore, one of the most frequent decisions the brain is faced with (<xref ref-type="bibr" rid="bib16">Bargary et al., 2017</xref>).</p><p>It is well established that the physical properties of the environment (bottom-up information) (<xref ref-type="bibr" rid="bib90">Kümmerer et al., 2022</xref>; <xref ref-type="bibr" rid="bib89">Kümmerer et al., 2016</xref>; <xref ref-type="bibr" rid="bib74">Itti et al., 1998</xref>; <xref ref-type="bibr" rid="bib75">Itti and Koch, 2001</xref>; <xref ref-type="bibr" rid="bib154">Theeuwes, 1994</xref>), the goals of the observer (top-down information) (<xref ref-type="bibr" rid="bib119">Posner, 1980</xref>; <xref ref-type="bibr" rid="bib115">Petersen and Posner, 2012</xref>; <xref ref-type="bibr" rid="bib120">Posner and Petersen, 1990</xref>; <xref ref-type="bibr" rid="bib42">Desimone and Duncan, 1995</xref>), and prior knowledge about a scene (selection history) (<xref ref-type="bibr" rid="bib12">Awh et al., 2012</xref>; <xref ref-type="bibr" rid="bib156">Theeuwes et al., 2022</xref>) drive where the eyes are moved. However, even when these factors are kept constant, there are many systematic biases in eye-movement behavior, such as a bias for cardinal compared with oblique saccade directions (<xref ref-type="bibr" rid="bib50">Foulsham and Kingstone, 2010</xref>; <xref ref-type="bibr" rid="bib54">Gilchrist and Harvey, 2006</xref>; <xref ref-type="bibr" rid="bib22">Bays and Husain, 2012</xref>; <xref ref-type="bibr" rid="bib5">Anderson et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">Engbert and Kliegl, 2003</xref>; <xref ref-type="bibr" rid="bib152">Tatler and Vincent, 2009</xref>). The presence of these biases suggests that additional factors must contribute to the decision of where to saccade, here referred to as ‘saccade selection.’ Recent evidence suggests that the effort involved with planning and executing (eye) movements may be one crucial factor in driving action selection (<xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>; <xref ref-type="bibr" rid="bib157">Thomas et al., 2022</xref>; <xref ref-type="bibr" rid="bib59">Hagura et al., 2017</xref>; <xref ref-type="bibr" rid="bib81">Kadner et al., 2022</xref>; <xref ref-type="bibr" rid="bib37">Cos et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Cos et al., 2011</xref>; <xref ref-type="bibr" rid="bib36">Cos et al., 2012</xref>; <xref ref-type="bibr" rid="bib159">Todorov and Jordan, 2002</xref>). Effort is thought to be minimized whenever possible (<xref ref-type="bibr" rid="bib73">Hull, 1943</xref>; <xref ref-type="bibr" rid="bib160">Tsai, 1932</xref>), likely because it is costly to spend inherently limited cognitive resources (<xref ref-type="bibr" rid="bib51">Friston, 2010</xref>; <xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>). We here use the term ’saccade cost’ to describe the intrinsic effort associated with planning and executing saccades. Although saccades are relatively affordable [i.e. not very costly; <xref ref-type="bibr" rid="bib49">Findlay and Gilchrist, 2003</xref>; <xref ref-type="bibr" rid="bib155">Theeuwes, 2012</xref>], they are executed very often (<xref ref-type="bibr" rid="bib65">Henderson, 2003</xref>; <xref ref-type="bibr" rid="bib64">Henderson and Hollingworth, 1998</xref>) and, therefore, even small costs should add up over time (<xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>; <xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>). We here hypothesized that affordable saccades are preferred over costly saccades. This would be in line with recent evidence from computational models suggesting that saccade costs predict saccade behavior [e.g. <xref ref-type="bibr" rid="bib71">Hoppe and Rothkopf, 2016</xref>; <xref ref-type="bibr" rid="bib72">Hoppe and Rothkopf, 2019</xref>; <xref ref-type="bibr" rid="bib81">Kadner et al., 2022</xref>; <xref ref-type="bibr" rid="bib157">Thomas et al., 2022</xref>]. These studies either assumed saccade costs or indirectly inferred them from gaze behavior itself. However, no study has been able to quantify saccade costs (neuro-)physiologically, and therefore been able to directly test this hypothesis until recently.</p><p>We recently demonstrated that the effort of saccade planning can be measured with pupil size, which allows for a physiological quantification of saccade costs as long as low-level visual factors are controlled for (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>). Pupil size is an established marker of effort (<xref ref-type="bibr" rid="bib83">Kahneman, 1973</xref>; <xref ref-type="bibr" rid="bib27">Bumke, 1911</xref>; <xref ref-type="bibr" rid="bib92">Laeng et al., 2012</xref>; <xref ref-type="bibr" rid="bib100">Mathôt, 2018</xref>; <xref ref-type="bibr" rid="bib147">Strauch et al., 2022</xref>; <xref ref-type="bibr" rid="bib94">Loewenfeld, 1993</xref>; <xref ref-type="bibr" rid="bib141">Sirois and Brisson, 2014</xref>; <xref ref-type="bibr" rid="bib168">van der Wel and van Steenbergen, 2018</xref>; <xref ref-type="bibr" rid="bib23">Beatty, 1982</xref>). For instance, loading more in working memory or tracking more objects results in stronger pupil dilation (<xref ref-type="bibr" rid="bib23">Beatty, 1982</xref>; <xref ref-type="bibr" rid="bib86">Koevoet et al., 2024</xref>; <xref ref-type="bibr" rid="bib125">Robison and Unsworth, 2019</xref>; <xref ref-type="bibr" rid="bib3">Alnæs et al., 2014</xref>; <xref ref-type="bibr" rid="bib82">Kahneman and Beatty, 1966</xref>; <xref ref-type="bibr" rid="bib162">Unsworth and Miller, 2021</xref>; <xref ref-type="bibr" rid="bib161">Unsworth and Robison, 2015</xref>; <xref ref-type="bibr" rid="bib2">Ahern and Beatty, 1979</xref>; <xref ref-type="bibr" rid="bib66">Hess and Polt, 1964</xref>). Pupil size not only reflects cognitive (or mental) effort but also the effort of planning and executing movements (<xref ref-type="bibr" rid="bib108">Naber and Murphy, 2020</xref>; <xref ref-type="bibr" rid="bib123">Richer and Beatty, 1985</xref>; <xref ref-type="bibr" rid="bib27">Bumke, 1911</xref>). We leveraged this to demonstrate that saccade costs can be captured with pupil size, and are higher for oblique compared with cardinal directions (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>). Here, we addressed whether saccade costs predict where to saccade.</p><p>We hypothesized that participants would prefer affordable over costly saccades to minimize effort expenditure. To test this, we first mapped out saccade costs across directions by measuring pupil size during saccade planning. To assess saccade preferences across the same directions, a subsequent free choice saccade task was employed. Previewing our results, saccade costs indeed predicted saccade preferences, as affordable directions were preferred over costly alternatives. Strikingly, this general principle even held when participants searched for targets in natural scenes in two additional experiments: saccade cost remained a fundamental driver of saccade selection. If saccades and other cognitive operations consume the same resources, this should reflect in adaptively changing saccade preferences in light of altering cognitive demands. We tested this idea experimentally by comparing saccade preferences with and without an auditory dual-task. As hypothesized, participants made fewer saccades overall under increased cognitive demand and especially cut the most costly directions. This provides convergent evidence that saccades are costly and rely at least in part on the same cognitive resources as other cognitively demanding operations.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Saccade costs differ around the visual field</title><p>Twenty human participants planned and executed saccades in 36 different directions at a fixed amplitude (10°, <xref ref-type="fig" rid="fig1">Figure 1a and b</xref>). Pupil size was measured to index effort and thereby saccade cost during saccade planning (–150 ms until 170 ms around cue offset; also see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). Replicating our previous findings, we found that pupil size differed across directions (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>; <xref ref-type="fig" rid="fig1">Figure 1c–f</xref>). We observed a larger pupil size during planning of oblique saccades compared with cardinal saccades (β = 7.662, SE  = 1.957, <italic>t</italic> = 3.916, p &lt; 0.001). Downward saccades were associated with a larger pupil size than upward saccades (β = 0.556, SE  = 0.171, <italic>t</italic> = 3.261, p = 0.001), and we found a slightly larger pupil size for leftward compared with rightward saccades (β = 0.226, SE  = 0.095, <italic>t</italic> = 2.388, p = 0.017). These effects were not mediated by differences in saccade properties, such as duration, amplitude, peak velocity, and landing precision (<xref ref-type="fig" rid="fig1">Figure 1e and f</xref>). Together, this shows that saccade costs differ as a function of direction, indicating that certain saccades are more costly than others.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Pupil size differs during saccade planning across directions.</title><p>(<bold>a</bold>) Twenty participants planned saccades in a cued direction. Saccades were executed as fast as possible upon cue offset. (<bold>b</bold>) All 36 possible saccade targets around the visual field. Only eight equally spaced locations were shown per trial. (<bold>c</bold>) Pupil size over time, split and averaged during saccade planning in oblique/cardinal, upward/downward, and left/rightward directions, locked to cue offset. Shaded areas indicate ± 1 s.e.m. (<bold>d</bold>) Averaged z-transformed pupil size during planning (–150 ms–170 ms post cue, gray area in <bold>e</bold>) across directions. (<bold>e</bold>) Linear mixed-effects model using obliqueness, verticalness, horizontalness of directions, and saccade properties to predict pupil size during saccade planning. (<bold>f</bold>) Standardized partial coefficients per predictor with 95% confidence intervals. *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97760-fig1-v1.tif"/></fig></sec><sec id="s2-2"><title>Saccade costs predict saccade preferences</title><p>The same twenty participants subsequently completed a saccade preference task adapted from <xref ref-type="bibr" rid="bib157">Thomas et al., 2022</xref>. To determine which of the 36 saccade directions were preferred, participants freely chose between two possible saccade targets in every trial (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). We first analyzed whether saccade preferences differed across directions. Results showed that participants preferred cardinal over oblique directions (β = 0.091, SE = 0.023, <italic>t</italic> = 3.910, p &lt; 0.001; <xref ref-type="fig" rid="fig2">Figure 2b</xref>), and preferred upward over downward directions (β = 0.036, SE = 0.017, <italic>t</italic> = 2.130, p = 0.033). No differences were observed between leftward and rightward saccade directions (β = 0.009, SE = 0.014, <italic>t</italic> = 0.668, p = 0.504).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Saccade preferences differ across directions and are predicted by saccade costs.</title><p>(<bold>a</bold>) The same twenty participants freely selected one of two saccade targets. (<bold>b</bold>) The average saccade preferences across directions (sum selected/sum offered). Shaded bands indicate ± 1 s.e.m. (<bold>c</bold>) Saccade costs correlated negatively with saccade preferences across directions: costly directions were avoided and affordable directions preferred. Black datapoints represent directions (averaged across participants). (<bold>d</bold>) Pupil size was larger for avoided compared with preferred directions. (<bold>e</bold>) Saccade costs predicted saccade selection on a trial-by-trial basis (56.64%). Together, the saccade costs in the first task predicted saccade preferences in the subsequent task. (<bold>c-e</bold>) Error bars reflect bootstrapped 95% confidence intervals. (<bold>d-e</bold>) Black datapoints represent participants. **p &lt; 0.01, ***p &lt; 0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97760-fig2-v1.tif"/></fig><p>These results indicate that saccade preferences seem to mirror the pattern of saccade costs (compare <xref ref-type="fig" rid="fig1">Figures 1d</xref> and <xref ref-type="fig" rid="fig2">2b</xref>). We proceeded to directly test if saccade costs predicted saccade preferences. To this end, we calculated the overall proportion that each direction was selected relative to how often it was offered to index saccade preferences (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). In line with our hypothesis, pupil size during saccade planning (in cued directions) negatively correlated with saccade preferences (during self-selection) (<italic>r</italic>(34) = –0.76, p &lt; 0.001; <xref ref-type="fig" rid="fig2">Figure 2c</xref>). For the first time, this demonstrates that intrinsic saccade costs critically predict saccade preferences. Put differently, participants preferred saccading towards affordable over costly options. A control analysis ruled out that the correlation between pupil size and saccade preferences was driven by other oculomotor metrics such as saccade latency and landing precision (see Supporting Information). Illustrating the robustness of this relationship further, we found smaller pupil sizes during saccade planning for preferred (selected &gt;50%) than for avoided (selected &lt;50%) directions (<italic>t</italic>(19) = 4.38, p &lt; 0.001, Cohen’s <italic>d</italic> = 0.979; <xref ref-type="fig" rid="fig2">Figure 2d</xref>). As another test of the robustness of the effect, we analyzed whether saccade costs predicted saccade selection on a trial-by-trial basis. To this end, we first determined the more affordable option for each trial using the established saccade cost map (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). We predicted that participants would select the more affordable option. Complementing the above analyses, the more affordable option was chosen above chance level across participants (<italic>M</italic> = 56.64%, 95% CI = [52.75–60.52%], one-sample <italic>t</italic>-test against 50%: <italic>t</italic>(19) = 3.26, p = 0.004, Cohen’s <italic>d</italic> = 0.729; <xref ref-type="fig" rid="fig2">Figure 2e</xref>). Together, these analyses established that saccade costs robustly predict saccade preferences.</p></sec><sec id="s2-3"><title>Saccade costs predict saccade curvature and latency</title><p>If saccade cost is indeed weighed during saccade selection, this should be reflected in the oculomotor properties of the ensuing saccade. Saccade curvature reflects conflict between target and distractor saccade vectors: if a distractor is inhibited, and the target is activated, the saccade curves away from the distractor location (<xref ref-type="bibr" rid="bib163">Van der Stigchel et al., 2006</xref>; <xref ref-type="bibr" rid="bib104">McPeek et al., 2003</xref>; <xref ref-type="bibr" rid="bib164">Van der Stigchel, 2010</xref>). Whenever saccade costs differ more between directions, there should, therefore, be more conflict between saccade vectors. If both directions were equally costly, there would be no need for conflict as cost minimization is impossible. We, therefore, hypothesized signs of increased oculomotor conflict to especially show in trials with relatively large differences in saccade costs. Furthermore, weighing costs (and reward) in decision-making is known to take time (<xref ref-type="bibr" rid="bib146">Spering, 2022</xref>, <xref ref-type="bibr" rid="bib118">Polanía et al., 2014</xref>). More elaborate decisions should, therefore, not only show in more curvature, but also in longer saccade latencies.</p><p>To test this, we first split trials into saccades curving toward and away from the non-selected option. Saccades curved away from the non-selected option in the majority of trials, indicating oculomotor conflict (<xref ref-type="fig" rid="fig3">Figure 3a</xref>; <italic>M</italic> = 78.15%, 95% CI = [74.734–81.567%], <italic>t</italic>(19) = 15.741, p &lt; 0.001, Cohen’s <italic>d</italic> = 3.519). We then examined how saccade curvature and latency predicted the difference in pupil size between the two possible saccade targets. Whenever the difference in pupil size between the two options was larger, saccades curved away more from the non-selected option (β = 0.004, SE  = 0.001, <italic>t</italic> = 4.448, p &lt; 0.001; <xref ref-type="fig" rid="fig3">Figure 3b</xref>), and their latencies slowed (β = 0.050, SE  = 0.013, <italic>t</italic> = 4.323, p &lt; 0.001; <xref ref-type="fig" rid="fig3">Figure 3c</xref>). Our results show that cost is actively weighed and leads to stronger conflict whenever cost differences are larger. This suggests that more elaborate decisions in saccade selection are predominantly made when warranted by sufficient differences in saccade costs between options.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Saccade curvature and latency reveal active weighing of cost during saccade selection.</title><p>(<bold>a</bold>) Schematic layout of saccade trajectories curving away (magenta) or toward (cyan) non-selected options. Curvature was calculated as the peak deviation from a straight line between gaze positions at saccade onset and offset. The top-right histogram shows that more saccades curved away than toward the non-selected option. (<bold>b</bold>) Difference in pupil size during the saccade planning task is linked to the peak curvature deviation in the saccade preference task. (<bold>c</bold>) Same as b, but now linked to saccade latency in the saccade preference task. Larger differences in pupil size are related to more oculomotor conflict between the two options, as reflected in more curvature away from the non-selected option and longer saccade latencies. (<bold>b, c</bold>) Black line depicts the relationship across all trials, gray lines denote regression fits per participant. (<bold>d</bold>) Saccade-cost based prediction of saccade selection split for toward and away curving trials. On a trial-by-trial basis, saccade costs predicted saccade selection above chance (59.72%) when saccades curved away from the non-selected option. In contrast, saccade costs did not predict saccade selection for ’toward’ saccades. Black datapoints represent participants. All error bars reflect bootstrapped 95% confidence intervals. ***p &lt; 0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97760-fig3-v1.tif"/></fig><p>The above analyses show that saccade costs affect oculomotor conflict, but does increased conflict between saccade vectors also lead to selecting more affordable options? We expected that especially when oculomotor conflict was high, participants would choose the more affordable option. This means that saccade costs should be more predictive of saccade selection in away compared with toward curving trials. To test this idea, we repeated the trial-by-trial prediction of which option was selected as before (<xref ref-type="fig" rid="fig2">Figure 2e</xref>), but now separately for trials with toward and away curving saccades. Pupil size (i.e. saccade cost) predicted saccade selection when saccades curved away (<italic>M</italic> = 59.72%, 95% CI = [55.208–64.233%], <italic>t</italic>(19) = 4.116, p &lt; 0.001, Cohen’s <italic>d</italic> = 0.920), but not toward (<italic>M</italic> = 48.42%, 95% CI = [44.496–52.338%], <italic>t</italic>(19) = 0.771, <italic>P</italic> = 0.450, Cohen’s <italic>d</italic> = 0.172) the non-selected option. These prediction accuracies differed between curve directions (<italic>t</italic>(19) = 4.795, p &lt; 0.001, Cohen’s <italic>d</italic> = 1.072; <xref ref-type="fig" rid="fig3">Figure 3d</xref>). This shows that saccade costs were predominantly considered when saccades curved away. Together, these analyses suggest that the costs of potential saccade targets are especially weighed during saccade selection when warranted by large differences in saccade costs. In these cases, oculomotor conflict increases and saccade cost plays a bigger role in saccade selection.</p></sec><sec id="s2-4"><title>Saccade costs predict saccade preferences in natural viewing</title><p>The previous results establish that saccade costs predict saccade preferences in highly controlled settings. However, a crucial question is whether saccade costs also predict saccade preferences in more complex and less controlled settings, in which physical saliency, the observer’s goals, and prior knowledge about the scene also affect saccade selection. To test this, we analyzed data from two existing datasets (<xref ref-type="bibr" rid="bib99">Mathôt et al., 2015</xref>) wherein participants (total n = 41) searched for small targets (‘Z’ or ‘H’) in natural scenes (<xref ref-type="fig" rid="fig4">Figure 4a</xref>; <xref ref-type="bibr" rid="bib158">Tkačik et al., 2011</xref>). Again, we tested whether pupil size prior to saccades negatively linked with saccade preferences across directions. Because saccade costs and preferences across directions could differ for different situations (i.e. natural viewing vs. saccade preference task), but should always be negatively linked, we established both cost and preferences independently in each dataset. Many factors influence pupil size in such a natural task, for which we controlled as much as possible by including variables known to covary with pupil size in a linear mixed-effects model (based on <xref ref-type="bibr" rid="bib99">Mathôt et al., 2015</xref>; e.g. luminance, gaze position, saccade properties, saliency, fixation number; see Methods) to access the underlying saccade costs. As hypothesized, we observed a negative relationship between pupil size and saccade preferences in both experiments (Exp. 1: β = 1.784, SE  = 0.324, <italic>t</italic> = 5.412, p &lt; 0.001; saccade preferences in <xref ref-type="fig" rid="fig4">Figure 4b</xref>, link in <xref ref-type="fig" rid="fig4">Figure 4c</xref>; Exp. 2: β = 0.644, SE  = 0.170, <italic>t</italic> = 3.780, p &lt; 0.001; saccade preferences in <xref ref-type="fig" rid="fig4">Figure 4d</xref>, link in <xref ref-type="fig" rid="fig4">Figure 4e</xref>). This shows that even when participants made unconstrained eye movements in natural scenes, saccade cost remained linked to saccade preferences: affordable directions were preferred over costly directions.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Saccade costs underlie saccade preferences in natural viewing.</title><p>(<bold>a</bold>) Forty-one participants searched for small letters (‘Z’ or ‘H’) in natural scenes (Exp. 1; n = 16), and either ignored (single task) or additionally attended (dual task) an auditory number stream (Exp. 2; n = 25). (<bold>b</bold>) Saccade preferences during search without auditory stimulation. (<bold>c</bold>) Preferred directions were associated with a smaller pupil size prior to the saccade (Exp. 1). (<bold>d, e</bold>) Same as b, c but now for Exp. 2 without attending the auditory number stream (single task). Preferred directions were again associated with a smaller pupil size preceding the saccade (Exp. 2). (<bold>f</bold>) Same as d but now under the increased cognitive demand of the (primary) auditory digit counting (dual) task. (<bold>g</bold>) Adjustment in saccade preferences between single- and dual-task conditions in percentage points. (<bold>h</bold>) Less saccades were executed in the more demanding dual-task condition. Black datapoints represent participants. (<bold>i</bold>) Pupil size during the single task predicted direction adjustments under additional cognitive demand. Costly saccades as assessed during the single-task condition were especially cut in the dual-task condition. (<bold>b, d, f, g</bold>) Shaded bands represent ± 1 s.e.m. Other error bars reflect bootstrapped 95% confidence intervals. (<bold>c, e, i</bold>) Black lines depict the relationship across all trials, gray lines denote regression fits per participant. ***p &lt; 0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97760-fig4-v1.tif"/></fig><p>Do cognitive operations and eye movements consume from a similar pool of resources (<xref ref-type="bibr" rid="bib23">Beatty, 1982</xref>)? If so, increasing cognitive demand for non-oculomotor processes should result in decreasing available resources for the oculomotor system. In line with this idea, previous work indeed shows altered eye-movement behavior under effort as induced by dual tasks, for example by making less saccades under increased cognitive demand (<xref ref-type="bibr" rid="bib102">May et al., 1990</xref>; <xref ref-type="bibr" rid="bib174">Walter and Bex, 2021</xref>; <xref ref-type="bibr" rid="bib39">Cui and Herrmann, 2023</xref>). We, therefore, investigated whether less saccades were made as soon as participants had to count the occurrence of a specific digit in the auditory number stream in comparison to ignoring the stream (in Exp. 2; <xref ref-type="fig" rid="fig4">Figure 4a</xref>). Participants were instructed to prioritize the auditory digit-counting task over finding the visual search target. Therefore, resources should be shifted from the oculomotor system to the primary auditory counting task. The additional cognitive demand of the dual task indeed led to a decreased saccade frequency (<italic>t</italic>(24) = 7.224, p &lt; 0.001, Cohen’s <italic>d</italic> = 1.445; <xref ref-type="fig" rid="fig4">Figure 4h</xref>). This indicates that the auditory dual task and the oculomotor system, at least in part, consumed from a shared pool of cognitive resources.</p><p>From a costs-perspective, it should be efficient to not only adjust the number of saccades (non-specific), but to also cut especially expensive directions the most (specific). Therefore, we expected participants to especially avoid costly saccades (as assessed in the single task) under higher cognitive demand (induced by the dual task). We calculated a saccade-adjustment map (<xref ref-type="fig" rid="fig4">Figure 4g</xref>) by subtracting the saccade preference map in the single task (<xref ref-type="fig" rid="fig4">Figure 4f</xref>) from the dual-task map (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Participants seemingly cut vertical saccades in particular, and made more saccades to the top right direction. This pattern may have emerged as vertical saccades are more costly than horizontal saccades (also see <xref ref-type="fig" rid="fig1">Figure 1d</xref>). Oblique saccades may not have been cut because there were very little oblique saccades in the single condition to begin with (<xref ref-type="fig" rid="fig4">Figure 4d</xref>), making it difficult to observe a further reduction of such saccades under additional cognitive demand (i.e. a floor effect). Nevertheless, pupil size negatively linked with the adjustment map as hypothesized (β = 9.333, SE  = 0.966, <italic>t</italic> = 9.659, p &lt; 0.001; <xref ref-type="fig" rid="fig4">Figure 4i</xref>; while controlling for the same possible covariates as before). This shows that costly saccades were cut disproportionally when more cognitive resources were consumed by the additional auditory dual task. This demonstrates that cognitive resources are flexibly (dis)allocated from and to the oculomotor system based on the current resource demands.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We here investigated whether effort determines saccade preferences. We first measured pupil size prior to saccade execution across directions as a physiological marker of effort and thus saccade costs. Next, saccade preferences were assessed in the same participants and directions. We observed that affordable saccades were preferred over costly ones. This is especially remarkable given that the delayed saccades in the planning task likely differ in their oculomotor program from the immediate saccades in the preference task in some regard. Furthermore, when two possible saccade directions differed more in saccade cost, we found higher oculomotor conflict as indexed by stronger saccade trajectory deviations away from the non-selected option and increased onset latencies. In two additional experiments, we demonstrated the link between saccade costs and saccade preferences to be robust even when participants made unconstrained eye movements during natural viewing. Lastly, saccade directions were flexibly adjusted based on cost as cognitive demand increased. Together, this demonstrates that saccade costs fundamentally underlie saccade selection, even when physical salience, the goals of the observer, and selection history affect where the eyes are moved.</p><p>What contributes to intrinsic saccade costs? We speculate that at least three processes contribute to the total cost of a saccade (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>): the complexity of oculomotor programming (<xref ref-type="bibr" rid="bib76">Jainta et al., 2011</xref>; <xref ref-type="bibr" rid="bib177">Wang and Munoz, 2021</xref>; <xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>), shifting of presaccadic attention (<xref ref-type="bibr" rid="bib124">Rizzolatti et al., 1987</xref>; <xref ref-type="bibr" rid="bib43">Deubel and Schneider, 1996</xref>), and predictive/spatial remapping (<xref ref-type="bibr" rid="bib126">Rolfs, 2015</xref>; <xref ref-type="bibr" rid="bib105">Melcher, 2007</xref>; <xref ref-type="bibr" rid="bib21">Bays and Husain, 2007</xref>; <xref ref-type="bibr" rid="bib48">Fabius et al., 2019</xref>). The complexity of an oculomotor program is arguably shaped by its neural underpinnings. For example, oblique but not cardinal saccades require communication between pontine and midbrain circuits (<xref ref-type="bibr" rid="bib145">Sparks, 2002</xref>; <xref ref-type="bibr" rid="bib84">King and Fuchs, 1979</xref>; <xref ref-type="bibr" rid="bib40">Curthoys et al., 1984</xref>). Such differences in neural complexity may underlie the additional costs of oblique compared with cardinal saccades. Besides saccade direction, other properties of the ensuing saccade such as its speed, distance, curvature, and accuracy may contribute to a saccade’s total cost (<xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>; <xref ref-type="bibr" rid="bib108">Naber and Murphy, 2020</xref>; <xref ref-type="bibr" rid="bib175">Wang et al., 2017</xref>; <xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>; <xref ref-type="bibr" rid="bib178">Wang et al., 2021</xref>) but this remains to be investigated directly. Furthermore, presaccadic attention is shifted prior to each saccade to prepare the brain for the abrupt changes in retinal input resulting from saccades through spatial/predictive remapping (<xref ref-type="bibr" rid="bib106">Melcher and Colby, 2008</xref>; <xref ref-type="bibr" rid="bib126">Rolfs, 2015</xref>; <xref ref-type="bibr" rid="bib105">Melcher, 2007</xref>; <xref ref-type="bibr" rid="bib21">Bays and Husain, 2007</xref>; <xref ref-type="bibr" rid="bib124">Rizzolatti et al., 1987</xref>; <xref ref-type="bibr" rid="bib43">Deubel and Schneider, 1996</xref>; <xref ref-type="bibr" rid="bib166">Van der Stigchel and Hollingworth, 2018</xref>). This preparation for upcoming changes in retinal input consumes neurocognitive resources and, therefore, likely also contributes to saccade costs (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>; <xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>). To better understand saccade selection more generally, future work should elucidate which processes contribute to saccade costs, and how costs shape different (aspects of) saccades.</p><p>The observed differences in saccade costs across directions could be linked to established anisotropies in perception (<xref ref-type="bibr" rid="bib180">Wexler et al., 2022</xref>; <xref ref-type="bibr" rid="bib15">Barbot et al., 2021</xref>; <xref ref-type="bibr" rid="bib13">Baldwin et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Greenwood et al., 2017</xref>; <xref ref-type="bibr" rid="bib31">Chakravarthi et al., 2022</xref>; <xref ref-type="bibr" rid="bib1">Abrams et al., 2012</xref>; <xref ref-type="bibr" rid="bib47">Ezzo et al., 2023</xref>), attention (<xref ref-type="bibr" rid="bib61">Hanning et al., 2024</xref>; <xref ref-type="bibr" rid="bib60">Hanning et al., 2022</xref>; <xref ref-type="bibr" rid="bib130">Schütz, 2014</xref>; <xref ref-type="bibr" rid="bib29">Carrasco et al., 2001</xref>; <xref ref-type="bibr" rid="bib97">Mackeben, 1999</xref>; <xref ref-type="bibr" rid="bib111">Ohl et al., 2024</xref>), saccade characteristics (<xref ref-type="bibr" rid="bib61">Hanning et al., 2024</xref>; <xref ref-type="bibr" rid="bib57">Greenwood et al., 2017</xref>; <xref ref-type="bibr" rid="bib60">Hanning et al., 2022</xref>; <xref ref-type="bibr" rid="bib111">Ohl et al., 2024</xref>), and (early) visual cortex (<xref ref-type="bibr" rid="bib68">Himmelberg et al., 2022</xref>; <xref ref-type="bibr" rid="bib169">Van Essen et al., 1984</xref>; <xref ref-type="bibr" rid="bib24">Benson et al., 2021</xref>; <xref ref-type="bibr" rid="bib67">Himmelberg et al., 2021</xref>; <xref ref-type="bibr" rid="bib140">Silva et al., 2018</xref>; also see <xref ref-type="bibr" rid="bib69">Himmelberg et al., 2023</xref>). For example, downward saccades are more costly than upward saccades, which mimics a similar asymmetry in early visual areas wherein the upper visual field is relatively underrepresented (<xref ref-type="bibr" rid="bib68">Himmelberg et al., 2022</xref>; <xref ref-type="bibr" rid="bib169">Van Essen et al., 1984</xref>; <xref ref-type="bibr" rid="bib24">Benson et al., 2021</xref>; <xref ref-type="bibr" rid="bib67">Himmelberg et al., 2021</xref>; <xref ref-type="bibr" rid="bib140">Silva et al., 2018</xref>); similarly stronger presaccadic benefits are found for down- compared with upward saccades (<xref ref-type="bibr" rid="bib61">Hanning et al., 2024</xref>, <xref ref-type="bibr" rid="bib60">Hanning et al., 2022</xref>). Moreover, upward saccades are more precise than downward saccades (<xref ref-type="bibr" rid="bib57">Greenwood et al., 2017</xref>). Future work should elucidate where saccade cost or the aforementioned anisotropies originate from and how they are related - something that pupil size alone cannot address.</p><p>We here measured cost as the degree of effort-linked pupil dilation. In addition to pupil size, other markers may also indicate saccade costs. For example, saccade latency has been proposed to index oculomotor effort (<xref ref-type="bibr" rid="bib133">Shadmehr et al., 2019</xref>), whereby saccades with longer latencies are associated with more oculomotor effort. This makes saccade latency a possible complementary marker of saccade costs (also see Appendix). Although relatively sluggish, pupil size is a valuable measure of attentional costs for (at least) two reasons. First, pupil size is a highly established marker of effort, and is sensitive to effort more broadly than only in the context of saccades (<xref ref-type="bibr" rid="bib141">Sirois and Brisson, 2014</xref>; <xref ref-type="bibr" rid="bib147">Strauch et al., 2022</xref>; <xref ref-type="bibr" rid="bib83">Kahneman, 1973</xref>; <xref ref-type="bibr" rid="bib82">Kahneman and Beatty, 1966</xref>; <xref ref-type="bibr" rid="bib23">Beatty, 1982</xref>; <xref ref-type="bibr" rid="bib92">Laeng et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Bumke, 1911</xref>; <xref ref-type="bibr" rid="bib168">van der Wel and van Steenbergen, 2018</xref>; <xref ref-type="bibr" rid="bib86">Koevoet et al., 2024</xref>; <xref ref-type="bibr" rid="bib94">Loewenfeld, 1993</xref>; <xref ref-type="bibr" rid="bib100">Mathôt, 2018</xref>). Pupil size, therefore, allows to capture not only the costs of saccades, but also of covert attentional shifts (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>), or shifts with other effectors such as head or arm movements (<xref ref-type="bibr" rid="bib123">Richer and Beatty, 1985</xref>; <xref ref-type="bibr" rid="bib171">Voudouris et al., 2023</xref>). Second, as we have demonstrated, pupil size can measure saccade costs even when searching in natural scenes (<xref ref-type="fig" rid="fig4">Figure 4</xref>). During natural viewing, it is difficult to disentangle fixation duration from saccade latencies, complicating the use of saccade latency as a measure of saccade cost. Together, pupil size, saccade latency, and potential other markers of saccade cost could fulfill complementary roles in studying the role of cost in saccade selection.</p><p>Our findings are in line with established effort-based models that assume costs to be weighed against rewards during decision-making (<xref ref-type="bibr" rid="bib87">Kool et al., 2010</xref>; <xref ref-type="bibr" rid="bib91">Kurzban et al., 2013</xref>; <xref ref-type="bibr" rid="bib138">Shenhav et al., 2021</xref>; <xref ref-type="bibr" rid="bib136">Shenhav et al., 2013</xref>; <xref ref-type="bibr" rid="bib137">Shenhav et al., 2017</xref>; <xref ref-type="bibr" rid="bib179">Westbrook and Braver, 2015</xref>). In such studies, reward and cognitive/physical effort are often parametrically manipulated to assess how much effort participants are willing to exert to acquire a given (monetary) reward (e.g. <xref ref-type="bibr" rid="bib28">Bustamante et al., 2023</xref>, <xref ref-type="bibr" rid="bib107">Müller et al., 2022</xref>). Whereas this line of work manipulated the extrinsic costs and/or rewards of decision options (e.g. perceptual consequences of saccades [<xref ref-type="bibr" rid="bib93">Lisi et al., 2019</xref>; <xref ref-type="bibr" rid="bib132">Sedaghat-Nejad and Shadmehr, 2021</xref>] or consequences associated with decision options), we here focus on the intrinsic costs of the movement itself (in terms of cognitive and physical effort). Relatedly, the intrinsic costs of arm movements are also considered during decision-making: biomechanically affordable movements are generally preferred over more costly ones (<xref ref-type="bibr" rid="bib35">Cos et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Cos et al., 2014</xref>; <xref ref-type="bibr" rid="bib36">Cos et al., 2012</xref>). We here extend these findings in two important ways. First, until now, the intrinsic costs of saccades and other movements have been inferred from gaze behavior itself or by using computational modeling (<xref ref-type="bibr" rid="bib157">Thomas et al., 2022</xref>; <xref ref-type="bibr" rid="bib81">Kadner et al., 2022</xref>; <xref ref-type="bibr" rid="bib71">Hoppe and Rothkopf, 2016</xref>; <xref ref-type="bibr" rid="bib72">Hoppe and Rothkopf, 2019</xref>; <xref ref-type="bibr" rid="bib35">Cos et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Cos et al., 2014</xref>; <xref ref-type="bibr" rid="bib36">Cos et al., 2012</xref>; <xref ref-type="bibr" rid="bib116">Petitet et al., 2021</xref>). In contrast, we directly measured cost physiologically using pupil size. Second, we show that physiologically measured saccade costs predict where saccades are directed in a controlled binary preference task, and even during natural viewing. Our findings could unite state-of-the-art computational models [e.g. <xref ref-type="bibr" rid="bib81">Kadner et al., 2022</xref>; <xref ref-type="bibr" rid="bib157">Thomas et al., 2022</xref>; <xref ref-type="bibr" rid="bib71">Hoppe and Rothkopf, 2016</xref>; <xref ref-type="bibr" rid="bib72">Hoppe and Rothkopf, 2019</xref>; <xref ref-type="bibr" rid="bib153">Tatler et al., 2017</xref>] with physiological data, to directly test the role of saccade costs and ultimately further our understanding of saccade selection.</p><p>Throughout this paper, we have used cost in the limited context of saccades. However, cost-based decision-making may be a more general property of the brain (<xref ref-type="bibr" rid="bib51">Friston, 2010</xref>; <xref ref-type="bibr" rid="bib83">Kahneman, 1973</xref>; <xref ref-type="bibr" rid="bib10">Attneave, 1959</xref>; <xref ref-type="bibr" rid="bib62">Hasenstaub et al., 2010</xref>; <xref ref-type="bibr" rid="bib77">Jamadar et al., 2024</xref>). Every action, be it physical or cognitive, is associated with an intrinsic cost, and pupil size is likely a general marker of this (<xref ref-type="bibr" rid="bib23">Beatty, 1982</xref>). Note, however, that pupil dilation does not always reflect cost, as the pupil dilates in response to many sensory and cognitive factors which should be controlled for, or at least considered, when interpreting pupillometric data [e.g., see <xref ref-type="bibr" rid="bib101">Mathôt and Vilotijević, 2023</xref>; <xref ref-type="bibr" rid="bib147">Strauch et al., 2022</xref>; <xref ref-type="bibr" rid="bib100">Mathôt, 2018</xref>; <xref ref-type="bibr" rid="bib141">Sirois and Brisson, 2014</xref>]. Effort-linked pupil dilations are thought to be, at least in part, driven by activity in the brainstem locus coeruleus (LC) (<xref ref-type="bibr" rid="bib78">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib79">Joshi and Gold, 2020</xref>; <xref ref-type="bibr" rid="bib8">Aston-Jones and Cohen, 2005b</xref>; <xref ref-type="bibr" rid="bib147">Strauch et al., 2022</xref>) [but other neurotransmitters also affect pupil size, e.g. <xref ref-type="bibr" rid="bib58">Grujic et al., 2024</xref>, <xref ref-type="bibr" rid="bib103">Mazancieux et al., 2023</xref>]. Activity in LC with its widespread connections throughout the brain (<xref ref-type="bibr" rid="bib131">Schwarz and Luo, 2015</xref>; <xref ref-type="bibr" rid="bib149">Szabadi, 2013</xref>; <xref ref-type="bibr" rid="bib8">Aston-Jones and Cohen, 2005b</xref>; <xref ref-type="bibr" rid="bib25">Berridge and Waterhouse, 2003</xref>; <xref ref-type="bibr" rid="bib9">Aston-Jones and Waterhouse, 2016</xref>; <xref ref-type="bibr" rid="bib7">Aston-Jones and Cohen, 2005a</xref>) is considered to be crucial for the communication within and between neural populations and modulates global neural gain (<xref ref-type="bibr" rid="bib117">Poe et al., 2020</xref>; <xref ref-type="bibr" rid="bib172">Wainstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib41">Dahl et al., 2022</xref>; <xref ref-type="bibr" rid="bib34">Corbetta et al., 2008</xref>; <xref ref-type="bibr" rid="bib121">Posner et al., 2006</xref>). Neural firing is costly (<xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>; <xref ref-type="bibr" rid="bib11">Attwell and Laughlin, 2001</xref>), and therefore LC activity and pupil size are (neuro)physiologically plausible markers of cost (<xref ref-type="bibr" rid="bib147">Strauch et al., 2022</xref>). Tentative evidence even suggests that continued exertion of effort (accompanied by altered pupil dilation) is linked to the accumulation of glutamate in the lateral prefrontal cortex (<xref ref-type="bibr" rid="bib181">Wiehler et al., 2022</xref>), which may be a metabolic marker of cost [also see <xref ref-type="bibr" rid="bib30">Castrillon et al., 2023</xref>; <xref ref-type="bibr" rid="bib181">Wiehler et al., 2022</xref>; <xref ref-type="bibr" rid="bib77">Jamadar et al., 2024</xref>].</p><p>Besides the costs of increased neural activity when exerting more effort, effort should be considered costly for a second reason: Cognitive resources are limited. Therefore, any unnecessary resource expenditure reduces cognitive and behavioral flexibility (<xref ref-type="bibr" rid="bib51">Friston, 2010</xref>; <xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>; <xref ref-type="bibr" rid="bib83">Kahneman, 1973</xref>; <xref ref-type="bibr" rid="bib77">Jamadar et al., 2024</xref>). As a result, the brain needs to distribute resources between cognitive operations and the oculomotor system. We found evidence for the idea that such resource distribution is adaptive to the general level of cognitive demand and available resources: Increasing cognitive demand through an additional primary auditory dual task led to a lower saccade frequency, and especially costly saccades were cut. In this case, it is important to consider that the auditory task was the <italic>primary task</italic>, which should cause participants to distribute resources from the oculomotor system to the counting task. In other situations, more resources could be distributed to the oculomotor system instead, for example, to discover new sources of reward (<xref ref-type="bibr" rid="bib134">Shadmehr and Ahmed, 2020</xref>; <xref ref-type="bibr" rid="bib56">Gottlieb, 2012</xref>). Adaptive resource allocation from, and to the oculomotor system parsimoniously explains a number of empirical observations. For example, higher cognitive demand is accompanied by smooth pursuits deviating more from to-be tracked targets (<xref ref-type="bibr" rid="bib88">Kosch et al., 2018</xref>), reduced (micro)saccade frequencies (<xref ref-type="fig" rid="fig4">Figure 4</xref>; <xref ref-type="bibr" rid="bib139">Siegenthaler et al., 2014</xref>; <xref ref-type="bibr" rid="bib102">May et al., 1990</xref>; <xref ref-type="bibr" rid="bib174">Walter and Bex, 2021</xref>; <xref ref-type="bibr" rid="bib39">Cui and Herrmann, 2023</xref>), and slower peak saccade velocities (<xref ref-type="bibr" rid="bib45">Di Stasi et al., 2011</xref>; <xref ref-type="bibr" rid="bib6">App and Debus, 1998</xref>; <xref ref-type="bibr" rid="bib148">Sylvestre and Cullen, 1999</xref>). Relatedly, more precise saccades are accompanied with worse performance in a crowding task (<xref ref-type="bibr" rid="bib57">Greenwood et al., 2017</xref>). Furthermore, it has been proposed that saccade costs are weighed against other cognitive operations such as using working memory (<xref ref-type="bibr" rid="bib143">Somai et al., 2020</xref>; <xref ref-type="bibr" rid="bib167">Van der Stigchel, 2020</xref>; <xref ref-type="bibr" rid="bib70">Hoogerbrugge et al., 2023</xref>; <xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>; <xref ref-type="bibr" rid="bib14">Ballard et al., 1995</xref>). How would the resources between the oculomotor system and cognitive tasks (like the auditory counting task) be related? One possibility is that both consume from limited working memory resources (<xref ref-type="bibr" rid="bib95">Luck and Vogel, 2013</xref>; <xref ref-type="bibr" rid="bib96">Ma et al., 2014</xref>). Saccades are thought to encode target objects in a mandatory fashion into (visual) working memory (<xref ref-type="bibr" rid="bib166">Van der Stigchel and Hollingworth, 2018</xref>), and the counting task requires participants to keep track of the auditory stream and maintain the count of the instructed digit in working memory. However, the exact nature of which resources overlap between tasks remain open for future investigation (also see <xref ref-type="bibr" rid="bib109">Nozari and Martin, 2024</xref>). Together, we propose that cognitive resources are flexibly (dis)allocated to and from the oculomotor system based on the current demands to establish an optimal balance between performance and cost minimization.</p><p>How does the brain keep track of saccade costs, and which areas use it during saccade selection? Although our data do not allow direct inferences about the precise neural circuitry underlying the computations of oculomotor selection, oculomotor control is generally thought to be steered by a network encompassing the frontal eye field (<xref ref-type="bibr" rid="bib113">Paus, 1996</xref>; <xref ref-type="bibr" rid="bib26">Bruce et al., 1985</xref>), the supplementary eye field (<xref ref-type="bibr" rid="bib129">Schlag and Schlag-Rey, 1987</xref>; <xref ref-type="bibr" rid="bib4">Amiez and Petrides, 2009</xref>; <xref ref-type="bibr" rid="bib135">Sharika et al., 2013</xref>), the anterior cingulate cortex (<xref ref-type="bibr" rid="bib53">Gaymard et al., 1998</xref>; <xref ref-type="bibr" rid="bib127">Ruehl et al., 2021</xref>; <xref ref-type="bibr" rid="bib122">Pouget, 2015</xref>; <xref ref-type="bibr" rid="bib33">Conti and Irish, 2021</xref>), the superior colliculus (<xref ref-type="bibr" rid="bib52">Gandhi and Katnani, 2011</xref>; <xref ref-type="bibr" rid="bib144">Sparks, 1999</xref>; <xref ref-type="bibr" rid="bib145">Sparks, 2002</xref>; <xref ref-type="bibr" rid="bib55">Glimcher and Sparks, 1992</xref>; <xref ref-type="bibr" rid="bib182">Wurtz and Albano, 1980</xref>; <xref ref-type="bibr" rid="bib18">Basso and May, 2017</xref>; <xref ref-type="bibr" rid="bib147">Strauch et al., 2022</xref>), and the cerebellum (<xref ref-type="bibr" rid="bib170">Voogd and Barmack, 2006</xref>; <xref ref-type="bibr" rid="bib151">Tanaka et al., 2021</xref>; <xref ref-type="bibr" rid="bib150">Takagi et al., 1998</xref>; <xref ref-type="bibr" rid="bib163">Van der Stigchel et al., 2006</xref>). These areas are not just associated with oculomotor control, but are all also thought to be crucial for decision-making processes (<xref ref-type="bibr" rid="bib184">Zhang et al., 2021</xref>; <xref ref-type="bibr" rid="bib176">Wang et al., 2020</xref>; <xref ref-type="bibr" rid="bib18">Basso and May, 2017</xref>; <xref ref-type="bibr" rid="bib80">Jun et al., 2021</xref>; <xref ref-type="bibr" rid="bib38">Crapse et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Deverett et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Basso et al., 2021</xref>; <xref ref-type="bibr" rid="bib142">So and Stuphorn, 2016</xref>; <xref ref-type="bibr" rid="bib183">Yang and Heinen, 2014</xref>; <xref ref-type="bibr" rid="bib32">Chudasama et al., 2013</xref>; <xref ref-type="bibr" rid="bib20">Baumann et al., 2015</xref>; <xref ref-type="bibr" rid="bib128">Schall, 2001</xref>). It is plausible that the weighing of saccade costs during saccade selection is performed by this oculomotor-decision making network, but other areas such as orbitofrontal cortex may also play a role (<xref ref-type="bibr" rid="bib112">Padoa-Schioppa and Conen, 2017</xref>; <xref ref-type="bibr" rid="bib173">Wallis, 2007</xref>).</p><p>We report a combination of correlational and causal findings. Despite the correlational nature of some of our results, they consistently support the hypothesis that saccade costs predict saccade selection [which we predicted previously, <xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>]. Causal evidence was provided by the dual-task experiment as saccade frequencies - and especially costly saccades were reduced under additional cognitive demand. Only a cost account predicts (1) a link between pupil size and saccade preferences, (2) a cardinal saccade bias, (3) reduced saccade frequency under additional cognitive demand, and (4) disproportional cutting of especially those directions associated with more pupil dilation. Together, our findings converge upon the conclusion that effort drives saccade selection.</p><p>To conclude, we have demonstrated that saccade costs can be measured using pupil size and that these costs robustly predict saccade selection. We propose that saccade selection is driven by physical properties of the environment, the observer’s goals, selection history, and another fundamental factor: effort.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Saccade planning and saccade preference tasks</title><sec id="s4-1-1"><title>Participants</title><p>Twenty-two participants with normal or corrected-to-normal vision took part in the saccade planning and preference tasks across two sessions. One participant was excluded due to only finishing a single session, and another dataset was discarded due to not following task instructions (&lt;50% included trials in the saccade planning task). Twenty participants were included in the analyses for the saccade planning, and saccade preference tasks (age: <italic>M</italic> = 24.00, range: (19-31), 12 women, 8 men). The current sample size was comparable with previous work investigating saccade costs (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>; <xref ref-type="bibr" rid="bib157">Thomas et al., 2022</xref>). The total number of trials was substantially larger in the current dataset than in <xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref> (14,400 vs 4800), albeit from a slightly smaller number of participants (n = 20 vs. n = 24). Participants provided written informed consent before taking part, and were awarded monetary compensation or course credits. The experimental procedure was approved by Utrecht University’s ethical review board of the Faculty of Social Sciences (22–0635).</p></sec><sec id="s4-1-2"><title>Apparatus and stimuli</title><p>Gaze position and pupil size were recorded at 1000  Hz with an Eyelink 1000 desktop mount (SR Research, Ontario, Canada) in a brightness- and sound-attenuated laboratory. A chin- and forehead-rest limited head movements. Stimuli were presented using PsychoPy [v.2022.2.5; <xref ref-type="bibr" rid="bib114">Peirce et al., 2019</xref>] on an ASUS ROG PG278Q monitor (2560 × 1440, 100  Hz) positioned 67.5  cm away from eye position. The eye-tracker was calibrated (9 points) at the beginning of each session, during each break, and whenever necessary throughout the experiment (same procedure for both tasks, see below).</p><p>Potential saccade targets were eight equally spaced out red rings (1° diameter) positioned at an eccentricity of 10° visual angle. The central fixation stimulus was a red eight-legged asterisk of which each leg pointed towards one of the possible saccade targets (1°). These stimuli were presented on a blue circle (12° diameter; 11.64  cd/m<sup>2</sup>); the remaining part of the screen was black (0.73  cd/m<sup>2</sup>) to ensure equal brightness across all 36 possible target locations (<xref ref-type="fig" rid="fig1">Figure 1a and b</xref>).</p><p>To control for low-level visual effects on pupil size, the red color of all stimuli was made equiluminant to the blue background color using a flicker fusion calibration [as in <xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>]. A blue background (HSV: 240.1.1) was presented continuously while a central red circle (5° diameter) continuously flickered at 25 Hz. Participants adjusted the luminance of the red color by moving the mouse across the horizontal plane of the screen until the flickering was the least noticeable, and then clicked the left mouse button to confirm. This procedure was performed thrice, and the average luminance of the red color was used for the fixation and target stimuli throughout the task. Participants completed the flicker fusion calibration preceding each task.</p></sec><sec id="s4-1-3"><title>Procedure</title><p>The experiment started with the saccade planning task (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>), wherein participants planned saccades into 36 different cued directions. Each trial started when the central stimulus was fixated for 500 ms. After a fixation period (2000 ms) eight equally spaced potential saccade targets were presented (randomized which eight out of the 36 between trials). Afterwards, one of the eight legs of the asterisk became slightly thicker, cueing a saccade target (750–1250 ms, 100% valid). Participants planned and withheld an eye movement until cue offset, and then executed the saccade as fast as possible. Trials ended upon fixating the target stimulus (within 3°) for 500 ms. Whenever participants saccaded too early or to an incorrect location, red feedback text was presented (‘too early,’ ‘wrong location’). Each session consisted of 360 trials, preceded by ten practice trials. Participants could initiate a break whenever they wanted.</p><p>Participants subsequently completed a saccade preference task [adapted from <xref ref-type="bibr" rid="bib157">Thomas et al., 2022</xref>]. Upon briefly fixating the central stimulus (10–500 ms), possible saccade targets were presented in two out of the 36 positions around the visual field. The only restriction was that the two targets should at least differ 20° in angle to ensure targets were sufficiently spaced out - and to limit saccade averaging (<xref ref-type="bibr" rid="bib165">Van der Stigchel and Nijboer, 2013</xref>). Trials ended when one of the two saccade targets was fixated for 50ms. Participants completed 360 trials per session.</p></sec><sec id="s4-1-4"><title>Data processing and analyses</title><p>All data were analyzed using custom Python (v3.9.14) and R (v4.3.1) scripts. Analyses of pupillometric data followed recommendations by <xref ref-type="bibr" rid="bib147">Strauch et al., 2022</xref>; <xref ref-type="bibr" rid="bib101">Mathôt and Vilotijević, 2023</xref>. Blinks were interpolated (<xref ref-type="bibr" rid="bib101">Mathôt and Vilotijević, 2023</xref>), data were downsampled to 100  Hz, and pupil data were subtractively baseline corrected with the mean of the first 250 ms after cue onset. Saccades were detected offline using an onset velocity threshold of 75 °/s and an offset threshold of 1 °/s. Trials with fast (&lt;175 ms) or slow (&gt;550 ms) onset latency (<xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>), a very short (&lt;10 ms) or long saccade (&gt;110 ms) duration (<xref ref-type="bibr" rid="bib110">Nyström and Holmqvist, 2010</xref>), an amplitude smaller than 5°, saccades landing more than 2° from the target location, saccades toward the wrong target, and practice trials were discarded (13.67% in total). To map out saccade planning costs across directions, the average pupil size was calculated 150 ms before until 170 ms after cue offset (<xref ref-type="fig" rid="fig1">Figure 1f</xref>) - before any saccade onsets to prevent pupil foreshortening errors (<xref ref-type="bibr" rid="bib63">Hayes and Petrov, 2016</xref>). We analyzed saccade costs by incorporating continuous predictors for oblique (cardinal vs. oblique; 0–4), vertical (up vs. down; in y coordinates), and horizontal (left vs. right; in x coordinates) direction biases in a linear mixed-effects model (<xref ref-type="fig" rid="fig1">Figure 1e and f</xref>). We also incorporated properties of the ensuing saccade to control for their possible associations with pupil size. The final model was determined using AIC-based backward model selection (Wilkinson notation: pupil size ∼ oblique*saccade duration + vertical + horizontal + amplitude + landing error + peak velocity + (1 + oblique + vertical|participant)). For all mixed-effects models, we included as many by-participant random slopes as possible for our main effects of interest while ensuring model convergence (<xref ref-type="bibr" rid="bib17">Barr, 2013</xref>; <xref ref-type="bibr" rid="bib99">Mathôt et al., 2015</xref>). Absolute effect sizes (i.e. <italic>r</italic>) and their corresponding 95% confidence intervals for the linear mixed-effects models were calculated using <italic>t</italic> and <italic>df</italic> values with the ’effectsize’ package (v.0.8.8) in R. To obtain an average saccade costs map, pupil sizes were z-transformed per participant within sessions, and then averaged across participants for each direction (<xref ref-type="fig" rid="fig1">Figure 1d</xref>).</p><p>For the saccade preference task, saccades were detected as above. Which saccade target was selected per trial was determined using the last 50 ms of gaze data of each trial - the option closest to the gaze position was treated as the selected target. Trials were discarded if the difference in distance between the two saccade options in gaze position was less than 1.5° (3.47%). A logistic mixed-effects model was fit to investigate anisotropies across directions (Wilkinson notation: saccade preference ∼ oblique + vertical + horizontal + (1+oblique + vertical + horizontal|participant)). Saccade preference for each direction was calculated per participant by summing how often a direction was chosen and then dividing by the number of times that direction was offered. As for the saccade cost map, the average saccade preference map was obtained by averaging across participants (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). Preferred (&gt;50%) and avoided (&lt;50% chosen) directions were grouped using the average preference map (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). To investigate if cost predicted saccade selection on a trial-by-trial basis, we compared the saccade costs of the two potential options. We predicted that the option with the smaller pupil size from the average cost map (obtained from the saccade planning task) would be chosen. This procedure was performed for each participant, and subsequently tested against chance performance (50%) with a one-sample <italic>t</italic>-test.</p><p>Saccade curvature was computed using the peak deviation from a straight line between gaze position at saccade onset until saccade offset (<xref ref-type="fig" rid="fig3">Figure 3a</xref>; <xref ref-type="bibr" rid="bib163">Van der Stigchel et al., 2006</xref>). Trials were excluded from these analyses if: (a) saccade latencies were shorter than 175 ms, (b) saccade amplitudes were smaller than 5°, (c) saccade durations were shorter than 10 ms or longer than 110 ms and (d) if the angle between targets exceeded 150° (<xref ref-type="bibr" rid="bib110">Nyström and Holmqvist, 2010</xref>; <xref ref-type="bibr" rid="bib85">Koevoet et al., 2023</xref>; <xref ref-type="bibr" rid="bib165">Van der Stigchel and Nijboer, 2013</xref>). To analyze the relationship between saccade costs and saccade properties, we first computed the absolute saccade cost difference for each trial (as indexed from the average saccade cost map). A linear mixed-effects model was conducted to test whether saccade curvature and latency linked to saccade costs (Wilkinson notation: cost difference ∼ peak deviation + latency + (1 + peak deviation|participant)). We then split the data based on whether saccades curved toward or away from the non-selected option. The same trial-by-trial analysis as described above was used to investigate if cost predicted saccade selection in toward and away trials separately.</p></sec></sec><sec id="s4-2"><title>Search in natural scenes</title><sec id="s4-2-1"><title>Procedure</title><p>We analyzed existing data of two experiments to investigate if effort drives saccade selection in a more natural task [for an exhaustive explanation of the procedure see the original paper <xref ref-type="bibr" rid="bib99">Mathôt et al., 2015</xref>]. Briefly, in Experiments 1 and 2, sixteen and twenty-five participants, respectively, searched for small letters (‘Z’ or ‘H’) in natural scenes (from <xref ref-type="bibr" rid="bib158">Tkačik et al., 2011</xref>). As in the saccade planning and preference tasks, gaze position and pupil size were recorded with an Eyelink 1000 (SR Research, Ontario, Canada) at 1000  Hz. Stimuli were presented (1280 × 1024) using OpenSesame (<xref ref-type="bibr" rid="bib98">Mathôt et al., 2012</xref>) with the PsychoPy backend (<xref ref-type="bibr" rid="bib114">Peirce et al., 2019</xref>).</p><p>In Experiment 2, auditory digits (0–9) were presented with an inter-digit interval of 1500 ms during search - note that Experiment 1 did not feature the auditory dual task. Crucially, participants either performed a dual task wherein the count of a specific digit was monitored throughout search, or a single task where the number stream was ignored. The single and dual conditions were blocked, and the sequence of these blocks was random across participants.</p></sec><sec id="s4-2-2"><title>Data processing and analyses</title><p>Pupil size was averaged per fixation and subsequently z-transformed per participant (<xref ref-type="bibr" rid="bib99">Mathôt et al., 2015</xref>). Fixations with pupil sizes deviating more than 3<italic>SD</italic> from the mean (within a participant) and fixations positioned outside of the monitor were excluded to mitigate possible confounds (Exp. 1: 4.32%, Exp. 2: 9.75% discarded). 57,127 and 214,449 fixations were analyzed from Experiments 1 and 2, respectively. Fixations were classified into 36 bins based on their direction (bins consistent with the saccade planning and preference tasks).</p><p>To investigate if saccade costs predicted saccade preferences when searching in natural scenes, we analyzed all fixations from Experiment 1, and fixations from the single condition in Experiment 2. Next, we computed the average saccade preference map separately for each experiment by calculating the percentage of saccades in any of the 36 directions. Linear mixed-effects models were used to investigate whether this preference map predicted pupil size on a fixation-by-fixation basis in both experiments. We controlled for as many possible factors that are known to covary with pupil size in our model to control for them as much as possible to attempt to access the underlying saccade cost signal (<xref ref-type="bibr" rid="bib99">Mathôt et al., 2015</xref>; Wilkinson notation: pupil size ∼ saccade preferences + luminance + saliency + fixation number + trial number + x gaze coordinate + y gaze coordinate + saccade duration + fixation duration + saccade amplitude + (1 + saccade preferences|participant)).</p><p>To investigate if costly saccades were avoided in particular when the overall level of demand increased via the dual task, we analyzed data from Experiment 2, The percentages of saccades made into each direction for the single and dual conditions were calculated. We subtracted these averaged preference maps to obtain an adjustment map: this revealed how participants altered their saccade preferences under additional demand (<xref ref-type="fig" rid="fig4">Figure 4e</xref>). We predicted pupil size using the average adjustment map for each direction while again controlling for many possible confounding factors in the single condition using a linear mixed-effects model on a fixation-by-fixation basis (Wilkinson notation: pupil size ∼ saccade adjustment + luminance + saliency + fixation number + trial number + x gaze coordinate + y gaze coordinate + saccade duration + fixation duration + saccade amplitude + (1 + saccade adjustment|participant)).</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Supervision, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Resources, Data curation, Software, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Resources, Supervision, Funding acquisition, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Participants provided written informed consent before taking part, and were awarded monetary compensation or course credits. The experimental procedure was approved by Utrecht University's ethical review board of the Faculty of Social Sciences (22-0635).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-97760-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data and analyses scripts to reproduce the results are available via the Open Science Framework: <ext-link ext-link-type="uri" xlink:href="https://osf.io/n3ktm/">https://osf.io/n3ktm/</ext-link>. The original data from <xref ref-type="bibr" rid="bib99">Mathôt et al., 2015</xref> are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/smathot/materials_for_P0010.5">https://github.com/smathot/materials_for_P0010.5</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Koevoet</surname><given-names>D</given-names></name><name><surname>Strauch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Effort drives saccade selection</data-title><source>Open Science Framework</source><pub-id pub-id-type="doi">10.17605/OSF.IO/N3KTM</pub-id></element-citation></p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Mathôt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><data-title>P0010.5 Cross-experimental analysis</data-title><source>GitHub</source><pub-id pub-id-type="accession" xlink:href="https://github.com/smathot/materials_for_P0010.5">aef127f</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (grant agreement n° 863732).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrams</surname><given-names>J</given-names></name><name><surname>Nizam</surname><given-names>A</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Isoeccentric locations are not equivalent: the extent of the vertical meridian asymmetry</article-title><source>Vision Research</source><volume>52</volume><fpage>70</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2011.10.016</pub-id><pub-id pub-id-type="pmid">22086075</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahern</surname><given-names>S</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Pupillary responses during information processing vary with Scholastic Aptitude Test scores</article-title><source>Science</source><volume>205</volume><fpage>1289</fpage><lpage>1292</lpage><pub-id pub-id-type="doi">10.1126/science.472746</pub-id><pub-id pub-id-type="pmid">472746</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alnæs</surname><given-names>D</given-names></name><name><surname>Sneve</surname><given-names>MH</given-names></name><name><surname>Espeseth</surname><given-names>T</given-names></name><name><surname>Endestad</surname><given-names>T</given-names></name><name><surname>van de Pavert</surname><given-names>SHP</given-names></name><name><surname>Laeng</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil size signals mental effort deployed during multiple object tracking and predicts brain activity in the dorsal attention network and the locus coeruleus</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.1167/14.4.1</pub-id><pub-id pub-id-type="pmid">24692319</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amiez</surname><given-names>C</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Anatomical organization of the eye fields in the human and non-human primate frontal cortex</article-title><source>Progress in Neurobiology</source><volume>89</volume><fpage>220</fpage><lpage>230</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2009.07.010</pub-id><pub-id pub-id-type="pmid">19665515</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>AJ</given-names></name><name><surname>Yadav</surname><given-names>H</given-names></name><name><surname>Carpenter</surname><given-names>RHS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Directional prediction by the saccadic system</article-title><source>Current Biology</source><volume>18</volume><fpage>614</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.03.057</pub-id><pub-id pub-id-type="pmid">18424143</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>App</surname><given-names>E</given-names></name><name><surname>Debus</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Saccadic velocity and activation: development of a diagnostic tool for assessing energy regulation</article-title><source>Ergonomics</source><volume>41</volume><fpage>689</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1080/001401398186856</pub-id><pub-id pub-id-type="pmid">9613229</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005a</year><article-title>Adaptive gain and the role of the locus coeruleus-norepinephrine system in optimal performance</article-title><source>The Journal of Comparative Neurology</source><volume>493</volume><fpage>99</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1002/cne.20723</pub-id><pub-id pub-id-type="pmid">16254995</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005b</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Waterhouse</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Locus coeruleus: From global projection system to adaptive regulation of behavior</article-title><source>Brain Research</source><volume>1645</volume><fpage>75</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2016.03.001</pub-id><pub-id pub-id-type="pmid">26969408</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Attneave</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1959">1959</year><source>Applications of Information Theory to Psychology: A Summary of Basic Concepts, Methods, and Results</source><publisher-loc>Oxford, England</publisher-loc><publisher-name>Henry Holt</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attwell</surname><given-names>D</given-names></name><name><surname>Laughlin</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>An energy budget for signaling in the grey matter of the brain</article-title><source>Journal of Cerebral Blood Flow &amp; Metabolism</source><volume>21</volume><fpage>1133</fpage><lpage>1145</lpage><pub-id pub-id-type="doi">10.1097/00004647-200110000-00001</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Awh</surname><given-names>E</given-names></name><name><surname>Belopolsky</surname><given-names>AV</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Top-down versus bottom-up attentional control: A failed theoretical dichotomy</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>437</fpage><lpage>443</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.06.010</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldwin</surname><given-names>AS</given-names></name><name><surname>Meese</surname><given-names>TS</given-names></name><name><surname>Baker</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The attenuation surface for contrast sensitivity has the form of a witch’s hat within the central visual field</article-title><source>Journal of Vision</source><volume>12</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.1167/12.11.23</pub-id><pub-id pub-id-type="pmid">23104816</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ballard</surname><given-names>DH</given-names></name><name><surname>Hayhoe</surname><given-names>MM</given-names></name><name><surname>Pelz</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Memory representations in natural tasks</article-title><source>Journal of Cognitive Neuroscience</source><volume>7</volume><fpage>66</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1162/jocn.1995.7.1.66</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbot</surname><given-names>A</given-names></name><name><surname>Xue</surname><given-names>S</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Asymmetries in visual acuity around the visual field</article-title><source>Journal of Vision</source><volume>21</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.1167/jov.21.1.2</pub-id><pub-id pub-id-type="pmid">33393963</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bargary</surname><given-names>G</given-names></name><name><surname>Bosten</surname><given-names>JM</given-names></name><name><surname>Goodbourn</surname><given-names>PT</given-names></name><name><surname>Lawrance-Owen</surname><given-names>AJ</given-names></name><name><surname>Hogg</surname><given-names>RE</given-names></name><name><surname>Mollon</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Individual differences in human eye movements: An oculomotor signature?</article-title><source>Vision Research</source><volume>141</volume><fpage>157</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2017.03.001</pub-id><pub-id pub-id-type="pmid">28373058</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barr</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Random effects structure for testing interactions in linear mixed-effects models</article-title><source>Frontiers in Psychology</source><volume>4</volume><elocation-id>328</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00328</pub-id><pub-id pub-id-type="pmid">23761778</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basso</surname><given-names>MA</given-names></name><name><surname>May</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Circuits for action and cognition: A view from the superior colliculus</article-title><source>Annual Review of Vision Science</source><volume>3</volume><fpage>197</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-102016-061234</pub-id><pub-id pub-id-type="pmid">28617660</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basso</surname><given-names>MA</given-names></name><name><surname>Bickford</surname><given-names>ME</given-names></name><name><surname>Cang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Unraveling circuits of visual perception and cognition through the superior colliculus</article-title><source>Neuron</source><volume>109</volume><fpage>918</fpage><lpage>937</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.01.013</pub-id><pub-id pub-id-type="pmid">33548173</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baumann</surname><given-names>O</given-names></name><name><surname>Borra</surname><given-names>RJ</given-names></name><name><surname>Bower</surname><given-names>JM</given-names></name><name><surname>Cullen</surname><given-names>KE</given-names></name><name><surname>Habas</surname><given-names>C</given-names></name><name><surname>Ivry</surname><given-names>RB</given-names></name><name><surname>Leggio</surname><given-names>M</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name><name><surname>Molinari</surname><given-names>M</given-names></name><name><surname>Moulton</surname><given-names>EA</given-names></name><name><surname>Paulin</surname><given-names>MG</given-names></name><name><surname>Pavlova</surname><given-names>MA</given-names></name><name><surname>Schmahmann</surname><given-names>JD</given-names></name><name><surname>Sokolov</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Consensus paper: the role of the cerebellum in perceptual processes</article-title><source>Cerebellum</source><volume>14</volume><fpage>197</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1007/s12311-014-0627-7</pub-id><pub-id pub-id-type="pmid">25479821</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Spatial remapping of the visual world across saccades</article-title><source>Neuroreport</source><volume>18</volume><fpage>1207</fpage><lpage>1213</lpage><pub-id pub-id-type="doi">10.1097/WNR.0b013e328244e6c3</pub-id><pub-id pub-id-type="pmid">17632269</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Active inhibition and memory promote exploration and search of natural scenes</article-title><source>Journal of Vision</source><volume>12</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.1167/12.8.8</pub-id><pub-id pub-id-type="pmid">22895881</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Task-evoked pupillary responses, processing load, and the structure of processing resources</article-title><source>Psychological Bulletin</source><volume>91</volume><fpage>276</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.91.2.276</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Kupers</surname><given-names>ER</given-names></name><name><surname>Barbot</surname><given-names>A</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cortical magnification in human visual cortex parallels task performance around the visual field</article-title><source>eLife</source><volume>10</volume><elocation-id>e67685</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.67685</pub-id><pub-id pub-id-type="pmid">34342581</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berridge</surname><given-names>CW</given-names></name><name><surname>Waterhouse</surname><given-names>BD</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The locus coeruleus–noradrenergic system: modulation of behavioral state and state-dependent cognitive processes</article-title><source>Brain Research Reviews</source><volume>42</volume><fpage>33</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/S0165-0173(03)00143-7</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruce</surname><given-names>CJ</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name><name><surname>Bushnell</surname><given-names>MC</given-names></name><name><surname>Stanton</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Primate frontal eye fields. II. Physiological and anatomical correlates of electrically evoked eye movements</article-title><source>Journal of Neurophysiology</source><volume>54</volume><fpage>714</fpage><lpage>734</lpage><pub-id pub-id-type="doi">10.1152/jn.1985.54.3.714</pub-id><pub-id pub-id-type="pmid">4045546</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bumke</surname><given-names>O</given-names></name></person-group><year iso-8601-date="1911">1911</year><source>Die Pupillenstörungen Bei Geistes-Und Nervenkrankheiten</source><publisher-name>Fischer</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bustamante</surname><given-names>LA</given-names></name><name><surname>Oshinowo</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>JR</given-names></name><name><surname>Tong</surname><given-names>E</given-names></name><name><surname>Burton</surname><given-names>AR</given-names></name><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Effort Foraging Task reveals positive correlation between individual differences in the cost of cognitive and physical effort in humans</article-title><source>PNAS</source><volume>120</volume><elocation-id>e2221510120</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2221510120</pub-id><pub-id pub-id-type="pmid">38064507</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrasco</surname><given-names>M</given-names></name><name><surname>Talgar</surname><given-names>CP</given-names></name><name><surname>Cameron</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Characterizing visual performance fields: effects of transient covert attention, spatial frequency, eccentricity, task and set size</article-title><source>Spatial Vision</source><volume>15</volume><fpage>61</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1163/15685680152692015</pub-id><pub-id pub-id-type="pmid">11893125</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castrillon</surname><given-names>G</given-names></name><name><surname>Epp</surname><given-names>S</given-names></name><name><surname>Bose</surname><given-names>A</given-names></name><name><surname>Fraticelli</surname><given-names>L</given-names></name><name><surname>Hechler</surname><given-names>A</given-names></name><name><surname>Belenya</surname><given-names>R</given-names></name><name><surname>Ranft</surname><given-names>A</given-names></name><name><surname>Yakushev</surname><given-names>I</given-names></name><name><surname>Utz</surname><given-names>L</given-names></name><name><surname>Sundar</surname><given-names>L</given-names></name><name><surname>Rauschecker</surname><given-names>JP</given-names></name><name><surname>Preibisch</surname><given-names>C</given-names></name><name><surname>Kurcyus</surname><given-names>K</given-names></name><name><surname>Riedl</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>An energy costly architecture of neuromodulators for human brain evolution and cognition</article-title><source>Science Advances</source><volume>9</volume><elocation-id>eadi7632</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.adi7632</pub-id><pub-id pub-id-type="pmid">38091393</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chakravarthi</surname><given-names>R</given-names></name><name><surname>Papadaki</surname><given-names>D</given-names></name><name><surname>Krajnik</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Visual field asymmetries in numerosity processing</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>84</volume><fpage>2607</fpage><lpage>2622</lpage><pub-id pub-id-type="doi">10.3758/s13414-022-02585-1</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chudasama</surname><given-names>Y</given-names></name><name><surname>Daniels</surname><given-names>TE</given-names></name><name><surname>Gorrin</surname><given-names>DP</given-names></name><name><surname>Rhodes</surname><given-names>SEV</given-names></name><name><surname>Rudebeck</surname><given-names>PH</given-names></name><name><surname>Murray</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The role of the anterior cingulate cortex in choices based on reward value and reward contingency</article-title><source>Cerebral Cortex</source><volume>23</volume><fpage>2884</fpage><lpage>2898</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs266</pub-id><pub-id pub-id-type="pmid">22944530</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conti</surname><given-names>F</given-names></name><name><surname>Irish</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Harnessing visual imagery and oculomotor behaviour to understand prospection</article-title><source>Trends in Cognitive Sciences</source><volume>25</volume><fpage>272</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2021.01.009</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Patel</surname><given-names>G</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The reorienting system of the human brain: from environment to theory of mind</article-title><source>Neuron</source><volume>58</volume><fpage>306</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.04.017</pub-id><pub-id pub-id-type="pmid">18466742</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cos</surname><given-names>I</given-names></name><name><surname>Bélanger</surname><given-names>N</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The influence of predicted arm biomechanics on decision making</article-title><source>Journal of Neurophysiology</source><volume>105</volume><fpage>3022</fpage><lpage>3033</lpage><pub-id pub-id-type="doi">10.1152/jn.00975.2010</pub-id><pub-id pub-id-type="pmid">21451055</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cos</surname><given-names>I</given-names></name><name><surname>Medleg</surname><given-names>F</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The modulatory influence of end-point controllability on decisions between actions</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>1764</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1152/jn.00081.2012</pub-id><pub-id pub-id-type="pmid">22773776</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cos</surname><given-names>I</given-names></name><name><surname>Duque</surname><given-names>J</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Rapid prediction of biomechanical costs during action decisions</article-title><source>Journal of Neurophysiology</source><volume>112</volume><fpage>1256</fpage><lpage>1266</lpage><pub-id pub-id-type="doi">10.1152/jn.00147.2014</pub-id><pub-id pub-id-type="pmid">24899673</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crapse</surname><given-names>TB</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Basso</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A role for the superior colliculus in decision criteria</article-title><source>Neuron</source><volume>97</volume><fpage>181</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.12.006</pub-id><pub-id pub-id-type="pmid">29301100</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>ME</given-names></name><name><surname>Herrmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Eye movements decrease during effortful speech listening</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>5856</fpage><lpage>5869</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0240-23.2023</pub-id><pub-id pub-id-type="pmid">37491313</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curthoys</surname><given-names>IS</given-names></name><name><surname>Markham</surname><given-names>CH</given-names></name><name><surname>Furuya</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Direct projection of pause neurons to nystagmus-related excitatory burst neurons in the cat pontine reticular formation</article-title><source>Experimental Neurology</source><volume>83</volume><fpage>414</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/S0014-4886(84)90109-2</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dahl</surname><given-names>MJ</given-names></name><name><surname>Mather</surname><given-names>M</given-names></name><name><surname>Werkle-Bergner</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Noradrenergic modulation of rhythmic neural activity shapes selective attention</article-title><source>Trends in Cognitive Sciences</source><volume>26</volume><fpage>38</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2021.10.009</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Neural mechanisms of selective visual attention</article-title><source>Annual Review of Neuroscience</source><volume>18</volume><fpage>193</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.18.030195.001205</pub-id><pub-id pub-id-type="pmid">7605061</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deubel</surname><given-names>H</given-names></name><name><surname>Schneider</surname><given-names>WX</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Saccade target selection and object recognition: Evidence for a common attentional mechanism</article-title><source>Vision Research</source><volume>36</volume><fpage>1827</fpage><lpage>1837</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(95)00294-4</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deverett</surname><given-names>B</given-names></name><name><surname>Koay</surname><given-names>SA</given-names></name><name><surname>Oostland</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>SSH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cerebellar involvement in an evidence-accumulation decision-making task</article-title><source>eLife</source><volume>7</volume><elocation-id>e36781</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.36781</pub-id><pub-id pub-id-type="pmid">30102151</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Stasi</surname><given-names>LL</given-names></name><name><surname>Antolí</surname><given-names>A</given-names></name><name><surname>Cañas</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Main sequence: an index for detecting mental workload variation in complex tasks</article-title><source>Applied Ergonomics</source><volume>42</volume><fpage>807</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1016/j.apergo.2011.01.003</pub-id><pub-id pub-id-type="pmid">21316645</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engbert</surname><given-names>R</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Microsaccades uncover the orientation of covert attention</article-title><source>Vision Research</source><volume>43</volume><fpage>1035</fpage><lpage>1045</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(03)00084-1</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ezzo</surname><given-names>R</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name><name><surname>Rokers</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Asymmetries in the discrimination of motion direction around the visual field</article-title><source>Journal of Vision</source><volume>23</volume><elocation-id>19</elocation-id><pub-id pub-id-type="doi">10.1167/jov.23.3.19</pub-id><pub-id pub-id-type="pmid">36995280</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fabius</surname><given-names>JH</given-names></name><name><surname>Fracasso</surname><given-names>A</given-names></name><name><surname>Nijboer</surname><given-names>TCW</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Time course of spatiotopic updating across saccades</article-title><source>PNAS</source><volume>116</volume><fpage>2027</fpage><lpage>2032</lpage><pub-id pub-id-type="doi">10.1073/pnas.1812210116</pub-id><pub-id pub-id-type="pmid">30655348</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Findlay</surname><given-names>JM</given-names></name><name><surname>Gilchrist</surname><given-names>ID</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Active Vision: The Psychology of Looking and Seeing</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780198524793.001.0001</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foulsham</surname><given-names>T</given-names></name><name><surname>Kingstone</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Asymmetries in the direction of saccades during perception of scenes and fractals: effects of image type and image features</article-title><source>Vision Research</source><volume>50</volume><fpage>779</fpage><lpage>795</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2010.01.019</pub-id><pub-id pub-id-type="pmid">20144645</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The free-energy principle: A unified brain theory?</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>127</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nrn2787</pub-id><pub-id pub-id-type="pmid">20068583</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gandhi</surname><given-names>NJ</given-names></name><name><surname>Katnani</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Motor functions of the superior colliculus</article-title><source>Annual Review of Neuroscience</source><volume>34</volume><fpage>205</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-061010-113728</pub-id><pub-id pub-id-type="pmid">21456962</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaymard</surname><given-names>B</given-names></name><name><surname>Rivaud</surname><given-names>S</given-names></name><name><surname>Cassarini</surname><given-names>JF</given-names></name><name><surname>Dubard</surname><given-names>T</given-names></name><name><surname>Rancurel</surname><given-names>G</given-names></name><name><surname>Agid</surname><given-names>Y</given-names></name><name><surname>Pierrot-Deseilligny</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Effects of anterior cingulate cortex lesions on ocular saccades in humans</article-title><source>Experimental Brain Research</source><volume>120</volume><fpage>173</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1007/s002210050391</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilchrist</surname><given-names>ID</given-names></name><name><surname>Harvey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Evidence for a systematic component within scan paths in visual search</article-title><source>Visual Cognition</source><volume>14</volume><fpage>704</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1080/13506280500193719</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glimcher</surname><given-names>PW</given-names></name><name><surname>Sparks</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Movement selection in advance of action in the superior colliculus</article-title><source>Nature</source><volume>355</volume><fpage>542</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1038/355542a0</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gottlieb</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attention, learning, and the value of information</article-title><source>Neuron</source><volume>76</volume><fpage>281</fpage><lpage>295</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.034</pub-id><pub-id pub-id-type="pmid">23083732</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenwood</surname><given-names>JA</given-names></name><name><surname>Szinte</surname><given-names>M</given-names></name><name><surname>Sayim</surname><given-names>B</given-names></name><name><surname>Cavanagh</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Variations in crowding, saccadic precision, and spatial localization reveal the shared topology of spatial vision</article-title><source>PNAS</source><volume>114</volume><fpage>E3573</fpage><lpage>E3582</lpage><pub-id pub-id-type="doi">10.1073/pnas.1615504114</pub-id><pub-id pub-id-type="pmid">28396415</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grujic</surname><given-names>N</given-names></name><name><surname>Polania</surname><given-names>R</given-names></name><name><surname>Burdakov</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Neurobehavioral meaning of pupil size</article-title><source>Neuron</source><volume>112</volume><fpage>3381</fpage><lpage>3395</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2024.05.029</pub-id><pub-id pub-id-type="pmid">38925124</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hagura</surname><given-names>N</given-names></name><name><surname>Haggard</surname><given-names>P</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Perceptual decisions are biased by the cost to act</article-title><source>eLife</source><volume>6</volume><elocation-id>e18422</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18422</pub-id><pub-id pub-id-type="pmid">28219479</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanning</surname><given-names>NM</given-names></name><name><surname>Himmelberg</surname><given-names>MM</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Presaccadic attention enhances contrast sensitivity, but not at the upper vertical meridian</article-title><source>iScience</source><volume>25</volume><elocation-id>103851</elocation-id><pub-id pub-id-type="doi">10.1016/j.isci.2022.103851</pub-id><pub-id pub-id-type="pmid">35198902</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanning</surname><given-names>NM</given-names></name><name><surname>Himmelberg</surname><given-names>MM</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Presaccadic attention depends on eye movement direction and is related to V1 cortical magnification</article-title><source>The Journal of Neuroscience</source><volume>44</volume><elocation-id>e1023232023</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1023-23.2023</pub-id><pub-id pub-id-type="pmid">38316562</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasenstaub</surname><given-names>A</given-names></name><name><surname>Otte</surname><given-names>S</given-names></name><name><surname>Callaway</surname><given-names>E</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Metabolic cost as a unifying principle governing neuronal biophysics</article-title><source>PNAS</source><volume>107</volume><fpage>12329</fpage><lpage>12334</lpage><pub-id pub-id-type="doi">10.1073/pnas.0914886107</pub-id><pub-id pub-id-type="pmid">20616090</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayes</surname><given-names>TR</given-names></name><name><surname>Petrov</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mapping and correcting the influence of gaze position on pupil size measurements</article-title><source>Behavior Research Methods</source><volume>48</volume><fpage>510</fpage><lpage>527</lpage><pub-id pub-id-type="doi">10.3758/s13428-015-0588-x</pub-id><pub-id pub-id-type="pmid">25953668</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>JM</given-names></name><name><surname>Hollingworth</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><chapter-title>Eye movements during scene viewing: an overview</chapter-title><person-group person-group-type="editor"><name><surname>Underwood</surname><given-names>G</given-names></name></person-group><source>Eye Guidance in Reading and Scene Perception</source><publisher-loc>Amsterdam</publisher-loc><publisher-name>Elsevier Science Ltd</publisher-name><fpage>269</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1016/B978-008043361-5/50013-4</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Human gaze control during real-world scene perception</article-title><source>Trends in Cognitive Sciences</source><volume>7</volume><fpage>498</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2003.09.006</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hess</surname><given-names>EH</given-names></name><name><surname>Polt</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Pupil size in relation to mental activity during simple problem-solving</article-title><source>Science</source><volume>143</volume><fpage>1190</fpage><lpage>1192</lpage><pub-id pub-id-type="doi">10.1126/science.143.3611.1190</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Himmelberg</surname><given-names>MM</given-names></name><name><surname>Kurzawski</surname><given-names>JW</given-names></name><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Pelli</surname><given-names>DG</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cross-dataset reproducibility of human retinotopic maps</article-title><source>NeuroImage</source><volume>244</volume><elocation-id>118609</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118609</pub-id><pub-id pub-id-type="pmid">34582948</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Himmelberg</surname><given-names>MM</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Linking individual differences in human primary visual cortex to contrast sensitivity around the visual field</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>3309</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-31041-9</pub-id><pub-id pub-id-type="pmid">35697680</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Himmelberg</surname><given-names>MM</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Polar angle asymmetries in visual perception and neural architecture</article-title><source>Trends in Neurosciences</source><volume>46</volume><fpage>445</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2023.03.006</pub-id><pub-id pub-id-type="pmid">37031051</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoogerbrugge</surname><given-names>AJ</given-names></name><name><surname>Strauch</surname><given-names>C</given-names></name><name><surname>Nijboer</surname><given-names>TCW</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Don’t hide the instruction manual: A dynamic trade-off between using internal and external templates during visual search</article-title><source>Journal of Vision</source><volume>23</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.1167/jov.23.7.14</pub-id><pub-id pub-id-type="pmid">37486300</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoppe</surname><given-names>D</given-names></name><name><surname>Rothkopf</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning rational temporal eye movement strategies</article-title><source>PNAS</source><volume>113</volume><fpage>8332</fpage><lpage>8337</lpage><pub-id pub-id-type="doi">10.1073/pnas.1601305113</pub-id><pub-id pub-id-type="pmid">27382164</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoppe</surname><given-names>D</given-names></name><name><surname>Rothkopf</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Multi-step planning of eye movements in visual search</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>144</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-37536-0</pub-id><pub-id pub-id-type="pmid">30644423</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hull</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="1943">1943</year><source>Principles of Behavior: An Introduction to Behavior Theory</source><publisher-loc>Oxford, England</publisher-loc><publisher-name>Appleton-Century</publisher-name></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itti</surname><given-names>L</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Niebur</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A model of saliency-based visual attention for rapid scene analysis</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>20</volume><fpage>1254</fpage><lpage>1259</lpage><pub-id pub-id-type="doi">10.1109/34.730558</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itti</surname><given-names>L</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Computational modelling of visual attention</article-title><source>Nature Reviews Neuroscience</source><volume>2</volume><fpage>194</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1038/35058500</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jainta</surname><given-names>S</given-names></name><name><surname>Vernet</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>Q</given-names></name><name><surname>Kapoula</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The pupil reflects motor preparation for saccades - even before the eye starts to move</article-title><source>Frontiers in Human Neuroscience</source><volume>5</volume><elocation-id>97</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00097</pub-id><pub-id pub-id-type="pmid">22046154</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jamadar</surname><given-names>S</given-names></name><name><surname>Behler</surname><given-names>A</given-names></name><name><surname>Deery</surname><given-names>H</given-names></name><name><surname>Breakspear</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The metabolic costs of cognition</article-title><source>Open Science Framework</source><volume>13</volume><elocation-id>m5jze</elocation-id><pub-id pub-id-type="doi">10.31219/osf.io/m5jze</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil size as a window on neural substrates of cognition</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>466</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.005</pub-id><pub-id pub-id-type="pmid">32331857</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>EJ</given-names></name><name><surname>Bautista</surname><given-names>AR</given-names></name><name><surname>Nunez</surname><given-names>MD</given-names></name><name><surname>Allen</surname><given-names>DC</given-names></name><name><surname>Tak</surname><given-names>JH</given-names></name><name><surname>Alvarez</surname><given-names>E</given-names></name><name><surname>Basso</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Causal role for the primate superior colliculus in the computation of evidence for perceptual decisions</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1121</fpage><lpage>1131</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00878-6</pub-id><pub-id pub-id-type="pmid">34183869</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kadner</surname><given-names>F</given-names></name><name><surname>Thomas</surname><given-names>T</given-names></name><name><surname>Hoppe</surname><given-names>D</given-names></name><name><surname>Rothkopf</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Improving saliency models’ predictions of the next fixation with humans’ intrinsic cost of gaze shifts</article-title><conf-name>2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</conf-name><pub-id pub-id-type="doi">10.1109/WACV56688.2023.00214</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Pupil diameter and load on memory</article-title><source>Scienc</source><volume>154</volume><fpage>1583</fpage><lpage>1585</lpage><pub-id pub-id-type="doi">10.1126/science.154.3756.1583</pub-id><pub-id pub-id-type="pmid">5924930</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1973">1973</year><source>Attention and Effort</source><publisher-name>Prentice-Hall</publisher-name></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>WM</given-names></name><name><surname>Fuchs</surname><given-names>AF</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Reticular control of vertical saccadic eye movements by mesencephalic burst neurons</article-title><source>Journal of Neurophysiology</source><volume>42</volume><fpage>861</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.1152/jn.1979.42.3.861</pub-id><pub-id pub-id-type="pmid">107287</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koevoet</surname><given-names>D</given-names></name><name><surname>Strauch</surname><given-names>C</given-names></name><name><surname>Naber</surname><given-names>M</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The costs of paying overt and covert attention assessed with pupillometry</article-title><source>Psychological Science</source><volume>34</volume><fpage>887</fpage><lpage>898</lpage><pub-id pub-id-type="doi">10.1177/09567976231179378</pub-id><pub-id pub-id-type="pmid">37314425</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koevoet</surname><given-names>D</given-names></name><name><surname>Strauch</surname><given-names>C</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name><name><surname>Mathôt</surname><given-names>S</given-names></name><name><surname>Naber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Revealing visual working memory operations with pupillometry: Encoding, maintenance, and prioritization</article-title><source>Wiley Interdisciplinary Reviews. Cognitive Science</source><volume>15</volume><elocation-id>e1668</elocation-id><pub-id pub-id-type="doi">10.1002/wcs.1668</pub-id><pub-id pub-id-type="pmid">37933423</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kool</surname><given-names>W</given-names></name><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Rosen</surname><given-names>ZB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Decision making and the avoidance of cognitive demand</article-title><source>Journal of Experimental Psychology. General</source><volume>139</volume><fpage>665</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1037/a0020198</pub-id><pub-id pub-id-type="pmid">20853993</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kosch</surname><given-names>T</given-names></name><name><surname>Hassib</surname><given-names>M</given-names></name><name><surname>Woźniak</surname><given-names>PW</given-names></name><name><surname>Buschek</surname><given-names>D</given-names></name><name><surname>Alt</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Your Eyes Tell: Leveraging Smooth Pursuit for Assessing Cognitive Workload</article-title><conf-name>Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</conf-name><pub-id pub-id-type="doi">10.1145/3173574.3174010</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kümmerer</surname><given-names>M</given-names></name><name><surname>Wallis</surname><given-names>TSA</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>DeepGaze II: Reading Fixations from Deep Features Trained on Object Recognition</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1610.01563">https://arxiv.org/abs/1610.01563</ext-link></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kümmerer</surname><given-names>M</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Wallis</surname><given-names>TSA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>DeepGaze III: Modeling free-viewing human scanpaths with deep learning</article-title><source>Journal of Vision</source><volume>22</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/jov.22.5.7</pub-id><pub-id pub-id-type="pmid">35472130</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurzban</surname><given-names>R</given-names></name><name><surname>Duckworth</surname><given-names>A</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Myers</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>An opportunity cost model of subjective effort and task performance</article-title><source>The Behavioral and Brain Sciences</source><volume>36</volume><fpage>661</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1017/S0140525X12003196</pub-id><pub-id pub-id-type="pmid">24304775</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laeng</surname><given-names>B</given-names></name><name><surname>Sirois</surname><given-names>S</given-names></name><name><surname>Gredebäck</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Pupillometry: A window to the preconscious?</article-title><source>Perspectives on Psychological Science</source><volume>7</volume><fpage>18</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1177/1745691611427305</pub-id><pub-id pub-id-type="pmid">26168419</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisi</surname><given-names>M</given-names></name><name><surname>Solomon</surname><given-names>JA</given-names></name><name><surname>Morgan</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Gain control of saccadic eye movements is probabilistic</article-title><source>PNAS</source><volume>116</volume><fpage>16137</fpage><lpage>16142</lpage><pub-id pub-id-type="doi">10.1073/pnas.1901963116</pub-id><pub-id pub-id-type="pmid">31337680</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Loewenfeld</surname><given-names>IE</given-names></name></person-group><year iso-8601-date="1993">1993</year><source>The Pupil: Anatomy, Physiology, and Clinical Applications</source><publisher-name>Iowa State University Press</publisher-name></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luck</surname><given-names>SJ</given-names></name><name><surname>Vogel</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual working memory capacity: from psychophysics and neurobiology to individual differences</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>391</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.006</pub-id><pub-id pub-id-type="pmid">23850263</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Changing concepts of working memory</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>347</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1038/nn.3655</pub-id><pub-id pub-id-type="pmid">24569831</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackeben</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Sustained focal attention and peripheral letter recognition</article-title><source>Spatial Vision</source><volume>12</volume><fpage>51</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1163/156856899X00030</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathôt</surname><given-names>S</given-names></name><name><surname>Schreij</surname><given-names>D</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>OpenSesame: an open-source, graphical experiment builder for the social sciences</article-title><source>Behavior Research Methods</source><volume>44</volume><fpage>314</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.3758/s13428-011-0168-7</pub-id><pub-id pub-id-type="pmid">22083660</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathôt</surname><given-names>S</given-names></name><name><surname>Siebold</surname><given-names>A</given-names></name><name><surname>Donk</surname><given-names>M</given-names></name><name><surname>Vitu</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Large pupils predict goal-driven eye movements</article-title><source>Journal of Experimental Psychology. General</source><volume>144</volume><fpage>513</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1037/a0039168</pub-id><pub-id pub-id-type="pmid">25867221</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathôt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupillometry: Psychology, physiology, and function</article-title><source>Journal of Cognition</source><volume>1</volume><elocation-id>16</elocation-id><pub-id pub-id-type="doi">10.5334/joc.18</pub-id><pub-id pub-id-type="pmid">31517190</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathôt</surname><given-names>S</given-names></name><name><surname>Vilotijević</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Methods in cognitive pupillometry: Design, preprocessing, and statistical analysis</article-title><source>Behavior Research Methods</source><volume>55</volume><fpage>3055</fpage><lpage>3077</lpage><pub-id pub-id-type="doi">10.3758/s13428-022-01957-7</pub-id><pub-id pub-id-type="pmid">36028608</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>May</surname><given-names>JG</given-names></name><name><surname>Kennedy</surname><given-names>RS</given-names></name><name><surname>Williams</surname><given-names>MC</given-names></name><name><surname>Dunlap</surname><given-names>WP</given-names></name><name><surname>Brannan</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Eye movement indices of mental workload</article-title><source>Acta Psychologica</source><volume>75</volume><fpage>75</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/0001-6918(90)90067-P</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazancieux</surname><given-names>A</given-names></name><name><surname>Mauconduit</surname><given-names>F</given-names></name><name><surname>Amadon</surname><given-names>A</given-names></name><name><surname>Willem de Gee</surname><given-names>J</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Brainstem fMRI signaling of surprise across different types of deviant stimuli</article-title><source>Cell Reports</source><volume>42</volume><elocation-id>113405</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2023.113405</pub-id><pub-id pub-id-type="pmid">37950868</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McPeek</surname><given-names>RM</given-names></name><name><surname>Han</surname><given-names>JH</given-names></name><name><surname>Keller</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Competition between saccade goals in the superior colliculus produces saccade curvature</article-title><source>Journal of Neurophysiology</source><volume>89</volume><fpage>2577</fpage><lpage>2590</lpage><pub-id pub-id-type="doi">10.1152/jn.00657.2002</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Melcher</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Predictive remapping of visual features precedes saccadic eye movements</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>903</fpage><lpage>907</lpage><pub-id pub-id-type="doi">10.1038/nn1917</pub-id><pub-id pub-id-type="pmid">17589507</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Melcher</surname><given-names>D</given-names></name><name><surname>Colby</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Trans-saccadic perception</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>466</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.09.003</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Müller</surname><given-names>T</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Apps</surname><given-names>MAJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Preferences for seeking effort or reward information bias the willingness to work</article-title><source>Scientific Reports</source><volume>12</volume><elocation-id>19486</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-022-21917-7</pub-id><pub-id pub-id-type="pmid">36376340</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naber</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupillometric investigation into the speed-accuracy trade-off in a visuo-motor aiming task</article-title><source>Psychophysiology</source><volume>57</volume><elocation-id>e13499</elocation-id><pub-id pub-id-type="doi">10.1111/psyp.13499</pub-id><pub-id pub-id-type="pmid">31736089</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nozari</surname><given-names>N</given-names></name><name><surname>Martin</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Is working memory domain-general or domain-specific?</article-title><source>Trends in Cognitive Sciences</source><volume>28</volume><fpage>1023</fpage><lpage>1036</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2024.06.006</pub-id><pub-id pub-id-type="pmid">39019705</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nyström</surname><given-names>M</given-names></name><name><surname>Holmqvist</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data</article-title><source>Behavior Research Methods</source><volume>42</volume><fpage>188</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.3758/BRM.42.1.188</pub-id><pub-id pub-id-type="pmid">20160299</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohl</surname><given-names>S</given-names></name><name><surname>Kroell</surname><given-names>LM</given-names></name><name><surname>Rolfs</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Saccadic selection in visual working memory is robust across the visual field and linked to saccade metrics: Evidence from nine experiments and more than 100,000 trials</article-title><source>Journal of Experimental Psychology. General</source><volume>153</volume><fpage>544</fpage><lpage>563</lpage><pub-id pub-id-type="doi">10.1037/xge0001520</pub-id><pub-id pub-id-type="pmid">38032614</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname><given-names>C</given-names></name><name><surname>Conen</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Orbitofrontal cortex: A neural circuit for economic decisions</article-title><source>Neuron</source><volume>96</volume><fpage>736</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.031</pub-id><pub-id pub-id-type="pmid">29144973</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paus</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Location and function of the human frontal eye-field: A selective review</article-title><source>Neuropsychologia</source><volume>34</volume><fpage>475</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(95)00134-4</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname><given-names>J</given-names></name><name><surname>Gray</surname><given-names>JR</given-names></name><name><surname>Simpson</surname><given-names>S</given-names></name><name><surname>MacAskill</surname><given-names>M</given-names></name><name><surname>Höchenberger</surname><given-names>R</given-names></name><name><surname>Sogo</surname><given-names>H</given-names></name><name><surname>Kastman</surname><given-names>E</given-names></name><name><surname>Lindeløv</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>PsychoPy2: Experiments in behavior made easy</article-title><source>Behavior Research Methods</source><volume>51</volume><fpage>195</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.3758/s13428-018-01193-y</pub-id><pub-id pub-id-type="pmid">30734206</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>SE</given-names></name><name><surname>Posner</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The attention system of the human brain: 20 years after</article-title><source>Annual Review of Neuroscience</source><volume>35</volume><fpage>73</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150525</pub-id><pub-id pub-id-type="pmid">22524787</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petitet</surname><given-names>P</given-names></name><name><surname>Attaallah</surname><given-names>B</given-names></name><name><surname>Manohar</surname><given-names>SG</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The computational cost of active information sampling before decision-making under uncertainty</article-title><source>Nature Human Behaviour</source><volume>5</volume><fpage>935</fpage><lpage>946</lpage><pub-id pub-id-type="doi">10.1038/s41562-021-01116-6</pub-id><pub-id pub-id-type="pmid">34045719</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poe</surname><given-names>GR</given-names></name><name><surname>Foote</surname><given-names>S</given-names></name><name><surname>Eschenko</surname><given-names>O</given-names></name><name><surname>Johansen</surname><given-names>JP</given-names></name><name><surname>Bouret</surname><given-names>S</given-names></name><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Harley</surname><given-names>CW</given-names></name><name><surname>Manahan-Vaughan</surname><given-names>D</given-names></name><name><surname>Weinshenker</surname><given-names>D</given-names></name><name><surname>Valentino</surname><given-names>R</given-names></name><name><surname>Berridge</surname><given-names>C</given-names></name><name><surname>Chandler</surname><given-names>DJ</given-names></name><name><surname>Waterhouse</surname><given-names>B</given-names></name><name><surname>Sara</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Locus coeruleus: A new look at the blue spot</article-title><source>Nature Reviews Neuroscience</source><volume>21</volume><fpage>644</fpage><lpage>659</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0360-9</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polanía</surname><given-names>R</given-names></name><name><surname>Krajbich</surname><given-names>I</given-names></name><name><surname>Grueschow</surname><given-names>M</given-names></name><name><surname>Ruff</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural oscillations and synchronization differentially support evidence accumulation in perceptual and value-based decision making</article-title><source>Neuron</source><volume>82</volume><fpage>709</fpage><lpage>720</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.03.014</pub-id><pub-id pub-id-type="pmid">24811387</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Orienting of attention</article-title><source>The Quarterly Journal of Experimental Psychology</source><volume>32</volume><fpage>3</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1080/00335558008248231</pub-id><pub-id pub-id-type="pmid">7367577</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>The attention system of the human brain</article-title><source>Annual Review of Neuroscience</source><volume>13</volume><fpage>25</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.13.030190.000325</pub-id><pub-id pub-id-type="pmid">2183676</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name><name><surname>Sheese</surname><given-names>BE</given-names></name><name><surname>Odludaş</surname><given-names>Y</given-names></name><name><surname>Tang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Analyzing and shaping human attentional networks</article-title><source>Neural Networks</source><volume>19</volume><fpage>1422</fpage><lpage>1429</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2006.08.004</pub-id><pub-id pub-id-type="pmid">17059879</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cortex is in overall control of “voluntary” eye movement</article-title><source>Eye</source><volume>29</volume><fpage>241</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1038/eye.2014.284</pub-id><pub-id pub-id-type="pmid">25475239</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richer</surname><given-names>F</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Pupillary dilations in movement preparation and execution</article-title><source>Psychophysiology</source><volume>22</volume><fpage>204</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1985.tb01587.x</pub-id><pub-id pub-id-type="pmid">3991847</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Riggio</surname><given-names>L</given-names></name><name><surname>Dascola</surname><given-names>I</given-names></name><name><surname>Umiltá</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Reorienting attention across the horizontal and vertical meridians: Evidence in favor of a premotor theory of attention</article-title><source>Neuropsychologia</source><volume>25</volume><fpage>31</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(87)90041-8</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robison</surname><given-names>MK</given-names></name><name><surname>Unsworth</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Pupillometry tracks fluctuations in working memory performance</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>81</volume><fpage>407</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.3758/s13414-018-1618-4</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolfs</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Attention in active vision: A perspective on perceptual continuity across saccades</article-title><source>Perception</source><volume>44</volume><fpage>900</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1177/0301006615594965</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruehl</surname><given-names>RM</given-names></name><name><surname>Ophey</surname><given-names>L</given-names></name><name><surname>Ertl</surname><given-names>M</given-names></name><name><surname>Zu Eulenburg</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The cingulate oculomotor cortex</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>138</volume><fpage>341</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2021.02.017</pub-id><pub-id pub-id-type="pmid">33812229</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schall</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neural basis of deciding, choosing and acting</article-title><source>Nature Reviews. Neuroscience</source><volume>2</volume><fpage>33</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1038/35049054</pub-id><pub-id pub-id-type="pmid">11253357</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlag</surname><given-names>J</given-names></name><name><surname>Schlag-Rey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Evidence for a supplementary eye field</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>179</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.57.1.179</pub-id><pub-id pub-id-type="pmid">3559671</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schütz</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Interindividual differences in preferred directions of perceptual and motor decisions</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>16</elocation-id><pub-id pub-id-type="doi">10.1167/14.12.16</pub-id><pub-id pub-id-type="pmid">25311304</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>LA</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Organization of the locus coeruleus-norepinephrine system</article-title><source>Current Biology</source><volume>25</volume><fpage>R1051</fpage><lpage>R1056</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.09.039</pub-id><pub-id pub-id-type="pmid">26528750</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sedaghat-Nejad</surname><given-names>E</given-names></name><name><surname>Shadmehr</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The cost of correcting for error during sensorimotor adaptation</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2101717118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2101717118</pub-id><pub-id pub-id-type="pmid">34580215</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>R</given-names></name><name><surname>Reppert</surname><given-names>TR</given-names></name><name><surname>Summerside</surname><given-names>EM</given-names></name><name><surname>Yoon</surname><given-names>T</given-names></name><name><surname>Ahmed</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Movement vigor as a reflection of subjective economic utility</article-title><source>Trends in Neurosciences</source><volume>42</volume><fpage>323</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2019.02.003</pub-id><pub-id pub-id-type="pmid">30878152</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>R</given-names></name><name><surname>Ahmed</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2020">2020</year><source>Vigor: Neuroeconomics of Movement Control</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharika</surname><given-names>KM</given-names></name><name><surname>Neggers</surname><given-names>SFW</given-names></name><name><surname>Gutteling</surname><given-names>TP</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name><name><surname>Dijkerman</surname><given-names>HC</given-names></name><name><surname>Murthy</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Proactive control of sequential saccades in the human supplementary eye field</article-title><source>PNAS</source><volume>110</volume><fpage>E1311</fpage><lpage>E1320</lpage><pub-id pub-id-type="doi">10.1073/pnas.1210492110</pub-id><pub-id pub-id-type="pmid">23493559</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The expected value of control: an integrative theory of anterior cingulate cortex function</article-title><source>Neuron</source><volume>79</volume><fpage>217</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.007</pub-id><pub-id pub-id-type="pmid">23889930</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Musslick</surname><given-names>S</given-names></name><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Kool</surname><given-names>W</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Toward a rational and mechanistic account of mental effort</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>99</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031526</pub-id><pub-id pub-id-type="pmid">28375769</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Prater Fahey</surname><given-names>M</given-names></name><name><surname>Grahek</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Decomposing the motivation to exert mental effort</article-title><source>Current Directions in Psychological Science</source><volume>30</volume><fpage>307</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1177/09637214211009510</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegenthaler</surname><given-names>E</given-names></name><name><surname>Costela</surname><given-names>FM</given-names></name><name><surname>McCamy</surname><given-names>MB</given-names></name><name><surname>Di Stasi</surname><given-names>LL</given-names></name><name><surname>Otero-Millan</surname><given-names>J</given-names></name><name><surname>Sonderegger</surname><given-names>A</given-names></name><name><surname>Groner</surname><given-names>R</given-names></name><name><surname>Macknik</surname><given-names>S</given-names></name><name><surname>Martinez-Conde</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Task difficulty in mental arithmetic affects microsaccadic rates and magnitudes</article-title><source>The European Journal of Neuroscience</source><volume>39</volume><fpage>287</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1111/ejn.12395</pub-id><pub-id pub-id-type="pmid">24438491</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silva</surname><given-names>MF</given-names></name><name><surname>Brascamp</surname><given-names>JW</given-names></name><name><surname>Ferreira</surname><given-names>S</given-names></name><name><surname>Castelo-Branco</surname><given-names>M</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Radial asymmetries in population receptive field size and cortical magnification factor in early visual cortex</article-title><source>NeuroImage</source><volume>167</volume><fpage>41</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.11.021</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sirois</surname><given-names>S</given-names></name><name><surname>Brisson</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupillometry</article-title><source>Wiley Interdisciplinary Reviews. Cognitive Science</source><volume>5</volume><fpage>679</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1002/wcs.1323</pub-id><pub-id pub-id-type="pmid">26308873</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>So</surname><given-names>N</given-names></name><name><surname>Stuphorn</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Supplementary eye field encodes confidence in decisions under risk</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>764</fpage><lpage>782</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv025</pub-id><pub-id pub-id-type="pmid">25750256</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Somai</surname><given-names>RS</given-names></name><name><surname>Schut</surname><given-names>MJ</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Evidence for the world as an external memory: A trade-off between internal and external visual memory storage</article-title><source>Cortex</source><volume>122</volume><fpage>108</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2018.12.017</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sparks</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Conceptual issues related to the role of the superior colliculus in the control of gaze</article-title><source>Current Opinion in Neurobiology</source><volume>9</volume><fpage>698</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(99)00039-2</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sparks</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The brainstem control of saccadic eye movements</article-title><source>Nature Reviews. Neuroscience</source><volume>3</volume><fpage>952</fpage><lpage>964</lpage><pub-id pub-id-type="doi">10.1038/nrn986</pub-id><pub-id pub-id-type="pmid">12461552</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spering</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Eye movements as a window into decision-making</article-title><source>Annual Review of Vision Science</source><volume>8</volume><fpage>427</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-100720-125029</pub-id><pub-id pub-id-type="pmid">35676097</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strauch</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>C-A</given-names></name><name><surname>Einhäuser</surname><given-names>W</given-names></name><name><surname>Van der Stigchel</surname><given-names>S</given-names></name><name><surname>Naber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Pupillometry as an integrated readout of distinct attentional networks</article-title><source>Trends in Neurosciences</source><volume>45</volume><fpage>635</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2022.05.003</pub-id><pub-id pub-id-type="pmid">35662511</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sylvestre</surname><given-names>PA</given-names></name><name><surname>Cullen</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Quantitative analysis of abducens neuron discharge dynamics during saccadic and slow eye movements</article-title><source>Journal of Neurophysiology</source><volume>82</volume><fpage>2612</fpage><lpage>2632</lpage><pub-id pub-id-type="doi">10.1152/jn.1999.82.5.2612</pub-id><pub-id pub-id-type="pmid">10561431</pub-id></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szabadi</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Functional neuroanatomy of the central noradrenergic system</article-title><source>Journal of Psychopharmacology</source><volume>27</volume><fpage>659</fpage><lpage>693</lpage><pub-id pub-id-type="doi">10.1177/0269881113490326</pub-id><pub-id pub-id-type="pmid">23761387</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takagi</surname><given-names>M</given-names></name><name><surname>Zee</surname><given-names>DS</given-names></name><name><surname>Tamargo</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Effects of lesions of the oculomotor vermis on eye movements in primate: saccades</article-title><source>Journal of Neurophysiology</source><volume>80</volume><fpage>1911</fpage><lpage>1931</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.80.4.1911</pub-id><pub-id pub-id-type="pmid">9772249</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>M</given-names></name><name><surname>Kunimatsu</surname><given-names>J</given-names></name><name><surname>Suzuki</surname><given-names>TW</given-names></name><name><surname>Kameda</surname><given-names>M</given-names></name><name><surname>Ohmae</surname><given-names>S</given-names></name><name><surname>Uematsu</surname><given-names>A</given-names></name><name><surname>Takeya</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Roles of the cerebellum in motor preparation and prediction of timing</article-title><source>Neuroscience</source><volume>462</volume><fpage>220</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2020.04.039</pub-id><pub-id pub-id-type="pmid">32360700</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tatler</surname><given-names>BW</given-names></name><name><surname>Vincent</surname><given-names>BT</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The prominence of behavioural biases in eye guidance</article-title><source>Visual Cognition</source><volume>17</volume><fpage>1029</fpage><lpage>1054</lpage><pub-id pub-id-type="doi">10.1080/13506280902764539</pub-id></element-citation></ref><ref id="bib153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tatler</surname><given-names>BW</given-names></name><name><surname>Brockmole</surname><given-names>JR</given-names></name><name><surname>Carpenter</surname><given-names>RHS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>LATEST: A model of saccadic decisions in space and time</article-title><source>Psychological Review</source><volume>124</volume><fpage>267</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1037/rev0000054</pub-id><pub-id pub-id-type="pmid">28358564</pub-id></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Stimulus-driven capture and attentional set: selective search for color and visual abrupt onsets</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>20</volume><fpage>799</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1037//0096-1523.20.4.799</pub-id><pub-id pub-id-type="pmid">8083635</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>The Influence of Attention, Learning, and Motivation on VisualSearch</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4614-4794-8</pub-id></element-citation></ref><ref id="bib156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name><name><surname>Bogaerts</surname><given-names>L</given-names></name><name><surname>van Moorselaar</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>What to expect where and when: how statistical learning drives visual selection</article-title><source>Trends in Cognitive Sciences</source><volume>26</volume><fpage>860</fpage><lpage>872</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2022.06.001</pub-id></element-citation></ref><ref id="bib157"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>T</given-names></name><name><surname>Hoppe</surname><given-names>D</given-names></name><name><surname>Rothkopf</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The Neuroeconomics of Individual Differences in Saccadic Decisions</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.06.03.494508</pub-id></element-citation></ref><ref id="bib158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkačik</surname><given-names>G</given-names></name><name><surname>Garrigan</surname><given-names>P</given-names></name><name><surname>Ratliff</surname><given-names>C</given-names></name><name><surname>Milčinski</surname><given-names>G</given-names></name><name><surname>Klein</surname><given-names>JM</given-names></name><name><surname>Seyfarth</surname><given-names>LH</given-names></name><name><surname>Sterling</surname><given-names>P</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Natural images from the birthplace of the human eye</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e20409</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0020409</pub-id><pub-id pub-id-type="pmid">21698187</pub-id></element-citation></ref><ref id="bib159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Optimal feedback control as a theory of motor coordination</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>1226</fpage><lpage>1235</lpage><pub-id pub-id-type="doi">10.1038/nn963</pub-id></element-citation></ref><ref id="bib160"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tsai</surname><given-names>LS</given-names></name></person-group><year iso-8601-date="1932">1932</year><source>The Laws of Minimum Effort and Maximum Satisfaction in Animal Behavior</source><publisher-name>National Research Institute of Psychology</publisher-name></element-citation></ref><ref id="bib161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unsworth</surname><given-names>N</given-names></name><name><surname>Robison</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Individual differences in the allocation of attention to items in working memory: Evidence from pupillometry</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>22</volume><fpage>757</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.3758/s13423-014-0747-6</pub-id></element-citation></ref><ref id="bib162"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unsworth</surname><given-names>N</given-names></name><name><surname>Miller</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Individual differences in the intensity and consistency of attention</article-title><source>Current Directions in Psychological Science</source><volume>30</volume><fpage>391</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1177/09637214211030266</pub-id></element-citation></ref><ref id="bib163"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Stigchel</surname><given-names>S</given-names></name><name><surname>Meeter</surname><given-names>M</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Eye movement trajectories and what they tell us</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>30</volume><fpage>666</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2005.12.001</pub-id></element-citation></ref><ref id="bib164"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Stigchel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Recent advances in the study of saccade trajectory deviations</article-title><source>Vision Research</source><volume>50</volume><fpage>1619</fpage><lpage>1627</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2010.05.028</pub-id></element-citation></ref><ref id="bib165"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Stigchel</surname><given-names>S</given-names></name><name><surname>Nijboer</surname><given-names>TCW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How global is the global effect? The spatial characteristics of saccade averaging</article-title><source>Vision Research</source><volume>84</volume><fpage>6</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2013.03.006</pub-id><pub-id pub-id-type="pmid">23523571</pub-id></element-citation></ref><ref id="bib166"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Stigchel</surname><given-names>S</given-names></name><name><surname>Hollingworth</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Visuospatial working memory as a fundamental component of the eye movement system</article-title><source>Current Directions in Psychological Science</source><volume>27</volume><fpage>136</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1177/0963721417741710</pub-id></element-citation></ref><ref id="bib167"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Stigchel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An embodied account of visual working memory</article-title><source>Visual Cognition</source><volume>28</volume><fpage>414</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.1080/13506285.2020.1742827</pub-id></element-citation></ref><ref id="bib168"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Wel</surname><given-names>P</given-names></name><name><surname>van Steenbergen</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupil dilation as an index of effort in cognitive control tasks: A review</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>25</volume><fpage>2005</fpage><lpage>2015</lpage><pub-id pub-id-type="doi">10.3758/s13423-018-1432-y</pub-id></element-citation></ref><ref id="bib169"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>The visual field representation in striate cortex of the macaque monkey: Asymmetries, anisotropies, and individual variability</article-title><source>Vision Research</source><volume>24</volume><fpage>429</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(84)90041-5</pub-id></element-citation></ref><ref id="bib170"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voogd</surname><given-names>J</given-names></name><name><surname>Barmack</surname><given-names>NH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Oculomotor cerebellum</article-title><source>Progress in Brain Research</source><volume>151</volume><fpage>231</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(05)51008-2</pub-id><pub-id pub-id-type="pmid">16221591</pub-id></element-citation></ref><ref id="bib171"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voudouris</surname><given-names>D</given-names></name><name><surname>Schuetz</surname><given-names>I</given-names></name><name><surname>Schinke</surname><given-names>T</given-names></name><name><surname>Fiehler</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Pupil dilation scales with movement distance of real but not of imagined reaching movements</article-title><source>Journal of Neurophysiology</source><volume>130</volume><fpage>104</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1152/jn.00024.2023</pub-id><pub-id pub-id-type="pmid">37283453</pub-id></element-citation></ref><ref id="bib172"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wainstein</surname><given-names>G</given-names></name><name><surname>Müller</surname><given-names>EJ</given-names></name><name><surname>Taylor</surname><given-names>N</given-names></name><name><surname>Munn</surname><given-names>B</given-names></name><name><surname>Shine</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The role of the locus coeruleus in shaping adaptive cortical melodies</article-title><source>Trends in Cognitive Sciences</source><volume>26</volume><fpage>527</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2022.03.006</pub-id></element-citation></ref><ref id="bib173"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallis</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Orbitofrontal cortex and its contribution to decision-making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>31</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.30.051606.094334</pub-id><pub-id pub-id-type="pmid">17417936</pub-id></element-citation></ref><ref id="bib174"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walter</surname><given-names>K</given-names></name><name><surname>Bex</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cognitive load influences oculomotor behavior in natural scenes</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>12405</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-91845-5</pub-id><pub-id pub-id-type="pmid">34117336</pub-id></element-citation></ref><ref id="bib175"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C-A</given-names></name><name><surname>Blohm</surname><given-names>G</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Boehnke</surname><given-names>SE</given-names></name><name><surname>Munoz</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Multisensory integration in orienting behavior: Pupil size, microsaccades, and saccades</article-title><source>Biological Psychology</source><volume>129</volume><fpage>36</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2017.07.024</pub-id><pub-id pub-id-type="pmid">28789960</pub-id></element-citation></ref><ref id="bib176"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>McAlonan</surname><given-names>K</given-names></name><name><surname>Goldstein</surname><given-names>S</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A causal role for mouse superior colliculus in visual perceptual decision-making</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>3768</fpage><lpage>3782</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2642-19.2020</pub-id><pub-id pub-id-type="pmid">32253361</pub-id></element-citation></ref><ref id="bib177"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C-A</given-names></name><name><surname>Munoz</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Differentiating global luminance, arousal and cognitive signals on pupil size and microsaccades</article-title><source>The European Journal of Neuroscience</source><volume>54</volume><fpage>7560</fpage><lpage>7574</lpage><pub-id pub-id-type="doi">10.1111/ejn.15508</pub-id><pub-id pub-id-type="pmid">34716728</pub-id></element-citation></ref><ref id="bib178"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C-A</given-names></name><name><surname>Nguyen</surname><given-names>KT</given-names></name><name><surname>Juan</surname><given-names>C-H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Linking pupil size modulated by global luminance and motor preparation to saccade behavior</article-title><source>Neuroscience</source><volume>476</volume><fpage>90</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2021.09.014</pub-id></element-citation></ref><ref id="bib179"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westbrook</surname><given-names>A</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cognitive effort: A neuroeconomic approach</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>15</volume><fpage>395</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.3758/s13415-015-0334-y</pub-id><pub-id pub-id-type="pmid">25673005</pub-id></element-citation></ref><ref id="bib180"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wexler</surname><given-names>M</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name><name><surname>Schütz</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Structure of visual biases revealed by individual differences</article-title><source>Vision Research</source><volume>195</volume><elocation-id>108014</elocation-id><pub-id pub-id-type="doi">10.1016/j.visres.2022.108014</pub-id><pub-id pub-id-type="pmid">35228090</pub-id></element-citation></ref><ref id="bib181"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiehler</surname><given-names>A</given-names></name><name><surname>Branzoli</surname><given-names>F</given-names></name><name><surname>Adanyeguh</surname><given-names>I</given-names></name><name><surname>Mochel</surname><given-names>F</given-names></name><name><surname>Pessiglione</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A neuro-metabolic account of why daylong cognitive work alters the control of economic decisions</article-title><source>Current Biology</source><volume>32</volume><fpage>3564</fpage><lpage>3575</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.07.010</pub-id><pub-id pub-id-type="pmid">35961314</pub-id></element-citation></ref><ref id="bib182"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wurtz</surname><given-names>RH</given-names></name><name><surname>Albano</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Visual-motor function of the primate superior colliculus</article-title><source>Annual Review of Neuroscience</source><volume>3</volume><fpage>189</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.03.030180.001201</pub-id><pub-id pub-id-type="pmid">6774653</pub-id></element-citation></ref><ref id="bib183"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>S-N</given-names></name><name><surname>Heinen</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Contrasting the roles of the supplementary and frontal eye fields in ocular decision making</article-title><source>Journal of Neurophysiology</source><volume>111</volume><fpage>2644</fpage><lpage>2655</lpage><pub-id pub-id-type="doi">10.1152/jn.00543.2013</pub-id><pub-id pub-id-type="pmid">24671543</pub-id></element-citation></ref><ref id="bib184"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Kan</surname><given-names>JYY</given-names></name><name><surname>Yang</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Tu</surname><given-names>J</given-names></name><name><surname>Dorris</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Transforming absolute value to categorical choice in primate superior colliculus during value-based decision making</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>3410</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-23747-z</pub-id><pub-id pub-id-type="pmid">34099726</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Saccade-locked pupil traces as index of saccade costs in different directions.</title><p>Using the average pupil size in the 350 ms before saccade onset (saccade-locked), results remained qualitatively identical. Planning oblique saccades was associated with a larger pupil size than cardinal ones (β = 9.897, SE  = 2.223, <italic>t</italic> = 4.451, p &lt; 0.001), and downward saccades were associated with a larger pupil size than upward saccades (β = 0.471, SE  = 0.112, <italic>t</italic> = 4.189, p &lt; 0.001). A slightly increased pupil size for leftward compared with rightward saccades was observed as well (β = 0.260, SE  = 0.107, <italic>t</italic> = 2.436, p = 0.015).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97760-app1-fig1-v1.tif"/></fig><sec sec-type="appendix" id="s8"><title>Supporting analysis</title><p>To ascertain whether pupil size or other oculomotor metrics predict saccade preferences, we conducted a multiple regression analysis. We calculated average pupil size, saccade latency, landing precision, and peak velocity maps across all 36 directions. The model, determined using AIC-based backward selection, included pupil size, latency, and landing precision as predictors (Wilkinson notation: saccade preferences ∼ pupil size+ saccade latency+ landing precision). The analysis revealed that pupil size (β = –42.853, <italic>t</italic> = 4.791, p &lt; 0.001) and saccade latency (β = –0.377, <italic>t</italic> = 2.106, p = 0.043) predicted saccade preferences. Landing precision did not reach significance (β = 23.631, <italic>t</italic> = 1.675, p = 0.104). Together, this demonstrates that although other oculomotor metrics such as saccade latency contribute to saccade selection, pupil size remains a robust marker of saccade selection.</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Full outcomes of the linear mixed-effects model analyzing pupil size assessed saccade costs across directions.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom">β</th><th align="left" valign="bottom"><italic>SE</italic></th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom"><italic>p</italic></th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">–26.510</td><td align="char" char="." valign="bottom">9.059</td><td align="char" char="." valign="bottom">–2.926</td><td align="char" char="." valign="bottom">0.003</td></tr><tr><td align="left" valign="bottom">Obliqueness</td><td align="char" char="." valign="bottom">7.662</td><td align="char" char="." valign="bottom">1.957</td><td align="char" char="." valign="bottom">3.916</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Verticalness</td><td align="char" char="." valign="bottom">–0.556</td><td align="char" char="." valign="bottom">0.171</td><td align="char" char="." valign="bottom">–3.261</td><td align="char" char="." valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom">Horizontalness</td><td align="char" char="." valign="bottom">–0.226</td><td align="char" char="." valign="bottom">0.095</td><td align="char" char="." valign="bottom">–2.388</td><td align="char" char="." valign="bottom">0.017</td></tr><tr><td align="left" valign="bottom">Obliqueness × Duration</td><td align="char" char="." valign="bottom">–0.109</td><td align="char" char="." valign="bottom">0.031</td><td align="char" char="." valign="bottom">–3.495</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Duration</td><td align="char" char="." valign="bottom">0.169</td><td align="char" char="." valign="bottom">0.085</td><td align="char" char="." valign="bottom">1.981</td><td align="char" char="." valign="bottom">0.048</td></tr><tr><td align="left" valign="bottom">Amplitude</td><td align="char" char="." valign="bottom">–2.423</td><td align="char" char="." valign="bottom">0.656</td><td align="char" char="." valign="bottom">–3.691</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Landing error</td><td align="char" char="." valign="bottom">7.344</td><td align="char" char="." valign="bottom">2.168</td><td align="char" char="." valign="bottom">3.387</td><td align="char" char="." valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom">Peak velocity</td><td align="char" char="." valign="bottom">0.054</td><td align="char" char="." valign="bottom">0.015</td><td align="char" char="." valign="bottom">3.692</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Participant Var</td><td align="char" char="." valign="bottom">602.851</td><td align="char" char="." valign="bottom">2.786</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Participant × Obliqueness Cov</td><td align="char" char="." valign="bottom">–55.890</td><td align="char" char="." valign="bottom">0.395</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Participant × Verticalness Cov</td><td align="char" char="." valign="bottom">–1.625</td><td align="char" char="." valign="bottom">0.058</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Obliqueness × Verticalness Cov</td><td align="char" char="." valign="bottom">0.934</td><td align="char" char="." valign="bottom">0.011</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Obliqueness Var</td><td align="char" char="." valign="bottom">13.790</td><td align="char" char="." valign="bottom">0.083</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Verticalness Var</td><td align="char" char="." valign="bottom">0.380</td><td align="char" char="." valign="bottom">0.003</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>Full outcomes of the linear mixed-effects model predicting pupil size using saccade preferences and control variables in Experiment 1.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom">β</th><th align="left" valign="bottom"><italic>SE</italic></th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom"><italic>p</italic></th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.825</td><td align="char" char="." valign="bottom">0.061</td><td align="char" char="." valign="bottom">13.504</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Direction preferences</td><td align="char" char="." valign="bottom">–1.784</td><td align="char" char="." valign="bottom">0.324</td><td align="char" char="." valign="bottom">–5.412</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">X coordinate</td><td align="char" char="." valign="bottom">–0.0002</td><td align="char" char="." valign="bottom">0.00001</td><td align="char" char="." valign="bottom">–21.12</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Y coordinate</td><td align="char" char="." valign="bottom">–0.0002</td><td align="char" char="." valign="bottom">0.00001</td><td align="char" char="." valign="bottom">–11.316</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Luminance</td><td align="char" char="." valign="bottom">–0.635</td><td align="char" char="." valign="bottom">0.017</td><td align="char" char="." valign="bottom">–36.251</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Saliency</td><td align="char" char="." valign="bottom">–0.001</td><td align="char" char="." valign="bottom">0.0001</td><td align="char" char="." valign="bottom">–10.536</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Trial number</td><td align="char" char="." valign="bottom">–0.006</td><td align="char" char="." valign="bottom">0.00006</td><td align="char" char="." valign="bottom">–91.139</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Fixation number (in trial)</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">0.0002</td><td align="char" char="." valign="bottom">55.513</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Saccade duration</td><td align="char" char="." valign="bottom">–0.004</td><td align="char" char="." valign="bottom">0.0009</td><td align="char" char="." valign="bottom">–42.150</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Fixation duration</td><td align="char" char="." valign="bottom">0.0003</td><td align="char" char="." valign="bottom">0.00004</td><td align="char" char="." valign="bottom">7.105</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Amplitude</td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">0.0007</td><td align="char" char="." valign="bottom">13.979</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Participant Var</td><td align="char" char="." valign="bottom">0.053</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Direction preferences Var</td><td align="char" char="." valign="bottom">0.833</td><td align="char" char="." valign="bottom">0.646</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Participant × Direction preferences Cov</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">0.250</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><table-wrap id="app1table3" position="float"><label>Appendix 1—table 3.</label><caption><title>Full outcomes of the linear mixed-effects model predicting pupil size using saccade preferences and control variables in Experiment 2.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom">β</th><th align="left" valign="bottom"><italic>SE</italic></th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom"><italic>p</italic></th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">1.093</td><td align="char" char="." valign="bottom">0.060</td><td align="char" char="." valign="bottom">18.301</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Direction preferences</td><td align="char" char="." valign="bottom">–0.644</td><td align="char" char="." valign="bottom">0.170</td><td align="char" char="." valign="bottom">–3.780</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">X coordinate</td><td align="char" char="." valign="bottom">–0.0001</td><td align="char" char="." valign="bottom">0.000005</td><td align="char" char="." valign="bottom">–24.442</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Y coordinate</td><td align="char" char="." valign="bottom">–0.00004</td><td align="char" char="." valign="bottom">0.000007</td><td align="char" char="." valign="bottom">–5.072</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Luminance</td><td align="char" char="." valign="bottom">–0.341</td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">–38.269</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Saliency</td><td align="char" char="." valign="bottom">–0.001</td><td align="char" char="." valign="bottom">0.00006</td><td align="char" char="." valign="bottom">–10.405</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Trial number</td><td align="char" char="." valign="bottom">–0.007</td><td align="char" char="." valign="bottom">0.00006</td><td align="char" char="." valign="bottom">–126.687</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Fixation number (in trial)</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">0.00009</td><td align="char" char="." valign="bottom">64.174</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Saccade duration</td><td align="char" char="." valign="bottom">–0.007</td><td align="char" char="." valign="bottom">0.00005</td><td align="char" char="." valign="bottom">–152.775</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Fixation duration</td><td align="char" char="." valign="bottom">0.000005</td><td align="char" char="." valign="bottom">0.00002</td><td align="char" char="." valign="bottom">0.732</td><td align="char" char="." valign="bottom">0.464</td></tr><tr><td align="left" valign="bottom">Amplitude</td><td align="char" char="." valign="bottom">0.013</td><td align="char" char="." valign="bottom">0.0003</td><td align="char" char="." valign="bottom">37.737</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Participant Var</td><td align="char" char="." valign="bottom">0.086</td><td align="char" char="." valign="bottom">0.041</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Direction preferences Var</td><td align="char" char="." valign="bottom">0.322</td><td align="char" char="." valign="bottom">0.339</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Participant × Direction preferences Cov</td><td align="char" char="." valign="bottom">0.034</td><td align="char" char="." valign="bottom">0.086</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><table-wrap id="app1table4" position="float"><label>Appendix 1—table 4.</label><caption><title>Full outcomes of the linear mixed-effects model predicting pupil size using saccade direction adjustment and control variables.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom">β</th><th align="left" valign="bottom"><italic>SE</italic></th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom"><italic>p</italic></th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">1.070</td><td align="char" char="." valign="bottom">0.060</td><td align="char" char="." valign="bottom">17.880</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Direction adjustment</td><td align="char" char="." valign="bottom">–9.333</td><td align="char" char="." valign="bottom">0.966</td><td align="char" char="." valign="bottom">–9.659</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">X coordinate</td><td align="char" char="." valign="bottom">–0.0001</td><td align="char" char="." valign="bottom">0.000005</td><td align="char" char="." valign="bottom">–23.388</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Y coordinate</td><td align="char" char="." valign="bottom">–0.00004</td><td align="char" char="." valign="bottom">0.000007</td><td align="char" char="." valign="bottom">–5.261</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Luminance</td><td align="char" char="." valign="bottom">–0.340</td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">–38.269</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Saliency</td><td align="char" char="." valign="bottom">–0.001</td><td align="char" char="." valign="bottom">0.00006</td><td align="char" char="." valign="bottom">–10.109</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Trial number</td><td align="char" char="." valign="bottom">–0.007</td><td align="char" char="." valign="bottom">0.00006</td><td align="char" char="." valign="bottom">–126.380</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Fixation number (in trial)</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">0.00009</td><td align="char" char="." valign="bottom">62.648</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Saccade duration</td><td align="char" char="." valign="bottom">–0.007</td><td align="char" char="." valign="bottom">0.00005</td><td align="char" char="." valign="bottom">–153.597</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Fixation duration</td><td align="char" char="." valign="bottom">0.00002</td><td align="char" char="." valign="bottom">0.00002</td><td align="char" char="." valign="bottom">1.537</td><td align="char" char="." valign="bottom">0.124</td></tr><tr><td align="left" valign="bottom">Amplitude</td><td align="char" char="." valign="bottom">0.012</td><td align="char" char="." valign="bottom">0.0003</td><td align="char" char="." valign="bottom">37.127</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Participant Var</td><td align="char" char="." valign="bottom">0.087</td><td align="char" char="." valign="bottom">0.041</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Direction adjustment Var</td><td align="char" char="." valign="bottom">16.878</td><td align="char" char="." valign="bottom">11.338</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Participant × Direction adjustment Cov</td><td align="char" char="." valign="bottom">0.142</td><td align="char" char="." valign="bottom">0.499</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table></table-wrap></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97760.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Stanford University, Howard Hughes Medical Institute</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This study provides <bold>important</bold> findings on the nature of eye movement choices by human subjects. The study uses a novel approach and provides relatively clear and <bold>convincing</bold> results of the relationship between pupil size and saccade production. The results should be of interest to a broad audience interested in sensorimotor integration and sensory-guided decision-making.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97760.3.sa1</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This manuscript extends previous research by this group by relating variation in pupil size to the endpoints of saccades produced by human participants under various conditions including trial-based choices between pairs of spots and search for small items in natural scenes. Based on the premise that pupil size is a reliable proxy of &quot;effort&quot;, the authors conclude that less costly saccade targets are preferred. Finding that this preference was influenced by the performance of a non-visual, attention-demanding task, the authors conclude that a common source of effort animates gaze behavior and other cognitive tasks.</p><p>Strengths:</p><p>Strengths of the manuscript include the novelty of the approach, the clarity of the findings, and the community interest in the problem.</p><p>Weaknesses:</p><p>Enthusiasm for this manuscript is reduced by the following weaknesses:</p><p>(1) A relationship between pupil size and saccade production seems clear based on the authors' previous and current work. What is at issue is the interpretation. The authors test one, preferred hypothesis, and the narrative of the manuscript treats the hypothesis that pupil size is a proxy of effort as beyond dispute or question. The stated elements of their argument seem to go like this:</p><p>PROPOSITION 1: Pupil size varies systematically across task conditions, being larger when tasks are more demanding.</p><p>PROPOSITION 2: Pupil size is related to the locus coeruleus.</p><p>PROPOSITION 3: The locus coeruleus NE system modulates neural activity and interactions.</p><p>CONCLUSION: Therefore, pupil size indexes the resource demand or &quot;effort&quot; associated with task conditions.</p><p>How the conclusion follows from the propositions is not self-evident. Proposition 3, in particular, fails to establish the link that is supposed to lead to the conclusion.</p><p>(2) The authors test one, preferred hypothesis and do not consider plausible alternatives. Is &quot;cost&quot; the only conceivable hypothesis? The hypothesis is framed in very narrow terms. For example, the cholinergic and dopamine systems that have been featured in other researchers' consideration of pupil size modulation are missing here. Thus, because the authors do not rule out plausible alternative hypotheses, the logical structure of this manuscript can be criticized as committing the fallacy of affirming the consequent.</p><p>(3) The authors cite particular publications in support of the claim that saccade selection is influenced by an assessment of effort. Given the extensive work by others on this general topic, the skeptic could regard the theoretical perspective of this manuscript as too impoverished. Their work may be enhanced by consideration of other work on this general topic, e.g, (i) Shenhav A, Botvinick MM, Cohen JD. (2013) The expected value of control: an integrative theory of anterior cingulate cortex function. Neuron. 2013 Jul 24;79(2):217-40. (ii) Müller T, Husain M, Apps MAJ. (2022) Preferences for seeking effort or reward information bias the willingness to work. Sci Rep. 2022 Nov 14;12(1):19486. (iii) Bustamante LA, Oshinowo T, Lee JR, Tong E, Burton AR, Shenhav A, Cohen JD, Daw ND. (2023) Effort Foraging Task reveals a positive correlation between individual differences in the cost of cognitive and physical effort in humans. Proc Natl Acad Sci U S A. 2023 Dec 12;120(50):e2221510120.</p><p>(4) What is the source of cost in saccade production? What is the currency of that cost? The authors state (page 13), &quot;... oblique saccades require more complex oculomotor programs than horizontal eye movements because more neuronal populations in the superior colliculus (SC) and frontal eye fields (FEF) [76-79], and more muscles are necessary to plan and execute the saccade [76, 80, 81].&quot; This statement raises questions and concerns. First, the basis of the claim that more neurons in FEF and SC are needed for oblique versus cardinal saccades is not established in any of the publications cited. Second, the authors may be referring to the fact that oblique saccades require coordination between pontine and midbrain circuits. This must be clarified. Second, the cost is unlikely to originate in extraocular muscle fatigue because the muscle fibers are so different from skeletal muscles, being fundamentally less fatigable. Third, if net muscle contraction is the cost, then why are upward saccades, which require the eyelid, not more expensive than downward? Thus, just how some saccades are more effortful than others is not clear.</p><p>(5) The authors do not consider observations about variation in pupil size that seem to be incompatible with the preferred hypothesis. For example, at least two studies have described systematically larger pupil dilation associated with faster relative to accurate performance in manual and saccade tasks (e.g., Naber M, Murphy P. Pupillometric investigation into the speed-accuracy trade-off in a visuo-motor aiming task. Psychophysiology. 2020 Mar;57(3):e13499; Reppert TR, Heitz RP, Schall JD. Neural mechanisms for executive control of speed-accuracy trade-off. Cell Rep. 2023 Nov 28;42(11):113422). Is the fast relative to the accurate option necessarily more costly?</p><p>(6) The authors draw conclusions based on trends across participants, but they should be more transparent about variation that contradicts these trends. In Figures 3 and 4 we see many participants producing behavior unlike most others. Who are they? Why do they look so different? Is it just noise, or do different participants adopt different policies?</p><p>Comments on revisions:</p><p>The authors have addressed the concerns and questions raised in the original review.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97760.3.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Koevoet</surname><given-names>Damian</given-names></name><role specific-use="author">Author</role><aff><institution>Utrecht University</institution><addr-line><named-content content-type="city">Utrecht</named-content></addr-line><country>Netherlands</country></aff></contrib><contrib contrib-type="author"><name><surname>Van Zantwijk</surname><given-names>Laura</given-names></name><role specific-use="author">Author</role><aff><institution>Utrecht University</institution><addr-line><named-content content-type="city">Utrecht</named-content></addr-line><country>Netherlands</country></aff></contrib><contrib contrib-type="author"><name><surname>Naber</surname><given-names>Marnix</given-names></name><role specific-use="author">Author</role><aff><institution>Utrecht University</institution><addr-line><named-content content-type="city">Utrecht</named-content></addr-line><country>Netherlands</country></aff></contrib><contrib contrib-type="author"><name><surname>Mathot</surname><given-names>Sebastian</given-names></name><role specific-use="author">Author</role><aff><institution>University of Groningen</institution><addr-line><named-content content-type="city">Groningen</named-content></addr-line><country>Netherlands</country></aff></contrib><contrib contrib-type="author"><name><surname>van der Stigchel</surname><given-names>Stefan</given-names></name><role specific-use="author">Author</role><aff><institution>Utrecht University</institution><addr-line><named-content content-type="city">Utrecht</named-content></addr-line><country>Nepal</country></aff></contrib><contrib contrib-type="author"><name><surname>Strauch</surname><given-names>Christoph</given-names></name><role specific-use="author">Author</role><aff><institution>Utrecht University</institution><addr-line><named-content content-type="city">Utrecht</named-content></addr-line><country>Netherlands</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Vision is a highly active process. Humans move their eyes 3-4 times per second to sample information with high visual acuity from our environment, and where eye movements are directed is critical to our understanding of active vision. Here, the authors propose that the cost of making a saccade contributes critically to saccade selection (i.e., whether and where to move the eyes). The authors build on their own recent work that the effort (as measured by pupil size) that comes with planning and generating an eye movement varies with saccade direction. To do this, the authors first measured pupil size for different saccade directions for each participant. They then correlated the variations in pupil size obtained in the mapping task with the saccade decision in a free-choice task. The authors observed a striking correlation: pupil size in the mapping task predicted the decision of where to move the eyes in the free choice task. In this study, the authors provide a number of additional insightful analyses (e.g., based on saccade curvature, and saccade latency) and experiments that further support their claim that the decision to move the eyes is influenced by the effort to move the eyes in a particular direction. One experiment showed that the same influence of assumed saccade costs on saccade selection is observed during visual search in natural scenes. Moreover, increasing the cognitive load by adding an auditory counting task reduced the number of saccades, and in particular reduced the costly saccades. In sum, these experiments form a nice package that convincingly establishes the association between pupil size and saccade selection.</p></disp-quote><p>We thank the reviewer for highlighting the novelty and cogency of our findings.</p><disp-quote content-type="editor-comment"><p>In my opinion, the causal structure underlying the observed results is not so clear. While the relationship between pupil size and saccade selection is compelling, it is not clear that saccade-related effort (i.e., the cost of a saccade) really drives saccade selection. Given the correlational nature of this relationship, there are other alternatives that could explain the finding. For example, saccade latency and the variance in landing positions also vary across saccade directions. This can be interpreted for instance that there are variations in oculomotor noise across saccade directions, and maybe the oculomotor system seeks to minimize that noise in a free-choice task. In fact, given such a correlational result, many other alternative mechanisms are possible. While I think the authors' approach of systematically exploring what we can learn about saccade selection using pupil size is interesting, it would be important to know what exactly pupil size can add that was not previously known by simply analyzing saccade latency. For example, saccade latency anisotropies across saccade directions are well known, and the authors also show here that saccade costs are related to saccade latency. An important question would be to compare how pupil size and saccade latency uniquely contribute to saccade selection. That is, the authors could apply the exact same logic to their analysis by first determining how saccade latencies (or variations in saccade landing positions; see Greenwood et al., 2017 PNAS) vary across saccade directions and how this saccade latency map explains saccade selection in subsequent tasks. Is it more advantageous to use one or the other saccade metric, and how well does a saccade latency map correlate with a pupil size map?</p></disp-quote><p>We thank the reviewer for the detailed comment. (1) The reviewer first points out the correlational nature of many of our results. Thereafter, (2), the reviewer asks whether saccade latencies and landing precision also predict saccade selection, and could be these potential predictors be considered alternative explanations to the idea of effort driving saccade selection? Moreover, what can pupil size add to what can be learned from saccade latency?</p><p>In brief, although we report a combination of correlational and causal findings, we do not know of a more parsimonious explanation for our findings than “effort drives saccade selection”. Moreover, we demonstrate that oculomotor noise cannot be construed as an alternative explanation for our findings.</p><p>(1) Correlational nature of many findings.</p><p>We acknowledge that many of our findings are predominantly correlational in nature. In our first tasks, we correlated pupil size during saccade planning to saccade preferences in a subsequent task. Although the link between across tasks was correlational, the observed relationship clearly followed our previously specified directed hypothesis. Moreover, experiments 1 and 2 of the visual search data replicated and extended this relationship. We also directly manipulated cognitive demand in the second visual search experiment. In line with the hypothesis that effort affects saccade selection, participants executed less saccades overall when performing a (primary) auditory dual task, and even cut the costly saccades most – which actually constitutes causal evidence for our hypothesis. A minimal oculomotor noise account would not directly predict a reduction in saccade rate under higher cognitive demand. To summarize, we have a combination of correlational and causal findings, although mediators cannot be ruled out fully for the latter. That said, we do not know of a more fitting and parsimonious explanation for our findings than effort predicting saccade selection (see following points for saccade latencies). We now address causality in the discussion for transparency and point more explicitly to the second visual search experiment for causal evidence.</p><p>“We report a combination of correlational and causal findings. Despite the correlational nature of some of our results, they consistently support the hypothesis that saccade costs predicts saccade selection [which we predicted previously, 33]. Causal evidence was provided by the dual-task experiment as saccade frequencies - and especially costly saccades were reduced under additional cognitive demand. Only a cost account predicts (1) a link between pupil size and saccade preferences, (2) a cardinal saccade bias, (3) reduced saccade frequency under additional cognitive demand, and (4) disproportional cutting of especially those directions associated with more pupil dilation. Together, our findings converge upon the conclusion that effort drives saccade selection.”</p><p>(2) Do anisotropies in saccade latencies constitute an alternative explanation?</p><p>First of all, we would like to to first stress that differences in saccade latencies are indeed thought to reflect oculomotor effort (Shadmehr et al., 2019; TINS). For example, saccades with larger amplitudes and saccades where distractors need to be ignored are associated with longer latencies. Therefore, even if saccade latencies would predict saccade selection, this would not contrast the idea that effort drives saccade selection. Instead, this would provide convergent evidence for our main novel conclusion: effort drives saccade selection. There are several reasons why pupil size can be used as a more general marker of effort (see responses to R2), but ultimately, our conclusions do not hinge on the employed measure of effort per se. As stressed above in (1), we see no equally parsimonious explanation besides the cost account. Moreover, we predicted this relationship in our previous publication before running the currently reported experiments and analyses (Koevoet et al., 2023). That said, we are open to discuss further alternative options and would be looking forward to test these accounts in future work against each other – we are welcoming the reviewers’ (but also the reader’s) suggestions.</p><p>We now discuss this in the manuscript as follows:</p><p>“We here measured cost as the degree of effort-linked pupil dilation. In addition to pupil size, other markers may also indicate saccade costs. For example, saccade latency has been proposed to index oculomotor effort [100], whereby saccades with longer latencies are associated with more oculomotor effort. This makes saccade latency a possible complementary marker of saccade costs (also see Supplemen- tary Materials). Although relatively sluggish, pupil size is a valuable measure of attentional costs for (at least) two reasons. First, pupil size is a highly established as marker of effort, and is sensitive to effort more broadly than only in the context of saccades [36–45, 48]. Pupil size therefore allows to capture not only the costs of saccades, but also of covert attentional shifts [33], or shifts with other effectors such as head or arm movements [54, 101]. Second, as we have demonstrated, pupil size can measure saccade costs even when searching in natural scenes (Figure 4). During natural viewing, it is difficult to disentangle fixation duration from saccade latencies, complicating the use of saccade latency as a measure of saccade cost.</p><p>Together, pupil size, saccade latency, and potential other markers of saccade cost could fulfill complementary roles in studying the role of cost in saccade selection.”</p><p>Second, we followed the reviewer’s recommendation in testing whether other oculomotor metrics would predict saccade selection. To this end, we conducted a linear regression across directions. We calculated pupil size, saccade latencies, landing precision and peak velocities maps from the saccade planning task. We then used AICbased backward model selection to determine the ‘best’ model model to determine which factor would predict saccade selection best. The best model included pupil size, latency and landing precision as predictors (Wilkinson notation: saccade preferences ~ pupil size + saccade latency + landing precision). Pupil size (b = -42.853, <italic>t</italic> = 4.791, <italic>p</italic> &lt; .001) and saccade latency (b = -.377, <italic>t</italic> = 2.106, <italic>p</italic> = .043; see Author response image 1) predicted saccade preferences significantly. In contrast, landing precision did not reach significance (b = 23.631, <italic>t</italic> = 1.675, <italic>p</italic> = .104). This analysis shows that although saccade latency also predicts saccade preferences, pupil size remains a robust predictor of saccade selection. These findings demonstrate that minimizing oculomotor noise cannot fully explain the pattern of results.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>The relationship between saccade latency (from the saccade planning task) and saccade preferences averaged across participants.</title><p>Individual points reflect directions and shading represents bootstrapped 95% confidence intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97760-sa2-fig1-v1.tif"/></fig><p>We have added this argument into the manuscript, and discuss the analysis in the discussion. Details of the analysis have been added to the Supporting Information for transparency and further detail.</p><p>“A control analysis ruled out that the correlation between pupil size and saccade preferences was driven by other oculomotor metrics such as saccade latency and landing precision (see Supporting Information).”</p><p>“To ascertain whether pupil size or other oculomotor metrics predict saccade preferences, we conducted a multiple regression analysis. We calculated average pupil size, saccade latency, landing precision and peak velocity maps across all 36 directions. The model, determined using AIC-based backward selection, included pupil size, latency and landing precision as predictors (Wilkinson notation: saccade preferences pupil size + saccade latency + landing precision). The analysis re- vealed that pupil size (β = -42.853, t = 4.791, p &lt; .001) and saccade latency (β = -.377, t = 2.106, p = .043) predicted saccade preferences. Landing precision did not reach significance (β = 23.631, t = 1.675, p = .104). Together, this demonstrates that although other oculomotor metrics such as saccade latency contribute to saccade selection, pupil size remains a robust marker of saccade selection.”</p><disp-quote content-type="editor-comment"><p>In addition to eye-movement-related anisotropies across the visual field, there are of course many studies reporting visual field anisotropies (see Himmelberg, Winawer &amp; Carrasco, 2023, Trends in Neuroscience for a review). It would be interesting to understand how the authors think about visual field anisotropies in the context of their own study. Do they think that their results are (in)dependent on such visual field variations (see Greenwood et al., 2017, PNAS; Ohl, Kroell, &amp; Rolfs, 2024, JEP:Gen for a similar discussion)?</p></disp-quote><p>We agree that established visual field anisotropies are fascinating to be discussed in context of our own results. At the reviewer’s suggestion, we now expanded this discussion.</p><p>The observed anisotropies in terms of saccade costs are likely related to established anisotropies in perception and early visual cortex. However, the exact way that these anisotropies may be linked remains elusive (i.e. what is cause, what is effect, are links causal?), and more research is necessary to understand how these are related.</p><p>“The observed differences in saccade costs across directions could be linked to established anisotropies in perception [80–86], attention [87–92], saccade charac- teristics [87, 88, 92, 93], and (early) visual cortex [94–98] [also see 99]. For example, downward saccades are more costly than upward saccades, which mimics a similar asymmetry in early visual areas wherein the upper visual field is relatively under- represented [94–98]; similarly stronger presaccadic benefits are found for down- compared with upward saccades [87, 88]. Moreover, upward saccades are more pre- cise than downward saccades [93]. Future work should elucidate where saccade cost or the aforementioned anisotropies originate from and how they are related - something that pupil size alone cannot address.”</p><p>We also added that the finding that more precise saccades are coupled with worse performance in a crowding task might be attributed to the increased effort associated with more precise saccades (Greenwood et al., 2017).</p><p>“Adaptive resource allocation from, and to the oculomotor system parsimoniously explains a number of empirical observations. For example, higher cognitive demand is accompanied by smooth pursuits deviating more from to-be tracked targets [137], reduced (micro)saccade frequencies [Figure 4; 63, 64, 138, 139], and slower peak saccade velocities [140–142]. Relatedly, more precise saccades are accompanied with worse performance in a crowding task [93].”</p><disp-quote content-type="editor-comment"><p>Finally, the authors conclude that their results &quot;suggests that the eye-movement system and other cognitive operations consume similar resources that are flexibly allocated among each other as cognitive demand changes. The authors should speculate what these similar resources could mean? What are the specific operations of the auditory task that overlap in terms of resources with the eye movement system?</p></disp-quote><p>We agree that the nature of joint resources is an interesting question. Our previous discussion was likely too simplistic here (see also responses to R3). We here specifically refer to the cognitive resources that one can flexibly distribute between tasks.</p><p>Our data do not directly speak to the question of what the shared resources between the auditory and oculomotor tasks are. Nevertheless, both tasks charge working memory as saccade targets are mandatorily encoded into working memory prior to saccade onset (Van der Stigchel &amp; Hollingworth, 2018), and the counting task clearly engages working memory. This may indicate some domain-generality between visual and auditory working memory during natural viewing (see Nozari &amp; Martin, 2024 for a recent review), but this remains speculative. Another possibility is that not the working memory encoding associated with saccades per se, but that the execution of overt motor actions itself also requires cognitive processing as suggested by Beatty (1982): “the organization of an overt motor act places additional demands on informationprocessing resources that are reflected in the task-evoked pupillary response”.</p><p>We have added upon this in more detail in the results and discussion sections.</p><p>“Besides the costs of increased neural activity when exerting more effort, effort should be considered costly for a second reason: Cognitive resources are limited. Therefore, any unnecessary resource expenditure reduces cognitive and behavioral flexibility [22, 31, 36, 116]. As a result, the brain needs to distribute resources between cognitive operations and the oculomotor system. We found evidence for the idea that such resource distribution is adaptive to the general level of cognitive demand and available resources: Increasing cognitive demand through an additional pri- mary auditory dual task led to a lower saccade frequency, and especially costly sac- cades were cut. In this case, it is important to consider that the auditory task was the primary task, which should cause participants to distribute resources from the ocu- lomotor system to the counting task. In other situations, more resources could be distributed to the oculomotor system instead, for example to discover new sources of reward [22, 136]. Adaptive resource allocation from, and to the oculomotor system parsimoniously explains a number of empirical observations. For example, higher cognitive demand is accompanied by smooth pursuits deviating more from to-be tracked targets [137], reduced (micro)saccade frequencies [Figure 4; 63, 64, 138, 139], and slower peak saccade velocities [140–142]. Relatedly, more precise saccades are accompanied with worse performance in a crowding task [93]. Furthermore, it has been proposed that saccade costs are weighed against other cognitive operations such as using working memory [33, 143–146]. How would the resources between the oculomotor system and cognitive tasks (like the auditory counting task) be related? One possibility is that both consume from limited working memory resources [147, 148]. Saccades are thought to encode target objects in a mandatory fashion into (vi- sual) working memory [79], and the counting task requires participants to keep track of the auditory stream and maintain count of the instructed digit in working mem- ory. However, the exact nature of which resources overlap between tasks remain open for future investigation [also see 149]. Together, we propose that cognitive re- sources are flexibly (dis)allocated to and from the oculomotor system based on the current demands to establish an optimal balance between performance and cost minimization.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>The authors attempt to establish presaccadic pupil size as an index of 'saccade effort' and propose this index as one new predictor of saccade target selection. They only partially achieved their aim: When choosing between two saccade directions, the less costly direction, according to preceding pupil size, is preferred. However, the claim that with increased cognitive demand participants would especially cut costly directions is not supported by the data. I would have expected to see a negative correlation between saccade effort and saccade direction 'change' under increased load. Yet participants mostly cut upwards saccades, but not other directions that, according to pupil size, are equally or even more costly (e.g. oblique saccades).</p><p>Strengths:</p><p>The paper is well-written, easy to understand, and nicely illustrated.</p><p>The sample size seems appropriate, and the data were collected and analyzed using solid and validated methodology.</p><p>Overall, I find the topic of investigating factors that drive saccade choices highly interesting and relevant.</p></disp-quote><p>We thank the reviewer for pointing out the strengths of our paper.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>The authors obtain pupil size and saccade preference measures in two separate tasks. Relating these two measures is problematic because the computations that underly saccade preparation differ. In Experiment 1, the saccade is cued centrally, and has to be delayed until a &quot;go-signal&quot; is presented; In Experiment 2, an immediate saccade is executed to an exogenously cued peripheral target. The 'costs' in Experiment 1 (computing the saccade target location from a central cue; withholding the saccade) do not relate to Experiment 2. It is unfortunate, that measuring presaccadic pupil size directly in the comparatively more 'natural' Experiment 2 (where saccades did not have to be artificially withheld) does not seem to be possible. This questions the practical application of pupil size as an index of saccade effort</p></disp-quote><p>This is an important point raised by the reviewer and we agree that a discussion on these points improves the manuscript. We reply in two parts: (1) Although the underlying computations during saccade preparation might differ, and are therefore unlikely to be fully similar (we agree), we can still predict saccade selection between (Saccade planning to Saccade preference) and within tasks (Visual search). (2) Pupil size is a sluggish physiological signal, but this is outweighed by the advantages of using pupil size as a general marker of effort, also in the context of visual selection compared with saccade latencies.</p><p>(1) Are delayed saccades (cost task) and the much faster saccades (preference task) linked?</p><p>As the reviewer notes the underlying ‘type’ of oculomotor program may differ between voluntarily delayed-saccades and those in the saccade preference task. There are, however, also considerable overlaps between the oculomotor programs as the directions and amplitudes are identical. Moreover, the different types of saccades have considerable overlap in their underlying neural circuitry. Nevertheless, the underlying oculomotor programs likely still differ in some regard. Even despite these differences, we were able to measure differences across directions in both tasks, and costs and preferences were negatively and highly correlated between tasks. The finding itself therefore indicates that the costs of saccades measured during the saccade planning task generalize to those in the saccade preference task. Note also that we predicted this finding and idea already in a previous publication before starting the present study (Koevoet et al., 2023).</p><p>We now address this interesting point in the discussion as follows:</p><p>“We observed that aOordable saccades were preferred over costly ones. This is especially remarkable given that the delayed saccades in the planning task likely differ in their oculomotor program from the immediate saccades in the preference task in some regard.”</p><p>(2) Is pupil size a sensible measure of saccade effort?</p><p>As the reviewer points out, the pupillary signal is indeed relatively sluggish and therefore relatively slow and more artifical tasks are preferred to quantify saccade costs. This does not preclude pupil size from being applied in more natural settings, as we demonstrate in the search experiments – but a lot of care has to be taken to control for many possible confounding factors and many trials will be needed.</p><p>That said, as saccade latencies may also capture differences in oculomotor effort (Shadmehr et al., 2019) they are a possible alternative option to assess effort in some oculomotor tasks (see below on why saccade latencies do not provide evidence for an alternative to effort driving saccade selection, but converging evidence). Whilst we do maintain that pupil size is an established and versatile physiological marker of effort, saccade latencies provide converging evidence for our conclusion that effort drives saccade selection.</p><p>As for the saccade preference task, we are not able to analyze the data in a similar manner as in the visual search task for two reasons. First, the number of saccades is much lower than in the natural search experiments. Second, in the saccade preference task, there were always two possible saccade targets. Therefore, even if we were able to isolate an effort signal, this signal could index a multitude of factors such as deciding between two possible saccade targets. Even simple binary decisions go hand in hand with reliable pupil dilations as they require effort (e.g. de Gee et al., 2014).</p><p>There are three major reasons why pupil size is a more versatile marker of saccade costs than saccade latencies (although as mentioned, latencies may constitute another valuable tool to study oculomotor effort). First, pupil size is able to quantify the cost of attentional shifts more generally, including covert attention as well as other effector systems such as head and hand movements. This circumvents the issue of different latencies of different effector systems and also allows to study attentional processes that are not associated with overt motor movements. Second, saccade latencies are difficult to interpret in natural viewing data, as fixation duration and saccade latencies are inherently confounded by one another. This makes it very difficult to separate oculomotor processes and the extraction of perceptual information from a fixated target. Thus, pupil size is a versatile marker of attentional costs in a variety of settings, and can measure costs that saccade latencies cannot (i.e. covert attention). Lastly, pupil size is highly established as a marker of effort which has been demonstrated across wide range of cognitive tasks and therefore not bound to eye movements alone (Bumke, 1911; Koevoet et al., 2024; Laeng et al., 2012; Loewenfeld, 1958; Mathôt, 2018; Robison &amp; Unsworth, 2019; Sirois &amp; Brisson, 2014; Strauch et al., 2022; van der Wel &amp; van Steenbergen, 2018).</p><p>We now discuss this as follows:</p><p>“We here measured cost as the degree of effort-linked pupil dilation. In addition to pupil size, other markers may also indicate saccade costs. For example, saccade latency has been proposed to index oculomotor effort [100], whereby saccades with longer latencies are associated with more oculomotor effort. This makes saccade latency a possible complementary marker of saccade costs (also see Supplemen- tary Materials). Although relatively sluggish, pupil size is a valuable measure of attentional costs for (at least) two reasons. First, pupil size is a highly established as marker of effort, and is sensitive to effort more broadly than only in the context of saccades [36–45, 48]. Pupil size therefore allows to capture not only the costs of saccades, but also of covert attentional shifts [33], or shifts with other effectors such as head or arm movements [54, 101]. Second, as we have demonstrated, pupil size can measure saccade costs even when searching in natural scenes (Figure 4). During natural viewing, it is difficult to disentangle fixation duration from saccade latencies, complicating the use of saccade latency as a measure of saccade cost. Together, pupil size, saccade latency, and potential other markers of saccade cost could fulfill complementary roles in studying the role of cost in saccade selection.”</p><disp-quote content-type="editor-comment"><p>The authors claim that the observed direction-specific 'saccade costs' obtained in Experiment 1 &quot;were not mediated by differences in saccade properties, such as duration, amplitude, peak velocity, and landing precision (Figure 1e,f)&quot;. Saccade latency, however, was not taken into account here but is discussed for Experiment 2.</p></disp-quote><p>The final model that was used to test for the observed anisotropies in pupil size across directions indeed did not include saccade latencies as a predictor. However, we did consider saccade latencies as a potential predictor originally. As we performed AICbased backward model selection, however, this predictor was removed due to the marginal predictive contribution of saccade latency beyond other predictors explaining pupil size.</p><p>For completeness, we here report the outcome of a linear mixed-effects that does include saccade latency as a predictor. Here, saccade latencies did not predict pupil size (b = 1.859e-03, <italic>t</italic> = .138, <italic>p</italic> = .889). The asymmetry effects remained qualitatively unchanged: preparing oblique compared with cardinal saccades resulted in a larger pupil size (b = 7.635, <italic>t</italic> = 3.969, <italic>p</italic> &lt; .001), and preparing downward compared with upward saccades also led to a larger pupil size (b = 3.344, <italic>t</italic> = 3.334, <italic>p</italic> = .003).</p><disp-quote content-type="editor-comment"><p>The apparent similarity of saccade latencies and pupil size, however, is striking. Previous work shows shorter latencies for cardinal than oblique saccades, and shorter latencies for horizontal and upward saccades than downward saccades - directly reflecting the pupil sizes obtained in Experiment 1 as well as in the authors' previous study (Koevoet et al., 2023, PsychScience).</p></disp-quote><p>As the reviewer notes, there are substantial asymmetries across the visual field in saccade latencies. These assymetries in saccade latency could also predict saccade preferences. We will reply to this in three points: (1) even if saccade latency is a predictor of saccade preferences, this would not constitute as an alternative explanation to the conclusion of effort driving saccade selection, (2) saccade latencies show an up-down asymmetry but oblique-cardinal effects in latency may not be generalizable across saccade tasks, (3) pupil size remains a robust predictor of saccade preferences even when saccade latencies are considered as a predictor of saccade preferences.</p><p>(1) We want to first stress that saccade latencies are thought to reflect oculomotor effort (Shadmehr et al., 2019). For example, saccades with larger amplitudes and saccades where distractors need to be ignored are associated with longer latencies. Therefore, even if saccade latencies predict saccade selection, this would not contrast the idea that effort drives saccade selection. Instead, this would provide convergent evidence for our main conclusion – effort predicting saccade selection (rather than pupil size predicting saccade selection per se).</p><p>“We here measured cost as the degree of effort-linked pupil dilation. In addition to pupil size, other markers may also indicate saccade costs. For example, saccade latency has been proposed to index oculomotor effort [100], whereby saccades with longer latencies are associated with more oculomotor effort. This makes saccade latency a possible complementary marker of saccade costs (also see Supplemen- tary Materials). Although relatively sluggish, pupil size is a valuable measure of attentional costs for (at least) two reasons. First, pupil size is a highly established as marker of effort, and is sensitive to effort more broadly than only in the context of saccades [36–45, 48]. Pupil size therefore allows to capture not only the costs of saccades, but also of covert attentional shifts [33], or shifts with other effectors such as head or arm movements [54, 101]. Second, as we have demonstrated, pupil size can measure saccade costs even when searching in natural scenes (Figure 4). During natural viewing, it is difficult to disentangle fixation duration from saccade latencies, complicating the use of saccade latency as a measure of saccade cost. Together, pupil size, saccade latency, and potential other markers of saccade cost could fulfill complementary roles in studying the role of cost in saccade selection.”</p><p>(2) We first tested anisotropies in saccade latency in the saccade planning task (Wilkinson notation: latency ~ obliqueness + updownness + leftrightness + saccade duration + saccade amplitude + saccade velocity + landing error + (1+obliqueness + updownness|participant)). We found upward latencies to be shorter than downward saccade latencies (b = -.535, <italic>t</italic> = 3.421, <italic>p</italic> = .003). In addition, oblique saccades showed shorter latencies than cardinal saccades (b = -1.083, <italic>t</italic> = 3.096, <italic>p</italic> = .002) – the opposite of what previous work has demonstrated.</p><p>We then also tested these latency anisotropies in another dataset wherein participants (<italic>n</italic> = 20) saccaded toward a single peripheral target as fast as possible (Koevoet et al., submitted; same amplitude and eccentricity as in the present manuscript). There we did not find a difference in saccade latency between cardinal and oblique targets, but we did observe shorter latencies for up- compared with downward saccades. We are therefore not sure in which situations oblique saccades do, or do not differ from cardinal saccades in terms of latency, and even in which direction the effect occurs.</p><p>In contrast, we have now demonstrated a larger pupil size prior to oblique compared with cardinal saccades in two experiments. This indicates that pupil size may be a more reliable and generalizable marker of saccade costs than saccade latency. However, this remains to be investigated further.</p><p>(3) To gain further insights into which oculomotor metrics would predict saccade selection, we conducted a linear regression across directions. We created pupil size, saccade latencies, landing precision and peak velocities maps from the saccade planning task. We then used AIC-based model selection to determine the ‘best’ model to determine which factor would predict saccade selection best. The selected model included pupil size, latency and landing precision as predictors (Wilkinson notation: saccade preferences ~ pupil size + saccade latency + landing precision). Pupil size (b = -42.853, <italic>t</italic> = 4.791, <italic>p</italic> &lt; .001) and saccade latency (b = -.377, <italic>t</italic> = 2.106, <italic>p</italic> = .043) predicted saccade preferences significantly. In contrast, landing precision did not reach significance (b = 23.631, <italic>t</italic> = 1.675, <italic>p</italic> = .104). This analysis shows that although saccade latency predicts saccade preferences, pupil size remains a robust predictor of saccade selection.</p><p>“To ascertain whether pupil size or other oculomotor metrics predict saccade preferences, we conducted a multiple regression analysis. We calculated average pupil size, saccade latency, landing precision and peak velocity maps across all 36 directions. The model, determined using AIC-based backward selection, included pupil size, latency and landing precision as predictors (Wilkinson notation: saccade preferences pupil size + saccade latency + landing precision). The analysis re- vealed that pupil size (β = -42.853, t = 4.791, p &lt; .001) and saccade latency (β = -.377, t = 2.106, p = .043) predicted saccade preferences. Landing precision did not reach significance (β = 23.631, t = 1.675, p = .104). Together, this demonstrates that although other oculomotor metrics such as saccade latency contribute to saccade selection, pupil size remains a robust marker of saccade selection.”</p><disp-quote content-type="editor-comment"><p>The authors state that &quot;from a costs-perspective, it should be eOicient to not only adjust the number of saccades (non-specific), but also by cutting especially expensive directions the most (specific)&quot;. However, saccade targets should be selected based on the maximum expected information gain. If cognitive load increases (due to an additional task) an effective strategy seems to be to perform less - but still meaningful - saccades. How would it help natural orienting to selectively cut saccades in certain (effortful) directions? Choosing saccade targets based on comfort, over information gain, would result in overall more saccades to be made - which is non-optimal, also from a cost perspective.</p></disp-quote><p>We thank the reviewer for this comment. Although we do not fully agree, the logic is quite close to our rationale and it is worth adding a point of discussion here. A vital part of the current interpretation is the instruction given to participants. In our second natural visual search task, participants were performing a dual task, where the auditory task was the primary task, whilst the search task was secondary. Therefore, participants are likely to adjust their resources to optimize performance on the primary task – at the expense of the secondary task. Therefore, less resources are made available and used to searching in the dual than in the single task, because these resources are needed for the auditory task. Cutting expensive directions does not help search in terms of search performance, but it does reduce the cost of search, so that more resources are available for the prioritized auditory task. Also note that the search task was rather difficult – participants did it, but it was tough (see the original description of the dataset for more details), which provides another reason to go full in on the auditory task at expense of the visual task. This, however, opens up a nice point of discussion: If one would emphasize the importance of search (maybe with punishment or reward), we would indeed expect participants to perform whichever eye movements are getting them to their goal fastest – thus reducing the relative influence of costs on saccade behavior. This remains to be tested however - we are working on this and are looking forward to discussing such findings in the future.</p><p>Together, we propose that there is a trade-off between distributing resources either towards cognitive tasks or the oculomotor system (also see Ballard et al., 1995; Van der Stigchel, 2020). How these resources are distributed depends highly on the current task demands (also see Sahakian et al., 2023). This allows for adaptive behavior in a wide range of contexts.</p><p>We now added these considerations to the manuscript as follows (also see our previous replies):</p><p>“Do cognitive operations and eye movements consume from a similar pool of resources [44]? If so, increasing cognitive demand for non-oculomotor processes should result in decreasing available resources for the oculomotor system. In line with this idea, previous work indeed shows altered eye-movement behavior un- der effort as induced by dual tasks, for example by making less saccades under increased cognitive demand [62–64]. We therefore investigated whether less sac- cades were made as soon as participants had to count the occurrence of a specific digit in the auditory number stream in comparison to ignoring the stream (in Exp. 2; Figure 4a). Participants were instructed to prioritize the auditory digit-counting task over finding the visual search target. Therefore, resources should be shifted from the oculomotor system to the primary auditory counting task. The additional cognitive demand of the dual task indeed led to a decreased saccade frequency (t(24) = 7.224, p &lt; .001, Cohen’s d = 1.445; Figure 4h).”</p><disp-quote content-type="editor-comment"><p>I would have expected to see a negative correlation between saccade effort and saccade direction 'change' under increased load. Yet participants mostly cut upwards saccades, but not other directions that, according to pupil size, are equally or even more costly (e.g. oblique saccades).</p></disp-quote><p>The reviewer’s point is taken from the initial comment, which we will address here. First, we’d like to point out that is it not established that saccade costs in different directions are always the same. Instead, it is possible that saccade costs could be different in natural viewing compared with our delayed-saccade task. Therefore, we used pupil size during natural viewing for the search experiments. Second, the reviewer correctly notes that oblique saccades are hardly cut when under additional cognitive demand. However, participants already hardly execute oblique saccades when not confronted with the additional auditory task (Figure 4b, d), making it difficult to reduce those further (i.e. floor effect). Participants chose to cut vertical saccades, possibly because these are more costly than horizontal saccades.</p><p>We incorporated these point in our manuscript as follows:</p><p>“To test this, we analyzed data from two existing datasets [63] wherein participants (total <italic>n</italic> = 41) searched for small targets (’Z’ or ’H’) in natural scenes (Figure 4a; [64]). Again, we tested whether pupil size prior to saccades negatively linked with saccade preferences across directions. Because saccade costs and preferences across directions could differ for different situations (i.e. natural viewing vs. saccade preference task), but should always be negatively linked, we established both cost and preferences independently in each dataset.”</p><p>“We calculated a saccade-adjustment map (Figure 4g) by subtracting the saccade preference map in the single task (Figure 4f) from the dual task map (Fig- ure 4d). Participants seemingly cut vertical saccades in particular, and made more saccades to the top right direction. This pattern may have emerged as vertical saccades are more costly than horizontal saccades (also see Figure 1d). Oblique saccades may not have been cut because there were very little oblique saccades in the single condition to begin with (Figure 4d), making it difficult to observe a further reduction of such saccades under additional cognitive demand (i.e. a floor effect).”</p><disp-quote content-type="editor-comment"><p>Overall, I am not sure what practical relevance the relation between pupil size (measured in a separate experiment) and saccade decisions has for eye movement research/vision science. Pupil size does not seem to be a straightforward measure of saccade effort. Saccade latency, instead, can be easily extracted in any eye movement experiment (no need to conduct a separate, delayed saccade task to measure pupil dilation), and seems to be an equally good index.</p></disp-quote><p>There are two points here.</p><p>(1) What is the practical relevance of a link between effort and saccade selection for eyemovement research and vision science?</p><p>We see plenty – think of changing eye movement patterns under effort (be it smooth pursuits, saccade rates, distributions of gaze positions to images etc.) which have substantial implications for human factors research, but also neuropsychology. With a cost account, one may predict (rather than just observe) how eye movement changes as soon as resources are reduced/ non-visual demand increases. With a cost account, we can explain such effects (e.g. lower saccade rates under effort, cardinal bias, perhaps also central bias) parsimoniously that cannot be explained by what is so far referred to as the three core drivers of eye movement behavior (saliency, selection history, goals, e.g., Awh et al., 2012). Conversely, one must wonder why eye-movement research/vision science simply accepts/dismisses these phenomena as such, without seeking overarching explanations.</p><p>(2) What is the usefulness of using pupil size to measure effort?</p><p>We hope that our replies to the comments above illustrate why pupil size is a sensible, robust and versatile marker of attentional costs. We briefly summarize our most important points here.</p><p>- Pupil size is an established measure of effort irrespective of context, as demonstrated by hundreds of original works (e.g. working memory load, multiple object tracking, individual differences in cognitive ability). This allows pupil size to be a versatile marker of the effort, and therefore costs, of non-saccadic attentional shifts such as covert attention or those realized by other effector systems (i.e. head or hand movements).</p><p>- Our new analysis indicates that pupil size remains a strong and robust predictor of saccade preference, even when considering saccade latency.</p><p>- Pupil size allows to study saccade costs in natural viewing. In contrast, saccade latencies are difficult to assess in natural viewing as fixation durations and saccade latencies are intrinsically linked and very difficult to disentangle.</p><p>- Note however, that we think that it is interesting and useful so study effects of effort/cost on eye movement behavior. Whichever index is used to do so, we see plenty potential in this line of research, this paper is a starting point to do so.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>This manuscript extends previous research by this group by relating variation in pupil size to the endpoints of saccades produced by human participants under various conditions including trial-based choices between pairs of spots and search for small items in natural scenes. Based on the premise that pupil size is a reliable proxy of &quot;effort&quot;, the authors conclude that less costly saccade targets are preferred. Finding that this preference was influenced by the performance of a non-visual, attentiondemanding task, the authors conclude that a common source of effort animates gaze behavior and other cognitive tasks.</p><p>Strengths:</p><p>Strengths of the manuscript include the novelty of the approach, the clarity of the findings, and the community interest in the problem.</p></disp-quote><p>We thank the reviewer for pointing out the strengths of our paper.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>Enthusiasm for this manuscript is reduced by the following weaknesses:</p><p>(1) A relationship between pupil size and saccade production seems clear based on the authors' previous and current work. What is at issue is the interpretation. The authors test one, preferred hypothesis, and the narrative of the manuscript treats the hypothesis that pupil size is a proxy of effort as beyond dispute or question. The stated elements of their argument seem to go like this:</p><p>PROPOSITION 1: Pupil size varies systematically across task conditions, being larger when tasks are more demanding.</p><p>PROPOSITION 2: Pupil size is related to the locus coeruleus.</p><p>PROPOSITION 3: The locus coeruleus NE system modulates neural activity and interactions.</p><p>CONCLUSION: Therefore, pupil size indexes the resource demand or &quot;effort&quot; associated with task conditions.</p><p>How the conclusion follows from the propositions is not self-evident. Proposition 3, in particular, fails to establish the link that is supposed to lead to the conclusion.</p></disp-quote><p>We inadvertently laid out this rationale as described above, and we thank the reviewer for pointing out this initial suboptimal structure of argumentation. The notion that the link between pupil size and effort is established in the literature <italic>because</italic> of its neural underpinnings is inaccurate. Instead, the tight link between effort and pupil size is established based on covariations of pupil diameter and cognition across a wide variety of tasks and domains. In line with this, we now introduce this tight link predominantly based on the relationships between pupil size and cognition instead of focusing on putative neural correlates of this relationship.</p><p>As reviewed previously (Beatty, 1982; Bumke, 1911; Kahneman, 1973; Kahneman &amp; Beatty, 1966; Koevoet et al., 2024; Laeng et al., 2012; Mathôt, 2018; Sirois &amp; Brisson, 2014; Strauch et al., 2022; van der Wel &amp; van Steenbergen, 2018), any increase in effort is consistently associated with an increase in pupil size. For instance, the pupil dilates when increasing load in working memory or multiple object tracking tasks, and such pupillary effects robustly explain individual differences in cognitive ability and fluctuations in performance across trials (Alnæs et al., 2014; Koevoet et al., 2024; Robison &amp; Brewer, 2020; Robison &amp; Unsworth, 2019; Unsworth &amp; Miller, 2021). This extends to the planning of movements as pupil dilations are observed prior to the execution of (eye) movements (Koevoet et al., 2023; Richer &amp; Beatty, 1985). The link between pupil size and effort has thus been firmly established for a long time, irrespective of the neural correlates of these effort-linked pupil size changes.</p><p>We again thank the reviewer for spotting this logical mistake, and now revised the paragraph where we introduce pupil size as an established marker of effort as follows:</p><p>“We recently demonstrated that the effort of saccade planning can be measured with pupil size, which allows for a physiological quantification of saccade costs as long as low-level visual factors are controlled for [33]. Pupil size is an established marker of effort [36–44]. For instance, loading more in working memory or tracking more objects results in stronger pupil dilation [44–52]. Pupil size not only reflects cognitive (or mental) effort but also the effort of planning and executing movements [37, 53, 54]. We leveraged this to demonstrate that saccade costs can be captured with pupil size, and are higher for oblique compared with cardinal directions [33]. Here, we addressed whether saccade costs predict where to saccade.”</p><p>We now mention the neural correlates of pupil size only in the discussion. Where we took care to also mention roles for other neurotransmitter systems:</p><p>“Throughout this paper, we have used cost in the limited context of saccades.</p><p>However, cost-based decision-making may be a more general property of the brain [31, 36, 114–116]. Every action, be it physical or cognitive, is associated with an in- trinsic cost, and pupil size is likely a general marker of this [44]. Note, however, that pupil dilation does not always reflect cost, as the pupil dilates in response to many sensory and cognitive factors which should be controlled for, or at least considered, when interpreting pupillometric data [e.g., see 39, 40, 42, 117]. Effort-linked pupil dilations are thought to be, at least in part, driven by activity in the brainstem locus coeruleus (LC) [40, 118–120] [but other neurotransmitters also affect pupil size, e.g. 121, 122]. Activity in LC with its widespread connections throughout the brain [120, 123–127] is considered to be crucial for the communication within and between neu- ral populations and modulates global neural gain [128–132]. Neural firing is costly [22, 133], and therefore LC activity and pupil size are (neuro)physiologically plausible markers of cost [40]. Tentative evidence even suggests that continued exertion of effort (accompanied by altered pupil dilation) is linked to the accumulation of glutamate in the lateral prefrontal cortex [134], which may be a metabolic marker of cost [also see 116, 134, 135]. “</p><disp-quote content-type="editor-comment"><p>(2) The authors test one, preferred hypothesis and do not consider plausible alternatives. Is &quot;cost&quot; the only conceivable hypothesis? The hypothesis is framed in very narrow terms. For example, the cholinergic and dopamine systems that have been featured in other researchers' consideration of pupil size modulation are missing here. Thus, because the authors do not rule out plausible alternative hypotheses, the logical structure of this manuscript can be criticized as committing the fallacy of aOirming the consequent.</p></disp-quote><p>As we have noted in the response to the reviewer’s first point, we did not motivate our use of pupil size as an index of effort clearly enough. For the current purpose, the neural correlates of pupil size are less relevant than the cognitive correlates (see previous point). We reiterate that the neuromodulatory underpinnings of the observed pupil size effects (which indeed possibly include effects of the cholinergic, dopaminergic and serotonergic systems), while interesting for the discussion on the neural origin of effects, are not crucial to our conclusion. We hope the new rationale (without focusing too much on the (irrelevant) exact neural underpinnings) convinces the reviewer and reader.</p><p>Our changes to the manuscript are shown in our reply to the previous comment.</p><p>The reviewer notes that other plausible alternative hypotheses could explain the currently reported results. However, we did not find a more parsimonuous explanation for our data than ‘Effort Drives Saccade Selection’. Effort explains why participants prefer saccading toward specific directions in (1) highly controlled and (2) more natural settings. Note that we also predicted this effect previously (Koevoet et al., 2023). Moreover, this account explains (3) why participants make less saccades under additional cognitive demand, and (4) why especially costly saccades are reduced under additional cognitive demand. We are very open to the reviewer presenting other possible interpretations of our data so these can be discussed to be put to test in future work.</p><disp-quote content-type="editor-comment"><p>(3) The authors cite particular publications in support of the claim that saccade selection is influenced by an assessment of effort. Given the extensive work by others on this general topic, the skeptic could regard the theoretical perspective of this manuscript as too impoverished. Their work may be enhanced by consideration of other work on this general topic, e.g, (i) Shenhav A, Botvinick MM, Cohen JD. (2013) The expected value of control: an integrative theory of anterior cingulate cortex function. Neuron. 2013 Jul 24;79(2):217-40. (ii) Müller T, Husain M, Apps MAJ. (2022) Preferences for seeking effort or reward information bias the willingness to work. Sci Rep. 2022 Nov 14;12(1):19486. (iii) Bustamante LA, Oshinowo T, Lee JR, Tong E, Burton AR, Shenhav A, Cohen JD, Daw ND. (2023) Effort Foraging Task reveals a positive correlation between individual differences in the cost of cognitive and physical effort in humans. Proc Natl Acad Sci U S A. 2023 Dec 12;120(50):e2221510120.</p></disp-quote><p>We thank the reviewer for pointing us toward this literature. These papers are indeed relevant for our manuscript, and we have now incorporated them. Specifically, we now discuss how the costs of effort are weighed in relation to possible rewards during decision-making. We have also incorporated work that has investigated how the biomechanical costs of arm movements contribute to action selection.</p><p>“Our findings are in line with established effort-based models that assume costs to be weighed against rewards during decision-making [102–107]. In such studies, reward and cognitive/physical effort are often parametrically manipulated to as- sess how much effort participants are willing to exert to acquire a given (monetary) reward [e.g. 108, 109]. Whereas this line of work manipulated the extrinsic costs and/or rewards of decision options (e.g. perceptual consequences of saccades [110, 111] or consequences associated with decision options), we here focus on the intrin- sic costs of the movement itself (in terms of cognitive and physical effort). Relatedly, the intrinsic costs of arm movements are also considered during decision-making: biomechanically aOordable movements are generally preferred over more costly ones [26–28]. We here extend these findings in two important ways. First, until now, the intrinsic costs of saccades and other movements have been inferred from gaze behavior itself or by using computational modelling [23, 25–28, 34, 35, 112]. In con- trast, we directly measured cost physiologically using pupil size. Secondly, we show that physiologically measured saccade costs predict where saccades are directed in a controlled binary preference task, and even during natural viewing. Our findings could unite state-of-the-art computational models [e.g. 23, 25, 34, 35, 113] with physiological data, to directly test the role of saccade costs and ultimately further our understanding of saccade selection.”</p><disp-quote content-type="editor-comment"><p>(4) What is the source of cost in saccade production? What is the currency of that cost? The authors state (page 13), &quot;... oblique saccades require more complex oculomotor programs than horizontal eye movements because more neuronal populations in the superior colliculus (SC) and frontal eye fields (FEF) [76-79], and more muscles are necessary to plan and execute the saccade [76, 80, 81].&quot; This statement raises questions and concerns. First, the basis of the claim that more neurons in FEF and SC are needed for oblique versus cardinal saccades is not established in any of the publications cited. Second, the authors may be referring to the fact that oblique saccades require coordination between pontine and midbrain circuits. This must be clarified. Second, the cost is unlikely to originate in extraocular muscle fatigue because the muscle fibers are so different from skeletal muscles, being fundamentally less fatigable. Third, if net muscle contraction is the cost, then why are upward saccades, which require the eyelid, not more expensive than downward? Thus, just how some saccades are more effortful than others is not clear.</p></disp-quote><p>Unfortunately, our current data do not allow for the specification of what the source is of differences in saccade production, nor what the currency is. We want to explicitly state that while pupil size is a sensitive measure of saccade costs, pupil size cannot directly inform what underlying mechanisms are causing differences in saccade costs across conditions (e.g. directions). Nevertheless, we do speculate about these issues because they are important to consider. We thank the reviewer for pointing out the shortcomings in our initial speculations.</p><p>Broadly, we agree with the reviewer that a neural source of differences in costs between different types of saccades is more likely than a purely muscular account (also see Koevoet et al., 2023). Furthermore, we think that the observed differences in saccade costs for oblique vs. cardinal and up vs. down could be due to different underlying mechanisms. While we caution against overinterpreting single directions, tentative evidence for this may also be drawn by the different time course of effects for up/down versus cardinal/oblique, Figure 1c.</p><p>Below we speculate about why some specific saccade directions may be more costly than others:</p><p>Why would oblique saccades be more costly than cardinal saccades? We thank the reviewer for pointing out that oblique saccades additionally require coordination between pontine and midbrain circuits (Curthoys et al., 1984; King &amp; Fuchs, 1979; Sparks, 2002). This point warrants more revised discussion compared to our initial version. We have incorporated this as follows:</p><p>“The complexity of an oculomotor program is arguably shaped by its neural underpinnings. For example, oblique but not cardinal saccades require communication between pontine and midbrain circuits [73–75]. Such differences in neural complexity may underlie the additional costs of oblique compared with cardinal saccades. Besides saccade direction, other properties of the ensuing saccade such as its speed, distance, curvature, and accuracy may contribute to a saccade’s total cost [22, 33, 53, 76, 77] but this remains to be investigated directly.”</p><p>Why would downward saccades be more costly than upward saccades? As the reviewer points out: from a net muscular contraction account of cost, one would expect the opposite pattern due to the movement of the eyelid. Instead, we speculate that our findings may be associated with the well-established anisotropy in early visual cortex along the vertical meridian. Specifically, the upper vertical meridian is represented at substantially less detail than the lower vertical meridian (Himmelberg et al., 2023; Silva et al., 2018). Prior to a saccade, attention is deployed towards the intended saccadic endpoint (Deubel &amp; Schneider, 1996; Kowler et al., 1995). Attention tunes neurons to preferentially process the attended location over non-attended locations. Due to the fact that the lower visual field is represented at higher detail than the upper visual field, attention may tune neuronal responses differently when preparing up- compared with downward saccades (Hanning et al., 2024; Himmelberg et al., 2023). Thus, it may be more costly to prepare down- compared with upward saccades. This proposition, however, does not account for the lower costs associated horizontal compared with up- and downward saccades as the horizontal meridian is represented at a higher acuity than the vertical merdian. This makes it unlikely that this explains the pattern of results completely. Again, at this point we can only speculate why costs differ, yet we demonstrate that these differences in cost are decisive for oculomotor behavior. We now explicitly state the speculative nature of these ideas that would all need to be tested directly.</p><p>We have updated our discussion of this issue as follows:</p><p>“The observed differences in saccade costs across directions could be linked to established anisotropies in perception [80–86], attention [87–92], saccade charac- teristics [87, 88, 92, 93], and (early) visual cortex [94–98] [also see 99]. For example, downward saccades are more costly than upward saccades, which mimics a similar asymmetry in early visual areas wherein the upper visual field is relatively under- represented [94–98]; similarly stronger presaccadic benefits are found for down- compared with upward saccades [87, 88]. Moreover, upward saccades are more pre- cise than downward saccades [93]. Future work should elucidate where saccade cost or the aforementioned anisotropies originate from and how they are related - something that pupil size alone cannot address.”</p><disp-quote content-type="editor-comment"><p>(5) The authors do not consider observations about variation in pupil size that seem to be incompatible with the preferred hypothesis. For example, at least two studies have described systematically larger pupil dilation associated with faster relative to accurate performance in manual and saccade tasks (e.g., Naber M, Murphy P. Pupillometric investigation into the speed-accuracy trade-off in a visuo-motor aiming task. Psychophysiology. 2020 Mar;57(3):e13499; Reppert TR, Heitz RP, Schall JD. Neural mechanisms for executive control of speed-accuracy trade-off. Cell Rep. 2023 Nov 28;42(11):113422). Is the fast relative to the accurate option necessarily more costly?</p></disp-quote><p>We thank the reviewer for this interesting point that we will answer in two ways. First, we discuss the main point: the link between pupil size, effort, and cost. Second, we discuss the findings described specifically in these two papers and how we interpret these from a pupillometric account.</p><p>First, one may generally ask whether (1) any effort results in pupil dilation, (2) whether any effort is costly, and (3) whether this means that pupil dilation always reflects effort and cost respectively. Indeed, it has been argued repeatedly, prominently, and independently (e.g., Bumke, 1911; Mathôt, 2018) that any change in effort (no matter the specific origin) is associated with an evoked pupil dilation. Effort, in turn, is consistently and widely experienced as aversive, both across tasks and cultures (David et al., 2024). Effort minimization may therefore be seen as an universal law of human cognition and behavior with effort as a to-be minimized cost (Shadmehr et al., 2019; Hull 1943, Tsai 1932). However, this does not imply that any pupil dilation necessarily reflects effort or that, as a consequence thereof, any pupil dilation is always signaling cost. For instance, the pupil dark response, the pupil far response and changes in baseline pupil size are not associated with effort. Baseline and task-evoked pupil dilation responses have to be interpreted differently (see below), moreover, the pupil also changes (and dilates) due to other factors (see Strauch et al., 2022; Mathôt, 2018, Bumke 1911, Loewenfeld, 1999 for reviews).</p><p>Second, as for Naber &amp; Murphy (2020) &amp; Reppert at al. (2023) specifically: Both Reppert et al. (2023) and Naber &amp; Murphy (2020) indeed demonstrate a larger <italic>baseline</italic> pupil size when participants made faster, less accurate responses. However, baseline pupil size is not an index of effort per-se, but task-evoked pupil dilation responses are (as studied in the present manuscript) (Strauch et al., 2022). For work on differences between baseline pupil diameter and task-evoked pupil responses, and their respective links with exploration and exploitation please see Jepma &amp; Nieuwenhuis (2011). Indeed, the link between effort and larger pupil size holds for task evoked responses, but not baseline pupil size per se (also see Koevoet et al., 2023).</p><p>Still, Naber (third author of the current paper) &amp; Murphy (2020) also demonstrated larger task-evoked pupil dilation responses when participants were instructed to make faster, less accurate responses compared with making accurate and relatively slow responses. However, this difference in task-evoked response gains significance only after the onset of the movement itself, and peaks substantially later than response offset. Whilst pupil dilation may be sluggish, it isn’t extremely sluggish either. As feedback to the performance of the participant was displayed 1.25s after performing the movement and clicking (taking about 630ms), we deem it possible that this effect may in part result from appraising the feedback to the participant rather than the speed of the response itself (in fact, Naber and Murphy also discuss this option). In addition to not measuring saccades but mouse movements, it is therefore possible that the observed evoked pupil effects in Naber &amp; Murphy (2020) are not purely linked to motor preparation and execution per se. Therefore, future work that aims to investigate the costs of movements should isolate the effects of feedback and other potential factors that may drive changes in pupil size. This will help clarify whether fast or more accurate movements could be linked to the underlying costs of the movements.</p><p>Relatedly, we do not find evidence that pupil size during saccade planning predicts the onset latency of the ensuing saccade (please refer to our second response to Reviewer 2 for a detailed discussion).</p><p>Together, we therefore do not see the results from Reppert et al. (2023) and Naber &amp; Murphy (2020) to be at odds with our interpretation of evoked pupil size reflecting effort and cost in the context of planning saccades.</p><p>We think that these are considerations important to the reader, which is why we now added them to the discussion as follows:</p><p>“Throughout this paper, we have used cost in the limited context of saccades.</p><p>However, cost-based decision-making may be a more general property of the brain [31, 36, 114–116]. Every action, be it physical or cognitive, is associated with an in- trinsic cost, and pupil size is likely a general marker of this [44]. Note, however, that pupil dilation does not always reflect cost, as the pupil dilates in response to many sensory and cognitive factors which should be controlled for, or at least considered, when interpreting pupillometric data [e.g., see 39, 40, 42, 117].”</p><disp-quote content-type="editor-comment"><p>(6) The authors draw conclusions based on trends across participants, but they should be more transparent about variation that contradicts these trends. In Figures 3 and 4 we see many participants producing behavior unlike most others. Who are they? Why do they look so different? Is it just noise, or do different participants adopt different policies?</p></disp-quote><p>We disagree with the transparency point of the reviewer. Note that we deviated from the norm here by being <italic>more</italic> transparent than common: we added individual data points and relationships rather than showing pooled effects across participants with error bars alone (see Figures 2c, 3b,c, 4c,e,f).</p><p>Moreover, our effects are consistent and stable across participants and are highly significant. To illustrate, for the classification analysis based on cost (Figure 2E) 16/20 participants showed an effect. As for the natural viewing experiments (total &gt; 250,000 fixations), we also find that a majority of participants show the observed effects: Experiment 1: 15/16 participants; Experiment 2: 16/25 participants; Experiment 2 – adjustment: 22/25 participants.</p><p>We fully agree that it’s interesting to understand where interindividual variation may originate from. We currently have too little data to allow robust analyses across individuals and zooming in on individual differences in cost maps, preference maps, or potential personalized strategies of saccade selection. That said, future work could study this further. We would recommend to hereby reduce the number of directions to gain more pupil size data per direction and therefore cleaner signals that may be more informative on the individual level. With such stronger signals, studying (differences in) links on an individual level may be feasible and would be interesting to consider – and will be a future direction in our own work too. Nonetheless, we again stress that the reported effects are robust and consistent across participants, and that interindividual differences are therefore not extensive. Moreover, our results from four experiments consistently support our conclusion that effort drives saccade selection.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>- Based on the public review, I would recommend that the authors carefully review and correct the manuscript with regard to the causal conclusions. The study is largely correlational (i.e. the pupil was only observed, not manipulated) and therefore does not allow causal conclusions to be drawn about the relationship between pupil size and saccade selection. These causal conclusions become even more confusing when pupil size is equated with effort and saccade cost. As a consequence, an actual correlation between pupil size and saccade selection has led to the title that effort drives saccade selection. It would also be helpful for the reader to summarize in an additional section of the discussion what they consider to be a causal or correlational link based on their results.</p></disp-quote><p>We agree with the reviewer, and we have indeed included more explicitly which findings are correlational and which causal in detail now. As outlined before we do not see a more parimanious explanation for our findings than our title, but we fully agree that the paper benefits from making the correlational/causal nature of evidence for this idea explicitly transparent.</p><p>“We report a combination of correlational and causal findings. Despite the correlational nature of some of our results, they consistently support the hypothesis that saccade costs predicts saccade selection [which we predicted previously, 33]. Causal evidence was provided by the dual-task experiment as saccade frequencies - and especially costly saccades were reduced under additional cognitive demand. Only a cost account predicts (1) a link between pupil size and saccade preferences, (2) a cardinal saccade bias, (3) reduced saccade frequency under additional cognitive demand, and (4) disproportional cutting of especially those directions associated with more pupil dilation. Together, our findings converge upon the conclusion that effort drives saccade selection.”</p><p>- Can the authors please elaborate in more detail on how they transformed the predictors of their linear mixed model for the visualization in Figure 1f? It is difficult to see how the coeOicients in the table and the figure match.</p><p>We used the ‘effectsize’ package to provide effect sizes of for each predictor of the linear mixed-effects model (<ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/effectsize/index.html">https://cran.r-project.org/web/packages/effectsize/index.html</ext-link>). We report absolute effect sizes to make it visually easier to compare different predictors. These details have now been included in the Methods section to be more transparent about how these effect sizes were computed.</p><p>“Absolute effect sizes (i.e. <italic>r</italic>) and their corresponding 95% confidence intervals for the linear mixed-effects models were calculated using <italic>t</italic> and <italic>df</italic> values with the ’effectsize’ package (v0.8.8) in R.”</p><disp-quote content-type="editor-comment"><p>- Could the authors please explain in more detail why they think that a trial-by-trial analysis in the free choice task adds something new to their conclusions? In fact, a trialby-trial analysis somehow suggests that the pupil size data would enter the analysis at a single trial level. If I understand correctly, the pupil size data come from their initial mapping task. So there is only one mean pupil size for a given participant and direction that goes into their analysis to predict free choice in a single trial. If this is the case, I don't see the point of doing this additional analysis given the results shown in Figure 2c.</p></disp-quote><p>The reviewer understands correctly that pupil size data is taken from the initial mapping task. We then used these mean values to predict which saccade target would be selected on a trial-by-trial basis. While showing the same conceptual result as the correlation analysis, we opted to include this analysis to show the robustness of the results across individuals. Therefore we have chosen to keep the analysis in the manuscript but now write more clearly that this shows the same conceptual finding as the correlation analysis.</p><p>“As another test of the robustness of the effect, we analyzed whether saccade costs predicted saccade selection on a trial-by-trial basis. To this end, we first determined the more aOordable option for each trial using the established saccade cost map (Figure 1d). We predicted that participants would select the more aOordable option. Complementing the above analyses, the more aOordable option was chosen above chance level across participants (M = 56.64%, 95%-CI = [52.75%-60.52%], one-sample t-test against 50%: t(19) = 3.26, p = .004, Cohen’s d = .729; Figure 2e). Together, these analyses established that saccade costs robustly predict saccade preferences.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>The authors report that &quot;Whenever the difference in pupil size between the two options was larger, saccades curved away more from the non-selected option (β = .004, SE = .001, t = 4.448, p &lt; .001; Figure 3b), and their latencies slowed (β = .050, SE = .013, t = 4.323, p &lt; .001; Figure 3c)&quot;. I suspect this effect might not be driven by the difference but by a correlation between pupil size and latency.</p><p>The authors correlate differences in pupil size (Exp1) with saccade latencies (Exp2), I recommend correlating pupil size with the latency directly, in either task. This would show if it is actually the difference between choices or simply the pupil size of the respective individual option that is linked to latency/effort. Same for curvature.</p></disp-quote><p>The reviewer raises a good point. Please see the previous analyses concerning the possible correlations between pupil size and saccade latency, and how they jointly predict saccade selection.</p><p>Our data show that saccade curvature and latencies are linked with the difference in pupil size between the selected and non-selected options. Are these effects driven by a difference in pupil size or by the pupil size associated with the chosen option?</p><p>To assess this, we conducted two linear mixed-effects models. We predicted saccade curvature and latency using pupil size (from the planning task) of the selected and nonselected options while controlling for the chosen direction (Wilkinson notation: saccade curvature/latency ~ selected pupil size + non-selected pupil size + obliqueness + vertical + horizontal + (1+ selected pupil size + non-selected pupil size|participant)). We found that saccades curved away more from costlier the non-selected targets (β = 1.534, <italic>t</italic> = 8.151, <italic>p</italic> &lt; .001), and saccades curved away from the non-selected target less when the selected target was cheaper (β = -2.571, <italic>t</italic> = -6.602, <italic>p</italic> &lt; .001). As the costs of the selected and non-selected show opposite effects on saccade curvature, this indicates that the difference between the two options drives oculomotor conflict.</p><p>As for saccade latencies, we found saccade onsets to slow when the cost of the selected target was higher (b = .068, <italic>t</italic> = 2.844, <italic>p</italic> = .004). In contrast, saccade latencies were not significantly affected by the cost of the non-selected target (β = -.018, <italic>t</italic> = 1.457, <italic>p</italic> = .145), although numerically the effect was in the opposite direction. This shows that latencies were primarily driven by the cost of the selected target but a difference account cannot be fully ruled out.</p><p>Together, these analyses demonstrate that the difference in costs between two alternatives reliably affects oculomotor conflict as indicated by the curvature analysis. However, saccade latencies are predominantly affected by the cost of the selected target – even when controlling for the obliqueness, updownness and leftrightness of the ensuing saccade. We have added these analyses here for completeness, but because the findings seem inconclusive for saccade latency we have chosen to not include these analyses in the current paper. We are open to including these analyses in the supplementary materials if the reviewer and/or editor would like us to, but have chosen not to do so due to conciseness and to keep the paper focused.</p><disp-quote content-type="editor-comment"><p>I was wondering why the authors haven't analyzed the pupil size in Experiment 2. If the pupil size can be assessed during a free viewing task (Experiment 3), shouldn't it be possible to also evaluate it in the saccade choice task?</p></disp-quote><p>We did not analyze the pupil size data from the saccade preference task for two reasons. First, the number of saccades is much lower than in the natural search experiments (~14.000 vs. ~250.000). Second, in the saccade preference task, there were always two possible saccade targets. Therefore, even if we were able to isolate an effort signal, this signal could index a multitude of factors such as deciding between two possible saccade targets (de Gee et al., 2014), and has the possibility of two oculomotor programs being realized instead of only a single one (Van der Stigchel, 2010).</p><disp-quote content-type="editor-comment"><p>Discussion: &quot;due to stronger presaccadic benefits for upward compared with downward saccades [93,94]&quot;. I think this should be the other way around.</p></disp-quote><p>We thank the reviewer for pointing this out. We have corrected our mistake in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Saccade latencies differ around the visual field; to account for that, results / pupil size should be (additionally) evaluated relative to saccade onset (rather than cue offset). It is interesting that latencies were not accounted for here (Exp1), since they are considered for Exp2 (where they correlate with a pupil size difference). I suspect that latencies not only correlate with the difference in pupil size, but directly with pupil size itself.</p></disp-quote><p>We agree with the reviewer that locking the pupil size signal to saccade onset instead of cue offset may be informative. We included an analysis in the supporting information that investigates this (see Figure S1). The results of the analysis were conceptually identical.</p><p>The reviewer writes that latencies were not accounted for in Experiment 1. Although saccade latency was not included in the final model reported in the paper, it was considered during AIC-based backward model selection. As saccade latency did not predict meaningful variance in pupil size, it was ultimately not included in the analysis as a predictor. For completeness, we here report the outcome of a linear mixed-effects that does include saccade latency as a predictor. Here, saccade latencies did not predict pupil size (β = 1.859e-03, <italic>t</italic> = .138, <italic>p</italic> = .889). The assymetry effects remained qualitatively unchanged: preparing oblique compared with cardinal saccades resulted in a larger pupil size (β = 7.635, <italic>t</italic> = 3.969, <italic>p</italic> &lt; .001), and preparing downward compared with upward saccades also led to a larger pupil size (β = 3.344, <italic>t</italic> = 3.334, <italic>p</italic> = .003).</p><p>In addition, we have included a new analysis in the supporting information that directly addresses this issue. We will reiterate the main results here:</p><p>“To ascertain whether pupil size or other oculomotor metrics predict saccade preferences, we conducted a multiple regression analysis. We calculated average pupil size, saccade latency, landing precision and peak velocity maps across all 36 directions. The model, determined using AIC-based backward selection, included pupil size, latency and landing precision as predictors (Wilkinson notation: saccade preferences pupil size + saccade latency + landing precision). The analysis re- vealed that pupil size (β = -42.853, t = 4.791, p &lt; .001) and saccade latency (β = -.377, t = 2.106, p = .043) predicted saccade preferences. Landing precision did not reach significance (β = 23.631, t = 1.675, p = .104). Together, this demonstrates that although other oculomotor metrics such as saccade latency contribute to saccade selection, pupil size remains a robust marker of saccade selection.”</p><p>We have also added this point in our discussion:</p><p>“We here measured cost as the degree of effort-linked pupil dilation. In addition to pupil size, other markers may also indicate saccade costs. For example, saccade latency has been proposed to index oculomotor effort [100], whereby saccades with longer latencies are associated with more oculomotor effort. This makes saccade latency a possible complementary marker of saccade costs (also see Supplemen- tary Materials). Although relatively sluggish, pupil size is a valuable measure of attentional costs for (at least) two reasons. First, pupil size is a highly established as marker of effort, and is sensitive to effort more broadly than only in the context of saccades [36–45, 48]. Pupil size therefore allows to capture not only the costs of saccades, but also of covert attentional shifts [33], or shifts with other effectors such as head or arm movements [54, 101]. Second, as we have demonstrated, pupil size can measure saccade costs even when searching in natural scenes (Figure 4). During natural viewing, it is difficult to disentangle fixation duration from saccade latencies, complicating the use of saccade latency as a measure of saccade cost. Together, pupil size, saccade latency, and potential other markers of saccade cost could fulfill complementary roles in studying the role of cost in saccade selection.”</p><p>References</p><p>Alnæs, D., Sneve, M. H., Espeseth, T., Endestad, T., van de Pavert, S. H. P., &amp; Laeng, B. (2014). Pupil size signals mental eFort deployed during multiple object tracking and predicts brain activity in the dorsal attention network and the locus coeruleus. Journal of Vision, 14(4), 1. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/14.4.1">https://doi.org/10.1167/14.4.1</ext-link></p><p>Awh, E., Belopolsky, A. V., &amp; Theeuwes, J. (2012). Top-down versus bottom-up attentional control: A failed theoretical dichotomy. Trends in Cognitive Sciences, 16(8), 437–443. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2012.06.010">https://doi.org/10.1016/j.tics.2012.06.010</ext-link></p><p>Ballard, D. H., Hayhoe, M. M., &amp; Pelz, J. B. (1995). Memory Representations in Natural Tasks. Journal of Cognitive Neuroscience, 7(1), 66–80. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.1995.7.1.66">https://doi.org/10.1162/jocn.1995.7.1.66</ext-link></p><p>Beatty, J. (1982). Task-evoked pupillary responses, processing load, and the structure of processing resources. Psychological Bulletin, 91(2), 276–292. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-2909.91.2.276">https://doi.org/10.1037/0033-2909.91.2.276</ext-link></p><p>Bumke, O. (1911). Die Pupillenstörungen bei Geistes-und Nervenkrankheiten (2nd ed.). Fischer.</p><p>Curthoys, I. S., Markham, C. H., &amp; Furuya, N. (1984). Direct projection of pause neurons to nystagmusrelated excitatory burst neurons in the cat pontine reticular formation. Experimental Neurology, 83(2), 414–422. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0014-4886(84)90109-2">https://doi.org/10.1016/S0014-4886(84)90109-2</ext-link></p><p>David, L., Vassena, E., &amp; Bijleveld, E. (2024). The unpleasantness of thinking: A meta-analytic review of the association between mental eFort and negative aFect. Psychological Bulletin, 150(9), 1070–1093. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/bul0000443">https://doi.org/10.1037/bul0000443</ext-link></p><p>de Gee, J. W., Knapen, T., &amp; Donner, T. H. (2014). Decision-related pupil dilation reflects upcoming choice and individual bias. Proceedings of the National Academy of Sciences, 111(5), E618–E625. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1317557111">https://doi.org/10.1073/pnas.1317557111</ext-link></p><p>Deubel, H., &amp; Schneider, W. X. (1996). Saccade target selection and object recognition: Evidence for a common attentional mechanism. Vision Research, 36(12), 1827–1837. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0042-6989(95)00294-4">https://doi.org/10.1016/0042-6989(95)00294-4</ext-link></p><p>Greenwood, J. A., Szinte, M., Sayim, B., &amp; Cavanagh, P. (2017). Variations in crowding, saccadic precision, and spatial localization reveal the shared topology of spatial vision. Proceedings of the National Academy of Sciences, 114(17), E3573–E3582. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1615504114">https://doi.org/10.1073/pnas.1615504114</ext-link></p><p>Hanning, N. M., Himmelberg, M. M., &amp; Carrasco, M. (2024). Presaccadic Attention Depends on Eye Movement Direction and Is Related to V1 Cortical Magnification. Journal of Neuroscience, 44(12). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1023-23.2023">https://doi.org/10.1523/JNEUROSCI.1023-23.2023</ext-link></p><p>Himmelberg, M. M., Winawer, J., &amp; Carrasco, M. (2023). Polar angle asymmetries in visual perception and neural architecture. Trends in Neurosciences, 46(6), 445–458. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2023.03.006">https://doi.org/10.1016/j.tins.2023.03.006</ext-link></p><p>Jepma, M., &amp; Nieuwenhuis, S. (2011). Pupil Diameter Predicts Changes in the Exploration–Exploitation Trade-oF: Evidence for the Adaptive Gain Theory. Journal of Cognitive Neuroscience, 23(7), 1587– 1596. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2010.21548">https://doi.org/10.1162/jocn.2010.21548</ext-link></p><p>Kahneman, D. (1973). Attention and Effort. Prentice-Hall.</p><p>Kahneman, D., &amp; Beatty, J. (1966). Pupil diameter and load on memory. Science (New York, N.Y.), 154(3756), 1583–1585. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.154.3756.1583">https://doi.org/10.1126/science.154.3756.1583</ext-link></p><p>King, W. M., &amp; Fuchs, A. F. (1979). Reticular control of vertical saccadic eye movements by mesencephalic burst neurons. Journal of Neurophysiology, 42(3), 861–876. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1979.42.3.861">https://doi.org/10.1152/jn.1979.42.3.861</ext-link></p><p>Koevoet, D., Strauch, C., Naber, M., &amp; Van der Stigchel, S. (2023). The Costs of Paying Overt and Covert Attention Assessed With Pupillometry. Psychological Science, 34(8), 887–898. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/09567976231179378">https://doi.org/10.1177/09567976231179378</ext-link></p><p>Koevoet, D., Strauch, C., Van der Stigchel, S., Mathôt, S., &amp; Naber, M. (2024). Revealing visual working memory operations with pupillometry: Encoding, maintenance, and prioritization. WIREs Cognitive Science, e1668. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/wcs.1668">https://doi.org/10.1002/wcs.1668</ext-link></p><p>Kowler, E., Anderson, E., Dosher, B., &amp; Blaser, E. (1995). The role of attention in the programming of saccades. Vision Research, 35(13), 1897–1916. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0042-6989(94)00279-U">https://doi.org/10.1016/0042-6989(94)00279-U</ext-link></p><p>Laeng, B., Sirois, S., &amp; Gredebäck, G. (2012). Pupillometry: A Window to the Preconscious? Perspectives on Psychological Science, 7(1), 18–27. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1745691611427305">https://doi.org/10.1177/1745691611427305</ext-link></p><p>Loewenfeld, I. E. (1958). Mechanisms of reflex dilatation of the pupil. Documenta Ophthalmologica, 12(1), 185–448. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00913471">https://doi.org/10.1007/BF00913471</ext-link></p><p>Mathôt, S. (2018). Pupillometry: Psychology, Physiology, and Function. Journal of Cognition, 1(1), 16. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5334/joc.18">https://doi.org/10.5334/joc.18</ext-link></p><p>Naber, M., &amp; Murphy, P. (2020). Pupillometric investigation into the speed-accuracy trade-oF in a visuomotor aiming task. Psychophysiology, 57(3), e13499. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/psyp.13499">https://doi.org/10.1111/psyp.13499</ext-link></p><p>Nozari, N., &amp; Martin, R. C. (2024). Is working memory domain-general or domain-specific? Trends in Cognitive Sciences, 0(0). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2024.06.006">https://doi.org/10.1016/j.tics.2024.06.006</ext-link></p><p>Reppert, T. R., Heitz, R. P., &amp; Schall, J. D. (2023). Neural mechanisms for executive control of speedaccuracy trade-oF. Cell Reports, 42(11). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.celrep.2023.113422">https://doi.org/10.1016/j.celrep.2023.113422</ext-link></p><p>Richer, F., &amp; Beatty, J. (1985). Pupillary Dilations in Movement Preparation and Execution. Psychophysiology, 22(2), 204–207. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1469-8986.1985.tb01587.x">https://doi.org/10.1111/j.1469-8986.1985.tb01587.x</ext-link></p><p>Robison, M. K., &amp; Brewer, G. A. (2020). Individual diFerences in working memory capacity and the regulation of arousal. Attention, Perception, &amp; Psychophysics, 82(7), 3273–3290. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-020-02077-0">https://doi.org/10.3758/s13414-020-02077-0</ext-link></p><p>Robison, M. K., &amp; Unsworth, N. (2019). Pupillometry tracks fluctuations in working memory performance. Attention, Perception, &amp; Psychophysics, 81(2), 407–419. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-0181618-4">https://doi.org/10.3758/s13414-0181618-4</ext-link></p><p>Sahakian, A., Gayet, S., PaFen, C. L. E., &amp; Van der Stigchel, S. (2023). Mountains of memory in a sea of uncertainty: Sampling the external world despite useful information in visual working memory. Cognition, 234, 105381. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2023.105381">https://doi.org/10.1016/j.cognition.2023.105381</ext-link></p><p>Shadmehr, R., Reppert, T. R., Summerside, E. M., Yoon, T., &amp; Ahmed, A. A. (2019). Movement Vigor as a Reflection of Subjective Economic Utility. Trends in Neurosciences, 42(5), 323–336. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2019.02.003">https://doi.org/10.1016/j.tins.2019.02.003</ext-link></p><p>Silva, M. F., Brascamp, J. W., Ferreira, S., Castelo-Branco, M., Dumoulin, S. O., &amp; Harvey, B. M. (2018). Radial asymmetries in population receptive field size and cortical magnification factor in early visual cortex. NeuroImage, 167, 41–52. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.11.021">https://doi.org/10.1016/j.neuroimage.2017.11.021</ext-link></p><p>Sirois, S., &amp; Brisson, J. (2014). Pupillometry. WIREs Cognitive Science, 5(6), 679–692. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/wcs.1323">https://doi.org/10.1002/wcs.1323</ext-link></p><p>Sparks, D. L. (2002). The brainstem control of saccadic eye movements. Nature Reviews Neuroscience, 3(12), Article 12. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn986">https://doi.org/10.1038/nrn986</ext-link></p><p>Strauch, C., Wang, C.-A., Einhäuser, W., Van der Stigchel, S., &amp; Naber, M. (2022). Pupillometry as an integrated readout of distinct attentional networks. Trends in Neurosciences, 45(8), 635–647. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2022.05.003">https://doi.org/10.1016/j.tins.2022.05.003</ext-link></p><p>Unsworth, N., &amp; Miller, A. L. (2021). Individual DiFerences in the Intensity and Consistency of Attention. Current Directions in Psychological Science, 30(5), 391–400. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/09637214211030266">https://doi.org/10.1177/09637214211030266</ext-link></p><p>Van der Stigchel, S. (2010). Recent advances in the study of saccade trajectory deviations. Vision Research, 50(17), 1619–1627. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2010.05.028">https://doi.org/10.1016/j.visres.2010.05.028</ext-link></p><p>Van der Stigchel, S. (2020). An embodied account of visual working memory. Visual Cognition, 28(5–8), 414–419. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/13506285.2020.1742827">https://doi.org/10.1080/13506285.2020.1742827</ext-link></p><p>Van der Stigchel, S., &amp; Hollingworth, A. (2018). Visuospatial Working Memory as a Fundamental Component of the Eye Movement System. Current Directions in Psychological Science, 27(2), 136–143. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0963721417741710">https://doi.org/10.1177/0963721417741710</ext-link></p><p>van der Wel, P., &amp; van Steenbergen, H. (2018). Pupil dilation as an index of eFort in cognitive control tasks: A review. Psychonomic Bulletin &amp; Review, 25(6), 2005–2015. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13423-018-1432-y">https://doi.org/10.3758/s13423-018-1432-y</ext-link></p></body></sub-article></article>