<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">87048</article-id><article-id pub-id-type="doi">10.7554/eLife.87048</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87048.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Different rules for binocular combination of luminance flicker in cortical and subcortical pathways</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-307386"><name><surname>Segala</surname><given-names>Federico G</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4982-8023</contrib-id><email>fgs502@york.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-333708"><name><surname>Bruno</surname><given-names>Aurelio</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4899-1769</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-325909"><name><surname>Martin</surname><given-names>Joel T</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4475-3835</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-307564"><name><surname>Aung</surname><given-names>Myat T</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-9426"><name><surname>Wade</surname><given-names>Alex R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4871-2747</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-47768"><name><surname>Baker</surname><given-names>Daniel H</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0161-443X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04m01e293</institution-id><institution>Department of Psychology, University of York</institution></institution-wrap><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04h699437</institution-id><institution>School of Psychology and Vision Sciences, University of Leicester</institution></institution-wrap><addr-line><named-content content-type="city">Leicester</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04m01e293</institution-id><institution>York Biomedical Research Institute, University of York</institution></institution-wrap><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Huxlin</surname><given-names>Krystel R</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>University of Rochester</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>26</day><month>09</month><year>2023</year></pub-date><volume>12</volume><elocation-id>RP87048</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-03-07"><day>07</day><month>03</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-02-15"><day>15</day><month>02</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.01.11.523568"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-05-09"><day>09</day><month>05</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87048.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-09-04"><day>04</day><month>09</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87048.2"/></event></pub-history><permissions><copyright-statement>© 2023, Segala et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Segala et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-87048-v1.pdf"/><abstract><p>How does the human brain combine information across the eyes? It has been known for many years that cortical normalization mechanisms implement ‘ocularity invariance’: equalizing neural responses to spatial patterns presented either monocularly or binocularly. Here, we used a novel combination of electrophysiology, psychophysics, pupillometry, and computational modeling to ask whether this invariance also holds for flickering luminance stimuli with no spatial contrast. We find dramatic violations of ocularity invariance for these stimuli, both in the cortex and also in the subcortical pathways that govern pupil diameter. Specifically, we find substantial binocular facilitation in both pathways with the effect being strongest in the cortex. Near-linear binocular additivity (instead of ocularity invariance) was also found using a perceptual luminance matching task. Ocularity invariance is, therefore, not a ubiquitous feature of visual processing, and the brain appears to repurpose a generic normalization algorithm for different visual functions by adjusting the amount of interocular suppression.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>binocular vision</kwd><kwd>EEG</kwd><kwd>pupillometry</kwd><kwd>computational modelling</kwd><kwd>pupillary light reflex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/V007580/1</award-id><principal-award-recipient><name><surname>Baker</surname><given-names>Daniel H</given-names></name><name><surname>Wade</surname><given-names>Alex R</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>10.35802/213616</award-id><principal-award-recipient><name><surname>Bruno</surname><given-names>Aurelio</given-names></name></principal-award-recipient></award-group><funding-statement>For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission. The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Binocular combination of luminance signals exhibits strong interocular suppression in pathways governing the pupil response, and weak interocular suppression in cortical pathways subserving perception.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The brain must combine information across multiple sensory inputs to derive a coherent percept of the external world. This involves a process of signal combination both within (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>) and between (<xref ref-type="bibr" rid="bib23">Ernst and Banks, 2002</xref>) the senses. Binocular vision is a useful test case for signal combination, as the inputs to the two eyes overlap substantially (in species with forward-facing eyes), and the neural locus is well-established (<xref ref-type="bibr" rid="bib28">Hubel and Wiesel, 1962</xref>). Much of our knowledge about binocular combination derives from studies on the contrast response of the ‘canonical’ visual pathway, in which signals pass from the eyes to the primary visual cortex (V1), via the lateral geniculate nucleus (LGN) (<xref ref-type="bibr" rid="bib47">Purves et al., 2008</xref>). However, signals are also combined across the eyes in the network of subcortical nuclei that govern pupil diameter in response to absolute light levels (<xref ref-type="bibr" rid="bib40">McDougal and Gamlin, 2008</xref>), and much less is known about the computations that operate in these subcortical pathways. Our primary purpose here is to investigate the computations governing signal combinations in these two anatomically distinct pathways in response to luminance changes.</p><p>For pattern vision, binocular presentation confers greater sensitivity to low-contrast targets than monocular presentation. This is known as binocular summation, with summation ratios (the relative improvement under binocular presentation) at detection threshold lying between √2 and 2 (<xref ref-type="bibr" rid="bib8">Baker et al., 2018</xref>; <xref ref-type="bibr" rid="bib16">Campbell and Green, 1965</xref>). This advantage is lost at high stimulus contrasts, where both psychophysical performance (contrast discrimination thresholds) (<xref ref-type="bibr" rid="bib32">Legge, 1984</xref>; <xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>) and neural activity (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>; <xref ref-type="bibr" rid="bib44">Moradi and Heeger, 2009</xref>) are approximately equal for monocular and binocular presentation. Contemporary models of binocular vision (<xref ref-type="bibr" rid="bib19">Ding and Sperling, 2006</xref>; <xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>) advocate a process of interocular suppression that normalizes the two eyes’ inputs at high contrasts and negates the binocular advantage. This is consistent with our everyday experience of ‘ocularity invariance’ (<xref ref-type="bibr" rid="bib5">Baker et al., 2007</xref>): perceived contrast does not change when one eye is opened and closed.</p><p>The pupillary light reflex is an automatic constriction of the iris sphincter muscles in response to increases in light levels, which causes the pupil to shrink (<xref ref-type="bibr" rid="bib40">McDougal and Gamlin, 2008</xref>). There is a clear binocular component to this reflex, as stimulation of one eye still causes constriction of the other eye’s pupil (termed the consensual response; <xref ref-type="bibr" rid="bib60">Wyatt and Musselman, 1981</xref>). Importantly, the neuroanatomical pathway involved completely bypasses the canonical cortical pathway (retina to V1), instead involving a network of subcortical nuclei, including the Pretectal Olivary nucleus, Superior Cervical ganglion, and Edinger-Westphal nucleus (<xref ref-type="bibr" rid="bib1">Angée et al., 2021</xref>; <xref ref-type="bibr" rid="bib38">Mathôt, 2018</xref>; <xref ref-type="bibr" rid="bib40">McDougal and Gamlin, 2008</xref>; <xref ref-type="bibr" rid="bib59">Wang and Munoz, 2015</xref>). To account for the consensual response, these brain regions must combine information from the left and right eyes (<xref ref-type="bibr" rid="bib54">ten Doesschate and Alpern, 1967</xref>), yet the computation that achieves this is unclear. The pupil response can be modulated by periodic changes in luminance, and is temporally low-pass (<xref ref-type="bibr" rid="bib12">Barrionuevo et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">Spitschan et al., 2014</xref>), most likely due to the mechanical limitations of the iris sphincter and dilator muscles (<xref ref-type="bibr" rid="bib46">Privitera and Stark, 2006</xref>).</p><p>To investigate the binocular combination of light, we designed an experiment that allowed us to simultaneously record electrophysiological and pupillometric responses to monocular and binocular stimuli. We chose a primary flicker frequency of 2 Hz as a compromise between the low-pass pupil response (see <xref ref-type="bibr" rid="bib12">Barrionuevo et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">Spitschan et al., 2014</xref>), and the relatively higher-pass EEG response (<xref ref-type="bibr" rid="bib49">Regan, 1966</xref>). This novel paradigm allowed us to probe both cortical (using EEG) and subcortical (using a binocular eye tracker) pathways simultaneously in response to flickering light, and make quantitative comparisons between them. Periodic flicker entrains both neural (<xref ref-type="bibr" rid="bib45">Norcia et al., 2015</xref>) and pupil (<xref ref-type="bibr" rid="bib52">Spitschan et al., 2014</xref>) responses at the flicker frequency, enabling precise estimation of response amplitudes in the Fourier domain. Relative to the response to a monocular signal, adding a signal in the other eye can either increase the response (facilitation) or reduce it (suppression). We followed up our main experiment with an additional exploration of the effect of stimulus frequency, and a psychophysical matching experiment measuring perceived flicker intensity (i.e. temporal contrast). The results are interpreted using a hierarchical Bayesian computational model of binocular vision, and reveal that subcortical pathways implement stronger interocular suppression than the canonical cortical pathway.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experiment 1</title><p>The pupillometry results are summarized in <xref ref-type="fig" rid="fig1">Figure 1</xref>. The group average waveform for binocular presentation is shown in <xref ref-type="fig" rid="fig1">Figure 1a</xref>. There is a substantial pupil constriction at stimulus onset, followed by visible oscillations at the flicker frequency (2 Hz, see waveform at foot). The average Fourier spectrum is displayed in <xref ref-type="fig" rid="fig1">Figure 1b</xref>, and shows a clear spike at 2 Hz, but no evidence of a second harmonic response at 4 Hz (though see Appendix 1). These results demonstrate that our paradigm can evoke measurable steady-state pupil responses at 2 Hz.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Summary of pupillometry results for N=30 participants.</title><p>Panel (<bold>a</bold>) shows a group average waveform for binocular presentation (low pass filtered at 5 Hz), with the driving signal plotted at the foot. Negative values indicate constriction relative to baseline, and positive values indicate dilation. Panel (<bold>b</bold>) shows the average Fourier spectrum (absolute amplitude values). Panels (<bold>c, d</bold>) show contrast response functions for pupil diameter at 2 Hz for different conditions (illustrated in <xref ref-type="fig" rid="fig8">Figure 8</xref>). Panel (<bold>e</bold>) shows contrast response functions at 1.6 Hz for three conditions. Shaded regions and error bars indicate bootstrapped standard errors.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig1-v1.tif"/></fig><p><xref ref-type="fig" rid="fig1">Figure 1c</xref> shows contrast response functions driven by stimuli flickering only at 2 Hz. Response amplitudes increased monotonically with target contrast, confirming that our paradigm is suitable for measuring contrast-dependent differences in the pupil response (to our knowledge this is the first time this has been demonstrated). The amplitude of the binocular condition (blue squares) is consistently greater than that of the monocular condition (red circles) across all target contrasts. A <inline-formula><mml:math id="inf1"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> repeated measures <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib10">Baker, 2021</xref>) comparing these conditions revealed a significant main effect of target contrast (F(8, 580) = 16.79,  p&lt;0.001), a significant effect of condition (F(2, 580) = 11.04,  p&lt;0.001), and a significant interaction (F(8, 580) = 56.25, p&lt;0.001). The dichoptic condition begins at a much higher amplitude, owing to the binocular combination of the target and high (48%) contrast mask, and then increases slightly with increasing target contrast (main effect of target contrast: F(8, 232) = 3.03, p&lt;0.003).</p><p>In <xref ref-type="fig" rid="fig1">Figure 1d</xref>, we plot responses to monocular target stimuli flickering at 2 Hz, when the other eye viewed stimuli flickering at 1.6 Hz (the red monocular-only data are replotted from <xref ref-type="fig" rid="fig1">Figure 1c</xref> for comparison). When the 1.6 Hz component had the same contrast as the target (the binocular cross condition, shown in purple) responses were facilitated slightly at low contrasts, and suppressed at the highest target contrasts (interaction between contrast and condition: F(8, 580) = 52.94, p&lt;0.001). When the 1.6 Hz component had a fixed contrast of 48% (the dichoptic cross condition, shown in yellow), responses were suppressed slightly across the contrast range (interaction between contrast and condition: F(8, 580) = 62.05, p&lt;0.001).</p><p><xref ref-type="fig" rid="fig1">Figure 1e</xref> shows responses at 1.6 Hz, for the same conditions, as well as for a condition in which a monocular stimulus flickered at 1.6 Hz (gray circles). Here, we find strong suppression in both the binocular cross (purple triangles) and dichoptic cross (yellow triangles) conditions. In the binocular cross condition, the amplitudes are reduced relative to the monocular condition (gray circles) (interaction effect: F(8, 580) = 41.23, p&lt;0.001). In the dichoptic cross condition, increasing the 2 Hz target contrast suppresses the response to the 1.6 Hz mask, and the function decreases (see e.g. <xref ref-type="bibr" rid="bib15">Busse et al., 2009</xref>) (main effect of target contrast F(8, 232) = 17, p&lt;0.001).</p><p><xref ref-type="fig" rid="fig2">Figure 2</xref> shows equivalent results, measured contemporaneously using EEG. <xref ref-type="fig" rid="fig2">Figure 2a</xref> shows the group average waveform for binocular presentation, and <xref ref-type="fig" rid="fig2">Figure 2b</xref> shows the Fourier spectrum for binocular presentation, both averaged across four posterior electrodes (<italic>Oz</italic>, <italic>POz</italic>, <italic>O1,</italic> and <italic>O2</italic>, marked on the inset scalp plots). Unlike for the pupillometry data, there are clear responses at both the first harmonic frequency (2 Hz), and also the second harmonic frequency (4 Hz). We therefore calculated contrast response functions at both first and second harmonic frequencies.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Summary of EEG results for N=30 participants.</title><p>Panel (<bold>a</bold>) shows a group average waveform for binocular presentation (low pass filtered at 5 Hz), with the driving signal plotted at the foot. Panel (<bold>b</bold>) shows the average Fourier spectrum, and inset scalp distributions. Black dots on the scalp plots indicate electrodes <italic>Oz</italic>, <italic>POz</italic>, <italic>O1</italic>, and <italic>O2</italic>. Panels (<bold>c, d</bold>) show contrast response functions at 2 Hz for different conditions. Panel (<bold>e</bold>) shows contrast response functions at 1.6 Hz for three conditions. Panels (<bold>f–h</bold>) are in the same format but for the second harmonic response. Shaded regions and error bars indicate bootstrapped standard errors.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig2-v1.tif"/></fig><p>When stimuli in both eyes flicker at 2 Hz, the binocular responses at the first (<xref ref-type="fig" rid="fig2">Figure 2c</xref>) and second (<xref ref-type="fig" rid="fig2">Figure 2f</xref>) harmonics are substantially greater than the monocular responses, particularly at high contrasts. Analysis of variance on the complex values (<inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>) revealed a main effect of contrast (F(8, 580) = 4.38, p&lt;0.001) and an interaction effect (F(8, 580) = 61.58, p&lt;0.001), but no effect of condition (p=0.13) at the first harmonic, with a similar pattern of results obtained at the second harmonic. For the cross-frequency conditions (<xref ref-type="fig" rid="fig2">Figure 2d and g</xref>), there was no appreciable effect of adding a 1.6 Hz component on the response at 2 Hz or 4 Hz (no effect of condition, and no interaction). Similarly, there were no clear interocular interactions between frequencies in the responses at 1.6 Hz (<xref ref-type="fig" rid="fig2">Figure 2e</xref>) and 3.2 Hz (<xref ref-type="fig" rid="fig2">Figure 2h</xref>). This pattern of results suggests that the processing of temporal luminance modulations happens in a more linear way in the visual cortex (indexed by EEG), compared with subcortical pathways (indexed by pupillometry), and shows no evidence of interocular suppression.</p><p>Finally, we calculated the ratio of binocular to monocular responses across the three data types from Experiment 1. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows that these ratios are approximately √2 across the low-to-intermediate contrast range for all three data types. At higher contrasts, we see ratios of 2 or higher for the EEG data, but much weaker ratios near 1 for the pupillometry data. Note that the ratios here are calculated on a per-participant basis and then averaged, rather than being the ratios of the average values shown in <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>. A <inline-formula><mml:math id="inf4"><mml:mrow><mml:mn>3</mml:mn><mml:mo>×</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> repeated measures ANOVA on the logarithmic (dB) ratios found a main effect of contrast (F(3.08, 89.28)=4.53, p&lt;0.002), no effect of data modality (F(2, 58) = 0.75, p=0.48), but a highly significant interaction (F(5.54, 160.67)=3.84, p&lt;0.001). All of the key results from Experiment 1 were subsequently replicated for peripheral stimulation (see Appendix 1).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Ratio of binocular to monocular response for three data types.</title><p>These were calculated by dividing the binocular response by the monocular response at each contrast level, using the data underlying <xref ref-type="fig" rid="fig1">Figure 1c</xref> and <xref ref-type="fig" rid="fig2">Figure 2c, f</xref>. Each value is the average ratio across N=30 participants, and error bars indicate bootstrapped standard errors.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig3-v1.tif"/></fig></sec><sec id="s2-2"><title>Experiment 2</title><p>The strong binocular facilitation and weak interocular suppression in the EEG data from Experiment 1 were very different from previous findings on binocular combination using steady-state EEG with grating stimuli (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>). One possible explanation is that the lower temporal frequency used here (2 Hz, vs 5 or 7 Hz in previous work) might be responsible for this difference. We, therefore, ran a second experiment to compare monocular and binocular responses at a range of temporal frequencies. Only EEG data were collected for this experiment, as the pupil response is substantially weaker above around 2 Hz (<xref ref-type="bibr" rid="bib12">Barrionuevo et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">Spitschan et al., 2014</xref>); note that we originally chose 2 Hz because it produces measurable signals for both EEG and pupillometry, yet is unfortunately optimal for neither.</p><p>Results from the temporal frequency experiment are shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>. <xref ref-type="fig" rid="fig4">Figure 4a</xref> shows the Fourier spectra for responses to binocular flicker at 5 different frequencies (2, 4, 8, 16, and 30 Hz). From 2–16 Hz, clear signals are observed at each fundamental frequency, and typically also their higher harmonics (integer multiples of the fundamental). However, at 30 Hz (upper row), the responses recorded were not demonstrably above the noise baseline. <xref ref-type="fig" rid="fig4">Figure 4b</xref> compares the monocular and binocular responses at each stimulation frequency. Here, we replicate the substantial summation effect across frequencies up to and including 16 Hz (<xref ref-type="fig" rid="fig4">Figure 4c</xref>), demonstrating that strong binocular facilitation in the EEG data of Experiment 1 cannot be attributed to our use of 2 Hz flicker.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Binocular facilitation at different temporal frequencies, measured using EEG.</title><p>Panel (<bold>a</bold>) shows Fourier spectra for responses to binocular flicker at five different frequencies (offset vertically for clarity). Panel (<bold>b</bold>) shows the response at each stimulation frequency for monocular (red circles) and binocular (blue squares) presentation. Panel (<bold>c</bold>) shows the ratio of binocular to monocular responses. Error bars and shaded regions indicate bootstrapped standard errors across N=12 participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig4-v1.tif"/></fig></sec><sec id="s2-3"><title>Experiment 3</title><p>In Experiment 1, we found evidence of stronger binocular facilitation for cortical responses to luminance flicker (measured using EEG), compared with subcortical responses (measured using pupillometry; see <xref ref-type="fig" rid="fig3">Figure 3</xref>). Since perception is dependent on cortical responses, these results provide a clear prediction for perceived contrast judgments indexed by psychophysical contrast matching paradigms (e.g. <xref ref-type="bibr" rid="bib2">Anstis and Ho, 1998</xref>; <xref ref-type="bibr" rid="bib31">Legge and Rubin, 1981</xref>; <xref ref-type="bibr" rid="bib33">Levelt, 1965</xref>; <xref ref-type="bibr" rid="bib48">Quaia et al., 2018</xref>). We therefore conducted such an experiment, in which participants judged which of two stimuli had the greater perceived amplitude of flicker. On each trial, one stimulus was a matching stimulus, that had a fixed binocular flicker amplitude of either 24% or 48% (temporal) contrast. The other stimulus was a target stimulus, the contrast of which was controlled by a staircase algorithm. We tested 9 ratios of target contrast between the left and right eyes.</p><p>The results from the matching experiment are shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Each data point indicates the contrast levels required in each eye that were perceptually equivalent to the binocular 24% (red circles) and 48% (blue circles) matching contrasts. At both matching contrasts, we see a very substantial increase in the physical contrast required for a monocular target (data points along the <italic>x</italic>- and <italic>y</italic>-axes), compared to a binocular target (points along the diagonal of <italic>x</italic>=<italic>y</italic>). For example with a 48% match, the monocular targets required contrasts close to 100%, whereas binocular targets required a contrast of around 50%. The data points between these extremes also fall close to the predictions of a linear summation model (diagonal dotted lines), and are inconsistent with a winner-takes-all (or MAX) model (dashed lines). Overall, these matching results are consistent with the approximately linear summation effects observed in the EEG data of Experiment 1 (<xref ref-type="fig" rid="fig2">Figure 2c and f</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Contrast matching functions.</title><p>Dotted and dashed lines are predictions of canonical summation models involving linear combination (dotted) or a winner-take-all rule (dashed). Error bars indicate the standard error across participants (N=10), and are constrained along radial lines converging at the origin. Note that, for the 48% match, the data point on the x-axis falls higher than 100% contrast. This is because the psychometric function fits for some individuals were interpolated such that the PSE fell above 100%, shifting the mean slightly above that value.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig5-v1.tif"/></fig></sec><sec id="s2-4"><title>Computational modeling</title><p>We fitted a computational model to the data from Experiments 1 &amp; 3 using a hierarchical Bayesian approach. The model behavior is displayed in <xref ref-type="fig" rid="fig6">Figure 6a–d</xref>, with empirical data superimposed for comparison. In general, the model captures the key characteristics of the empirical data, with group-level parameter estimates provided in <xref ref-type="table" rid="table1">Table 1</xref>. We were particularly interested in comparing the weight of interocular suppression across datasets. We therefore plot the posterior distributions for this parameter for all four datasets (see <xref ref-type="fig" rid="fig6">Figure 6e</xref>). The key finding is that the pupillometry results (green distribution) display a much greater weight of interocular suppression compared with the other dataets (gray, purple, and yellow distributions). There is no overlap between the pupillometry distribution and any of the other three. All four distributions are also meaningfully below a weight of 1 – the value that previous work using grating stimuli would predict (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>; <xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>), and the peak location of our prior distribution (black curve). These results offer an explanation of the empirical data: the strong interocular suppression for the pupillometry data is consistent with the weak binocular facilitation, and measurable dichoptic masking observed using that method. The weaker suppression for the other experiments is consistent with the near-linear binocular facilitation effects, and absent dichoptic masking.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Summary of computational modeling.</title><p>Panels (<bold>a–d</bold>) show empirical data from key conditions, replotted from earlier figures for the pupillometry (<bold>a</bold>), first harmonic EEG responses (<bold>b</bold>), second harmonic EEG responses (<bold>c</bold>) and contrast matching (<bold>d</bold>) experiments, with curves showing model behavior generated using the median group-level parameter values. Panel (<bold>e</bold>) shows the posterior probability distributions of the interocular suppression parameter for each of the four model fits. The pupillometry distribution (green) is centered about a substantially higher suppressive weight than for the other data types (note the logarithmic x-axis). The black curve shows the (scaled) prior distribution for the weight parameter.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig6-v1.tif"/></fig><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Summary of median parameter values.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Dataset</th><th align="left" valign="bottom">Z</th><th align="left" valign="bottom">n</th><th align="left" valign="bottom">w</th><th align="left" valign="bottom">Rmax</th></tr></thead><tbody><tr><td align="left" valign="bottom">Pupillometry</td><td align="char" char="." valign="bottom">3.44</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.61</td><td align="char" char="." valign="bottom">0.00023</td></tr><tr><td align="left" valign="bottom">EEG 1 F</td><td align="char" char="." valign="bottom">2.62</td><td align="char" char="." valign="bottom">0.15</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.00336</td></tr><tr><td align="left" valign="bottom">EEG 2 F</td><td align="char" char="." valign="bottom">3.71</td><td align="char" char="." valign="bottom">0.07</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.0031</td></tr><tr><td align="left" valign="bottom">Matching</td><td align="char" char="." valign="bottom">0.30</td><td align="char" char="." valign="bottom">5.10</td><td align="char" char="." valign="bottom">0.09</td><td align="left" valign="bottom">-</td></tr></tbody></table></table-wrap></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Using a novel paradigm that combines EEG and pupillometry, we found surprising results for the binocular integration of flickering light. In the visual cortex response (indexed by EEG), the binocular combination of spatially uniform temporal luminance modulations seems to happen approximately linearly, with no evidence of interocular suppression. Evidence for this comes from the substantial binocular facilitation effect when comparing monocular and binocular responses, and the lack of a dichoptic suppression effect when the two eyes were stimulated at different frequencies. In the subcortical pathway (indexed by pupillometry), the binocular combination is more non-linear, with evidence of interocular suppression. This was evidenced by a weaker binocular facilitation, and stronger dichoptic suppression, relative to the EEG data. This pattern of results was confirmed by computational modeling, which showed a much greater suppressive weight for the pupillometry data compared to the EEG data. Additionally, we found that the perception of flickering light is consistent with a near-linear binocular summation process, consistent with the cortical (EEG) responses.</p><p>The results of our main experiment were unexpected for both the pupillometry and the EEG measures. Previous studies investigating binocular combination of spatial patterns (i.e. sine wave grating stimuli) are generally consistent with strong interocular suppression and weak binocular facilitation at high contrasts (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>; <xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>; <xref ref-type="bibr" rid="bib44">Moradi and Heeger, 2009</xref>) (however, we note that facilitation as substantial as ours has been reported in previous EEG work by <xref ref-type="bibr" rid="bib3">Apkarian et al., 1981</xref>). Our second experiment ruled out the possibility that these differences were due to the lower temporal frequency (2 Hz) used here. However, there is evidence of more extensive binocular facilitation for a range of other stimuli. Using scleral search coils, <xref ref-type="bibr" rid="bib48">Quaia et al., 2018</xref> observed a strong binocular facilitation (or ‘supersummation’) in the reflexive eye movement response to rapidly moving stimuli (also known as the ocular following response). <xref ref-type="bibr" rid="bib53">Spitschan and Cajochen, 2019</xref> report a similar result in archival data on melatonin suppression due to light exposure (melatonin is a hormone released by the pineal gland that regulates sleep; its production is suppressed by light exposure and can be measured from saliva assays). Work on the accommodative response indicates that binocular combination is approximately linear (<xref ref-type="bibr" rid="bib25">Flitcroft et al., 1992</xref>), and can even cancel when signals are in antiphase (we did not try this configuration here). In the auditory system, interaural suppression of amplitude modulation also appears to be weak when measured using a similar steady-state paradigm (<xref ref-type="bibr" rid="bib9">Baker et al., 2020</xref>). Finally, psychophysical matching experiments using static stimuli also show near-linear behavior for luminance increments (<xref ref-type="bibr" rid="bib2">Anstis and Ho, 1998</xref>; <xref ref-type="bibr" rid="bib6">Baker et al., 2012</xref>; <xref ref-type="bibr" rid="bib33">Levelt, 1965</xref>), though not for luminance decrements (<xref ref-type="bibr" rid="bib2">Anstis and Ho, 1998</xref>). Overall, this suggests that strong interocular normalization may be specific to spatial pattern vision, and not a general feature of binocular signal combination (or combination across multiple inputs in other senses).</p><p>Given the above, where does this leave our understanding of the overarching purpose of signal combination? <xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref> point out that strong suppression between channels that are subsequently summed is equivalent to a Kalman filter, which is the optimal method for combining two noisy inputs (see also <xref ref-type="bibr" rid="bib23">Ernst and Banks, 2002</xref>). Functionally, interocular suppression may, therefore, act to dynamically suppress noise, rendering binocular vision more stable. This account has intuitive appeal and is consistent with other models that propose binocular combination as a means of redundancy reduction (<xref ref-type="bibr" rid="bib34">Li and Atick, 1994</xref>; <xref ref-type="bibr" rid="bib39">May and Zhaoping, 2022</xref>). One possibility is that optimal combination is useful for visual perception — a critical system for interacting with the local environment — and is, therefore, worth devoting the additional resource of inhibitory wiring between ocular channels. However, the other examples of binocular combination discussed above are primarily physiological responses (pupil size, eye movements, hormone release) that may benefit more from an increased signal-to-noise ratio, or otherwise be phylogenetically older than binocular pattern vision. Conceptualized another way, the brain can repurpose a generic architecture for different situational demands by adjusting parameter values (here the weight of interocular suppression) to achieve different outcomes. Our future work in this area intends to compare binocular combinations for specific photoreceptor pathways, including different cone classes, and intrinsically photoreceptive retinal ganglion cells.</p><p>Pupil size affects the total amount of light falling on the retina. It is, therefore, the case that fluctuations in pupil diameter will have a downstream effect on the signals reaching cortex. We did not incorporate such interactions into our computational model, though in principle this might be worthwhile. However, we anticipate that any such effects would be small since pupil modulations at 2 Hz are in the order of 2% of overall diameter (e.g. <xref ref-type="bibr" rid="bib52">Spitschan et al., 2014</xref>). It is also the case that cortical activity can modulate pupil diameter, usually through arousal and attention mechanisms (e.g. <xref ref-type="bibr" rid="bib14">Bradley et al., 2008</xref>). We think it unlikely that these temporally coarse processes would have a differential effect on e.g., monocular and binocular stimulation conditions in our experiment, and any fluctuations during an experimental session (perhaps owing to fatigue) will be equivalent for our comparisons of interest. Therefore, we make the simplifying assumption that the pupil and perceptual pathways are effectively distinct, but hope to investigate this more directly in future neuroimaging work. Using fMRI to simultaneously image cortical and subcortical brain regions will also allow us to check that the differences we report here are not a consequence of the different measurement techniques we used (pupillometry and EEG).</p><p>Classic studies investigating the neurophysiological architecture of V1 reported that cells in cytochrome-oxidase ‘blobs’ (<xref ref-type="bibr" rid="bib27">Horton and Hubel, 1981</xref>; <xref ref-type="bibr" rid="bib35">Livingstone and Hubel, 1984</xref>) are biased towards low spatial frequencies (<xref ref-type="bibr" rid="bib22">Edwards et al., 1995</xref>; <xref ref-type="bibr" rid="bib55">Tootell et al., 1988</xref>), and relatively insensitive to stimulus orientation (<xref ref-type="bibr" rid="bib27">Horton and Hubel, 1981</xref>; <xref ref-type="bibr" rid="bib35">Livingstone and Hubel, 1984</xref>; though see <xref ref-type="bibr" rid="bib21">Economides et al., 2011</xref>). As the blob regions are embedded within ocular dominance columns (<xref ref-type="bibr" rid="bib27">Horton and Hubel, 1981</xref>), they are also largely monocular (<xref ref-type="bibr" rid="bib35">Livingstone and Hubel, 1984</xref>; <xref ref-type="bibr" rid="bib57">Tychsen et al., 2004</xref>). More recent work has reported psychophysical evidence for unoriented chromatic (<xref ref-type="bibr" rid="bib26">Gheiratmand et al., 2013</xref>) and achromatic (<xref ref-type="bibr" rid="bib43">Meese and Baker, 2011</xref>) mechanisms, that also appear to be monocular. Our use of luminance flicker might preferentially stimulate these mechanisms, perhaps explaining why our EEG data show little evidence of binocular interactions. Indeed, our EEG results could potentially be explained by a model involving entirely non-interacting monocular channels, with the binocular facilitation effects we find (e.g. <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>) owing to additivity of the electrophysiological response across independent monocular cells, rather than within binocular neurons. We, therefore, performed an additional analysis to investigate this possibility.</p><p>In the steady-state literature, one hallmark of a nonlinear system that pools inputs is the presence of intermodulation responses at the sums and differences of the fundamental flicker frequencies (<xref ref-type="bibr" rid="bib4">Baitch and Levi, 1988</xref>; <xref ref-type="bibr" rid="bib56">Tsai et al., 2012</xref>). In <xref ref-type="fig" rid="fig7">Figure 7</xref> we plot the amplitude spectra of conditions from Experiment 1 in which the two eyes were stimulated at different frequencies (2 Hz and 1.6 Hz) but at the same contrast (48%; these correspond to the binocular cross and dichoptic cross conditions in <xref ref-type="fig" rid="fig1">Figures 1d, e ,</xref>, <xref ref-type="fig" rid="fig2">2d and e</xref>). <xref ref-type="fig" rid="fig7">Figure 7a</xref> reveals a strong intermodulation difference response at 0.4 Hz (red dashed line), and <xref ref-type="fig" rid="fig7">Figure 7b</xref> reveals an intermodulation sum response at 3.6 Hz (red dashed line). It seems likely that the absence of a sum response for pupillometry data, and of a difference responses for the EEG data, is a consequence of the temporal constraints of these methods. The presence of intermodulation terms is predicted by nonlinear gain control models of the type considered here (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>; <xref ref-type="bibr" rid="bib56">Tsai et al., 2012</xref>), and indicates that the processing of monocular flicker signals is not fully linear prior to the point at which they are combined across the eyes. Indeed, our model architecture (<xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>) makes specific predictions about the location of interocular suppression - it impacts before binocular combination, consistent with results from primate physiology (<xref ref-type="bibr" rid="bib20">Dougherty et al., 2019</xref>).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Summary of intermodulation responses in pupillometry (<bold>a</bold>) and EEG (<bold>b</bold>) data.</title><p>The data are pooled across the binocular cross and dichoptic cross conditions of Experiment 1, with a target contrast of 48%. Vertical dashed lines indicate the fundamental flicker frequencies of 2 Hz (F1; black) and 1.6 Hz (F2; green), and the intermodulation difference (F1-F2=0.4 Hz) and sum (F1+F2=3.6 Hz) frequencies (red). Data are averaged across N=30 participants, and shaded regions indicate ±1 standard error.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig7-v1.tif"/></fig><sec id="s3-1"><title>Conclusions</title><p>We have demonstrated that the binocular combination of flickering light differs between cortical and subcortical pathways. Flicker was also associated with substantially weaker interocular suppression, and stronger binocular facilitation, compared to the combination of spatial luminance modulations in the visual cortex. Our computational framework for understanding signal combination permits direct comparisons between disparate experimental paradigms and data types. We anticipate that this will help elucidate the constraints the brain faces when combining different types of signals to govern perception, action, and biological function.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Participants</title><p>Thirty (20 females), twelve (seven females), and ten (three females) adult participants, whose ages ranged from 18 to 45, were recruited for Experiments 1, 2, and 3, respectively. All participants had normal or corrected to normal binocular vision, and gave written informed consent. Our procedures were approved by the Ethics Committee of the Department of Psychology at the University of York (identification number 792).</p></sec><sec id="s4-2"><title>Apparatus &amp; stimuli</title><p>The stimuli were two discs of achromatic flickering light with a diameter of 3.74 degrees, presented on a black background. The same stimuli were used for all three experiments. Four dark red lines were added around both discs to help with their perceptual fusion, giving the appearance of a single binocular disc (see upper left insert in <xref ref-type="fig" rid="fig8">Figure 8</xref> for an example of the fused stimulus). The discs were viewed through a four-mirror stereoscope, which used front silvered mirrors to avoid internal reflections, and meant that participants saw a single fused disc. The use of a stereoscope allowed us to modulate the stimuli in three different ocular configurations: monocular, binocular, and dichoptic. Note that during the monocular presentation of flicker, the unstimulated eye still saw the static (non-flickering) disc of mean luminance.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Schematic diagram illustrating the ocular arrangements, and temporal waveforms of the luminance modulations used in Experiment 1.</title><p>Shaded waveforms indicate a target stimulus, that was presented at one of five contrasts on each trial (denoted by the shading levels). Unshaded waveforms indicate mask stimuli, that were presented at a fixed contrast level of 48% regardless of the target contrast. Each waveform corresponds to a 1 s period of a 12 s trial, and coloured symbols are for consistency with <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref>. The icon in the upper left corner illustrates the stimulus appearance (a luminous disc against a black background). The left and right eye assignments were counterbalanced across trials in the experiment (i.e. the monocular stimulus could be shown to either eye with equal probability).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-fig8-v1.tif"/></fig><p>All stimuli had a mean luminance of 42 cd/m<sup>2</sup> and were displayed on an Iiyama VisionMaster Pro 510 display (800 × 600 pixels, 60 Hz refresh rate), which was gamma-corrected using a Minolta LS-110 photometer (Minolta Camera Co. Ltd., Japan). For experiments 1 and 2, the stimuli were presented using Psychopy (v3.0.7). For experiment 3, the stimuli were presented using Psychopy (v2022.1.1).</p><p>EEG data were collected for Experiments 1 and 2 using a 64-electrode ANT WaveGuard cap and the signals were recorded at 1 kHz using the ASA software (ANT Neuro, Netherlands). Pupillometry data were collected for Experiment 1 using a binocular Pupil Core eye-tracker (Pupil Labs GmbH, Berlin, Germany; <xref ref-type="bibr" rid="bib29">Kassner et al., 2014</xref>) running at 120 Hz, and the signals were recorded with the Pupil Capture software.</p></sec><sec id="s4-3"><title>Procedure</title><p>Before each experiment, participants adjusted the angle of the stereoscope mirrors to achieve binocular fusion. This was done so that they would perceive the two discs as one fused disc when looking at the screen through the stereoscope.</p><sec id="s4-3-1"><title>Experiment 1: simultaneous EEG and pupillometry</title><p>The experiment was conducted in a windowless room, in which the only light source was the monitor. The participants sat at 99 cm from the monitor and the total optical viewing distance (through the stereoscope) was 107 cm. The experiment was carried out in a single session lasting 45 min in total, divided into three blocks of 15 min each. In each block, there were 60 trials lasting 15 s each (12 s of stimulus presentation, with an interstimulus interval of 3 s). The participants were given no task other than to look at the fixation cross in the middle of the disc while trying to minimize their blinking during the presentation period.</p><p>We included six distinct ocular conditions, each at five temporal contrast levels (combined factorially) relative to the mean luminance: 6, 12, 24, 48, and 96%. Contrast was defined as temporal Michelson contrast; the difference between maximum and minimum luminances, scaled by the mean and expressed as a percentage. In the first three conditions, the discs flickered at 2 Hz, in either a monocular, binocular, or dichoptic arrangement (see upper rows of <xref ref-type="fig" rid="fig8">Figure 8</xref>). In the dichoptic condition, the non-target eye saw a fixed temporal contrast of 48%. The rationale for including the monocular and binocular conditions is that they permit us to measure empirically any binocular facilitation, by comparing the response amplitudes across these two conditions. The rationale for including the dichoptic condition is that it provides additional constraints to computational models, and further explores the binocular contrast-response space (see <xref ref-type="bibr" rid="bib5">Baker et al., 2007</xref>).</p><p>In the remaining three conditions (termed the cross-frequency conditions) an additional flicker frequency of 1.6 Hz was introduced. We chose this frequency because it is sufficiently well-isolated from the target frequency (2 Hz) in the Fourier spectrum for 10 s trials. We repeated the monocular condition with this stimulus (one eye sees 1.6 Hz flicker, the other sees mean luminance), as well as testing in a binocular cross configuration (one eye sees each frequency at the target contrast). The rationale for the binocular cross condition is that it allows us to see the effects of suppression between the eyes without the additional complication of signal summation (which occurs when both eyes receive the same frequency), because the response of each eye can be resolved independently by frequency. Finally, in the dichoptic cross condition, one eye saw the target stimulus flickering at 2 Hz, and the other eye saw flicker at 1.6 Hz with a contrast of 48% - again this reveals the presence of suppression (by comparison with the 2 Hz monocular condition). A schematic overview of the cross-frequency conditions is shown in the lower rows of <xref ref-type="fig" rid="fig8">Figure 8</xref>. In all conditions, we counterbalanced the presentation of the target stimulus across the left and right eyes.</p></sec><sec id="s4-3-2"><title>Experiment 2: EEG responses across temporal frequency</title><p>This experiment used the same equipment setup as Experiment 1, except that the eye tracker was not used. Unlike the first experiment, only one contrast level was used (96%) and the discs were set to flicker at five different frequencies (2, 4, 8, 16, and 30 Hz). Only two ocular configurations, monocular and binocular, were included, with the latter having both discs flickering at the same frequency. The experiment was carried out in one session lasting 25 min in total, divided into five blocks of 5 min each. In each block, there were 20 trials in total with the same timing as for Experiment 1.</p></sec><sec id="s4-3-3"><title>Experiment 3: temporal contrast matching</title><p>The experiment was conducted in a darkened room with a blacked-out window. The display equipment (monitor and stereoscope) was the same as for the two previous experiments, but no EEG or pupillometry data were collected. A two-interval contrast matching procedure was used to collect data. In one interval, participants were presented with a standard fused disc that flickered at a set contrast level (either 24 or 48%), which was selected by the experimenter at the beginning of each block. In the other interval, a target disc was displayed, flickering at different contrast levels on each trial, but with a fixed interocular contrast ratio across the block. The contrast level of the target was controlled by a 1-up, 1-down staircase moving in logarithmic (dB) steps of contrast. The ratio of flicker amplitudes in the left and right eyes was varied across blocks and was set to be 0, 0.25, 0.5, 0.75, or 1 (nine distinct conditions). The standard and target discs were displayed for 1 s each, with an interstimulus interval of 0.5 s. After both discs had appeared on the screen, the participants had to indicate which interval they perceived as having the more intense flicker. The intervals were randomly ordered, and all discs flickered at a frequency of 2 Hz (two cycles in sine phase).</p><p>Due to its long duration (approximately 3 hr in total), the participants completed the experiment across multiple sessions initiated at their own convenience. The experiment was divided into 54 blocks (3 repetitions ×2 standard contrasts ×9 target ratios), which lasted on average 3 min each, depending on the response speed of the participant. In each block, there was a total of 50 trials. No auditory feedback was given for this subjective task.</p></sec></sec><sec id="s4-4"><title>Data analysis</title><p>EEG data were converted from the ANT-EEProbe format to a compressed csv text file using a custom Matlab script (available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/bakerdh/PupillometryEEG/">https://github.com/bakerdh/PupillometryEEG/</ext-link> copy archived at <xref ref-type="bibr" rid="bib11">Baker, 2023</xref>; <xref ref-type="bibr" rid="bib51">Segala et al., 2023</xref>) and components of the EEGlab toolbox (<xref ref-type="bibr" rid="bib18">Delorme and Makeig, 2004</xref>). The data for each participant were then loaded into R for analysis, where a 10 s waveform for each trial at each electrode was extracted (omitting the first 2 s). The Fourier transform of each waveform was calculated, and the complex spectrum was stored in a matrix. All repetitions of each condition were then averaged for each electrode. They were then averaged across four occipital electrodes (<italic>POz</italic>, <italic>Oz</italic>, <italic>O1</italic>, <italic>O2</italic>), to obtain individual results. Finally, these were averaged across participants to obtain the group results. All averaging was performed in the complex domain and, therefore, retained the phase information (i.e. coherent averaging), and at each stage, we excluded data points with a Mahalanobis distance exceeding D = 3 from the complex-valued mean (see <xref ref-type="bibr" rid="bib10">Baker, 2021</xref>). For statistical comparisons of complex-valued data, we use the <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> statistic described by <xref ref-type="bibr" rid="bib10">Baker, 2021</xref>. This is a multivariate extension of ANOVA that assumes equal variance of the real and imaginary Fourier components, or equivalently, an extension of the <inline-formula><mml:math id="inf6"><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> statistic of <xref ref-type="bibr" rid="bib58">Victor and Mast, 1991</xref> that can compare more than two conditions.</p><p>A similar analysis pipeline was adopted for the pupillometry data. The data were converted from mp4 videos to a csv text file using the Pupil Player software (<xref ref-type="bibr" rid="bib29">Kassner et al., 2014</xref>), which estimated pupil diameter for each eye on each frame using a 3D model of the eyeball. The individual data were then loaded into R for analysis, where again a 10 s waveform for each trial in each eye was extracted (excluding the first 2 s after stimulus onset). We interpolated across any dropped or missing frames to ensure regular and continuous sampling over time. The Fourier transform was calculated for each waveform, and all repetitions of each condition were pooled across the eye and then averaged. We confirmed in additional analyses that the monocular consensual pupil response was complete, justifying our pooling of data across the eyes. Finally, data were averaged across all participants to obtain the group results. Again, we used coherent averaging, and excluded outlying data points in the same way as for the EEG data. Note that previous pupillometry studies using luminance flicker have tended to fit a single sine-wave at the fundamental frequency, rather than using Fourier analysis (e.g. <xref ref-type="bibr" rid="bib52">Spitschan et al., 2014</xref>). The Fourier approach is more robust to noise at other frequencies (which can make the phase and amplitude of a fitted sine wave unstable) and has been used in some previous studies (see <xref ref-type="bibr" rid="bib12">Barrionuevo et al., 2014</xref>; <xref ref-type="bibr" rid="bib13">Barrionuevo and Cao, 2016</xref>). Additionally, it makes the pupillometry analysis is consistent with standard practice in steady-state EEG analysis (e.g. <xref ref-type="bibr" rid="bib24">Figueira et al., 2022</xref>).</p><p>To analyze the matching data, we pooled the trial responses across all repetitions of a given condition for each participant. We then fitted a cumulative normal psychometric function to estimate the point of subjective equality at the 50% level. Thresholds were averaged across participants in logarithmic (dB) units.</p><p>For all experiments, we used a bootstrapping procedure with 1000 iterations to estimate standard errors across participants. All analysis and figure construction was conducted using a single R-script, available online, making this study fully computationally reproducible.</p></sec><sec id="s4-5"><title>Computational model and parameter estimation</title><p>To describe our data, we chose a model of binocular contrast gain control with the same general form as the first stage of the model proposed by <xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>. The second gain control stage was omitted (consistent with <xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>) to simplify the model and reduce the number of free parameters. The response of the left eye’s channel is given by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mi>Z</mml:mi><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>with an equivalent expression for the right eye:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mi>Z</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>In both equations, <italic>L</italic> and <italic>R</italic> are the contrast signals from the left and right eyes, <italic>Z</italic> is a saturation constant that shifts the contrast-response function laterally, and <italic>w</italic> is the weight of suppression from the other eye.</p><p>The responses from the two eyes are then summed binocularly:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <italic>n</italic> is a noise parameter, and <inline-formula><mml:math id="inf7"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> scales the overall response amplitude. The <inline-formula><mml:math id="inf8"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> parameter was omitted when modeling the contrast-matching data, as it has no effect in this paradigm.</p><p>Despite being derived from the model proposed by <xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>, the simplifications applied to this architecture make it very similar to other models (e.g. <xref ref-type="bibr" rid="bib19">Ding and Sperling, 2006</xref>; <xref ref-type="bibr" rid="bib54">ten Doesschate and Alpern, 1967</xref>; <xref ref-type="bibr" rid="bib32">Legge, 1984</xref>; <xref ref-type="bibr" rid="bib50">Schrödinger, 1926</xref>). In particular, we fixed the numerator exponent at 2 in our model, because otherwise, this value tends to trade off with the weight of interocular suppression (see <xref ref-type="bibr" rid="bib6">Baker et al., 2012</xref>; <xref ref-type="bibr" rid="bib30">Kingdom and Libenson, 2015</xref>). Our key parameter of interest is the weight of interocular suppression. Large values around w = 1 result in a very small or nonexistent binocular advantage at suprathreshold contrasts, consistent with previous work using grating stimuli (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>). Low values around w = 0 produce substantial, near-linear binocular facilitation (<xref ref-type="bibr" rid="bib9">Baker et al., 2020</xref>). Models from this family can handle both scalar contrast values and continuous waveforms (<xref ref-type="bibr" rid="bib56">Tsai et al., 2012</xref>) or images (<xref ref-type="bibr" rid="bib42">Meese and Summers, 2007</xref>) as inputs. For time-varying inputs, the calculations are performed at each time point, and the output waveform can then be analyzed using Fourier analysis in the same way as for empirical data. This means that the model can make predictions for the entire Fourier spectrum, including harmonic and intermodulation responses that arise as a consequence of nonlinearities in the model (<xref ref-type="bibr" rid="bib7">Baker and Wade, 2017</xref>). However, for computational tractability, we performed fitting here using scalar contrast values.</p><p>We implemented the model within a Bayesian framework using the Stan software (<xref ref-type="bibr" rid="bib17">Carpenter et al., 2017</xref>). This allowed us to estimate group-level posterior parameter distributions for the weight of interocular suppression, <inline-formula><mml:math id="inf9"><mml:mi>w</mml:mi></mml:math></inline-formula>, and the other free model parameters <inline-formula><mml:math id="inf10"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf11"><mml:mi>Z</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf12"><mml:mi>n</mml:mi></mml:math></inline-formula>. The prior distributions for all parameters were Gaussian, with means and standard deviations of 1 and 0.5 for <inline-formula><mml:math id="inf13"><mml:mi>w</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and 5 and 2 for <inline-formula><mml:math id="inf15"><mml:mi>Z</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf16"><mml:mi>n</mml:mi></mml:math></inline-formula>, with these values chosen based on previous literature (<xref ref-type="bibr" rid="bib6">Baker et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Meese et al., 2006</xref>). We sampled from a Student’s t-distribution for the amplitudes in the pupillometry and EEG experiments, and from a Bernoulli distribution for the single trial matching data. The models were fit using the individual data across all participants, independently for each dataset. We used coherent averaging to combine the data across participants, but this was not implemented in the model, so to compensate we corrected the group-level model by scaling the estimated noise parameter (<inline-formula><mml:math id="inf17"><mml:mi>n</mml:mi></mml:math></inline-formula>) by the square root of the number of participants (<inline-formula><mml:math id="inf18"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:msqrt><mml:mn>30</mml:mn></mml:msqrt></mml:mfrac></mml:mrow></mml:math></inline-formula>). We took posterior samples at over a million steps for each dataset, using a computer cluster, and retained 10% of samples for plotting.</p></sec><sec id="s4-6"><title>Preregistration, data, and code availability</title><p>We initially preregistered our main hypotheses and analysis intentions for the first experiment. We then conducted a pilot study with N=12 participants, before making some minor changes to the stimulus (we added dim red lines to aid binocular fusion). We then ran the main experiment, followed by two additional experiments that were not preregistered. The preregistration document, raw data files, and experimental and analysis code are available on the project repository: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/TBEMA">https://doi.org/10.17605/OSF.IO/TBEMA</ext-link>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Funding acquisition, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Software, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Resources, Software, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All participants gave written informed consent. Our procedures were approved by the Ethics Committee of the Department of Psychology at the University of York (identification number 792).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-87048-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Raw data files, and experimental and analysis code, are available on the project repository on the Open Science Framework: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/TBEMA">https://doi.org/10.17605/OSF.IO/TBEMA</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Segala</surname><given-names>FG</given-names></name><name><surname>Bruno</surname><given-names>A</given-names></name><name><surname>Martin</surname><given-names>JT</given-names></name><name><surname>Aung</surname><given-names>MT</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Baker</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Pupillometric measures of binocular combination</data-title><source>Open Science Framework</source><pub-id pub-id-type="doi">10.17605/OSF.IO/TBEMA</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>Supported by Biotechnology and Biological Sciences Research Council grant BB/V007580/1 awarded to DHB and ARW, and Wellcome Trust grant 213616/Z/18/Z to AB.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angée</surname><given-names>C</given-names></name><name><surname>Nedelec</surname><given-names>B</given-names></name><name><surname>Erjavec</surname><given-names>E</given-names></name><name><surname>Rozet</surname><given-names>JM</given-names></name><name><surname>Fares Taie</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Congenital microcoria: Clinical features and molecular genetics</article-title><source>Genes</source><volume>12</volume><elocation-id>624</elocation-id><pub-id pub-id-type="doi">10.3390/genes12050624</pub-id><pub-id pub-id-type="pmid">33922078</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anstis</surname><given-names>S</given-names></name><name><surname>Ho</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Nonlinear combination of luminance excursions during flicker, simultaneous contrast, afterimages and binocular fusion</article-title><source>Vision Research</source><volume>38</volume><fpage>523</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(97)00167-3</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Apkarian</surname><given-names>PA</given-names></name><name><surname>Nakayama</surname><given-names>K</given-names></name><name><surname>Tyler</surname><given-names>CW</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Binocularity in the human visual evoked potential: facilitation, summation and suppression</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>51</volume><fpage>32</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(81)91507-8</pub-id><pub-id pub-id-type="pmid">6161780</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baitch</surname><given-names>LW</given-names></name><name><surname>Levi</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Evidence for nonlinear binocular interactions in human visual cortex</article-title><source>Vision Research</source><volume>28</volume><fpage>1139</fpage><lpage>1143</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(88)90140-x</pub-id><pub-id pub-id-type="pmid">3257016</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name><name><surname>Meese</surname><given-names>TS</given-names></name><name><surname>Georgeson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Binocular interaction: contrast matching and contrast discrimination are predicted by the same model</article-title><source>Spatial Vision</source><volume>20</volume><fpage>397</fpage><lpage>413</lpage><pub-id pub-id-type="doi">10.1163/156856807781503622</pub-id><pub-id pub-id-type="pmid">17716525</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name><name><surname>Wallis</surname><given-names>SA</given-names></name><name><surname>Georgeson</surname><given-names>MA</given-names></name><name><surname>Meese</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Nonlinearities in the binocular combination of luminance and contrast</article-title><source>Vision Research</source><volume>56</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2012.01.008</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Evidence for an optimal algorithm underlying signal combination in human visual cortex</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>254</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw395</pub-id><pub-id pub-id-type="pmid">28031176</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name><name><surname>Lygo</surname><given-names>FA</given-names></name><name><surname>Meese</surname><given-names>TS</given-names></name><name><surname>Georgeson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Binocular summation revisited: beyond √2</article-title><source>Psychological Bulletin</source><volume>144</volume><fpage>1186</fpage><lpage>1199</lpage><pub-id pub-id-type="doi">10.1037/bul0000163</pub-id><pub-id pub-id-type="pmid">30102058</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name><name><surname>Vilidaite</surname><given-names>G</given-names></name><name><surname>McClarnon</surname><given-names>E</given-names></name><name><surname>Valkova</surname><given-names>E</given-names></name><name><surname>Bruno</surname><given-names>A</given-names></name><name><surname>Millman</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Binaural summation of amplitude modulation involves weak interaural suppression</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>3560</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-60602-5</pub-id><pub-id pub-id-type="pmid">32103139</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Statistical analysis of periodic data in neuroscience</article-title><source>Neurons, Behavior, Data Analysis, and Theory</source><volume>5</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.51628/001c.27680</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Pupillometry EEG</data-title><version designator="swh:1:rev:6a8dba14145893bb75249eb37bfcff70ccd70c5d">swh:1:rev:6a8dba14145893bb75249eb37bfcff70ccd70c5d</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:99678a295f0c43d9d812f753a31ee5847f7ef2fc;origin=https://github.com/bakerdh/PupillometryEEG;visit=swh:1:snp:80369ee59f26437dd627123f3d54b40c54c32b0b;anchor=swh:1:rev:6a8dba14145893bb75249eb37bfcff70ccd70c5d">https://archive.softwareheritage.org/swh:1:dir:99678a295f0c43d9d812f753a31ee5847f7ef2fc;origin=https://github.com/bakerdh/PupillometryEEG;visit=swh:1:snp:80369ee59f26437dd627123f3d54b40c54c32b0b;anchor=swh:1:rev:6a8dba14145893bb75249eb37bfcff70ccd70c5d</ext-link></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrionuevo</surname><given-names>PA</given-names></name><name><surname>Nicandro</surname><given-names>N</given-names></name><name><surname>McAnany</surname><given-names>JJ</given-names></name><name><surname>Zele</surname><given-names>AJ</given-names></name><name><surname>Gamlin</surname><given-names>P</given-names></name><name><surname>Cao</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Assessing rod, cone, and melanopsin contributions to human pupil flicker responses</article-title><source>Investigative Ophthalmology &amp; Visual Science</source><volume>55</volume><fpage>719</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1167/iovs.13-13252</pub-id><pub-id pub-id-type="pmid">24408974</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrionuevo</surname><given-names>PA</given-names></name><name><surname>Cao</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Luminance and chromatic signals interact differently with melanopsin activation to control the pupil light response</article-title><source>Journal of Vision</source><volume>16</volume><elocation-id>29</elocation-id><pub-id pub-id-type="doi">10.1167/16.11.29</pub-id><pub-id pub-id-type="pmid">27690169</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Miccoli</surname><given-names>L</given-names></name><name><surname>Escrig</surname><given-names>MA</given-names></name><name><surname>Lang</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The pupil as a measure of emotional arousal and autonomic activation</article-title><source>Psychophysiology</source><volume>45</volume><fpage>602</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2008.00654.x</pub-id><pub-id pub-id-type="pmid">18282202</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname><given-names>L</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title><source>Neuron</source><volume>64</volume><fpage>931</fpage><lpage>942</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.004</pub-id><pub-id pub-id-type="pmid">20064398</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>FW</given-names></name><name><surname>Green</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Monocular versus binocular visual acuity</article-title><source>Nature</source><volume>208</volume><fpage>191</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1038/208191a0</pub-id><pub-id pub-id-type="pmid">5884255</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>B</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Hoffman</surname><given-names>MD</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Goodrich</surname><given-names>B</given-names></name><name><surname>Betancourt</surname><given-names>M</given-names></name><name><surname>Brubaker</surname><given-names>MA</given-names></name><name><surname>Guo</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Riddell</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Stan: A probabilistic programming language</article-title><source>Journal of Statistical Software</source><volume>76</volume><fpage>1</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.18637/jss.v076.i01</pub-id><pub-id pub-id-type="pmid">36568334</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><volume>134</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A gain-control theory of binocular combination</article-title><source>PNAS</source><volume>103</volume><fpage>1141</fpage><lpage>1146</lpage><pub-id pub-id-type="doi">10.1073/pnas.0509629103</pub-id><pub-id pub-id-type="pmid">16410354</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dougherty</surname><given-names>K</given-names></name><name><surname>Cox</surname><given-names>MA</given-names></name><name><surname>Westerberg</surname><given-names>JA</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Binocular modulation of monocular V1 Neurons</article-title><source>Current Biology</source><volume>29</volume><fpage>381</fpage><lpage>391</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.12.004</pub-id><pub-id pub-id-type="pmid">30661798</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Economides</surname><given-names>JR</given-names></name><name><surname>Sincich</surname><given-names>LC</given-names></name><name><surname>Adams</surname><given-names>DL</given-names></name><name><surname>Horton</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Orientation tuning of cytochrome oxidase patches in macaque primary visual cortex</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1574</fpage><lpage>1580</lpage><pub-id pub-id-type="doi">10.1038/nn.2958</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>DP</given-names></name><name><surname>Purpura</surname><given-names>KP</given-names></name><name><surname>Kaplan</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Contrast sensitivity and spatial frequency response of primate cortical neurons in and around the cytochrome oxidase blobs</article-title><source>Vision Research</source><volume>35</volume><fpage>1501</fpage><lpage>1523</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(94)00253-i</pub-id><pub-id pub-id-type="pmid">7667910</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ernst</surname><given-names>MO</given-names></name><name><surname>Banks</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title><source>Nature</source><volume>415</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/415429a</pub-id><pub-id pub-id-type="pmid">11807554</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Figueira</surname><given-names>JSB</given-names></name><name><surname>Kutlu</surname><given-names>E</given-names></name><name><surname>Scott</surname><given-names>LS</given-names></name><name><surname>Keil</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The FreqTag toolbox: A principled approach to analyzing electrophysiological time series in frequency tagging paradigms</article-title><source>Developmental Cognitive Neuroscience</source><volume>54</volume><elocation-id>101066</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2022.101066</pub-id><pub-id pub-id-type="pmid">35184025</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flitcroft</surname><given-names>DI</given-names></name><name><surname>Judge</surname><given-names>SJ</given-names></name><name><surname>Morley</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Binocular interactions in accommodation control: effects of anisometropic stimuli</article-title><source>The Journal of Neuroscience</source><volume>12</volume><fpage>188</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.12-01-00188.1992</pub-id><pub-id pub-id-type="pmid">1729434</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gheiratmand</surname><given-names>M</given-names></name><name><surname>Meese</surname><given-names>TS</given-names></name><name><surname>Mullen</surname><given-names>KT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Blobs versus bars: psychophysical evidence supports two types of orientation response in human color vision</article-title><source>Journal of Vision</source><volume>13</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.1167/13.1.2</pub-id><pub-id pub-id-type="pmid">23283693</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horton</surname><given-names>JC</given-names></name><name><surname>Hubel</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Regular patchy distribution of cytochrome oxidase staining in primary visual cortex of macaque monkey</article-title><source>Nature</source><volume>292</volume><fpage>762</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1038/292762a0</pub-id><pub-id pub-id-type="pmid">6267472</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex</article-title><source>The Journal of Physiology</source><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id><pub-id pub-id-type="pmid">14449617</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kassner</surname><given-names>M</given-names></name><name><surname>Patera</surname><given-names>W</given-names></name><name><surname>Bulling</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil: An open source platform for pervasive eye tracking and mobile gaze-based interaction</article-title><conf-name>Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication</conf-name><fpage>1151</fpage><lpage>1160</lpage></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingdom</surname><given-names>FAA</given-names></name><name><surname>Libenson</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dichoptic color saturation mixture: Binocular luminance contrast promotes perceptual averaging</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.1167/15.5.2</pub-id><pub-id pub-id-type="pmid">26067520</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legge</surname><given-names>GE</given-names></name><name><surname>Rubin</surname><given-names>GS</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Binocular interactions in suprathreshold contrast perception</article-title><source>Perception &amp; Psychophysics</source><volume>30</volume><fpage>49</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.3758/bf03206136</pub-id><pub-id pub-id-type="pmid">7290896</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legge</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Binocular contrast summation--II. Quadratic summation</article-title><source>Vision Research</source><volume>24</volume><fpage>385</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(84)90064-6</pub-id><pub-id pub-id-type="pmid">6740959</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levelt</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Binocular brightness averaging and contour information</article-title><source>British Journal of Psychology</source><volume>56</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1111/j.2044-8295.1965.tb00939.x</pub-id><pub-id pub-id-type="pmid">14292050</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Atick</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Efficient stereo coding in the multiscale representation</article-title><source>Network</source><volume>5</volume><fpage>157</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1088/0954-898X_5_2_003</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Livingstone</surname><given-names>MS</given-names></name><name><surname>Hubel</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Anatomy and physiology of a color system in the primate visual cortex</article-title><source>The Journal of Neuroscience</source><volume>4</volume><fpage>309</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.04-01-00309.1984</pub-id><pub-id pub-id-type="pmid">6198495</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>JT</given-names></name><name><surname>Pinto</surname><given-names>J</given-names></name><name><surname>Bulte</surname><given-names>D</given-names></name><name><surname>Spitschan</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>PyPlr: a versatile, integrated system of hardware and software for researching the human pupillary light reflex</article-title><source>Behavior Research Methods</source><volume>54</volume><fpage>2720</fpage><lpage>2739</lpage><pub-id pub-id-type="doi">10.3758/s13428-021-01759-3</pub-id><pub-id pub-id-type="pmid">36002631</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>JT</given-names></name><name><surname>Boynton</surname><given-names>GM</given-names></name><name><surname>Baker</surname><given-names>DH</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Spitschan</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>PySilSub: An open-source Python toolbox for implementing the method of silent substitution in vision and nonvisual photoreception research</article-title><source>Journal of Vision</source><volume>23</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.1167/jov.23.7.10</pub-id><pub-id pub-id-type="pmid">37450287</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathôt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupillometry: Psychology, physiology, and function</article-title><source>Journal of Cognition</source><volume>1</volume><elocation-id>16</elocation-id><pub-id pub-id-type="doi">10.5334/joc.18</pub-id><pub-id pub-id-type="pmid">31517190</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>May</surname><given-names>K</given-names></name><name><surname>Zhaoping</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Li and Atick’s theory of efficient binocular coding: A tutorial and mini-review</article-title><source>Vision Research</source><volume>201</volume><elocation-id>107950</elocation-id><pub-id pub-id-type="doi">10.1016/j.visres.2021.08.005</pub-id><pub-id pub-id-type="pmid">36216600</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McDougal</surname><given-names>DH</given-names></name><name><surname>Gamlin</surname><given-names>PD</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Pupillary Control Pathways.The Senses: A Comprehensive Reference</source><publisher-name>Elsevier</publisher-name><fpage>521</fpage><lpage>536</lpage></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meese</surname><given-names>TS</given-names></name><name><surname>Georgeson</surname><given-names>MA</given-names></name><name><surname>Baker</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Binocular contrast vision at and above threshold</article-title><source>Journal of Vision</source><volume>6</volume><fpage>1224</fpage><lpage>1243</lpage><pub-id pub-id-type="doi">10.1167/6.11.7</pub-id><pub-id pub-id-type="pmid">17209731</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meese</surname><given-names>TS</given-names></name><name><surname>Summers</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Area summation in human vision at and above detection threshold</article-title><source>Proceedings of the Royal Society B</source><volume>274</volume><fpage>2891</fpage><lpage>2900</lpage><pub-id pub-id-type="doi">10.1098/rspb.2007.0957</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meese</surname><given-names>TS</given-names></name><name><surname>Baker</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A reevaluation of achromatic spatio-temporal vision: Nonoriented filters are monocular, they adapt, and can be used for decision making at high flicker speeds</article-title><source>I-Perception</source><volume>2</volume><fpage>159</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1068/i0416</pub-id><pub-id pub-id-type="pmid">23145234</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moradi</surname><given-names>F</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Inter-ocular contrast normalization in human visual cortex</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1167/9.3.13</pub-id><pub-id pub-id-type="pmid">19757952</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>Appelbaum</surname><given-names>LG</given-names></name><name><surname>Ales</surname><given-names>JM</given-names></name><name><surname>Cottereau</surname><given-names>BR</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The steady-state visual evoked potential in vision research: A review</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/15.6.4</pub-id><pub-id pub-id-type="pmid">26024451</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Privitera</surname><given-names>CM</given-names></name><name><surname>Stark</surname><given-names>LW</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A binocular pupil model for simulation of relative afferent pupil defects and the swinging flashlight test</article-title><source>Biological Cybernetics</source><volume>94</volume><fpage>215</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1007/s00422-005-0042-8</pub-id><pub-id pub-id-type="pmid">16404612</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Purves</surname><given-names>D</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name><name><surname>Cabeza</surname><given-names>R</given-names></name><name><surname>LaBar</surname><given-names>KS</given-names></name><name><surname>Huettel</surname><given-names>SA</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name><name><surname>Woldorff</surname><given-names>MG.</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Principles of Cognitive Neuroscience</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quaia</surname><given-names>C</given-names></name><name><surname>Optican</surname><given-names>LM</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Binocular summation for reflexive eye movements</article-title><source>Journal of Vision</source><volume>18</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/18.4.7</pub-id><pub-id pub-id-type="pmid">29621384</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Some characteristics of average steady-state and transient responses evoked by modulated light</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>20</volume><fpage>238</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(66)90088-5</pub-id><pub-id pub-id-type="pmid">4160391</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schrödinger</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1926">1926</year><chapter-title>Die Gesichtsempfindungen</chapter-title><source>Mueller-Pouillets Lehrbuch Der Physik</source><publisher-loc>Braunschweig</publisher-loc><publisher-name>Vieweg</publisher-name><fpage>456</fpage><lpage>560</lpage></element-citation></ref><ref id="bib51"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Segala</surname><given-names>FG</given-names></name><name><surname>Bruno</surname><given-names>A</given-names></name><name><surname>Martin</surname><given-names>JT</given-names></name><name><surname>Aung</surname><given-names>MT</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Baker</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Different rules for binocular combination of luminance flicker in cortical and subcortical pathways</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.01.11.523568</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spitschan</surname><given-names>M</given-names></name><name><surname>Jain</surname><given-names>S</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Aguirre</surname><given-names>GK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Opponent melanopsin and S-cone signals in the human pupillary light response</article-title><source>PNAS</source><volume>111</volume><fpage>15568</fpage><lpage>15572</lpage><pub-id pub-id-type="doi">10.1073/pnas.1400942111</pub-id><pub-id pub-id-type="pmid">25313040</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spitschan</surname><given-names>M</given-names></name><name><surname>Cajochen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Binocular facilitation in light-mediated melatonin suppression?</article-title><source>Journal of Pineal Research</source><volume>67</volume><elocation-id>e12602</elocation-id><pub-id pub-id-type="doi">10.1111/jpi.12602</pub-id><pub-id pub-id-type="pmid">31361918</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>ten Doesschate</surname><given-names>J</given-names></name><name><surname>Alpern</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Effect of photoexcitation of the two retinas on pupil size</article-title><source>Journal of Neurophysiology</source><volume>30</volume><fpage>562</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1152/jn.1967.30.3.562</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Silverman</surname><given-names>MS</given-names></name><name><surname>Hamilton</surname><given-names>SL</given-names></name><name><surname>De Valois</surname><given-names>RL</given-names></name><name><surname>Switkes</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Functional anatomy of macaque striate cortex. III. Color</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>1569</fpage><lpage>1593</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-05-01569.1988</pub-id><pub-id pub-id-type="pmid">3367211</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsai</surname><given-names>JJ</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Norcia</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dynamics of normalization underlying masking in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>2783</fpage><lpage>2789</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4485-11.2012</pub-id><pub-id pub-id-type="pmid">22357861</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tychsen</surname><given-names>L</given-names></name><name><surname>Wong</surname><given-names>AMF</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Paucity of horizontal connections for binocular vision in V1 of naturally strabismic macaques: Cytochrome oxidase compartment specificity</article-title><source>The Journal of Comparative Neurology</source><volume>474</volume><fpage>261</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1002/cne.20113</pub-id><pub-id pub-id-type="pmid">15164426</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Mast</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>A new statistic for steady-state evoked potentials</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>78</volume><fpage>378</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(91)90099-p</pub-id><pub-id pub-id-type="pmid">1711456</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>CA</given-names></name><name><surname>Munoz</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A circuit for pupil orienting responses: implications for cognitive modulation of pupil size</article-title><source>Current Opinion in Neurobiology</source><volume>33</volume><fpage>134</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2015.03.018</pub-id><pub-id pub-id-type="pmid">25863645</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyatt</surname><given-names>HJ</given-names></name><name><surname>Musselman</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Pupillary light reflex in humans: evidence for an unbalanced pathway from nasal retina, and for signal cancellation in brainstem</article-title><source>Vision Research</source><volume>21</volume><fpage>513</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(81)90097-3</pub-id><pub-id pub-id-type="pmid">7269329</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><p>We conducted a conceptual replication of Experiment 1 using an alternative system of hardware and software (<xref ref-type="bibr" rid="bib37">Martin et al., 2023</xref>; <xref ref-type="bibr" rid="bib36">Martin et al., 2022</xref>). A pair of Spectra Tune Lab multiprimary devices (LEDmotive Technologies LLC, Barcelona, Spain) were coupled to a binocular headset using liquid light guides. The light was imaged onto a circular diffuser for each eye (field size 30 deg) with the central 8 degrees masked off using a black occluder. Therefore, the replication experiment involved peripheral stimulation, unlike the main experiment which stimulated the central ~4 degrees of the visual field. All conditions were otherwise as described for the main experiment, and we tested 12 participants in total.</p><p>The pupillometry results are shown in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> and correspond closely to those from the main experiment (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The ratio of binocular to monocular responses in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1c</xref> is similar, and suppression is evident in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1d, e</xref>. Of particular interest is the existence of a slight response at the second harmonic (4 Hz, <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1b</xref>), which was not present in our original data. This may be because the driving signal is stronger when stimulating the periphery (note the clear waveform in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1a</xref>), or more robust to eye movements, or it might indicate additional nonlinearities not present at the fovea.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Summary of pupillometry results for N=12 participants, for peripheral stimulation.</title><p>See <xref ref-type="fig" rid="fig1">Figure 1</xref> for a description of each panel.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-app1-fig1-v1.tif"/></fig><p>The EEG results are shown in <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>. These still show a strong binocular facilitation effect at the highest contrast levels (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2c, f</xref>), but the contrast response function is less clear at both the first and second harmonics. We suspect that this is because the cortical representation of the peripheral visual field is primarily along the calcarine sulcus, which results in some cancellation of the steady-state signal. This results in weaker signals than we obtained for foveal stimulation (represented at the occipital pole) in the main experiment (see <xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Summary of steady-state EEG results for N=12 participants, for peripheral stimulation.</title><p>See <xref ref-type="fig" rid="fig2">Figure 2</xref> for a description of each panel.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-app1-fig2-v1.tif"/></fig></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87048.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Huxlin</surname><given-names>Krystel R</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Rochester</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>This study provides potentially <bold>important</bold>, new insights about the combination of information from the two eyes in humans. The data includes frequency tagging of each eye's inputs and measures reflecting both cortical (EEG) and sub-cortical processes (pupillometry). The strength of supporting evidence is <bold>solid</bold>, suggesting that temporal modulations are combined differently than spatial modulations, with additional differences between subcortical and cortical pathways. However, questions remain as to exactly how information is combined, how the findings relate to the extant literature and more broadly, to the interests of vision scientists at large.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87048.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In this paper, the interocular/binocular combination of temporal luminance modulations is studied. Binocular combination is of broad interest because it provides a remarkable case study of how the brain combines information from different sources. In addition, the mechanisms of binocular combination are of interest to vision scientists because they provide insight into when/where/how information from two eyes is combined.</p><p>This study focuses on how luminance flicker is combined across two eyes, extending previous work that focused mainly on spatial modulations. The results appear to show that temporal modulations are combined in different ways, with additional differences between subcortical and cortical pathways.</p><p>The manuscript has been revised to address prior reviewers' comments. It now provides more justification for the empirical choices made by the authors, and a better illustration of the methods. That said, the paper would still benefit from an expanded rationale for significance beyond this specific area. There were no substantive changes made to the abstract or introduction, and only little to the discussion.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87048.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Previous studies have extensively explored the rules by which patterned inputs from the two eyes are combined in visual cortex. Here the authors explore these rules for un-patterned inputs (luminance flicker) at both the level of cortex, using Steady-State Visual Evoked Potentials (SSVEPs) and at the sub-cortical level using pupillary responses. They find that the pattern of binocular combination differs between cortical and sub-cortical levels with the cortex showing less dichoptic masking and somewhat more binocular facilitation.</p><p>Importantly, the present results with flicker differ markedly from those with gratings Hou et al., 2020, J Neurosci, Baker and Wade 2017 cerebral cortex, Norcia et al, 2000 Neuroreport, Brown et al., 1999, IOVS. When SSVEP responses are measured under dichoptic conditions where each eye is driven with a unique temporal frequency, in the case of grating stimuli, the magnitude of the response in the fixed contrast eye decreases as a function of contrast in the variable contrast eye. Here the response increases by varying (small) magnitudes. The authors favor a view that cortex and perception pool binocular flicker inputs approximately linearly using cells that are largely monocular. The lack of a decrease below the monocular level when modulation strength increase is taken to indicate that previously observed normalization mechanism in pattern vision does not play a substantial role in the processing of flicker. The authors present of computational model of binocular combination that captures features of the data when fit separately to each data set. Because the model has no frequency dependence and is based on scalar quantities, it cannot make joint predictions for the multiple experimental conditions which one of its limitations.</p><p>A strength of the current work is the use of frequency-tagging of both pupil and EEG responses to measure responses for flicker stimuli at two anatomical levels of processing. Flicker responses are interesting but have been relatively neglected. The tagging approach allows one to access responses driven by each eye, even when the other eye is stimulated which is a great strength. The tagging approach can be applied at both levels of processing at the same time when stimulus frequencies are low, which is an advantage as they can be directly compared. The authors demonstrate the versatility of frequency tagging in a novel experimental design which may inspire other uses, both within the present context and others. A disadvantage of the tagging approach for studying sub-cortical dynamics via pupil responses is that it is restricted to low temporal frequencies given the temporal bandwidth of the pupil. The inclusion of a behavioral measure and a model is also a strength, but there are some limitations in the modeling (see below).</p><p>The authors suggest in the discussion that luminance flicker may preferentially drive cortical mechanisms that are largely monocular and in the results that they are approximately linear in the dichoptic cross condition (no effect of the fixed contrast stimulus in the other eye). By contrast, prior research using dichoptic dual frequency flickering stimuli has found robust intermodulation (IM) components in the VEP response spectrum (Baitch and Levi, 1988, Vision Res; Stevens et al., 1994 J Ped Ophthal Strab; France and Ver Hoeve, 1994, J Ped Ophthal Strab; Suter et al., 1996 Vis Neurosci). The presence of IM is a direct signature of binocular interaction and suggests that at least under some measurement conditions, binocular luminance combination is &quot;essentially&quot; non-linear, where essential implies a point-like non-linearity such as squaring of excitatory inputs. The two views are in striking contrast.</p><p>In this revised manuscript, the addition of Figure 8, which shows more complete response spectra, partially addresses this issue. However, it also raises new questions. Critically, intermodulation (IM) has to be generated at or after a point of binocular combination, as it is a mixture of the two monocular frequencies and the monocular frequencies can only mix after a point of binocular combination.</p><p>In equations 1 and 2 and in the late summation and two-stage models of Meese et al (2006), there are divisive binocular cross-links prior to a summation block. This division is a form of binocular interaction. Do equations 1 and 2 generate IM on their own with parameters used for the overall modeling? Multiplication of two inputs clearly does, as the authors indicate in their toy model. If not, then a different binocular summation rule than the one expressed in equation 3 needs to be considered to produce IM.</p><p>The discussion considers flicker processing as manifest in the EEG to be largely monocular, given the relative lack of binocular facilitation and suppression effects. And yet there is robust IM. These are difficult to reconcile as it stands. The authors suggest that their generic modeling framework can predict IM, but can it predict IM with the parameters used to fit the data, e.g. with very low values of the weight of interocular suppression and no other binocular non-linearity?</p><p>Determining whether IM can be generated by the existing non-linear elements in the model is important because previous work on dichoptic flicker IM has considered a variety of simple models of dichoptic flicker summation and has favored models involving either a non-linear combination of linear monocular inputs (Baitch and Levi, Vis Research, 1988) or a non-linear combination of rectified (non-linear) monocular inputs (Regan and Regan, Canadian J Neurol Sci, 1989). In either case, the last stage of binocular combination is non-linear, rather than linear. The authors' model is different - it has a stage of divisive binocular interaction and this &quot;quasi-monocular&quot; stage feeds a linear binocular combination stage.</p><p>There is a second opportunity to test the proposed model that the authors could take advantage of. In the initial review, two of the reviewers were curious about what is predicted for counter-phase inputs to the two eyes. The authors indicate that the class of models they are using could be extended to cover this case. As it turns out, this experiment has been done for dichoptic full-field flicker (Sherrington, BrJPsychiatr, 1904); van der Tweel and Estevez, Ophthalmologica, 1974; Odom and Chao, IntJNeurosci, 1995; Cavonius, QJExpPsych, 1979; Levi et al., BJO, 1982. More importantly, the predictions of several binocular combination models for anti-phase inter-ocular flicker stimulation have been tested for both the VEP and psychophysics (Odom and Chao, Int J Neurosci). Varying the relative phase of the two eyes inputs from in phase to antiphase, Odom and Chao observed that the 2nd harmonic response went to a minimum at 90 deg of interocular phase. This will happen because a 2nd order nonlinearity in the monocular path will double the phase shift of the second harmonic, putting the two eyes' 2nd harmonic response out of phase when the interocular phase is 90 deg. Summing these inputs thus leads to cancellation at 90 deg, rather than 180 deg of interocular phase. Does the authors' model predict this behavior with typical parameters used in the modeling? In the end, to account for details of both VEP and psychophysical data, Odom and Chao favored a two-path model with one path comprising non-linear monocular inputs being combined linearly and a second path combining linear monocular inputs at a non-linear binocular stage. A similar set of results and models has been developed for inter-ocular presentation of gratings (Zemon et al., PNAS, 1995).</p><p>The Odom/Chao/Zemon VEP and psychophysical data are directly relevant to the authors' work and need to be taken into account in sufficient detail so that we can judge the consistency of the proposed framework with their data and the similarities and differences in the model predictions for dichoptic flicker combination. These models are also relevant to the generation of IM, a concern raised above.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87048.3.sa3</article-id><title-group><article-title>Author Response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Segala</surname><given-names>Federico G</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Bruno</surname><given-names>Aurelio</given-names></name><role specific-use="author">Author</role><aff><institution>University of Leicester</institution><addr-line><named-content content-type="city">Leicester</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Martin</surname><given-names>Joel T</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Aung</surname><given-names>Myat T</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Wade</surname><given-names>Alex R</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Baker</surname><given-names>Daniel H</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>eLife assessment</bold></p><p>This study provides potentially important, new information about the combination of information from the two eyes in humans. The data included frequency tagging of each eye's inputs and measures reflecting both cortical (EEG) and sub-cortical processes (pupillometry). Binocular combination is of potentially general interest because it provides -in essence- a case study of how the brain combines information from different sources and through different circuits. The strength of supporting evidence appears to be solid, showing that temporal modulations are combined differently than spatial modulations, with additional differences between subcortical and cortical pathways. However, the manuscript's clarity could be improved, including by adding more convincing motivations for the approaches used.</p></disp-quote><p>We thank the editor and reviewers for their detailed comments and suggestions regarding our paper. We have implemented most of the suggested changes. In doing so we noticed a minor error in our analysis code that affected the functions shown in Figure 2e (previously Figure 1e), and have fixed this and rerun the modelling. Our main results and conclusions are unaffected by this change. We have also added a replication data set to the Appendix, as this bears on one of the points raised by a reviewer, and included a co-author who helped run this experiment.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>In this paper, the interocular/binocular combination of temporal luminance modulations is studied. Binocular combination is of broad interest because it provides a remarkable case study of how the brain combines information from different sources. In addition, the mechanisms of binocular combination are of interest to vision scientists because they provide insight into when/where/how information from two eyes is combined.</p><p>This study focuses on how luminance flicker is combined across two eyes, extending previous work that focused mainly on spatial modulations. The results appear to show that temporal modulations are combined in different ways, with additional differences between subcortical and cortical pathways.</p><p>1. Main concern: subcortical and cortical pathways are assessed in quite different ways. On the one hand, this is a strength of the study (as it relies on unique ways of interrogating each pathway). However, this is also a problem when the results from two approaches are combined - leading to a sort of attribution problem: Are the differences due to actual differences between the cortical and subcortical binocular combinations, or are they perhaps differences due to different methods. For example, the results suggest that the subcortical binocular combination is nonlinear, but it is not clear where this nonlinearity occurs. If this occurs in the final phase that controls pupillary responses, it has quite different implications.</p><p>At the very least, this work should clearly discuss the limitations of using different methods to assess subcortical and cortical pathways.</p></disp-quote><p>The modelling asserts that the nonlinearity is primarily interocular suppression, and that this is stronger in the subcortical pathway. Moreover the suppression impacts before binocular combination. So this is quite a specific location. We now say more about this in the Discussion, and also suggest that fMRI might avoid the limits on the conclusions we can draw from different methods.</p><disp-quote content-type="editor-comment"><p>1. Adding to the previous point, the paper needs to be a better job of justifying not only the specific methods but also other details of the study (e.g., why certain parameters were chosen). To illustrate, a semi-positive example: Only page 7 explains why 2Hz modulation was used, while the methods for 2Hz modulation are described in detail on page 3. No justifications are provided for most of the other experimental choices. The paper should be expanded to better explain this area of research to non-experts. A notable strength of this paper is that it should be of interest to those not working in this particular field, but this goal is not achieved if the paper is written for a specialist audience. In particular, the introduction should be expanded to better explain this area of research, the methods should include justifications for important empirical decisions, and the discussion should make the work more accessible again (in addition to addressing the issues raised in point 1 above). The results also need more context. For example, why EEG data have overtones but pupillometry does not?</p></disp-quote><p>We now explain the choice of frequency in the final paragraph of the introduction as follows:</p><p>‘We chose a primary flicker frequency of 2Hz as a compromise between the low-pass pupil response (see Barrionuevo et al., 2014; Spitschan et al., 2014), and the relatively higher-pass EEG response (Regan, 1966).’</p><p>We also mention why the pupil response is low-pass:</p><p>‘The pupil response can be modulated by periodic changes in luminance, and is temporally low-pass (Barrionuevo et al., 2014; Spitschan et al. 2014), most likely due to the mechanical limitations of the iris sphincter and dilator muscles’.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Previous studies have extensively explored the rules by which patterned inputs from the two eyes are combined in the visual cortex. Here the authors explore these rules for un-patterned inputs (luminance flicker) at both the level of the cortex, using Steady-State Visual Evoked Potentials (SSVEPs) and at the sub-cortical level using pupillary responses. They find that the pattern of binocular combination differs between cortical and sub-cortical levels with the cortex showing less dichoptic masking and somewhat more binocular facilitation.</p><p>Importantly, the present results with flicker differ markedly from those with gratings (Hou et al., 2020, J Neurosci, Baker and Wade 2017 cerebral cortex, Norcia et al, 2000 Nuroreport, Brown et al., 1999, IOVS). When SSVEP responses are measured under dichoptic conditions where each eye is driven with a unique temporal frequency, in the case of grating stimuli, the magnitude of the response in the fixed contrast eye decreases as a function of contrast in the variable contrast eye. Here the response increases by varying (small) magnitudes. The authors favor a view that cortex and perception pool binocular flicker inputs approximately linearly using cells that are largely monocular. The lack of a decrease below the monocular level when modulation strength increase is taken to indicate that previously observed normalization mechanism in pattern vision does not play a substantial role in the processing of flicker. The authors present a computational model of binocular combination that captures features of the data when fit separately to each data set. Because the model has no frequency dependence and is based on scalar quantities, it cannot make joint predictions for the multiple experimental conditions which is one of its limitations.</p><p>A strength of the current work is the use of frequency-tagging of both pupil and EEG responses to measure responses for flicker stimuli at two anatomical levels of processing. Flicker responses are interesting but have been relatively neglected. The tagging approach allows one to access responses driven by each eye, even when the other eye is stimulated which is a great strength. The tagging approach can be applied at both levels of processing at the same time when stimulus frequencies are low, which is an advantage as they can be directly compared. The authors demonstrate the versatility of frequency tagging in a novel experimental design which may inspire other uses, both within the present context and others. A disadvantage of the tagging approach for studying sub-cortical dynamics via pupil responses is that it is restricted to low temporal frequencies given the temporal bandwidth of the pupil. The inclusion of a behavioral measure and a model is also a strength, but there are some limitations in the modeling (see below).</p><p>The authors suggest in the discussion that luminance flicker may preferentially drive cortical mechanisms that are largely monocular and in the results that they are approximately linear in the dichoptic cross condition (no effect of the fixed contrast stimulus in the other eye). By contrast, prior research using dichoptic dual frequency flickering stimuli has found robust intermodulation (IM) components in the VEP response spectrum (Baitch and Levi, 1988, Vision Res; Stevens et al., 1994 J Ped Ophthal Strab; France and Ver Hoeve, 1994, J Ped Ophthal Strab; Suter et al., 1996 Vis Neurosci). The presence of IM is a direct signature of binocular interaction and suggests that at least under some measurement conditions, binocular luminance combination is &quot;essentially&quot; non-linear, where essential implies a point-like non-linearity such as squaring of excitatory inputs. The two views are in striking contrast. It would thus be useful for the authors could show spectra for the dichoptic, two-frequency conditions to see if non-linear binocular IM components are present.</p></disp-quote><p>This is an excellent point, and one that we had not previously appreciated the importance of. We have generated a figure (Fig 8) showing the IM response in the cross frequency conditions. There is a clear response at 0.4Hz in the pupillometry data (2-1.6Hz), and at 3.6Hz in the EEG data (2+1.6Hz). We therefore agree that this shows the system is essentially nonlinear, despite the binocular combination appearing approximately linear. We now say in the Discussion:</p><p>‘In the steady-state literature, one hallmark of a nonlinear system is the presence of intermodulation responses at the sums and differences of fundamental flicker frequencies (Baitch &amp; Levi, 1988; Tsai et al., 2012). In Figure 8 we plot the amplitude spectra of conditions from Experiment 1 in which the two eyes were stimulated at different frequencies (2Hz and 1.6Hz) but at the same contrast (48%; these correspond to the binocular cross and dichoptic cross conditions in Figures 2d,e and 3d,e). Consistent with the temporal properties of pupil responses and EEG, Figure 8a reveals a strong intermodulation difference response at 0.4Hz (red dashed line), and Figure 8b reveals an intermodulation sum response at 3.6Hz (red dashed line). The presence of these intermodulation terms is predicted by nonlinear gain control models of the type considered here (Baker and Wade, 2017; Tsai et al., 2012), and indicates that the processing of monocular flicker signals is not fully linear prior to the point at which they are combined across the eyes.’</p><disp-quote content-type="editor-comment"><p>If the IM components are indeed absent, then there is a question of the generality of the conclusions, given that several previous studies have found them with dichoptic flicker. The previous studies differ from the authors' in terms of larger stimuli and in their use of higher temporal frequencies (e.g. 18/20 Hz, 17/21 Hz, 6/8 Hz). Either retinal area stimulated (periphery vs central field) or stimulus frequency (high vs low) could affect the results and thus the conclusions about the nature of dichoptic flicker processing in cortex. It would be interesting to sort this out as it may point the research in new directions.</p></disp-quote><p>This is a great suggestion about retinal area. As chance would have it, we had already collected a replication data set where we stimulated the periphery, and we now include a summary of this data set as an Appendix. In general the results are similar, though we obtain a measurable (though still small) second harmonic response in the pupillometry data with this configuration, which is a further indication of nonlinear processing.</p><disp-quote content-type="editor-comment"><p>Whether these components are present or absent is of interest in terms of the authors' computational model of binocular combination. It appears that the present model is based on scalar magnitudes, rather than vectors as in Baker and Wade (2017), so it would be silent on this point. The final summation of the separate eye inputs is linear in the model. In the first stage of the model, each eye's input is divided by a weighted input from the other eye. If we take this input as inhibitory, then IM would not emerge from this stage either.</p></disp-quote><p>We have performed the modelling using scalar values here for simplicity and transparency, and to make the fitting process computationally feasible (it took several days even done this way). This type of model is quite capable of processing sine waves as inputs, and producing a complex output waveform which is Fourier transformed and then analysed in the same way as the experimental data (see e.g. Tsai, Wade &amp; Norcia, 2012, J Neurosci; Baker &amp; Wade, 2017, Cereb Cortex). However our primary aim here was to fit the model, and make inferences about the parameter values, rather than to use a specific set of parameter values to make predictions.We now say more about this family of models and how they can be applied in the methods section:</p><p>“Models from this family can handle both scalar contrast values and continuous waveforms (Tsai et al., 2012) or images (Meese and Summers, 2007) as inputs. For time-varying inputs, the calculations are performed at each time point, and the output waveform can then be analysed using Fourier analysis in the same way as for empirical data.This means that the model can make predictions for the entire Fourier spectrum, including harmonic and intermodulation responses that arise as a consequence of nonlinearities in the model (Baker and Wade, 2017). However for computational tractability, we performed fitting here using scalar contrast values.”</p><p>As a side point, there are quite a lot of ways to produce intermodulation terms, meaning they are not as diagnostic as one might suppose. We demonstrate this in Author response image 1, which shows the Fourier spectra produced by a toy model that multiplies its two inputs together (for an interactive python notebook that allows various nonlinearities to be explored, see here). Intermodulation terms also arise when two inputs of different frequencies are summed, followed by exponentiation. So it would be possible to have an entirely linear binocular summation process, followed by squaring, and have this generate IM terms (not that we think this is necessarily what is happening in our experiments).</p><fig id="sa3fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87048-sa3-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>Related to the model: One of the more striking results is the substantial difference between the dichoptic and dichoptic-cross conditions. They differ in that the latter has two different frequencies in the two eyes while the former has the same frequency in each eye. As it stands, if fit jointly on the two conditions, the model would make the same prediction for the dichoptic and dichoptic-cross conditions. It would also make the same prediction whether the two eyes were in-phase temporally or in anti-phase temporally. There is no frequency/phase-dependence in the model to explain differences in these cases or to potentially explain different patterns at the different VEP response harmonics. The model also fits independently to each data set which weakens its generality. An interpretation outside of the model framework would thus be helpful for the specific case of differences between the dichoptic and dichoptic-cross conditions.</p></disp-quote><p>As mentioned above, the limitations the reviewer highlights are features of the specific implementation, rather than the model architecture in general. Furthermore, although this particular implementation of the model does not have separate channels for different phases, these can be added (see e.g. Georgeson et al., 2016, Vis Res, for an example in the spatial domain). In future work we intend to explore the phase relationship of flicker, but do not have space to do this here.</p><disp-quote content-type="editor-comment"><p>Prior work has defined several regimes of binocular summation in the VEP (Apkarian et al.,1981 EEG Journal). It would be useful for the authors to relate the use of their terms &quot;facilitation&quot; and &quot;suppression&quot; to these regimes and to justify/clarify differences in usage, when present. Experiment 1, Fig. 3 shows cases where the binocular response is more than twice the monocular response. Here the interpretation is clear: the responses are super-additive and would be classed as involving facilitation in the Apkarian et al framework. In the Apkarian et al framework, a ratio of 2 indicates independence/linearity. Ratios between 1 and 2 indicate sub-additivity and are diagnostic of the presence of binocular interaction but are noted by them to be difficult to interpret mechanistically. This should be discussed. A ratio of &lt;1 indicates frank suppression which is not observed here with flicker.</p></disp-quote><p>Operationally, we use facilitation to mean an increase in response relative to a monocular baseline, and suppression to mean a decrease in response. We now state this explicitly in the Introduction. Facilitation greater than a factor of 2 indicates some form of super-additive summation. In the context of the model, we also use the term suppression to indicate divisive suppression between channels, however this feature does not always result in empirical suppression (it depends on the condition, and the inhibitory weight). We think that interpretation of results such as these is greatly aided by the use of a computational modelling framework, which is why we take this approach here. The broad applicability of the model we use in the domain of spatial contrast lends it credibility for our stimuli here.</p><disp-quote content-type="editor-comment"><p>Can the model explore the full range of binocular/monocular ratios in the Apkarian et al framework? I believe much of the data lies in the &quot;partial summation&quot; regime of Apkarian et al and that the model is mainly exploring this regime and is a way of quantifying varying degrees of partial summation.</p></disp-quote><p>Yes, in principle the model can produce the full range of behaviours. When the weight of suppression is 1, binocular and monocular responses are equal. When the weight is zero, the model produces linear summation. When the weight is greater than 1, suppression occurs. It is also possible to produce super-additive summation effects, most straightforwardly by changing the model exponents. However this was not required for our data here, and so we kept these parameters fixed. We agree that the model is a good way to unify the results across disparate experimental paradigms, and that is our main intention with Figure 7i.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>This manuscript describes interesting experiments on how information from the two eyes is combined in cortical areas, sub-cortical areas, and perception. The experimental techniques are strong and the results are potentially quite interesting. But the manuscript is poorly written and tries to do too much in too little space. I had a lot of difficulty understanding the various experimental conditions, the complicated results, and the interpretations of those results. I think this is an interesting and useful project so I hope the authors will put in the time to revise the manuscript so that regular readers like myself can better understand what it all means.</p><p>Now for my concerns and suggestions:</p><p>The experimental conditions are novel and complicated, so readers will not readily grasp what the various conditions are and why they were chosen. For example, in one condition different flicker frequencies were presented to the two eyes (2Hz to one and 1.6Hz to the other) with the flicker amplitude fixed in the eye presented to the lower frequency and the flicker amplitude varied in the eye presented to the higher frequency. This is just one of several conditions that the reader has to understand in order to follow the experimental design. I have a few suggestions to make it easier to follow. First, create a figure showing graphically the various conditions. Second, come up with better names for the various conditions and use those names in clear labels in the data figures and in the appropriate captions. Third, combine the specific methods and results sections for each experiment so that one will have just gone through the relevant methods before moving forward into the results. The authors can keep a general methods section separate, but only for the methods that are general to the whole set of experiments.</p></disp-quote><p>We have created a new figure (now Fig 1) that illustrates the conditions from Experiment 1, and is referenced throughout the paper. We have kept the names constant, as they are rooted in a substantial existing literature, and it will be confusing to readers familiar with that work if we diverge from these conventions. We did consider separating out the methods section, but feel it helps the flow of the results section to keep it as a single section.</p><disp-quote content-type="editor-comment"><p>I wondered why the authors chose the temporal frequencies they did. Barrionuevo et al (2014) showed that the human pupil response is greatest at 1Hz and is nearly a log unit lower at 2Hz (i.e., the change in diameter is nearly a log unit lower; the change in area is nearly 2 log units lower). So why did the authors choose 2Hz for their primary frequency? And why did the authors choose 1.6Hz which is quite close to 2Hz for their off frequency? The rationale behind these important decisions should be made explicit.</p></disp-quote><p>We now explain this in the Introduction as follows:</p><p>‘We chose a primary flicker frequency of 2Hz as a compromise between the low-pass pupil response (see Barrionuevo et al., 2014; Spitschan et al., 2014), and the relatively higher-pass EEG response (Regan, 1966).’</p><p>It is a compromise frequency that is not optimal for either modality, but generates a measurable signal for both. The choice of 1.6 Hz was for similar reasons - for a 10-second trial it is four frequency bins away from the primary frequency, so can be unambiguously isolated in the spectrum.</p><disp-quote content-type="editor-comment"><p>By the way, I wondered if we know what happens when you present the same flicker frequencies to the two eyes but in counter-phase. The average luminance seen binocularly would always be the same, so if the pupil system is linear, there should be no pupil response to this stimulus. An experiment like this has been done by Flitcroft et al (1992) on accommodation where the two eyes are presented stimuli moving oppositely in optical distance and indeed there was no accommodative response, which strongly suggests linearity.</p></disp-quote><p>We have not tried this yet, but it’s on our to-do list for future work. The accommodation work is very interesting, and we now cite it in the manuscript as follows:</p><p>‘Work on the accommodative response indicates that binocular combination there is approximately linear (Flitcroft et al. 1992), and can even cancel when signals are in antiphase (we did not try this configuration here).’</p><disp-quote content-type="editor-comment"><p>Figures 1 and 2 are important figures because they show the pupil and EEG results, respectively. But it's really hard to get your head around what's being shown in the lower row of each figure. The labeling for the conditions is one problem. You have to remember how &quot;binocular&quot; in panel c differs from &quot;binocular cross&quot; in panel d. And how &quot;monocular&quot; in panel d is different than &quot;monocular 1.6Hz&quot; in panel e. Additionally, the colors of the data symbols are not very distinct so it makes it hard to determine which one is which condition. These results are interesting. But they are difficult to digest.</p></disp-quote><p>We hope that the new Figure 1 outlining the conditions has helped with interpretation here.</p><disp-quote content-type="editor-comment"><p>The authors make a strong claim that they have found substantial differences in binocular interaction between cortical and sub-cortical circuits. But when I look at Figures 1 and 2, which are meant to convey this conclusion, I'm struck by how similar the results are. If the authors want to continue to make their claim, they need to spend more time making the case.</p></disp-quote><p>Indeed, it is hard to make direct comparisons across figures - this is why Figure 4 plots the ratio of binocular to monocular conditions, and shows a clear divergence between the EEG and pupillometry results at high contrasts.</p><disp-quote content-type="editor-comment"><p>Figure 5 is thankfully easy to understand and shows a very clear result. These perceptual results deviate dramatically from the essentially winner-take-all results for spatial sinewaves shown by Legge &amp; Rubin (1981); whom they should cite by the way. Thus, very interestingly the binocular combination of temporal variation is quite different than the binocular combination of spatial variation. Can the pupil and EEG results also be plotted in the fashion of Figure 5? You'd pick a criterion pupil (or EEG) change and use it to make such plots.</p></disp-quote><p>We now cite Legge &amp; Rubin. We see what you mean about plotting the EEG and pupillometry results in the same coordinates as the matching data, but we don’t think this is especially informative as we would end up only with data points along the axes and diagonal of the plot, without the points at other angles. This is a consequence of how the experiments were conducted.</p><disp-quote content-type="editor-comment"><p>My main suggestion is that the authors need to devote more space to explaining what they've done, what they've found, and how they interpret the data. I suggest therefore that they drop the computational model altogether so that they can concentrate on the experiments. The model could be presented in a future paper.</p></disp-quote><p>We feel that the model is central to the understanding and interpretation of our results, and have retained it in the revised version of the paper.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>I found the terms for the stimulus conditions confusing. I think a simple schematic diagram of the conditions would help the reader.</p></disp-quote><p>Now added (the new Fig 1).</p><disp-quote content-type="editor-comment"><p>In reporting the binocular to monocular ratio, please clarify whether the monocular data was from one eye alone (and how that eye was chosen) or from both eyes and then averaged, or something else. It would be useful to plot the results from the dichoptic condition in this form, as well.</p></disp-quote><p>These were averaged across both eyes. We now say in the Methods section:</p><p>‘We confirmed in additional analyses that the monocular consensual pupil response was complete, justifying our pooling of data across the eyes.’</p><disp-quote content-type="editor-comment"><p>Also, clarify whether the term facilitation is used as above throughout (facilitation being &gt; 2 times monocular response under binocular condition) or if a different criterion is being used. If we take facilitation to mean a ratio &gt; 2, then facilitation depends on temporal frequency in Figure 4.</p></disp-quote><p>We now explain our use of these terms in the final paragraph of the Introduction:</p><p>‘Relative to the response to a monocular signal, adding a signal in the other eye can either increase the response (facilitation) or reduce it (suppression).’</p><disp-quote content-type="editor-comment"><p>The magnitude of explicit facilitation attained is interesting, but not without precedent. Ratios of binocular to mean monocular &gt; 2, have been reported previously and values of summation depend strongly on the stimulus used (see for example Apkarian et al., EEG Journal, 1981, Nicol et al., Doc Ophthal, 2011).</p></disp-quote><p>We now mention this in the Discussion as follows:</p><p>‘(however we note that facilitation as substantial as ours has been reported in previous EEG work by Apkarian et al. (1981))’</p><disp-quote content-type="editor-comment"><p>In Experiment 3, the authors say that the psychophysical matching results are consistent with the approximately linear summation effects observed in the EEG data of Experiment 1. In describing Fig. 3, the claim is that the EEG is non-linear, e.g. super-additive - at least at high contrasts. Please reconcile these statements.</p></disp-quote><p>We think that the ‘superadditive’ effects are close enough to linear that we don’t want to make too much of a big deal about them - this could be measurement error, for example. So we use terms such as near-linear, or approximately linear, when referring to them throughout.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>Let me make some more specific comments using a page/paragraph/line format to indicate where in the text they're relevant.</p><p>1/2 (middle)/3 from end. &quot;In addition&quot; seems out of place here.</p></disp-quote><p>Removed.</p><disp-quote content-type="editor-comment"><p>1/3/4. By &quot;intensities&quot; do you mean &quot;contrasts&quot;?</p></disp-quote><p>Fixed.</p><disp-quote content-type="editor-comment"><p>1/3/last. &quot;... eyes'...&quot;.</p></disp-quote><p>Fixed.</p><disp-quote content-type="editor-comment"><p>2/5/3. By &quot;one binocular disc&quot;, you mean into &quot;one perceptually fused disc&quot;.</p></disp-quote><p>Rewritten as: ‘to help with their perceptual fusion, giving the appearance of a single binocular disc’</p><disp-quote content-type="editor-comment"><p>3/1/1. &quot;calibrated&quot; seems like the wrong word here. I think you're just changing the vergence angle to enable fusion, right?</p></disp-quote><p>Now rewritten as: ‘Before each experiment, participants adjusted the angle of the stereoscope mirrors to achieve binocular fusion’</p><disp-quote content-type="editor-comment"><p>3/1/1. &quot;adjusting the angles...&quot;. And didn't changing the mirror angles affect the shapes of the discs in the retinal images?</p></disp-quote><p>Perhaps very slightly, but this is well within the tolerance of the visual system to compensate for in the fused image, especially for such high contrast edges.</p><disp-quote content-type="editor-comment"><p>3/3/5. &quot;fixed contrast&quot; is confusing here because it's still a flickering stimulus if I follow the text here. Reword.</p></disp-quote><p>Now ‘fixed temporal contrast’</p><disp-quote content-type="editor-comment"><p>3/4/1. It would be clearer to say &quot;pupil tracker&quot; rather than &quot;eye tracker&quot; because you're not really doing eye tracking.</p></disp-quote><p>True, but the device is a commercial eye tracker, so this is the appropriate term regardless of what we are using it for.</p><disp-quote content-type="editor-comment"><p>3/5/6. I'm getting lost here. &quot;varying contrast levels&quot; applies to the dichoptic stimulus, right?</p></disp-quote><p>Yes, now reworded as ‘In the other interval, a target disc was displayed, flickering at different contrast levels on each trial, but with a fixed interocular contrast ratio across the block.’</p><disp-quote content-type="editor-comment"><p>3/5/7. Understanding the &quot;ratio of flicker amplitudes&quot; is key to understanding what's going on here. More explanation would be helpful.</p></disp-quote><p>Addressed in the above point.</p><disp-quote content-type="editor-comment"><p>4/3/near end. Provide some explanation about why the Fourier approach is more robust to noise.</p></disp-quote><p>Added ‘(which can make the phase and amplitude of a fitted sine wave unstable)’</p><disp-quote content-type="editor-comment"><p>Figure 1. In panel a, explain what the numbers on the ordinate mean. What's zero, for example? Which direction is dilation? Same question for panel b. It's interesting in panel c that the response in one eye to 2Hz increases when the other eye sees 1.6Hz. Would be good to point that out in the text.</p></disp-quote><p>Good idea about panel (a) - we have changed the y-axis to ‘Relative amplitude’ for clarity, and now note in the figure caption that ‘Negative values indicate constriction relative to baseline, and positive values indicate dilation.’ Panel (b) is absolute amplitude, so is unsigned. Panel (c) only contains 2Hz conditions, but there is some dichoptic suppression across the two frequencies in panels (d,e) - we now cover this in the text and include statistics.</p><disp-quote content-type="editor-comment"><p>6/2/1. Make clear in the text that Figure 1c shows contrast response functions for the pupil.</p></disp-quote><p>Now noted in the caption.</p><disp-quote content-type="editor-comment"><p>Figure 3. I'm lost here. I feel like I should be able to construct this figure from Figures 1 and 2, but don't know how. More explanation is needed at least in the caption.</p></disp-quote><p>Done. The caption now reads:</p><p>‘Ratio of binocular to monocular response for three data types. These were calculated by dividing the binocular response by the monocular response at each contrast level, using the data underlying Figures 2c, 3c and 3f. Each value is the average ratio across N=30 participants, and error bars indicate bootstrapped standard errors.’</p><disp-quote content-type="editor-comment"><p>9/1/1-2. I didn't find the evidence supporting this statement compelling.</p></disp-quote><p>We now point the reader to Figure 4 as a reminder of the evidence for this difference.</p><disp-quote content-type="editor-comment"><p>9/1/6-9. You said this. But this kind of problem can be fixed by moving the methods sections as I suggested above.</p></disp-quote><p>As mentioned, we feel that the results section flows better with the current structure.</p><disp-quote content-type="editor-comment"><p>Figure 4. Make clear that this is EEG data.</p></disp-quote><p>Now added to caption.</p><disp-quote content-type="editor-comment"><p>Figure 5 caption. Infinite exponent in what equation?</p></disp-quote><p>Now clarified as: ‘models involving linear combination (dotted) or a winner-take-all rule (dashed)’</p><disp-quote content-type="editor-comment"><p>Figure 6. I hope this gets dropped. No one will understand how the model predictions were derived. And those who look at the data and model predictions will surely note (as the authors do) that they are rather different from one another.</p></disp-quote><p>As noted above, we feel that the model is central to the paper and have retained this figure. We have also worked out how to correct the noise parameter in the model for the number of participants included in the coherent averaging, which fixes the discrepancy at low contrasts. The correspondence between the data and model in is now very good, and we have plotted the data points and curves in the same panels, which makes the figure less busy.</p><disp-quote content-type="editor-comment"><p>12/1. Make clear in this paragraph that &quot;visual cortex&quot; is referring to EEG and perception results and that &quot;subcortical&quot; is referring to pupil. Explain clearly what &quot;linear&quot; would be and what the evidence for &quot;non-linear&quot; is.</p></disp-quote><p>Good suggestion, we have added qualifiers linking to both methods. Also tidied up the language to make it clearer that we are talking about binocular combination specifically in terms of linearity, and spelled out the evidence for each point.</p><disp-quote content-type="editor-comment"><p>12/2/6-9. Explain the Quaia et al results enough for the reader to know what reflexive eye movements were studied and how.</p></disp-quote><p>We now specify that these eye movements are also known as the ‘ocular following response’ and were measured using scleral search coils.</p><disp-quote content-type="editor-comment"><p>12/2/9-10. Same for Spitchan and Cajochen: more explanation.</p></disp-quote><p>Added:</p><p>“(melatonin is a hormone released by the pineal gland that regulates sleep; its production is suppressed by light exposure and can be measured from saliva assays)”</p><disp-quote content-type="editor-comment"><p>12/3/2-3. Intriguing statements about optimally combining noisy signals, but explain this more. It won't be obvious to most readers.</p></disp-quote><p>We have added some more explanation to this section.</p><disp-quote content-type="editor-comment"><p>13/1. This is an interesting paragraph where the authors have a chance to discuss what would be most advantageous to the organism. They make the standard argument for perception, but basically punt on having an argument for the pupil.</p></disp-quote><p>Indeed, we agree that this point is necessarily speculative, however we think it is interesting for the reader to consider.</p><disp-quote content-type="editor-comment"><p>13/2/1. &quot;Pupil size affects the ...&quot; is more accurate.</p></disp-quote><p>Fixed.</p><disp-quote content-type="editor-comment"><p>13/2/2 from end. Which &quot;two pathways&quot;? Be clear.</p></disp-quote><p>Changed to ‘the pupil and perceptual pathways’</p></body></sub-article></article>