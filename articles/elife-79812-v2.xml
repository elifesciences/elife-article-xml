<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">79812</article-id><article-id pub-id-type="doi">10.7554/eLife.79812</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Cell Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group></article-categories><title-group><article-title>Determining growth rates from bright-field images of budding cells through identifying overlaps</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-115694"><name><surname>Pietsch</surname><given-names>Julian MJ</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9992-2384</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-278908"><name><surname>Muñoz</surname><given-names>Alán F</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-278909"><name><surname>Adjavon</surname><given-names>Diane-Yayra A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-278910"><name><surname>Farquhar</surname><given-names>Iseabail</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-278911"><name><surname>Clark</surname><given-names>Ivan BN</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-24128"><name><surname>Swain</surname><given-names>Peter S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7489-8587</contrib-id><email>peter.swain@ed.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01nrxwf90</institution-id><institution>Centre for Engineering Biology and School of Biological Sciences, University of Edinburgh</institution></institution-wrap><addr-line><named-content content-type="city">Edinburgh</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Moses</surname><given-names>Alan M</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Eisen</surname><given-names>Michael B</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>University of California, Berkeley</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>07</day><month>07</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e79812</elocation-id><history><date date-type="received" iso-8601-date="2022-04-27"><day>27</day><month>04</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-07-06"><day>06</day><month>07</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-05-12"><day>12</day><month>05</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.05.11.491488"/></event></pub-history><permissions><copyright-statement>© 2023, Pietsch et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Pietsch et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-79812-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-79812-figures-v2.pdf"/><abstract><p>Much of biochemical regulation ultimately controls growth rate, particularly in microbes. Although time-lapse microscopy visualises cells, determining their growth rates is challenging, particularly for those that divide asymmetrically, like <italic>Saccharomyces cerevisiae</italic>, because cells often overlap in images. Here, we present the Birth Annotator for Budding Yeast (BABY), an algorithm to determine single-cell growth rates from label-free images. Using a convolutional neural network, BABY resolves overlaps through separating cells by size and assigns buds to mothers by identifying bud necks. BABY uses machine learning to track cells and determine lineages and estimates growth rates as the rates of change of volumes. Using BABY and a microfluidic device, we show that bud growth is likely first sizer- then timer-controlled, that the nuclear concentration of Sfp1, a regulator of ribosome biogenesis, varies before the growth rate does, and that growth rate can be used for real-time control. By estimating single-cell growth rates and so fitness, BABY should generate much biological insight.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>time-lapse microscopy</kwd><kwd>image processing</kwd><kwd>growth rate</kwd><kwd>single cells</kwd><kwd>machine learning</kwd><kwd>budding cells</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>S. cerevisiae</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000275</institution-id><institution>Leverhulme Trust</institution></institution-wrap></funding-source><award-id>RPG-2018-04</award-id><principal-award-recipient><name><surname>Swain</surname><given-names>Peter S</given-names></name><name><surname>Pietsch</surname><given-names>Julian MJ</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/R001359/1</award-id><principal-award-recipient><name><surname>Swain</surname><given-names>Peter S</given-names></name><name><surname>Clark</surname><given-names>Ivan BN</given-names></name><name><surname>Farquhar</surname><given-names>Iseabail</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100018694</institution-id><institution>Marie Sklodowska-Curie Actions</institution></institution-wrap></funding-source><award-id>764591 - SynCrop</award-id><principal-award-recipient><name><surname>Muñoz</surname><given-names>Alán F</given-names></name><name><surname>Adjavon</surname><given-names>Diane-Yayra A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The BABY algorithm by estimating growth rates of individual cells from time-lapse microscopy images will help characterise the diversity in populations of budding cells, particularly differences in fitness.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>For microbes, growth rate correlates strongly with fitness (<xref ref-type="bibr" rid="bib58">Orr, 2009</xref>). Cells increase growth rates through balancing their synthesis of ribosomes with their intake of nutrients (<xref ref-type="bibr" rid="bib10">Broach, 2012</xref>; <xref ref-type="bibr" rid="bib46">Levy and Barkai, 2009</xref>; <xref ref-type="bibr" rid="bib69">Scott et al., 2014</xref>) and target a particular size through coordinating growth with division (<xref ref-type="bibr" rid="bib41">Johnston et al., 1977</xref>; <xref ref-type="bibr" rid="bib42">Jorgensen et al., 2004</xref>; <xref ref-type="bibr" rid="bib20">Di Talia et al., 2007</xref>; <xref ref-type="bibr" rid="bib75">Turner et al., 2012</xref>). Metazoans, too, not only coordinate growth over time but also in space to both size and position cells correctly (<xref ref-type="bibr" rid="bib29">Ginzberg et al., 2015</xref>).</p><p>To understand how organisms regulate growth rate, studying single cells is often most informative (<xref ref-type="bibr" rid="bib57">Murugan et al., 2021</xref>). Time-lapse microscopy, particularly with microfluidic technology to control the extracellular environment (<xref ref-type="bibr" rid="bib49">Locke and Elowitz, 2009</xref>; <xref ref-type="bibr" rid="bib6">Bennett and Hasty, 2009</xref>), has been pivotal, allowing, for example, studies of the cell-cycle machinery (<xref ref-type="bibr" rid="bib20">Di Talia et al., 2007</xref>), of the control of cell size (<xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>; <xref ref-type="bibr" rid="bib68">Schmoller et al., 2015</xref>; <xref ref-type="bibr" rid="bib71">Soifer et al., 2016</xref>), of antibiotic effects (<xref ref-type="bibr" rid="bib14">Coates et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">El Meouche and Dunlop, 2018</xref>), of the response to stress (<xref ref-type="bibr" rid="bib47">Levy et al., 2012</xref>; <xref ref-type="bibr" rid="bib33">Granados et al., 2017</xref>; <xref ref-type="bibr" rid="bib34">Granados et al., 2018</xref>), of feedback between growth and metabolism (<xref ref-type="bibr" rid="bib43">Kiviet et al., 2014</xref>), and of ageing (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>).</p><p>For cells that bud, like <italic>Saccharomyces cerevisiae</italic>, estimating an instantaneous growth rate for individual cells is challenging. <italic>S. cerevisiae</italic> grows by forming a bud that increases in size while the volume of the rest of the cell remains relatively unchanged. Although single-cell growth rate is typically reported as the rate of change of volume (<xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>; <xref ref-type="bibr" rid="bib71">Soifer et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Chandler-Brown et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>; <xref ref-type="bibr" rid="bib28">Garmendia-Torres et al., 2018</xref>; <xref ref-type="bibr" rid="bib48">Litsios et al., 2019</xref>), which approximates a cell’s increase in mass, these estimates rely on solving multiple computational challenges: accurately determining the outlines of cells – particularly buds – in images, extrapolating these outlines to volumes, tracking cells over time, assigning buds to the appropriate mother cells, and identifying budding events. Growth rates for budding yeast are therefore often only reported for isolated cells using low-throughput and semi-automated methods (<xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>; <xref ref-type="bibr" rid="bib48">Litsios et al., 2019</xref>). In contrast, for rod-shaped cells that divide symmetrically, like <italic>Escherichia coli</italic>, the growth rate can be found more simply, as the rate of change of a cell’s length (<xref ref-type="bibr" rid="bib43">Kiviet et al., 2014</xref>).</p><p>A particular difficulty is identifying cell boundaries because neighbouring cells in images often overlap: like other microbes, yeast grows in colonies. Although samples for microscopy are often prepared to encourage cells to grow in monolayers (<xref ref-type="bibr" rid="bib49">Locke and Elowitz, 2009</xref>), growth can be more complex because cells inevitably have different sizes. We observe substantial and frequent overlaps between buds and neighbouring cells in ALCATRAS microfluidic devices (<xref ref-type="bibr" rid="bib17">Crane et al., 2014</xref>). Inspecting images obtained by others, we believe overlap is a widespread, if undeclared, problem: it occurs during growth in the commercial CellASIC devices (<xref ref-type="bibr" rid="bib81">Wood and Doncic, 2019</xref>; <xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>), against an agar substrate (<xref ref-type="bibr" rid="bib25">Falconnet et al., 2011</xref>; <xref ref-type="bibr" rid="bib71">Soifer et al., 2016</xref>), in a microfluidic dissection platform (<xref ref-type="bibr" rid="bib48">Litsios et al., 2019</xref>), and in microfluidic devices requiring cells to be attached to the cover slip (<xref ref-type="bibr" rid="bib35">Hansen et al., 2015</xref>).</p><p>Yet only a few algorithms allow for overlaps (<xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Lu et al., 2019</xref>) despite software to automatically identify and track cells in bright-field and phase-contrast images being well established (<xref ref-type="bibr" rid="bib32">Gordon et al., 2007</xref>; <xref ref-type="bibr" rid="bib25">Falconnet et al., 2011</xref>; <xref ref-type="bibr" rid="bib80">Versari et al., 2017</xref>; <xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>; <xref ref-type="bibr" rid="bib81">Wood and Doncic, 2019</xref>) and enhanced with deep learning (<xref ref-type="bibr" rid="bib26">Falk et al., 2019</xref>; <xref ref-type="bibr" rid="bib50">Lu et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>; <xref ref-type="bibr" rid="bib72">Stringer et al., 2021</xref>). For example, the convolutional neural network U-net (<xref ref-type="bibr" rid="bib65">Ronneberger et al., 2015a</xref>), a workhorse in biomedical image processing, identifies which pixels in an image are likely from cells, but researchers must find individual cells from these predictions using additional techniques. Even then different instances of cells typically cannot overlap (<xref ref-type="bibr" rid="bib26">Falk et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>). Other deep-learning approaches, like Mask-RCNN (<xref ref-type="bibr" rid="bib38">He et al., 2017</xref>) and extended U-nets like StarDist (<xref ref-type="bibr" rid="bib67">Schmidt et al., 2018</xref>), can identify overlapping instances in principle, but typically do not, either by implementation (<xref ref-type="bibr" rid="bib67">Schmidt et al., 2018</xref>) or by the labelling of the training data (<xref ref-type="bibr" rid="bib50">Lu et al., 2019</xref>). Furthermore, assigning lineages and births is often performed manually (<xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Chandler-Brown et al., 2017</xref>) or through fluorescent markers (<xref ref-type="bibr" rid="bib71">Soifer et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Garmendia-Torres et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Cuny et al., 2022</xref>), but such markers require an imaging channel.</p><p>Here, we describe the Birth Annotator for Budding Yeast (BABY), a complete pipeline to determine single-cell growth rates from label-free images of budding yeast. In developing BABY, we solved multiple image-processing challenges generated by cells dividing asymmetrically. BABY resolves instances of overlapping cells – buds, particularly small ones, usually overlap with their mothers or neighbours – by extending the U-net architecture with custom training targets and then applying additional image processing. It tracks cells between time points with a machine-learning algorithm, which is able to resolve any large movements of cells from one image to the next, and assigns buds to their mothers, informed by the U-net. These innovations improve performance. BABY produces high-fidelity time series of the volumes of both mother cells and buds and so the instantaneous growth rates of single cells.</p><p>Using BABY, we see a peak in growth rate during the S/G2/M phase of the cell cycle and show that this peak indicates where the bud’s growth transitions from being sizer- to timer-controlled. Studying Sfp1, an activator of ribosome synthesis, we observe that fluctuations in this regulator’s nuclear concentration correlate with but precede those in growth rate. Finally, we demonstrate that BABY enables real-time control, running an experiment where changes in the extracellular medium are triggered automatically when the growth of the imaged cells crosses a pre-determined threshold.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Segmenting overlapping cells using a multi-target convolutional neural network</title><p>To estimate single-cell growth rates from time-lapse microscopy images, correctly identifying cells is essential. Poorly defined outlines, missed time points, and mistakenly joined cells all degrade accuracy.</p><p>Segmenting asymmetrically dividing cells, such as budding yeast, is challenging. The differing sizes of the mothers and buds makes each appear and behave distinctly, yet identifying buds is crucial because they have the fastest growth rates (<xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Even when constrained in a microfluidic device, buds imaged in a single Z section often appear to overlap with their mother and neighbouring cells (<xref ref-type="fig" rid="fig1">Figure 1a and b</xref>). If an algorithm is able to separate the cells, the area of either the bud or the neighbouring cells is often underestimated, and the bud may even be missed entirely. Buds also move more in the Z-axis relative to mother cells, changing how they appear in bright-field images (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). Depending on the focal plane, a bud may be difficult to detect by eye. Nevertheless, our BABY algorithm maintains high reliability (<xref ref-type="fig" rid="fig1">Figure 1e</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Reliably identifying individual cells makes automatically segmenting label-free cells that bud challenging.</title><p>(<bold>a</bold>) A schematic of a budding cell constrained in a microfluidic device showing how a mother cell can produce a bud beneath the previous daughter. The microscope, denoted by the eye, sees a projection of these cells. (<bold>b</bold>) A time series of bright-field images of budding yeast trapped in an ALCATRAS microfluidic device (<xref ref-type="bibr" rid="bib17">Crane et al., 2014</xref>), in which a growing bud (white arrowheads) overlaps with both its sister and mother. On the duplicated images below, we show outlines produced by BABY. (<bold>c</bold>) Bright-field images of growing buds (white arrowheads) taken at different focal planes demonstrate how the appearance of small buds may change. (<bold>d</bold>) Cells can move substantially from image to image. Here medium flowing through the microfluidic device causes a cell to wash out between time points and the remaining cells to pivot. We indicate the correct lineage assignment by white arrowheads and the correct tracking by the numbers within the BABY outlines. (<bold>e</bold>) We show a time series of a mother (purple) and its buds and daughters for a switch from 2% to 0.1% glucose using volumes and growth rates estimated by BABY. Bud growth rates are truncated to the predicted time of cytokinesis (triangles). Shaded areas are twice the standard deviation of the fitted Gaussian process.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Growth rates are highest for small buds.</title><p>We plot growth rates against cell size for nine sets of manually annotated time series of mother-bud pairs randomly selected from microfluidics experiments in four different growth conditions. Growth rates are estimated either as (<bold>a</bold>) the central difference in mask area or (<bold>b</bold>) using a Gaussian process fit of the conical volume estimated from the mask. For each pair, we annotated the mother and bud from when the bud appears to when the mother next buds. The points are growth rate and size estimates for each annotated time point, coloured using a kernel density estimate.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig1-figsupp1-v2.tif"/></fig></fig-group><p>Like others, we use a U-net, a convolutional neural network (CNN) with an architecture that aims to balance accuracy with simplicity (<xref ref-type="bibr" rid="bib65">Ronneberger et al., 2015a</xref>), and our main innovation is in the choice of training targets. We improve performance further by using multiple Z-sections (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), although BABY can predict overlapping outlines from a single 2D image, and we train on single images.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>BABY uses multiple bright-field Z-sections, a multi-target convolutional neural network followed by a custom segmentation algorithm, and two machine-learning classifiers to identify cells and their buds reliably from image to image.</title><p>(<bold>a</bold>) Either single or multiple, we typically use five, bright-field Z-sections are input into a multi-target U-net CNN. (<bold>b</bold>) The curated training data comprises multiple outlines that we categorise by size to reduce overlaps between cells within each category. (<bold>c</bold>) We train the CNN to predict a morphological erosion of the target cell images, which act as seeds for segmenting instances of cells. (<bold>d</bold>) We use edge targets from the CNN to refine each cell’s outline, parameterised as a radial spline. (<bold>e</bold>) We use a bud-neck target from the CNN and metrics characterising the cells’ morphologies to estimate the probability that a pair of cells is a mother and bud via a machine-learning classifier. (<bold>f</bold>) Another classifier uses the same morphological metrics to estimate the probability that an outline in the previous time point matches the current one.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig2-v2.tif"/></fig><p>Inspecting cells, we noted that how much and how often they overlap depends on their size (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>). Most overlaps occur between mid-sized cells and buds with sizes in the range expected for fast growth (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a</xref>). We therefore divided our training data into three categories based on cell size. From each annotated image – a single Z section, we generated up to three new training images: one showing any cells in the annotated image in our small category, one showing any in the medium category, and one for any large cells. We decreased any remaining overlaps in these training images by applying a morphological erosion (<xref ref-type="fig" rid="fig2">Figure 2b</xref>; <xref ref-type="fig" rid="app1fig1">Appendix 1—figures 1</xref> and <xref ref-type="fig" rid="app1fig2">2</xref>), shrinking the cells by removing pixels from their boundaries. Although this transformation does reduce the number of overlapping cells, it may undermine accuracy when we segment the cells. We therefore include the boundary pixels of all the cells in the original annotated image (<xref ref-type="fig" rid="fig2">Figure 2d</xref>) as a training target. To complement this size-based approach, we add another training target: the overlaps between any pair of cells irrespective of their size in the annotated image.</p><p>A final target is the ‘bud neck’ (<xref ref-type="fig" rid="fig2">Figure 2e</xref>), which helps to identify which bud belongs to which cell. In bright-field images, cytokinesis is sometimes visible as a darkening of the bud neck, indicating that these images contain information on cytokinesis that the U-net can potentially learn. We manually created the training data to avoid ambiguity, annotating bright-field images and then generating binary ones showing only bud necks.</p><p>The targets of the U-net therefore comprise the cell interiors and boundaries, separated by size, all overlaps between cells, and the bud necks. Using a four-layer U-net, we achieved high accuracy for predicting the cell interiors early in training and with around 600 training images (1,813 annotated cells in total; <xref ref-type="fig" rid="fig2">Figure 2c</xref> &amp; <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3c</xref>). The performance on bud necks is lower (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3e</xref>), but sufficient because we supplement this information with morphological features when assigning buds. Unlike others (<xref ref-type="bibr" rid="bib52">Lugagne et al., 2018</xref>; <xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>), we do not need to explicitly ignore objects in the image because the network learns to disregard both the traps in ALCATRAS devices and any debris.</p><p>To determine smooth cell boundaries, we apply additional image processing to the U-net’s outputs. First, we reverse the morphological erosion that we applied to the training data (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>), adding pixels to the U-net’s predicted cell interiors. Second, and like the StarDist (<xref ref-type="bibr" rid="bib67">Schmidt et al., 2018</xref>) and DISCO algorithms (<xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>), we parameterise the cell boundaries using a radial representation because we expect yeast cells to appear elliptical – although we can describe any star-convex shape. We fit radial splines with 4–8 rays depending on the cell’s size to a re-weighted version of its boundary pixels predicted by the U-net (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>). On test images, the resulting cell boundaries improve accuracy compared to using the U-net’s predictions directly (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>Other features further improve performance. We developed a graphical user interface (GUI) to label and annotate overlapping cells (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>). With the GUI, we create a 2D binary image of each cell’s outline by using all Z sections together to annotate the outline from the Z section where the cell is most in focus. We also wrote scripts to optimise BABY’s hyper-parameters during training (Methods).</p><p>We find that BABY outperforms alternatives (<xref ref-type="fig" rid="fig3">Figure 3a</xref>), even when we retrain these alternatives with the BABY training data. For larger cell sizes, BABY performs comparably with two algorithms based on deep learning: Cellpose (<xref ref-type="bibr" rid="bib72">Stringer et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Pachitariu and Stringer, 2022</xref>), a generalist algorithm, and YeaZ (<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>), an algorithm optimised for yeast. For smaller cell sizes, BABY performs better, identifying buds overlapping with mother cells that both Cellpose and YeaZ miss (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). To assess its generality, we turned to time-lapse images of yeast microcolonies, training a BABY model on only 6% of the annotated microcolony training data provided by YeaZ and evaluating its performance on the remaining images. BABY performs competitively (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), and even detects buds that were neither annotated in the ground truth nor detected by Cellpose and YeaZ (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>BABY outperforms other algorithms for segmenting, tracking, and particularly for estimating growth rates.</title><p>(<bold>a</bold>) Comparing the intersection-over-union (IoU) score (Methods) between manually curated single cells and those predicted by the BABY, Cellpose, YeaZ, and DISCO algorithms shows that BABY performs best, particularly with five Z sections as input (5Z). We show the performance of the generalist YeaZ model and the Cellpose and YeaZ algorithms retrained on the BABY training data. (<bold>b</bold>) BABY performs particularly well for smaller cell sizes. Inset: counts of curated cells missed by each algorithm. (<bold>c</bold>) BABY finds a higher fraction of complete tracks than either YeaZ or Cellpose, an algorithm only for segmentation and trained on BABY data, combined with btrack (<xref ref-type="bibr" rid="bib77">Ulicna et al., 2021</xref>), a tracking algorithm. We show the results for each Z section separately because BABY is the only algorithm that can use more than one. (<bold>d</bold>) We show BABY’s precision and recall for correctly assigning mother and bud tracks in the tracking evaluation data set as a function of the threshold for defining matching tracks. Performance is best for the central trapped cell. We are unaware of any other algorithms performing mother-bud assignment directly from bright-field images with which to compare. (<bold>e</bold>) By accurately detecting and estimating buds with small volumes, BABY also shows the smallest Root Mean Squared Error (RMSE) when comparing predicted bud growth rates with those derived from a manually curated set of time series of randomly selected mother-bud pairs from four different growth conditions. To highlight the importance of segmentation quality for estimating growth rates, we matched outlines to ground truth ignoring any tracking errors. We used 10<sup>4</sup> bootstraps of 90% of the ground truth data (209 estimates of growth rate from 9 buds) to find the distributions of RMSE.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Optimising edges and using multiple Z sections as inputs improves segmentation.</title><p>(<bold>a–c</bold>) We evaluated the intersection over union (IoU) with curated masks for the predictions of selected stages of the BABY algorithm: masks predicted directly from CNN output with appropriate morphological dilation (no spline), preliminary fits of these masks with an equal-angle radial spline (initial spline), or optimised fits of the radial spline to the edge output of the CNN (optimised spline). (<bold>d–f</bold>) With either one, three, or five bright-field Z sections as input, we found the IoU with curated masks of the full BABY algorithm’s predictions. (<bold>a, d</bold>) The distributions of the IoU with curated outline area. (<bold>b, e</bold>) The distributions of curated outline areas for missed predictions, with an IoU of zero. (<bold>c, f</bold>) Violin plots summarising the IoU distributions. The black horizontal line is the median.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>BABY is competitive with existing algorithms for segmenting microcolonies.</title><p>We show the intersection over union (IoU) with manually annotated masks from the YeaZ bright-field training data <xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref> for predictions from BABY (single Z section), Cellpose, and YeaZ. All were trained on both the BABY training data and an additional three images from the YeaZ training data. We show too predictions from the default YeaZ model trained on all evaluation data, labelled as YeaZ (general), and from a generalist Cellpose model, labelled cellpose (general).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>BABY detects buds that were missing in the YeaZ training images.</title><p>We show examples of buds detected by BABY (bright magenta overlay) in cropped bright-field images of a microcolony in the YeaZ training data [<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>]. Although reported as false positives and off the focal plane, we disagree here with the ground truth and would annotate these objects as buds. YeaZ, with its own standard bright-field model that includes these images in its training data, annotated one of the buds; Cellpose trained on the same data as BABY misses all.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>BABY produces fewer missing tracks than existing other algorithms.</title><p>We compare the distribution of single-cell track IoUs between manually curated and predicted tracks – the number of time points where the masks match relative to the total number of time points in both tracks. We focus on performance for a single Z section (the focal plane and most central one), comparing the single-Z BABY algorithm, YeaZ [<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>], and tracking by the btrack algorithm [<xref ref-type="bibr" rid="bib77">Ulicna et al., 2021</xref>] on outlines segmented by Cellpose [<xref ref-type="bibr" rid="bib59">Pachitariu and Stringer, 2022</xref>]. Unassigned ground-truth tracks have an IoU of zero. They typically arise when two ground-truth tracks appear as a single predicted track. We exclude unassigned predicted tracks.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>All algorithms tested track similarly when assessed with a generalised metric.</title><p>We show mean Multiple Object Tracking Accuracies (MOTA) [<xref ref-type="bibr" rid="bib7">Bernardin et al., 2006</xref>] for each Z section of our test data for BABY, the btrack algorithm [<xref ref-type="bibr" rid="bib77">Ulicna et al., 2021</xref>] on outlines segmented with Cellpose [<xref ref-type="bibr" rid="bib59">Pachitariu and Stringer, 2022</xref>] – the top performer, and YeaZ [<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>]. We include too the five-Z section BABY algorithm (5Z). Error bars are standard error of the mean (<inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig3-figsupp5-v2.tif"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 6.</label><caption><title>A peak in the bud’s growth rate predicts cytokinesis.</title><p>(<bold>a</bold>) Using MYO1-GFP as a marker, we split individual cell cycles of mother cells into G1 and S/G2/M phases. We show bright-field and fluorescence images for a representative cell during one cell cycle. Myo1’s fluorescence at the bud neck abruptly disappears at cytokinesis. The cell’s growth rate (purple) and that of its bud (blue) are shown with a measure of Myo1’s localisation (orange). We estimate the point of cytokinesis from the drop in Myo1 fluorescence (orange dashed line). (<bold>b</bold>) Horizontal lines with shading indicating growth rates show the time series for 388 buds or daughters of 318 cells growing in 2% palatinose. We align cells by the drop in Myo1’s fluorescence and plot the corresponding median growth rates of mother and bud below, with the interquartile range shaded. Red points in the time series mark the time of cytokinesis predicted from the bud’s growth rate, and we show their distribution above. (<bold>c</bold>) The time series for 850 buds or daughters of 520 cells growing in 2% glucose after a switch from palatinose (Pal. → Gluc.). (<bold>d</bold>) The fraction of cytokinesis events whose timing was correctly identified by our method of predicting cytokinesis directly from growth rate. We find the ground-truth values using Myo1-GFP (<inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>550</mml:mn></mml:mrow></mml:math></inline-formula> for 2% palatinose; <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1093</mml:mn></mml:mrow></mml:math></inline-formula> for 2% glucose after switching from palatinose). (<bold>e</bold>) Accuracy of our method for ground-truth data estimated using a tagged nuclear marker (Nhp6A-mCherry), which reports the start of anaphase (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>984</mml:mn></mml:mrow></mml:math></inline-formula> for 2% glucose; <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>773</mml:mn></mml:mrow></mml:math></inline-formula> for 2% raffinose; <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>240</mml:mn></mml:mrow></mml:math></inline-formula> for 2% pyruvate; <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>363</mml:mn></mml:mrow></mml:math></inline-formula> for 2% palatinose; and <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>813</mml:mn></mml:mrow></mml:math></inline-formula> for 2% glucose after switching from palatinose). We assume a fixed 20-min delay from the onset of anaphase to cytokinesis [<xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>].</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig3-figsupp6-v2.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Using machine learning to track lineages robustly</title><p>To determine growth rates, we should estimate both the mother’s and the bud’s volumes because most growth occurs in the bud (<xref ref-type="bibr" rid="bib37">Hartwell and Unger, 1977</xref>; <xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>). We should therefore track cells from one time point to the next and correctly identify, track, and assign buds to their mothers (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>).</p><p>This last task of assigning a bud to its mother is challenging (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). Buds frequently first appear surrounded by cells, displacing their neighbours as they grow (<xref ref-type="fig" rid="fig1">Figure 1b</xref>), obfuscating which is the mother. Both mother and bud can react to the flow of medium: buds often pivot around their mother, with other cells sometimes moving too (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). If tracked incorrectly, a pivoting bud may be misidentified as a new one.</p><p>By combining the U-net’s predicted bud-necks with information on the shape of the cells, we accurately assign buds. Our approach is first to identify cells in an image that are likely buds and then to assign their mothers. We use a standard classification algorithm to estimate the probability that each pair of cells in an image are a mother and bud (<xref ref-type="fig" rid="app2fig4">Appendix 2—figure 4</xref>). This classifier uses as inputs both the predicted bud-necks and the cells’ morphological characteristics, which we extract from the segmented image – one with every cell identified. For each bud, we assign its mother using information from both the current image and the past: the mother is the cell with the highest accumulated probability of pairing with the bud over all previous images showing both cells (Appendix 2).</p><p>We use another classifier-based approach for tracking. The classifier estimates the probability that each pair of cells in two segmented images at different time points, with one cell in the first image and the other in the second, are the same cell (<xref ref-type="fig" rid="fig2">Figure 2f</xref>). To be able to track cells that pivot (<xref ref-type="fig" rid="fig1">Figure 1d</xref>), we train two classifiers: the first using only the cells’ morphological characteristics and the second using these characteristics augmented with the distance between the cells, a more typical approach (<xref ref-type="bibr" rid="bib25">Falconnet et al., 2011</xref>; <xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>; <xref ref-type="bibr" rid="bib28">Garmendia-Torres et al., 2018</xref>; <xref ref-type="bibr" rid="bib81">Wood and Doncic, 2019</xref>; <xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>) but one that often misses pivoted cells. If the results of the first classifier are ambiguous, we defer to the second (Appendix 2). We aggregate tracking predictions over the previous three time points to be robust to transient errors in image processing and in imaging, like a loss of focus. Our algorithm also identifies unmatched cells, which we treat either as new buds or cells moved by the flow of medium: cells may disappear from one time point to the next or be swept downstream and appear by a trap.</p><p>BABY finds more complete or near-complete tracks than other algorithms (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). Cellpose does not perform tracking, and we therefore used the btrack algorithm (<xref ref-type="bibr" rid="bib77">Ulicna et al., 2021</xref>) to track outlines segmented by a Cellpose model trained on the BABY training data. We assessed each algorithm against manually curated data by calculating the intersection-over-union score (IoU) between cells in a ground-truth track with those in a predicted track. We report both the fraction of ground-truth tracks that a predicted track matches, to within some tolerance for missing time points (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), and the track IoU – the number of time points where the cells match relative to the total duration of both tracks (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). If multiple predicted tracks match a ground-truth track, we use the match with the highest track IoU, and any predicted tracks left unassigned have a track IoU of zero. BABY excels because it detects buds early, which both increases the track IoU and prevents new buds being tracked to an incorrect cell.</p><p>We also compared tracking performance using a more general metric, the Multiple Object Tracking Accuracy (MOTA) (<xref ref-type="bibr" rid="bib7">Bernardin et al., 2006</xref>; <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>). With this metric, all methods performed similarly, though Cellpose with btrack appeared more robust to the given Z section. The MOTA score is ideal when there are numerous objects to track and frequent mismatches. Accurately measuring the duration of tracks is necessary to report division times, and so our metrics penalise track splitting, where a ground-truth track is erroneously split into two predicted tracks. The penalty for a single tracking error can therefore differ depending on when that error happens. In contrast, MOTA explicitly avoids penalising splitting errors.</p><p>We are unaware of other algorithms that assign buds to mothers using only bright-field images and so report only BABY’s precision and recall for correctly pairing mother and bud tracks on the manually curated data set (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). Microfluidic devices with traps typically capture one central cell per trap, so we present both the performance for all cells and for only these central cells. BABY requires a mother and bud to be paired over at least three time points (15 min or an eighth of a cell-cycle in 2% glucose), and so when considering all cells, BABY fails to recall multiple mother-bud pairs because daughters of the central cell are often washed away soon after producing a bud.</p></sec><sec id="s2-3"><title>Estimating growth rates</title><p>From the time series of segmented cells, we estimate instantaneous single-cell growth rates as time derivatives of volumes (Appendix 3). We independently estimate the growth rates of mothers and buds, each from their own time series of volumes. A cell’s growth rate, the rate of change of the total volume of a mother and bud, is their sum. To find a cell’s volume from its segmented outline, we use a conical method (<xref ref-type="bibr" rid="bib32">Gordon et al., 2007</xref>; <xref ref-type="fig" rid="fig1">Figure 1e</xref>) and make only weak assumptions to find growth rates from these volumes. Researchers have modelled single-cell growth rates in yeast as bilinear (<xref ref-type="bibr" rid="bib15">Cookson et al., 2010</xref>; <xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>; <xref ref-type="bibr" rid="bib28">Garmendia-Torres et al., 2018</xref>) and exponential (<xref ref-type="bibr" rid="bib20">Di Talia et al., 2007</xref>; <xref ref-type="bibr" rid="bib30">Godin et al., 2010</xref>; <xref ref-type="bibr" rid="bib71">Soifer et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Chandler-Brown et al., 2017</xref>), but that choice has implications for size control (<xref ref-type="bibr" rid="bib75">Turner et al., 2012</xref>). Instead, we use a Gaussian process to both smooth the time series of volumes and to estimate their time derivatives (<xref ref-type="bibr" rid="bib73">Swain et al., 2016</xref>), and so make assumptions only on the class of functions that describe growth rather than choosing a particular functional form. Like others (<xref ref-type="bibr" rid="bib15">Cookson et al., 2010</xref>; <xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>), we observe periodic changes in growth rate across the cell cycle (<xref ref-type="fig" rid="fig1">Figure 1e</xref>).</p><p>BABY estimates growth rates more reliably than other algorithms (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). We manually curated time series of randomly selected mother-bud pairs from four different growth conditions, annotating both mother and bud from the bud’s first appearance to the appearance of the next one (436 outlines total). BABY best reproduces the growth rates derived from this ground truth.</p></sec><sec id="s2-4"><title>BABY provides new insights and experimental designs</title><sec id="s2-4-1"><title>Nutrient modulation of birth size occurs after the peak in growth rate</title><p>Using a fluorescent marker for cytokinesis (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6a</xref>), we observed that cellular growth has two phases (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6b–c</xref>). During G1, the mother’s growth rate peaks; during S/G2/M, which we identify by the cells having buds, the bud dominates growth with its growth rate peaking approximately midway to cytokinesis (<xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>).</p><p>This tight coordination between bud growth rate and cytokinesis suggested that the peak in bud growth rate preceding cytokinesis may mark a regulatory transition. Comparing growth rates over S/G2/M for buds in different carbon sources, we found that the maximal growth rate occurs at similar times relative to cytokinesis despite substantial differences in the duration of the S/G2/M phases (<xref ref-type="fig" rid="fig4">Figure 4a</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Buds reach similar sizes as their growth rate peaks regardless of carbon source.</title><p>(<bold>a</bold>) Although buds grow faster in richer media, the time of the maximal growth rate relative to the start of anaphase is approximately constant, unlike the duration of the mothers’ S/G2/M phases. We grew cells in 2% glucose (data for 1014 cell cycles), 2% raffinose (803 cycles), 2% pyruvate (270 cycles), 2% palatinose (393 cycles), or in 2% glucose after a switch from palatinose (pal. → gluc.; 842 cycles). We show median bud growth rates with the interquartile range shaded and estimate the timing of anaphase from a fluorescently tagged nuclear marker (Nhp6A-mCherry; Appendix 6) and the start of S phase by when a bud first appears. (<bold>b</bold>) Binning median bud growth rates according to volume, with the interquartile range shaded, shows that the bud volumes when their growth rate is maximal are more similar in all carbon sources than those at birth, taken as 20 min after start of anaphase (<xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>) .</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Growth rates estimated with BABY show expected correlations with volume.</title><p>(<bold>a</bold>) The mean growth rate of a bud from first detection to birth correlates with its volume at birth for buds growing in either 2% glucose, 2% raffinose, 2% pyruvate, 2% palatinose, or 2% glucose after a switch from palatinose (Pal. → gluc). We define birth to be when cytokinesis completes as estimated from an Nhp6A-mCherry marker – Appendix 6. (<bold>b</bold>) The mean growth rate of a daughter cell during its first G1 phase, from birth to START, correlates with its volume at START. We define START when the daughter’s first bud appears. In our microfluidic devices, the medium washes most daughters away before they can bud. (<bold>c</bold>) The mean growth rate of a mother during G1, from birth of a daughter to START, shows less correlation with its volume at START. We define START by when the mother’s next bud appears.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig4-figsupp1-v2.tif"/></fig></fig-group><p>Daughters born in rich media are larger than those born in poor media, and some of this regulation occurs during S/G2/M (<xref ref-type="bibr" rid="bib41">Johnston et al., 1977</xref>; <xref ref-type="bibr" rid="bib42">Jorgensen et al., 2004</xref>; <xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>). Understanding the mechanism, however, is confounded by the longer S/G2/M phases in poorer media (<xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>; <xref ref-type="fig" rid="fig4">Figure 4a</xref>), which counterintuitively allow daughters that should be smaller longer to grow.</p><p>Given that the time between maximal growth and anaphase appears approximately constant in different carbon sources (<xref ref-type="fig" rid="fig4">Figure 4a</xref>), we hypothesised that the growth rate falls because the bud has reached a critical size. Compared to how their sizes vary immediately after cytokinesis, buds have similar sizes when their growth rates peak — in all carbon sources (<xref ref-type="fig" rid="fig4">Figure 4b</xref>): the longer S/G2/M phase in poorer media compensates the slower growth rates. During the subsequent constant time to cytokinesis, the faster growth in richer carbon sources would then generate larger daughters, and we observe that the bud’s average growth rate correlates positively with the volume of the daughter it becomes (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Cells likely therefore implement some size regulation in S/G2/M as they approach cytokinesis.</p><p>Although such regulation in M phase is known (<xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>; <xref ref-type="bibr" rid="bib28">Garmendia-Torres et al., 2018</xref>), our data suggest a sequential mechanism to match size to growth rate, with a nutrient-independent sizer followed by a nutrient-dependent timer. To detect the peak in bud growth generated by the sizer, cells may use Gin4-related kinases (<xref ref-type="bibr" rid="bib40">Jasani et al., 2020</xref>).</p></sec><sec id="s2-4-2"><title>Changes in ribosome biogenesis precede changes in growth</title><p>An important advantage of the BABY algorithm is that we can estimate single-cell growth rates without fluorescence markers, freeing fluorescence channels for other reporters. Here we focus on Sfp1, a transcription factor that helps coordinate ribosome synthesis with the availability of nutrients (<xref ref-type="bibr" rid="bib42">Jorgensen et al., 2004</xref>).</p><p>Sfp1 promotes the synthesis of ribosomes by activating the ribosomal protein (RP) and ribosome biogenesis (RiBi) genes (<xref ref-type="bibr" rid="bib42">Jorgensen et al., 2004</xref>; <xref ref-type="bibr" rid="bib2">Albert et al., 2019</xref>). Upon being phosphorylated directly by TORC1 and likely protein kinase A (<xref ref-type="bibr" rid="bib42">Jorgensen et al., 2004</xref>; <xref ref-type="bibr" rid="bib45">Lempiäinen et al., 2009</xref>; <xref ref-type="bibr" rid="bib70">Singh and Tyers, 2009</xref>) – two conserved nutrient-sensing kinases, Sfp1 enters the nucleus (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). In steady-state conditions, levels of ribosomes positively correlate with growth rate (<xref ref-type="bibr" rid="bib55">Metzl-Raz et al., 2017</xref>), and we therefore assessed whether Sfp1’s nuclear localisation predicts changes in instantaneous single-cell growth rates.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>The translocation dynamics of the ribosomal regulator Sfp1 anticipate changes in single-cell growth rates.</title><p>(<bold>a</bold>) The transcription factor Sfp1 is phosphorylated by TORC1 and likely PKA when extracellular nutrients increase and moves into the nucleus, where it promotes synthesis of ribosomes and so higher growth rates. (<bold>b</bold>) Growth rate follows changes in Sfp1’s nuclear localisation if nutrients decrease but lags if nutrients increase. We show the median time series of Sfp1-GFP localised to the nuclei of mother cells (green) and the summed bud and mother growth rates (black) for cells switched from 2% palatinose to 2% glucose and back. Shading shows interquartile ranges. We filtered data to those cell cycles that could be unambiguously split into G1 and S/G2/M phases by a nuclear marker, and we display the number in each phase in the lower plot. Above the switches of media, we show box plots for the distributions of single-cell half-times: the time of crossing midway between each cell’s minimal and maximal values. (<bold>c</bold>) The mean single-cell autocorrelation of nuclear Sfp1 and the summed mother and bud growth rates are periodic because both vary during the cell cycle. We calculate the autocorrelations for constant medium using data four hours before each switch (Appendix 7). Shading shows the 95% confidence interval. (<bold>d</bold>) The mean cross-correlation between nuclear Sfp1 and the summed mother and bud growth rate shows that fluctuations in Sfp1 precede those in growth, with the correlation peaking at negative lags.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Irrespective of cell cycle phase, growth rates transiently drop for a shift to a poorer carbon source.</title><p>We show time series of median growth rate (upper panel) and median Sfp1-GFPlocalisation (lower panel) across different cell-cycle phases for a switch from 2% palatinose to 2% glucose and back. We used a Nhp6A-mCherry reporter to identify cytokinesis – Appendix 6 – and so partitioned the time series into cell-cycle phases: G1 phase for the daughter is from cytokinesis up to BABY detecting its first bud; S/G2/M phase for the mother is from budding to cytokinesis; and its G1 phase is from cytokinesis to budding. The shading shows the interquartile range.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig5-figsupp1-v2.tif"/></fig></fig-group><p>Shifting cells from glucose to the poorer carbon source palatinose and back again, we observed that Sfp1 responds quickly to both the up- and downshifts and that growth rate responds as quickly to downshifts, but more slowly to upshifts (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). As a target of TORC1 and PKA, Sfp1 acts as a fast read-out of the cell’s sensing of a change in nutrients (<xref ref-type="bibr" rid="bib34">Granados et al., 2018</xref>). In contrast, synthesising more ribosomes is likely to be slower and explains the lag in growth rate after the upshift. The fast drop in growth rate in downshifts is more consistent, however, with cells deactivating ribosomes, rather than regulating their numbers. Measuring the half-times of these responses (<xref ref-type="fig" rid="fig5">Figure 5b</xref> boxplots), there is a mean delay of 30 ± 2 minutes (95% confidence; <inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>245</mml:mn></mml:mrow></mml:math></inline-formula>) from Sfp1 localising in the nucleus to the rise in growth rate in the upshift. This delay is only 8 ± 1 minutes (95% confidence; <inline-formula><mml:math id="inf10"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>336</mml:mn></mml:mrow></mml:math></inline-formula>) in the downshift, and downshift half-times are less variable than those for upshifts, consistent with fast post-translational regulation. Although changes in Sfp1 consistently precede those in growth rate, the higher variability in half-times for the growth rate is not explained by Sfp1’s half-time (Pearson correlation 0.03, <inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math></inline-formula>).</p><p>By enabling both single-cell fluorescence and growth rates to be measured, BABY permits correlation analyses (<xref ref-type="bibr" rid="bib43">Kiviet et al., 2014</xref>; Appendix 7). Both Sfp1’s activity and the growth rate vary during the cell cycle. The autocorrelation functions for nuclear Sfp1 and for the growth rate are periodic with periods consistent with cell-division times (<xref ref-type="fig" rid="fig5">Figure 5c</xref>): around 90 min in glucose and 140 min in palatinose for Sfp1; and 95 min and 150 min for the growth rate. If Sfp1 acts upstream of growth rate, then its fluctuations in nuclear localisation should precede fluctuations in growth rate. Cross-correlating nuclear Sfp1 with growth rate shows that fluctuations in Sfp1 do lead those in growth rate, by an average of 25 min in glucose and by 50 min in palatinose (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). Nevertheless, the weak strength of this correlation suggests substantial control besides Sfp1.</p><p>During the downshift, we note that the growth rate transiently drops to zero (<xref ref-type="fig" rid="fig5">Figure 5b</xref>), irrespective of a cell’s stage in the cell cycle (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>), and there is a coincident rise in the fraction of cells in G1 (<xref ref-type="fig" rid="fig5">Figure 5b</xref> bottom), suggesting that cells arrest in that phase.</p></sec><sec id="s2-4-3"><title>Using growth rate for real-time control</title><p>With BABY, we can use growth rate as a control variable in real time because BABY’s speed and accuracy enables cells to be identified in images and their growth rates estimated during an experiment (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). As an example, we switched the medium to a poorer carbon source and used BABY to determine how long to keep cells in this medium if we want 50% to have resumed dividing before switching back to the richer medium (Appendix 8). After 5 hr in glucose, we switched the carbon source to ethanol, or galactose – <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>. There is a lag in growth as cells adapt. Using BABY, we automatically determined the fraction of cells that have escaped the lag at each time point — those cells that have at least one bud or daughter whose growth rate exceeds a threshold (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). The software running the microscopes reads this statistic and triggers the switch back to glucose when 50% of the cells have escaped (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). We note that all cells resume dividing in glucose and initially grow synchronously because of the rapid change of media. This synchrony is most obvious in those cells that did not divide in ethanol (<xref ref-type="fig" rid="fig6">Figure 6c</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>BABY allows growth rate to be used as a variable for real-time control.</title><p>(<bold>a</bold>) By running BABY in real time during a microscopy experiment, we are able to use the cells’ growth rate to control changes in media. Following 5 hr in 0.5% glucose, we switch the extracellular medium to one containing 2% ethanol, a poorer carbon source, and cells arrest growth. The images collected are analysed by BABY to determine growth rates. When the majority of cells have resumed dividing, detected by the growth rate of at least one of their buds or daughters exceeding 15μm<sup>3</sup>/hr, the microscopy software triggers a change in pumping and returns glucose to the microfluidic device. (<bold>b</bold>) The fraction of cells that have escaped the lag and resumed dividing increases with the amount of time in ethanol. All cells divide shortly after glucose returns. (<bold>c</bold>) The growth rates of the buds for each mother cell drop in ethanol and resume in glucose. Each row shows data from a single mother cell with the bud growth rate indicated by the heat map. We sort rows by the time each cell resumes dividing in ethanol, with the bottom rows showing the 50% that re-initiated growth.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Changing experimental protocols in real time using growth rates.</title><p>(<bold>a</bold>) A heat map showing the bud growth rates calculated in real time for an experiment where the medium changes from glucose to galactose, rather than the ethanol of <xref ref-type="fig" rid="fig6">Figure 6</xref>. We sort rows representing mother cells by the time each cell resumes dividing, with cells resuming later at the top. We indicate the corresponding time on the plot below. (<bold>b</bold>) Cells are slow to resume division, or “escape”, following the switch to 2% ethanol (green) compared to 0.5% galactose. (<bold>c</bold>) The growth rate but not Sfp1’s localisation is predictive of whether cells escape. We plot the mutual information between cells labelled as either escapers or non-escapers and the time series of either bud growth rate or Sfp1’s localisation. We estimated the mutual information using the decoding method <xref ref-type="bibr" rid="bib34">Granados et al., 2018</xref> for a sliding time-window of 100 minutes and show the mean and, with shading, the 95% confidence interval of 100 bootstraps. Decoding was by a gradient-boosting classifier trained on the time-window data concatenated with both Fourier-transformed and rank-ordered versions of the same data. (<bold>d</bold>) Cells accumulate in G1 while in the poorer carbon source, and their cell cycles appear to synchronise– notice the periodic waves of the proportions of G1 cells once glucose is re-introduced. The dotted lines mark media transitions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-fig6-figsupp1-v2.tif"/></fig></fig-group><p>This proof-of-principle shows that BABY is applicable for more complex feedback control, where a desired response is achieved by comparing behaviour with a computational model to predict the necessary inputs, such as changes in media (<xref ref-type="bibr" rid="bib36">Harrigan et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Milias-Argeitis et al., 2011</xref>; <xref ref-type="bibr" rid="bib74">Toettcher et al., 2011</xref>; <xref ref-type="bibr" rid="bib76">Uhlendorf et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Lugagne et al., 2017</xref>; <xref ref-type="bibr" rid="bib54">Menolascina et al., 2014</xref>). Unlike previous approaches though, which typically measure fluorescence, BABY not only allows single-cell fluorescence but also growth rates to be control variables, and growth rate correlates strongly with fitness (<xref ref-type="bibr" rid="bib58">Orr, 2009</xref>).</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here, we present BABY, an algorithm to extract growth rates from label-free, time-lapse images through reliably estimating time series of cellular volumes. We introduce both a segmentation algorithm that identifies individual cells in images even if they overlap and general machine-learning methods to track and assign lineages robustly. The novel training targets for CNNs that we propose, particularly splitting one training image into multiple with each comprising cells of a particular size, should be beneficial not only for other yeasts but for other cell types.</p><p>Although BABY detects buds shortly after they form, we stop following a bud as soon as the mother buds again and instead follow the new one. Ideally we would like to identify from bright-field images when a bud becomes an independent daughter cell. We would then know when a mother cell exits M phase and be able to identify their G1 and the (budded) S/G2/M phases. We have partly achieved this task with an algorithm that predicts the end of the peak in the bud’s growth rate (Appendix 6), which often occurs at cytokinesis (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6a</xref>; <xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1a</xref>). It assigns to within two time points over 60% of the cytokinesis events identified independently using a fluorescent reporter (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6d–e</xref>), but higher accuracy likely needs more advanced techniques.</p><p>Indeed, we believe that integrating BABY with other algorithms will improve its performance even further. How Cellpose defines training targets for its CNN appears particularly powerful (<xref ref-type="bibr" rid="bib72">Stringer et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Pachitariu and Stringer, 2022</xref>), and this formulation could be combined with BABY’s size-dependent categorisation. Similarly, for assigning lineages, there are now methods that use image classification to identify division and budding times for cells in traps (<xref ref-type="bibr" rid="bib3">Aspert et al., 2022</xref>), and for tracking, our machine learning approach would benefit from Fourier transforming the images we use, which provides a rich source of features (<xref ref-type="bibr" rid="bib19">Cuny et al., 2022</xref>).</p><p>Cell biologists often wish to understand how cells respond to change (<xref ref-type="bibr" rid="bib57">Murugan et al., 2021</xref>), and watching individual cells in real time as their environment alters gives unique insights (<xref ref-type="bibr" rid="bib49">Locke and Elowitz, 2009</xref>). Together time-lapse microscopy, microfluidic technology, and fluorescent proteins allow us to control extracellular environments, impose dynamic changes, and phenotype cellular responses over time. With BABY, we add the ability – using only bright-field images – to measure what is often our best estimate of fitness, single-cell growth rates. The strategies used by cells in their decision making are of high interest (<xref ref-type="bibr" rid="bib63">Perkins and Swain, 2009</xref>; <xref ref-type="bibr" rid="bib5">Balázsi et al., 2011</xref>). With BABY, or comparable software, we are able not only to use fitness to rank each cell’s decision-making strategy, but also to investigate the strategies used to regulate fitness itself, through how cells control their growth, size, and divisions.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Strains and media</title><p>Strains included in the curated training images were all derivatives of BY4741 (<xref ref-type="bibr" rid="bib9">Brachmann et al., 1998</xref>). We derived both BY4741 Myo1-GFP Whi5-mCherry and BY4741 Sfp1-GFP Nhp6A-mCherry from the respective parent in the <italic>Saccharomyces cerevisiae</italic> GFP collection <xref ref-type="bibr" rid="bib39">Huh et al., 2003</xref> by PCR-based genomic integration of mCherry-Kan <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> from pBS34 (EUROSCARF) to tag either Whi5 or the chromatin-associated Nhp6A protein. We validated all tags by sequencing. The media used for propagation and growth was standard synthetic complete (SC) medium supplemented either with 2% glucose, 2% palatinose, or 0.5% glucose depending on the starting condition in the microfluidic devices. Cells were grown at 30 °C.</p></sec><sec id="s4-2"><title>Microscopy and microfluidics</title><sec id="s4-2-1"><title>Device preparation and imaging</title><p>We inoculated overnight cultures with low cell numbers so that they would reach mid-log phase in 13–16 hr. We diluted cells in fresh medium to OD<sub>600</sub> of 0.1 and incubated for an additional 3–4 hr before loading them into microfluidic devices at ODs of 0.3–0.4. To expose multiple strains to the same environmental conditions and to optimise data acquisition, we use multi-chamber versions of ALCATRAS (<xref ref-type="bibr" rid="bib17">Crane et al., 2014</xref>; <xref ref-type="bibr" rid="bib33">Granados et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Crane et al., 2019</xref>), which allow for either three or five different strains to be observed in separate chambers while being exposed to the same extracellular medium. The ALCATRAS chambers were pre-filled with growth medium with added 0.05% bovine serum albumin (BSA) to facilitate cell loading and reduce clumping. We passed all microfluidics media through 0.2 μm filters before use.</p><p>We captured images on a Nikon Ti-E microscope using a 60×, 1.4 NA oil immersion objective (Nikon), OptoLED light source (Cairn Research) and sCMOS (Prime95B), or EMCCD (Evolve) cameras (both Photometrics) controlled through custom MATLAB software using Micro-manager (<xref ref-type="bibr" rid="bib23">Edelstein et al., 2014</xref>). We acquired bright-field and fluorescence images at five Z sections spaced 0.6 μm apart. A custom-made incubation chamber (Okolabs) maintained the microscope and syringe pumps containing media at 30 °C.</p></sec><sec id="s4-2-2"><title>Changing the extracellular environment</title><p>For experiments in which the cells experience a change of media, two syringes (BD Emerald, 10 ml) mounted in syringe pumps (Aladdin NE-1002X, National Instruments) connected via PTFE tubing (Smiths Medical) to a sterile metal T-junction delivered media through the T-junction and via PTFE tubing to the microfluidic device. Initially the syringe with the first medium infused at 4 μL/min while the second pump was off. To remove back pressure and achieve a rapid switch, we infused medium at 150 μL/min for 40 s from the second pump while the first withdrew at the same rate. The second pump was then set to infuse at 4 μL/min and the first switched off. We reversed this sequence to achieve a second switch in some experiments. Custom Matlab software, via RS232 serial ports, controlled the flow rates and directions of the pumps.</p></sec></sec><sec id="s4-3"><title>Birth Annotator for Budding Yeast (BABY) algorithm</title><p>The BABY algorithm takes either a stack of bright-field images or a single Z-section as input and coordinates multiple machine-learning models to output individual cell masks annotated for both tracking and lineage relationships.</p><p>Central to segmenting and annotating lineages is a multi-target CNN (Appendix 1). Each target is semantic – pixels have binary labels. We define these targets for particular categories of cell size and mask pre-processing steps, chosen to ease both segmenting overlapping instances and assigning lineages. We first identify cell instances as semantic masks and then refine their edges using a radial spline representation.</p><p>To track cells and lineages, we use machine-learning classifiers both to link cell outlines from one time point to the next and to identify mother-bud relationships. The classifier converts a feature vector, representing quantitatively how two cell masks are related, into probabilities for two possible classes. For cell tracking, this probability is the probability that the two cells at different time points are the same cell. For assigning lineages, the probability is the probability that the two cells have a mother-bud relationship. We aggregate over time a target of the CNN dedicated to assigning lineages to determine this probability (Appendix 2).</p><p>We used Python to implement the algorithm and Tensorflow (<xref ref-type="bibr" rid="bib1">Abadi, 2015</xref>) for the deep-learning models, Scikit-learn (<xref ref-type="bibr" rid="bib61">Pedregosa, 2011</xref>) for machine learning, and Scikit-image (<xref ref-type="bibr" rid="bib78">van der Walt et al., 2014</xref>) for image processing. The code can be run either directly from Python or as an HTTP server, which enables access from other languages, such as Matlab. Scripts automate the training process, including optimising the hyperparameters, for the size categories and CNN architecture, and post-processing parameters (Appendices 1 and 2).</p></sec><sec id="s4-4"><title>Training data</title><p>Training data for the segmentation and bud assignment models comprises bright-field time-lapse images of yeast cells and manually curated annotations: a bit-mask outline for each cell (a binary image with the pixels constituting the cell marked with ones) and its associated tracking label and lineage assignment, if any. For the models optimised for microfluidic devices with traps, including both the single and five Z-section models, we took training images with five Z sections using a 60× lens. These images were from six independent experiments and annotated by three different people and include a total of 3233 annotated cell outlines distributed across 1028 time points, 130 traps, and 28 fields-of-view. We include examples taken using cameras with different pixel sizes (0.182 μm and 0.263 μm). Cells in the training data were all derivatives of BY4741 growing in SC with glucose as carbon source. Most of the training images are of cells trapped in ALCATRAS devices (<xref ref-type="bibr" rid="bib17">Crane et al., 2014</xref>), but some were for different trap designs. When training for a single Z-section, each of the five Z sections is independently presented to the CNN.</p><p>We split the training data into training, validation, and test sets (<xref ref-type="bibr" rid="bib31">Goodfellow et al., 2016</xref>). We use the training set (588 trap images) to train the CNN and the validation set (248 trap images) to optimise hyperparameters and post-processing parameters. We use the test set (192 trap images) only to assess performance and generalisability after training. To increase the independence between each data set, our code allocates images using trap identities rather than time points or Z sections.</p><p>For the model optimised for microcolonies (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), we supplemented the ALCATRAS trap training set with 18 images from three fields-of-view (6% of the full data set) taken from the YeaZ bright-field training data (<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>). To allow for overlaps in this data set, we re-annotated each field-of-view using our GUI (Appendix 4).</p><p>For training the tracking model, we used both the annotations from the segmentation training data, which are short time series of around five time points, and an additional data set of 300 time points of outlines, segmented using BABY and crudely tracked and then manually curated.</p></sec><sec id="s4-5"><title>Evaluating performance</title><sec id="s4-5-1"><title>Segmentation</title><p>We evaluated BABY’s segmentation on the training data’s test set and compared with recent algorithms for processing yeast images (<xref ref-type="bibr" rid="bib60">Padovani et al., 2022</xref>): Cellpose version 2.1.1 (<xref ref-type="bibr" rid="bib72">Stringer et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Pachitariu and Stringer, 2022</xref>), YeaZ (<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>) from 11 October 2022, and our previous segmentation algorithm DISCO (<xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>). For Cellpose and YeaZ, we also trained new models on the images and annotations from both our training and validation sets, following their suggested methods (<xref ref-type="bibr" rid="bib59">Pachitariu and Stringer, 2022</xref>; <xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>). Because neither handles overlapping regions, we applied a random order to the cell annotations such that pixels in regions of overlap were assigned the last observed label. We augmented the input data for each model by resampling the images five times, thus avoiding bias by forcing the models to adapt to uncertainty in the regions of overlap.</p><p>We assessed performance by calculating the intersection over union (IoU) of all predicted masks with the manually curated ground-truth masks from our test set. We paired predicted masks with the ground truth masks beginning with the highest IoU score; we assigned unmatched predictions an IoU of zero. To calculate the average precision for each annotated image, we used the area under the precision-recall curve for varying thresholds on the IoU score (<xref ref-type="bibr" rid="bib53">Manning et al., 2008</xref>). Not all of the algorithms we tested give a confidence score, and so we generated precision-recall curves assuming ideal ordering of the predicted masks, by decreasing IoU. For the BABY models, ordering by mask probability produces similar results. We report the mean average precision over all images in the test set. To evaluate segmentation on microcolony images, we performed a similar analysis using the ground-truth annotations of the YeaZ bright-field training data (<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>), but excluding the 18 images annotated and used to train BABY. We also re-trained the Cellpose and YeaZ models using our training data set supplemented with the microcolony images and evaluated the pre-trained bright-field YeaZ model, which includes this evaluation data in its training set, and the general-purpose pre-trained cyto2 Cellpose model, which segments cells from multiple different organisms.</p></sec><sec id="s4-5-2"><title>Tracking</title><p>We evaluated tracking on independent, manually curated data, comprising time series with 180–300 time points for 10 randomly selected traps from two experiments and four different growth conditions, making a total of 128 tracks. We initially generated the annotations using an early version of our segmentation and tracking models, but we manually corrected all tracking and lineage assignment errors and any obviously misshapen, misplaced or missing outlines, including removing false positives and adding outlines to the first visible appearance of buds. Unedited outlines, however, remain and will inevitably impart a bias. By requiring a mask IoU score of 0.5 or higher to match masks for the tracking, we expect to negate this bias. We compared BABY with YeaZ (<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>) and btrack (<xref ref-type="bibr" rid="bib77">Ulicna et al., 2021</xref>) because Cellpose cannot track. For YeaZ, we used the model trained on our data; for btrack, we used the Cell-ACDC platform (<xref ref-type="bibr" rid="bib60">Padovani et al., 2022</xref>) to combine segmentation by Cellpose with tracking by btrack.</p><p>The output of each model comprises masks with associated labels. We matched predicted and ground-truth masks at each time point to obtain maps from predicted to ground-truth labels, in descending order of mask IoUs but providing the mask IoU was greater than 0.5. We then calculated a track IoU between all predicted and ground-truth tracks: the number of time points where a predicted label mapped to a ground-truth label divided by the number of time points for which either track had a mask. This approach gave a map between predicted and ground-truth tracks in descending order of track IoUs. Using the mapping, we reported either the fraction of predicted tracks whose duration, the number of masks identified within that track, matched the ground-truth tracks (<xref ref-type="fig" rid="fig3">Figure 3c</xref>) or the distribution of track IoUs for all ground-truth tracks (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). For the Multiple Object Tracking Accuracy (MOTA) metric (<xref ref-type="bibr" rid="bib7">Bernardin et al., 2006</xref>), we used the mask IoU to measure distance and considered correspondences as valid if the mask IoU ≥ 0.5.</p></sec><sec id="s4-5-3"><title>Assigning lineages</title><p>We evaluated BABY’s lineage assignment using the lineage annotations included in the tracking evaluation data. These assignments pair bud and mother track labels. We used the track IoU to match ground-truth and predicted tracks above a given track IoU threshold and then compared lineage assignments based on this map. We counted true positives for each ground-truth bud-to-mother mapping if the ground-truth bud track had a matching predicted track and this predicted track had a predicted mother track matching the ground-truth mother track. False negatives were any ground-truth mother-bud pairs not counted as true positives; false positives were any predicted mother-bud pairs that were not counted as true positives. We repeated this analysis only for buds assigned to the central trapped cell or its matching predicted track.</p></sec><sec id="s4-5-4"><title>Estimating growth rates</title><p>We evaluated how well BABY estimates growth rates on independent, manually curated data comprising annotated time series of mother-bud pairs. We did not include this image data, which has growth in glucose, raffinose, pyruvate, and palatinose, in our training data. To select positions, traps, and time points, we randomly selected mother-bud pairs, rejecting samples only if there was no pair with a complete bud-to-bud cycle. We segmented this data with BABY and Cellpose and YeaZ trained on our data. To avoid penalising YeaZ and Cellpose for tracking errors, we found the matching predicted outlines with highest positive IoU for each ground-truth mask. We then used our method to estimate volumes (Appendix 3) to derive volumes for all masks, both ground-truth and predicted. Associating the masks with the ground-truth track, we fit a Gaussian process to each time series of volumes, omitting any time points with no matching mask. From the Gaussian process, we estimated a growth rate for each time point. Finally, we calculated the Root Mean Square Distance (RMSD) between the predicted and ground-truth estimates.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Investigation, Visualization, Methodology, Writing - original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Supervision, Funding acquisition, Writing - original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-79812-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data is available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7488/ds/3427">https://doi.org/10.7488/ds/3427</ext-link> and code from <ext-link ext-link-type="uri" xlink:href="https://git.ecdf.ed.ac.uk/swain-lab/baby">https://git.ecdf.ed.ac.uk/swain-lab/baby</ext-link> (copy archived at <xref ref-type="bibr" rid="bib64">Pietsch, 2023</xref>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Pietsch</surname><given-names>JMJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>A label-free method to track individuals and lineages of budding cells</data-title><source>Edinburgh DataShare</source><pub-id pub-id-type="doi">10.7488/ds/3427</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We gratefully acknowledge support from the Leverhulme Trust (JMJP &amp; PSS — grant number RPG-2018–04), the BBSRC (IF, IBNC, &amp; PSS — grant number BB/R001359/1), and the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska Curie grant agreement no. 764591 — SynCrop (AFM &amp; DYA).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Abadi</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>TensorFlow: Large-scale machine learning on heterogeneous systems</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1603.04467">https://arxiv.org/abs/1603.04467</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albert</surname><given-names>B</given-names></name><name><surname>Tomassetti</surname><given-names>S</given-names></name><name><surname>Gloor</surname><given-names>Y</given-names></name><name><surname>Dilg</surname><given-names>D</given-names></name><name><surname>Mattarocci</surname><given-names>S</given-names></name><name><surname>Kubik</surname><given-names>S</given-names></name><name><surname>Hafner</surname><given-names>L</given-names></name><name><surname>Shore</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sfp1 regulates transcriptional networks driving cell growth and division through multiple promoter-binding modes</article-title><source>Genes &amp; Development</source><volume>33</volume><fpage>288</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1101/gad.322040.118</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aspert</surname><given-names>T</given-names></name><name><surname>Hentsch</surname><given-names>D</given-names></name><name><surname>Charvin</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Detecdiv, a generalist deep-learning platform for automated cell division tracking and survival analysis</article-title><source>eLife</source><volume>11</volume><elocation-id>e79519</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.79519</pub-id><pub-id pub-id-type="pmid">35976090</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakker</surname><given-names>E</given-names></name><name><surname>Swain</surname><given-names>PS</given-names></name><name><surname>Crane</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Morphologically constrained and data informed cell segmentation of budding yeast</article-title><source>Bioinformatics</source><volume>34</volume><fpage>88</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx550</pub-id><pub-id pub-id-type="pmid">28968663</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balázsi</surname><given-names>G</given-names></name><name><surname>van Oudenaarden</surname><given-names>A</given-names></name><name><surname>Collins</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cellular decision making and biological noise: from microbes to mammals</article-title><source>Cell</source><volume>144</volume><fpage>910</fpage><lpage>925</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2011.01.030</pub-id><pub-id pub-id-type="pmid">21414483</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennett</surname><given-names>MR</given-names></name><name><surname>Hasty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Microfluidic devices for measuring gene network dynamics in single cells</article-title><source>Nature Reviews. Genetics</source><volume>10</volume><fpage>628</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1038/nrg2625</pub-id><pub-id pub-id-type="pmid">19668248</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bernardin</surname><given-names>K</given-names></name><name><surname>Elbs</surname><given-names>A</given-names></name><name><surname>Stiefelhagen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Multiple object tracking performance metrics and evaluation in a smart room environment</article-title><conf-name>Sixth IEEE International Workshop on Visual Surveillance</conf-name></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern Recognition and Machine Learning</source><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brachmann</surname><given-names>CB</given-names></name><name><surname>Davies</surname><given-names>A</given-names></name><name><surname>Cost</surname><given-names>GJ</given-names></name><name><surname>Caputo</surname><given-names>E</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Hieter</surname><given-names>P</given-names></name><name><surname>Boeke</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Designer deletion strains derived from <italic>Saccharomyces cerevisiae</italic> S288C: a useful set of strains and plasmids for PCR-mediated gene disruption and other applications</article-title><source>Yeast</source><volume>14</volume><fpage>115</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1097-0061(19980130)14:2&lt;115::AID-YEA204&gt;3.0.CO;2-2</pub-id><pub-id pub-id-type="pmid">9483801</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broach</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Nutritional control of growth and development in yeast</article-title><source>Genetics</source><volume>192</volume><fpage>73</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1534/genetics.111.135731</pub-id><pub-id pub-id-type="pmid">22964838</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandler-Brown</surname><given-names>D</given-names></name><name><surname>Schmoller</surname><given-names>KM</given-names></name><name><surname>Winetraub</surname><given-names>Y</given-names></name><name><surname>Skotheim</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The adder phenomenon emerges from independent control of pre- and post-start phases of the budding yeast cell cycle</article-title><source>Current Biology</source><volume>27</volume><fpage>2774</fpage><lpage>2783</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.08.015</pub-id><pub-id pub-id-type="pmid">28889980</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T</given-names></name><name><surname>Guestrin</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>XGBoost: A scalable tree boosting system</article-title><conf-name>KDD ’16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</conf-name><fpage>785</fpage><lpage>794</lpage><pub-id pub-id-type="doi">10.1145/2939672.2939785</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>KL</given-names></name><name><surname>Crane</surname><given-names>MM</given-names></name><name><surname>Kaeberlein</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Microfluidic technologies for yeast replicative lifespan studies</article-title><source>Mechanisms of Ageing and Development</source><volume>161</volume><fpage>262</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1016/j.mad.2016.03.009</pub-id><pub-id pub-id-type="pmid">27015709</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coates</surname><given-names>J</given-names></name><name><surname>Park</surname><given-names>BR</given-names></name><name><surname>Le</surname><given-names>D</given-names></name><name><surname>Şimşek</surname><given-names>E</given-names></name><name><surname>Chaudhry</surname><given-names>W</given-names></name><name><surname>Kim</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Antibiotic-induced population fluctuations and stochastic clearance of bacteria</article-title><source>eLife</source><volume>7</volume><elocation-id>e32976</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32976</pub-id><pub-id pub-id-type="pmid">29508699</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cookson</surname><given-names>NA</given-names></name><name><surname>Cookson</surname><given-names>SW</given-names></name><name><surname>Tsimring</surname><given-names>LS</given-names></name><name><surname>Hasty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Cell cycle-dependent variations in protein concentration</article-title><source>Nucleic Acids Research</source><volume>38</volume><fpage>2676</fpage><lpage>2681</lpage><pub-id pub-id-type="doi">10.1093/nar/gkp1069</pub-id><pub-id pub-id-type="pmid">20019065</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costanzo</surname><given-names>M</given-names></name><name><surname>Nishikawa</surname><given-names>JL</given-names></name><name><surname>Tang</surname><given-names>X</given-names></name><name><surname>Millman</surname><given-names>JS</given-names></name><name><surname>Schub</surname><given-names>O</given-names></name><name><surname>Breitkreuz</surname><given-names>K</given-names></name><name><surname>Dewar</surname><given-names>D</given-names></name><name><surname>Rupes</surname><given-names>I</given-names></name><name><surname>Andrews</surname><given-names>B</given-names></name><name><surname>Tyers</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>CDK activity antagonizes Whi5, an inhibitor of G1/S transcription in yeast</article-title><source>Cell</source><volume>117</volume><fpage>899</fpage><lpage>913</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2004.05.024</pub-id><pub-id pub-id-type="pmid">15210111</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crane</surname><given-names>MM</given-names></name><name><surname>Clark</surname><given-names>IBN</given-names></name><name><surname>Bakker</surname><given-names>E</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name><name><surname>Swain</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A microfluidic system for studying ageing and dynamic single-cell responses in budding yeast</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e100042</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0100042</pub-id><pub-id pub-id-type="pmid">24950344</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crane</surname><given-names>MM</given-names></name><name><surname>Russell</surname><given-names>AE</given-names></name><name><surname>Schafer</surname><given-names>BJ</given-names></name><name><surname>Blue</surname><given-names>BW</given-names></name><name><surname>Whalen</surname><given-names>R</given-names></name><name><surname>Almazan</surname><given-names>J</given-names></name><name><surname>Hong</surname><given-names>MG</given-names></name><name><surname>Nguyen</surname><given-names>B</given-names></name><name><surname>Goings</surname><given-names>JE</given-names></name><name><surname>Chen</surname><given-names>KL</given-names></name><name><surname>Kelly</surname><given-names>R</given-names></name><name><surname>Kaeberlein</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>DNA damage checkpoint activation impairs chromatin homeostasis and promotes mitotic catastrophe during aging</article-title><source>eLife</source><volume>8</volume><elocation-id>e50778</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.50778</pub-id><pub-id pub-id-type="pmid">31714209</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuny</surname><given-names>AP</given-names></name><name><surname>Ponti</surname><given-names>A</given-names></name><name><surname>Kündig</surname><given-names>T</given-names></name><name><surname>Rudolf</surname><given-names>F</given-names></name><name><surname>Stelling</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Cell region fingerprints enable highly precise single-cell tracking and lineage reconstruction</article-title><source>Nature Methods</source><volume>19</volume><fpage>1276</fpage><lpage>1285</lpage><pub-id pub-id-type="doi">10.1038/s41592-022-01603-2</pub-id><pub-id pub-id-type="pmid">36138173</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Talia</surname><given-names>S</given-names></name><name><surname>Skotheim</surname><given-names>JM</given-names></name><name><surname>Bean</surname><given-names>JM</given-names></name><name><surname>Siggia</surname><given-names>ED</given-names></name><name><surname>Cross</surname><given-names>FR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The effects of molecular noise and size control on variability in the budding yeast cell cycle</article-title><source>Nature</source><volume>448</volume><fpage>947</fpage><lpage>951</lpage><pub-id pub-id-type="doi">10.1038/nature06072</pub-id><pub-id pub-id-type="pmid">17713537</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dietler</surname><given-names>N</given-names></name><name><surname>Minder</surname><given-names>M</given-names></name><name><surname>Gligorovski</surname><given-names>V</given-names></name><name><surname>Economou</surname><given-names>AM</given-names></name><name><surname>Joly</surname><given-names>DAHL</given-names></name><name><surname>Sadeghi</surname><given-names>A</given-names></name><name><surname>Chan</surname><given-names>CHM</given-names></name><name><surname>Koziński</surname><given-names>M</given-names></name><name><surname>Weigert</surname><given-names>M</given-names></name><name><surname>Bitbol</surname><given-names>A-F</given-names></name><name><surname>Rahi</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A convolutional neural network segments yeast microscopy images with high accuracy</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>5723</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-19557-4</pub-id><pub-id pub-id-type="pmid">33184262</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunlop</surname><given-names>MJ</given-names></name><name><surname>Cox</surname><given-names>RS</given-names><suffix>III</suffix></name><name><surname>Levine</surname><given-names>JH</given-names></name><name><surname>Murray</surname><given-names>RM</given-names></name><name><surname>Elowitz</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Regulatory activity revealed by dynamic correlations in gene expression noise</article-title><source>Nature Genetics</source><volume>40</volume><fpage>1493</fpage><lpage>1498</lpage><pub-id pub-id-type="doi">10.1038/ng.281</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edelstein</surname><given-names>AD</given-names></name><name><surname>Tsuchida</surname><given-names>MA</given-names></name><name><surname>Amodaj</surname><given-names>N</given-names></name><name><surname>Pinkard</surname><given-names>H</given-names></name><name><surname>Vale</surname><given-names>RD</given-names></name><name><surname>Stuurman</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Advanced methods of microscope control using μManager software</article-title><source>Journal of Biological Methods</source><volume>1</volume><elocation-id>e10</elocation-id><pub-id pub-id-type="doi">10.14440/jbm.2014.36</pub-id><pub-id pub-id-type="pmid">25606571</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El Meouche</surname><given-names>I</given-names></name><name><surname>Dunlop</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Heterogeneity in efflux pump expression predisposes antibiotic-resistant cells to mutation</article-title><source>Science</source><volume>362</volume><fpage>686</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1126/science.aar7981</pub-id><pub-id pub-id-type="pmid">30409883</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falconnet</surname><given-names>D</given-names></name><name><surname>Niemistö</surname><given-names>A</given-names></name><name><surname>Taylor</surname><given-names>RJ</given-names></name><name><surname>Ricicova</surname><given-names>M</given-names></name><name><surname>Galitski</surname><given-names>T</given-names></name><name><surname>Shmulevich</surname><given-names>I</given-names></name><name><surname>Hansen</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>High-throughput tracking of single yeast cells in a microfluidic imaging matrix</article-title><source>Lab on a Chip</source><volume>11</volume><fpage>466</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1039/c0lc00228c</pub-id><pub-id pub-id-type="pmid">21088765</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falk</surname><given-names>T</given-names></name><name><surname>Mai</surname><given-names>D</given-names></name><name><surname>Bensch</surname><given-names>R</given-names></name><name><surname>Çiçek</surname><given-names>Ö</given-names></name><name><surname>Abdulkadir</surname><given-names>A</given-names></name><name><surname>Marrakchi</surname><given-names>Y</given-names></name><name><surname>Böhm</surname><given-names>A</given-names></name><name><surname>Deubner</surname><given-names>J</given-names></name><name><surname>Jäckel</surname><given-names>Z</given-names></name><name><surname>Seiwald</surname><given-names>K</given-names></name><name><surname>Dovzhenko</surname><given-names>A</given-names></name><name><surname>Tietz</surname><given-names>O</given-names></name><name><surname>Bosco</surname><given-names>CD</given-names></name><name><surname>Walsh</surname><given-names>S</given-names></name><name><surname>Saltukoglu</surname><given-names>D</given-names></name><name><surname>Tay</surname><given-names>TL</given-names></name><name><surname>Prinz</surname><given-names>M</given-names></name><name><surname>Palme</surname><given-names>K</given-names></name><name><surname>Simons</surname><given-names>M</given-names></name><name><surname>Diester</surname><given-names>I</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name><name><surname>Ronneberger</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>U-Net: deep learning for cell counting, detection, and morphometry</article-title><source>Nature Methods</source><volume>16</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0356-4</pub-id><pub-id pub-id-type="pmid">30804552</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrezuelo</surname><given-names>F</given-names></name><name><surname>Colomina</surname><given-names>N</given-names></name><name><surname>Palmisano</surname><given-names>A</given-names></name><name><surname>Garí</surname><given-names>E</given-names></name><name><surname>Gallego</surname><given-names>C</given-names></name><name><surname>Csikász-Nagy</surname><given-names>A</given-names></name><name><surname>Aldea</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The critical size is set at a single-cell level by growth rate to attain homeostasis and adaptation</article-title><source>Nature Communications</source><volume>3</volume><elocation-id>1012</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms2015</pub-id><pub-id pub-id-type="pmid">22910358</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garmendia-Torres</surname><given-names>C</given-names></name><name><surname>Tassy</surname><given-names>O</given-names></name><name><surname>Matifas</surname><given-names>A</given-names></name><name><surname>Molina</surname><given-names>N</given-names></name><name><surname>Charvin</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multiple inputs ensure yeast cell size homeostasis during cell cycle progression</article-title><source>eLife</source><volume>7</volume><elocation-id>e34025</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34025</pub-id><pub-id pub-id-type="pmid">29972352</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ginzberg</surname><given-names>MB</given-names></name><name><surname>Kafri</surname><given-names>R</given-names></name><name><surname>Kirschner</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>On being the right (cell) size</article-title><source>Science</source><volume>348</volume><elocation-id>1245075</elocation-id><pub-id pub-id-type="doi">10.1126/science.1245075</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Godin</surname><given-names>M</given-names></name><name><surname>Delgado</surname><given-names>FF</given-names></name><name><surname>Son</surname><given-names>S</given-names></name><name><surname>Grover</surname><given-names>WH</given-names></name><name><surname>Bryan</surname><given-names>AK</given-names></name><name><surname>Tzur</surname><given-names>A</given-names></name><name><surname>Jorgensen</surname><given-names>P</given-names></name><name><surname>Payer</surname><given-names>K</given-names></name><name><surname>Grossman</surname><given-names>AD</given-names></name><name><surname>Kirschner</surname><given-names>MW</given-names></name><name><surname>Manalis</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Using buoyant mass to measure the growth of single cells</article-title><source>Nature Methods</source><volume>7</volume><fpage>387</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1452</pub-id><pub-id pub-id-type="pmid">20383132</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Deep Learning</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>A</given-names></name><name><surname>Colman-Lerner</surname><given-names>A</given-names></name><name><surname>Chin</surname><given-names>TE</given-names></name><name><surname>Benjamin</surname><given-names>KR</given-names></name><name><surname>Yu</surname><given-names>RC</given-names></name><name><surname>Brent</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Single-cell Quantification of molecules and rates using open-source microscope-based cytometry</article-title><source>Nature Methods</source><volume>4</volume><fpage>175</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1038/nmeth1008</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Granados</surname><given-names>AA</given-names></name><name><surname>Crane</surname><given-names>MM</given-names></name><name><surname>Montano-Gutierrez</surname><given-names>LF</given-names></name><name><surname>Tanaka</surname><given-names>RJ</given-names></name><name><surname>Voliotis</surname><given-names>M</given-names></name><name><surname>Swain</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distributing tasks via multiple input pathways increases cellular survival in stress</article-title><source>eLife</source><volume>6</volume><elocation-id>e21415</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21415</pub-id><pub-id pub-id-type="pmid">28513433</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Granados</surname><given-names>AA</given-names></name><name><surname>Pietsch</surname><given-names>JMJ</given-names></name><name><surname>Cepeda-Humerez</surname><given-names>SA</given-names></name><name><surname>Farquhar</surname><given-names>IL</given-names></name><name><surname>Tkačik</surname><given-names>G</given-names></name><name><surname>Swain</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Distributed and dynamic intracellular organization of extracellular information</article-title><source>PNAS</source><volume>115</volume><fpage>6088</fpage><lpage>6093</lpage><pub-id pub-id-type="doi">10.1073/pnas.1716659115</pub-id><pub-id pub-id-type="pmid">29784812</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>AS</given-names></name><name><surname>Hao</surname><given-names>N</given-names></name><name><surname>O’Shea</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>High-throughput microfluidics to control and measure signaling dynamics in single yeast cells</article-title><source>Nature Protocols</source><volume>10</volume><fpage>1181</fpage><lpage>1197</lpage><pub-id pub-id-type="doi">10.1038/nprot.2015.079</pub-id><pub-id pub-id-type="pmid">26158443</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrigan</surname><given-names>P</given-names></name><name><surname>Madhani</surname><given-names>HD</given-names></name><name><surname>El-Samad</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Real-time genetic compensation defines the dynamic demands of feedback control</article-title><source>Cell</source><volume>175</volume><fpage>877</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.09.044</pub-id><pub-id pub-id-type="pmid">30340045</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartwell</surname><given-names>LH</given-names></name><name><surname>Unger</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Unequal division in <italic>Saccharomyces cerevisiae</italic> and its implications for the control of cell division</article-title><source>The Journal of Cell Biology</source><volume>75</volume><fpage>422</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1083/jcb.75.2.422</pub-id><pub-id pub-id-type="pmid">400873</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Gkioxari</surname><given-names>G</given-names></name><name><surname>Dollar</surname><given-names>P</given-names></name><name><surname>Girshick</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mask R-CNN</article-title><conf-name>2017 IEEE International Conference on Computer Vision (ICCV</conf-name><conf-loc>Venice</conf-loc><fpage>2961</fpage><lpage>2969</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2017.322</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huh</surname><given-names>W-K</given-names></name><name><surname>Falvo</surname><given-names>JV</given-names></name><name><surname>Gerke</surname><given-names>LC</given-names></name><name><surname>Carroll</surname><given-names>AS</given-names></name><name><surname>Howson</surname><given-names>RW</given-names></name><name><surname>Weissman</surname><given-names>JS</given-names></name><name><surname>O’Shea</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Global analysis of protein localization in budding yeast</article-title><source>Nature</source><volume>425</volume><fpage>686</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1038/nature02026</pub-id><pub-id pub-id-type="pmid">14562095</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jasani</surname><given-names>A</given-names></name><name><surname>Huynh</surname><given-names>T</given-names></name><name><surname>Kellogg</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Growth-dependent activation of protein kinases suggests a mechanism for measuring cell growth</article-title><source>Genetics</source><volume>215</volume><fpage>729</fpage><lpage>746</lpage><pub-id pub-id-type="doi">10.1534/genetics.120.303200</pub-id><pub-id pub-id-type="pmid">32461268</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnston</surname><given-names>GC</given-names></name><name><surname>Pringle</surname><given-names>JR</given-names></name><name><surname>Hartwell</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Coordination of growth with cell division in the yeast <italic>Saccharomyces cerevisiae</italic></article-title><source>Experimental Cell Research</source><volume>105</volume><fpage>79</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1016/0014-4827(77)90154-9</pub-id><pub-id pub-id-type="pmid">320023</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jorgensen</surname><given-names>P</given-names></name><name><surname>Rupes</surname><given-names>I</given-names></name><name><surname>Sharom</surname><given-names>JR</given-names></name><name><surname>Schneper</surname><given-names>L</given-names></name><name><surname>Broach</surname><given-names>JR</given-names></name><name><surname>Tyers</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A dynamic transcriptional network communicates growth potential to ribosome synthesis and critical cell size</article-title><source>Genes &amp; Development</source><volume>18</volume><fpage>2491</fpage><lpage>2505</lpage><pub-id pub-id-type="doi">10.1101/gad.1228804</pub-id><pub-id pub-id-type="pmid">15466158</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiviet</surname><given-names>DJ</given-names></name><name><surname>Nghe</surname><given-names>P</given-names></name><name><surname>Walker</surname><given-names>N</given-names></name><name><surname>Boulineau</surname><given-names>S</given-names></name><name><surname>Sunderlikova</surname><given-names>V</given-names></name><name><surname>Tans</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Stochasticity of metabolism and growth at the single-cell level</article-title><source>Nature</source><volume>514</volume><fpage>376</fpage><lpage>379</lpage><pub-id pub-id-type="doi">10.1038/nature13582</pub-id><pub-id pub-id-type="pmid">25186725</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leitao</surname><given-names>RM</given-names></name><name><surname>Kellogg</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The duration of mitosis and daughter cell size are modulated by nutrients in budding yeast</article-title><source>The Journal of Cell Biology</source><volume>216</volume><fpage>3463</fpage><lpage>3470</lpage><pub-id pub-id-type="doi">10.1083/jcb.201609114</pub-id><pub-id pub-id-type="pmid">28939614</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lempiäinen</surname><given-names>H</given-names></name><name><surname>Uotila</surname><given-names>A</given-names></name><name><surname>Urban</surname><given-names>J</given-names></name><name><surname>Dohnal</surname><given-names>I</given-names></name><name><surname>Ammerer</surname><given-names>G</given-names></name><name><surname>Loewith</surname><given-names>R</given-names></name><name><surname>Shore</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sfp1 interaction with TORC1 and Mrs6 reveals feedback regulation on TOR signaling</article-title><source>Molecular Cell</source><volume>33</volume><fpage>704</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1016/j.molcel.2009.01.034</pub-id><pub-id pub-id-type="pmid">19328065</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>S</given-names></name><name><surname>Barkai</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Coordination of gene expression with growth rate: a feedback or a feed-forward strategy</article-title><source>FEBS Letters</source><volume>583</volume><fpage>3974</fpage><lpage>3978</lpage><pub-id pub-id-type="doi">10.1016/j.febslet.2009.10.071</pub-id><pub-id pub-id-type="pmid">19878679</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>SF</given-names></name><name><surname>Ziv</surname><given-names>N</given-names></name><name><surname>Siegal</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Bet hedging in yeast by heterogeneous, age-correlated expression of a stress protectant</article-title><source>PLOS Biology</source><volume>10</volume><elocation-id>e1001325</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001325</pub-id><pub-id pub-id-type="pmid">22589700</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litsios</surname><given-names>A</given-names></name><name><surname>Huberts</surname><given-names>D</given-names></name><name><surname>Terpstra</surname><given-names>HM</given-names></name><name><surname>Guerra</surname><given-names>P</given-names></name><name><surname>Schmidt</surname><given-names>A</given-names></name><name><surname>Buczak</surname><given-names>K</given-names></name><name><surname>Papagiannakis</surname><given-names>A</given-names></name><name><surname>Rovetta</surname><given-names>M</given-names></name><name><surname>Hekelaar</surname><given-names>J</given-names></name><name><surname>Hubmann</surname><given-names>G</given-names></name><name><surname>Exterkate</surname><given-names>M</given-names></name><name><surname>Milias-Argeitis</surname><given-names>A</given-names></name><name><surname>Heinemann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Differential scaling between G1 protein production and cell size dynamics promotes commitment to the cell division cycle in budding yeast</article-title><source>Nature Cell Biology</source><volume>21</volume><fpage>1382</fpage><lpage>1392</lpage><pub-id pub-id-type="doi">10.1038/s41556-019-0413-3</pub-id><pub-id pub-id-type="pmid">31685990</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Locke</surname><given-names>JCW</given-names></name><name><surname>Elowitz</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Using movies to analyse gene circuit dynamics in single cells</article-title><source>Nature Reviews. Microbiology</source><volume>7</volume><fpage>383</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1038/nrmicro2056</pub-id><pub-id pub-id-type="pmid">19369953</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>AX</given-names></name><name><surname>Zarin</surname><given-names>T</given-names></name><name><surname>Hsu</surname><given-names>IS</given-names></name><name><surname>Moses</surname><given-names>AM</given-names></name><name><surname>Murphy</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>YeastSpotter: accurate and parameter-free web segmentation for microscopy images of yeast cells</article-title><source>Bioinformatics</source><volume>35</volume><fpage>4525</fpage><lpage>4527</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz402</pub-id><pub-id pub-id-type="pmid">31095270</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lugagne</surname><given-names>JB</given-names></name><name><surname>Sosa Carrillo</surname><given-names>S</given-names></name><name><surname>Kirch</surname><given-names>M</given-names></name><name><surname>Köhler</surname><given-names>A</given-names></name><name><surname>Batt</surname><given-names>G</given-names></name><name><surname>Hersen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Balancing a genetic toggle switch by real-time feedback control and periodic forcing</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>1671</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-01498-0</pub-id><pub-id pub-id-type="pmid">29150615</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lugagne</surname><given-names>J-B</given-names></name><name><surname>Jain</surname><given-names>S</given-names></name><name><surname>Ivanovitch</surname><given-names>P</given-names></name><name><surname>Ben Meriem</surname><given-names>Z</given-names></name><name><surname>Vulin</surname><given-names>C</given-names></name><name><surname>Fracassi</surname><given-names>C</given-names></name><name><surname>Batt</surname><given-names>G</given-names></name><name><surname>Hersen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Identification of individual cells from Z-stacks of bright-field microscopy images</article-title><source>Scientific Reports</source><volume>8</volume><elocation-id>11455</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-29647-5</pub-id><pub-id pub-id-type="pmid">30061662</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Manning</surname><given-names>CD</given-names></name><name><surname>Raghavan</surname><given-names>P</given-names></name><name><surname>Schütze</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Introduction to Information Retrieval</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511809071</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menolascina</surname><given-names>F</given-names></name><name><surname>Fiore</surname><given-names>G</given-names></name><name><surname>Orabona</surname><given-names>E</given-names></name><name><surname>De Stefano</surname><given-names>L</given-names></name><name><surname>Ferry</surname><given-names>M</given-names></name><name><surname>Hasty</surname><given-names>J</given-names></name><name><surname>di Bernardo</surname><given-names>M</given-names></name><name><surname>di Bernardo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>In-vivo real-time control of protein expression from endogenous and synthetic gene networks</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003625</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003625</pub-id><pub-id pub-id-type="pmid">24831205</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Metzl-Raz</surname><given-names>E</given-names></name><name><surname>Kafri</surname><given-names>M</given-names></name><name><surname>Yaakov</surname><given-names>G</given-names></name><name><surname>Soifer</surname><given-names>I</given-names></name><name><surname>Gurvich</surname><given-names>Y</given-names></name><name><surname>Barkai</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Principles of cellular resource allocation revealed by condition-dependent proteome profiling</article-title><source>eLife</source><volume>6</volume><elocation-id>e28034</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.28034</pub-id><pub-id pub-id-type="pmid">28857745</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milias-Argeitis</surname><given-names>A</given-names></name><name><surname>Summers</surname><given-names>S</given-names></name><name><surname>Stewart-Ornstein</surname><given-names>J</given-names></name><name><surname>Zuleta</surname><given-names>I</given-names></name><name><surname>Pincus</surname><given-names>D</given-names></name><name><surname>El-Samad</surname><given-names>H</given-names></name><name><surname>Khammash</surname><given-names>M</given-names></name><name><surname>Lygeros</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>In silico feedback for in vivo regulation of a gene expression circuit</article-title><source>Nature Biotechnology</source><volume>29</volume><fpage>1114</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1038/nbt.2018</pub-id><pub-id pub-id-type="pmid">22057053</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murugan</surname><given-names>A</given-names></name><name><surname>Husain</surname><given-names>K</given-names></name><name><surname>Rust</surname><given-names>MJ</given-names></name><name><surname>Hepler</surname><given-names>C</given-names></name><name><surname>Bass</surname><given-names>J</given-names></name><name><surname>Pietsch</surname><given-names>JMJ</given-names></name><name><surname>Swain</surname><given-names>PS</given-names></name><name><surname>Jena</surname><given-names>SG</given-names></name><name><surname>Toettcher</surname><given-names>JE</given-names></name><name><surname>Chakraborty</surname><given-names>AK</given-names></name><name><surname>Sprenger</surname><given-names>KG</given-names></name><name><surname>Mora</surname><given-names>T</given-names></name><name><surname>Walczak</surname><given-names>AM</given-names></name><name><surname>Rivoire</surname><given-names>O</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Wood</surname><given-names>KB</given-names></name><name><surname>Skanata</surname><given-names>A</given-names></name><name><surname>Kussell</surname><given-names>E</given-names></name><name><surname>Ranganathan</surname><given-names>R</given-names></name><name><surname>Shih</surname><given-names>HY</given-names></name><name><surname>Goldenfeld</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Roadmap on biology in time varying environments</article-title><source>Physical Biology</source><volume>18</volume><pub-id pub-id-type="doi">10.1088/1478-3975/abde8d</pub-id><pub-id pub-id-type="pmid">33477124</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orr</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fitness and its role in evolutionary genetics</article-title><source>Nature Reviews. Genetics</source><volume>10</volume><fpage>531</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1038/nrg2603</pub-id><pub-id pub-id-type="pmid">19546856</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Cellpose 2.0: how to train your own model</article-title><source>Nature Methods</source><volume>19</volume><fpage>1634</fpage><lpage>1641</lpage><pub-id pub-id-type="doi">10.1038/s41592-022-01663-4</pub-id><pub-id pub-id-type="pmid">36344832</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padovani</surname><given-names>F</given-names></name><name><surname>Mairhörmann</surname><given-names>B</given-names></name><name><surname>Falter-Braun</surname><given-names>P</given-names></name><name><surname>Lengefeld</surname><given-names>J</given-names></name><name><surname>Schmoller</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Segmentation, tracking and cell cycle analysis of live-cell imaging data with cell-ACDC</article-title><source>BMC Biology</source><volume>20</volume><elocation-id>174</elocation-id><pub-id pub-id-type="doi">10.1186/s12915-022-01372-6</pub-id><pub-id pub-id-type="pmid">35932043</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: Machine learning in Python</article-title><source>Journal of Machine Learning Research: JMLR</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelt</surname><given-names>DM</given-names></name><name><surname>Sethian</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A mixed-scale dense convolutional neural network for image analysis</article-title><source>PNAS</source><volume>115</volume><fpage>254</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1073/pnas.1715832114</pub-id><pub-id pub-id-type="pmid">29279403</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perkins</surname><given-names>TJ</given-names></name><name><surname>Swain</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Strategies for cellular decision-making</article-title><source>Molecular Systems Biology</source><volume>5</volume><elocation-id>326</elocation-id><pub-id pub-id-type="doi">10.1038/msb.2009.83</pub-id><pub-id pub-id-type="pmid">19920811</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pietsch</surname><given-names>JMJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>The birth Annotator for budding yeast (BABY)</data-title><version designator="swh:1:rev:63d6aa7a4c11426fc3aad4b39ea6c6fb50d56438">swh:1:rev:63d6aa7a4c11426fc3aad4b39ea6c6fb50d56438</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:9751e385e3e7a35035137c9defaecc60305ef551;origin=https://git.ecdf.ed.ac.uk/swain-lab/baby;visit=swh:1:snp:3390f39a30685561c5ff0f4f0af72baae40e7d3e;anchor=swh:1:rev:63d6aa7a4c11426fc3aad4b39ea6c6fb50d56438">https://archive.softwareheritage.org/swh:1:dir:9751e385e3e7a35035137c9defaecc60305ef551;origin=https://git.ecdf.ed.ac.uk/swain-lab/baby;visit=swh:1:snp:3390f39a30685561c5ff0f4f0af72baae40e7d3e;anchor=swh:1:rev:63d6aa7a4c11426fc3aad4b39ea6c6fb50d56438</ext-link></element-citation></ref><ref id="bib65"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Fischer</surname><given-names>P</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>U-net: Convolutional networks for biomedical image segmentation</article-title><conf-name>International Conference on Medical Image Computing and Computer-Assisted Intervention</conf-name><fpage>234</fpage><lpage>241</lpage></element-citation></ref><ref id="bib66"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Fischer</surname><given-names>P</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>U-Net: convolutional networks for biomedical image segmentation</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1505.04597">https://arxiv.org/abs/1505.04597</ext-link><pub-id pub-id-type="doi">10.1007/978-3-319-24574-4</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>U</given-names></name><name><surname>Weigert</surname><given-names>M</given-names></name><name><surname>Broaddus</surname><given-names>C</given-names></name><name><surname>Myers</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cell detection with star-convex polygons</article-title><conf-name>Medical Image Computing and Computer Assisted Intervention - MICCAI 2018</conf-name><fpage>265</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-00934-2</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmoller</surname><given-names>KM</given-names></name><name><surname>Turner</surname><given-names>JJ</given-names></name><name><surname>Kõivomägi</surname><given-names>M</given-names></name><name><surname>Skotheim</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dilution of the cell cycle inhibitor Whi5 controls budding-yeast cell size</article-title><source>Nature</source><volume>526</volume><fpage>268</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/nature14908</pub-id><pub-id pub-id-type="pmid">26390151</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>M</given-names></name><name><surname>Klumpp</surname><given-names>S</given-names></name><name><surname>Mateescu</surname><given-names>EM</given-names></name><name><surname>Hwa</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emergence of robust growth laws from optimal regulation of ribosome synthesis</article-title><source>Molecular Systems Biology</source><volume>10</volume><elocation-id>747</elocation-id><pub-id pub-id-type="doi">10.15252/msb.20145379</pub-id><pub-id pub-id-type="pmid">25149558</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>J</given-names></name><name><surname>Tyers</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A Rab escort protein integrates the secretion system with TOR signaling and ribosome biogenesis</article-title><source>Genes &amp; Development</source><volume>23</volume><fpage>1944</fpage><lpage>1958</lpage><pub-id pub-id-type="doi">10.1101/gad.1804409</pub-id><pub-id pub-id-type="pmid">19684114</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soifer</surname><given-names>I</given-names></name><name><surname>Robert</surname><given-names>L</given-names></name><name><surname>Amir</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Single-cell analysis of growth in budding yeast and bacteria reveals a common size regulation strategy</article-title><source>Current Biology</source><volume>26</volume><fpage>356</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.11.067</pub-id><pub-id pub-id-type="pmid">26776734</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Michaelos</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title><source>Nature Methods</source><volume>18</volume><fpage>100</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1038/s41592-020-01018-x</pub-id><pub-id pub-id-type="pmid">33318659</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swain</surname><given-names>PS</given-names></name><name><surname>Stevenson</surname><given-names>K</given-names></name><name><surname>Leary</surname><given-names>A</given-names></name><name><surname>Montano-Gutierrez</surname><given-names>LF</given-names></name><name><surname>Clark</surname><given-names>IBN</given-names></name><name><surname>Vogel</surname><given-names>J</given-names></name><name><surname>Pilizota</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Inferring time derivatives including cell growth rates using Gaussian processes</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13766</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13766</pub-id><pub-id pub-id-type="pmid">27941811</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toettcher</surname><given-names>JE</given-names></name><name><surname>Gong</surname><given-names>D</given-names></name><name><surname>Lim</surname><given-names>WA</given-names></name><name><surname>Weiner</surname><given-names>OD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Light-based feedback for controlling intracellular signaling dynamics</article-title><source>Nature Methods</source><volume>8</volume><fpage>837</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1700</pub-id><pub-id pub-id-type="pmid">21909100</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>JJ</given-names></name><name><surname>Ewald</surname><given-names>JC</given-names></name><name><surname>Skotheim</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Cell size control in yeast</article-title><source>Current Biology</source><volume>22</volume><fpage>R350</fpage><lpage>R359</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.02.041</pub-id><pub-id pub-id-type="pmid">22575477</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uhlendorf</surname><given-names>J</given-names></name><name><surname>Miermont</surname><given-names>A</given-names></name><name><surname>Delaveau</surname><given-names>T</given-names></name><name><surname>Charvin</surname><given-names>G</given-names></name><name><surname>Fages</surname><given-names>F</given-names></name><name><surname>Bottani</surname><given-names>S</given-names></name><name><surname>Batt</surname><given-names>G</given-names></name><name><surname>Hersen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Long-term model predictive control of gene expression at the population and single-cell levels</article-title><source>PNAS</source><volume>109</volume><fpage>14271</fpage><lpage>14276</lpage><pub-id pub-id-type="doi">10.1073/pnas.1206810109</pub-id><pub-id pub-id-type="pmid">22893687</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulicna</surname><given-names>K</given-names></name><name><surname>Vallardi</surname><given-names>G</given-names></name><name><surname>Charras</surname><given-names>G</given-names></name><name><surname>Lowe</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Automated deep lineage tree analysis using a Bayesian single cell tracking approach</article-title><source>Frontiers in Computer Science</source><volume>3</volume><elocation-id>734559</elocation-id><pub-id pub-id-type="doi">10.3389/fcomp.2021.734559</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Walt</surname><given-names>S</given-names></name><name><surname>Schönberger</surname><given-names>JL</given-names></name><name><surname>Nunez-Iglesias</surname><given-names>J</given-names></name><name><surname>Boulogne</surname><given-names>F</given-names></name><name><surname>Warner</surname><given-names>JD</given-names></name><name><surname>Yager</surname><given-names>N</given-names></name><name><surname>Gouillart</surname><given-names>E</given-names></name><name><surname>Yu</surname><given-names>T</given-names></name><collab>scikit-image contributors</collab></person-group><year iso-8601-date="2014">2014</year><article-title>scikit-image: image processing in Python</article-title><source>PeerJ</source><volume>2</volume><elocation-id>e453</elocation-id><pub-id pub-id-type="doi">10.7717/peerj.453</pub-id><pub-id pub-id-type="pmid">25024921</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>van Tulder</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>elasticdeform: Elastic deformations for N-dimensional images</data-title><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.7102577">https://doi.org/10.5281/zenodo.7102577</ext-link></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Versari</surname><given-names>C</given-names></name><name><surname>Stoma</surname><given-names>S</given-names></name><name><surname>Batmanov</surname><given-names>K</given-names></name><name><surname>Llamosi</surname><given-names>A</given-names></name><name><surname>Mroz</surname><given-names>F</given-names></name><name><surname>Kaczmarek</surname><given-names>A</given-names></name><name><surname>Deyell</surname><given-names>M</given-names></name><name><surname>Lhoussaine</surname><given-names>C</given-names></name><name><surname>Hersen</surname><given-names>P</given-names></name><name><surname>Batt</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Long-term tracking of budding yeast cells in brightfield microscopy: CellStar and the Evaluation Platform</article-title><source>Journal of the Royal Society, Interface</source><volume>14</volume><elocation-id>20160705</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2016.0705</pub-id><pub-id pub-id-type="pmid">28179544</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>NE</given-names></name><name><surname>Doncic</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A fully-automated, robust, and versatile algorithm for long-term budding yeast segmentation and tracking</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0206395</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0206395</pub-id><pub-id pub-id-type="pmid">30917124</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>The BABY algorithm: identifying cells and buds</title><sec sec-type="appendix" id="s8-1"><title>Mapping cell instances to a semantic representation</title><p>For epifluorescence microscopy, samples are typically prepared to constrain cells in a monolayer. For cells with similar sizes that match the height of this constraint, they will be physically prevented from overlapping. If cells are of different sizes, however, then a small cell can potentially fit in gaps and overlap with others. This phenomenon is especially prevalent for cells that divide asymmetrically, where a small bud grows out of a larger mother.</p><p>Few segmentation algorithms identify instances of overlapping cells. Most, including recent methods for budding yeast (<xref ref-type="bibr" rid="bib81">Wood and Doncic, 2019</xref>; <xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>; <xref ref-type="bibr" rid="bib52">Lugagne et al., 2018</xref>), assume that cells can be labelled semantically, with each pixel of the image identified with at most one cell. Similarly, most tools for annotating also label semantically, and consequently curated training data does not allow for overlaps (<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>), even when the segmentation algorithm could (<xref ref-type="bibr" rid="bib50">Lu et al., 2019</xref>). Our laboratory’s previous segmentation algorithm included limited overlap between neighbouring cells (<xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>), but not the substantial overlap we see between the smaller buds and their neighbours.</p></sec><sec sec-type="appendix" id="s8-2"><title>Separating cells by size to disjoin overlapping cells</title><p>We rely on two consequences of the height constraint to segment overlapping instances. First, cells of different sizes show different patterns of overlap; second, the cells’ centres are rarely coincident. Very occasionally, we do observe small buds stacked directly on top of each other, but neglecting these rare cases does not degrade performance. We therefore use morphological erosions to obtain semantic images by shrinking cell masks within a size category and, later, morphological dilations to approximate the original cell outlines from each resulting connected region.</p><p>To separate overlapping cells, we define three size categories and treat instances in each category differently. <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> illustrates our approach, where we segment a bud (orange outline) that overlaps a mother cell (green outline). The bud is only visible in the third and fourth Z sections of the bright-field images (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1a</xref>). If used for training, we would split the manually curated outlines in this example (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1b</xref>) into different size categories (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1c</xref>). The bud is assigned to the small category. When we fill the outlines in this category and convert the image to a binary one (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1d</xref>), the individual cell masks are distinct. For the large category, however, the masks are not separable when immediately converted, but become so when the filled outlines are morphologically eroded (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1d</xref>). The largest size category tolerates more erosions than smaller ones, for which the mask may disappear or lose its shape.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Mapping cell instances to semantic targets of a CNN.</title><p>(<bold>a</bold>) Bright-field Z-sections of cells trapped in an ALCATRAS device. (<bold>b</bold>) Curated cell outlines overlaid on one bright-field section. (<bold>c</bold>) BABY separates outlines into categories by size, with each category having some overlap with neighbouring ones. Here the red outline in the medium category appears too in the small category. (<bold>d</bold>) Cell-interior targets for the CNN are the cell masks generated after different rounds of morphological erosions appropriate for each size category: no erosion for small cells, four iterations for medium, and five for large. On the right, we show the outlines overlaid on the target masks. (<bold>e</bold>) The CNN’s edge targets are the outlines for each size category. (<bold>f</bold>) The curated cell outlines of b, but with arrows to show the lineages assigned during curation. (<bold>g</bold>) Using these curated lineages, we define the CNN’s ‘bud neck’ target as the overlap of the bud mask with a morphological dilation of the mother mask (right).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app1-fig1-v2.tif"/></fig></sec><sec sec-type="appendix" id="s8-3"><title>Determining the size categories</title><p>Using the training data – curated masks for each cell present at each trap at each time point, we identify the size categories that best separate overlapping cells. To begin, we calculate the overlap fraction – the intersection over union – between all pairs of cell masks. Its distribution reveals that the most substantial overlaps occur between cells of different sizes (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2a</xref> – upper triangle).</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>BABY reduces overlaps between cells through categorising cells by size.</title><p>(<bold>a</bold>) Upper triangle: plotting the overlap fraction for each pair of cells – the intersection over union of their bit masks, shows that the majority of overlaps occur for cells of different sizes. Almost all overlaps have the size of cell 2 greater than the size of cell 1 and lie off the diagonal. Lower triangle: With a single fuzzy size threshold, cells in the small category have sizes less than the upper threshold (<inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula>; dashed line), and cells in the larger category have sizes greater than the lower threshold (<inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula>; dotted line). We show the overlap fraction by the size of the dot. Within each category (green and blue dots), small overlap fractions dominate; between the two categories (red dots), large overlaps dominate. By converting the bit masks into two binary images, one for each size category, rather than a single binary image, we therefore eliminate most of the substantial overlaps. (<bold>b</bold>) The distribution of all mask areas in the same training data for comparison. We indicate the size thresholds as in a. (<bold>c</bold>) The distributions of overlap fractions for mask pairs grouped using the fuzzy size threshold of a. We omit pairs that do not overlap for clarity. (<bold>d</bold>) Applying morphological erosions of the cell masks reduces the number of overlapping cell pairs, but generates smaller masks. We judge masks with areas below 10 pixels squared to be too small. (<bold>e</bold>) The numbers of overlapping cell pairs remaining from the training, validation, and test sets either before, denoted None, or after splitting into size categories and applying an optimised number of erosions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app1-fig2-v2.tif"/></fig><p>We therefore choose the size categories so that most overlaps occur between pairs of cells in different categories and little overlap occurs between pairs of cells within a category. For example, rather than converting the cell masks directly into a single binary image for training, if first we divide cells into two size categories and convert the masks within each category to a separate binary image, giving two images rather than one, then in these two images we have eliminated all overlaps occurring between cells in the smaller category with cells in the larger category (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> and <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref> – lower triangle).</p><p>To divide the cell masks into two categories, we define a fuzzy size threshold using a threshold <inline-formula><mml:math id="inf15"><mml:mi>T</mml:mi></mml:math></inline-formula> and padding value <inline-formula><mml:math id="inf16"><mml:mi>P</mml:mi></mml:math></inline-formula>. The set of smaller masks is all masks whose area is less than <inline-formula><mml:math id="inf17"><mml:mrow><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula>; the set of larger masks is all masks whose area is greater than <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula>. Consequently, the same mask can be in both sets (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1c</xref>). This redundancy ensures the CNN produces confident predictions even for cells close to the size threshold, and we eliminate any resulting duplicate predictions in post-processing. BABY prevents a pair of masks overlapping by converted each into distinct binary images if the padded threshold separates their sizes: the smaller cell must have a size <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and the larger cell must have a size <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. To scale with pixel size, we set <inline-formula><mml:math id="inf21"><mml:mi>P</mml:mi></mml:math></inline-formula> to be 1% of the area of the largest mask in the training set.</p><p>To determine an optimal fuzzy threshold, we test <inline-formula><mml:math id="inf22"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> values evenly spaced between the minimal and maximal mask sizes and choose the threshold that minimises the summed overlap fraction for all mask pairs not excluded by the threshold. Even with one fuzzy threshold (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2a</xref>), we exclude most of the pairs with substantial overlap – typically buds with neighbouring cells (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2c</xref>).</p><p>After applying the threshold, overlaps between cells within a size category remain, and we reduce such overlaps using morphological erosions (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). We use the training data to optimise the number of erosions per size category. As the number of iterations increases, there is a trade-off between the number of overlapping mask pairs and the number of masks whose eroded areas become too small to be confidently predicted by the CNN (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2d</xref>). Without erosion, the large cells can show overlaps; with too much erosion, the smallest masks distort their shapes or disappear. We therefore optimise the number of iterations separately for each size category, picking the highest number of iterations that do not let any of that category’s training masks either fall below an absolute minimal size, defined as 10 pixels squared, or fall below 50% of the category’s median cell size before any erosions.</p><p>Combining categorising by size with eroding reduces the number of pairs of overlapping masks almost to zero (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2e</xref>). We arrive at three size categories by first introducing an additional fuzzy threshold for each of the two initial size categories. These thresholds are similarly determined by testing <inline-formula><mml:math id="inf23"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> fuzzy threshold values and calculating the overlap fraction for all mask pairs not excluded by either the original or the new threshold. We only keep one of the new thresholds – the one minimising the overlap fraction, giving three size categories in total. This extra category results in a further, although proportionally smaller, decrease in the number of overlapping masks.</p><p>After erosion, mask interiors within each size category are easily identified, but with less resolved edges. To help alleviate this loss, we generate edge targets for the CNN from the training data (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1e</xref>) – the outlines of all cells within each size category.</p><p>The microcolony training images for YeaZ (<xref ref-type="bibr" rid="bib21">Dietler et al., 2020</xref>) include a larger range of cell sizes than in our training set. We therefore increased <inline-formula><mml:math id="inf24"><mml:mi>B</mml:mi></mml:math></inline-formula> to 200 (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) and determined the thresholds on square-root transformed sizes. We transformed these thresholds back to the original scale when providing targets for the CNN.</p></sec><sec sec-type="appendix" id="s8-4"><title>Four types of training targets</title><p>We further annotate the curated data with lineage assignments (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1f</xref>), which BABY uses to generate ‘bud neck’ targets for the CNN (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1g</xref>). The final target is another binary image, which is only true wherever masks of any size overlap.</p><p>In total, the eight training targets for the CNN are the mask interiors and edges for three size categories, the bud necks, and the overlap target. We weighted the targets according to their difficulty and importance in post-processing steps: the large and medium edge targets and small interior target with a weight of two and the small edge target with one of four.</p></sec><sec sec-type="appendix" id="s8-5"><title>Predicting semantic targets with a convolutional neural network</title><p>We trained fully convolutional neural networks (<xref ref-type="bibr" rid="bib31">Goodfellow et al., 2016</xref>) to map a stack of bright-field sections to multiple binary target images. We show some example inputs and outputs in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, but we also trained networks with only one or three bright-field sections. The intensities of the bright-field sections were normalised to the interval <inline-formula><mml:math id="inf25"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> by subtracting the median and scaling according to the range of intensities expected between the 2nd and 98 percentiles.</p><p>Each output layer of the CNN approximates the probability that a given pixel belongs to the target class, being a convolution with kernel of size 1 × 1 and sigmoidal activation. All other convolutions had kernels of size 3 × 3 with ReLU activation and used padding to ensure consistent dimensions for input and output layers.</p></sec><sec sec-type="appendix" id="s8-6"><title>Augmenting the training data</title><p>To prevent over-fitting and improve generalisation, we augmented the training data (<xref ref-type="bibr" rid="bib31">Goodfellow et al., 2016</xref>). Each time the CNN sees a training example, it sees too a randomly selected series of image manipulations applied to the input and target. The same training example therefore typically appears differently for each epoch.</p><p>Three augmentations were always applied and the others applied with a certain probability. The fixed augmentations were horizontal and vertical translations and if the bright-field input had more Z sections than expected by the network, we selected a random subset, excluding any subsets with selected sections separated by two or more missing sections. Those augmentations applied with a probability <inline-formula><mml:math id="inf26"><mml:mi>p</mml:mi></mml:math></inline-formula> comprised elastic deformation (<inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>), image rotation (<inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>), re-scaling (<inline-formula><mml:math id="inf29"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>), vertical and horizontal flips (each with <inline-formula><mml:math id="inf30"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>), addition of white noise (<inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>), and a step shift of the Z sections (<inline-formula><mml:math id="inf32"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math></inline-formula>). The probability of not augmenting was thus <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>. To show a different region of each image-mask pair at each epoch, translation, rotation, and re-scaling were all applied to images and masks before cropping to a consistent size (128 × 128 pixels for a pixel size of 0.182μm). Using reflection to handle the boundary, translations were over a random distance and rotations over a random angle. To apply elastic deformation, as described for the original U-Net (<xref ref-type="bibr" rid="bib66">Ronneberger et al., 2015b</xref>), we used the elasticdeform package (<xref ref-type="bibr" rid="bib79">van Tulder, 2022</xref>) for an evenly spaced grid with target distance between points of 32 pixels and standard deviation of displacement of 2. Augmentation by re-scaling was for a randomly selected scaling factor up to 5%. Augmentation by addition of white noise involved adding random Gaussian noise with a standard deviation picked from an exponential distribution with rate  to each pixel of the (normalised) bright-field images.</p><p>To reduce aliasing errors when manipulating binary masks during augmentation, we applied all image transformations independently to each filled mask before converting the transformed masks into one binary image. Further, before a transformation, we smoothed each binary filled outline with a 2D Gaussian filter and found the transformed binary outline with the Canny algorithm. To determine the standard deviation of this Gaussian filter, σ, we tested a range of values on the training outlines. For each filled outline and σ, we applied the filter followed by edge detection and filling. We then calculated the intersection over union of the resulting filled outline with the original filled outline. We observed that as a function of edge length, defined as the number of edge pixels, the σ producing the highest intersection over union increased exponentially. We consequently used an exponential fit of this data to estimate an appropriate σ for each outline.</p><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Training performance of the multi-target U-Net.</title><p>(<bold>a</bold>) A schematic of a U-Net architecture with depth <inline-formula><mml:math id="inf34"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>. The labels above the convolution operations indicate the number of output filters as a multiple of <inline-formula><mml:math id="inf35"><mml:mi>n</mml:mi></mml:math></inline-formula>. Layer heights indicate reduction in image size with network depth. (<bold>b</bold>) Loss for the fully trained 5Z model U-Net with hyperparameters chosen from training trial giving the lowest final validation loss: a U-Net with depth <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, filter factor <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:math></inline-formula>, and batch normalisation. (<bold>c–e</bold>) Performance of (<bold>c</bold>) interior, (<bold>d</bold>) edge and (<bold>e</bold>) bud neck, and overlap targets by the U-Net of b decomposed into the three different size categories when possible. The Dice coefficient reports similarity between prediction probabilities and target masks with a value of 1 indicating identity. For two sets <inline-formula><mml:math id="inf38"><mml:mi>X</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf39"><mml:mi>Y</mml:mi></mml:math></inline-formula>, the Dice coefficient is <inline-formula><mml:math id="inf40"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>∩</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app1-fig3-v2.tif"/></fig></sec><sec sec-type="appendix" id="s8-7"><title>Training</title><p>We trained networfks using Keras with TensorFlow 2.8. We used Adam optimisation with the default parameters except for a learning rate of 0.001 and regularised by keeping only the network weights from the epoch with the lowest validation loss (similar in principle to the early stopping method) (<xref ref-type="bibr" rid="bib31">Goodfellow et al., 2016</xref>). We train for 600 epochs, or complete iterations over the training data set.</p><p>The loss function is the sum of the binary cross-entropy and one minus the Dice coefficient across all targets:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf41"><mml:mi>y</mml:mi></mml:math></inline-formula> is the tensor of true values, <inline-formula><mml:math id="inf42"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> is the CNN’s sigmoid tensor output of the CNN, and <inline-formula><mml:math id="inf43"><mml:mi>i</mml:mi></mml:math></inline-formula> is a vectorised index.</p><p>Each CNN is trained to a specific pixel size, and we ensured that training images and masks with different pixel sizes were re-scaled appropriately</p></sec><sec sec-type="appendix" id="s8-8"><title>CNN architectures</title><p>We trialled two core architectures for the CNN – U-Net (<xref ref-type="bibr" rid="bib66">Ronneberger et al., 2015b</xref>; <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3a</xref>) and Mixed-Scale-Dense (MSD) (<xref ref-type="bibr" rid="bib62">Pelt and Sethian, 2018</xref>) – and optimised hyperparameters to find the smallest loss on the validation data.</p><p>The U-Net performed best (see ‘Optimising hyperparameters’ below). The U-Net has two parts: an encoder that reduces the input into multiple small features and a decoder that scales these features up into an output (<xref ref-type="bibr" rid="bib66">Ronneberger et al., 2015b</xref>). Each step of the encoder comprises a convolutional block, which creates a new, larger set of features from its input. To force the network to keep only small, relevant features, a down-sampling step is applied after three convolutional blocks. This maximum pooling layer reduces the size of the features by half by replacing each two-by-two block of pixels by their maximal value. The decoder also comprises convolutional blocks, but with up-sampling instead of down-sampling. The up-sampling step is the inverse of down-sampling: each pixel is turned into a two-by-two block by repeating its value. Finally, most characteristic of the U-Net is its skip layers. These layers preserve information on the global organisation of the pixels by passing larger-scale information from the encoder to the decoder after each up-sampling step. They act by concatenating the same-size layer of the encoder into the decoder layers, which are then used as inputs for the next step of the decoder. The decoder is therefore able to create an output from both the local features that it up-sampled and from the global features that it obtains from the skip layers.</p><p>For the U-Net, we optimised for depth, for a scaling factor for the number of filters output by each convolution, whether or not to include batch normalisation, and for the proportion of neurons to drop out on each batch. For the MSD, we optimised for depth, defined as the total number of convolutions, for the number of dilation rates to loop over with each loop increasing dilation by a factor of two, for an overall dilation-rate scaling factor, and whether or not to include batch normalisation.</p></sec><sec sec-type="appendix" id="s8-9"><title>Optimising hyperparameters</title><p>We used KerasTuner with TensorFlow 2.4 to optimise hyperparameters, choosing random search with default settings, training for a maximum of 100 epochs, and having 10 training and validation steps per epoch. The U-Net and MSD networks with the lowest final validation loss were then re-trained as described, and the network with the lowest validation loss chosen.</p><p>For our data, the best performing model was a U-Net with depth four, and so three contractions, with a scaling factor of 16 for the number of filters output by each convolution, giving 16, 32, 64 and 128 filters for each of the two chained convolution layers of the encoding and decoding blocks, with batch normalisation, and with no drop-out. We show its performance for the 5Z model in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3c–e</xref>.</p></sec><sec sec-type="appendix" id="s8-10"><title>Identifying cells</title><p>To identify cell instances from the semantic predictions of the CNN, we developed a post-processing pipeline with two parts (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4a</xref>): proposing unique cell outlines and then refining their edges.</p><p>The pipeline includes multiple parameters that we optimise on validation data by a partial grid search. We favour precision, the fraction of true predicted positives, over recall, the fraction of ground truth positives we predict, by maximising the <inline-formula><mml:math id="inf44"><mml:msub><mml:mi>F</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:math></inline-formula> score with <inline-formula><mml:math id="inf45"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>. Recall that for true positives <inline-formula><mml:math id="inf46"><mml:mi>TP</mml:mi></mml:math></inline-formula>, false negatives <inline-formula><mml:math id="inf47"><mml:mi>FN</mml:mi></mml:math></inline-formula>, and false positives <inline-formula><mml:math id="inf48"><mml:mi>FP</mml:mi></mml:math></inline-formula>,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>TP</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>TP</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi>FN</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>FP</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We measure how well two masks match using the intersection over union (IoU) and consider a match to occur if <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Nevertheless, multiple predictions may match a single target mask because predicted masks can overlap too. We therefore count true positives as target masks for which there is at least one predicted mask with <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Any predicted masks in excess of the true positive count are false positives, thus avoiding double counting. Unmatched target masks are false negatives.</p></sec><sec sec-type="appendix" id="s8-11"><title>Proposing cell outlines</title><p>The post-processing pipeline starts by identifying candidate outlines independently for each size category. The CNN’s outputs are images <inline-formula><mml:math id="inf51"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> approximating the probability that a pixel at position <inline-formula><mml:math id="inf52"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> belongs to either the small, medium, or large size categories, denoted <inline-formula><mml:math id="inf53"><mml:mi>S</mml:mi></mml:math></inline-formula>, and to one of the other classes, denoted <inline-formula><mml:math id="inf54"><mml:mi>C</mml:mi></mml:math></inline-formula>: either the interior (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4b</xref>), edge (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4e and f</xref>), bud neck, or general overlap classes.</p><p>In principle, we could find instances for each size category by thresholding the interior probability <inline-formula><mml:math id="inf55"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>interior</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and identifying connected regions as outlines. To further enhance separability, however, we also re-weight the interior probabilities using the edge probabilities. Specifically, we identify connected regions from semantic bit masks <inline-formula><mml:math id="inf56"><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>interior</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> by those pixels that satisfy<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf57"><mml:msup><mml:mi>Dilate</mml:mi><mml:mi>N</mml:mi></mml:msup></mml:math></inline-formula> specifies <inline-formula><mml:math id="inf58"><mml:mi>N</mml:mi></mml:math></inline-formula> iterations of a gray scale morphological dilation and <inline-formula><mml:math id="inf59"><mml:msub><mml:mi>T</mml:mi><mml:mi>interior</mml:mi></mml:msub></mml:math></inline-formula> is a threshold. We optimise the thresholds <inline-formula><mml:math id="inf60"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>interior</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mn>0.95</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, number of dilations <inline-formula><mml:math id="inf61"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>dilate</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and the order of connectivity (one- or two-connectivity) for each size category.</p><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Segmenting overlapping cell instances from the CNN’s output.</title><p>(<bold>a</bold>) A flow chart summarising the post-processing for identifying individual instances from the CNN’s multi-target output. Here and below, we show results using the five Z sections of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> as input to the CNN, and one of which we repeat here. (<bold>b</bold>) The probability maps output by the CNN for the interiors of small, medium, and large cells. (<bold>c</bold>) Bit masks obtained by thresholding on the CNN’s output. Darker shading shows bit masks before we dilate each instance to compensate for the erosion applied when generating the training targets. Colour indicates distinctly identified instances. (<bold>d</bold>) We show the initial, equiangular radial splines proposed for each instance overlaid on the dilated bitmasks from c, with the rays defining placement of the knots as spokes. (<bold>e</bold>) The same initial proposed radial splines overlaid on the edge target probability maps output by the CNN. (<bold>f</bold>) The radial splines after optimisation to match edge probabilities. The outline in the medium size category is detected as a duplicate and not optimised.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app1-fig4-v2.tif"/></fig><p>The connected regions in <inline-formula><mml:math id="inf62"><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>interior</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> define masks that are initial estimates of the cells’ interiors (darker shading in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4c</xref>). We generate the cell interiors for training the CNN by iterative, binary morphological erosions of the full mask, where the number of iterations <inline-formula><mml:math id="inf63"><mml:msub><mml:mi>N</mml:mi><mml:mi>erosion</mml:mi></mml:msub></mml:math></inline-formula> is pre-determined for each size category. First, we remove small holes and small foreground features by applying up to two binary morphological closings followed by up to two binary morphological openings. Second, we estimate full masks <inline-formula><mml:math id="inf64"><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>full</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> from each putative mask by applying <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>N</mml:mi><mml:mi>erosion</mml:mi></mml:msub></mml:math></inline-formula> binary dilations (light shading in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4c</xref>) undoing the level of erosion on which the CNN was trained. We optimise both the numbers of closing, <inline-formula><mml:math id="inf66"><mml:msub><mml:mi>N</mml:mi><mml:mi>closing</mml:mi></mml:msub></mml:math></inline-formula>, and opening, <inline-formula><mml:math id="inf67"><mml:msub><mml:mi>N</mml:mi><mml:mi>opening</mml:mi></mml:msub></mml:math></inline-formula>, operations.</p><p>Any masks whose area falls outside the limits for a size category, we discard. For each category, however, we soften the limits, on top of the fuzzy thresholds, by optimising an expansion factor <inline-formula><mml:math id="inf68"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>exp</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which extends the limits by a fractional amount of that category’s size range. We also optimise a single hard lower threshold <inline-formula><mml:math id="inf69"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>20</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on mask area.</p></sec><sec sec-type="appendix" id="s8-12"><title>Using splines to describe mask edges</title><p>To prepare for refining edges and to further smooth and constrain outlines, we use a radial spline to match the edge of each of the remaining masks (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4d</xref>). As in DISCO (<xref ref-type="bibr" rid="bib4">Bakker et al., 2018</xref>), we define radial splines as periodic cubic B splines using polar coordinates whose origin is at the mask’s centroid. We generalise this representation to have a variable number <inline-formula><mml:math id="inf70"><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> of knots per mask specified by <inline-formula><mml:math id="inf71"><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>-dimensional vectors of radii <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and angles <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>θ</mml:mi><mml:mo stretchy="false">↦</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>A mask’s outline is then fully specified by those pixels that intersect with this spline.</p><p>To initially place the knots, we search along rays originating at the centroid of each mask <inline-formula><mml:math id="inf74"><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>full</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and find where these rays intersect with the mask edge. We determine the edge by applying a minimum filter with two-connectivity to the mask and set to true all pixels in the filtered image that are different from the original one. We then smooth the resulting edge image using a Gaussian filter with <inline-formula><mml:math id="inf75"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>. For a given polar angle <inline-formula><mml:math id="inf76"><mml:mi>θ</mml:mi></mml:math></inline-formula>, we find the radius of the corresponding knot by averaging the edge pixels that intersect with the ray, weighted by their values. We use the major axis of the ellipse with the same normalised second central moment as the mask (regionprops function from Scikit-image <xref ref-type="bibr" rid="bib78">van der Walt et al., 2014</xref>) to determine both the number of rays, and so knots, and their orientations. The length <inline-formula><mml:math id="inf77"><mml:msup><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> of the major axis gives the number of rays: four for <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msup><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; six for <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>5</mml:mn><mml:mo>≤</mml:mo><mml:msup><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; and eight for <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>≥</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. For this initial placement, we choose equiangular <inline-formula><mml:math id="inf81"><mml:msup><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, with the first knot on the ellipse’s major axis.</p></sec><sec sec-type="appendix" id="s8-13"><title>Discarding poor or duplicated outlines</title><p>The quality of the outline masks <inline-formula><mml:math id="inf82"><mml:msubsup><mml:mover accent="true"><mml:mi>o</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> derived from these initial radial splines are then assessed against the edge probabilities generated by the CNN (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4e</xref>) and masks of poor quality discarded. We calculate the edge score for a given outline as<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>o</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We discard those outlines for which the edge score is less than a threshold, where the thresholds <inline-formula><mml:math id="inf83"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>edge</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are optimised for each size category based on the range of edge scores observed.</p><p>With a smoothed and filtered set of outlines, we proceed by detecting and eliminating any outlines duplicated between size categories. We start by filling the outlines to form a set of full masks <inline-formula><mml:math id="inf84"><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>. We then compare these masks between neighbouring size categories <inline-formula><mml:math id="inf85"><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf86"><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>. We consider the pair of masks <italic>i</italic><sub>1</sub> and <italic>i</italic><sub>2</sub> as duplicates if one of the masks is almost wholly contained within the other:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∩</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>for some threshold <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, optimised on validation data. For pairs that exceed this threshold, we keep only the mask with the highest edge score given by <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>.</p><p>For each size category, the first part of the post-processing pipeline finishes with the set of outlines that pass these size, edge probability, and containment thresholds. <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref> gives values for the optimised post-processing parameters.</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Optimised post-processing parameters for BABY’s standard model.</title><p>The standard model takes five bright-field Z sections with a pixel size of 0.182m as input. Excepting <inline-formula><mml:math id="inf88"><mml:msub><mml:mi>T</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf89"><mml:msub><mml:mi>T</mml:mi><mml:mi>containment</mml:mi></mml:msub></mml:math></inline-formula>, we optimised parameters separately for each size category.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mi>small</mml:mi></mml:mrow></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf91"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mi>medium</mml:mi></mml:mrow></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf92"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mi>large</mml:mi></mml:mrow></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="left" valign="top"><inline-formula><mml:math id="inf93"><mml:msub><mml:mi>T</mml:mi><mml:mi>interior</mml:mi></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0.35</td><td align="char" char="." valign="bottom">0.5</td><td align="char" char="." valign="bottom">0.95</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="inf94"><mml:msub><mml:mi>N</mml:mi><mml:mi>dilate</mml:mi></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="top">Connectivity</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="inf95"><mml:msub><mml:mi>N</mml:mi><mml:mi>closing</mml:mi></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="inf96"><mml:msub><mml:mi>N</mml:mi><mml:mi>opening</mml:mi></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">2</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="inf97"><mml:msub><mml:mi>F</mml:mi><mml:mi>exp</mml:mi></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0.32</td><td align="char" char="." valign="bottom">0.06</td><td align="char" char="." valign="bottom">0.28</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="inf98"><mml:msub><mml:mi>T</mml:mi><mml:mi>edge</mml:mi></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0.0012</td><td align="char" char="." valign="bottom">0.0028</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="inf99"><mml:msub><mml:mi>T</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">19</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="inf100"><mml:msub><mml:mi>T</mml:mi><mml:mi>containment</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">0.85</td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap></sec><sec sec-type="appendix" id="s8-14"><title>Refining edges</title><p>The outlines <inline-formula><mml:math id="inf101"><mml:msubsup><mml:mover accent="true"><mml:mi>o</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, defined by the radial splines, do not directly make use of the CNN’s edge targets for their shape and deviate from <inline-formula><mml:math id="inf102"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>edge</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, particularly for those in the large size category (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4e</xref>).</p><p>We therefore optimise the radial splines to better match the predicted edge. This optimisation is challenging because <inline-formula><mml:math id="inf103"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>edge</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> provide only a semantic representation of the edge – the association of a given pixel <inline-formula><mml:math id="inf104"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with a particular instance <inline-formula><mml:math id="inf105"><mml:mi>i</mml:mi></mml:math></inline-formula> is unknown. Our approach is to use the outlines to generate priors on whether predicted edge pixels associate with a given instance. We then apply standard techniques to optimise the fit of the radii and angles of the knots for each outline’s spline to its instance’s likely edge pixels.</p><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Optimisation of the radial spline to fit the predicted edge.</title><p>(<bold>a</bold>) We show the rdge pixels predicted by the CNN in polar coordinates for two different instances in the top and bottom panels. Darker shading indicates a higher probability of being an edge. Open green circles are the manually curated ground truth. Solid lines are the initial radial splines estimated from the interiors predicted by the CNN. Insets show the predicted edge in cartesian coordinates with the instance providing the origin marked by its initial outline and the indicated polar coordinates. (<bold>b</bold>) We plot the binned residuals of the predicted edge pixels with the initial radial spline for the examples ofa. The algorithm considers only edge pixels with probability greater than 0.2. Binned residuals for the ground truth are in green. Black lines show the function used to re-weight pixel probabilities for each instance. (<bold>c</bold>) As for a, but after the edge pixels have been re-weighted for each instance. Solid lines indicate the optimised radial spline. We show the outline favoured by the instance-association probability as a solid line in the inset; disfavoured outlines are dashed.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app1-fig5-v2.tif"/></fig><p>To associate pixels with instances, we first calculate the radial distance of each pixel from the initial radial spline function <inline-formula><mml:math id="inf106"><mml:mi>s</mml:mi></mml:math></inline-formula> proposed for an instance in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>. To increase speed, we consider only pixels where <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Expressing the edge pixels in polar coordinates as <inline-formula><mml:math id="inf108"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with the origin at the instance’s centroid, this distance is<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>which we will refer to as a pixel’s residual. We give two examples of edge pixels (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5a</xref>) and of the corresponding residuals (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5b</xref>), which highlight the need to associate pixels with a given instance before attempting to optimise the spline.</p><p>We use the residuals, <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, to assign prior weights to pixels:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mi>W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mtext>if </mml:mtext><mml:mi>R</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mtext>if </mml:mtext><mml:mi>R</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf109"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf110"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. The function <inline-formula><mml:math id="inf111"><mml:mi>W</mml:mi></mml:math></inline-formula> is a Gaussian function of the residual for pixels exterior to the proposed outline and an exponential function for pixels interior (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5b</xref>). This asymmetry should increase tolerance for interior edge pixels, which may belong to neighbouring instances overlapping with the cell of interest. In such cases, we should thus improve instance association, particularly where the edges of each of the cells intersect.</p><p>With these prior weights, we find the probability that each edge pixel associates with a particular instance and not with the others via:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>×</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mi>W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf112"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of detected instances in this and adjacent size categories, with <inline-formula><mml:math id="inf113"><mml:mi>j</mml:mi></mml:math></inline-formula> running over all these instances. We filter the result, keeping only those edge pixels with <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Examples are shown in <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5c</xref>.</p><p>We optimise the knot radii <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and angles <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for each radial spline by minimising the squared radial residual between the spline and the edge pixels, <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>. With residuals weighted by <inline-formula><mml:math id="inf117"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>edge</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>, and initial values taken from each <inline-formula><mml:math id="inf118"><mml:msubsup><mml:mover accent="true"><mml:mi>o</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, we constrain radii to a 30% change from their initial values and angles to a change of ±25% of the initial angular separation between knots: <inline-formula><mml:math id="inf119"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The resulting optimised radial splines provide the outlines output by the BABY algorithm.</p></sec></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>The BABY algorithm: tracking cells and identifying lineages</title><p>To track cells and lineages, we have two tasks: first, link cell outlines from one time point to the next (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1a</xref>), and second, identify mother-bud relationships (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1b</xref>).</p><fig id="app2fig1" position="float"><label>Appendix 2—figure 1.</label><caption><title>Determining accurate lineages requires solving two independent tasks.</title><p>(<bold>a</bold>) We must identify cells across time points regardless of how they grow and move within the images. (<bold>b</bold>) We have to find the mother-bud relationship between cells at every time point.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app2-fig1-v2.tif"/></fig><sec sec-type="appendix" id="s9-1"><title>Tracking cells from image to image</title><p>In our setup, daughter cells may be washed out of the microfluidic device and so disappear from one time point to the next. These absences undermine other approaches to tracking, such as the Hungarian algorithm (<xref ref-type="bibr" rid="bib80">Versari et al., 2017</xref>).</p><p>To track cells (<xref ref-type="fig" rid="app2fig2">Appendix 2—figure 2</xref>), we use the changes in their masks over time to indicate identity. From each mask, we extract an array of attributes, such as the mask’s area, major axis length, etc., and to compare a mask at one time point to a mask at another time point, we subtract the two corresponding arrays of features. This array of differences is the array of features we use for classification.</p><fig id="app2fig2" position="float"><label>Appendix 2—figure 2.</label><caption><title>Overview of the algorithm for tracking cells.</title><p>(<bold>a</bold>) We obtain the attributes of all cells at times <inline-formula><mml:math id="inf120"><mml:mi>t</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. This results in two matrices of shape <inline-formula><mml:math id="inf122"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf123"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic>m</italic><sub><italic>x</italic></sub> is the number of cells at time <inline-formula><mml:math id="inf124"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf125"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of attributes. (<bold>b</bold>) We generate a feature vector for every cell pair by subtracting, element-wise, the attributes of all cells at time <inline-formula><mml:math id="inf126"><mml:mi>t</mml:mi></mml:math></inline-formula> from the attributes of all cells at time <inline-formula><mml:math id="inf127"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>c</bold>) We apply a classifier to the feature vector corresponding to each pair of cells. (<bold>d</bold>) We repeat the same process but using <inline-formula><mml:math id="inf128"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf129"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> instead of <inline-formula><mml:math id="inf130"><mml:mi>t</mml:mi></mml:math></inline-formula>. (<bold>e</bold>) We pick the maximal probability for every pair of cells over all the probability matrices. (<bold>f</bold>) We apply our cell-labelling algorithm to assign cell pairs (<bold>g</bold>) Finally, we use a threshold to identify new cells.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app2-fig2-v2.tif"/></fig><p>Our training data comprises a series of manually labelled time-lapse images from four experiments. For two consecutive time points, we calculated the difference in feature arrays between all pairs of cells and grouped these difference arrays into two classes: one for identical cells – cells with the same label – and one for all other cells.</p></sec><sec sec-type="appendix" id="s9-2"><title>Using multiple time points in the past:</title><p>To generate additional training data, we use multiple time points backwards in time. For example, for time <inline-formula><mml:math id="inf131"><mml:mi>t</mml:mi></mml:math></inline-formula>, we generate not only feature vectors by comparing with cells at <inline-formula><mml:math id="inf132"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, but also with cells at <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>. We found this additional data increased generalisability, maintaining accuracy across a wider range of imaging intervals and growth rates. For the purpose of training, we treat the additional data as consecutive time points: the algorithm does not know whether the features come from one or more than one time point in the past.</p><p>As part of testing if all features contribute to the learning, we divided the features into two overlapping sets. One set had no features that explicitly depend on distance, comprising area, lengths of the minor and major axes, convex area, and area of the bounding box; the second set did include distance-dependent features, comprising area, lengths of the minor and major axes, and convex area again, but additionally including the mask’s centroid, and the distance obtained from the x- and y-axis locations.</p><p>We compared three standard algorithms for classification (<xref ref-type="bibr" rid="bib8">Bishop, 2006</xref>): the Support Vector Classifier (SVC), Random Forest, and Gradient Boosting, specifically Xtreme Gradient Boosting (<xref ref-type="bibr" rid="bib12">Chen and Guestrin, 2016</xref>). We used scikit-learn (<xref ref-type="bibr" rid="bib61">Pedregosa, 2011</xref>) to optimise over a grid of hyperparameters.</p><p>For the SVC, we considered a regularisation parameter <inline-formula><mml:math id="inf135"><mml:mi>C</mml:mi></mml:math></inline-formula> of 0,1, 10, or 100; a <inline-formula><mml:math id="inf136"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula> kernel coefficient of 1, 10−3, or 10−4; no shrinking heuristic to speed up training; and either a radial basis function or sigmoid kernel.</p><p>For the Random Forest, we explored a range between 10 and 80 estimators and a depth between 2 and 10 levels.</p><p>For Gradient Boosting, we used a maximal depth of either 2, 4, or 8 levels; a minimal child weight of 1, 5, or 10; gamma, the minimal reduction in loss to partition a leaf node, of 0.5, 1, 1.5, 2, or 5; and a sub-sampling ratio of 0.6, 0.8, or 1.</p><p>Within the training data, the number of time points for each experiment is different. To prevent biases toward long experiments, we define the accuracy as the fraction of true positives – cells correctly linked between images – and compare the precision and recall of this time-averaged accuracy.</p><p>After training, we evaluated which features were important using the Random Forest. The distribution of the feature weights depends on whether we include distance (<xref ref-type="fig" rid="app2fig3">Appendix 2—figure 3</xref>), and excluding distance distributes the weights more evenly.</p><fig id="app2fig3" position="float"><label>Appendix 2—figure 3.</label><caption><title>The importance of the features used by the Random Forest classifier for tracking cells between time points.</title><p>Depending on the features we use, the feature weights, a measure of their importance, are more evenly spread. (<bold>a</bold>) If we train the classifier using features that explicitly include distance-dependence, distance drives the decisions, and the remaining features are only used for marginal cases. (<bold>b</bold>) If we train the classifier using distance-implicit features, however, the weights are more uniform. (<bold>c</bold>) The precision-recall curve shows high accuracy for both sets of features.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app2-fig3-v2.tif"/></fig></sec><sec sec-type="appendix" id="s9-3"><title>An ensemble model</title><p>The precision-recall curve indicates that using the distance-explicit features is best, although both sets of features have high accuracy (<xref ref-type="fig" rid="app2fig3">Appendix 2—figure 3c</xref>). Despite performing better on our test data, we expect that using the distance-explicit features may perform worse if the cells pivot or become displaced. Therefore, we use the non-explicit features as our main model, but also use the distance-explicit features to resolve any ambiguous predictions. The ensemble model performs similarly to the distance-implicit classifier, but for more stringent thresholds behaves like the distance-explicit one.</p></sec><sec sec-type="appendix" id="s9-4"><title>Making predictions</title><p>To predict with the classifier, we use data from the current time point and the two most recent previous time points. We generate feature arrays between <inline-formula><mml:math id="inf137"><mml:mi>t</mml:mi></mml:math></inline-formula> and independently <inline-formula><mml:math id="inf138"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf139"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> and feed both arrays to the classifier. If the probability returned is greater than 0.9, we accept the result; if the probability lies between 0.1 and 0.9, we use instead the probability returned by the backup classifier, which uses the distance-explicit features.</p><p>Using multiple time points to track cells has two advantages: first, it reduces noise generated by artefacts, either in image acquisition, such as a loss of focus, or in segmentation; second, it ensures that cells are more consistently identified if their position or shape transiently changes. Including data further back in time is neither computationally efficient nor more accurate, and greater than three time points is long, over 15 minutes in our experiments and about a sixth of a cell cycle.</p><p>We apply the linear sum assignment algorithm, via SciPy, on the probability matrix of predictions to assign labels (Appendix 2 Algorithm 1). This approach guarantees at most one outline is assigned to each cell by choosing the set of probabilities whose total sum is highest. To match a cell with its previous self, we pick the cell in the recent past that generates the highest probability when paired with the cell of interest, providing this probability is greater than 0.5. We label a cell as new if the probabilities returned from pairing with all cells in the recent past is below 0.5.</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups" id="AL1"><thead><tr><th align="left" valign="bottom">Algorithm 1 Cell labelling</th></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>Data:</bold> <italic>probMat</italic>, <italic>threshold</italic>, <italic>oldLabels</italic>, <italic>maxLabel</italic><break/><bold>Result:</bold> New cell labels (<italic>newLabels</italic>)<break/>let <italic>newLabels</italic> be zeros(ncols(<italic>probMat</italic>));<break/><bold>for</bold> <italic>old</italic>, <italic>new</italic> ∈ <italic>linearSumAssignment</italic>(−<italic>ProbMat</italic>) <bold>do</bold><break/> <bold>if</bold> <italic>probMat</italic>[<italic>old</italic>, <italic>new</italic>] &gt; <italic>threshold</italic> <bold>then</bold><break/>  <italic>newLabels</italic>[<italic>new</italic>] ← <italic>oldLabels</italic>[<italic>old</italic>];<break/> <bold>end</bold><break/><bold>end</bold><break/><bold>for</bold> <italic>label</italic> ∈ <italic>newLabels</italic> <bold>do</bold><break/> <bold>if</bold> <italic>label</italic>! = 0 <bold>then</bold><break/>  <italic>label</italic> = <italic>maxLabel</italic> + 1;<break/>  <italic>maxLabel</italic> = label;<break/> <bold>end</bold><break/><bold>end</bold><break/>return <italic>newLabels</italic></td></tr></tbody></table></table-wrap></sec><sec sec-type="appendix" id="s9-5"><title>Assigning lineages</title><p>We wish to identify which cells are buds of mothers and which mothers have buds. This problem is analogous to tracking, but, rather than identifying pairs of cells that are the same cell at different time points, we must identify pairs of cells that are a mother-bud pair at one time point. We therefore seek to determine the probability that a pair of cells is a mother-bud pair (<xref ref-type="fig" rid="app2fig4">Appendix 2—figure 4</xref>). Unlike tracking, however, we anticipated that the cell outlines alone would be at best a weak indicator of this probability.</p></sec><sec sec-type="appendix" id="s9-6"><title>Defining mother-bud features</title><p>We observed that cytokinesis is sometimes visible in bright-field images as a darkening of the bud neck and designed features to exploit this characteristic of mother-bud pairs.</p><p>Such features often rely on the CNN’s prediction of bud necks. For generalisability and to avoid ambiguity, we chose to define the corresponding training target using manually annotated outlines and lineage relationships, rather than relying on a fluorescent bud-neck marker. Specifically, we define a binary semantic ‘bud-neck’ training target that is true only at pixels where a mother mask, dilated twice by morphological dilation, intersects with its assigned bud (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). Assigning a time of cytokinesis by eye is challenging, and so we included two constraints to identify a bud. First, the bud must be current – as soon as BABY finds another bud associated to the mother, we drop the current one. Second, we exclude buds if their area is larger than and has always been larger than 10 μm<sup>2</sup> (300 pixels for our standard training target with a pixel size of 0.182 μm and corresponding to a sphere of ∼ 24 μm<sup>3</sup>).</p><fig id="app2fig4" position="float"><label>Appendix 2—figure 4.</label><caption><title>Overview of the algorithm for assigning lineages.</title><p>(<bold>a, b</bold>) We start from the cell outlines and the CNN’s predicted probabilities of a pixel being a bud neck for small cells. Different colour intensities show the probabilities with white denoting zero probability. (<bold>c</bold>) Composite features used by the classifier to solve the task. (<bold>d</bold>) The probability of small cells being a bud. (<bold>e</bold>) An intermediate element of assigning lineages is defining <inline-formula><mml:math id="inf140"><mml:msub><mml:mi>M</mml:mi><mml:mi>joining</mml:mi></mml:msub></mml:math></inline-formula> – the red line, actually a rectangular box. (<bold>f</bold>) Feeding the features into a trained random forest model returns the probability of a pair of cells being a mother and bud.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app2-fig4-v2.tif"/></fig><p>We used multiple image features to characterise a mother-bud relationship. For an ordered pairing of all cells in an image, we consider a putative mother-bud pair and define a mask, <inline-formula><mml:math id="inf141"><mml:msub><mml:mi>M</mml:mi><mml:mi>joining</mml:mi></mml:msub></mml:math></inline-formula>, as the joining rectangle between the centres of the mother and bud with a width equal to one quarter the length of the bud’s minor axis. Given <inline-formula><mml:math id="inf142"><mml:msub><mml:mi>M</mml:mi><mml:mi>joining</mml:mi></mml:msub></mml:math></inline-formula>, we consider five features:</p><list list-type="roman-lower"><list-item><p><inline-formula><mml:math id="inf143"><mml:msub><mml:mi>F</mml:mi><mml:mi>size</mml:mi></mml:msub></mml:math></inline-formula>, which is the ratio of the mother’s to bud’s area. Mothers generally have a greater size than their bud so that <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></list-item><list-item><p><inline-formula><mml:math id="inf145"><mml:msub><mml:mi>F</mml:mi><mml:mi>adjacency</mml:mi></mml:msub></mml:math></inline-formula>, which is the fraction of <inline-formula><mml:math id="inf146"><mml:msub><mml:mi>M</mml:mi><mml:mi>joining</mml:mi></mml:msub></mml:math></inline-formula> intersecting with the union of the mother’s and bud’s masks. Mothers should be proximal to their buds so that <inline-formula><mml:math id="inf147"><mml:msub><mml:mi>F</mml:mi><mml:mi>adjacency</mml:mi></mml:msub></mml:math></inline-formula> is close to one: only a small fraction of <inline-formula><mml:math id="inf148"><mml:msub><mml:mi>M</mml:mi><mml:mi>joining</mml:mi></mml:msub></mml:math></inline-formula> should lie outside of the mother and bud outlines.</p></list-item><list-item><p><inline-formula><mml:math id="inf149"><mml:msub><mml:mi>F</mml:mi><mml:mi>bud</mml:mi></mml:msub></mml:math></inline-formula>, which is the mean over the union of the CNN’s output for a small, interior targets and all pixels contained in the bud. <inline-formula><mml:math id="inf150"><mml:msub><mml:mi>F</mml:mi><mml:mi>bud</mml:mi></mml:msub></mml:math></inline-formula> approximates the probability that a cell is a bud and should be close to one for mother-bud pairs.</p></list-item><list-item><p><inline-formula><mml:math id="inf151"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub></mml:math></inline-formula>, which is the mean over the union of the pixels contained in <inline-formula><mml:math id="inf152"><mml:msub><mml:mi>M</mml:mi><mml:mi>joining</mml:mi></mml:msub></mml:math></inline-formula> with the CNN’s output for bud-necks, only including those pixels whose probability is greater than 0.2. <inline-formula><mml:math id="inf153"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub></mml:math></inline-formula> approximates the probability that a bud neck joins a mother and bud.</p></list-item><list-item><p><inline-formula><mml:math id="inf154"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:msub></mml:math></inline-formula>, which is the number of the CNN’s bud-neck target pixels with a probability greater than 0.2 that are in <inline-formula><mml:math id="inf155"><mml:msub><mml:mi>M</mml:mi><mml:mi>joining</mml:mi></mml:msub></mml:math></inline-formula> normalised by the square root of the bud’s area, or effectively the bud’s perimeter. We interpret <inline-formula><mml:math id="inf156"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:msub></mml:math></inline-formula> as a confidence score on <inline-formula><mml:math id="inf157"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub></mml:math></inline-formula> because a single spurious pixel with high bud-neck probability could produce high <inline-formula><mml:math id="inf158"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub></mml:math></inline-formula>.</p></list-item></list></sec><sec sec-type="appendix" id="s9-7"><title>Training a classifier</title><p>With these features, we train a random forest classifier to predict the probability that a pair of cells is a mother and bud. We train on all pairs of cells in the validation data. We optimised the hyperparameters, including the number of estimators and tree depth, using a grid search with five-fold cross-validation. We optimise for precision because true mother-bud pairs are in the minority and because our strategy for assigning lineages aggregates over multiple time points (as detailed below).</p><p>For our standard 5Z CNN trained to a pixel size of 0.182, the random forest classifier had a precision of 0.83 and recall of 0.54 on the test data. This precision and recall of the classifier to assign mother-bud pairs within a single time point is distinct from the precision and recall of mother-bud pairs after accumulating across time (reported in <xref ref-type="fig" rid="fig3">Figure 3d</xref>). This data has 211 true mother-bud pairs out of 1678 total pairs. The classifier assigned feature weights of 0.46 for <inline-formula><mml:math id="inf159"><mml:msub><mml:mi>F</mml:mi><mml:mi>size</mml:mi></mml:msub></mml:math></inline-formula>, 0.11 for <inline-formula><mml:math id="inf160"><mml:msub><mml:mi>F</mml:mi><mml:mi>adjacency</mml:mi></mml:msub></mml:math></inline-formula>, 0.24 for <inline-formula><mml:math id="inf161"><mml:msub><mml:mi>F</mml:mi><mml:mi>bud</mml:mi></mml:msub></mml:math></inline-formula>, 0.06 for <inline-formula><mml:math id="inf162"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub></mml:math></inline-formula>, and 0.13 for <inline-formula><mml:math id="inf163"><mml:msub><mml:mi>F</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:msub></mml:math></inline-formula>.</p></sec><sec sec-type="appendix" id="s9-8"><title>Assigning each cell a unique mother</title><p>To establish lineages, we need to assign at most one tracked mother cell to each tracked cell object. We use the classifier to assign a mother-bud probability <inline-formula><mml:math id="inf164"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> for each time point at which a pair of tracked objects are together. We then estimate the probability that a tracked object <inline-formula><mml:math id="inf165"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> has ever been a mother using<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>as well as the probability that it has ever been a bud with<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Finally, we calculate a cumulative score for a putative mother-bud pair and reduce this score if the candidate bud has previously shown a high probability of being a mother:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>At each time point, we then propose lineages by assigning each putative cell object <inline-formula><mml:math id="inf166"><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>b</mml:mi></mml:msub></mml:math></inline-formula> with a bud probability <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and a mother <inline-formula><mml:math id="inf168"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>argmax</mml:mi><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>b</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. We treat the mother-bud assignments proposed at the final time point as definitive because they have integrated information over the entire time series. To avoid spurious assignments, we require all buds to be present for at least three time points.</p></sec><sec sec-type="appendix" id="s9-9"><title>Post-processing</title><p>Though rare, we do have to mitigate occasional detection, tracking and assignment errors. For example, debris can occasionally be mistakenly identified as a cell and tracked.</p><p>We discard tracks that have both small volumes and show limited growth over the experiment. Specifically, we discard a given cell track <inline-formula><mml:math id="inf169"><mml:mi>i</mml:mi></mml:math></inline-formula> with duration <inline-formula><mml:math id="inf170"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, minimal volume <inline-formula><mml:math id="inf171"><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>min</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> at time <inline-formula><mml:math id="inf172"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>min</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, and maximal volume <inline-formula><mml:math id="inf173"><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>max</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> at time <inline-formula><mml:math id="inf174"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>max</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, if both <inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> μm<sup>3</sup> and the estimated average growth rate <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> μm<sup>3</sup>/hour, where<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Our tracking algorithm usually identifies correctly instances where a mother and bud pivot with the flow of the medium, but exceptions do arise. For a given mother, we therefore join contiguous bud tracks – pairs of bud tracks where one ends with the other starting on the next time point – if the extrapolated volume of the old track falls within a threshold difference of the volume of the new track. Specifically, for the pair of contiguous tracks <inline-formula><mml:math id="inf177"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf178"><mml:mi>j</mml:mi></mml:math></inline-formula>, with track <inline-formula><mml:math id="inf179"><mml:mi>i</mml:mi></mml:math></inline-formula> ending at time point <inline-formula><mml:math id="inf180"><mml:mi>t</mml:mi></mml:math></inline-formula> and track <inline-formula><mml:math id="inf181"><mml:mi>j</mml:mi></mml:math></inline-formula> beginning at time point <inline-formula><mml:math id="inf182"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, we calculate<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf183"><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the volume of track <inline-formula><mml:math id="inf184"><mml:mi>i</mml:mi></mml:math></inline-formula> at time point <inline-formula><mml:math id="inf185"><mml:mi>t</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf186"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula> is the time step between time points <inline-formula><mml:math id="inf187"><mml:mi>t</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf188"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. We join these tracks if <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> μm<sup>3</sup>.</p><p>Finally, we discard any tracks with fewer than five time points.</p></sec></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>The BABY algorithm: estimating volumes and growth rates</title><sec sec-type="appendix" id="s10-1"><title>Calculating cell volumes</title><p>To estimate cell volumes, we model a 3D cell from our 2D outline. We use a conical method (<xref ref-type="bibr" rid="bib32">Gordon et al., 2007</xref>), which is robust to common cell shapes, to estimate cell volume from an outline. This method makes two assumptions: that the outline obtained cuts through the widest part of the cell and that the cell is ellipsoidal. We build a cone with a base shape that is the filled outline of the cell by iteratively eroding the segmented mask of the cell and stacking these masks in the <inline-formula><mml:math id="inf190"><mml:mi>Z</mml:mi></mml:math></inline-formula> dimension. We find the volume of the cone by summing the voxels in the corresponding 3D mask. Finally, we multiply this sum by four to obtain the volume of the cell: a cone whose base is the equatorial plane of an ellipsoid will have a volume that is a quarter of the corresponding ellipsoid’s volume (<xref ref-type="bibr" rid="bib32">Gordon et al., 2007</xref>).</p></sec><sec sec-type="appendix" id="s10-2"><title>Estimating single-cell growth rates</title><p>Depending on the need for computational speed, we use one of two methods for estimating instantaneous growth rates.</p><p>For long-term, and stored, analysis, we estimate growth rates by fitting a Gaussian process with a Matern covariance function to the time series of each cell’s volume (<xref ref-type="bibr" rid="bib73">Swain et al., 2016</xref>). We set the bounds on the hyperparameters to prevent over-fitting. Maximising the likelihood of the hyperparameters, we are able to obtain the mean and first and second time derivatives of the volume, as well as estimates of their errors. The volume’s first derivative is the single-cell growth rate.</p><p>During real-time processing where we may wish to use to the growth rate to control the microscope, fitting a Gaussian process is too slow. Instead we estimate growth rates from the smoothed first derivative obtained by Savitzky-Golay filtering of each cell’s volume time series. Though faster, this method is less reliable and does not estimate errors. For time series of mothers, we use a third-order polynomial with a smoothing window of seven time points; for time series of buds, we use a fourth-order polynomial also with a smoothing window of seven time points.</p><p>We estimate growth rates separately for mothers and their buds because both are informative. We find that the summed results are qualitatively similar to previous estimates of growth rate, which fit the time series of the combined volume of the mother and its bud (<xref ref-type="bibr" rid="bib27">Ferrezuelo et al., 2012</xref>; <xref ref-type="bibr" rid="bib15">Cookson et al., 2010</xref>).</p></sec></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>A graphical user interface for curating</title><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>Main features of the graphical user interface used for annotation.</title><p>We developed a custom graphical user interface (GUI) in Matlab to annotate efficiently overlapping cell instances, tracks and lineages over long time courses. The screen-shot shows the GUI in its horizontal layout with three bright-field sections and a fluorescence channel selected for parallel view. Annotated outlines and arrows indicating lineage relationships have each been toggled on for display. The GUI can display up to 9 time points in parallel; the slider at the bottom allows fast scrolling through the entire time-lapse. A time-course summary panel is displayed above the slider and has been set to show the outline areas for a mother and all its buds. An overview image of the entire position allows navigation between traps. The user can select from multiple editing modes for manipulating annotations in the parallel view region, including modes for draggable outline editing, track merging and splitting, and lineage reassignments.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app4-fig1-v2.tif"/></fig><p>To ease annotating overlapping instances, cell tracks and lineage relationships, we developed a Graphical User Interface (GUI) in Matlab that allows parallel viewing of multiple Z sections and time points (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>). This parallel view helps curate buds obscured by a lack of focus and those that might be missed without simultaneously observing multiple time points. The GUI mirrors manipulations made to outlines and tracks to all views in real time. The interface is highly customisable, with multiple layouts available and the ability to select which sections and channels to display. To edit outlines for smaller cells, the user can adjust the level of zoom. Further, starting outlines can be copied across time points and interpolated forwards or backwards in time (interpolated outlines are annotated as such until they are manually adjusted).</p><p>The GUI saves annotations in a custom format for computational efficiency, but various export options are available. For training we exported annotations in PNG format with one image per time point. Because outlines can potentially overlap, they are tiled, with one cell instance per tile. We store track and lineage annotations in the metadata of the PNG file.</p><p>Furthermore, the GUI includes features to efficiently detect and correct rare errors. A track display panel provides visual aids to summarise tracks across the entire time course. In particular, the ‘Display mother and daughter areas’ mode uses this panel to plot the area of the currently selected cell and all of its daughters over the time course. Using this mode, many segmentation and tracking errors are highlighted as unexpected jumps in area or changes in track label (denoted in colour). We use a slider to navigate to these errors where they can be either corrected in place or saved for future curation.</p><p>Although the GUI works with whole images, it includes features to navigate and annotate images that naturally partition into regions, such as the traps of our ALCATRAS devices. Then the trap navigation image shows trap locations and enables moving between traps.</p></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s12"><title>Quantifying localisation</title><p>During each experiment, we acquired bright-field and fluorescence images at five Z sections spaced 0.6 μm apart and used the maximum projection of these images (the maximum pixel values across all Z sections) for quantification.</p><p>For each cell, we determined its fluorescence image by subtracting the median fluorescence of the cell’s pixels and setting all non-cell pixels to zero. A cytoplasmic pixel will determine this median fluorescence, and we assume that it results from autofluorescence only, which requires sufficiently low numbers of fluorescent markers.</p><p>To quantify fluorescent markers in the nucleus, we noted that fluorescence there appears in an image as a two-dimensional Gaussian distribution because of point spreading in epifluorescence microscopes. We therefore identified the most probable location of the nucleus for each cell by convolving a Gaussian filter with the fluorescence image. The maximal value in the resulting filtered image marks the location that most closely matches this filter.</p><p>Using data from nuclei segmented via Nhp6A-mCherry reporters (<xref ref-type="bibr" rid="bib34">Granados et al., 2018</xref>), we observed that the area of the nucleus <inline-formula><mml:math id="inf191"><mml:msub><mml:mi>A</mml:mi><mml:mi>nuc</mml:mi></mml:msub></mml:math></inline-formula> scales as a fraction of cell area <inline-formula><mml:math id="inf192"><mml:msub><mml:mi>A</mml:mi><mml:mi>cell</mml:mi></mml:msub></mml:math></inline-formula> with a scaling factor <inline-formula><mml:math id="inf193"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>nuc</mml:mi></mml:msub><mml:mo>≃</mml:mo><mml:mn>0.085</mml:mn></mml:mrow></mml:math></inline-formula>. We used this result to estimate a standard deviation σ for the Gaussian filter. If the nucleus is approximately circular then we estimate its radius as<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mi>π</mml:mi></mml:mfrac></mml:msqrt><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Assuming that the segmented area of nucleus contains 95% of the nuclear fluorescence, we choose the σ of the Gaussian filter so that 95% of its probability is obtained by integrating over a circle of radius <italic>r</italic><sub><italic>nuc</italic></sub>. Writing <inline-formula><mml:math id="inf194"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula>, we have<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mrow><mml:mtext>nuc</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width=".5em"/><mml:mspace width="thickmathspace"/><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>r</mml:mi><mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width=".5em"/><mml:mspace width="thickmathspace"/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>switching to polar coordinates. Using that the cumulative distribution function of the <inline-formula><mml:math id="inf195"><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> distribution with two degrees of freedom is <inline-formula><mml:math id="inf196"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, we can rearrange <xref ref-type="disp-formula" rid="equ16">Equation 16</xref> and combine with <xref ref-type="disp-formula" rid="equ15">Equation 15</xref> to give<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>nuc</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>cell</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We next assume an ideal fluorescence image of the nucleus can be described by the same Gaussian filter but re-scaled by some amplitude <italic>a</italic><sub><italic>f</italic></sub>. If we apply the Gaussian convolution <inline-formula><mml:math id="inf197"><mml:mi>G</mml:mi></mml:math></inline-formula> to the pixel in this ideal image with maximal fluorescence, we obtain<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo symmetric="true">‖</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf198"><mml:mrow><mml:mo>∥</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>∥</mml:mo></mml:mrow></mml:math></inline-formula> is the sum of the squared values of the Gaussian filter. This quantity should in principle be equal to <inline-formula><mml:math id="inf199"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf200"><mml:mi>C</mml:mi></mml:math></inline-formula> is the Gaussian filtered fluorescence image of the actual cell. Therefore<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mrow><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>∥</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Finally, <italic>a</italic><sub><italic>f</italic></sub> is our prediction of the total nuclear fluorescence, but the concentration is more biologically relevant and, if denoted <inline-formula><mml:math id="inf201"><mml:mi>N</mml:mi></mml:math></inline-formula>, is<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="1em"/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>which is the measure we use.</p><p>For quantifying the localisation of Myo1-GFP to the bud neck, we note that <inline-formula><mml:math id="inf202"><mml:mi>N</mml:mi></mml:math></inline-formula> is a sensitive proxy for localisation and assume that it applies equally well in this case.</p></sec></app><app id="appendix-6"><title>Appendix 6</title><sec sec-type="appendix" id="s13"><title>Estimating cytokinesis using fluorescent markers</title><fig id="app6fig1" position="float"><label>Appendix 6—figure 1.</label><caption><title>Markers for anaphase and cytokinesis reveal coincidence with a crossing point in mother and bud growth rates.</title><p>(<bold>a</bold>) Time series for a mother (purple) and its buds and daughters for a switch from 2% palatinose to 2% glucose and back, with volumes and growth rates estimated by BABY. We use the localisation of Myo1-GFP to the bud neck to identify times of cytokinesis (vertical black dotted lines). For comparison, we show birth times predicted by our growth rate heuristic as vertical red dashed lines. (<bold>b</bold>) As for a, but using the localisation of Nhp6A-mCherry to the nucleus to identify times of cytokinesis (vertical black dotted lines). We show both the raw (points) and smoothed (lines; Savitzky-Golay filter with third degree polynomial and smoothing window of 15 time points) localisation of Nhp6A-mCherry.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79812-app6-fig1-v2.tif"/></fig><p>We used either Myo1-GFP or Nhp6A-mCherry to estimate the time at which a bud becomes an independent daughter. Myo1, a type II myosin, localises to the bud neck and shows a drop in intensity upon cytokinesis (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1a</xref>); Nhp6A, a histone-associated protein localised to the nucleus and shows a drop in intensity during anaphase as cells transport chromosomes into their buds (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1b</xref>). Although anaphase and cytokinesis are distinct events in the cell cycle, the timing between the start of anaphase and completion of cytokinesis is similar across growth conditions (<xref ref-type="bibr" rid="bib44">Leitao and Kellogg, 2017</xref>), and we assume cytokinesis occurs 20 min after anaphase. For <xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6a–d</xref> and <xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1a</xref>, we used Myo1-GFP; for <xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6e</xref>, <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1d</xref>, and <xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1b</xref>, we used Nhp6A-mCherry.</p></sec><sec sec-type="appendix" id="s14"><title>Detecting cytokinesis from fluorescent Myo1</title><p>A drop in Myo1-GFP intensity at the mother cell’s bud neck accompanies cytokinesis (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6a</xref>), and we assume that this drop is fast compared to the time interval of imaging. We use the time series of fluorescence localisation within the mother cell over the period where the mother has a bud and estimate its time derivative using backward finite differences. To obtain candidate time points for cytokinesis, we find the dips in this derivative with a minimum prominence via Matlab’s findpeaks function. We take the actual time point marking completion of cytokinesis as the last observed candidate peak before the next bud appears.</p></sec><sec sec-type="appendix" id="s15"><title>Detecting anaphase from fluorescent Nhp6A</title><p>During anaphase, there is both a fall in fluorescence localisation of Nhp6A-mCherry in the mother and a rise in the bud (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1b</xref>). Both signals typically level to a similar value as anaphase completes. For each bud, we therefore identify the start of anaphase using the difference between the mother and bud localisation signals, from when the bud appears to either when it disappears or the next bud appears. We set the start of anaphase as the last time point for which this mother-bud difference, normalised by its maximum, is greater than 0.5. We avoid selecting spurious differences after anaphase by considering only candidates that exist five time points before we observe a normalised difference under 0.1.</p><p>We ignore buds in further analysis for four reasons: we find no candidate time point for anaphase; the candidate is the first or second time point after the bud appears; the normalised difference does not drop below 0.1 within the 20 min following the candidate time, implying cytokinesis did not occur; the drop in the normalised localisation signal in the mother is less than or equal to 0.1.</p></sec><sec sec-type="appendix" id="s16"><title>Predicting cytokinesis from growth rate</title><p>All together, we are able to determine key events of the cell cycle. First, we define a cell cycle for each mother as the duration between two budding events, obtained from the lineage assignment. These points approximately correspond to shortly after the START checkpoint (<xref ref-type="bibr" rid="bib16">Costanzo et al., 2004</xref>). Second, assuming that the buds are accurately predicted, we identify a single point of cytokinesis within the corresponding cell cycle.</p><p>We observe three phases of growth during a cell cycle (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6a–b</xref>). First, the bud dominates growth during S/G2/M, with its growth rate peaking midway through that period while simultaneously the mother’s growth rate falls. Second, the bud’s growth rate decreases as cytokinesis approaches. Near cytokinesis, the mother’s and bud’s growth rates have similar magnitudes, becoming identical at multiple time points. Finally, the mother’s growth rate increases after cytokinesis, peaking during G1.</p><p>Observing that cytokinesis typically occurs where the peak in bud growth rate ends, we developed an algorithm to estimate the point of cytokinesis. For each bud, we consider its growth rate from its appearance to either its disappearance, the first appearance of its own bud, or the appearance of its mother’s next bud. The time point of cytokinesis is then identified as the first time point after the maximum growth rate for which either the growth rate drops below zero or the derivative of the growth rate, estimated as the second derivative of the Gaussian process fit to the volume, rises above a threshold <inline-formula><mml:math id="inf203"><mml:mi>g</mml:mi></mml:math></inline-formula>. If neither condition holds, we set cytokinesis to the last of the time points considered.</p><p>We determined the threshold <inline-formula><mml:math id="inf204"><mml:mi>g</mml:mi></mml:math></inline-formula> from a training set of 150 ground-truth estimates of cytokinesis determined by the Nhp6A-mCherry marker (30 from each condition in <xref ref-type="fig" rid="fig4">Figure 4</xref>). We evaluated accuracy using ground-truth estimates of cytokinesis determined from either the Myo1-GFP or Nhp6A-mCherry markers, excluding those used in training (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>). Across multiple conditions, our method predicts the timing of cytokinesis to within two time points (6–10 min) for over 60% of the examples. A potential issue, however, is that we can compare only with cells for which we are able to assign at least one valid cell cycle using Myo1 or Nhp6A. There are multiple predictions made by the growth-rate method that we therefore ignore because there is no corresponding ground truth, and discarding these predictions may affect the overall result.</p><p>We used this method to predict cytokinesis for <xref ref-type="fig" rid="fig1">Figure 1e</xref>, <xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref> and <xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1</xref>.</p></sec></app><app id="appendix-7"><title>Appendix 7</title><sec sec-type="appendix" id="s17"><title>Correlating nuclear Sfp1 with growth rate</title><p>The cross correlation of time series can reveal regulatory relationships (<xref ref-type="bibr" rid="bib22">Dunlop et al., 2008</xref>). We applied cross correlations to investigate if fluctuations in Sfp1’s localisation anticipate fluctuations in growth rate. Analysis by the method of <xref ref-type="bibr" rid="bib43">Kiviet et al., 2014</xref> assumes steady-state cells. We nonetheless make use of data with a switch from palatinose to glucose and back (<xref ref-type="fig" rid="fig4">Figure 4b</xref>), but limit ourselves to time points from either the four hours preceding the switch to glucose – approximately steady growth in palatinose – or the four hours preceding the switch back to palatinose – approximately steady growth in glucose.</p><p>Correlations may occur on scales longer than the duration of a cell cycle, so we analysed only mother cells present over the full four hours of steady growth. We used the summed mother and bud growth rates whenever a bud is present because most of the mother’s growth is in the bud. We identified when a daughter separates from its mother using Nhp6A-mCherry (Appendix 6). The medium washes away almost all daughters before they become mothers, making the lineage trees in our data have no branches and simplifying the analysis.</p><p>For each mother <inline-formula><mml:math id="inf205"><mml:mi>i</mml:mi></mml:math></inline-formula>, we have a time series <inline-formula><mml:math id="inf206"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> of the degree of localisation of Sfp1-GFP and a time series of instantaneous growth rates <inline-formula><mml:math id="inf207"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. For our sampling interval of <inline-formula><mml:math id="inf208"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> min, <inline-formula><mml:math id="inf209"><mml:mi>N</mml:mi></mml:math></inline-formula> is 48. We denote the total number of mother cells by <inline-formula><mml:math id="inf210"><mml:mi>M</mml:mi></mml:math></inline-formula> and calculate the deviation from the population mean for each time series:<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>δ</mml:mi><mml:msubsup><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>ℓ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>δ</mml:mi><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The cross-covariance of Sfp1 localisation and growth rate at a time lag of <inline-formula><mml:math id="inf211"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> is then (<xref ref-type="bibr" rid="bib43">Kiviet et al., 2014</xref>):<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mstyle displaystyle="false"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>⁢</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>δ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mtext>if </mml:mtext><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise</mml:mtext><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We find the cross-correlation through normalising by the standard deviations:<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We determined the auto-correlation for Sfp1 localisation, <inline-formula><mml:math id="inf212"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and for growth rate, <inline-formula><mml:math id="inf213"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, similarly. In <xref ref-type="fig" rid="fig5">Figure 5c–d</xref> of the main text, we show the mean and 95% confidence interval over all mother cells (all <inline-formula><mml:math id="inf214"><mml:mi>i</mml:mi></mml:math></inline-formula>).</p></sec></app><app id="appendix-8"><title>Appendix 8</title><sec sec-type="appendix" id="s18"><title>Real-time feedback control</title><p>In these experiments, we wished to trigger a change in media based on the cells’ growth rate. As an example, we switched medium from a richer to a poorer carbon source and used BABY to determine how long we should keep cells in this medium for approximately 50% to have resumed dividing before we switch back to the richer medium.</p><p>We ran code to implement the feedback control on two computers: one controlling the microscope (Appendix 8 Algorithm 2) and the other both segmenting images, via calls to Python, and determining growth rates (Appendix 8 Algorithm 3). The code is in Matlab and available on request.</p><p>We defined the fraction of escaped cells as the proportion of included mothers that have had a bud or daughter exceed a threshold in growth rate of 15 μm<sup>3</sup>/hr at any time point after the onset of the lag in growth caused by the poorer carbon source. We defined this lag period to begin at the time point when the median daughter growth rate first drops below 5 μm<sup>3</sup>/hr. To be included, a mother cell must satisfy two requirements: be present in our data for at least 95% of the time points from the 20 time points before the first switch to the current time point; and have an assigned bud or daughter for at least 10% of the time we observe it.</p><p>To increase processing speed, we used Savitzky-Golay filtering to estimate growth rates. The resulting first derivative is not well constrained at the end-points, making instantaneous growth rates vary widely at the most recently acquired time point. We therefore used growth rates up to and including the time point three steps before the most recent when determining the fraction of escaped cells.</p><p>We used the strain BY4741 Sfp1-GFP Nhp6A-mCherry in both experiments.</p><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups" id="AL2"><thead><tr><th align="left" valign="bottom">Algorithm 2 Feedback control – pseudocode for microscope acquisition software</th></tr></thead><tbody><tr><td align="left" valign="bottom">Set glucose pump to infuse at 4μl/min;<break/>Set ethanol pump off;<break/><bold>for</bold> <italic>270 timepoints</italic> <bold>do</bold><break/>  image acquired time = current time + 5 min Acquire images at 6 stage positions<break/>  Save images in networked directory<break/>  <bold>while</bold> <italic>current time&lt;image acquired time</italic> <bold>do</bold><break/>   <bold>if</bold> <italic>time since start ≥ 5hours and first switch has not happened</italic> <bold>then</bold><break/>    Run switch protocol (fast infuse/withdraw to remove back pressure);<break/>    Set glucose pump off;<break/>    Set ethanol pump to infuse at 4μl/min;<break/>   <bold>end</bold><break/>   read <monospace>onlinedata.txt</monospace><break/>   <bold>if</bold> <italic>fraction of escaped mothers is recorded and second switch has not happened</italic> <bold>then</bold><break/>    <bold>if</bold> <italic>fraction of escaped mothers ≥ 0.5</italic> <bold>then</bold><break/>     Run switch protocol (fast infuse/withdraw to remove back pressure);<break/>     Set glucose pump to infuse at 4μl/min;<break/>     Set ethanol pump off;<break/>    <bold>end</bold><break/>   <bold>end</bold><break/>  <bold>end</bold><break/><bold>end</bold></td></tr></tbody></table></table-wrap><table-wrap id="inlinetable3" position="anchor"><table frame="hsides" rules="groups" id="AL3"><thead><tr><th align="left" valign="bottom">Algorithm 3 Feedback control – pseudocode for segmentation software</th></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>for</bold> <italic>270 timepoints</italic> <bold>do</bold><break/><bold>   while</bold> <italic>segmentation of all positions is not complete</italic> <bold>do</bold><break/>    <bold>for</bold> <italic>6 positions</italic> <bold>do</bold><break/>     Check networked data directory<break/>     <bold>if</bold> <italic>all images for current position are recorded</italic> <bold>then</bold><break/>      Run BABY segmentation on current position<break/>     <bold>end</bold><break/>    <bold>end</bold><break/>  <bold>end</bold><break/>  <bold>for</bold> <italic>6 positions</italic> <bold>do</bold><break/>   Calculate growth rates by Savitzky-Golay filtering<break/>   Append result to array for all positions<break/>  <bold>end</bold><break/>  Write median growth rate to <monospace>onlinedata.txt</monospace><break/>  <bold>if</bold> <italic>first switch has happened</italic> <bold>then</bold><break/>   Calculate lag start time as first time point where median growth rate &lt;5µl/hour<break/>   <bold>if</bold> <italic>lag start has happened</italic> <bold>then</bold><break/>    Calculate fraction of escaped mothers and write to <monospace>onlinedata.txt</monospace><break/>   <bold>end</bold><break/>  <bold>end</bold><break/><bold>end</bold></td></tr></tbody></table></table-wrap></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79812.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Moses</surname><given-names>Alan M</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.05.11.491488" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.05.11.491488"/></front-stub><body><p>The authors develop important machine-learning approaches to extract single-cell growth rates and show convincing evidence that their methods can yield insight into growth control. They also introduce compelling new methodologies for several other aspects of automated image analysis.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79812.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Moses</surname><given-names>Alan M</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.05.11.491488">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.05.11.491488v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;A label-free method to track individuals and lineages of budding cells&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Naama Barkai as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission. Overall, all the reviewers were impressed by the innovative techniques and potential biological insights in the paper. At the same time, however, after discussion, the reviewers were not convinced that the work represents a &quot;method&quot; in the sense that it could actually be used by others or on data from other labs. Further, the reviewers all had major problems with the clarity of the manuscript, finding it difficult to fully understand either the key methodological or biological contributions.</p><p>Essential revisions:</p><p>1) Convince the reader that the &quot;method&quot; described here can be applied in other settings and that improved identification of small buds will be a generally important advance towards estimating growth rates from movies. As it stands, the reviewers wondered if the contribution here was really only a solution to a specific data analysis problem that arises in the specific imaging/microfluidics set-up considered here. Ideally, this issue could be addressed by clearly specifying the problem(s) that the method is designed to solve (e.g., is it bud identification, cell tracking and/or growth rate estimation), and clear comparison of this method to state-of-the-art methods on a variety of datasets (with appropriate held out test data and statistics.)</p><p>2) Clarify what the major novelty/contributions/discoveries are in the main manuscript text, describe them fully, and move all the other clever innovations (that are not fully supported by empirical data) to the supplementary materials or Methods section. For each contribution, give the appropriate context (previous work, hypothesis, importance, etc.) and ensure that the generality of the claims match the experiments/data presented (e.g., generality of observation of sizer vs timer regulating bud growth or generality of the tracking results beyond cells grown in traps). Ensure that the Title and Abstract reflect what has actually been demonstrated in the paper.</p><p>3) Overall, clarify the writing to give the appropriate scientific context for a general biology audience, and remove or explain technical jargon that will not be familiar to the readers of <italic>eLife</italic>.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>Specific issues:</p><p>– I am left wondering if this a software that other groups can expect to download and use, or is it an abstract &quot;method&quot; to make the point that it's possible to accurately segment small buds and extract growth rates and other labs should implement similar systems for their own imaging setups?</p><p>– Quite a bit of discussion of &quot;morphological erosion&quot; which I could not really follow. Is it the same usage as this?</p><p>https://en.wikipedia.org/wiki/Erosion_(morphology)</p><p>The authors should define what they mean by this term and explain why it is important.</p><p>– Very hard for me to understand the training and testing data: what is the data used? Was the method ever evaluated on data from other microscopes/labs/benchmarks? The only numbers I got were the training images 588 trap images – 1813 annotated cells in total.</p><p>– Sfp1 experiments are explained relatively clearly compared to the rest of the paper, but still major improvements are needed. E.g., it is never stated that the authors are assuming nuclear localization of Sfp1 reflects its &quot;activity&quot; (what is even meant, transcriptional activity?) While plausible, what is the evidence that this is true? Similarly, &quot;enters the nucleus in response to two conserved nutrient-sensing kinases&quot; – again this is not specific enough. How does Sfp1 &quot;respond&quot;? Presumably the kinases phosphorylate something and eventually Sfp1 translocates into the nucleus, and the authors are quantifying the GFP-signal in the nucleus? Non- experts will not be able to follow this without much more specific explanation.</p><p>– &quot;With BABY, we add the ability – with no extra imaging costs – to measure what is often our best estimate of fitness, single-cell growth rates.&quot; one of the points of the paper is that the cell size/growth information can be obtained 'for free' (i.e., with no additional labels) from microfluidics experiments. Have the authors actually gone back and reanalyzed any (even of their own) previously published data to illustrate this point? As it stands it seems a bit like a rhetorical argument.</p><p>– &quot;To better characterise how growth rate varies during the cell cycle, we ran experiments for cells with the gene MYO1 tagged with Green Fluorescent Protein&quot; Very hard to follow this. &quot;Ran experiments&quot; is not scientific. What is the logic? What was measured? &quot;We determined that we could predict cytokinesis from growth rate because at cytokinesis the mother's and bud's growth rates often reach a similar magnitude (Appendix 5).&quot; I can't follow this. What is the evidence that cytokinesis can be predicted? How is this measured? What are the alternative models that were rejected? Do I need to read Appendix 5? I found this claim in Appendix 5: &quot;We evaluated the algorithm by the correlation between the real time of cytokinesis and the predicted time&quot; What were the sample sizes for the test data? etc., etc., How was the &quot;real&quot; time measured? Is it this: &quot;The actual time of cytokinesis is taken to be the candidate point with the minimal derivative, corresponding to the strongest down-shift in fluorescence.&quot;?</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>1. It is not entirely clear to me how successful the automated bud-mother assignment actually is. In the main text (page 6) the authors talk about 80% precision. However, in the appendix we learn that the recall is only 47%. What is the actual accuracy of correct mother-bud identifications after the downstream assignment? How many tracks are rejected by the post-processing? The accuracy of the final pedigree analysis needs to be reported more directly.</p><p>2. Along those lines, the results shown in Figure 3c and d make it very hard to assess the actual accuracy of the automated extraction of cell cycle information. Especially the low number of only 6 daughter cells in Figure 3c is far from sufficient, as can be also seen by the unusual bimodal distribution – which does not reflect the distributions in Figure 3d. Instead, the authors should compare the results in Figure 3d to a manual analysis of the same cells (or at least a significant subfraction). Rather than histograms, it would be informative to see plots showing predicted vs manually analyzed TM and TD or a distribution of differences between those values in manually annotated and predicted data.</p><p>3. Unfortunately, the correlations shown in Figure 2a and c of Appendix 5 are mostly meaningless. The high correlation is simply a consequence of the fact that absolute time of the experiment is shown, and obviously cells born later in the experiment will finish cytokinesis later (or have a later time of predicted cytokinesis). As can be seen from this plot, predictions often deviate dramatically (on the timescale of hours!) from the ground truth. We need to see the same plot using time relative to bud emergence rather than absolute time.</p><p>4. The plots shown in Figure 3a and b are fine, but it would be beneficial to also see more standard metrics, such as average precision vs IoU threshold (see for example https://doi.org/10.1038/s41592-020-01018-x), or MOTA for tracking.</p><p>5. To allow fair comparison, segmentation by BABY using a single z-slice should</p><p>be compared with e.g. YeaZ (and ideally other deep learning methods) retrained with the same data.</p><p>6. It is not entirely clear to me whether Figure 4d and e rely on the Myo1-GFP signal or are purely obtained with automated BABY analysis. The Myo1-based data are a nice opportunity to further quantify the accuracy of the BABY-based cell cycle predictions. Again it would be nice to see predicted vs Myo1-based cell-cycle duration plotted against each other.</p><p>7. The biological results shown in Figure 4 are very interesting. However, I think to support the claim of sizer-timer based bud growth regulation, more than two conditions are needed. Does this claim still hold with multiple different media, or even appropriate mutants?</p><p>8. If I understand correctly, buds by definition are defined as independent cells if they become larger than 24 fL (page 33)? How many buds are affected by this criteria? How does this match with Figure 4e, where we clearly see bigger buds?</p><p>9. The claim in Figure S1 that YeaZ underestimates bud size more than BABY should be supported by a more direct plot, e.g. showing YeaZ (and BABY) predictions vs ground truth bud size on a single bud level.</p><p>10. Is the choice of evaluating 10 sets of hyperparameters in Appendix 3, Figure 3 determined by limiting computational resources? If not, this seems rather sparse, especially given the fact that panel b does not give the impression that a parameter set close to the optimum is found. Would testing more combinations not likely result in a significant improvement?</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>I would recommend the authors rewrite the paper focusing on the very interesting biology. Then, they can choose whatever method they like to analyze their data since that is not the main focus of the paper and there are no claims as to which method is better than which other.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79812.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Convince the reader that the &quot;method&quot; described here can be applied in other settings and that improved identification of small buds will be a generally important advance towards estimating growth rates from movies. As it stands, the reviewers wondered if the contribution here was really only a solution to a specific data analysis problem that arises in the specific imaging/microfluidics set-up considered here. Ideally, this issue could be addressed by clearly specifying the problem(s) that the method is designed to solve (e.g., is it bud identification, cell tracking and/or growth rate estimation), and clear comparison of this method to state-of-the-art methods on a variety of datasets (with appropriate held out test data and statistics.)</p></disp-quote><p>We now emphasise that BABY’s main innovation is estimating single-cell growth rates. Its ability to do so is by identifying buds both accurately and early through segmenting overlapping cells. That ability comes from defining multiple targets of differing cell sizes for the neural network. We expect this solution to be widely applicable and have changed the paper’s title accordingly.</p><p>To demonstrate the generality of our approach, we have performed extensive analyses, comparing BABY not only with YeaZ but also with Cellpose, a state-of-the-art, deep-learning based segmentation algorithm. Figure 3 is completely new as a consequence, and we have added a new section on evaluating BABY’s performance in Methods.</p><p>We show that BABY generalises, accurately analysing YeaZ’s microcolony training data (Figure 3, figure supplement 2). Although this training data is labelled, it does not allow for overlaps. We therefore manually annotated three of its 45 fields-of-view and added these to the BABY training data. We then assessed performance on the remaining 42 fields-of-view using the annotations from the YeaZ paper. Because YeaZ’s curation lacks overlaps, BABY has no particular advantage, but it nonetheless shows competitive performance with YeaZ and the Cellpose algorithm when we train all on the same data. We further note that some of the false positives detected by BABY were, upon inspection of the images, true positive buds, which were not annotated in the YeaZ training data, perhaps because they overlapped substantially with other cells.</p><p>For our own curated images with traps, we now compare BABY with both the Cellpose and YeaZ algorithms, showing results after retraining on the same training data as BABY (Figure 3a and 3b). For fair comparison, we focus on BABY’s performance when the input is only a single Z section. We nonetheless continue to highlight the advantage of using multiple Z sections (Figure 3a, 3c and Figure 3 supplement 1d-f), and we use this highest-performing model in our applications.</p><p>BABY produces the lowest errors in growth rates (Figure 3c), mostly because it more accurately segments cells with small sizes (Figure 3b).</p><p>We also now demonstrate the importance of detecting buds when estimating growth rates with a new supplement to figure 1 (Figure 1 figure supplement 1). This figure shows that smaller buds have the fastest growth rates, particularly in the size range where we observe overlaps (Appendix 1, Figure 2). The data are from a new benchmark data set, which we manually segmented specifically for testing the accuracy of estimating growth rates.</p><disp-quote content-type="editor-comment"><p>2) Clarify what the major novelty/contributions/discoveries are in the main manuscript text, describe them fully, and move all the other clever innovations (that are not fully supported by empirical data) to the supplementary materials or Methods section. For each contribution, give the appropriate context (previous work, hypothesis, importance, etc.) and ensure that the generality of the claims match the experiments/data presented (e.g., generality of observation of sizer vs timer regulating bud growth or generality of the tracking results beyond cells grown in traps). Ensure that the Title and Abstract reflect what has actually been demonstrated in the paper.</p></disp-quote><p>We now highlight BABY’s innovations, particularly the choice of targets for the U-net, which bring most of the improved performance and can be used widely in other image-processing applications. We have shortened the manuscript, removing the section on identifying cytokinesis and reducing the discussion. As well as the changes shown in blue, we have made minor edits throughout to improve focus and clarity.</p><p>We have changed the title and removed and re-written parts of the abstract.</p><disp-quote content-type="editor-comment"><p>3) Overall, clarify the writing to give the appropriate scientific context for a general biology audience, and remove or explain technical jargon that will not be familiar to the readers of eLife.</p></disp-quote><p>Throughout we are now careful both to define technical terms used in image processing and machine learning and to minimise their use.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>Specific issues:</p><p>– I am left wondering if this a software that other groups can expect to download and use, or is it an abstract &quot;method&quot; to make the point that it's possible to accurately segment small buds and extract growth rates and other labs should implement similar systems for their own imaging setups?</p></disp-quote><p>Our paper aims to provide both of these things. Researchers can freely download and use BABY on their data, but we believe too that others will incorporate its novel techniques into their own image-processing software.</p><p>As discussed in Essential revisions, we now demonstrate that BABY works not only on images with traps but also on microcolonies. We also show the importance of accurately segmenting small buds when estimating growth rates.</p><disp-quote content-type="editor-comment"><p>– Quite a bit of discussion of &quot;morphological erosion&quot; which I could not really follow. Is it the same usage as this?</p><p>https://en.wikipedia.org/wiki/Erosion_(morphology)</p><p>The authors should define what they mean by this term and explain why it is important.</p></disp-quote><p>We have minimised and now explain image-processing jargon.</p><disp-quote content-type="editor-comment"><p>– Very hard for me to understand the training and testing data: what is the data used? Was the method ever evaluated on data from other microscopes/labs/benchmarks? The only numbers I got were the training images 588 trap images – 1813 annotated cells in total.</p></disp-quote><p>We have moved where we describe the training data from Appendix 2 to a new “Training data” subsection in Methods and provide more detail on the sources of the images. We also now demonstrate that BABY works on microcolony data from another laboratory, using data from YeaZ.</p><disp-quote content-type="editor-comment"><p>– Sfp1 experiments are explained relatively clearly compared to the rest of the paper, but still major improvements are needed. E.g., it is never stated that the authors are assuming nuclear localization of Sfp1 reflects its &quot;activity&quot; (what is even meant, transcriptional activity?) While plausible, what is the evidence that this is true? Similarly, &quot;enters the nucleus in response to two conserved nutrient-sensing kinases&quot; – again this is not specific enough. How does Sfp1 &quot;respond&quot;? Presumably the kinases phosphorylate something and eventually Sfp1 translocates into the nucleus, and the authors are quantifying the GFP-signal in the nucleus? Non- experts will not be able to follow this without much more specific explanation.</p></disp-quote><p>We have re-written this section. Sfp1 is directly phosphorylated by TORC1 and likely too by PKA and moves into the nucleus because of these phosphorylations. We no longer say “activity”, only “nuclear localisation”.</p><disp-quote content-type="editor-comment"><p>– &quot;With BABY, we add the ability – with no extra imaging costs – to measure what is often our best estimate of fitness, single-cell growth rates.&quot; one of the points of the paper is that the cell size/growth information can be obtained 'for free' (i.e., with no additional labels) from microfluidics experiments. Have the authors actually gone back and reanalyzed any (even of their own) previously published data to illustrate this point? As it stands it seems a bit like a rhetorical argument.</p></disp-quote><p>We have changed “no extra imaging costs” to “using only bright-field images”, which we hope the reviewer agrees is clearer.</p><disp-quote content-type="editor-comment"><p>– &quot;To better characterise how growth rate varies during the cell cycle, we ran experiments for cells with the gene MYO1 tagged with Green Fluorescent Protein&quot; Very hard to follow this. &quot;Ran experiments&quot; is not scientific. What is the logic? What was measured? &quot;We determined that we could predict cytokinesis from growth rate because at cytokinesis the mother's and bud's growth rates often reach a similar magnitude (Appendix 5).&quot; I can't follow this. What is the evidence that cytokinesis can be predicted? How is this measured? What are the alternative models that were rejected? Do I need to read Appendix 5? I found this claim in Appendix 5: &quot;We evaluated the algorithm by the correlation between the real time of cytokinesis and the predicted time&quot; What were the sample sizes for the test data? etc., etc., How was the &quot;real&quot; time measured? Is it this: &quot;The actual time of cytokinesis is taken to be the candidate point with the minimal derivative, corresponding to the strongest down-shift in fluorescence.&quot;?</p></disp-quote><p>We agree that this section was too terse and its importance over emphasised, and we no longer include the method described in the main BABY algorithm. We have therefore moved the section to Appendix 6, where we have improved its clarity, expanding on how we define cytokinesis.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>1. It is not entirely clear to me how successful the automated bud-mother assignment actually is. In the main text (page 6) the authors talk about 80% precision. However, in the appendix we learn that the recall is only 47%. What is the actual accuracy of correct mother-bud identifications after the downstream assignment? How many tracks are rejected by the post-processing? The accuracy of the final pedigree analysis needs to be reported more directly.</p></disp-quote><p>We apologise for the confusion. Those precision and recall values were for assignments given a single time point. Our algorithm, however, benefits by aggregating over time, and we now evaluate both precision and recall for pairing mother and bud tracks (Figure 3d). We used our tracking test set, but supplemented with extra manually curated tracks to cover an additional two growth conditions.</p><p>The tracks we reject with post-processing are those with small volumes, low growth rates, or with durations under five time points. If such tracks correspond to cells, they are almost always not the central cells – those caught in the centre of the microfluidic traps – because these cells are usually stably trapped. As we now show in Figure 3d, BABY’s recall reduces if we assess performance against all tracks rather than those for central cells. We do not, however, consider this decrease important for most applications. In our laboratory at least, the focus has always been on the central cells because of their stability. With up to a thousand in one video, this restriction causes no shortage of data.</p><disp-quote content-type="editor-comment"><p>2. Along those lines, the results shown in Figure 3c and d make it very hard to assess the actual accuracy of the automated extraction of cell cycle information. Especially the low number of only 6 daughter cells in Figure 3c is far from sufficient, as can be also seen by the unusual bimodal distribution – which does not reflect the distributions in Figure 3d. Instead, the authors should compare the results in Figure 3d to a manual analysis of the same cells (or at least a significant subfraction). Rather than histograms, it would be informative to see plots showing predicted vs manually analyzed TM and TD or a distribution of differences between those values in manually annotated and predicted data.</p></disp-quote><p>We agree with the reviewer that the performance on extracting cell-cycle information was ambiguous. These results partly relied on our prediction of points of cytokinesis from growth rates. We now consider the accuracy of these predictions insufficient and on longer include predicting cytokinesis in the main BABY algorithm. Consequently, we have removed the results showing the extracted cell-cycle information entirely.</p><disp-quote content-type="editor-comment"><p>3. Unfortunately, the correlations shown in Figure 2a and c of Appendix 5 are mostly meaningless. The high correlation is simply a consequence of the fact that absolute time of the experiment is shown, and obviously cells born later in the experiment will finish cytokinesis later (or have a later time of predicted cytokinesis). As can be seen from this plot, predictions often deviate dramatically (on the timescale of hours!) from the ground truth. We need to see the same plot using time relative to bud emergence rather than absolute time.</p></disp-quote><p>Thank you: this error was one we should have caught.</p><p>We now compare with the predicted time of cytokinesis from the most recent budding event (Appendix 6). Although we predict cytokinesis within two time points (ten minutes) of the ground truth for 60% of the cells tested, we feel that this accuracy is too low compared to the accuracy of the rest of BABY, and we have removed the cytokinesis predictions from the main algorithm.</p><disp-quote content-type="editor-comment"><p>4. The plots shown in Figure 3a and b are fine, but it would be beneficial to also see more standard metrics, such as average precision vs IoU threshold (see for example https://doi.org/10.1038/s41592-020-01018-x), or MOTA for tracking.</p></disp-quote><p>We now report the mean average precision versus IoU threshold for all tested algorithms in Figure 3a.</p><p>We also evaluated tracking using the Multiple Object Tracking Performance metric (Figure 3 supplement 5), but found that it did not distinguish well between the tested methods. We suspect that this result is because the MOTA metric aims to assess cases where many objects are tracked with frequent errors. In our setting, however, we believe it is more important to have as many high precision tracks of the correct length rather than correctly identifying many short-lived tracks. We therefore include an alternative, more intuitive tracking metric in Figure 3c and have moved our previous track-overlap metric to Figure 3 supplement 4.</p><disp-quote content-type="editor-comment"><p>5. To allow fair comparison, segmentation by BABY using a single z-slice should</p><p>be compared with e.g. YeaZ (and ideally other deep learning methods) retrained with the same data.</p></disp-quote><p>In Figure 3, we now highlight and focus on the performance of the single Z-slice model. We also compare with models trained on our data, both for YeaZ and Cellpose.</p><disp-quote content-type="editor-comment"><p>6. It is not entirely clear to me whether Figure 4d and e rely on the Myo1-GFP signal or are purely obtained with automated BABY analysis. The Myo1-based data are a nice opportunity to further quantify the accuracy of the BABY-based cell cycle predictions. Again it would be nice to see predicted vs Myo1-based cell-cycle duration plotted against each other.</p></disp-quote><p>Those panels relied on using fluorescent Nhp6A, a nuclear marker, to estimate when anaphase starts. We have altered Figure 4’s legend and axes labels to clarify this use of Nhp6A and highlight the time at which we expect cytokinesis, approximately 20 minutes after anaphase begins.</p><p>To avoid confusion with our prediction of cytokinesis from growth rate – now dropped from the main BABY algorithm, we have moved the original panels Figure 4a-c to a figure in Appendix 6.</p><disp-quote content-type="editor-comment"><p>7. The biological results shown in Figure 4 are very interesting. However, I think to support the claim of sizer-timer based bud growth regulation, more than two conditions are needed. Does this claim still hold with multiple different media, or even appropriate mutants?</p></disp-quote><p>We have supplemented our analysis with data from three additional growth conditions and more correctly identify the previously reported glucose growth condition as following a transition from growth in palatinose.</p><disp-quote content-type="editor-comment"><p>8. If I understand correctly, buds by definition are defined as independent cells if they become larger than 24 fL (page 33)? How many buds are affected by this criteria? How does this match with Figure 4e, where we clearly see bigger buds?</p></disp-quote><p>We exclude a track from being assigned as a bud if the volume of the corresponding cell was always above 24 fL. Objects above this size are often indistinguishable from small cells that the flow of medium transiently washes into the field-of-view from upstream in the microfluidic device. We have added this information to Appendix 2.</p><p>If BABY identifies small buds early enough and they are correctly tracked, then the size of a bud may grow beyond 24 fL.</p><disp-quote content-type="editor-comment"><p>9. The claim in Figure S1 that YeaZ underestimates bud size more than BABY should be supported by a more direct plot, e.g. showing YeaZ (and BABY) predictions vs ground truth bud size on a single bud level.</p></disp-quote><p>We have removed this figure. Figure 3e now systematically compares BABY and YeaZ, and Cellpose, to the ground truth.</p><disp-quote content-type="editor-comment"><p>10. Is the choice of evaluating 10 sets of hyperparameters in Appendix 3, Figure 3 determined by limiting computational resources? If not, this seems rather sparse, especially given the fact that panel b does not give the impression that a parameter set close to the optimum is found. Would testing more combinations not likely result in a significant improvement?</p></disp-quote><p>We have removed this panel, which showed the performance of U-nets with differing numbers of filters and depths. As the reviewer implies, it is not particularly informative. Nonetheless, we consistently found that U-nets with fewer parameters than the standard one, which has a depth of d = 5 and n = 64 filters, showed similar, if not slightly higher, performance, but use less memory and storage and are faster.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>I would recommend the authors rewrite the paper focusing on the very interesting biology. Then, they can choose whatever method they like to analyze their data since that is not the main focus of the paper and there are no claims as to which method is better than which other.</p></disp-quote><p>Here unfortunately we have to disagree with the reviewer. We believe that a methods paper will have higher impact if it has accompanying examples illustrating the new insights the method brings.</p></body></sub-article></article>