<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">80047</article-id><article-id pub-id-type="doi">10.7554/eLife.80047</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Structural Biology and Molecular Biophysics</subject></subj-group></article-categories><title-group><article-title>Automated systematic evaluation of cryo-EM specimens with SmartScope</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-279916"><name><surname>Bouvette</surname><given-names>Jonathan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3550-5319</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-279918"><name><surname>Huang</surname><given-names>Qinwen</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7082-5257</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-279919"><name><surname>Riccio</surname><given-names>Amanda A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7782-0363</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-100564"><name><surname>Copeland</surname><given-names>William C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0359-0953</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-279917"><name><surname>Bartesaghi</surname><given-names>Alberto</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7360-1523</contrib-id><email>alberto.bartesaghi@duke.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-278941"><name><surname>Borgnia</surname><given-names>Mario J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9159-1413</contrib-id><email>mborgnia@nih.gov</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00j4k1h63</institution-id><institution>Genome Integrity and Structural Biology Laboratory, National Institute of Environmental Health Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Research Triangle Park</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Computer Science, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Electrical and Computer Engineering, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Biochemistry, Duke University School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Scheres</surname><given-names>Sjors HW</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00tw3jy02</institution-id><institution>MRC Laboratory of Molecular Biology</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Swartz</surname><given-names>Kenton J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>National Institute of Neurological Disorders and Stroke, National Institutes of Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>23</day><month>08</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e80047</elocation-id><history><date date-type="received" iso-8601-date="2022-05-06"><day>06</day><month>05</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-07-21"><day>21</day><month>07</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-05-06"><day>06</day><month>05</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.05.05.490801"/></event></pub-history><permissions><ali:free_to_read/><license xlink:href="http://creativecommons.org/publicdomain/zero/1.0/"><ali:license_ref>http://creativecommons.org/publicdomain/zero/1.0/</ali:license_ref><license-p>This is an open-access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0 public domain dedication</ext-link>.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-80047-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-80047-figures-v1.pdf"/><abstract><p>Finding the conditions to stabilize a macromolecular target for imaging remains the most critical barrier to determining its structure by cryo-electron microscopy (cryo-EM). While automation has significantly increased the speed of data collection, specimens are still screened manually, a laborious and subjective task that often determines the success of a project. Here, we present SmartScope, the first framework to streamline, standardize, and automate specimen evaluation in cryo-EM. SmartScope employs deep-learning-based object detection to identify and classify features suitable for imaging, allowing it to perform thorough specimen screening in a fully automated manner. A web interface provides remote control over the automated operation of the microscope in real time and access to images and annotation tools. Manual annotations can be used to re-train the feature recognition models, leading to improvements in performance. Our automated tool for systematic evaluation of specimens streamlines structure determination and lowers the barrier of adoption for cryo-EM.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>cryo-electron microscopy</kwd><kwd>automation</kwd><kwd>machine learning</kwd><kwd>deep learning</kwd><kwd>object recognition</kwd><kwd>software platform</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000066</institution-id><institution>National Institute of Environmental Health Sciences</institution></institution-wrap></funding-source><award-id>ZIC ES103326</award-id><principal-award-recipient><name><surname>Borgnia</surname><given-names>Mario J</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000066</institution-id><institution>National Institute of Environmental Health Sciences</institution></institution-wrap></funding-source><award-id>ZIA ES103341</award-id><principal-award-recipient><name><surname>Borgnia</surname><given-names>Mario J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000066</institution-id><institution>National Institute of Environmental Health Sciences</institution></institution-wrap></funding-source><award-id>Z01 ES065078</award-id><principal-award-recipient><name><surname>Copeland</surname><given-names>William C</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>Chan Zuckerberg Initiative</institution></institution-wrap></funding-source><award-id>2021-234602</award-id><principal-award-recipient><name><surname>Bartesaghi</surname><given-names>Alberto</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>SmartScope is the first software package designed to streamline, standardize, and fully automate screening of specimens in cryo-electron microscopy, providing real-time remote control of the microscope and access to data through a standard web interface.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Over the past decade, advances in hardware and software have improved the resolution and throughput of single particle analysis (SPA), establishing cryo-EM as a method of choice in structural biology. However, optimizing specimens for high-resolution cryo-EM imaging remains a significant barrier (<xref ref-type="bibr" rid="bib24">Weissenberger et al., 2021</xref>). The ideal specimen for solving a structure is a single layer of randomly oriented macromolecular complexes embedded into a thin slab of vitreous ice. During specimen preparation, interactions with the air-water interface facilitated by the confinement into a thin layer of buffer can destabilize protein complexes leading to denaturation and aggregation or force the molecules into a ‘preferred orientation’ (<xref ref-type="bibr" rid="bib12">Noble et al., 2018</xref>). In addition, vitrification methods typically yield variations in ice thickness across the grid. These artifacts can severely limit the quality of specimens and are typically addressed through an optimization process in which several parameters are varied to increase the stability and mono-dispersity of the target macromolecule (<xref ref-type="bibr" rid="bib13">Passmore and Russo, 2016</xref>). Evaluating each combination of parameters involves comprehensive sampling of one or more grids using a cryo-EM. Testing all combinations is impractical because the number grows significantly with the inclusion of each parameter. Instead, an iterative search is performed in which a limited number of parameters are evaluated, and new conditions are selected based on the results.</p><p>The goal of specimen screening is to learn as much as possible from each condition, often taking advantage of the heterogeneous landscape of each grid to extract valuable information about the behavior of the macromolecule of interest. This process involves selecting areas for evaluation, adjusting the positioning and optical conditions of the microscope, and recording images at multiple magnifications. The lowest magnifications are used to assess the overall quality of the vitrification process, the number of potential areas amenable to sampling at higher resolution and some macroscopic indicators of sample instability such as aggregation. Higher magnification images provide direct information about the macromolecules of interest, such as particle integrity, distribution, affinity for the substrate, density, heterogeneity and orientation, as well as the quality of the ice, and the resolution limit of the images. This makes manual specimen screening a time-consuming activity with a steep learning curve in which the implicit subjectivity in the selection of areas can lead to suboptimal sampling, resulting in missing information. The quality of the results, the speed, and even the integrity of the instrument, all depend on the experience and skills of the operator.</p><p>Existing software for automated cryo-EM is not designed to provide a thorough sampling of each grid. Instead, packages are optimized for acquiring a large number of high-quality images of a pre-selected set of targets (<xref ref-type="bibr" rid="bib11">Mastronarde, 2005</xref>; <xref ref-type="bibr" rid="bib21">Suloway et al., 2005</xref>). Although all data collection packages preserve lower magnification images and the associated stage positions, they are not designed to facilitate virtual navigation of the grid with the exception Leginon’s companion software, Appion (<xref ref-type="bibr" rid="bib10">Lander et al., 2009</xref>), which provides offline access to the results via a web user interface (WebUI). However, none of the existing packages is optimized for screening, nor they provide a web-based solution for controlling the microscope during specimen evaluation.</p><p>Here, we present SmartScope, a web-based, highly available expert system capable of performing unsupervised screening of specimens and automated data collection for cryo-EM. SmartScope uses pretrained generalized deep learning (DL) models for feature detection and selection to maximize sampling and provide information to guide specimen optimization. By combining automation, machine learning, and remote control, we aim to increase the efficiency of the screening process, reducing costs and dramatically increasing availability. Finally, SmartScope is designed as a modular framework, facilitating the addition of new algorithms for area selection and navigation that can further improve targeting performance.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>The complexity of a screening workflow depends on several factors including the instrument used and the type of specimen. Here, we describe the extended operation of a microscope furnished with an autoloader device and loaded with frozen hydrated targets for SPA, which are prepared on a micropatterned holey substrate or continuous carbon (<xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). All the interactions with the software are carried out using the SmartScope WebUI which also allows to monitor progress and control the workflow with little to no training in cryo-EM. Further, SmartScope permits simultaneous access from multiple remote devices, greatly facilitating collaborative work.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Overview of the SmartScope framework.</title><p>(<bold>A</bold>) Workflow for unsupervised grid navigation and imaging. SmartScope handles specimen exchange, atlas acquisition, regions of interest (ROIs) identification, classification, and selection. It then visits the selected regions and identifies and selects targets of interest (TOIs) which are acquired at higher magnification and preprocessed. (<bold>B</bold>) Detailed steps in ROI selection. After detection and classification, ROIs are also clustered into groups. In the example is a clustering by size. Then, from the ROIs are queried based on their class and ROIs from different clusters are selected. (<bold>C</bold>) Detailed steps in TOI selection. Shown here is the hole detection followed by a median intensity clustering. Then, holes are grouped by image-shift radius and groups from each cluster are selected for imaging.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Detailed SmartScope workflow.</title><p>Steps carried out by SerialEM (<xref ref-type="bibr" rid="bib11">Mastronarde, 2005</xref>) are shown in purple and steps carried out by SmartScope are shown in blue. Steps that can be modified within the sessions setup or during the session are shown in bold (see <xref ref-type="table" rid="table1">Table 1</xref> for descriptions of the parameters). The steps in the dashed boxes are executed asynchronously from the main workflow, meaning that the workflow moves to the next steps while these are executing.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Beam-image shift hole grouping algorithm.</title><p>(<bold>A</bold>) The hole grouping function takes the coordinates of the holes in a square, the maximum grouping radius in microns and a minimum group size. The algorithm uses the distance matrix between the holes and attempts to group them to maximize the coverage while minimizing the number of groups. Each iteration, shown in the dark gray box, uses a randomized matrix. The iterations will stop after 500, unless 250 consecutive iterations did not improve the score. Scores can be weighted in favor of coverage or the number of groups by changing the weight (default weight = 2). (<bold>B</bold>) Example of how grouping can be optimized by labeling holes bad holes (red) and re-running the grouping algorithm (white scale bars are 10 μm).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Overall software architecture of SmartScope.</title><p>SmartScope uses a database server (MariaDB), a web application with a web server and a Worker that runs the main processes. Each component can be installed on different computers and communicate with each other using Socket or SSH connections. Ongoing sessions are updated in real time via a WebSocket connection. The worker is the only service that requires network access to the SerialEM computer. The worker and Web server need access to a shared disk to continuously update the results. After data is acquired, it can be moved to an optional long-term storage such as a local network drive or to an AWS S3 bucket.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig1-figsupp3-v1.tif"/></fig></fig-group><sec id="s2-1"><title>Initialization</title><p>After a cassette is inserted in the autoloader, a session is initialized by providing the list of grids to be evaluated along with a series of parameters applicable to all of them (<xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>). SmartScope then initiates a connection to SerialEM (<xref ref-type="bibr" rid="bib11">Mastronarde, 2005</xref>) via its python API to issue commands to the microscope. This connection is locked to prevent the simultaneous execution of multiple workflows. For instruments equipped with automated loading systems, grids are loaded sequentially into the column and subjected to the operations described in the sections below.</p></sec><sec id="s2-2"><title>Grid analysis</title><p>For each grid loaded, a series of low magnification images are acquired and stitched together to generate a grid map or ‘Atlas’ which is analyzed by SmartScope’s DL driven window detector and classifier (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Windows deemed suboptimal for imaging due to physical damage or heavy contamination are excluded from further analysis. The remaining ‘good’ windows are reclassified and clustered based on a selectable criterion (e.g. areas suitable for imaging). Representatives of each window cluster are added to a list of regions of interest (ROIs) with the goal of adequately sampling the diversity of imageable areas (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The program then proceeds to visit and select imaging targets from the ROIs in this list, which can be modified via the WebUI at any time before the grid is completed.</p></sec><sec id="s2-3"><title>Selection of targets</title><p>The stage is moved to the next ROI, brought to eucentric height, and imaged at a magnification that ensures complete coverage of the area (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The next step is to identify targets of interest (TOIs) based on a programmable criterion that depends on the specimen. For example, SmartScope’s DL based hole finder is used to detect holes in frozen hydrated SPA specimens. The current algorithm classifies the holes based on their average signal intensity (a proxy for ice thickness) and clusters them into a selectable number of groups. By default, the group containing the darkest targets is rejected as not suitable for imaging. To maximize diversity, holes are selected from the different clusters and added to a TOI list (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). As with ROIs, this selection can be modified at any time during imaging of the grid. A protocol for selecting negative stain TOIs is also available and plug-ins for other types of specimens may be incorporated in the future.</p><p>Selected TOIs are visited sequentially by moving the stage to their predicted coordinates. A series of images, at a magnification that encompasses the TOI and surrounding area, are used to recenter the imaging area on the target (a hole in the substrate for SPA). These intermediate resolution images are stored in the database as they often provide valuable information about the specimen, such as affinity of the macromolecules for the support material, aggregation, denaturation, etc. Autofocus and drift stabilization procedures are then performed before acquiring high-magnification images of the target. An optional random offset from the center of each hole can be specified to capture images at different distances from the edge of the substrate. The newly acquired images are processed using the routine alignframes in IMOD (<xref ref-type="bibr" rid="bib9">Kremer et al., 1996</xref>) and the program CTFFIND4 (<xref ref-type="bibr" rid="bib18">Rohou and Grigorieff, 2015</xref>) to facilitate assessment of data quality. This cycle is repeated until all TOIs are imaged; then the workflow proceeds to the next ROI.</p><p>After all selected ROIs for the grid is finished, SmartScope automatically switches to the next grid. This behavior may be modified by selecting the ‘pause between grids’ option on the session menu. Pausing allows for the selection of additional ROIs at the end of the cycle, providing better control of unattended sessions or when evaluating unusual specimens where automated sampling may not be satisfactory.</p></sec><sec id="s2-4"><title>Accessing and annotating results</title><p>SmartScope systematically documents the results and facilitates their analysis. During collection, all images and their related metadata are stored in a consistent data structure. To display and interact with these data, SmartScope implements an intuitive WebUI that tracks the imaging process in real time. Moreover, it enables remote interaction with a running session, such as modifying area selection, changing labels and acquisition parameters, and taking notes about the specimen, all without interrupting the acquisition workflow.</p><p>After a session is over, SmartScope can automatically copy the data to long-term or object storage. The data remains available through the WebUI and allows users to make additional annotations. Other tools, such as micrograph curation and exporting of metadata as star files are also available.</p></sec><sec id="s2-5"><title>Tools for exhaustive screening and high-throughput data collection</title><p>SmartScope can also perform high-throughput data collection. A session can be initialized in data collection mode or changed from screening to data collection by setting the number of TOI to sample to zero. This will select all the available TOIs for imaging.</p><p>To achieve high-throughput, SmartScope makes uses beam-image shift (BIS) for multi-hole imaging (<xref ref-type="bibr" rid="bib3">Cheng et al., 2018</xref>). BIS can be used during screening for more exhaustive sampling, allowing for exploratory data collections that can provide enough images to carry out 2D classification or initial 3D reconstruction. The BIS grouping in SmartScope uses an algorithm that groups the holes within a given radius (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Only the targets that are labeled as ‘good’ and are in the included clusters are used for the grouping. The algorithm attempts to maximize the coverage of targets while minimizing the total number of groups. To maximize the speed of data collection, a minimal group size can also be specified to prevent the algorithm from assigning small groups of holes. The BIS radius and minimal group size is specified at the start of each session and can be modified during the session.</p><p>One way to alleviate the commonly occurring problem of orientation bias in single-particle cryo-EM is to collect data on a tilted specimen (<xref ref-type="bibr" rid="bib22">Tan et al., 2017</xref>). SmartScope can perform BIS data collection on tilted specimens, where the position and defocus of the targets are corrected using geometrical tilt constraints with a throughput that is similar to regular non-tilted data collection. Moreover, the tilt angle can be seamlessly changed at any point during the acquisition process. Combined with the integrated in-line data processing, this allows to adapt the data collection strategy on-the-fly based on the newly acquired knowledge.</p><p>The combination of automated operations such as feature detection routines, multi-hole imaging, and tilted data collection capabilities, makes SmartScope a powerful tool that can accelerate screening of cryo-EM samples and achieve high-throughput data collection.</p></sec><sec id="s2-6"><title>Asynchronous imaging and processing</title><p>SmartScope was designed to maximize microscope efficiency and to remove much of the idling time in the imaging process. A common source of idling is the processing time required for rendering the frame averages or calculating the CTF fits. To minimize the impact of this, the microscope’s imaging process and the image processing routines run as parallel processes. The newly acquired images or movies are queued up for analysis and processed sequentially on a separate thread. For the atlas and windows, processing includes detecting, classifying, and selecting targets. For high-magnification TOIs, it involves frame alignment when fractions are saved, and CTF estimation. This allows the microscope to immediately acquire the next target while the images are being analyzed (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></sec><sec id="s2-7"><title>Installation and configuration</title><p>SmartScope bundles a web server for the WebUI, a database server and the core package necessary to run the main imaging workflow. It relies on the database to store and query essential metadata (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). To simplify the deployment and orchestration of these services, we created a Docker image that should be compatible with most Linux systems.</p><p>The application can be installed on a single workstation that will handle the execution of all the services. It can also be installed in a master-worker configuration where, for example, one computer handles the web server and the database (master), while the main workflow is executed on a workstation that is connected to the microscope network (worker). The minimal requirements are that all the systems can access the database that holds the metadata for the session and targets, and the filesystem where the images are saved.</p><p>A long-term storage area that holds the data from previous sessions can be specified. Both mounted network drives and object-stores can be used to store the data. This allows to clear data from the main local drives leaving space for the ongoing sessions while keeping older data accessible through the WebUI.</p><p>After installation, administrators can login to the WebUI management portal where microscope and detector information needs to be added to allow connection to the instruments. Multiple microscopes can be installed on a single instance of SmartScope, serving as a central hub for microscope access. To access the server, each user has an account and groups are created by an administrator. Users can only access the data from the groups they belong to.</p><p>In SerialEM, a settings file containing the magnification for low-dose imaging needs to be prepared for each microscope and detector. The conditions should be set as follows: full square image bound to the Search preset using a magnification that shows the entire square; the fine hole re-alignment condition in low SA magnification bound to the View preset; the data acquisition conditions bound to the Record preset with the acquisition and dose fractionation settings bound to the Preview. As different hardware combinations would require different settings, we included a table with the settings used on a Talos Arctica equipped with a K2 detector and Titan Krios G4 equipped a K3 detector and bio-continuum energy filter as guidelines (<xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref>).</p></sec><sec id="s2-8"><title>Automated object detection and classification</title><p>SmartScope identifies and classifies ROIs and TOIs suitable for cryo-EM imaging using DL approaches. At the atlas level, areas suitable for imaging appear as ‘windows,’ commonly shaped as squares, through the metallic grid in which the support layer is intact and not blocked by thick ice or large contaminants. Windows are automatically detected and classified using a pretrained Region-based Convolutional Neural Network (<xref ref-type="bibr" rid="bib6">Girshick, 2015</xref>) that identifies the ‘good’ windows with 80% precision (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>, <xref ref-type="table" rid="app1table3">Appendix 1—table 3</xref>), thus providing information that can effectively guide the instrument to avoid undesirable regions of the grid.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Deep-learning-based feature recognition for autonomous grid navigation.</title><p>Sample images show the performance of the square (<bold>A</bold>) and hole (<bold>B</bold>) detectors applied to gold (left) and carbon (right) grids. (<bold>A</bold>) Automatic detection of squares and classification into six different classes: small, cracked, dry, contaminated, good, and partial (white scale bars are 100 μm). Representative examples of squares assigned to each class and corresponding detection precision values are shown (bottom panel). (<bold>B</bold>) Hole detection performance on representative square images extracted from gold and carbon grids. The hole detector implements a classification step to filter out contaminants (shown in yellow) and increases hole detection precision (shown as pink circles) (white scale bars are 10 μm).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Object detection training strategy.</title><p>Atlas (<bold>A</bold>) and Windows (<bold>B</bold>) where manually picked and annotated. The annotated dataset was augmented using a combination of rotations, translations, contrast variations, magnifications, and flip transforms. The models were trained against their specific architectures.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Selected windows are then acquired at a higher magnification where TOIs can take various shapes depending on whether the modality is single particle cryo-EM, tomography, or negative stain. In single particle cryo-EM, these TOIs usually show as holes in the substrate and are difficult to detect with traditional image processing tools due to the low contrast, especially when carbon mesh grids are used. We implemented a robust hole detector for frozen specimens based on the You-Only-Look-Once (<xref ref-type="bibr" rid="bib16">Redmon et al., 2016</xref>) object detection architecture (<xref ref-type="fig" rid="fig2">Figure 2B</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>). To prevent the network from incorrectly picking dark ice contaminants, we also added a classification step to separate holes from contaminants and were able to correctly identify 89% of the holes.</p></sec><sec id="s2-9"><title>Screening mode statistics</title><p>In screening mode, the average time required for exchanging specimens and acquiring a partial atlas covering at least 25% of the grid surface is 7.8 min (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="table" rid="app1table4">Appendix 1—table 4</xref> and <xref ref-type="table" rid="app1table5">Appendix 1—table 5</xref>). The median sampling time for a specimen is 21 min, yielding a median of 9.0 high-magnification images of holes sampled from 3.0 different windows. Each day, our screening microscope thoroughly screens an average of 16 specimens and performs data collection for approximately 16 hr.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>SmartScope’s screening mode statistics.</title><p>Screening rates with and without beam-image shift (BIS) were 1.0 and 0.7 holes per minute, respectively (RANSAC regression). The red arrow indicates the time of specimen loading and start of atlas acquisition. Dashed blue line represents the median session duration (21.6min) and the median number of high-magnification images (9.0) obtained per specimen during screening mode.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig3-v1.tif"/></fig></sec><sec id="s2-10"><title>Data collection mode statistics</title><p>SmartScope offers a convenient option to set up, track data collection and to label and annotate exposures. In data collection mode, the microscope continuously acquires areas and finds targets using operator assistance only to fine tune the selection to specific needs, significantly reducing setup time as compared to our manual workflow. The median data collection setup time, from specimen loading to the start of high-magnification acquisition, is 32 min with our K2 detector (<xref ref-type="table" rid="app1table6">Appendix 1—table 6</xref>). As an example, we used SmartScope to determine a 3.4 Å map of the 55 kDa homodimer accessory subunit of the human mitochondrial DNA polymerase (<xref ref-type="bibr" rid="bib29">Young and Copeland, 2013</xref>) (EMD-25764, <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). For this specimen, we collected 4327 micrographs and seamlessly tilted to 30° for the last third of the dataset to improve the angular sampling of the protein (<xref ref-type="table" rid="table1">Table 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Acquisition of POLG2 dataset using SmartScope.</title><p>(<bold>A</bold>) Atlas of the specimen (left), typical micrograph (center) with some particles picked (purple circles) and 2D classes of POLG2 (right). (<bold>B</bold>) Resulting map of POLG2 colored by local resolution (left) and example of an alpha helix with atomic model fit into the density (left). (<bold>C</bold>) Masked Fourier-shell correlation curve between half-maps showing a resolution of 3.4Å.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Structure determination of POLG2 using SmartScope.</title><p>(<bold>A</bold>) Screening of the specimen used for POLG2 data collection. Sample images from screening are shown. Data can be labeled from the webUI as a way to keep track of the quality. The holes will be colored according to their quality (red: thick ice, blue: great) (white scale bars are 100 nm). (<bold>B</bold>) Data collection of the same POLG2 specimen with sample squares and micrographs. Purple circles on the micrographs represent POLG2 particles (right). (<bold>C</bold>) Data processing of the POLG2 dataset using cryoSPARC (<xref ref-type="bibr" rid="bib15">Punjani et al., 2017</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>POLG2 particles from the areas collected at 0° tilt, 30° tilt, and combined.</title><p>(<bold>A</bold>) For each set, the angular distribution plot, the map and a zoom into a helix where PDB ID: 2G4C was fitted. All maps are displayed at a contour level of 0.6. (<bold>B</bold>) FSC plot of each set. Resolutions values can be found in <xref ref-type="table" rid="table1">Table 1</xref>. The horizontal dashed line represents the 0.143 FSC threshold.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80047-fig4-figsupp2-v1.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Cryo-EM data acquisition parameters and statistics.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="center" valign="bottom" colspan="3">POLG2 (EMD-25764)</th></tr><tr><th align="left" valign="bottom"/><th align="center" valign="bottom">No tilt</th><th align="center" valign="bottom">Tilted</th><th align="center" valign="bottom">Combined</th></tr></thead><tbody><tr><td align="left" valign="bottom" colspan="4"><bold>Hardware</bold></td></tr><tr><td align="left" valign="bottom">Microscope</td><td align="center" valign="bottom" colspan="3">Talos Arctica (Thermo Fisher)</td></tr><tr><td align="left" valign="bottom">Detector</td><td align="center" valign="bottom" colspan="3">K2 summit (Gatan Inc)</td></tr><tr><td align="left" valign="bottom" colspan="4"><bold>Data collection and processing</bold></td></tr><tr><td align="left" valign="bottom">Magnification</td><td align="center" valign="bottom" colspan="3">45,000</td></tr><tr><td align="left" valign="bottom">Voltage (kV)</td><td align="center" valign="bottom" colspan="3">200</td></tr><tr><td align="left" valign="bottom">Electron exposure (e<sup>-</sup>/Å<sup>2</sup>)</td><td align="center" valign="bottom" colspan="3">50</td></tr><tr><td align="left" valign="bottom">Defocus range (µm)</td><td align="center" valign="bottom">1.2–1.8</td><td align="center" valign="bottom">1.4–1.6</td><td align="center" valign="bottom">1.2–1.8</td></tr><tr><td align="left" valign="bottom">Tilt angle (°)</td><td align="center" valign="bottom">0</td><td align="center" valign="bottom">30</td><td align="center" valign="bottom"/></tr><tr><td align="left" valign="bottom">Pixel size (Å/pixel)</td><td align="center" valign="bottom" colspan="3">0.932</td></tr><tr><td align="left" valign="bottom">Movie No.</td><td align="center" valign="bottom">3029 (70%)</td><td align="center" valign="bottom">1282 (30%)</td><td align="center" valign="bottom">4311</td></tr><tr><td align="left" valign="bottom">Symmetry imposed</td><td align="center" valign="bottom" colspan="3">C2</td></tr><tr><td align="left" valign="bottom">Final particles</td><td align="center" valign="bottom">99,189 (78%)</td><td align="center" valign="bottom">28,641 (22%)</td><td align="center" valign="bottom">127,860</td></tr><tr><td align="left" valign="bottom">Map resolution (unmasked)</td><td align="center" valign="bottom">3.7</td><td align="center" valign="bottom">4.3</td><td align="center" valign="bottom">3.7</td></tr><tr><td align="left" valign="bottom">Map resolution (masked)</td><td align="center" valign="bottom">3.5</td><td align="center" valign="bottom">3.9</td><td align="center" valign="bottom">3.4</td></tr><tr><td align="left" valign="bottom">FSC threshold</td><td align="center" valign="bottom" colspan="3">0.143</td></tr><tr><td align="left" valign="bottom"><bold>Data collection statistics</bold></td><td align="center" valign="bottom" colspan="3"/></tr><tr><td align="left" valign="bottom">Setup time<xref ref-type="table-fn" rid="table1fn1">*</xref> (min)</td><td align="center" valign="bottom" colspan="3">60</td></tr><tr><td align="left" valign="bottom">Throughput (movies/hr)</td><td align="center" valign="bottom" colspan="3">117.9</td></tr><tr><td align="left" valign="bottom">Throughput last hour (movies)</td><td align="center" valign="bottom" colspan="3">130</td></tr></tbody></table><table-wrap-foot><fn id="table1fn1"><label>*</label><p>Data collection times are calculated as the time needed from grid loading to the collection of the first 50 high-magnification targets minus the time required for these 50 targets to be acquired.</p></fn></table-wrap-foot></table-wrap></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>SmartScope is the first package specifically designed to assist, document, and automate specimen evaluation during the process of optimizing samples for cryo-EM. The program delivers a unique user experience through a WebUI that provides live remote supervision and control of the screening process using a standard web browser. The same WebUI facilitates analysis of results at any time during and after a session. Multiple users can access the same live or stored session simultaneously and multiple instruments can be controlled from the same server. Automated navigation routines provide control of the microscope without granting full access to functions that may compromise the integrity of the instrument. SmartScope uses fast and robust AI-driven feature recognition algorithms to fully automate the cryo-EM imaging workflow. The steps of target identification, object classification, and clustering offer a powerful way to sample a wide variety of areas during screening and help determine the next steps in specimen optimization. This enables complete unsupervised execution of a screening workflow as well as supervised exploration with minimal user training.</p><p>SmartScope can also collect data in a semi-supervised or fully automated way. The areas automatically selected by SmartScope can be modified interactively or programmatically without interrupting the process of data collection. This maximizes the use of the microscope and offers the possibility of integrating feedback from in-line data processing workflows to adaptively improve image quality during acquisition, without user intervention. Unsupervised multi-specimen screening and short exploratory data collection sessions can be scheduled to run overnight, offering new ways of using the microscope.</p><p>The interface to the microscope hardware in SmartScope is currently achieved through SerialEM, which provides abstraction interfaces to the main microscope and detector manufacturers as well as being open source and well supported. However, the current integration is made so that interfaces to other software (e.g. Leginon, Digital Micrograph, SmartEPU) can also be integrated with SmartScope in the future.</p><p>SmartScope has a modular design where new object detection and classification algorithms can be added as plugins, allowing integration of existing object detection, and area selection programs for cryo-EM (<xref ref-type="bibr" rid="bib5">Fan et al., 2022</xref>; <xref ref-type="bibr" rid="bib8">Kim et al., 2021</xref>; <xref ref-type="bibr" rid="bib17">Rheinberger et al., 2021</xref>; <xref ref-type="bibr" rid="bib20">Schorb et al., 2019</xref>; <xref ref-type="bibr" rid="bib26">Xu et al., 2020</xref>; <xref ref-type="bibr" rid="bib27">Yokoyama et al., 2020</xref>; <xref ref-type="bibr" rid="bib28">Yonekura et al., 2021</xref>). Additionally, the ability to use multiple feature detection and clustering methods at different magnification levels enables the creation of customized protocols for specific applications. This provides flexibility to optimize the selection of areas on a wider variety of targets in cryo-EM, such as virions, filaments, and cells. Finally, as we gather more data about difficult specimens and edge cases, we envision the establishment of a globally accessible ‘virtual microscopist’ server capable of improving itself through periodic re-training based on voluntarily submitted labeled datasets.</p><p>SmartScope has proven to be an extremely valuable tool in our facility. It has streamlined bookkeeping, which in turn resulted in better decision making for specimen optimization. It has also maximized microscope usage by eliminating idling time, reducing setup, and screening times. SmartScope facilitates data and instrumentation access as well as collaboration by easing access to cryo-EM technologies and improving the way cryo-EM experiments are carried out. With specimen screening as a primary focus, SmartScope addresses an important limiting step in cryo-EM.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Cryo-EM</title><p>All the data presented in this study was acquired on a Talos Arctica (Thermo Fisher Scientific) operating at 200 kV and equipped with a K2 direct-electron detector (Gatan Inc). SmartScope was also tested on a Ceta CMOS detector and a Titan Krios (Thermo Fisher Scientific) equipped with a K3 detector and BioQuantum energy filter (Gatan Inc). The statistics were derived from data acquired exclusively with the K2 detector. For microscope and detector control, SmartScope uses SerialEM 4.0 through the python API library (<xref ref-type="bibr" rid="bib11">Mastronarde, 2005</xref>).</p></sec><sec id="s4-2"><title>Square finder</title><p>To localize and classify square windows, a Faster R-CNN-based framework (<xref ref-type="bibr" rid="bib6">Girshick, 2015</xref>) that uses a ResNet50 architecture as the feature extraction backbone was adopted. It incorporates a feature pyramid network for identification of objects at different magnification levels. In addition, since most features have approximately equal width and height, the bounding boxes were constrained to have aspect ratios within the 0.8–1.2 range. To improve robustness and stability of the model, data augmentation was applied to the training data, including zoom-in/zoom-out, rotation, contrast adjustments, and flipping. The degree of augmentation for the contrast intensity was limited to the 0.8 and 1.2 range. To compensate for label imbalance, random oversampling was added during training. Squares are classified into six different classes: good (suitable for imaging), small (thick ice), contaminated, cracked, fractioned, and broken. The low-level magnification feature detector was trained using a total of 26 atlases from both carbon and gold mesh grids acquired on Ceta (Thermo Fisher Scientific) and K2 (Gatan Inc) detectors. Each atlas contains around 50–100 squares on average. The original atlases, usually having widths and heights greater than 10,000 pixels were downsampled to 2048 × 2048 pixels to reduce memory requirements. The framework is implemented using the python library Detectron2 (<xref ref-type="bibr" rid="bib25">Wu et al., 2019</xref>). Training the detector takes around 2 hr when running on a NVIDIA TITAN V GPU card with 32 GB of RAM. The pre-trained weights are then used for fast real-time square detection during screening, which can evaluate each atlas image in under a second.</p></sec><sec id="s4-3"><title>Hole finder</title><p>To identify holes in all grid types and contrast levels, a deep neural-network architecture based on the YOLOv5 model was adopted (<xref ref-type="bibr" rid="bib7">Jocher et al., 2020</xref>; <xref ref-type="bibr" rid="bib16">Redmon et al., 2016</xref>). We used the Cross Stage Partial Network (CSPNet) (<xref ref-type="bibr" rid="bib23">Wang et al., 2019</xref>) as the feature extraction backbone and standard convolutional layers as detection layers. Since holes have circular shapes, the aspect ratios of the bounding boxes were also constrained. To further facilitate training, instead of using arbitrary numbers for anchor bounding boxes generation, clustering algorithms to the ground truth boxes from the training dataset were applied to find the most common occurring sizes and we used these sizes to determine the anchor bounding box sizes. Data augmentation was applied during training, including contrast/brightness adjustment, rotation/translation, zoom-in/zoom-out, and cropping. To deal with small contamination areas that can be incorrectly detected as holes, an additional ‘contaminants’ class is used to filter out such areas. Training of the hole finder was done using 36 square images acquired on Ceta (Thermo Fisher Scientic) and K2 (Gatan Inc) detectors and took 1.5 hr when running on a NVIDIA TITAN V GPU card with 32 GB of RAM and inference takes less than a second. For memory efficiency, each square was resized to 1280 × 1280 pixels.</p></sec><sec id="s4-4"><title>POLG2 purification</title><p>Protein was expressed and purified essentially as described (<xref ref-type="bibr" rid="bib30">Young et al., 2015</xref>) with the following exception: Triton-X was removed from all steps following lysis. Following Ni purification, pooled protein containing His<sub>6</sub>-POLG2, as determined by SDS-PAGE, was injected onto a monoS column. Protein was eluted from S column in a linear gradient from 5 to 50% Buffer B (25 mM HEPES, 1 M NaCl, 10% glycerol, 1 mM EDTA, 1 mM TCEP). Peak fractions were eluted around 310 mM NaCl. Fractions were checked for purity, combined, and concentrated using an Amicon concentrator (Millipore) to 28 µM. Protein is flash frozen and stored at –80 °C.</p><p>4.1 µM (monomer) his-tag POLG2 was incubated in a 1:1 molar ratio with FORK1 DNA as previously described (6) Oligonucleotides: (i) DCRANDOM- 44 <named-content content-type="sequence">ACTTGAATGCGGCTTAGTATGCATTGTAAAACGACGGCCAGTGC</named-content> (2) TSTEM <named-content content-type="sequence">GCACTGGCCGTCGTTTTACGGTCGTGACTGGGAAAACCCTGGCG</named-content> (3) U25 <named-content content-type="sequence">CGCCAGGGTTTTCCCAGTCACGACC</named-content> were all purchased from IDT. Protein in a final buffer of 20 mM HEPES pH 8, 1.5 mM Tris pH 7.5, 30 mM KCl, 50 mM imidazole pH 8, 0.3 mM EDTA, 225 mM NaCl, 1.5% glycerol, 1 mM TCEP was incubated on ice for approximately 30 min before grid application.</p></sec><sec id="s4-5"><title>Cryo-EM specimen preparation</title><p>UltraAUfoil R1.2/3 (Quantifoil Micro Tools GmbH) grids were glow-discharged on both sides for 30 s at 15 mA using a Pelco Easiglow. 3 µL of the final buffer was deposited on the back of the grid and 3 µL of POLG2 sample was deposited on front side of the grid. Excess sample was blotted 4 s with blotting force –1, the chamber set at 12 °C and 95% humidity using a Vitrobot Mark IV (Thermo Fisher Scientific).</p></sec><sec id="s4-6"><title>Data collection of POLG2 with SmartScope</title><p>Data was collected on a Talos Arctica (Thermo Fisher Scientific) operating at 200 kV equipped with a Gatan K2 direct electron detector (Gatan Inc). Data collection was set up using SmartScope using a 6 × 6 tile atlas, image-shift grouping radius of 4 µm and minimum group size of four holes, rolling target defocus of –1.2 to –1.8 µm and drift settling threshold at 1 Å/s. A total of 4311 60-frame movies were collected at a 0.932 Å/pixel and a total dose of 54 e<sup>-</sup>/Å<sup>2</sup>. 3029 movies were collected at 0° tilt angle and 1282 movies were collected with 30° tilt angle. Data was collected at a rate of 120 movies per hour.</p></sec><sec id="s4-7"><title>Cryo-EM data processing and refinement</title><p>The POLG2 dataset was processed using cryoSPARC (<xref ref-type="bibr" rid="bib15">Punjani et al., 2017</xref>) as detailed in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1C</xref>. Final maps were sharpened using DeepEMhancer (<xref ref-type="bibr" rid="bib19">Sanchez-Garcia et al., 2021</xref>). An atomic model from PDB ID: 2G4C (<xref ref-type="bibr" rid="bib4">Fan et al., 2006</xref>) was fit into the map using Chimera (<xref ref-type="bibr" rid="bib14">Pettersen et al., 2004</xref>).</p></sec><sec id="s4-8"><title>Data availability</title><p>Trained models used to obtain the results shown in <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> are available to download from <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6842025">10.5281/zenodo.6842025</ext-link>. The Jupyter notebook used to aggregate the statistic in <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="table" rid="app1table2 app1table3 app1table4 app1table5">Appendix 1—Tables 2–5</xref> is part of the code repository (<xref ref-type="bibr" rid="bib1">Bouvette et al., 2022a</xref>). Cryo-EM density maps of POLG2 collected using SmartScope have been deposited in the Electron Microscopy Data Bank (EMDB) with accession code EMD-25764. Square and hole images and corresponding labels used for training the ML models are available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6814642">10.5281/zenodo.6814642</ext-link> (square finder) and <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6814652">10.5281/zenodo.6814652</ext-link> (hole finder).</p></sec><sec id="s4-9"><title>Code availability</title><p>The source code for SmartScope is distributed under the open source BSD 3-clause license available at <ext-link ext-link-type="uri" xlink:href="https://github.com/NIEHS/SmartScope">https://github.com/NIEHS/SmartScope</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:82bd5d9289b5725821bfcd799c954a00be4e4580;origin=https://github.com/NIEHS/SmartScope;visit=swh:1:snp:133dce0fc5365b66a8fc784668d4dc3db86ae897;anchor=swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b">swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b</ext-link>, <xref ref-type="bibr" rid="bib1">Bouvette et al., 2022a</xref>). The AI algorithms are available as a standalone package at <ext-link ext-link-type="uri" xlink:href="https://gitlab.cs.duke.edu/bartesaghilab/smartscopeAI">https://gitlab.cs.duke.edu/bartesaghilab/smartscopeAI</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:de41415d9348a36c922c291938427f38e3b1053b;origin=https://gitlab.cs.duke.edu/bartesaghilab/smartscopeAI;visit=swh:1:snp:a379ed609f0524baf6fe0eee0facba6b3cf6aa47;anchor=swh:1:rev:43b29ae8c333a94463e0a4d9ecb97a5d5b6adf92">swh:1:rev:43b29ae8c333a94463e0a4d9ecb97a5d5b6adf92</ext-link>; <xref ref-type="bibr" rid="bib2">Bouvette et al., 2022b</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing, Development and implementation of SmartScope</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing, Developed and implemented the AI detection and classification for SmartScope</p></fn><fn fn-type="con" id="con3"><p>Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing, PolG2 project including cloning and purification of the protein</p></fn><fn fn-type="con" id="con4"><p>Resources, Supervision, Funding acquisition, Methodology, PolG2 project including conceptualization</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing – original draft, Project administration, Writing – review and editing, Developed and implemented the AI detection and classification for SmartScope</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing – original draft, Project administration, Writing – review and editing, Development and implementation of SmartScope</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-80047-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>SmartScope is open source software. Source code and installation instructions are available from <ext-link ext-link-type="uri" xlink:href="https://github.com/NIEHS/SmartScope">https://github.com/NIEHS/SmartScope</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:82bd5d9289b5725821bfcd799c954a00be4e4580;origin=https://github.com/NIEHS/SmartScope;visit=swh:1:snp:133dce0fc5365b66a8fc784668d4dc3db86ae897;anchor=swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b">swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b</ext-link>). Cryo-EM density maps of POLG2 collected using SmartScope have been deposited in the Electron Microscopy Data Bank (EMDB) with accession code EMD-25764.</p><p>The following datasets were generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Bouvette</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Bartesaghi</surname><given-names>A</given-names></name><name><surname>Borgnia</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Automated systematic evaluation of cryo-EM specimens with SmartScope - Training data for square detector</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.6814642</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset2"><person-group person-group-type="author"><name><surname>Bouvette</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Bartesaghi</surname><given-names>A</given-names></name><name><surname>Borgnia</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Automated systematic evaluation of cryo-EM specimens with SmartScope - Training data for hole detector</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.6814652</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset3"><person-group person-group-type="author"><name><surname>Bouvette</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Bartesaghi</surname><given-names>A</given-names></name><name><surname>Borgnia</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Automated systematic evaluation of cryo-EM specimens with SmartScope - Trained models for square and hole detectors</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.6842025</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset4"><person-group person-group-type="author"><name><surname>Riccio</surname><given-names>AA</given-names></name><name><surname>Bouvette</surname><given-names>J</given-names></name><name><surname>Borgnia</surname><given-names>MJ</given-names></name><name><surname>Copeland</surname><given-names>WC</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>human DNA polymerase gamma accessory subunit, POLG2</data-title><source>Electron Microscopy Data Bank</source><pub-id pub-id-type="accession" xlink:href="https://www.ebi.ac.uk/emdb/EMD-25764">EMD-25764</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported in part by the Intramural Research Program of the NIH; National Institute of Environmental Health Sciences (ZIC ES103326 and ZIA ES103341 to M.J.B., and Z01 ES065078 to W.C.C.), and a Visual Proteomics Imaging grant from the Chan Zuckerberg Initiative (2021-234602 to A.B.). This work utilized cloud computational resources and services accessed through the NIH STRIDES Initiative (<ext-link ext-link-type="uri" xlink:href="https://cloud.nih.gov">https://cloud.nih.gov</ext-link>) and computational resources offered by Duke Research Computing (<ext-link ext-link-type="uri" xlink:href="http://rc.duke.edu">http://rc.duke.edu</ext-link>). We thank Tracy Futhey, Charley Kneifel, Katie Kilroy, Mike Newton, Victor Orlikowski, Tom Milledge, and David Lane from the Duke Office of Information Technology and Research Computing for assistance with the computing environment. We also thank David Fargo, John Grovenstein, and Chris Stone from the NIEHS Office of Scientific Computing for allocating computational resources to this project and especially to Gregory Stamper for assistance in setting up computing environments. We also thank Dr. Joshua Strauss from the UNC cryo-EM Core and Dr. Nilakshee Bhattacharya from the Duke Shared Material Instrumentation Facility (SMIF) for testing early versions of SmartScope. Molecular graphics and analyses performed with UCSF Chimera, developed by the Resource for Biocomputing, Visualization, and Informatics at the University of California, San Francisco, with support from NIH P41-GM103311. We thank Robin E Stanley and Bradley P Klemm for critical review of the manuscript.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bouvette</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Riccio</surname><given-names>AA</given-names></name><name><surname>Copeland</surname><given-names>WC</given-names></name><name><surname>Bartesaghi</surname><given-names>A</given-names></name><name><surname>Borgnia</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022a</year><data-title>SmartScope</data-title><version designator="swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b">swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:82bd5d9289b5725821bfcd799c954a00be4e4580;origin=https://github.com/NIEHS/SmartScope;visit=swh:1:snp:133dce0fc5365b66a8fc784668d4dc3db86ae897;anchor=swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b">https://archive.softwareheritage.org/swh:1:dir:82bd5d9289b5725821bfcd799c954a00be4e4580;origin=https://github.com/NIEHS/SmartScope;visit=swh:1:snp:133dce0fc5365b66a8fc784668d4dc3db86ae897;anchor=swh:1:rev:9e58e2a2b278ca65156390175d393819fbb16a3b</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bouvette</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Riccio</surname><given-names>AA</given-names></name><name><surname>Copeland</surname><given-names>WC</given-names></name><name><surname>Bartesaghi</surname><given-names>A</given-names></name><name><surname>Borgnia</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022b</year><data-title>SmartscopeAI</data-title><version designator="swh:1:rev:43b29ae8c333a94463e0a4d9ecb97a5d5b6adf92">swh:1:rev:43b29ae8c333a94463e0a4d9ecb97a5d5b6adf92</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:de41415d9348a36c922c291938427f38e3b1053b;origin=https://gitlab.cs.duke.edu/bartesaghilab/smartscopeAI;visit=swh:1:snp:a379ed609f0524baf6fe0eee0facba6b3cf6aa47;anchor=swh:1:rev:43b29ae8c333a94463e0a4d9ecb97a5d5b6adf92">https://archive.softwareheritage.org/swh:1:dir:de41415d9348a36c922c291938427f38e3b1053b;origin=https://gitlab.cs.duke.edu/bartesaghilab/smartscopeAI;visit=swh:1:snp:a379ed609f0524baf6fe0eee0facba6b3cf6aa47;anchor=swh:1:rev:43b29ae8c333a94463e0a4d9ecb97a5d5b6adf92</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>A</given-names></name><name><surname>Eng</surname><given-names>ET</given-names></name><name><surname>Alink</surname><given-names>L</given-names></name><name><surname>Rice</surname><given-names>WJ</given-names></name><name><surname>Jordan</surname><given-names>KD</given-names></name><name><surname>Kim</surname><given-names>LY</given-names></name><name><surname>Potter</surname><given-names>CS</given-names></name><name><surname>Carragher</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>High resolution single particle cryo-electron microscopy using beam-image shift</article-title><source>Journal of Structural Biology</source><volume>204</volume><fpage>270</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1016/j.jsb.2018.07.015</pub-id><pub-id pub-id-type="pmid">30055234</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>L</given-names></name><name><surname>Kim</surname><given-names>S</given-names></name><name><surname>Farr</surname><given-names>CL</given-names></name><name><surname>Schaefer</surname><given-names>KT</given-names></name><name><surname>Randolph</surname><given-names>KM</given-names></name><name><surname>Tainer</surname><given-names>JA</given-names></name><name><surname>Kaguni</surname><given-names>LS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A novel processive mechanism for DNA synthesis revealed by structure, modeling and mutagenesis of the accessory subunit of human mitochondrial DNA polymerase</article-title><source>Journal of Molecular Biology</source><volume>358</volume><fpage>1229</fpage><lpage>1243</lpage><pub-id pub-id-type="doi">10.1016/j.jmb.2006.02.073</pub-id><pub-id pub-id-type="pmid">16574152</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Yao</surname><given-names>Y</given-names></name><name><surname>Cohn</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Vos</surname><given-names>SM</given-names></name><name><surname>Cianfrocco</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>CryoRL: Reinforcement Learning Enables Efficient Cryo-EM Data Collection</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2204.07543v1">https://arxiv.org/abs/2204.07543v1</ext-link></element-citation></ref><ref id="bib6"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Girshick</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Fast R-CNN</article-title><conf-name>2015 IEEE International Conference on Computer Vision (ICCV</conf-name><conf-loc>Santiago, Chile</conf-loc><pub-id pub-id-type="doi">10.1109/ICCV.2015.169</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jocher</surname><given-names>GR</given-names></name><name><surname>Stoken</surname><given-names>A</given-names></name><name><surname>Borovec</surname><given-names>J</given-names></name><name><surname>Claramunt</surname><given-names>ER</given-names></name><name><surname>Changyu</surname><given-names>L</given-names></name><name><surname>hopesala</surname><given-names>DP</given-names></name><collab>NanoCode, ChristopherSTAN</collab></person-group><year iso-8601-date="2020">2020</year><data-title>ultralytics/yolov5</data-title><version designator="v3.0">v3.0</version><source>Ultralytics/Yolov5</source></element-citation></ref><ref id="bib8"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>PT</given-names></name><name><surname>Noble</surname><given-names>AJ</given-names></name><name><surname>Cheng</surname><given-names>A</given-names></name><name><surname>Bepler</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning to Automate Cryo-Electron Microscopy Data Collection with Ptolemy</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2112.01534">https://arxiv.org/abs/2112.01534</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kremer</surname><given-names>JR</given-names></name><name><surname>Mastronarde</surname><given-names>DN</given-names></name><name><surname>McIntosh</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Computer visualization of three-dimensional image data using IMOD</article-title><source>Journal of Structural Biology</source><volume>116</volume><fpage>71</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1006/jsbi.1996.0013</pub-id><pub-id pub-id-type="pmid">8742726</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lander</surname><given-names>GC</given-names></name><name><surname>Stagg</surname><given-names>SM</given-names></name><name><surname>Voss</surname><given-names>NR</given-names></name><name><surname>Cheng</surname><given-names>A</given-names></name><name><surname>Fellmann</surname><given-names>D</given-names></name><name><surname>Pulokas</surname><given-names>J</given-names></name><name><surname>Yoshioka</surname><given-names>C</given-names></name><name><surname>Irving</surname><given-names>C</given-names></name><name><surname>Mulder</surname><given-names>A</given-names></name><name><surname>Lau</surname><given-names>PW</given-names></name><name><surname>Lyumkis</surname><given-names>D</given-names></name><name><surname>Potter</surname><given-names>CS</given-names></name><name><surname>Carragher</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Appion: an integrated, database-driven pipeline to facilitate EM image processing</article-title><source>Journal of Structural Biology</source><volume>166</volume><fpage>95</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/j.jsb.2009.01.002</pub-id><pub-id pub-id-type="pmid">19263523</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastronarde</surname><given-names>DN</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Automated electron microscope tomography using robust prediction of specimen movements</article-title><source>Journal of Structural Biology</source><volume>152</volume><fpage>36</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1016/j.jsb.2005.07.007</pub-id><pub-id pub-id-type="pmid">16182563</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noble</surname><given-names>AJ</given-names></name><name><surname>Dandey</surname><given-names>VP</given-names></name><name><surname>Wei</surname><given-names>H</given-names></name><name><surname>Brasch</surname><given-names>J</given-names></name><name><surname>Chase</surname><given-names>J</given-names></name><name><surname>Acharya</surname><given-names>P</given-names></name><name><surname>Tan</surname><given-names>YZ</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Kim</surname><given-names>LY</given-names></name><name><surname>Scapin</surname><given-names>G</given-names></name><name><surname>Rapp</surname><given-names>M</given-names></name><name><surname>Eng</surname><given-names>ET</given-names></name><name><surname>Rice</surname><given-names>WJ</given-names></name><name><surname>Cheng</surname><given-names>A</given-names></name><name><surname>Negro</surname><given-names>CJ</given-names></name><name><surname>Shapiro</surname><given-names>L</given-names></name><name><surname>Kwong</surname><given-names>PD</given-names></name><name><surname>Jeruzalmi</surname><given-names>D</given-names></name><name><surname>des Georges</surname><given-names>A</given-names></name><name><surname>Potter</surname><given-names>CS</given-names></name><name><surname>Carragher</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Routine single particle CryoEM sample and grid characterization by tomography</article-title><source>eLife</source><volume>7</volume><elocation-id>e34257</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34257</pub-id><pub-id pub-id-type="pmid">29809143</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Passmore</surname><given-names>LA</given-names></name><name><surname>Russo</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><chapter-title>Specimen Preparation for High-Resolution Cryo-EM</chapter-title><person-group person-group-type="editor"><name><surname>Passmore</surname><given-names>LA</given-names></name></person-group><source>Methods in Enzymology, The Resolution Revolution: Recent Advances In CryoEM</source><publisher-name>Academic Press</publisher-name><fpage>51</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1016/bs.mie.2016.04.011</pub-id><pub-id pub-id-type="pmid">27572723</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pettersen</surname><given-names>EF</given-names></name><name><surname>Goddard</surname><given-names>TD</given-names></name><name><surname>Huang</surname><given-names>CC</given-names></name><name><surname>Couch</surname><given-names>GS</given-names></name><name><surname>Greenblatt</surname><given-names>DM</given-names></name><name><surname>Meng</surname><given-names>EC</given-names></name><name><surname>Ferrin</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>UCSF Chimera--A visualization system for exploratory research and analysis</article-title><source>Journal of Computational Chemistry</source><volume>25</volume><fpage>1605</fpage><lpage>1612</lpage><pub-id pub-id-type="doi">10.1002/jcc.20084</pub-id><pub-id pub-id-type="pmid">15264254</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Punjani</surname><given-names>A</given-names></name><name><surname>Rubinstein</surname><given-names>JL</given-names></name><name><surname>Fleet</surname><given-names>DJ</given-names></name><name><surname>Brubaker</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>cryoSPARC: algorithms for rapid unsupervised cryo-EM structure determination</article-title><source>Nature Methods</source><volume>14</volume><fpage>290</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4169</pub-id><pub-id pub-id-type="pmid">28165473</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Redmon</surname><given-names>J</given-names></name><name><surname>Divvala</surname><given-names>S</given-names></name><name><surname>Girshick</surname><given-names>R</given-names></name><name><surname>Farhadi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>You Only Look Once: Unified, Real-Time Object Detection</article-title><conf-name>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR</conf-name><conf-loc>Las Vegas, NV, USA</conf-loc><pub-id pub-id-type="doi">10.1109/CVPR.2016.91</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rheinberger</surname><given-names>J</given-names></name><name><surname>Oostergetel</surname><given-names>G</given-names></name><name><surname>Resch</surname><given-names>GP</given-names></name><name><surname>Paulino</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Optimized cryo-EM data-acquisition workflow by sample-thickness determination</article-title><source>Acta Crystallographica. Section D, Structural Biology</source><volume>77</volume><fpage>565</fpage><lpage>571</lpage><pub-id pub-id-type="doi">10.1107/S205979832100334X</pub-id><pub-id pub-id-type="pmid">33950013</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohou</surname><given-names>A</given-names></name><name><surname>Grigorieff</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>CTFFIND4: Fast and accurate defocus estimation from electron micrographs</article-title><source>Journal of Structural Biology</source><volume>192</volume><fpage>216</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1016/j.jsb.2015.08.008</pub-id><pub-id pub-id-type="pmid">26278980</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Garcia</surname><given-names>R</given-names></name><name><surname>Gomez-Blanco</surname><given-names>J</given-names></name><name><surname>Cuervo</surname><given-names>A</given-names></name><name><surname>Carazo</surname><given-names>JM</given-names></name><name><surname>Sorzano</surname><given-names>COS</given-names></name><name><surname>Vargas</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>DeepEMhancer: a deep learning solution for cryo-EM volume post-processing</article-title><source>Communications Biology</source><volume>4</volume><elocation-id>e874</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-021-02399-1</pub-id><pub-id pub-id-type="pmid">34267316</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schorb</surname><given-names>M</given-names></name><name><surname>Haberbosch</surname><given-names>I</given-names></name><name><surname>Hagen</surname><given-names>WJH</given-names></name><name><surname>Schwab</surname><given-names>Y</given-names></name><name><surname>Mastronarde</surname><given-names>DN</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Software tools for automated transmission electron microscopy</article-title><source>Nature Methods</source><volume>16</volume><fpage>471</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0396-9</pub-id><pub-id pub-id-type="pmid">31086343</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suloway</surname><given-names>C</given-names></name><name><surname>Pulokas</surname><given-names>J</given-names></name><name><surname>Fellmann</surname><given-names>D</given-names></name><name><surname>Cheng</surname><given-names>A</given-names></name><name><surname>Guerra</surname><given-names>F</given-names></name><name><surname>Quispe</surname><given-names>J</given-names></name><name><surname>Stagg</surname><given-names>S</given-names></name><name><surname>Potter</surname><given-names>CS</given-names></name><name><surname>Carragher</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Automated molecular microscopy: the new Leginon system</article-title><source>Journal of Structural Biology</source><volume>151</volume><fpage>41</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.jsb.2005.03.010</pub-id><pub-id pub-id-type="pmid">15890530</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>YZ</given-names></name><name><surname>Baldwin</surname><given-names>PR</given-names></name><name><surname>Davis</surname><given-names>JH</given-names></name><name><surname>Williamson</surname><given-names>JR</given-names></name><name><surname>Potter</surname><given-names>CS</given-names></name><name><surname>Carragher</surname><given-names>B</given-names></name><name><surname>Lyumkis</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Addressing preferred specimen orientation in single-particle cryo-EM through tilting</article-title><source>Nature Methods</source><volume>14</volume><fpage>793</fpage><lpage>796</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4347</pub-id><pub-id pub-id-type="pmid">28671674</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C-Y</given-names></name><name><surname>Mark Liao</surname><given-names>H-Y</given-names></name><name><surname>Wu</surname><given-names>Y-H</given-names></name><name><surname>Chen</surname><given-names>P-Y</given-names></name><name><surname>Hsieh</surname><given-names>J-W</given-names></name><name><surname>Yeh</surname><given-names>I-H</given-names></name></person-group><article-title>CSPNet: A New Backbone that can Enhance Learning Capability of CNN</article-title><conf-name>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW).</conf-name><year iso-8601-date="2019">2019</year><conf-loc>Seattle, WA, USA</conf-loc><ext-link ext-link-type="uri" xlink:href="https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=9142289">https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=9142289</ext-link><pub-id pub-id-type="doi">10.1109/CVPRW50498.2020.00203</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weissenberger</surname><given-names>G</given-names></name><name><surname>Henderikx</surname><given-names>RJM</given-names></name><name><surname>Peters</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Understanding the invisible hands of sample preparation for cryo-EM</article-title><source>Nature Methods</source><volume>18</volume><fpage>463</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1038/s41592-021-01130-6</pub-id><pub-id pub-id-type="pmid">33963356</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Kirillov</surname><given-names>A</given-names></name><name><surname>Massa</surname><given-names>F</given-names></name><name><surname>Lo</surname><given-names>WY</given-names></name><name><surname>Girshick</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Detectron2</data-title><source>Detectron2</source><ext-link ext-link-type="uri" xlink:href="https://github.com/facebookresearch/detectron2">https://github.com/facebookresearch/detectron2</ext-link></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Timm</surname><given-names>DE</given-names></name><name><surname>Elhabian</surname><given-names>SY</given-names></name></person-group><year iso-8601-date="2020">2020</year><chapter-title>Attention-Guided Quality Assessment for Automated Cryo-EM Grid Screening</chapter-title><person-group person-group-type="editor"><name><surname>Martel</surname><given-names>AL</given-names></name><name><surname>Abolmaesumi</surname><given-names>P</given-names></name><name><surname>Stoyanov</surname><given-names>D</given-names></name><name><surname>Mateus</surname><given-names>D</given-names></name><name><surname>Zuluaga</surname><given-names>MA</given-names></name><name><surname>Zhou</surname><given-names>SK</given-names></name><name><surname>Racoceanu</surname><given-names>D</given-names></name><name><surname>Joskowicz</surname><given-names>L</given-names></name></person-group><source>Medical Image Computing and Computer Assisted Intervention – MICCAI 2020, Lecture Notes in Computer Science</source><publisher-loc>Cham</publisher-loc><publisher-name>Springer International Publishing</publisher-name><fpage>56</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-59722-1_6</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yokoyama</surname><given-names>Y</given-names></name><name><surname>Terada</surname><given-names>T</given-names></name><name><surname>Shimizu</surname><given-names>K</given-names></name><name><surname>Nishikawa</surname><given-names>K</given-names></name><name><surname>Kozai</surname><given-names>D</given-names></name><name><surname>Shimada</surname><given-names>A</given-names></name><name><surname>Mizoguchi</surname><given-names>A</given-names></name><name><surname>Fujiyoshi</surname><given-names>Y</given-names></name><name><surname>Tani</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Development of a deep learning-based method to identify “good” regions of a cryo-electron microscopy grid</article-title><source>Biophysical Reviews</source><volume>12</volume><fpage>349</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1007/s12551-020-00669-6</pub-id><pub-id pub-id-type="pmid">32162215</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonekura</surname><given-names>K</given-names></name><name><surname>Maki-Yonekura</surname><given-names>S</given-names></name><name><surname>Naitow</surname><given-names>H</given-names></name><name><surname>Hamaguchi</surname><given-names>T</given-names></name><name><surname>Takaba</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Machine learning-based real-time object locator/evaluator for cryo-EM data collection</article-title><source>Communications Biology</source><volume>4</volume><elocation-id>e1044</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-021-02577-1</pub-id><pub-id pub-id-type="pmid">34493805</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Young</surname><given-names>MJ</given-names></name><name><surname>Copeland</surname><given-names>WC</given-names></name></person-group><year iso-8601-date="2013">2013</year><chapter-title>Mitochondrial Disorders Associated with the Mitochondrial DNA Polymerase g: A Focus on Intersubunit Interactions</chapter-title><person-group person-group-type="editor"><name><surname>Wong</surname><given-names>LJC</given-names></name></person-group><source>Mitochondrial Disorders Caused by Nuclear Genes</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer</publisher-name><fpage>49</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1007/978-1-4614-3722-2_3</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>MJ</given-names></name><name><surname>Humble</surname><given-names>MM</given-names></name><name><surname>DeBalsi</surname><given-names>KL</given-names></name><name><surname>Sun</surname><given-names>KY</given-names></name><name><surname>Copeland</surname><given-names>WC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>POLG2 disease variants: analyses reveal a dominant negative heterodimer, altered mitochondrial localization and impaired respiratory capacity</article-title><source>Human Molecular Genetics</source><volume>24</volume><fpage>5184</fpage><lpage>5197</lpage><pub-id pub-id-type="doi">10.1093/hmg/ddv240</pub-id><pub-id pub-id-type="pmid">26123486</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>SmartScope: Framework for unsupervised cryo-EM imaging</title><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Input parameters for a SmartScope session.</title><p>Parameter names and their description. This is presented as a form on the web interface. These parameters can also be updated during the imaging process.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter name</th><th align="left" valign="bottom">Description</th></tr><tr><th align="left" valign="bottom" colspan="2">General session parameters</th></tr></thead><tbody><tr><td align="left" valign="bottom">Session name</td><td align="left" valign="bottom">Name of the microscopy session</td></tr><tr><td align="left" valign="bottom">Group</td><td align="left" valign="bottom">Group name of the microscopy session. Usually the principal investigator’s name</td></tr><tr><td align="left" valign="bottom">Microscope</td><td align="left" valign="bottom">Microscope being used for the session</td></tr><tr><td align="left" valign="bottom">Detector</td><td align="left" valign="bottom">Detector being used for the session</td></tr><tr><th align="left" valign="bottom" colspan="2">Collection parameters</th></tr><tr><td align="left" valign="bottom">Atlas X</td><td align="left" valign="bottom">Number of tiles for the Atlas acquisition in X axis (default: 3)</td></tr><tr><td align="left" valign="bottom">Atlas Y</td><td align="left" valign="bottom">Number of tiles for the Atlas acquisition in Y axis (default: 3)</td></tr><tr><td align="left" valign="bottom">Square X</td><td align="left" valign="bottom">Number of tiles for the window acquisition in X axis (default: 1)</td></tr><tr><td align="left" valign="bottom">Square Y</td><td align="left" valign="bottom">Number of tiles for the window acquisition in the Y axis (default: 1)</td></tr><tr><td align="left" valign="bottom">Squares num</td><td align="left" valign="bottom">Number of windows to be selected for high-magnification imaging (default: 3)</td></tr><tr><td align="left" valign="bottom">Holes per square</td><td align="left" valign="bottom">Number of targets per windows to be selected for higher-magnification imaging. If 0 is entered, all targets will be selected and data collection mode will be enabled (default: 3)</td></tr><tr><td align="left" valign="bottom">BIS max distance</td><td align="left" valign="bottom">Beam-Image shift grouping radius in microns (default: 0)</td></tr><tr><td align="left" valign="bottom">Min BIS group size</td><td align="left" valign="bottom">Smallest Beam-Image shift group size to be considered (default: 1)</td></tr><tr><td align="left" valign="bottom">Target defocus min</td><td align="left" valign="bottom">Lower end of the defocus range for rolling defocus in microns (default: –2)</td></tr><tr><td align="left" valign="bottom">Target defocus max</td><td align="left" valign="bottom">Higher end of the defocus range for rolling defocus in microns (default: –2)</td></tr><tr><td align="left" valign="bottom">Defocus step</td><td align="left" valign="bottom">Step by which the defocus is varied between each target group (default: 0)</td></tr><tr><td align="left" valign="bottom">Drift crit</td><td align="left" valign="bottom">Drift threshold to be met during the drift settling procedure before proceeding with high-magnification imaging. Use –1 to disable (default: –1)</td></tr><tr><td align="left" valign="bottom">Tilt angle</td><td align="left" valign="bottom">Tilt angle to use for high-magnification imaging. Works with BIS enabled (default: 0)</td></tr><tr><td align="left" valign="bottom">Save frames</td><td align="left" valign="bottom">Whether to save the movie frames or return aligned sum (default: Saving enabled)</td></tr><tr><td align="left" valign="bottom">Zeroloss delay</td><td align="left" valign="bottom">Time delay in hours for zero loss peak refinement. Only useful if the microscope has an energy filter. Use –1 to deactivate (default: –1)</td></tr><tr><td align="left" valign="bottom">Offset targeting</td><td align="left" valign="bottom">Enable random targeting off-center to sample the ice gradient and carbon mesh particles. Automatically disabled in data collection mode (default: enabled)</td></tr><tr><td align="left" valign="bottom">Offset distance</td><td align="left" valign="bottom">Override the random offset by an absolute value in microns. Can be used in data collection mode. Use –1 to disable (default: disabled)</td></tr><tr><th align="left" valign="bottom" colspan="2">Autoloader (1 per grid)</th></tr><tr><td align="left" valign="bottom">Name</td><td align="left" valign="bottom">Name of the grid</td></tr><tr><td align="left" valign="bottom">Position</td><td align="left" valign="bottom">Position in the autoloader</td></tr><tr><td align="left" valign="bottom">Hole type</td><td align="left" valign="bottom">Grid hole spacing type (i.e. R1.2/1.3)</td></tr><tr><td align="left" valign="bottom">Mesh size</td><td align="left" valign="bottom">Grid mesh size and spacing (i.e. 300)</td></tr><tr><td align="left" valign="bottom">Mesh material</td><td align="left" valign="bottom">Grid mesh material (i.e. carbon or gold)</td></tr></tbody></table></table-wrap><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>Examples of SerialEM settings for SmartScope usage.</title><p>These settings serve as guidelines and will need to be adapted for different hardware combinations. Updated versions of this table can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/NIEHS/SmartScope">github.com/NIEHS/SmartScope</ext-link>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom">Example 1</th><th align="left" valign="bottom">Example 2</th></tr><tr><th align="left" valign="bottom">Instrument</th><th align="center" valign="bottom"/><th align="center" valign="bottom"/></tr></thead><tbody><tr><td align="left" valign="bottom">Microscope</td><td align="left" valign="bottom">Talos Arctica</td><td align="left" valign="bottom">Titan Krios G4</td></tr><tr><td align="left" valign="bottom">Detector</td><td align="left" valign="bottom">Gatan K2 Summit</td><td align="left" valign="bottom">Gatan K3</td></tr><tr><td align="left" valign="bottom">Energy filter</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">Gatan BioContiuum</td></tr><tr><th align="left" valign="bottom" colspan="3">Low Dose Presets</th></tr><tr><th align="left" valign="bottom" colspan="3">Search</th></tr><tr><td align="left" valign="bottom">Magnification</td><td align="left" valign="bottom">210</td><td align="left" valign="bottom">580</td></tr><tr><td align="left" valign="bottom">Pixel size (Å/pixel)</td><td align="left" valign="bottom">196</td><td align="left" valign="bottom">152</td></tr><tr><td align="left" valign="bottom">Mode</td><td align="left" valign="bottom">Linear</td><td align="left" valign="bottom">Counting</td></tr><tr><th align="left" valign="bottom" colspan="3">View</th></tr><tr><td align="left" valign="bottom">Magnification</td><td align="left" valign="bottom">2600</td><td align="left" valign="bottom">8700</td></tr><tr><td align="left" valign="bottom">Pixel size (Å/pixel)</td><td align="left" valign="bottom">16.1</td><td align="left" valign="bottom">10.1</td></tr><tr><td align="left" valign="bottom">Mode</td><td align="left" valign="bottom">Linear</td><td align="left" valign="bottom">Counting</td></tr><tr><th align="left" valign="bottom" colspan="3">Focus/record</th></tr><tr><td align="left" valign="bottom">Magnification<xref ref-type="table-fn" rid="app1table2fn1">*</xref></td><td align="left" valign="bottom">36,000</td><td align="left" valign="bottom">81,000</td></tr><tr><td align="left" valign="bottom">Pixel size (Å/pixel)<xref ref-type="table-fn" rid="app1table2fn1">*</xref></td><td align="left" valign="bottom">1.19</td><td align="left" valign="bottom">1.08</td></tr><tr><td align="left" valign="bottom">Mode</td><td align="left" valign="bottom">Counting</td><td align="left" valign="bottom">Counting</td></tr><tr><th align="left" valign="bottom" colspan="2">Full grid montage presets</th><th align="center" valign="bottom"/></tr><tr><td align="left" valign="bottom">Magnification</td><td align="left" valign="bottom">62</td><td align="left" valign="bottom">135</td></tr><tr><td align="left" valign="bottom">Pixel size (Å/pix)</td><td align="left" valign="bottom">644</td><td align="left" valign="bottom">654</td></tr><tr><td align="left" valign="bottom">Mode</td><td align="left" valign="bottom">Linear</td><td align="left" valign="bottom">Counting</td></tr></tbody></table><table-wrap-foot><fn id="app1table2fn1"><label>*</label><p>These are the presets that are used for screening. They can be changes to suit the requirement for the specimen.</p></fn></table-wrap-foot></table-wrap><table-wrap id="app1table3" position="float"><label>Appendix 1—table 3.</label><caption><title>Average precision obtained for each type of grid square.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Feature type</th><th align="left" valign="bottom">Small</th><th align="left" valign="bottom">Cracked</th><th align="left" valign="bottom">Dry</th><th align="left" valign="bottom">Contaminated</th><th align="left" valign="bottom">Good</th><th align="left" valign="bottom">Partial</th></tr></thead><tbody><tr><td align="left" valign="bottom">Without augmentation</td><td align="center" valign="bottom">65.7%</td><td align="center" valign="bottom">71.6%</td><td align="center" valign="bottom">77.9%</td><td align="center" valign="bottom">46.7%</td><td align="center" valign="bottom">77.7%</td><td align="center" valign="bottom">45.0%</td></tr><tr><td align="left" valign="bottom">With augmentation</td><td align="center" valign="bottom">73.4%</td><td align="center" valign="bottom">76.5%</td><td align="center" valign="bottom">79.4%</td><td align="center" valign="bottom">50.41%</td><td align="center" valign="bottom">81.2 %</td><td align="center" valign="bottom">45.5%</td></tr></tbody></table></table-wrap><table-wrap id="app1table4" position="float"><label>Appendix 1—table 4.</label><caption><title>Smartscope screening mode statistics.</title><p>All grids were collected using a K2 detector. The default parameters for screening mode are a 9-tile atlas, 3 squares and 3 holes per square.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Total specimens = 981</th><th align="left" valign="top">min</th><th align="left" valign="top">max</th><th align="left" valign="top">mean</th><th align="left" valign="top">median</th><th align="left" valign="top">standard deviation</th></tr></thead><tbody><tr><td align="left" valign="top">Squares sampled</td><td align="char" char="." valign="top">0</td><td align="char" char="." valign="top">7</td><td align="char" char="." valign="top">2.5</td><td align="char" char="." valign="top">3.0</td><td align="char" char="." valign="top">1.3</td></tr><tr><td align="left" valign="top">Holes sampled</td><td align="char" char="." valign="top">0</td><td align="char" char="." valign="top">33</td><td align="char" char="." valign="top">8.0</td><td align="char" char="." valign="top">9.0</td><td align="char" char="." valign="top">5.0</td></tr><tr><td align="left" valign="top">Time spent on specimen (min)</td><td align="char" char="." valign="top">3.0</td><td align="char" char="." valign="top">56.3</td><td align="char" char="." valign="top">21.0</td><td align="char" char="." valign="top">20.9</td><td align="char" char="." valign="top">8.4</td></tr></tbody></table></table-wrap><table-wrap id="app1table5" position="float"><label>Appendix 1—table 5.</label><caption><title>Smartscope screening mode statistics excluding specimens with no usable or visible squares.</title><p>All grids were collected using a K2 detector. The default parameters for screening mode are a 9-tile atlas, 3 squares and 3 holes per square.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Total specimens = 772</th><th align="left" valign="bottom">min</th><th align="left" valign="bottom">max</th><th align="left" valign="bottom">mean</th><th align="left" valign="bottom">median</th><th align="left" valign="bottom">standard deviation</th></tr></thead><tbody><tr><td align="left" valign="bottom">Square sampled</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">7</td><td align="char" char="." valign="bottom">3.0</td><td align="char" char="." valign="bottom">3.0</td><td align="char" char="." valign="bottom">0.9</td></tr><tr><td align="left" valign="bottom">Hole sampled</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">33</td><td align="char" char="." valign="bottom">9.4</td><td align="char" char="." valign="bottom">9.0</td><td align="char" char="." valign="bottom">4.0</td></tr><tr><td align="left" valign="bottom">Time spent on specimen (min)</td><td align="char" char="." valign="bottom">9.1</td><td align="char" char="." valign="bottom">56.3</td><td align="char" char="." valign="bottom">23.0</td><td align="char" char="." valign="bottom">21.7</td><td align="char" char="." valign="bottom">6.7</td></tr></tbody></table></table-wrap><table-wrap id="app1table6" position="float"><label>Appendix 1—table 6.</label><caption><title>Smartscope data collection mode statistics.</title><p>Start times are at the start of specimen loading in the column. All grids were imaged using a K2 detector.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Total specimens = 58</th><th align="left" valign="bottom">min</th><th align="left" valign="bottom">max</th><th align="left" valign="bottom">median</th><th align="left" valign="bottom">mean ± SD</th></tr></thead><tbody><tr><td align="left" valign="bottom">Total micrographs</td><td align="left" valign="bottom">565</td><td align="left" valign="bottom">8333</td><td align="left" valign="bottom">1626</td><td align="left" valign="bottom">2155±1502</td></tr><tr><td align="left" valign="bottom">Holes per hour</td><td align="left" valign="bottom">51</td><td align="left" valign="bottom">141</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">100±22</td></tr><tr><td align="left" valign="bottom">Data collection setup time (min)<xref ref-type="table-fn" rid="app1table6fn1">*</xref></td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">80</td><td align="left" valign="bottom">32</td><td align="left" valign="bottom">34±17</td></tr><tr><td align="left" valign="bottom">Setup time per 1000 micrographs (min)</td><td align="left" valign="bottom">4</td><td align="left" valign="bottom">55</td><td align="left" valign="bottom">17</td><td align="left" valign="bottom">19±11</td></tr></tbody></table><table-wrap-foot><fn id="app1table6fn1"><label>*</label><p>Data collection times are calculated as the time needed from grid loading to the collection of the first 50 high-magnification targets minus the time required for these 50 targets to be acquired.</p></fn></table-wrap-foot></table-wrap></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80047.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Scheres</surname><given-names>Sjors HW</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00tw3jy02</institution-id><institution>MRC Laboratory of Molecular Biology</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.05.05.490801" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.05.05.490801"/></front-stub><body><p>This paper describes a new software tool: SmartScope, for automated screening of cryo-EM grids. SmartScope can also perform automated data collection on suitable grids, including with beam-image shifts and tilted stage geometries. If it works in practice as advertised in the paper, then it will be a highly useful tool for the field, especially if other groups would also contribute to its open-source and modular code.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80047.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Scheres</surname><given-names>Sjors HW</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00tw3jy02</institution-id><institution>MRC Laboratory of Molecular Biology</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Scheres</surname><given-names>Sjors HW</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00tw3jy02</institution-id><institution>MRC Laboratory of Molecular Biology</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Jakobi</surname><given-names>Arjen J</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02e2c7k09</institution-id><institution>Delft University of Technology</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.05.05.490801">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.05.05.490801v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Automated systematic evaluation of cryo-EM specimens with SmartScope&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Sjors HW Scheres as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by a Reviewing Editor and Kenton Swartz as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Arjen J Jakobi (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>All three reviewers agreed that the software described in this paper would be a highly useful addition to the field and are in support of publication.</p><p>1) A table summarising the data acquisition parameters and data collection statistics should be provided.</p><p>Strong encouragements:</p><p>1) The reviewers praise the authors for their intention to make the code available to the community and encourage them to do so as soon as possible.</p><p>2) Besides providing the source of the smartScope program on github, the authors are also encouraged to provide the labelled raw training data for the convolutional neural networks. Public repositories like Zenodo or EMPIAR could be used.</p><p>3) The 3 reviewers each make useful suggestions to improve the manuscript below. Although these are not essential for acceptance, the authors are encouraged to give this serious consideration.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>All Supplementary Figures should become supplements to one of the main figures.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The paper is in my opinion very well structured with clear figures and procedure steps. In general, I really enjoyed reading it and I am willing to test it soon. Of course, a work of this type passes the real test when it starts being used by the community. I believe that SmartScope will be used as there are no other fully automated solutions for grid screening.</p><p>From the description in the text, the software appears to be quite solid and the authors have pretty much answered in the text itself any questions that were coming to my mind while reading. In short, this manuscript is very detailed, easy to follow in a logical mind flow, and takes into consideration all aspects of specimen screening and data acquisition. From my side, the article is publishable as it is.</p><p>Some more detailed comments:</p><p>Line 143: SmartFlow is bound to serialEM, will it be possible to couple it to EPU for example, which is widely used, or other software used for the collection of diffraction data? How dependent is on serialEM 4.0? Will SmartScope be maintained as serialEM develops?</p><p>Line 153: Is there a minimal magnification that has to be used for the window clustering to work properly? Can the authors include some comments/guidelines on this?</p><p>Line 175: Do I understand correctly that some images are also taken in the carbon, or at the carbon/ice interface to evaluate the distribution of particles?</p><p>Line 179: I would simplify the procedure to gain time, at least for relatively short exposure times. Probably not in all cases frames alignment and CTF estimation are necessary, to view the stability of the new microscopes equipped with autoloader. However, it is probably better to have these options while running the automatic screening e.g. overnight.</p><p>Line 221: Out of full completeness the authors might comment on how their algorithm to maximise target coverage while minimising numbers of groups compares to the same procedure in EPU. There the BIS applied can be changed. Is that possible in SmartScope?</p><p>The fact that SmartScope can perform BIS collection on tilted specimens in a correct way is great.</p><p>For the evaluation of the network organisation part, I have asked the opinion of an expert colleague, who commented:</p><p>Line 237: I don't quite understand what the authors mean with: &quot;bundles a webserver and the main imaging workflow&quot;. I assume the webserver is for interacting with the program and the &quot;main imaging workflow&quot; is what runs on the worker if installed on separate computers, but it would be better to make it a bit more clear.</p><p>The Singularity container image is convenient and good that it's versatile enough to be installed on separate systems.</p><p>Line 245: Why do both the web server and the worker need to have access to a shared disk? Does the worker write and the web server only reads the results to display to the user? What kind of information is stored in the database?</p><p>248: The object store can be accessed via the Amazon S3 API. It's a nice feature for exporting data to &quot;the cloud&quot;. Maybe the author should clarify a bit what are the full advantages that one can get from such a setup?</p><p>Supplementary 43: &quot;communicate with each other using Socket or SSH connections&quot; Do they mean HTTP? In the graph, there is no mention of SSH connections, only HTTP.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>Points for consideration:</p><p>– The introduction describes many important concepts and limitations in the preparation of cryo-EM specimens and in screening/data collection, but only sparsely cites, and if, very general reviews on these topics. The reader may benefit if the authors would more specifically refer to the excellent primary literature on these topics.</p><p>– In addition to their YOLO-based hole finder, the authors may consider mentioning that the open and modular approach of their software allows integration with approaches such as e.g. virtual maps in Py-EM, which could extend the reach of their method to more sophisticated screening/targeting scenarios and different sample supports.</p><p>– The micrograph pre-processing routines implemented in SmartScope currently involve frame alignment and CTF estimation. The authors may consider including the possibility of image denoising workflows such as those implemented in data pre-processing pipelines (Warp, Scipion, SPHIRE, CryoSparc Live, …), which can be useful tools for rapid selection of suitable imaging areas, in particular if particles are small.</p><p>– The authors comment on the screening mode statistics from the operation of SmartScope in their facility. From their facility projects, are there statistics available on how many cases the screening procedure followed by automated, targeted data collection lead to successful structure determination, and how this compares to manual screening and subjective targeting on the same sample? This could be insightful.</p><p>– The authors mention that data collection of human mitochondrial DNA polymerase involved tilting of the specimen in a subset of the dataset to improve angular sampling. It would be useful to show angular distribution plots for the data excluding and including the tilted images to illustrate this was required and how automation by SmartScope can help detect and mitigate such problems on the fly.</p><p>– A table summarising the data acquisition parameters and data collection statistics should be provided.</p><p>– It is laudable that the authors make their software and models publicly available. It would be more useful to have the repository public open at the moment of preprint posting so as to give reviewers the possibility to also screen review code. The data availability statement contains a remark of disclosure of data upon reasonable request. It is unclear what this statement means, and which requests are considered reasonable; these data can be useful for other academic projects following related but complementary approaches, as well as comparison and benchmarking. I encourage the authors to make raw ML data available through public repositories such as Zenodo, and to deposit raw micrographs at EMPIAR.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80047.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>All three reviewers agreed that the software described in this paper would be a highly useful addition to the field and are in support of publication.</p></disp-quote><p>We appreciate the support of the reviewers.</p><disp-quote content-type="editor-comment"><p>1) A table summarising the data acquisition parameters and data collection statistics should be provided.</p></disp-quote><p>Thank you for pointing this out, we have added this information in the new table1.</p><disp-quote content-type="editor-comment"><p>Strong encouragements:</p><p>1) The reviewers praise the authors for their intention to make the code available to the community and encourage them to do so as soon as possible.</p></disp-quote><p>Thank you. The code will be made available immediately when the manuscript becomes live. The Code availability section now states that the code will be available and the corresponding github URL.</p><disp-quote content-type="editor-comment"><p>2) Besides providing the source of the smartScope program on github, the authors are also encouraged to provide the labelled raw training data for the convolutional neural networks. Public repositories like Zenodo or EMPIAR could be used.</p></disp-quote><p>Thanks for pointing this out, this was our intention from the beginning, which we considered implicit in committing to the publication of the code. The raw training data is now available on Zenodo. The data availability section of the manuscript has been modified to refer explicitly to the training datasets as well as to the trained model.</p><disp-quote content-type="editor-comment"><p>3) The 3 reviewers each make useful suggestions to improve the manuscript below. Although these are not essential for acceptance, the authors are encouraged to give this serious consideration.</p></disp-quote><p>We appreciate the suggestions and we have introduced changes guided by them.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>All Supplementary Figures should become supplements to one of the main figures.</p></disp-quote><p>We have reorganized the figures as requested.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>The paper is in my opinion very well structured with clear figures and procedure steps. In general, I really enjoyed reading it and I am willing to test it soon. Of course, a work of this type passes the real test when it starts being used by the community. I believe that SmartScope will be used as there are no other fully automated solutions for grid screening.</p><p>From the description in the text, the software appears to be quite solid and the authors have pretty much answered in the text itself any questions that were coming to my mind while reading. In short, this manuscript is very detailed, easy to follow in a logical mind flow, and takes into consideration all aspects of specimen screening and data acquisition. From my side, the article is publishable as it is.</p><p>Some more detailed comments:</p><p>Line 143: SmartFlow is bound to serialEM, will it be possible to couple it to EPU for example, which is widely used, or other software used for the collection of diffraction data? How dependent is on serialEM 4.0? Will SmartScope be maintained as serialEM develops?</p></disp-quote><p>Historically, SerialEM didn’t remove features so we expect that all the current scripting commands within SerialEM4.0 will exist for the foreseeable future. We are planning on making SmartScope a long-term solution where more features and updates will be added.</p><disp-quote content-type="editor-comment"><p>Line 153: Is there a minimal magnification that has to be used for the window clustering to work properly? Can the authors include some comments/guidelines on this?</p></disp-quote><p>We added a supplementary table 2 with the magnification/pixel sizes that have been used for acquiring the squares. The hole finder was also successfully tested on the low-mag atlas but is not part of the software yet.</p><disp-quote content-type="editor-comment"><p>Line 175: Do I understand correctly that some images are also taken in the carbon, or at the carbon/ice interface to evaluate the distribution of particles?</p></disp-quote><p>Intermediate magnification images always include carbon areas (for carbon grids naturally). The version that we tested for this version of the manuscript did not contemplate taking images of the interface at higher magnification. In a newer version, now available, random exploration of the hole area including the water carbon interface can be achieved by specifying an “offset” parameter from the center of the hole, we have amended the manuscript to reference this parameter. Future versions may include “smarter” exploration based on the analysis of intermediate resolution pictures.</p><disp-quote content-type="editor-comment"><p>Line 179: I would simplify the procedure to gain time, at least for relatively short exposure times. Probably not in all cases frames alignment and CTF estimation are necessary, to view the stability of the new microscopes equipped with autoloader. However, it is probably better to have these options while running the automatic screening e.g. overnight.</p></disp-quote><p>Frame alignment is not essential and will occur only when the exposure mode is set in SerialEM to save the frames. However, since these processes occur asynchronously from acquisition, movie alignment does not have an impact in the speed of imaging.</p><disp-quote content-type="editor-comment"><p>Line 221: Out of full completeness the authors might comment on how their algorithm to maximise target coverage while minimising numbers of groups compares to the same procedure in EPU. There the BIS applied can be changed. Is that possible in SmartScope?</p></disp-quote><p>SmartScope will group the targets according to an input BIS radius in the acquisition settings, which can be changed at any point during the session. A sentence was added in the manuscript to clarify this point. Interestingly, newer versions of EPU seem to have eliminated the user’s ability to modify this parameter in the GUI. The BIS (AFIS) radius in EPU can still be changed through parameter hidden in the global configuration files, but requires restarting the software. The comparison with the algorithm used in EPU is difficult as the code for EPU is not available.</p><disp-quote content-type="editor-comment"><p>The fact that SmartScope can perform BIS collection on tilted specimens in a correct way is great.</p><p>For the evaluation of the network organisation part, I have asked the opinion of an expert colleague, who commented:</p><p>Line 237: I don't quite understand what the authors mean with: &quot;bundles a webserver and the main imaging workflow&quot;. I assume the webserver is for interacting with the program and the &quot;main imaging workflow&quot; is what runs on the worker if installed on separate computers, but it would be better to make it a bit more clear.</p></disp-quote><p>We have reworked this section to improve clarity.</p><disp-quote content-type="editor-comment"><p>The Singularity container image is convenient and good that it's versatile enough to be installed on separate systems.</p><p>Line 245: Why do both the web server and the worker need to have access to a shared disk? Does the worker write and the web server only reads the results to display to the user? What kind of information is stored in the database?</p></disp-quote><p>Only metadata about the relationship between the images and their targets is stored in the database. All the images are served directly from disk. This helps in keeping the size of the database small.</p><disp-quote content-type="editor-comment"><p>248: The object store can be accessed via the Amazon S3 API. It's a nice feature for exporting data to &quot;the cloud&quot;. Maybe the author should clarify a bit what are the full advantages that one can get from such a setup?</p></disp-quote><p>This feature allows to set up mirror instance in the cloud to provide access to users who, for security reasons, may not have access to the resources behind a firewall. At this point, this instance is distinct from the system that allows navigation of the specimen in real time.</p><disp-quote content-type="editor-comment"><p>Supplementary 43: &quot;communicate with each other using Socket or SSH connections&quot; Do they mean HTTP? In the graph, there is no mention of SSH connections, only HTTP.</p></disp-quote><p>SSH has been added to the figure to match the description.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>Points for consideration:</p><p>– The introduction describes many important concepts and limitations in the preparation of cryo-EM specimens and in screening/data collection, but only sparsely cites, and if, very general reviews on these topics. The reader may benefit if the authors would more specifically refer to the excellent primary literature on these topics.</p></disp-quote><p>Heeding the request of Reviewer #1, we have shortened significantly the introduction removing most of the discussion on the difficulties of specimen preparation. Instead, we have introduced a couple of key references.</p><disp-quote content-type="editor-comment"><p>– In addition to their YOLO-based hole finder, the authors may consider mentioning that the open and modular approach of their software allows integration with approaches such as e.g. virtual maps in Py-EM, which could extend the reach of their method to more sophisticated screening/targeting scenarios and different sample supports.</p></disp-quote><p>We have added a citation to Py-EM to the paragraph in which we discuss modularity.</p><disp-quote content-type="editor-comment"><p>– The micrograph pre-processing routines implemented in SmartScope currently involve frame alignment and CTF estimation. The authors may consider including the possibility of image denoising workflows such as those implemented in data pre-processing pipelines (Warp, Scipion, SPHIRE, CryoSparc Live, …), which can be useful tools for rapid selection of suitable imaging areas, in particular if particles are small.</p></disp-quote><p>This is indeed a feature that we’re interested in adding to replace the current preprocessing when necessary. All the pieces are in place to build different wrappers around other packages to fetch the processing data. We didn’t focus on these yet because they didn’t seem quite as urgent for processing a few screening images. However, it becomes more interesting when thinking about data collection.</p><disp-quote content-type="editor-comment"><p>– The authors comment on the screening mode statistics from the operation of SmartScope in their facility. From their facility projects, are there statistics available on how many cases the screening procedure followed by automated, targeted data collection lead to successful structure determination, and how this compares to manual screening and subjective targeting on the same sample? This could be insightful.</p></disp-quote><p>We did not run a control comparison between SmartScope and manual operation. One of the main reasons is that, in the case of data collection, humans are still the ones deciding which are the squares to collect.</p><disp-quote content-type="editor-comment"><p>– The authors mention that data collection of human mitochondrial DNA polymerase involved tilting of the specimen in a subset of the dataset to improve angular sampling. It would be useful to show angular distribution plots for the data excluding and including the tilted images to illustrate this was required and how automation by SmartScope can help detect and mitigate such problems on the fly.</p></disp-quote><p>The intent was not to provide a solution to a problem with this particular sample but rather demonstrate that the quality of tilted data approximates that of untitled images. As it turns out, tilting was not required for POLG2. It was our first time collecting the samples so a subset of the data was collected with tilt to ensure a better angular distribution. We added a breakdown of the tilted vs non-tilted resolutions and angular distribution in the table 1 and Figure 1—figure supplement 2 The particles from the tilted data alone reached a 3.9A resolution and although their inclusion did not improve the to the overall final resolution in the combined dataset, the distribution plot indicates improvements in angular sampling.</p><disp-quote content-type="editor-comment"><p>– A table summarising the data acquisition parameters and data collection statistics should be provided.</p></disp-quote><p>This information was added in the new table 1.</p><disp-quote content-type="editor-comment"><p>– It is laudable that the authors make their software and models publicly available. It would be more useful to have the repository public open at the moment of preprint posting so as to give reviewers the possibility to also screen review code. The data availability statement contains a remark of disclosure of data upon reasonable request. It is unclear what this statement means, and which requests are considered reasonable; these data can be useful for other academic projects following related but complementary approaches, as well as comparison and benchmarking. I encourage the authors to make raw ML data available through public repositories such as Zenodo, and to deposit raw micrographs at EMPIAR.</p></disp-quote><p>We decided to go through a closed beta phase to address questions of ease of installation, documentation and testing at other facilities. Adoption of a new software relies on making sure these points are addressed before release. The code will be made available via github upon publication, and the training data and trained models will be made available on Zenodo. We have made changes to the data and code availability sections to reflect these changes and reported the datasets in the manuscript submission system. We agree with the reviewer that it would be a good feature for the journal to provide means of ensuring access to private repositories by anonymous reviewers.</p></body></sub-article></article>