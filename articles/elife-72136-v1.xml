<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">72136</article-id><article-id pub-id-type="doi">10.7554/eLife.72136</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mechanisms of distributed working memory in a large-scale network of macaque neocortex</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-145438"><name><surname>Mejías</surname><given-names>Jorge F</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8096-4891</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-6345"><name><surname>Wang</surname><given-names>Xiao-Jing</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3124-8474</contrib-id><email>xjwang@nyu.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>Swammerdam Institute for Life Sciences, University of Amsterdam</institution></institution-wrap><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Center for Neural Science, New York University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Pasternak</surname><given-names>Tatiana</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Stanford University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>24</day><month>02</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e72136</elocation-id><history><date date-type="received" iso-8601-date="2021-07-12"><day>12</day><month>07</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-01-19"><day>19</day><month>01</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2019-09-08"><day>08</day><month>09</month><year>2019</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/760231"/></event></pub-history><permissions><copyright-statement>© 2022, Mejías and Wang</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Mejías and Wang</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-72136-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-72136-figures-v1.pdf"/><abstract><p>Neural activity underlying working memory is not a local phenomenon but distributed across multiple brain regions. To elucidate the circuit mechanism of such distributed activity, we developed an anatomically constrained computational model of large-scale macaque cortex. We found that mnemonic internal states may emerge from inter-areal reverberation, even in a regime where none of the isolated areas is capable of generating self-sustained activity. The mnemonic activity pattern along the cortical hierarchy indicates a transition in space, separating areas engaged in working memory and those which do not. A host of spatially distinct attractor states is found, potentially subserving various internal processes. The model yields testable predictions, including the idea of counterstream inhibitory bias, the role of prefrontal areas in controlling distributed attractors, and the resilience of distributed activity to lesions or inactivation. This work provides a theoretical framework for identifying large-scale brain mechanisms and computational principles of distributed cognitive processes.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>working memory</kwd><kwd>large-scale brain model</kwd><kwd>macaque</kwd><kwd>cortical hierarchy</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01MH062349</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Xiao-Jing</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000006</institution-id><institution>Office of Naval Research</institution></institution-wrap></funding-source><award-id>N00014-17-1-2041</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Xiao-Jing</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Wang</surname><given-names>Xiao-Jing</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>Human Brain Project SGA 3</institution></institution-wrap></funding-source><award-id>945539</award-id><principal-award-recipient><name><surname>F Mejías</surname><given-names>Jorge F</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>2015276</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Xiao-Jing</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>An anatomically constrained computational model of the macaque cortical network demonstrates the emergence of large-scale distributed patterns of mnemonic activity sustained by long-range cortico-cortical interactions.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>With the advances of brain connectomics and physiological recording technologies like Neuropixels (<xref ref-type="bibr" rid="bib45">Jun et al., 2017</xref>; <xref ref-type="bibr" rid="bib80">Stringer et al., 2019</xref>), an increasingly important challenge in Neuroscience is to investigate biological mechanisms and computational principles of cognitive functions that engage many interacting brain regions. Here, the goal is no longer to identify one local parcellated brain region that contributes to or is crucial for a particular function, but how a large-scale brain system with many interacting parts underlie behavior. Currently, there is a dearth of theoretical ideas and established models for understanding distributed brain dynamics and function.</p><p>A basic cognitive function recently shown to involve multiple brain areas is working memory, the brain’s ability to retain and manipulate information in the absence of external inputs. Working memory has been traditionally associated with mnemonic delay neural firing in localized brain areas, such as those in the frontal cortex (<xref ref-type="bibr" rid="bib32">Funahashi et al., 1989</xref>; <xref ref-type="bibr" rid="bib33">Fuster, 1973</xref>; <xref ref-type="bibr" rid="bib35">Goldman-Rakic, 1995</xref>; <xref ref-type="bibr" rid="bib41">Inagaki et al., 2019</xref>; <xref ref-type="bibr" rid="bib47">Kopec et al., 2015</xref>; <xref ref-type="bibr" rid="bib70">Romo et al., 1999</xref>) and computational models uncovered the involvement of local recurrent connections and NMDA receptors in the encoding of memory items in selective neural assemblies (<xref ref-type="bibr" rid="bib2">Amit and Brunel, 1997</xref>; <xref ref-type="bibr" rid="bib8">Brunel and Wang, 2001</xref>; <xref ref-type="bibr" rid="bib12">Compte et al., 2000</xref>; <xref ref-type="bibr" rid="bib90">Wang et al., 2013</xref>; <xref ref-type="bibr" rid="bib87">Wang, 1999</xref>).</p><p>In spite of the prevalence of prefrontal cortex as a ‘hub’ for working memory maintenance, self-sustained neural activity during working memory has been found in multiple brain regions; and often such highly engaged areas appear in coactivation (<xref ref-type="bibr" rid="bib11">Christophel et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>; <xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Sreenivasan and D’Esposito, 2019</xref>). Previous modeling efforts have been limited to exploring either the emergence of sustained activity in local circuits, or in two interacting areas at most (<xref ref-type="bibr" rid="bib19">Edin et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Murray et al., 2017b</xref>). It is presently not known what biophysical mechanisms could underlie a distributed form of memory-related sustained activity in a large-scale cortex. The observation that mnemonic activity is commonly found in the prefrontal cortex (PFC) does not prove that it is produced locally rather than resulting from multi-regional interactions; conversely, a distributed activity pattern could in principle be a manifestation of sustained inputs broadcasted by a local source area that can produce self-sustained activity in isolation. Therefore, understanding the distributed nature of cognitive functions such as working memory is challenging and requires of both novel theoretical ideas and multi-area recordings (<xref ref-type="bibr" rid="bib19">Edin et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>).</p><p>In this study, we tackle this challenge by building and analyzing an anatomically constrained computational model of the cortical network of macaque monkey, and investigate a novel scenario in which long-range cortical interactions support distributed activity patterns during working memory. The anatomical data is used to constrain the model at the level of long-range connections but also at the level of local circuit connectivity. In particular, the model incorporated differences between individual cortical areas, by virtue of macroscopic gradients of local circuit properties in the large-scale network. The emerging distributed patterns of sustained activity involve many areas across the cortex. They engage temporal, frontal and parietal areas but not early sensory areas, in agreement with a recent meta-analysis of delay period activity in macaque cortex (<xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>). Sustained firing rates of cortical areas across the hierarchy display a gap, indicative of the existence of a transition akin to a bifurcation in cortical space that does not require tuning of bifurcation parameters. Furthermore, the distributed patterns emerge even when individual areas are unable to maintain stable representations, or when other mechanisms such as activity-silent memory traces are considered. Our model predicts that distributed WM patterns (i) require the existence of a certain level of inhibition in long-range feedback projections, (ii) can be controlled or inactivated from a small group of areas at the top of the cortical hierarchy, and (iii) increase the robustness of the network to distractors and simulated inactivation of areas. The concept departs from the classical view of working memory based on local attractors, and sheds new light into recent evidence on distributed activity during cognitive functions.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Our computational model includes 30 areas distributed across all four neocortical lobes (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; see Materials and methods for further details). The inter-areal connectivity is based on quantitative connectomic data from tract-tracing studies of the macaque monkey (<xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>; <xref ref-type="bibr" rid="bib54">Markov et al., 2014b</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). For simplicity, each of the cortical areas is modeled as a neural circuit which contains two excitatory populations (selective to sensory stimuli A and B, respectively) and one inhibitory population (<xref ref-type="bibr" rid="bib89">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib87">Wang, 1999</xref>; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). In addition, the model assumes a macroscopic gradient of outgoing and recurrent synaptic excitation (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib44">Joglekar et al., 2018</xref>; <xref ref-type="bibr" rid="bib91">Wang, 2020</xref>), so that the level of synaptic strength is specific of each area (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). This gradient is introduced by considering that the number of apical dendritic spines, loci of excitatory synapses, per pyramidal cells increases (<xref ref-type="bibr" rid="bib27">Elston, 2007</xref>) along the cortical hierarchy as defined by anatomical studies (<xref ref-type="bibr" rid="bib29">Felleman and Van Essen, 1991</xref>; <xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>; <xref ref-type="fig" rid="fig1">Figure 1C</xref>). The gradient of area-specific connection strength was applied to both local recurrent and long-range excitatory outgoing projections. In particular, we denote the maximal strength of local and long-range excitation for the area at the top of the cortical hierarchy by J<sub>max</sub>, which is an important parameter of the model (see below). To allow for the propagation of activity from sensory to association areas, we assumed that inter-areal long-distance outgoing projections target more strongly excitatory neurons for feedforward pathways and inhibitory neurons for feedback pathways, in a graded fashion (<xref ref-type="bibr" rid="bib58">Mejias et al., 2016</xref>; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). We shall refer to the gradual preferential targeting onto inhibitory neurons by top-down projections as the ‘counterstream inhibitory bias’ hypothesis. We assume that the bias of top-down projections towards inhibitory neurons is proportional to the fraction of infragranular projections (see Materials and methods). It is worth noting that exploration of such new hypotheses would have not been possible without a quantitative definition of the cortical hierarchy and biologically realistic circuit modeling. The results provided by this anatomically constrained model, while leading to concrete experimental predictions for macaques, are also robust to small alterations of parameter values and connectivity structure, suggesting the validity of our conclusions in other conditions or animal species.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Scheme and anatomical basis of the multi-regional macaque neocortex model.</title><p>(<bold>A</bold>) Lateral view of the macaque cortical surface with modelled areas in color. (<bold>B</bold>) In the model, inter-areal connections are calibrated by mesoscopic connectomic data (<xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>), each parcellated area is modeled by a population firing rate description with two selective excitatory neural pools and an inhibitory neural pool (<xref ref-type="bibr" rid="bib95">Wong and Wang, 2006</xref>). Recurrent excitation within each selective pool is not shown for the sake of clarity of the figure. (<bold>C</bold>) Correlation between spine count data (<xref ref-type="bibr" rid="bib27">Elston, 2007</xref>) and anatomical hierarchy as defined by layer-dependent connections (<xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Anatomical connectivity data of the macaque cortex.</title><p>Data from anatomical studies (<xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>; <xref ref-type="bibr" rid="bib54">Markov et al., 2014b</xref>). (<bold>A</bold>) Connectivity of the 30 areas (positioned in 3D space following injection coordinates of experiments). Width of the lines denote two-way averaged FLN values (i.e. average strength of the projection). (<bold>B</bold>) Map of FLN values for all connections considered. (<bold>C</bold>) The proportion of supragranular vs infragranular neurons projecting to the injection site allowed to define an anatomical hierarchy. (<bold>D</bold>) Map of SLN values for all connections considered.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Spine count data used to constrain connectivity strength.</title><p>Data from anatomical studies (<xref ref-type="bibr" rid="bib27">Elston, 2007</xref>), see also <xref ref-type="table" rid="table1">Table 1</xref>. (<bold>A</bold>) Spine count of the basal dendrites of layer 2/3 neurons across cortical areas of young (2~3years old) macaques. When data from older macaques had to be considered, an age correction was introduced (orange bars). (<bold>B</bold>) Correlation between the spine count data and the hierarchical value h<sub>i</sub> (left) or the hierarchical position/rank (right). A robust fit obtained by random sampling consensus (grey, 100 randomized trials with a threshold for number of outliers &lt; 10% of the total points) suggest areas 7m and LIP as potential outliers. Pearson correlation and corresponding p-value are shown in each panel. In the model, the connectivity strength of areas for which spine count data was not available was estimated using their hierarchical value.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig1-figsupp2-v1.tif"/></fig></fig-group><sec id="s2-1"><title>Distributed WM is sustained by long-range cortical loops</title><p>In local circuit models of working memory (WM)(<xref ref-type="bibr" rid="bib12">Compte et al., 2000</xref>; <xref ref-type="bibr" rid="bib87">Wang, 1999</xref>), areas high in the cortical hierarchy make use of sufficiently strong synaptic connections (notably involving NMDA receptors <xref ref-type="bibr" rid="bib90">Wang et al., 2013</xref>; <xref ref-type="bibr" rid="bib87">Wang, 1999</xref>) to generate self-sustained delay activity. Specifically, the strength of local synaptic reverberation must exceed a threshold level (in our model, the local coupling parameter J<sub>S</sub> must be larger than a critical value of 0.4655), for an isolated local area to produce stimulus-selective mnemonic activity states that coexist with a resting state of spontaneous activity (operating in a multistable regime rather than in a monostable regime, see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). However, there is presently no conclusive experimental demonstration that an isolated cortical area like dorsolateral prefrontal cortex (dlPFC) is indeed capable of generating mnemonic sustained activity. Indeed, recent evidence suggest that thalamocortical support might be needed to achieve sustained activity in dlPFC (<xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>). In this study, we first examined the scenario in which all areas, including dlPFC (9/46d) at the top of the hierarchy, have J<sub>S</sub> values below the critical value for multistability (so <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>§amp;lt;</mml:mo><mml:mn>0.4655</mml:mn></mml:math></inline-formula>) and are connected via excitatory long-range projections of global coupling strength G (we set J<sub>max</sub> = 0.42 and G = 0.48 unless specified otherwise)(<xref ref-type="fig" rid="fig2">Figure 2A</xref>). In this case, any observed sustained activity pattern must result from inter-areal connection loops. In a model simulation of a visual delayed response task, a transient visual input excites a selective neural pool in the primary visual cortex (V1), which yielded activation of other visual areas such as MT during stimulus presentation (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, upper left). After stimulus withdrawal, neural activity persists in multiple areas across frontal, temporal and parietal lobes (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, top right). The resulting activation pattern shows a substantial agreement with a large body of data, from decades of monkey neurophysiological experiments, reviewed in recent meta-analyses (<xref ref-type="bibr" rid="bib11">Christophel et al., 2017</xref>; <xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>), regarding which areas display WM-related activity during delay period of WM tasks (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, bottom right). The activation pattern from the model was stimulus specific, so only the neural pool selective to the presented stimulus in each cortical area displayed elevated sustained activity (<xref ref-type="fig" rid="fig2">Figure 2C</xref>; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). We observed cross-area variations of neural dynamics: while areas like 9/46d displayed a sharp binary jump of activity, areas like LIP exhibited a more gradual ramping activity. Such a population level, or neuron-averaged, ramping activity of LIP in our model would correspond to the trial-averaged temporal accumulation of information in decision-making (<xref ref-type="bibr" rid="bib75">Shadlen and Newsome, 2001</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Distributed WM sustained via long-range loops in cortical networks.</title><p>(<bold>A</bold>) Bifurcation diagram for an isolated area. Green circles denote the position of each area, with all of them in the monostable regime when isolated. (<bold>B</bold>) Spatial activity map during visual stimulation (left) and delay period (upper right). For comparison purposes, bottom right map summarizes the experimental evidence of WM-related delay activity across multiple studies (<xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>), dark blue corresponds to strong evidence and light blue to moderate evidence. (<bold>C</bold>) Activity of selected cortical areas during the WM task, with a selective visual input of 500ms duration. (<bold>D</bold>) Firing rate for all areas during the delay period, ranked by firing rate.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Behavior of all areas in the network during the visual WM task.</title><p>Top: spatial maps of the simulated macaque brain during stimulation and delay period, with activity color coded. Bottom: evolution of the firing rate of all areas in the network. Stimulation occurs in V1 at t = 4 s and has a duration of 500ms. Parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Behavior of all areas in the network during the somatosensory WM task.</title><p>Top: spatial maps of the simulated macaque brain during stimulation and delay period, with activity color coded. Bottom: evolution of the firing rate of all areas in the network. Stimulation occurs in area 2 (primary somatosensory area) at t = 4 seconds, and has a duration of 500ms. Other parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>A simple gating mechanism controls the participation of areas in distributed WM.</title><p>(<bold>A</bold>) Response of all cortical areas when gates are closed for all areas (orange), open for visual areas only (green) and open to all areas (blue). Note that areas not involved in visual processing, such as somatosensory areas, are not activated by the input when only visual areas are gated. (<bold>B</bold>) Spatial activity maps for the delay period corresponding to the three cases in panel A. A weak global coupling (G = 0.2) is used to provide room for the effects of gating (see Materials and Methods), all other parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. For the purposes of the gating simulation, ‘visual’ areas were selected according to a recent meta-analysis: V1, V2, V4, MT, LIP, 7a, TEO, TEpd, 8l, 8m, 8B, 46d, 9/46d, and 9/46v. The strength of the gating modulation is g<sub>s</sub> = 0.38 for the visual-only case, and g<sub>s</sub> = 0.28 for the all-areas case since it involves more areas (this situation is roughly equivalent to <xref ref-type="fig" rid="fig2">Figure 2</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Firing rates for selected areas during a visual WM task with a short (50ms) stimulus duration.</title><p>(<bold>A</bold>) Only NMDA and GABA synapses are considered in the network, the stimulus does not reach frontal areas. (<bold>B</bold>) By introducing simplified AMPA-like synapses (proportional to the firing rates) on feedforward excitatory projections, we obtain distributed WM patterns for this type of short inputs. The results suggests that it is convenient to consider AMPA/NMDA asymmetry along the FF/FB projections in the hierarchy for brief stimulation patterns. Other parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig2-figsupp4-v1.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>Firing rate of ranked cortical areas reveals a robust transition in space with different ranking systems.</title><p>(<bold>A</bold>) Areas ranked by displayed firing rate. (<bold>B</bold>) Areas ranked by spine count. (<bold>C</bold>) Areas ranked following their hierarchical (as obtained from SLN data) position. Parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig2-figsupp5-v1.tif"/></fig></fig-group><p>Given that selective mnemonic activity is also found in somatosensory WM tasks (<xref ref-type="bibr" rid="bib70">Romo et al., 1999</xref>), we further test our model and simulate a simple somatosensory WM task by transiently and selectively stimulating a neural pool in primary somatosensory cortex. As in the case of visual stimulation, this leads to the emergence of a distributed sustained activity pattern of equal selectivity as the input (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), showing the validity of the distributed WM mechanism across different sensory modalities. At this stage, the model is however not able to predict different between attractors evoked by different sensory modalities. For this, we show that the introduction of a simple gating mechanism allows to study the involvement of certain areas in the processing of particular input modalities, further refining the model predictions (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Likewise, our model has considered NMDA receptors as the only excitatory dynamics for simplicity. However, AMPA dynamics may also be important (<xref ref-type="bibr" rid="bib86">van Vugt et al., 2020</xref>), and can be easily introduced leading to a good behavior of the model for shorter durations of the stimulus presentation (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>).</p><p>When we plotted the firing rate of stimulus-selective sustained activity across 30 areas along the hierarchy, our results revealed a separation between the areas displaying sustained activity and those that did not (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This is a novel type of abrupt transition of behavior that takes place in space, rather than as a function of a network parameter like in <xref ref-type="fig" rid="fig2">Figure 2A</xref>. As a matter of fact, the relevant parameter here is the strength of synaptic excitation that varies across cortical space, in the form of a macroscopic gradient. The transition is robust in two respects. First, the separation between areas appears not only when areas are ranked according to their firing rates, but also when they follow their positions in the anatomical hierarchy or in the rank of spine count values (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). Second, it does not depend on any fine tuning of parameter values.</p></sec><sec id="s2-2"><title>Simplified model of distributed working memory</title><p>The above model, albeit a simplification of real brain circuits, includes several biologically realistic features, which makes it difficult to identify essential ingredients for the emergence of distributed WM. For this reason, we developed a minimal model consisting on a fully connected network of excitatory firing-rate nodes (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, see Appendix 1). This simplified model will allow us to explore the minimal conditions for the emergence of distributed WM, in the same way that the full, biologically realistic model provided us with stronger support for the mechanism in realistic conditions. The network of the simplified model includes a linear gradient of local properties: areas at the beginning of such gradient have weak self-coupling, while areas at the end have strong self-coupling. As in the more elaborated model, self-excitation is too weak to generate bistability in any isolated nodes.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Simplified model of distributed WM.</title><p>(<bold>A</bold>) Scheme of our simplified model: a fully connected network of N = 30 excitatory nodes with a gradient of local coupling strength. (<bold>B</bold>) Population-average firing rate as a function of the global coupling strength, according to numerical simulations (symbols) and a mean-field solution based on first-order (gray line) or second-order statistics (blue). (<bold>C</bold>) Firing rates of three example individual nodes (symbols denote simulations, lines denote second-order mean-field solutions). (<bold>D</bold>) Activity of an example node when isolated (light blue) or connected to the network (dark blue). (<bold>E</bold>) Two forms for the gradient of local coupling strength (lines) compared with the spine count data (symbols). (<bold>F</bold>) The number of bistable areas in the attractor (grey) is either zero or N when the gradient of local properties saturates as suggested by spine count data. When feedback projections become weaker, resembling inhibitory feedback, the network is able to display distributed WM patterns which involve only a limited number of areas (black).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Simplified network model for distributed, activity-silent memory traces.</title><p>We modified our simplified network model (see <xref ref-type="fig" rid="fig3">Figure 3</xref>) to incorporate short-term synaptic facilitation (STF) in its local and long-range projections (see Materials and methods). Original projection strengths were reduced from the original values to allow STF to enhance synaptic strengths in an activity-dependent manner. Columns show traces of firing rate and synaptic efficacy (resp. baseline of P) for areas from the bottom (left) to the top (right) section of the linear gradient of local strengths. Top row: network without STF and isolated areas. Middle row: network with STF (time constant of 1.5 s) and isolated areas. Bottom row: network with STF (time constant of 1.5 s) and interconnected areas (G = 6). Parameters are <italic>P</italic> = 0.1 (initial synaptic probability release), background current I=-10, η<sub>1</sub> = 0.05, η<sub>N</sub>=0.25, <italic>δ</italic> = 0.05. External input are pulses of 50ms duration arriving every second at the lowest area of the linear gradient (simulating a primary sensory area), the first pulse has a strength of 15 and the rest (internal ‘ping’ signals) of 10. Other parameters as in <xref ref-type="fig" rid="fig3">Figure 3</xref> B.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig3-figsupp1-v1.tif"/></fig></fig-group><p>This simple model allows for a mean-field analytical solution for the network average firing rate R of the form: <inline-formula><mml:math id="inf2"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>, with <inline-formula><mml:math id="inf3"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> being a sigmoidal function, <inline-formula><mml:math id="inf4"><mml:mi>J</mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> the average local coupling value across areas, <inline-formula><mml:math id="inf5"><mml:mi>G</mml:mi></mml:math></inline-formula> the inter-areal connection strength, and <inline-formula><mml:math id="inf6"><mml:mi>I</mml:mi></mml:math></inline-formula> a background input current (see Appendix 1 for a full derivation of a two-area example and a more complete N-area network). The factor <inline-formula><mml:math id="inf7"><mml:mi>J</mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>G</mml:mi></mml:math></inline-formula> determines whether the above equation has one stable solution (spontaneous firing) or two (spontaneous and sustained firing). As this factor includes both local and global components, the average network firing rate may be bistable even if local couplings are weak, as long as the inter-areal connections are strong enough. This mean-field solution, as well as a more precise second-order version, show a good agreement with numerical simulations and confirm the emergence of distributed activity in the system (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Simulations also show, around <inline-formula><mml:math id="inf8"><mml:mi>G</mml:mi><mml:mo>~</mml:mo><mml:mn>0.17</mml:mn></mml:math></inline-formula>, the appearance of states in which only areas at the top of the gradient show bistability, indicated by low values of R. Once R is known, the mean-field solution also permits to predict the emergence of sustained activity in individual nodes (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) and also observe how monostable isolated units become bistable when incorporated into the network (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Briefly, the existence of a clear bistability in R would induce, in the individual areas with stronger self-coupling, the emergence of bistability for these areas. For areas with weak self-coupling, either possible value of R is not enough to induce local bistability, and these areas remain in the monostable regime.</p><p>The simplified model demonstrates that distributed WM patterns, in which some (but not all) areas display bistability when connected to each other, may emerge on generic networks of excitatory units as long as (i) their long-range connections are strong enough and (ii) the network has a linear gradient of local couplings. When considering biological constraints, however, these two conditions might not be easy to meet. In particular, data on the area-specific number of spines per neuron seems to monotonically increase, but saturates instead of growing linearly (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Introducing this saturating gradient on the simplified model makes the nodes more homogeneous, and as a result the network is not able to display distributed WM patterns without indistinctively activating all nodes (<xref ref-type="fig" rid="fig3">Figure 3F</xref>, gray curve). This problem was solved when we assumed that feedforward projections (i.e. those going from lower to higher areas in the gradient) were slightly stronger while feedback projections were slightly weaker, which is consistent with the counterstream inhibitory bias hypothesis. Such assumption, needed for saturating gradients, allows to recover solutions in which only a subset of areas display bistability in the WM patterns (<xref ref-type="fig" rid="fig3">Figure 3F</xref>, black curve).</p><p>Simplified models can also be used to explore the plausibility of the distributed WM hypothesis in other scenarios besides delay activity –for example, for activity-silent memory traces (<xref ref-type="bibr" rid="bib46">Kamiński and Rutishauser, 2020</xref>; <xref ref-type="bibr" rid="bib62">Mongillo et al., 2008</xref>; <xref ref-type="bibr" rid="bib79">Stokes, 2015</xref>). We modified the simplified model introduced above by adding short-term synaptic facilitation (STF) to both local and long-range projections of the network (and decreasing the overall synaptic strength to allow the transient enhancements of STF to play a sufficient role; see Appendix 1). In such a model, a slowly decaying transient of synaptic efficacy, susceptible of reactivations along the delay period, is thought to preserve the information in an activity-silent manner. As in the delay activity model, isolated areas without STF are not able to sustain the information; similar results are obtained when STF is introduced. However, when long-range projections are considered in a network with STF, synaptic efficacies are sustained for long periods of time (as a result of the contribution of both local and long-range interactions), leading to areas with strong enough synapses to preserve the information via activity-silent memory traces (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></sec><sec id="s2-3"><title>Impact of the counterstream inhibitory bias in the full model</title><p>As indicated by the simplified model, introducing differences between feedforward and feedback projections is a key ingredient to achieve realistic patterns of distributed WM in a data-constrained model. In the full, biologically more realistic model –which will be considered for the rest of the study –this asymmetry is introduced by considering a graded preferential targeting to inhibitory neurons by top-down projections (i.e. counterstream inhibitory bias, or CIB), which prevent indiscriminate sustained activation across all cortical areas (<xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>; <xref ref-type="fig" rid="fig4">Figure 4A</xref>). We systematically varied the strength of the feedback projections targeting inhibitory population in our model, and computed the firing rates of different areas during delay for these cases. We observed that, for strong enough CIB, the overall firing rate of early sensory areas is reduced, while the activity levels of areas high in the hierarchy is maintained at appropriate values (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). This also allows distributed WM patterns to emerge for a wide range of the global coupling strength (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).</p><p>The strength of the counterstream inhibitory bias has also an impact on the overall activity profiles across the brain network. <xref ref-type="fig" rid="fig4">Figure 4D</xref> shows activity maps for several CIB level, revealing that a moderate to strong inhibitory feedback agrees well with the experimental evidence.</p><p>It is also worth noting that exceptions to the CIB rule may exist in brain networks without compromising the stability of distributed WM attractors. For example, a more balanced targeting would allow for WM-related activity in primary visual areas, which still constitutes a point of controversy in the field (<xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>). FEF areas 8 l and 8 m, on the other hand, are not able to sustain delay activity when receiving strong inhibitory feedback (especially from other frontal areas) and had to be excluded from this general rule, although such exception does not affect the results aside from local effects in FEF (Materials and Methods, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Effect of inhibitory feedback on distributed WM for the full model.</title><p>(<bold>A</bold>) Scheme showing a circuit without (left) or with (right) the assumption of counterstream inhibitory bias, or CIB. (<bold>B</bold>) Firing rate of areas at the bottom and top of the hierarchy (10 areas each, thick lines denote averages) as a function of the CIB strength. (<bold>C</bold>) Number of areas showing sustained activity in the example distributed activity pattern vs global coupling strength without (grey) and with (black) CIB. (<bold>D</bold>) Activity maps as a function of the CIB strength. As in <xref ref-type="fig" rid="fig2">Figure 2</xref> B, bottom map denotes the experimental evidence for each area (dark blue denotes strong evidence, light blue denotes moderate evidence).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Corrections to localized regions; example of FEF areas.</title><p>(<bold>A</bold>) Traces of every area in the simulated neocortical network. We limit here the strength of counterstream inhibitory bias, or preference of feedback towards inhibition, which feedback projections from frontal areas to FEF areas (8 l and 8 m) may display. For each plotted area, blue lines of increasing darkness show the effects of limiting frontal inhibitory feedback to FEF to 0.2, 0.4, 0.6, or 0.8. The effects are mostly visible in areas 8 l and 8 m, and to a lesser extent in TEO. (<bold>B</bold>) Transition in the cortical space for the different limitations to FEF inhibitory feedback. (<bold>C</bold>) Activity maps for the four conditions shown in panels A and B. Other parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Effect of jitter on dendritic spine values and surrogate networks.</title><p>(<bold>A</bold>) Scheme of networks with jittered area-specific dendritic spine numbers (within 15% of their original values), and therefore jittered local and long-range synaptic strengths. (<bold>B</bold>) Effects of the jitter in traces for selected areas (lines of different colors represent activity for different configurations). (<bold>C</bold>) Jittering has a minor effect on the duration of the sustained state for low/middle spine count areas. (<bold>D</bold>) Transition in cortical space for jittered networks. (<bold>E</bold>) Scheme of surrogate networks, in which FLN values are randomly shuffled. (<bold>F</bold>) Effects of shuffling FLN values on traces of selected areas. (<bold>G</bold>) Surrogate networks present moderate differences in the duration of the sustained states of high spine count values. (<bold>H</bold>) Transition in cortical space for surrogate networks. Parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>A gradient of time scales emerges in the network.</title><p>(<bold>A</bold>) Autocorrelation function of the activity (low-pass-filtered to simulate an LFP recording) of each area in the network, fitted with a decaying exponential function. (<bold>B</bold>) The values for the local decay time constant increase with the cortical hierarchy, going from ~60 ms in early visual areas to ~300 ms in some frontal areas. This range is similar to the spike-count autocorrelations found experimentally across different cortical areas (<xref ref-type="bibr" rid="bib64">Murray et al., 2014</xref>; <xref ref-type="bibr" rid="bib77">Siegle, 2019</xref>), and improves predictions from previous models (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 2015</xref>) but see additional considerations <xref ref-type="bibr" rid="bib73">Schmidt et al., 2018</xref>. Parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig4-figsupp3-v1.tif"/></fig></fig-group><p>In <xref ref-type="fig" rid="fig2">Figure 2</xref> and also in the following sections, the strength of the counterstream inhibitory bias was considered proportional to the fraction of infragranular projections, as suggested by anatomical studies (<xref ref-type="bibr" rid="bib54">Markov et al., 2014b</xref>) and following previous work (<xref ref-type="bibr" rid="bib58">Mejias et al., 2016</xref>). This results in a very small bias for most of the projections, but enough to produce the desired effect (see Materials and methods for further details). In addition to supporting the emergence of distributed WM, CIB could explain observed top-down inhibitory control effects (<xref ref-type="bibr" rid="bib84">Tsushima et al., 2006</xref>).</p><p>While the macroscopic gradient of excitability is an important property of the model, the particular values of excitatory strength assigned to each area are not relevant for the phenomenon (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> A-D). Similar conclusions can be obtained when the anatomical structure of the cortical network is changed –for example, by randomly shuffling individual projection strength values (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2E-H</xref>). However, in this case, the duration of the sustained activity for multiple areas may be affected. This suggests that salient statistical features of the structure embedded in the cortical network may play a role in the emergence of distributed activity patterns. The model also predicts the emergence of a hierarchy of time scales across cortical areas (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>), in agreement with experimental findings (<xref ref-type="bibr" rid="bib64">Murray et al., 2014</xref>) and supporting and improving previous computational descriptions (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 2015</xref>).</p></sec><sec id="s2-4"><title>Long-range cortical loops support a large number of different distributed attractors</title><p>We realized that a large-scale circuit can potentially display a large number of distributed sustained activity patterns (attractors), and some of them may not be accessible by stimulation of a primary sensory area. Note that distinct attractor states are defined here in terms of their spatial patterns, which does not depend on the number of selective excitatory neural pools per area. We developed a numerical approach to identify and count distinct attractors (see Appendix 2 for further details). Our aim is not to exhaustively identify all possible attractors, as the activity space is too large, but to gain insight on how our estimations depend on relevant parameters such as the global coupling strength G, or the maximum area-specific synaptic strength J<sub>max</sub>. Five examples of different distributed WM attractors are shown in <xref ref-type="fig" rid="fig5">Figure 5A</xref>, where we can appreciate that not all distributed attractors engage cortical areas at all lobes, and that frontal areas are the ones more commonly involved.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Distributed and local WM mechanisms can coexist in the full model.</title><p>(<bold>A</bold>) Five example distributed attractors of the network model (J<sub>max</sub> = 0.42). (<bold>B</bold>) Bifurcation diagram of an isolated local area with the four cases considered. (<bold>C</bold>) Number of attractors (normalized) found via numerical exploration as a function of the global coupling for all four cases. (<bold>D</bold>) Maximum (peak) number of attractors for each one of the cases. (<bold>E</bold>) Correlation between size of attractors and mean firing rate of its constituting areas for J<sub>max</sub> = 0.45and G = 0.2. (<bold>F</bold>) Participation index of each area (left, arranged by spine count) and distribution of attractors according to their size (right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig5-v1.tif"/></fig><p>A more detailed analysis included four cases depending on the value of the maximum area-specific synaptic strength J<sub>max</sub> assumed: two of the cases had J<sub>max</sub> above the bifurcation threshold for isolated areas (0.4655), and the other two had J<sub>max</sub> below the bifurcation threshold. For the first two cases, having J<sub>max</sub> &gt; 0.4655 means that at least certain areas high in the hierarchy, such as dlPFC, have strong enough local reverberation to sustain activity independently (i.e. they were ‘intrinsically multistable’ and able to display bistability even when isolated from the network, <xref ref-type="fig" rid="fig5">Figure 5B</xref>); however, areas lower in the hierarchy like 24 c and F2 would require long-range support to participate in WM. For the last two cases, in which J<sub>max</sub> &lt; 0.4655, none of the areas was able to display bistability when isolated, but they can contribute to stabilize distributed WM attractors as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. In all four cases, the number of attractors turns out to be an inverted-U function of the global coupling strength G, with an optimal G value maximizing the number of attractors (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, curves are normalized to have a peak height of one for visualization purposes). This reflects the fact that a minimal global coupling is needed for areas to coordinate and form distributed WM attractors, but for values of G too large, all areas will follow the majority rule and the diversity and number of possible attractors will decrease. The optimal G value shifted towards lower values for increasing J<sub>max</sub>, and the peak number of attractors simultaneously increasing (<xref ref-type="fig" rid="fig5">Figure 5D</xref>).</p><p>Across all four cases and G values considered, we found a significant positive correlation between the number of areas involved in a given attractor and the average firing rate of these areas (<xref ref-type="fig" rid="fig5">Figure 5E</xref>), which constitutes an experimentally testable prediction of the distributed model of WM. We also analyzed how distributed WM attractors were constituted for the four different cases (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). When the network has a high number of intrinsically multistable areas (i.e. when J<sub>max</sub>&gt;0.4655), attractors tend to only involve these areas and are therefore largely restricted to the areas located at the top of the hierarchy (<xref ref-type="fig" rid="fig5">Figure 5F</xref>, bottom left and right panels). On the other hand, when the network has zero or a low number of intrinsically multistable areas (i.e. J<sub>max</sub>&lt;0.4655), attractors typically involve a larger number of areas (as a larger pool of areas is needed to sustain distributed WM attractors, see top right panel in <xref ref-type="fig" rid="fig5">Figure 5F</xref>) and the areas involved are more diverse in their composition (<xref ref-type="fig" rid="fig5">Figure 5F</xref>, top left panel).</p></sec><sec id="s2-5"><title>Effects of inactivating areas on distributed attractors</title><p>To continue probing the robustness of distributed WM patterns, we tested the effect of inactivating cortical areas in our model during WM tasks, which can be done experimentally using optogenetic methods or lesioning selected areas. We tested this by completely and permanently suppressing the firing rate of the inactivated areas in the model, in such a way that the area becomes a sink of current and does not communicate with other areas. We began by inactivating (or silencing) a given number of randomly selected areas in a visually evoked distributed WM attractor, and found that the number of active areas in the attractor decreases only linearly with the number of inactivated areas (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Furthermore, the activity of the areas remained in the distributed WM patterns linearly decreased their sustained activity level with the number of inactivated areas (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). As silencing areas at the top of the hierarchy could in principle have strong effects, we then systematically silenced areas in reverse hierarchical order (i.e., silencing the top area first, then the top and second-from-top areas, etc), instead of in random order. In this case, the number of active areas decreases a bit more abruptly (<xref ref-type="fig" rid="fig6">Figure 6C</xref>) and, as we will see later, can prevent the emergence of distributed WM altogether if J<sub>max</sub> is not sufficiently large.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Effects of lesioning/silencing areas on the activity and number of attractors.</title><p>Silencing occurs throughout the full trial for each area indicated here. (<bold>A</bold>) Number of active areas in the example attractor as a function of the number of (randomly selected) silenced areas. (<bold>B</bold>) The activity of the areas which remain as part of the attractor decreases with the number of silenced areas. (<bold>C</bold>) The number of active WM areas decreases faster when areas are incrementally and simultaneously silenced in reverse hierarchical order. (<bold>D</bold>) When considering all accessible attractors for a given network (G = 0.48, J<sub>max</sub> = 0.42), silencing areas at the top of the hierarchy has a higher impact on the number of surviving attractors than silencing bottom or middle areas. (<bold>E</bold>) Numerical exploration of the percentage of surviving attractors for silencing areas in different lobes. (<bold>F</bold>) Silencing areas at the center of the ‘bowtie hub’ has a strong impact on WM (adapted from <xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>). (<bold>G</bold>) Numerical impact of silencing areas in the center and sides of the bowtie on the number of surviving attractors. For panels (<bold>E</bold>) and (<bold>F</bold>), areas color-coded in blue/red have the least/most impact when silenced, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig6-v1.tif"/></fig><p>We also carried out a more systematic evaluation of the effect of cortical inactivations, including their effect on attractors that were not accessible from sensory stimulation directly. This study revealed that inactivating most areas has only limited consequences on the total number of available distributed attractors, although in general the impact increases with the location of the silenced area in the hierarchy (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). In particular, the overall impact was large when some temporal and prefrontal areas are silenced, and sometimes more than half of the initially available attractors were lost (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). Interestingly, and beyond any hierarchical dependence, the temporal and prefrontal areas that had the strongest impact are part of a subset of the anatomical network which has a very high (92%) density of connections between its nodes. This anatomical core, which has sparser connections with the remaining areas (forming the periphery of the network) is known as the anatomical 'bowtie hub' of the macaque cortex identified in anatomical studies (<xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>; <xref ref-type="fig" rid="fig6">Figure 6F</xref>). Overall, silencing areas at the center of the bowtie had a deeper impact, in terms of the number of attractors surviving the silencing, than silencing areas on the periphery (<xref ref-type="fig" rid="fig6">Figure 6G</xref>).</p></sec><sec id="s2-6"><title>Effects of inactivations and distractors in distributed vs localized WM patterns</title><p>Across all analyses performed above, we assumed a relatively large value for the maximum area-specific recurrent strength J<sub>max</sub> = 0.42, even if still below the critical value needed for bistability in isolation (0.4655). In order to provide clean predictions linked to the distributed WM scenario, in the following sections we studied the case of a strongly distributed WM system with J<sub>max</sub> = 0.26 and G = 0.48, and compared it to the case of networks which rely purely on a localized WM strategy (with J<sub>max</sub> = 0.468, G = 0.21 and feedback projections removed to avoid long-range loops).</p><p>We first reexamined the effect of inactivations for this strongly distributed WM network. We found that inactivations have in general a stronger effect here than for networks with larger J<sub>max</sub> (as in <xref ref-type="fig" rid="fig6">Figure 6</xref>). For example, inactivating key prefrontal areas such as 9/46d (dlPFC) fully prevented the emergence of distributed WM patterns evoked by external stimulation (<xref ref-type="fig" rid="fig7">Figure 7A and b</xref>), which is in agreement with classical prefrontal lesion studies –see (<xref ref-type="bibr" rid="bib14">Curtis and D’Esposito, 2004</xref>) for a review and a discussion of the implications for dlPFC organization. On the other hand, other areas can still be inactivated without disrupting distributed WM. In some cases, inactivating specific areas might even lead to a disinhibition of other areas and to a general reinforcement of the attractor (e.g. inactivating 24c leads to a larger and faster response by area STPi, <xref ref-type="fig" rid="fig7">Figure 7B</xref>). This is a consequence of the hierarchical relationship of cortical areas and the counterstream inhibitory bias –silencing a top area which is effectively inhibiting lower areas might release these lower areas from the inhibition and increase their firing.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Effect of silencing areas in localized vs distributed WM.</title><p>(<bold>A</bold>) Full-brain activity maps during the delay period for the control case (left), and lesioning/silencing area 24 (top right) or area 9/46d (bottom right). (<bold>B</bold>) Traces of selected areas for the three cases in panel A show the effects of silencing each area. (<bold>C</bold>) For a network displaying localized WM (top row, corresponding to J<sub>max</sub> = 0.468, G = 0.21), a brief inactivation of area 9/46d leads to losing the selective information retained in that area. For a network displaying distributed working memory (middle row, J<sub>max</sub> = 0.26, G = 0.48) a brief inactivation removes the selective information only transiently, and once the external inhibition is removed the selective information is recovered. In spite of this robustness to brief inactivations, distributed WM patters can be shut down by inhibiting a selective group of frontal areas simultaneously (bottom row, inhibition to areas 9/46 v, 9/46d, F7, and 8B). The shut-down input, of strength I = 0.3 and 1s duration, is provided to the nonselective inhibitory population of each of these four areas.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig7-v1.tif"/></fig><p>In addition to permanently inactivating areas, we tested the effects of brief (500ms ~ 1 s) inactivations in specific areas, and compare the effects in localized vs distributed WM scenarios. For networks relying on localized WM, areas at the top of the hierarchy maintained their selective information largely independent from each other. Consequently, briefly inactivating area 9/46d would not, for example, have an effect on the sustained activity of other areas such as 8B (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, top row). Furthermore, the brief inactivation was enough to remove the information permanently from 9/46d, which remained in the spontaneous state after the inhibition was withdrawn. On the other hand, silencing an area like 9/46d will slightly affect the sustained activity in other areas (such as 8B) in a network strongly relying on distributed WM (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, middle row). However, area 9/46d will be able to recover the encoded selective information once the inhibitory pulse is removed, due to the strong interaction between cortical areas during the delay period. This constitutes a strong prediction for networks which rely on distributed interactions to maintain WM.</p><p>The marked resilience of distributed WM attractors to brief inhibitory pulses raises the question of how to shut down the sustained activity once the task has been done. In many traditional WM models, this is achieved by providing a strong nonspecific excitatory input to the whole WM circuit, which triggers inhibition and drives the activity of the selective populations back to their spontaneous state (<xref ref-type="bibr" rid="bib13">Compte, 2006</xref>; <xref ref-type="bibr" rid="bib12">Compte et al., 2000</xref>; <xref ref-type="bibr" rid="bib87">Wang, 1999</xref>). It is, however, unrealistic to expect that this approach could also be used for shutting down distributed WM patterns, as it would require a large-scale synchronous inhibitory pulse to all active areas.</p><p>We therefore explore in our model whether more spatially selective signals can shut down distributed patterns of activity. In spite of their robustness to sensory distractors as discussed above, we find that distributed WM activity patterns can be shut down with an excitatory input targeting inhibitory populations of areas high in the hierarchy. <xref ref-type="fig" rid="fig7">Figure 7C</xref> (bottom row) shows how a visually evoked distributed WM attractor is deactivated when we deliver excitatory input to the inhibitory populations in the top four areas of the hierarchy (9/46v, 9/46d, F7 and 8B). These prefrontal areas are spatially localized and thought to be highly engaged in WM maintenance, and therefore they are suitable candidates to control the suppression of sustained activity in other cortical areas, such as areas LIP and 24c. Therefore, in spite of engaging cortical areas across all four lobes, distributed WM attractors can be controlled and deactivated by localized inhibition to a small set of frontal areas.</p><p>Finally, the distributed nature of WM has also implications for the impact of distractors and similar sensory perturbations on maintenance of selective activity and overall performance of the network. We simulated a delayed response task with distractors (<xref ref-type="fig" rid="fig8">Figure 8A</xref>), in which stimulus A is cued to be maintained in WM and stimulus B is presented as distractor during the delay period (and vice versa). When simulated in the localized WM network, we observed that distractors with the same saliency than the original cue were sufficient to switch the network into the new stimuli, making the network easy to distract (<xref ref-type="bibr" rid="bib12">Compte et al., 2000</xref>; <xref ref-type="fig" rid="fig8">Figure 8B</xref>). For the case of distributed WM, however, the network was highly resilient, and distractors with similar saliency levels as the input cues were filtered out by the network so that working memory storage is preserved (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). Overall, we found that localized WM networks can be distracted with stimuli similar or even weaker than the minimum cue input strength required to encode a WM pattern, while effective distractors need to be about three times as strong in the case of distributed WM networks (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). This difference is due to the robustness of a distributed attractor compared to a local circuit mechanism, but also to the effect of the counterstream inhibitory bias which dampens the propagation of distractor signals (cf. MT responses in <xref ref-type="fig" rid="fig8">Figure 8B and C</xref>). This constitutes a key difference between distributed and local WM models feasible of experimental validation.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Resistance to distractors in localized vs distributed WM.</title><p>(<bold>A</bold>) Scheme of the WM task with a distractor, with the cue (current pulse of strength I<sub>A</sub> = 0.3 and duration 500ms) preceding the distractor (I<sub>B</sub> = 0.3, 500ms) by four seconds. (<bold>B</bold>) Activity traces of selected areas during the task, for a network displaying localized WM (J<sub>max</sub> = 0.468, G = 0.21). (<bold>C</bold>) Same as panel B, but for a model displaying distributed WM (J<sub>max</sub> = 0.26, G = 0.48). (<bold>D</bold>) Minimal strength required by the cue (blue) to elicit a sustained activity state, and minimal strength required by the distractor (purple) to remove the sustained activity, both for localized WM (left) and distributed WM (right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-fig8-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The investigation of cognitive functions has been traditionally restricted to operations in local brain circuits –mostly due to the limitations on available precision recording techniques to local brain regions, a problem that recent developments are starting to overcome (<xref ref-type="bibr" rid="bib45">Jun et al., 2017</xref>; <xref ref-type="bibr" rid="bib67">Panichello and Buschman, 2021</xref>; <xref ref-type="bibr" rid="bib76">Siegel et al., 2015</xref>; <xref ref-type="bibr" rid="bib80">Stringer et al., 2019</xref>). It is therefore imperative to advance in the study of distributed cognition using computational models as well, to support experimental advances. In this work, we have presented a large-scale circuit mechanism of distributed working memory, realized by virtue of a new concept of robust transition in space. The distributed WM scenario is compatible with recent observations of multiple cortical areas participating in WM tasks (<xref ref-type="bibr" rid="bib11">Christophel et al., 2017</xref>; <xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Sreenivasan and D’Esposito, 2019</xref>), even when some of these areas have not been traditionally associated with WM. Importantly, considering distributed WM in a truly large-scale network has revealed phenomena such as the transition in cortical space (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), the counterstream inhibition (<xref ref-type="fig" rid="fig4">Figure 4</xref>) and the diverse pool of available attractors (<xref ref-type="fig" rid="fig5">Figure 5</xref>) which would not emerge when studying systems of one or two cortical areas as in <xref ref-type="bibr" rid="bib19">Edin et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Murray et al., 2017b</xref>.</p><p>One of the main ingredients of the model is the gradient of excitation across the cortical hierarchy, implemented via an increase of excitatory recurrent connections (hinted by the existing anatomical evidence on dendritic spines on pyramidal cells across multiple cortical areas <xref ref-type="bibr" rid="bib27">Elston, 2007</xref>). The particular values of projection strengths do not impact the emergence of distributed WM patterns, but they influence the performance of individual areas (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2E-H</xref>). Moreover, we introduce the concept of counterstream inhibitory bias (CIB) which was found to stabilize distributed yet spatially confined mnemonic sustained activity patterns in spite of dense inter-areal connectivity. Evidence compatible with CIB includes anatomical studies of feedback projections targeting supragranular layers (<xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>; <xref ref-type="bibr" rid="bib69">Rockland and Van Hoesen, 1994</xref>), which contain multiple types of inhibitory neurons, and electrophysiological studies showing that figure-ground segregation requires at least partially inhibitory feedback (<xref ref-type="bibr" rid="bib39">Hupé et al., 1998</xref>). CIB is also compatible with other theoretical frameworks such as predictive coding, which require inhibitory feedback to minimize prediction errors along the cortical hierarchy (<xref ref-type="bibr" rid="bib5">Bastos et al., 2012</xref>).</p><p>Macroscopic gradients and hierarchical structures have recently been proposed as a general principle for understanding heterogeneities in the cortex (<xref ref-type="bibr" rid="bib91">Wang, 2020</xref>). A standing challenge is to clarify how structural gradients relate to functional ones –for example, the gradual progression from sensory-related to task-related activity as one ascends in the cortical hierarchy, or the higher mixed selectivity in higher cortical areas. For example, it has been shown that gradients of circuit properties in line with hierarchical structures contribute to the emergence of a gradient of time scales across cortex, supporting slow dynamics in prefrontal areas (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Murray et al., 2014</xref>; <xref ref-type="bibr" rid="bib91">Wang, 2020</xref>) (see also <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>), and also that a hierarchical organization of functional states could serve as basis for WM-guided decisions and executive control (<xref ref-type="bibr" rid="bib61">Miller et al., 2018</xref>; <xref ref-type="bibr" rid="bib63">Muhle-Karbe et al., 2020</xref>). It is possible that structural gradients would play a role not only in other cognitive functions in monkeys, but also in other animals including mice (<xref ref-type="bibr" rid="bib31">Fulcher et al., 2019</xref>) and humans (<xref ref-type="bibr" rid="bib9">Burt et al., 2018</xref>; <xref ref-type="bibr" rid="bib16">Demirtaş et al., 2019</xref>).</p><p>Theoretically, the present work is the first to show that graded changes of circuit properties along the cortical hierarchy provides a mechanism to explain qualitatively distinct functions of different cortical areas (whether engaged in working memory). This is reminiscent of the phenomenon mathematically called bifurcation, which denotes the emergence of novel behavior as a result of quantitative property change as a control parameter in a nonlinear dynamical system (<xref ref-type="bibr" rid="bib81">Strogatz, 1994</xref>). Our model displays a novel form of transition across the cortex, which cannot be simply explained by a parameter change laid out spatially by virtue of a macroscopic gradient, because areas are densely connected with each other in a complex large-scale network. Such a transition implies that a few association areas should exhibit signs of dynamical criticality akin to water near a transition between gas and liquid states. This will be explored further in the future.</p><p>Interestingly, the model uncovered a host of distinct sustained activity attractor states, each with its own transition location in the cortical tissue. They are defined by their spatial distributed patterns in the large-scale cortical system, independent of the number of selective neural pools per area (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Many of these mnemonic activity states are not produced by stimulation of primary sensory areas. These attractor internal states could serve various forms of internal representations such as those that are not triggered by a particular sensory pathway –or those triggered by sensory input but are encoded differently as memories (<xref ref-type="bibr" rid="bib59">Mendoza-Halliday and Martinez-Trujillo, 2017</xref>). The identification of these internal representations in further detail are beyond the scope of the present study, but uncovering their functional role should be within reach of additional experimental and computational work.</p><p>Although our proposal extends the idea of attractor dynamics to the scale of large networks, there are several fundamental differences between our model and standard Hopfield-like models of local attractor dynamics. In a large network in which the areas share a preferred selectivity (i.e. the population ‘A’ in <xref ref-type="fig" rid="fig1">Figure 1B</xref>), a Hopfield model would trigger a sustained activity of all the populations selective to ‘A’ across the network, which is incompatible with experimental observations (<xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>). More complex patterns with early sensory areas inactive can be learned by Hopfield models, but only at the expense of modifying the selectivity of population ‘A’ in those areas. On the other hand, our model considers the gradient of properties as a partial solution to this problem, and even tests the validity of such solutions for realistic local coupling levels, which in turn leads to the prediction of the CIB. Overall, our model constitutes an example of how classical ideas of local circuit dynamics may be translated to large-scale networks, and the corresponding new theoretical insights that such process brings along.</p><sec id="s3-1"><title>Extending the model of distributed working memory</title><p>The reported model of large-scale cortical networks is, to the best of our knowledge, the first of its kind addressing a cardinal cognitive function in a data-constrained way, and it opens the door for elucidating this and similar complex brain processes in future research. Several avenues may be taken to extend the functionality of the present model. First, it is straightforward to have an arbitrary number of selective neural pools per area (<xref ref-type="bibr" rid="bib87">Wang, 1999</xref>), which would increase both the selectivity to sensory inputs and the available number of distributed WM attractors. In that case, more complex connections (not necessarily A to A, B to B, etc.) can be investigated, including a distance-dependent ‘ring structure’ (<xref ref-type="bibr" rid="bib12">Compte et al., 2000</xref>) or random connections (<xref ref-type="bibr" rid="bib7">Bouchacourt and Buschman, 2019</xref>). Second, the model presented here is limited to 30 cortical areas, and can be expanded to include both additional cortical areas and subcortical structures relevant for working memory such as thalamic nuclei <xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Jaramillo et al., 2019</xref> as their connectivity data become available. Interesting extensions in this sense could involve mouse connectomics, to explore the role of thalamocortical loops (<xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>) in sustained activity (although working memory mechanisms could differ between rodents and primates), and human connectomics, to reveal the potential influence of complex network structures in the emergence of distributed distractors (<xref ref-type="bibr" rid="bib4">Bassett and Sporns, 2017</xref>; <xref ref-type="bibr" rid="bib16">Demirtaş et al., 2019</xref>; <xref ref-type="bibr" rid="bib85">van den Heuvel and Sporns, 2013</xref>). Third, electrophysiological recording from multiple brain areas could be used to further constrain the dynamics of the model. For example, when extending the model to more complex WM tasks involving components of attention or sensorimotor decisions, additional electrophysiological data could improve the model’s predictive power, especially for areas such as V4 or LIP (<xref ref-type="bibr" rid="bib67">Panichello and Buschman, 2021</xref>; <xref ref-type="bibr" rid="bib76">Siegel et al., 2015</xref>). Fourth, the model can be improved by incorporating more biological details such as cortical layers (<xref ref-type="bibr" rid="bib58">Mejias et al., 2016</xref>), contributions of different neuromodulators, and various types of inhibitory neurons.</p></sec><sec id="s3-2"><title>Attractor model of working memory and activity-silent state models</title><p>In the description adopted here, we have considered that working memory maintained via selective activity is described as an attractor state (<xref ref-type="bibr" rid="bib2">Amit and Brunel, 1997</xref>; <xref ref-type="bibr" rid="bib13">Compte, 2006</xref>; <xref ref-type="bibr" rid="bib88">Wang, 2001</xref>). Other mechanisms have also been proposed, including the maintenance of memories via feedforward mechanisms and activity-silent state mechanisms (<xref ref-type="bibr" rid="bib3">Barbosa et al., 2020</xref>; <xref ref-type="bibr" rid="bib34">Goldman, 2009</xref>; <xref ref-type="bibr" rid="bib46">Kamiński and Rutishauser, 2020</xref>; <xref ref-type="bibr" rid="bib61">Miller et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Mongillo et al., 2008</xref>; <xref ref-type="bibr" rid="bib79">Stokes, 2015</xref>; <xref ref-type="bibr" rid="bib83">Trübutschek et al., 2017</xref>; <xref ref-type="bibr" rid="bib94">Wolff et al., 2017</xref>). Importantly, not limited to steady-states, the attractor framework is fully consistent with temporal variations of delay activity. For instance, during a mnemonic delay a working memory circuit can exhibit stochastic oscillations in the gamma (~40Hz) frequency range, in which neurons often stop momentarily before resuming spike firing, the temporal gap of silence is bridged by slow synaptic reverberation (<xref ref-type="bibr" rid="bib12">Compte et al., 2000</xref>; <xref ref-type="bibr" rid="bib51">Lundqvist et al., 2016</xref>). Another example is self-sustained repetition of brief bursts of spikes interspersed with long silent time epochs (<xref ref-type="bibr" rid="bib60">Mi et al., 2017</xref>). As discussed in a recent review (<xref ref-type="bibr" rid="bib92">Wang, 2021</xref>), the real conceptual alternative to attractor states is transient activity that fades away in time while a memory trace remains as a hidden state. The biological mechanisms such as the NMDA receptors at recurrent excitatory synapses or short-term synaptic plasticity are not fundamentally separate. A stable (attractor) state does not mean the absence of short-term synaptic facilitation which, as an activity-dependent process can contribute to the maintenance of an attractor state by supplying sufficient excitatory reverberation (<xref ref-type="bibr" rid="bib38">Hempel et al., 2000</xref>; <xref ref-type="bibr" rid="bib68">Pereira and Wang, 2015</xref>; <xref ref-type="bibr" rid="bib60">Mi et al., 2017</xref>), enhance robustness of self-sustained mnemonic activity (<xref ref-type="bibr" rid="bib37">Hansel and Mato, 2013</xref>; <xref ref-type="bibr" rid="bib42">Itskov et al., 2011</xref>; <xref ref-type="bibr" rid="bib56">Mejias and Torres, 2009</xref>; <xref ref-type="bibr" rid="bib57">Mejias et al., 2012</xref>; <xref ref-type="bibr" rid="bib68">Pereira and Wang, 2015</xref>; <xref ref-type="bibr" rid="bib74">Seeholzer et al., 2019</xref>) and induce cross-trial serial effects (<xref ref-type="bibr" rid="bib3">Barbosa et al., 2020</xref>; <xref ref-type="bibr" rid="bib6">Bliss et al., 2017</xref>). When the combined strength of excitatory-to-excitatory connections and short-term plasticity is sufficient to maintain a mnemonic state, it is mathematically described as an attractor, no matter how complex its spatiotemporal dynamics may be; otherwise, there is not enough reverberation and neural firing would decay over time over a sufficiently long delay period and never returns spontaneously (<xref ref-type="bibr" rid="bib62">Mongillo et al., 2008</xref>). Strictly speaking, only the latter should be referred to as activity-silent. An activity-silent state also depends on spiking activity to refresh hidden memory traces and to readout the stored information content. Short-term plasticity could therefore contribute to activity-silent memory traces but also to self-sustained activity. It is worth noting that the above discussion is limited to a local circuit model. The assumed absence of any input to it is unlikely to hold in real life, when there are always external stimulation from the environment and internal processes (e.g. intruding thoughts) in other brain regions that project to the local area under consideration. A mixture of activity-silent state and episodic spikes caused by inputs from the rest of the brain represents an interesting possibility that a local network model is not suitable to investigate. Multi-regional modeling as reported here in interplay with new experiments in the future will shed insights into such a scenario.</p><p>Multi-regional network modeling should be extended to explore complex dynamics and cell-to-cell heterogeneity of neural population activity patterns underlying working memory representations (<xref ref-type="bibr" rid="bib17">Druckmann and Chklovskii, 2012</xref>; <xref ref-type="bibr" rid="bib40">Hussar and Pasternak, 2009</xref>; <xref ref-type="bibr" rid="bib50">Lim and Goldman, 2013</xref>; <xref ref-type="bibr" rid="bib65">Murray et al., 2017a</xref>; <xref ref-type="bibr" rid="bib79">Stokes, 2015</xref>; <xref ref-type="bibr" rid="bib93">Wimmer et al., 2016</xref>). There is no reason to think that the encoding of memory items could not use the complex spatiotemporal interactions between brain areas instead of just local interactions. A large-scale implementation of WM also pairs well with recent hypotheses in which memory selectivity is reached via dynamical flexibility instead of content-based attractors, since the wide number and heterogeneity of long-range projections would reduce connection overlap and alleviate the limit capacity of these models (<xref ref-type="bibr" rid="bib7">Bouchacourt and Buschman, 2019</xref>). The use of inter-areal interactions to sustain WM-related activity has been explored in other recent works (<xref ref-type="bibr" rid="bib19">Edin et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Guo et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Murray et al., 2017b</xref>); however, this was limited to two-area systems and the models were not anatomically constrained, therefore limiting their predictive power. Frameworks of WM in which oscillations play an active role, for example regarding WM-guided executive control (<xref ref-type="bibr" rid="bib61">Miller et al., 2018</xref>), may benefit from using distributed WM approaches, given the usefulness of previous models of large-scale brain networks to explain oscillatory phenomena in the macaque brain (<xref ref-type="bibr" rid="bib58">Mejias et al., 2016</xref>). Finally, with a simplified model we show that, when short-term facilitation is incorporated at an appropriate level, it enhances the synaptic efficacy in areas at the top of the hierarchy. A more extended consideration of short-term synaptic plasticity, and the contrast between self-sustained activity versus activity-silent state was reported elsewhere (<xref ref-type="bibr" rid="bib30">Froudist-Walsh et al., 2021</xref>).</p></sec><sec id="s3-3"><title>Experimental predictions provided by our model</title><p>The distributed WM model presented here yields four experimentally testable predictions in monkey (and potentially rodent) experiments, which can be used to validate our theory. First, the model predicts a positive correlation between the number of areas involved in a WM task and their average firing rate of sustained activity (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). Such relationship should not occur according to models of localized WM, since activity levels would be fairly independent across areas. Only a distributed WM model in which neurons of similar selectivity (but located at different areas) support each other via long-range projections would lead to this prediction. This prediction could be tested with neuroimaging experiments, by correlating the level of activation of different brain regions during WM with the number of regions activated. Existing data could be used to carefully test this prediction in future studies. A complementary version of this prediction is that, if areas displaying sustained activity are silenced (e.g. optogenetically), the activity of the other sustained activity areas will decrease (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p><p>Second, our model predicts that areas involved in distributed WM patterns can be briefly silenced without losing the encoded information, which will be recovered as soon as the inhibition is gone (<xref ref-type="fig" rid="fig7">Figure 7</xref>, middle row), something that localized WM do not predict (<xref ref-type="fig" rid="fig7">Figure 7</xref> top row; see however, related effects on continuous attractor models <xref ref-type="bibr" rid="bib74">Seeholzer et al., 2019</xref>). As in the first prediction, large-scale interactions across neurons of similar selectivity are a condition for this phenomenon, according to our model. Optogenetic inactivations could be used to test this result.</p><p>Third, distributed WM is significantly more robust to distractors than localized WM (<xref ref-type="fig" rid="fig8">Figure 8</xref>), due to their intrinsic resilience and the inhibitory feedback condition. Behavioral and neuroimaging experiments in macaques should be able to test this, by testing potential correlations between the spatial extension of a distributed WM pattern and its robustness of the corresponding trials to distractors.</p><p>Fourth, electrophysiological recordings in macaques could test whether FEF areas require support from frontal areas (in the form of strong excitation) to maintain WM-related activity (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). In particular, coactivation between FEF and frontal areas could be correlated with elevated activity in FEF neurons. Although this prediction focuses on a particular set of areas, it should shed light into unclear aspects of FEF dynamics.</p><p>In a more general sense, our model predicts a reversed gradient of inhibition and strong large-scale interactions to sustain distributed WM patterns, which may be observed using different experimental approaches. It will also be interesting to see whether the same model is able to account for decision-making processes as well as working memory (<xref ref-type="bibr" rid="bib89">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib95">Wong and Wang, 2006</xref>).</p><p>Given that our model is constrained using data from the macaque brain, it is interesting to discuss which of our results would extend to other conditions (and, in particular, to other animal models). First, we have shown with the simplified model (<xref ref-type="fig" rid="fig3">Figure 3</xref>) that the emergence of distributed WM requires minimal elements and is therefore likely to emerge in cortical networks of other animals such as rodents or humans. The existence of a CIB (<xref ref-type="fig" rid="fig4">Figure 4</xref>) is a requirement for distributed WM as long as the gradient of local properties grows sublinearly, which makes the CIB a plausible condition in other species as well. Our results on the activity and number of attractors (<xref ref-type="fig" rid="fig5">Figure 5</xref>) and the effects of silencing (<xref ref-type="fig" rid="fig6">Figures 6</xref> and <xref ref-type="fig" rid="fig7">7</xref>) are highly dependent on the anatomical constraints used, so their validity will need to be tested for rodents and humans. Finally, the results on the robustness to distractors (<xref ref-type="fig" rid="fig8">Figure 8</xref>) rely on the presence of distributed activity (with moderated values of local coupling strengths) and the effect of the CIB on incoming distractor signals, so as long as these ingredients are present in other species, we should expect these effects to be there as well.</p><p>Conceptually, this work revealed a novel mechanism in cortical space to generate differential functions across different cortical areas, a concept that is likely to be generalizable for understanding how distinct cortical areas endowed with a canonical circuit organization are at the same time suited for differential functions (<xref ref-type="bibr" rid="bib91">Wang, 2020</xref>).</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Anatomical data</title><p>The anatomical connectivity data used has been gathered in an ongoing track tracing study in macaque and has been described in detail elsewhere (<xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>; <xref ref-type="bibr" rid="bib54">Markov et al., 2014b</xref>; <xref ref-type="bibr" rid="bib58">Mejias et al., 2016</xref>). Briefly, retrograde tracer injected into a given target area labels neurons in a number of source areas projecting to the target area. By counting the number of labeled neurons on a given source area, Markov et al. defined the fraction of labeled neurons (FLN) from that source to the target area. FLN can serve as a proxy for the ‘connection strength’ between two cortical areas, which yields the connectivity pattern of the cortical network (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A-B</xref>). In addition, Markov et al. also measured the number of labeled neurons on the supragranular layer of a given source area. Dividing this number over the total number of labeled neurons on that area, we can define the supragranular layered neurons (SLN) from that source to the target area (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C-D</xref>).</p><p>SLN values may be used to build a well-defined anatomical hierarchy (<xref ref-type="bibr" rid="bib29">Felleman and Van Essen, 1991</xref>; <xref ref-type="bibr" rid="bib54">Markov et al., 2014b</xref>). Source areas located lower (higher) than the target area in the anatomical hierarchy, as defined in <xref ref-type="bibr" rid="bib29">Felleman and Van Essen, 1991</xref>, display a progressively higher (lower) proportion of labeled neurons in the supragranular layer. As a consequence, the lower (higher) the source area relative to the target area, the higher (lower) the SLN values of the source-to-target projection. By performing a logistic regression on the SLN data to accommodate each area in its optimal position in the anatomical hierarchy (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 2015</xref>), we assign a hierarchical value h<sub>i</sub> to each area ‘i’.</p><p>Iterating these measurements across other anatomical areas yields an anatomical connectivity matrix with weighted directed connections and an embedded structural hierarchy. The 30 cortical used to build our data-constrained large-scale brain network are, in hierarchical order: V1, V2, V4, DP, MT, 8 m, 5, 8 l, 2, TEO, F1, STPc, 7 A, 46d, 10, 9/46 v, 9/46d, F5, TEpd, PBr, 7 m, LIP, F2, 7B, ProM, STPi, F7, 8B, STPr and 24 c. Finally, data on wiring connectivity distances between cortical areas is available for this dataset as well, allowing to consider communication time lags when necessary (we found however that introducing time lags this way does not have a noticeable impact on the dynamics of our model). The connectivity data used here is available to other researchers from <ext-link ext-link-type="uri" xlink:href="https://core-nets.org">https://core-nets.org</ext-link>.</p><p>The corresponding 30 × 30 matrices of FLN and SLN are shown in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B, D</xref>. Areas in these matrices are arranged following the anatomical hierarchy, which is computed with the SLN values and a generalized linear model (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Mejias et al., 2016</xref>). Surgical and histology procedures followed European requirements 86/609/EEC and were approved by the ethics committee of the Rhone-Alpes region.</p><p>In addition to the data on FLN and SLN across 30 cortical areas, we used additional data to constrain the area-to-area differences in the large-scale brain network. In particular, we have collected data on the total spine count of layer 2/3 pyramidal neuron basal dendrites across different cortical areas, as the spine count constitutes a proxy for the density of synaptic connections within a given cortical area (<xref ref-type="bibr" rid="bib27">Elston, 2007</xref>). A full list of all area-specific values of spine densities considered and their sources is given in <xref ref-type="table" rid="table1">Table 1</xref>. We use an age correction factor meant to correct for the decrease of spine counts with age for data obtained from old monkeys. A plausible estimate would be a ~ 30% decrease for a 10y difference (<xref ref-type="bibr" rid="bib18">Duan et al., 2003</xref>; <xref ref-type="bibr" rid="bib97">Young et al., 2014</xref>). See <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref> for the effect of this correction on the overall gradient established by the spine count data, and the correlation of such gradient with the SLN hierarchy.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Spine count data from basal dendrites of layer 2/3 pyramidal neurons in young (~2y o) macaque, acquired from the specified literature.</title><p>See also <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Rank in SLN hierarchy</th><th align="left" valign="bottom">Area name</th><th align="left" valign="bottom">Measured spine count</th><th align="left" valign="bottom">Age correction factor</th><th align="left" valign="bottom">Source</th></tr></thead><tbody><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">V1</td><td align="char" char="." valign="bottom">643</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib23">Elston et al., 1999</xref>; <xref ref-type="bibr" rid="bib20">Elston and Rosa, 1997</xref></td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">V2</td><td align="char" char="." valign="bottom">1201</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib20">Elston and Rosa, 1997</xref></td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">V4</td><td align="char" char="." valign="bottom">2429</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib22">Elston and Rosa, 1998b</xref></td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">DP</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">5</td><td align="left" valign="bottom">MT</td><td align="char" char="." valign="bottom">2077</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib23">Elston et al., 1999</xref></td></tr><tr><td align="char" char="." valign="bottom">6</td><td align="char" char="." valign="bottom">8m</td><td align="char" char="." valign="bottom">3200</td><td align="char" char="." valign="bottom">1.30</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib22">Elston and Rosa, 1998b</xref></td></tr><tr><td align="char" char="." valign="bottom">7</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">4689</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib25">Elston and Rockland, 2002</xref></td></tr><tr><td align="char" char="." valign="bottom">8</td><td align="char" char="." valign="bottom">8l</td><td align="char" char="." valign="bottom">3200</td><td align="char" char="." valign="bottom">1.30</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib22">Elston and Rosa, 1998b</xref></td></tr><tr><td align="char" char="." valign="bottom">9</td><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">10</td><td align="left" valign="bottom">TEO</td><td align="char" char="." valign="bottom">4812</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib22">Elston and Rosa, 1998b</xref></td></tr><tr><td align="char" char="." valign="bottom">11</td><td align="left" valign="bottom">F1</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">12</td><td align="left" valign="bottom">STPc</td><td align="char" char="." valign="bottom">8337</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib23">Elston et al., 1999</xref></td></tr><tr><td align="char" char="." valign="bottom">13</td><td align="char" char="." valign="bottom">7a</td><td align="char" char="." valign="bottom">2572</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib20">Elston and Rosa, 1997</xref>; <xref ref-type="bibr" rid="bib21">Elston and Rosa, 1998a</xref></td></tr><tr><td align="char" char="." valign="bottom">14</td><td align="char" char="." valign="bottom">46d</td><td align="char" char="." valign="bottom">6600</td><td align="char" char="." valign="bottom">1.15</td><td align="left" valign="bottom">Estimated from <xref ref-type="bibr" rid="bib27">Elston, 2007</xref>;</td></tr><tr><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">10</td><td align="char" char="." valign="bottom">6488</td><td align="char" char="." valign="bottom">1.15</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib28">Elston et al., 2011</xref></td></tr><tr><td align="char" char="." valign="bottom">16</td><td align="char" char="." valign="bottom">9/46 v</td><td align="char" char="." valign="bottom">7800</td><td align="char" char="." valign="bottom">1.15</td><td align="left" valign="bottom">Estimated from <xref ref-type="bibr" rid="bib27">Elston, 2007</xref></td></tr><tr><td align="char" char="." valign="bottom">17</td><td align="char" char="." valign="bottom">9/46d</td><td align="char" char="." valign="bottom">7800</td><td align="char" char="." valign="bottom">1.15</td><td align="left" valign="bottom">Estimated from <xref ref-type="bibr" rid="bib27">Elston, 2007</xref></td></tr><tr><td align="char" char="." valign="bottom">18</td><td align="left" valign="bottom">F5</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">19</td><td align="left" valign="bottom">TEpd</td><td align="char" char="." valign="bottom">7260</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib23">Elston et al., 1999</xref></td></tr><tr><td align="char" char="." valign="bottom">20</td><td align="left" valign="bottom">PBr</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">21</td><td align="char" char="." valign="bottom">7m</td><td align="char" char="." valign="bottom">2294</td><td align="char" char="." valign="bottom">1.30</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib24">Elston, 2001</xref></td></tr><tr><td align="char" char="." valign="bottom">22</td><td align="left" valign="bottom">LIP</td><td align="char" char="." valign="bottom">2316</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib20">Elston and Rosa, 1997</xref>; <xref ref-type="bibr" rid="bib21">Elston and Rosa, 1998a</xref></td></tr><tr><td align="char" char="." valign="bottom">23</td><td align="left" valign="bottom">F2</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">24</td><td align="char" char="." valign="bottom">7B</td><td align="char" char="." valign="bottom">6841</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib25">Elston and Rockland, 2002</xref></td></tr><tr><td align="char" char="." valign="bottom">25</td><td align="left" valign="bottom">ProM</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">26</td><td align="left" valign="bottom">STPi</td><td align="char" char="." valign="bottom">8337</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib23">Elston et al., 1999</xref></td></tr><tr><td align="char" char="." valign="bottom">27</td><td align="left" valign="bottom">F7</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">28</td><td align="char" char="." valign="bottom">8B</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">29</td><td align="left" valign="bottom">STPr</td><td align="char" char="." valign="bottom">8337</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib23">Elston et al., 1999</xref></td></tr><tr><td align="char" char="." valign="bottom">30</td><td align="char" char="." valign="bottom">24 c</td><td align="char" char="." valign="bottom">6825</td><td align="char" char="." valign="bottom">1.15</td><td align="char" char="." valign="bottom"><xref ref-type="bibr" rid="bib26">Elston et al., 2005</xref></td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>Experimental evidence of WM-related activity across cortical areas</title><p>To compare the results of our model with existing evidence, we generated brain maps highlighting areas for which experimental evidence of WM-related activity during the delay period has been found. Following the data collected by recent review studies (<xref ref-type="bibr" rid="bib11">Christophel et al., 2017</xref>; <xref ref-type="bibr" rid="bib48">Leavitt et al., 2017</xref>), we distinguish between three categories. First, areas with strong WM evidence (for which at least two studies show support of WM-related activity, or if only studies supporting WM activity are known) are shown in dark blue in the maps of <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig4">4</xref>. Second, areas with moderate evidence (for which substantial positive and negative evidence exist) are shown in light blue. Finally, areas for which strong negative evidence exists (more than two studies with negative evidence, or absence of any positive studies) are left as grey in the map. Alternative criteria have only small effects on the resulting maps and the general results are consistent to variations.</p></sec><sec id="s4-3"><title>Computational model: local neural circuit</title><p>We describe the neural dynamics of the local microcircuit representing a cortical area with the Wong-Wang model (<xref ref-type="bibr" rid="bib95">Wong and Wang, 2006</xref>). In its three-variable version, this model describes the temporal evolution of the firing rate of two input-selective excitatory populations as well as the evolution of the firing rate of an inhibitory population. All populations are connected to each other (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>). The model is described by the following equations:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula><disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula><disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>Here, S<sub>A</sub> and S<sub>B</sub> are the NMDA conductances of selective excitatory populations A and B respectively, and S<sub>C</sub> is the GABAergic conductance of the inhibitory population. Values for the constants are τ<sub>N</sub>=60 ms, τ<sub>G</sub>=5 ms, <italic>γ</italic> = 1.282 and γ<sub>I</sub>=2. The variables r<sub>A</sub>, r<sub>B</sub> and r<sub>C</sub> are the mean firing rates of the two excitatory and one inhibitory populations, respectively. They are obtained by solving, at each time step, the transcendental equation <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> (where <inline-formula><mml:math id="inf10"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> is the transfer function of the population, detailed below), with I<sub>i</sub> being the input to population ‘i’, given by<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>In these expressions, J<sub>s</sub>, J<sub>c</sub> are the self- and cross-coupling between excitatory populations, respectively, J<sub>EI</sub> is the coupling from the inhibitory populations to any of the excitatory ones, J<sub>IE</sub> is the coupling from any of the excitatory populations to the inhibitory one, and J<sub>II</sub> is the self-coupling strength of the inhibitory population. The parameters I<sub>0i</sub> with i = A, B, C are background inputs to each population. Parameters are J<sub>s</sub> = 0.3213 nA, J<sub>c</sub> = 0.0107 nA, J<sub>IE</sub> = 0.15 nA, J<sub>EI</sub> = −0.31 nA, J<sub>II</sub> = −0.12 nA, I<sub>0A</sub>=I<sub>0B</sub> = 0.3294 nA and I<sub>0C</sub>=0.26 nA. Later we will modify some of these parameters in an area-specific manner (in particular J<sub>s</sub> and J<sub>IE</sub>) to introduce a gradient of properties across the cortical hierarchy. The term I<sup>i</sup><sub>net</sub> denotes the long-range input coming from other areas in the network, which we will keep as zero for now but will be detailed later. Sensory stimulation can be introduced here as extra pulse currents of strength I<sub>pulse</sub> = 0.3 and duration T<sub>pulse</sub> = 0.5 sec (unless specified otherwise).</p><p>The last term x<sub>i</sub>(t) with i = A, B, C is an Ornstein-Uhlenbeck process, which introduces some level of stochasticity in the system. It is given by<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>Here, ξ<sub>i</sub>(t) is a Gaussian white noise, the time constant is τ<sub>noise</sub>=2 ms and the noise strength is σ<sub>A,B</sub>=0.005 nA for excitatory populations and σ<sub>C</sub>=0 for the inhibitory one.</p><p>The transfer function ϕ<sub>i</sub>(t) which transform the input into firing rates takes the following form for the excitatory populations (<xref ref-type="bibr" rid="bib1">Abbott and Chance, 2005</xref>):<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>The values for the parameters are <italic>a</italic> = 135 Hz/nA, <italic>b</italic> = 54 Hz, and <italic>d</italic> = 0.308 s. For the inhibitory population a similar function can be used, but for convenience we choose a threshold-linear function:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></disp-formula></p><p>The notation <inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> denotes rectification. The values for the parameters are g<sub>I</sub> = 4, c<sub>1</sub> = 615 Hz/nA, c<sub>0</sub> = 177 Hz and r<sub>0</sub> = 5.5 Hz. Finally, it is sometimes useful for simulations (although not a requirement) to replace the transcendental equation <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> by its analogous differential equation, of the form<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>The time constant can take a typical value of τ<sub>r</sub>=2 ms.</p></sec><sec id="s4-4"><title>Computational model: gradient of synaptic strengths</title><p>Before considering the large-scale network and the inter-areal connections, we look into the area-to-area heterogeneity to be included in the model.</p><p>Our large-scale cortical system consists of N = 30 local cortical areas, for which inter-areal connectivity data is available. Each cortical area is described as a Wong-Wang model of three populations like the ones described in the previous section. Instead of assuming areas to be identical to each other, here we will consider some of the natural area-to-area heterogeneity that has been found in anatomical studies. For example, work from <xref ref-type="bibr" rid="bib27">Elston, 2007</xref> has identified a gradient of dendritic spine density, from low spine numbers (~600) found in early sensory areas to large spine counts (~9000) found in higher cognitive areas. On the other hand, EPSP have similar values both in early sensory (~1.7 ± 1.3 mV) and higher cognitive areas (~0.55 ± 0.43 mV). The combination of these findings suggests an increase of local recurrent strength as we move from sensory to association areas. In addition, cortical areas are distributed along an anatomical hierarchy (<xref ref-type="bibr" rid="bib29">Felleman and Van Essen, 1991</xref>; <xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>). The position of a given area ‘i’ within this hierarchy, namely h<sub>i</sub>, can be computed with a generalized linear model using data on the SLN (fraction of supragranular layer neurons) projecting to and from that area. In particular, we assigned hierarchical values to each area such that the difference in values predicts the SLN of a projection. Concretely, we assign a value H<sub>i</sub> to each area A<sub>i</sub> so that SLN(A<sub>j</sub>→ A<sub>i</sub>)~ f (H<sub>i</sub>-H<sub>j</sub>), with ‘f’ being a logistic regression. The final hierarchical values are then obtained by normalizing h<sub>i</sub> = H<sub>i</sub>/H<sub>max</sub>. Further details on the regression are provided elsewhere (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Markov et al., 2014b</xref>).</p><p>In the following, we will assign the incoming synaptic strength (both local and long-range) of a given area as a linear function of the dendritic spine count values observed in anatomical studies, with age-related corrections when necessary. Alternatively, when spine count data is not available for a given area, we will use its position in the anatomical hierarchy, which displays a high correlation with the spine count data, as a proxy for the latter. After this process, the large-scale network will display a gradient of local and long-range recurrent strength, with sensory/association areas showing weak/strong local connectivity, respectively. We denote the local and long-range strength value of a given area <italic>i</italic> in this gradient as h<sub>i</sub>, and this value normalized between zero (bottom of the gradient, area V1) and one. In summary:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>We assume therefore a gradient of values of J<sub>s</sub>, with its value going from J<sub>min</sub> to J<sub>max</sub>. Having large values of J<sub>s</sub> for association areas affects the spontaneous activity of these areas, even without considering inter-areal coupling. A good way to keep the spontaneous firing rate of these areas within physiologically realistic limits is to impose that the spontaneous activity fixed point is the same for all areas (<xref ref-type="bibr" rid="bib66">Murray et al., 2017b</xref>). To introduce this into the model, we take into account that the solutions in the spontaneous state are symmetrical: S<sub>A</sub> = S<sub>B</sub> = S (we assume zero noise for simplicity). The current entering any of the excitatory populations is then (assuming I<sub>0A</sub>=I<sub>0B</sub>=I<sub>0</sub>):<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>S</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p><p>Assuming a fast dynamics for r<sub>C</sub> and S<sub>C</sub> (mediated by GABA) as compared to S<sub>A</sub> and S<sub>B</sub> (mediated by NMDA) we can obtain the approximate expression for S<sub>C</sub>:<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>≃</mml:mo><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mi>ζ</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi></mml:math></disp-formula></p><p>with<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mi>ζ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mi>S</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mi>ζ</mml:mi><mml:mi> </mml:mi><mml:mi>S</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p><list list-type="simple"><list-item><p>The equation for the excitatory current has then the form</p></list-item></list><p>To maintain the excitatory input (and therefore the spontaneous activity level S) constant while varying J<sub>s</sub> across areas, we just have to keep the quantity <inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mi>ζ</mml:mi><mml:mo>≡</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> constant (for the original parameters of the isolated area described above, we obtain J<sub>0</sub> = 0.2112 nA). A good choice, but not the only one, is to assume that the excitatory synapses to inhibitory neurons, J<sub>IE</sub>, also scales with the ranks and with J<sub>s</sub> accordingly:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mi>ζ</mml:mi></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>This linear relationship ensures that the spontaneous solution is the same for all areas in the network. Note that deviations from this linear relationship would simply lead to different areas having slightly different spontaneous activity levels, but it does not substantially affect our main results.</p><p>Since J<sub>IE</sub> needs to be non-negative, the linear relationship above imposes a minimum value of J<sub>min</sub> = 0.205 nA for J<sub>s</sub>. The particular maximum value of J<sub>s</sub>, namely J<sub>max</sub>, will determine the type of WM model we assume. Since the bifurcation point of an isolated area is at J<sub>s</sub> = 0.4655 nA for this set of parameter values, setting J<sub>max</sub> below that value implies that all areas in the network are monostable in isolation. In this situation, any sustained activity displayed by the model will be a consequence of a global, cooperative effect due to inter-areal interactions. On the other hand, having J<sub>max</sub> above the bifurcation point means that some areas will be multistable when isolated, for example they will be intrinsically multistable and compatible with classical WM theories.</p><p>Unless specified otherwise, we assume a range of J<sub>min</sub> = 0.21 nA and J<sub>max</sub> = 0.42 nA (i.e. below the critical value), so that the model displays distributed WM without having any intrinsically bistable areas.</p></sec><sec id="s4-5"><title>Computational model: inter-areal projections</title><p>We now consider the inter-areal projections connecting isolated areas to form the large-scale cortical network. Assuming that inter-areal projections stem only from excitatory neurons (as inhibitory projections tend to be local in real circuits) and that such projections are selective for excitatory neurons, the network or long-range input term arriving at each of the populations of a given area <italic>x</italic> from all other cortical areas is given by<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mi>S</mml:mi><mml:mi>L</mml:mi><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mi>S</mml:mi><mml:mi>L</mml:mi><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mi>L</mml:mi><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, G is the global coupling strength, Z is a balancing factor, and W is the connectivity matrix (more details given below). In these equations, a superindex denotes the cortical area and a subindex the particular population within each area. The sum in all equations runs over all cortical areas of the network (N = 30). Excitatory populations A and B receive long-range inputs from equally selective units from other areas, while inhibitory populations receive inputs from both excitatory populations. Therefore, neurons in population A of a given area may be influenced by A-selective neurons of other areas directly, and by B-selective neurons of other areas indirectly, via local interneurons.</p><p>G is the global coupling strength, which controls the overall long-range projection strength in the network (G = 0.48 unless specified otherwise). Z is a factor that takes into account the relative balance between long-range excitatory and inhibitory projections. Setting Z = 1 means that both excitatory and inhibitory long-range projections are equally strong, but this does not guarantee that their effect is balanced in the target area, due to the effect of local connections. Following previous work (<xref ref-type="bibr" rid="bib66">Murray et al., 2017b</xref>), we choose to impose a balance condition that guarantees that, if populations A and B have the same activity level, their net effect on other areas will be zero –therefore highlighting the selectivity aspect of the circuits. Again, deviations from this balance condition do not strongly affect our results besides the appearance of small differences between populations A and B. Considering that the transfer function of inhibitory populations is linear and their approximately linear rate-conductance relationship, it can be shown that<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Aside from global scaling factors, the effect of long-range projections from population <italic>y</italic> to population <italic>x</italic> is influenced by two factors. The first one, <italic>W<sup>xy</sup></italic>, is the anatomical projection strength as revealed by tract-tracing data (<xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>). We use the fraction of labelled neurons (FLN) from population <italic>y</italic> to <italic>x</italic> to constrain our projections values to anatomical data. We rescale these strengths to translate the broad range of FLN values (over five orders of magnitude) to a range more suitable for our firing rate models. We use a rescaling that maintains the proportions between projection strengths, and therefore the anatomical information, that reads<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:mi>L</mml:mi><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></disp-formula></p><p>Here, the values of the rescaling are <italic>k<sub>1</sub></italic> = 1.2 and <italic>k<sub>2</sub></italic> = 0.3. The same qualitative behavior can be obtained from the model if other parameter values, or other rescaling functions, are used as long as the network is set into a standard working regime (i.e. signals propagate across areas, global synchronization is avoided, etc.) FLN values are also normalized so that <inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>F</mml:mi><mml:mi>L</mml:mi><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. While in-degree heterogeneity might impact network dynamics (<xref ref-type="bibr" rid="bib15">de Franciscis et al., 2011</xref>; <xref ref-type="bibr" rid="bib72">Roxin, 2011</xref>), this was done to have a better control of the heterogeneity levels of each area, and to minimize confounding factors such as the uncertainty on volume injections of tract tracing experiments and the influence of potential homeostatic mechanisms. In addition, and as done for the local connections, we introduce a gradient of long-range projection strengths using the spine count data: <inline-formula><mml:math id="inf15"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mo>⁡</mml:mo></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> , so that long-range projections display the same gradient as the local connectivity presented above.</p><p>The second factor that needs to be taken into account is the directionality of signal propagation across the hierarchy. Feedforward (FF) projections that are preferentially excitatory constitute a reasonable assumption which facilitate signal transmission from sensory to higher areas. On the other hand, having feedback (FB) projections with a preferential inhibitory nature contributes to the emergence of realistic distributed WM patterns (<xref ref-type="fig" rid="fig4">Figure 4</xref>) (see also previous work <xref ref-type="bibr" rid="bib54">Markov et al., 2014b</xref>; <xref ref-type="bibr" rid="bib84">Tsushima et al., 2006</xref>). This feature can be introduced, in a gradual manner, by linking the different inter-areal projections with the SLN data, which provides a proxy for the FF/FB nature of a projection (SLN = 1 means purely FF, and SLN = 0 means purely FB). In the model, we assume a linear dependence with SNL for projections to excitatory populations and with (1-SLN) for projections to inhibitory populations, as shown above.</p><p>Following recent evidence of frontal networks having primarily strong excitatory loops (<xref ref-type="bibr" rid="bib55">Markowitz et al., 2015</xref>), it is convenient to ensure that the SLN-driven modulation of FB projections between frontal areas is not too large, so that interactions between these areas are never strongly inhibitory. In practice, such constraint is only necessary for projections from frontal areas to 8 l and 8 m (which are part of the frontal eye fields) and has little effect on the behavior of our model otherwise. The introduction of this limitation has two minor consequences: (i) it allows area 8 l and 8 m to exhibit a higher level of sustained activity during distributed WM –as their hierarchical position and recurrent strength are not strong enough to sustain activity otherwise, as previously suggested in anatomical studies (<xref ref-type="bibr" rid="bib52">Markov et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Markov et al., 2014a</xref>) and (ii) it slightly shifts the transition point in cortical space (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Unless specified otherwise (and in <xref ref-type="fig" rid="fig4">Figure 4</xref>, where the limitation is not considered for a cleaner study of the effects of inhibitory feedback), we consider that the SLN-driven modulation of FB projections to 8 l and 8 m is never larger than 0.4.</p><p>Deviations from our general assumptions could occur in other areas –for example, a slightly stronger CIB value to primary somatosensory areas could prevent sustained activity in area 2, as the evidence of such activity is still controversial (<xref ref-type="bibr" rid="bib49">Lemus et al., 2010</xref>; <xref ref-type="bibr" rid="bib71">Rossi-Pool et al., 2016</xref>; <xref ref-type="bibr" rid="bib98">Zhou and Fuster, 1996</xref>).</p></sec><sec id="s4-6"><title>Gating mechanism</title><p>To implement a simple gating mechanism which modulates areas receptive to a particular type of input, we assume that, when the gate of a given area is ‘open’, the strength of incoming synaptic projections effectively increases by a quantity g<sub>s</sub>. This reflects, in a simplified way, existing gating mechanisms based on the activation of input-specific dendritic compartments, in which activation of a specific dendritic branch increases the effect of synaptic afferents targeting such dendritic branch (<xref ref-type="bibr" rid="bib96">Yang et al., 2016</xref>). The effects of such gating mechanism are shown in <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Funding acquisition, Investigation, Software, Validation, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Funding acquisition, Investigation, Validation, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-72136-transrepform1-v1.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. Modelling code has been uploaded to ModelDB.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Mejias</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Distributed working memory in large-scale macaque brain model</data-title><source>ModelDB</source><pub-id pub-id-type="accession" xlink:href="http://modeldb.yale.edu/267295">267295</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Rishidev Chaudhuri, John Murray and Jorge Jaramillo for their support during the development of this work, and Henry Kennedy for providing the connectivity dataset.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Chance</surname><given-names>FS</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Drivers and modulators from push-pull and balanced synaptic input</article-title><source>Progress in Brain Research</source><volume>149</volume><fpage>147</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(05)49011-1</pub-id><pub-id pub-id-type="pmid">16226582</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amit</surname><given-names>DJ</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title><source>Cerebral Cortex</source><volume>7</volume><fpage>237</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1093/cercor/7.3.237</pub-id><pub-id pub-id-type="pmid">9143444</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbosa</surname><given-names>J</given-names></name><name><surname>Stein</surname><given-names>H</given-names></name><name><surname>Martinez</surname><given-names>RL</given-names></name><name><surname>Galan-Gadea</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Dalmau</surname><given-names>J</given-names></name><name><surname>Adam</surname><given-names>KCS</given-names></name><name><surname>Valls-Solé</surname><given-names>J</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Interplay between persistent activity and activity-silent dynamics in the prefrontal cortex underlies serial biases in working memory</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1016</fpage><lpage>1024</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0644-4</pub-id><pub-id pub-id-type="pmid">32572236</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Network neuroscience</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>353</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.1038/nn.4502</pub-id><pub-id pub-id-type="pmid">28230844</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Mangun</surname><given-names>GR</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Canonical microcircuits for predictive coding</article-title><source>Neuron</source><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id><pub-id pub-id-type="pmid">23177956</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bliss</surname><given-names>DP</given-names></name><name><surname>Sun</surname><given-names>JJ</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Serial dependence is absent at the time of perception but increases in visual working memory</article-title><source>Scientific Reports</source><volume>7</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41598-017-15199-7</pub-id><pub-id pub-id-type="pmid">29116132</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouchacourt</surname><given-names>F</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Flexible Model of Working Memory</article-title><source>Neuron</source><volume>103</volume><fpage>147</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.04.020</pub-id><pub-id pub-id-type="pmid">31103359</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Effects of neuromodulation in a cortical network model of object working memory dominated by recurrent inhibition</article-title><source>Journal of Computational Neuroscience</source><volume>11</volume><fpage>63</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1023/a:1011204814320</pub-id><pub-id pub-id-type="pmid">11524578</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burt</surname><given-names>JB</given-names></name><name><surname>Demirtaş</surname><given-names>M</given-names></name><name><surname>Eckner</surname><given-names>WJ</given-names></name><name><surname>Navejar</surname><given-names>NM</given-names></name><name><surname>Ji</surname><given-names>JL</given-names></name><name><surname>Martin</surname><given-names>WJ</given-names></name><name><surname>Bernacchia</surname><given-names>A</given-names></name><name><surname>Anticevic</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1251</fpage><lpage>1259</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0195-0</pub-id><pub-id pub-id-type="pmid">30082915</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Gariel</surname><given-names>MA</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Large-Scale Circuit Mechanism for Hierarchical Dynamical Processing in the Primate Cortex</article-title><source>Neuron</source><volume>88</volume><fpage>419</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.008</pub-id><pub-id pub-id-type="pmid">26439530</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophel</surname><given-names>TB</given-names></name><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Spitzer</surname><given-names>B</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The Distributed Nature of Working Memory</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>111</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.12.007</pub-id><pub-id pub-id-type="pmid">28063661</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Compte</surname><given-names>A</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Synaptic mechanisms and network dynamics underlying spatial working memory in a cortical network model</article-title><source>Cerebral Cortex</source><volume>10</volume><fpage>910</fpage><lpage>923</lpage><pub-id pub-id-type="doi">10.1093/cercor/10.9.910</pub-id><pub-id pub-id-type="pmid">10982751</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Compte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Computational and in vitro studies of persistent activity: edging towards cellular and synaptic mechanisms of working memory</article-title><source>Neuroscience</source><volume>139</volume><fpage>135</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2005.06.011</pub-id><pub-id pub-id-type="pmid">16337341</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curtis</surname><given-names>CE</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The effects of prefrontal lesions on working memory performance and theory</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>4</volume><fpage>528</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.3758/cabn.4.4.528</pub-id><pub-id pub-id-type="pmid">15849895</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Franciscis</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>S</given-names></name><name><surname>Torres</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Enhancing neural-network performance via assortativity</article-title><source>Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</source><volume>83</volume><elocation-id>036114</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.83.036114</pub-id><pub-id pub-id-type="pmid">21517565</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demirtaş</surname><given-names>M</given-names></name><name><surname>Burt</surname><given-names>JB</given-names></name><name><surname>Helmer</surname><given-names>M</given-names></name><name><surname>Ji</surname><given-names>JL</given-names></name><name><surname>Adkinson</surname><given-names>BD</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name><name><surname>Anticevic</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hierarchical Heterogeneity across Human Cortex Shapes Large-Scale Neural Dynamics</article-title><source>Neuron</source><volume>101</volume><fpage>1181</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.017</pub-id><pub-id pub-id-type="pmid">30744986</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Druckmann</surname><given-names>S</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuronal circuits underlying persistent representations despite time varying activity</article-title><source>Current Biology</source><volume>22</volume><fpage>2095</fpage><lpage>2103</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.08.058</pub-id><pub-id pub-id-type="pmid">23084992</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duan</surname><given-names>H</given-names></name><name><surname>Wearne</surname><given-names>SL</given-names></name><name><surname>Rocher</surname><given-names>AB</given-names></name><name><surname>Macedo</surname><given-names>A</given-names></name><name><surname>Morrison</surname><given-names>JH</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Age-related dendritic and spine changes in corticocortically projecting neurons in macaque monkeys</article-title><source>Cerebral Cortex</source><volume>13</volume><fpage>950</fpage><lpage>961</lpage><pub-id pub-id-type="doi">10.1093/cercor/13.9.950</pub-id><pub-id pub-id-type="pmid">12902394</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edin</surname><given-names>F</given-names></name><name><surname>Klingberg</surname><given-names>T</given-names></name><name><surname>Johansson</surname><given-names>P</given-names></name><name><surname>McNab</surname><given-names>F</given-names></name><name><surname>Tegnér</surname><given-names>J</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Mechanism for top-down control of working memory capacity</article-title><source>PNAS</source><volume>106</volume><fpage>6802</fpage><lpage>6807</lpage><pub-id pub-id-type="doi">10.1073/pnas.0901894106</pub-id><pub-id pub-id-type="pmid">19339493</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name><name><surname>Rosa</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The occipitoparietal pathway of the macaque monkey: comparison of pyramidal cell morphology in layer III of functionally related cortical visual areas</article-title><source>Cerebral Cortex</source><volume>7</volume><fpage>432</fpage><lpage>452</lpage><pub-id pub-id-type="doi">10.1093/cercor/7.5.432</pub-id><pub-id pub-id-type="pmid">9261573</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name><name><surname>Rosa</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="1998">1998a</year><article-title>Complex dendritic fields of pyramidal cells in the frontal eye field of the macaque monkey: comparison with parietal areas 7a and LIP</article-title><source>Neuroreport</source><volume>9</volume><fpage>127</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1097/00001756-199801050-00025</pub-id><pub-id pub-id-type="pmid">9592061</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name><name><surname>Rosa</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="1998">1998b</year><article-title>Morphological variation of layer III pyramidal neurones in the occipitotemporal pathway of the macaque monkey visual cortex</article-title><source>Cerebral Cortex</source><volume>8</volume><fpage>278</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1093/cercor/8.3.278</pub-id><pub-id pub-id-type="pmid">9617923</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name><name><surname>Tweedale</surname><given-names>R</given-names></name><name><surname>Rosa</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cortical integration in the visual system of the macaque monkey: large-scale morphological differences in the pyramidal neurons in the occipital, parietal and temporal lobes</article-title><source>Proceedings. Biological Sciences</source><volume>266</volume><fpage>1367</fpage><lpage>1374</lpage><pub-id pub-id-type="doi">10.1098/rspb.1999.0789</pub-id><pub-id pub-id-type="pmid">10445291</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Interlaminar differences in the pyramidal cell phenotype in cortical areas 7 m and STP (the superior temporal polysensory area) of the macaque monkey</article-title><source>Experimental Brain Research</source><volume>138</volume><fpage>141</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1007/s002210100705</pub-id><pub-id pub-id-type="pmid">11417455</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name><name><surname>Rockland</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The pyramidal cell of the sensorimotor cortex of the macaque monkey: phenotypic variation</article-title><source>Cerebral Cortex</source><volume>12</volume><fpage>1071</fpage><lpage>1078</lpage><pub-id pub-id-type="doi">10.1093/cercor/12.10.1071</pub-id><pub-id pub-id-type="pmid">12217971</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name><name><surname>Benavides-Piccione</surname><given-names>R</given-names></name><name><surname>Defelipe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A study of pyramidal cell structure in the cingulate cortex of the macaque monkey with comparative notes on inferotemporal and primary visual cortex</article-title><source>Cerebral Cortex</source><volume>15</volume><fpage>64</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhh109</pub-id><pub-id pub-id-type="pmid">15238445</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Specialization of the Neocortical Pyramidal Cell during Primate Evolution</article-title><source>Evolution of Nervous Systems</source><fpage>191</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1016/B0-12-370878-8/00164-6</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name><name><surname>Benavides-Piccione</surname><given-names>R</given-names></name><name><surname>Elston</surname><given-names>A</given-names></name><name><surname>Manger</surname><given-names>PR</given-names></name><name><surname>Defelipe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pyramidal cells in prefrontal cortex of primates: marked differences in neuronal structure among species</article-title><source>Frontiers in Neuroanatomy</source><volume>5</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2011.00002</pub-id><pub-id pub-id-type="pmid">21347276</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname><given-names>DJ</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title><source>Cerebral Cortex</source><volume>1</volume><fpage>1</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1093/cercor/1.1.1-a</pub-id><pub-id pub-id-type="pmid">1822724</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Froudist-Walsh</surname><given-names>S</given-names></name><name><surname>Bliss</surname><given-names>DP</given-names></name><name><surname>Ding</surname><given-names>X</given-names></name><name><surname>Rapan</surname><given-names>L</given-names></name><name><surname>Niu</surname><given-names>M</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Palomero-Gallagher</surname><given-names>N</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A dopamine gradient controls access to distributed working memory in the large-scale monkey cortex</article-title><source>Neuron</source><volume>109</volume><fpage>3500</fpage><lpage>3520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.08.024</pub-id><pub-id pub-id-type="pmid">34536352</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Zerbi</surname><given-names>V</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Multimodal gradients across mouse cortex</article-title><source>PNAS</source><volume>116</volume><fpage>4689</fpage><lpage>4695</lpage><pub-id pub-id-type="doi">10.1073/pnas.1814144116</pub-id><pub-id pub-id-type="pmid">30782826</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Bruce</surname><given-names>CJ</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Mnemonic coding of visual space in the monkey’s dorsolateral prefrontal cortex</article-title><source>Journal of Neurophysiology</source><volume>61</volume><fpage>331</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1152/jn.1989.61.2.331</pub-id><pub-id pub-id-type="pmid">2918358</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Unit activity in prefrontal cortex during delayed-response performance: neuronal correlates of transient memory</article-title><source>Journal of Neurophysiology</source><volume>36</volume><fpage>61</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1152/jn.1973.36.1.61</pub-id><pub-id pub-id-type="pmid">4196203</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Memory without feedback in a neural network</article-title><source>Neuron</source><volume>61</volume><fpage>621</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.012</pub-id><pub-id pub-id-type="pmid">19249281</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Cellular basis of working memory</article-title><source>Neuron</source><volume>14</volume><fpage>477</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/0896-6273(95)90304-6</pub-id><pub-id pub-id-type="pmid">7695894</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>ZV</given-names></name><name><surname>Inagaki</surname><given-names>HK</given-names></name><name><surname>Daie</surname><given-names>K</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Maintenance of persistent activity in a frontal thalamocortical loop</article-title><source>Nature</source><volume>545</volume><fpage>181</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1038/nature22324</pub-id><pub-id pub-id-type="pmid">28467817</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansel</surname><given-names>D</given-names></name><name><surname>Mato</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Short-term plasticity explains irregular persistent activity in working memory tasks</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>133</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3455-12.2013</pub-id><pub-id pub-id-type="pmid">23283328</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hempel</surname><given-names>CM</given-names></name><name><surname>Hartman</surname><given-names>KH</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Multiple forms of short-term plasticity at excitatory synapses in rat medial prefrontal cortex</article-title><source>Journal of Neurophysiology</source><volume>83</volume><fpage>3031</fpage><lpage>3041</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.83.5.3031</pub-id><pub-id pub-id-type="pmid">10805698</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupé</surname><given-names>JM</given-names></name><name><surname>James</surname><given-names>AC</given-names></name><name><surname>Payne</surname><given-names>BR</given-names></name><name><surname>Lomber</surname><given-names>SG</given-names></name><name><surname>Girard</surname><given-names>P</given-names></name><name><surname>Bullier</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Cortical feedback improves discrimination between figure and background by V1, V2 and V3 neurons</article-title><source>Nature</source><volume>394</volume><fpage>784</fpage><lpage>787</lpage><pub-id pub-id-type="doi">10.1038/29537</pub-id><pub-id pub-id-type="pmid">9723617</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hussar</surname><given-names>CR</given-names></name><name><surname>Pasternak</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Flexibility of sensory representations in prefrontal cortex depends on cell type</article-title><source>Neuron</source><volume>64</volume><fpage>730</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.018</pub-id><pub-id pub-id-type="pmid">20005828</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inagaki</surname><given-names>HK</given-names></name><name><surname>Fontolan</surname><given-names>L</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Discrete attractor dynamics underlies persistent activity in the frontal cortex</article-title><source>Nature</source><volume>566</volume><fpage>212</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-0919-7</pub-id><pub-id pub-id-type="pmid">30728503</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itskov</surname><given-names>V</given-names></name><name><surname>Hansel</surname><given-names>D</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Short-Term Facilitation may Stabilize Parametric Working Memory Trace</article-title><source>Frontiers in Computational Neuroscience</source><volume>5</volume><elocation-id>40</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2011.00040</pub-id><pub-id pub-id-type="pmid">22028690</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaramillo</surname><given-names>J</given-names></name><name><surname>Mejias</surname><given-names>JF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Engagement of Pulvino-cortical Feedforward and Feedback Pathways in Cognitive Computations</article-title><source>Neuron</source><volume>101</volume><fpage>321</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.11.023</pub-id><pub-id pub-id-type="pmid">30553546</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joglekar</surname><given-names>MR</given-names></name><name><surname>Mejias</surname><given-names>JF</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inter-areal Balanced Amplification Enhances Signal Propagation in a Large-Scale Circuit Model of the Primate Cortex</article-title><source>Neuron</source><volume>98</volume><fpage>222</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.02.031</pub-id><pub-id pub-id-type="pmid">29576389</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Barbarits</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Andrei</surname><given-names>A</given-names></name><name><surname>Aydın</surname><given-names>Ç</given-names></name><name><surname>Barbic</surname><given-names>M</given-names></name><name><surname>Blanche</surname><given-names>TJ</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Couto</surname><given-names>J</given-names></name><name><surname>Dutta</surname><given-names>B</given-names></name><name><surname>Gratiy</surname><given-names>SL</given-names></name><name><surname>Gutnisky</surname><given-names>DA</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Lopez</surname><given-names>CM</given-names></name><name><surname>Mitelut</surname><given-names>C</given-names></name><name><surname>Musa</surname><given-names>S</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Putzeys</surname><given-names>J</given-names></name><name><surname>Rich</surname><given-names>PD</given-names></name><name><surname>Rossant</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>W-L</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><volume>551</volume><fpage>232</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/nature24636</pub-id><pub-id pub-id-type="pmid">29120427</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamiński</surname><given-names>J</given-names></name><name><surname>Rutishauser</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Between persistently active and activity-silent frameworks: novel vistas on the cellular basis of working memory</article-title><source>Annals of the New York Academy of Sciences</source><volume>1464</volume><fpage>64</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1111/nyas.14213</pub-id><pub-id pub-id-type="pmid">31407811</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Erlich</surname><given-names>JC</given-names></name><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical and Subcortical Contributions to Short-Term Memory for Orienting Movements</article-title><source>Neuron</source><volume>88</volume><fpage>367</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.033</pub-id><pub-id pub-id-type="pmid">26439529</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leavitt</surname><given-names>ML</given-names></name><name><surname>Mendoza-Halliday</surname><given-names>D</given-names></name><name><surname>Martinez-Trujillo</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sustained Activity Encoding Working Memories: Not Fully Distributed</article-title><source>Trends in Neurosciences</source><volume>40</volume><fpage>328</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2017.04.004</pub-id><pub-id pub-id-type="pmid">28515011</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemus</surname><given-names>L</given-names></name><name><surname>Hernández</surname><given-names>A</given-names></name><name><surname>Luna</surname><given-names>R</given-names></name><name><surname>Zainos</surname><given-names>A</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Do sensory cortices process more than one sensory modality during perceptual judgments?</article-title><source>Neuron</source><volume>67</volume><fpage>335</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.06.015</pub-id><pub-id pub-id-type="pmid">20670839</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>S</given-names></name><name><surname>Goldman</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Balanced cortical microcircuitry for maintaining information in working memory</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1306</fpage><lpage>1314</lpage><pub-id pub-id-type="doi">10.1038/nn.3492</pub-id><pub-id pub-id-type="pmid">23955560</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lundqvist</surname><given-names>M</given-names></name><name><surname>Rose</surname><given-names>J</given-names></name><name><surname>Herman</surname><given-names>P</given-names></name><name><surname>Brincat</surname><given-names>SL</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Gamma and Beta Bursts Underlie Working Memory</article-title><source>Neuron</source><volume>90</volume><fpage>152</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.02.028</pub-id><pub-id pub-id-type="pmid">26996084</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markov</surname><given-names>NT</given-names></name><name><surname>Ercsey-Ravasz</surname><given-names>M</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Toroczkai</surname><given-names>Z</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical high-density counterstream architectures</article-title><source>Science</source><volume>342</volume><elocation-id>1238406</elocation-id><pub-id pub-id-type="doi">10.1126/science.1238406</pub-id><pub-id pub-id-type="pmid">24179228</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markov</surname><given-names>NT</given-names></name><name><surname>Ercsey-Ravasz</surname><given-names>MM</given-names></name><name><surname>Ribeiro Gomes</surname><given-names>AR</given-names></name><name><surname>Lamy</surname><given-names>C</given-names></name><name><surname>Magrou</surname><given-names>L</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Misery</surname><given-names>P</given-names></name><name><surname>Falchier</surname><given-names>A</given-names></name><name><surname>Quilodran</surname><given-names>R</given-names></name><name><surname>Gariel</surname><given-names>MA</given-names></name><name><surname>Sallet</surname><given-names>J</given-names></name><name><surname>Gamanut</surname><given-names>R</given-names></name><name><surname>Huissoud</surname><given-names>C</given-names></name><name><surname>Clavagnier</surname><given-names>S</given-names></name><name><surname>Giroud</surname><given-names>P</given-names></name><name><surname>Sappey-Marinier</surname><given-names>D</given-names></name><name><surname>Barone</surname><given-names>P</given-names></name><name><surname>Dehay</surname><given-names>C</given-names></name><name><surname>Toroczkai</surname><given-names>Z</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>A weighted and directed interareal connectivity matrix for macaque cerebral cortex</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>17</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs270</pub-id><pub-id pub-id-type="pmid">23010748</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markov</surname><given-names>NT</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Chameau</surname><given-names>P</given-names></name><name><surname>Falchier</surname><given-names>A</given-names></name><name><surname>Quilodran</surname><given-names>R</given-names></name><name><surname>Huissoud</surname><given-names>C</given-names></name><name><surname>Lamy</surname><given-names>C</given-names></name><name><surname>Misery</surname><given-names>P</given-names></name><name><surname>Giroud</surname><given-names>P</given-names></name><name><surname>Ullman</surname><given-names>S</given-names></name><name><surname>Barone</surname><given-names>P</given-names></name><name><surname>Dehay</surname><given-names>C</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Anatomy of hierarchy: feedforward and feedback pathways in macaque visual cortex</article-title><source>The Journal of Comparative Neurology</source><volume>522</volume><fpage>225</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1002/cne.23458</pub-id><pub-id pub-id-type="pmid">23983048</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markowitz</surname><given-names>DA</given-names></name><name><surname>Curtis</surname><given-names>CE</given-names></name><name><surname>Pesaran</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Multiple component networks support working memory in prefrontal cortex</article-title><source>PNAS</source><volume>112</volume><fpage>11084</fpage><lpage>11089</lpage><pub-id pub-id-type="doi">10.1073/pnas.1504172112</pub-id><pub-id pub-id-type="pmid">26283366</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mejias</surname><given-names>JF</given-names></name><name><surname>Torres</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Maximum memory capacity on neural networks with short-term synaptic depression and facilitation</article-title><source>Neural Computation</source><volume>21</volume><fpage>851</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.02-08-719</pub-id><pub-id pub-id-type="pmid">18928372</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mejias</surname><given-names>JF</given-names></name><name><surname>Hernandez-Gomez</surname><given-names>B</given-names></name><name><surname>Torres</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Short-term synaptic facilitation improves information retrieval in noisy neural networks</article-title><source>EPL</source><volume>97</volume><elocation-id>48008</elocation-id><pub-id pub-id-type="doi">10.1209/0295-5075/97/48008</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mejias</surname><given-names>JF</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Feedforward and feedback frequency-dependent interactions in a large-scale laminar network of the primate cortex</article-title><source>Science Advances</source><volume>2</volume><elocation-id>e1601335</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.1601335</pub-id><pub-id pub-id-type="pmid">28138530</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mendoza-Halliday</surname><given-names>D</given-names></name><name><surname>Martinez-Trujillo</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neuronal population coding of perceived and memorized visual features in the lateral prefrontal cortex</article-title><source>Nature Communications</source><volume>8</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/ncomms15471</pub-id><pub-id pub-id-type="pmid">28569756</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mi</surname><given-names>Y</given-names></name><name><surname>Katkov</surname><given-names>M</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Synaptic Correlates of Working Memory Capacity</article-title><source>Neuron</source><volume>93</volume><fpage>323</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.004</pub-id><pub-id pub-id-type="pmid">28041884</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Lundqvist</surname><given-names>M</given-names></name><name><surname>Bastos</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Working Memory 2.0</article-title><source>Neuron</source><volume>100</volume><fpage>463</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.09.023</pub-id><pub-id pub-id-type="pmid">30359609</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mongillo</surname><given-names>G</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Synaptic theory of working memory</article-title><source>Science</source><volume>319</volume><fpage>1543</fpage><lpage>1546</lpage><pub-id pub-id-type="doi">10.1126/science.1150769</pub-id><pub-id pub-id-type="pmid">18339943</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Muhle-Karbe</surname><given-names>PS</given-names></name><name><surname>Myers</surname><given-names>NE</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Plasticity after Cortical Stroke Involves Potentiating Responses of Pre-Existing Circuits but Not Functional Remapping to New Circuits</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.04.16.044511</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Bernacchia</surname><given-names>A</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Wallis</surname><given-names>JD</given-names></name><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Padoa-Schioppa</surname><given-names>C</given-names></name><name><surname>Pasternak</surname><given-names>T</given-names></name><name><surname>Seo</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A hierarchy of intrinsic timescales across primate cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1661</fpage><lpage>1663</lpage><pub-id pub-id-type="doi">10.1038/nn.3862</pub-id><pub-id pub-id-type="pmid">25383900</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Bernacchia</surname><given-names>A</given-names></name><name><surname>Roy</surname><given-names>NA</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Stable population coding for working memory coexists with heterogeneous neural dynamics in prefrontal cortex</article-title><source>PNAS</source><volume>114</volume><fpage>394</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1073/pnas.1619449114</pub-id><pub-id pub-id-type="pmid">28028221</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Jaramillo</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Working Memory and Decision-Making in a Frontoparietal Circuit Model</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>12167</fpage><lpage>12186</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0343-17.2017</pub-id><pub-id pub-id-type="pmid">29114071</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panichello</surname><given-names>MF</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Shared mechanisms underlie the control of working memory and attention</article-title><source>Nature</source><volume>592</volume><fpage>601</fpage><lpage>605</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03390-w</pub-id><pub-id pub-id-type="pmid">33790467</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Tradeoff Between Accuracy and Flexibility in a Working Memory Circuit Endowed with Slow Feedback Mechanisms</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3586</fpage><lpage>3601</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu202</pub-id><pub-id pub-id-type="pmid">25253801</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rockland</surname><given-names>KS</given-names></name><name><surname>Van Hoesen</surname><given-names>GW</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Direct temporal-occipital feedback connections to striate cortex (V1) in the macaque monkey</article-title><source>Cerebral Cortex</source><volume>4</volume><fpage>300</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1093/cercor/4.3.300</pub-id><pub-id pub-id-type="pmid">8075534</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Hernández</surname><given-names>A</given-names></name><name><surname>Lemus</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neuronal correlates of parametric working memory in the prefrontal cortex</article-title><source>Nature</source><volume>399</volume><fpage>470</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1038/20939</pub-id><pub-id pub-id-type="pmid">10365959</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi-Pool</surname><given-names>R</given-names></name><name><surname>Salinas</surname><given-names>E</given-names></name><name><surname>Zainos</surname><given-names>A</given-names></name><name><surname>Alvarez</surname><given-names>M</given-names></name><name><surname>Vergara</surname><given-names>J</given-names></name><name><surname>Parga</surname><given-names>N</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Emergence of an abstract categorical code enabling the discrimination of temporally structured tactile stimuli</article-title><source>PNAS</source><volume>113</volume><fpage>E7966</fpage><lpage>E7975</lpage><pub-id pub-id-type="doi">10.1073/pnas.1618196113</pub-id><pub-id pub-id-type="pmid">27872293</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roxin</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The role of degree distribution in shaping the dynamics in networks of sparsely connected spiking neurons</article-title><source>Frontiers in Computational Neuroscience</source><volume>5</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2011.00008</pub-id><pub-id pub-id-type="pmid">21556129</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>M</given-names></name><name><surname>Bakker</surname><given-names>R</given-names></name><name><surname>Shen</surname><given-names>K</given-names></name><name><surname>Bezgin</surname><given-names>G</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>van Albada</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A multi-scale layer-resolved spiking network model of resting-state dynamics in macaque visual cortical areas</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006359</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006359</pub-id><pub-id pub-id-type="pmid">30335761</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeholzer</surname><given-names>A</given-names></name><name><surname>Deger</surname><given-names>M</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Stability of working memory in continuous attractor networks under the control of short-term plasticity</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006928</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006928</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>1916</fpage><lpage>1936</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.4.1916</pub-id><pub-id pub-id-type="pmid">11600651</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical information flow during flexible sensorimotor decisions</article-title><source>Science</source><volume>348</volume><fpage>1352</fpage><lpage>1355</lpage><pub-id pub-id-type="doi">10.1126/science.aab0551</pub-id><pub-id pub-id-type="pmid">26089513</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Siegle</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Survey of Spiking Activity Reveals a Functional Hierarchy of Mouse Corticothalamic Visual Areas</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/805010</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname><given-names>KK</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The what, where and how of delay activity</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>466</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0176-7</pub-id><pub-id pub-id-type="pmid">31086326</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>“Activity-silent” working memory in prefrontal cortex: a dynamic coding framework</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>394</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.05.004</pub-id><pub-id pub-id-type="pmid">26051384</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>255</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Strogatz</surname><given-names>SH.</given-names></name></person-group><year iso-8601-date="1994">1994</year><source>Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry and Engineering</source><publisher-loc>Reading, MA</publisher-loc><publisher-name>Perseus Books</publisher-name></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks</article-title><source>Neural Computation</source><volume>25</volume><fpage>626</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00409</pub-id><pub-id pub-id-type="pmid">23272922</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trübutschek</surname><given-names>D</given-names></name><name><surname>Marti</surname><given-names>S</given-names></name><name><surname>Ojeda</surname><given-names>A</given-names></name><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Mi</surname><given-names>Y</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A theory of working memory without consciousness or sustained activity</article-title><source>eLife</source><volume>6</volume><elocation-id>e23871</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23871</pub-id><pub-id pub-id-type="pmid">28718763</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsushima</surname><given-names>Y</given-names></name><name><surname>Sasaki</surname><given-names>Y</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Greater disruption due to failure of inhibitory control on an ambiguous distractor</article-title><source>Science</source><volume>314</volume><fpage>1786</fpage><lpage>1788</lpage><pub-id pub-id-type="doi">10.1126/science.1133197</pub-id><pub-id pub-id-type="pmid">17170308</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Network hubs in the human brain</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>683</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.09.012</pub-id><pub-id pub-id-type="pmid">24231140</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Vugt</surname><given-names>B</given-names></name><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Vartak</surname><given-names>D</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The Contribution of AMPA and NMDA Receptors to Persistent Firing in the Dorsolateral Prefrontal Cortex in Working Memory</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>2458</fpage><lpage>2470</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2121-19.2020</pub-id><pub-id pub-id-type="pmid">32051326</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Synaptic basis of cortical persistent activity: the importance of NMDA receptors to working memory</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>9587</fpage><lpage>9603</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-21-09587.1999</pub-id><pub-id pub-id-type="pmid">10531461</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Synaptic reverberation underlying mnemonic persistent activity</article-title><source>Trends in Neurosciences</source><volume>24</volume><fpage>455</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.1016/s0166-2236(00)01868-3</pub-id><pub-id pub-id-type="pmid">11476885</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title><source>Neuron</source><volume>36</volume><fpage>955</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01092-9</pub-id><pub-id pub-id-type="pmid">12467598</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>CJ</given-names></name><name><surname>Gamo</surname><given-names>NJ</given-names></name><name><surname>Jin</surname><given-names>LE</given-names></name><name><surname>Mazer</surname><given-names>JA</given-names></name><name><surname>Morrison</surname><given-names>JH</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Arnsten</surname><given-names>AFT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>NMDA receptors subserve persistent neuronal firing during working memory in dorsolateral prefrontal cortex</article-title><source>Neuron</source><volume>77</volume><fpage>736</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.032</pub-id><pub-id pub-id-type="pmid">23439125</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Macroscopic gradients of synaptic excitation and inhibition in the neocortex</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>169</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0262-x</pub-id><pub-id pub-id-type="pmid">32029928</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>50 years of mnemonic persistent activity: quo vadis?</article-title><source>Trends in Neurosciences</source><volume>44</volume><fpage>888</fpage><lpage>902</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2021.09.001</pub-id><pub-id pub-id-type="pmid">34654556</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Ramon</surname><given-names>M</given-names></name><name><surname>Pasternak</surname><given-names>T</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Transitions between Multiband Oscillatory Patterns Characterize Memory-Guided Perceptual Decisions in Prefrontal Circuits</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>489</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3678-15.2016</pub-id><pub-id pub-id-type="pmid">26758840</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Jochim</surname><given-names>J</given-names></name><name><surname>Akyürek</surname><given-names>EG</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>864</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1038/nn.4546</pub-id><pub-id pub-id-type="pmid">28414333</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>KF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>1314</fpage><lpage>1328</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3733-05.2006</pub-id><pub-id pub-id-type="pmid">16436619</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A dendritic disinhibitory circuit mechanism for pathway-specific gating</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12815</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12815</pub-id><pub-id pub-id-type="pmid">27649374</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>ME</given-names></name><name><surname>Ohm</surname><given-names>DT</given-names></name><name><surname>Dumitriu</surname><given-names>D</given-names></name><name><surname>Rapp</surname><given-names>PR</given-names></name><name><surname>Morrison</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Differential effects of aging on dendritic spines in visual cortex and prefrontal cortex of the rhesus monkey</article-title><source>Neuroscience</source><volume>274</volume><fpage>33</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2014.05.008</pub-id><pub-id pub-id-type="pmid">24853052</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>YD</given-names></name><name><surname>Fuster</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Mnemonic neuronal activity in somatosensory cortex</article-title><source>PNAS</source><volume>93</volume><fpage>10533</fpage><lpage>10537</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.19.10533</pub-id><pub-id pub-id-type="pmid">8927629</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>Simplified computational model: two areas</title><p>To provide a deeper intuition of the nature of distributed WM and the model ingredients which are fundamental for the phenomenon, we describe here a simplified version of our model which is suitable for theoretical analysis. We will first introduce a version of the model with two interconnected excitatory nodes, each of them following a rate dynamics:<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are the firing rates of node 1 and 2, with display self-connections of strength <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and cross-connections of strength <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . Both areas have a relaxation time constant <inline-formula><mml:math id="inf19"><mml:mi>τ</mml:mi></mml:math></inline-formula> and receive a background input current <inline-formula><mml:math id="inf20"><mml:mi>I</mml:mi></mml:math></inline-formula>. The transfer function is a threshold-linear function, that is <inline-formula><mml:math id="inf21"><mml:mi>ϕ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:mi>θ</mml:mi></mml:math></inline-formula> if <inline-formula><mml:math id="inf22"><mml:mi>I</mml:mi><mml:mo>§amp;gt;</mml:mo><mml:mi>θ</mml:mi></mml:math></inline-formula> and zero otherwise.</p><p>The equation for the fixed point of the dynamics can be easily written as a function of the average firing rate of both units, namely R, which leads to the equation<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:mi>θ</mml:mi></mml:math></disp-formula></p><p>The above is only true in the linear regime, while for the subthreshold regime we get the trivial solution <italic>R</italic> = 0. Solving <xref ref-type="disp-formula" rid="equ25">Eq. 25</xref> leads to the following expression<disp-formula id="equ26"><label>(26)</label><mml:math id="m26"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>θ</mml:mi><mml:mo>-</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p><xref ref-type="disp-formula" rid="equ26">Equation 26</xref> permits a positive solution for R if both numerator and denominator are positive (or both negative, but the solution in this case is less interesting biologically). Interestingly, if the cross-connection strength is large enough, we can have a fixed point solution with nonzero R even if <inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>§amp;lt;</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>, which would correspond to the case in which nodes would be monostable if isolated from each other. Distributed sustained activity can emerge, therefore, even in simple cases of two coupled excitatory nodes.</p></sec><sec id="s9" sec-type="appendix"><title>Simplified computational model: N areas</title><p>We present now the case in which we have a large number N of connected excitatory nodes. We consider a fully connected network for simplicity and N = 30 nodes for the simulations. The activity of the nodes is given by<disp-formula id="equ27"><label>(27)</label><mml:math id="m27"><mml:mrow><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>J</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>G</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, the term <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a monotonically increasing linear function that is used to introduce a gradient of connectivity strength across the network, with minimum value <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:math></inline-formula> and maximum value <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.85</mml:mn><mml:mo>.</mml:mo></mml:math></inline-formula> Other parameters values chosen for simulations are: <inline-formula><mml:math id="inf27"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:mi> </mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mn>4.81</mml:mn><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi> </mml:mi><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mn>0.91</mml:mn><mml:mo>.</mml:mo></mml:math></inline-formula> For the transfer function, we choose a sigmoidal function (to demonstrate robustness of the phenomenon observed before for the threshold-linear):<disp-formula id="equ28"><label>(28)</label><mml:math id="m28"><mml:mi>ϕ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Parameters chosen for simulations are <inline-formula><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>60</mml:mn><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>30</mml:mn><mml:mo>.</mml:mo></mml:math></inline-formula> For these parameters, an isolated node is bistable only if <inline-formula><mml:math id="inf29"><mml:mi>η</mml:mi><mml:mo>≅</mml:mo><mml:mn>0.88</mml:mn></mml:math></inline-formula>, which is above our chosen <inline-formula><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> value and implies that all nodes are monostable in isolation.</p><p>This model admits an approximate mean-field solution if we define the network-average firing rate as <inline-formula><mml:math id="inf31"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> . Averaging <xref ref-type="disp-formula" rid="equ27">Equation 27</xref> over units and using standard mean-field approximations like <inline-formula><mml:math id="inf32"><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced><mml:mo>≈</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:math></inline-formula>, we arrive at<disp-formula id="equ29"><label>(29)</label><mml:math id="m29"><mml:mi>τ</mml:mi><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:mi> </mml:mi><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:mi>η</mml:mi><mml:mi> </mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>G</mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>To estimate the average of the product <inline-formula><mml:math id="inf33"><mml:mi>η</mml:mi><mml:mi> </mml:mi><mml:mi>r</mml:mi></mml:math></inline-formula> over units, we can follow to approaches. First, we can assume independence between these two variables and accept that <inline-formula><mml:math id="inf34"><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:mi>η</mml:mi><mml:mi> </mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mo>≈</mml:mo><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mi>R</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> being the mean value of <inline-formula><mml:math id="inf36"><mml:mi>η</mml:mi></mml:math></inline-formula>. We will refer to this as the first-order mean field solution in the text, and is given by the following equations:<disp-formula id="equ30"><label>(30)</label><mml:math id="m30"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ31"><label>(31)</label><mml:math id="m31"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>It is important to notice that <xref ref-type="disp-formula" rid="equ30">Eq. 30</xref> is the real self-consistent mean-field solution, which can be solved numerically to find the fixed point solutions of our system. <xref ref-type="disp-formula" rid="equ31">Eq. 31</xref>, on the other hand, is useful since it allows to obtain the fixed point solutions for any node ‘i’ that is connected to the network, and allows to explore the effect of the local heterogeneity <inline-formula><mml:math id="inf37"><mml:mi>η</mml:mi></mml:math></inline-formula>.</p><p>As an alternative to this solution, we can consider additional term in the dependence between the heterogeneity and firing rate of the nodes. For example, we can assume that the firing rate of units will grow proportionally to both <inline-formula><mml:math id="inf38"><mml:mi>η</mml:mi></mml:math></inline-formula> and G, which is a plausible approximation that takes into account both the heterogeneity and the global interactions. We can write this as<disp-formula id="equ32"><label>(32)</label><mml:math id="m32"><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mfenced><mml:mo>≅</mml:mo><mml:mi>α</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi> </mml:mi><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:mi>η</mml:mi></mml:math></disp-formula></p><p>This leads to the following expression:<disp-formula id="equ33"><label>(33)</label><mml:math id="m33"><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:mi>η</mml:mi><mml:mi> </mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mo>≈</mml:mo><mml:mi>α</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi> </mml:mi><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:mfenced close="〉" open="〈" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi> </mml:mi><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>The mean-field solution obtained, which we denote here as second-order solution, is given by<disp-formula id="equ34"><label>(34)</label><mml:math id="m34"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>J</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>α</mml:mi><mml:mi> </mml:mi><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:mfenced><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>J</mml:mi><mml:mi> </mml:mi><mml:mi>β</mml:mi><mml:mi> </mml:mi><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ35"><label>(35)</label><mml:math id="m35"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>G</mml:mi><mml:mi> </mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>A choice of <inline-formula><mml:math id="inf39"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.94</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> (which fulfills the recommendations for a perturbative approach, since <inline-formula><mml:math id="inf41"><mml:mi>α</mml:mi><mml:mo>≈</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf42"><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>) provides good results as <xref ref-type="fig" rid="fig3">Figure 3</xref> shows. However, both the first and second order solutions predict the emergence of distributed WM, and the choice of one or the other solution has only minor implications.</p></sec><sec id="s10" sec-type="appendix"><title>Simplified model for activity-silent memory traces</title><p>Similar to the simplified model above, we consider a network of N = 30 nodes whose dynamics is described by<disp-formula id="equ36"><label>(36)</label><mml:math id="m36"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi>G</mml:mi><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>Both local and long-range projections are now modulated by a variable, u<sub>i</sub>, accounting for short-term synaptic plasticity (STF), described by<disp-formula id="equ37"><label>(37)</label><mml:math id="m37"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>Transfer function and other parameters as above, unless specifically mentioned (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></sec></app><app id="appendix-2"><title>Appendix 2</title><sec id="s11" sec-type="appendix"><title>Data analysis: Overview</title><p>We developed a numerical method to estimate the number of stable distributed WM attractors for a particular set of parameters values of our model. This method, which follows simplified density-based clustering principles, is used to obtain the results shown in <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref>. To allow for a cleaner estimation, we do not consider noise in neural dynamics during these simulations.</p><p>Our large-scale cortical network has 30 areas, with each of them having two selective excitatory populations A and B. Simply assuming that each of the areas can reach one of three possible states (sustained activity in A, sustained activity in B, or spontaneous activity) means that our model can potentially display up to three to the power of 30 attractor combinations. This number can be even larger if we refine the firing rate reached by each area rather than simply its sustained/non-sustained activity status. Since it is not possible to fully explore this extremely large number of possible attractors, we devised a strategy based on the exploration of a sample of the input space of the model. The core idea is to stimulate the model with a certain input pattern (targeting randomized areas) and registering the fixed point that the dynamics of the model converges to. By repeating this process with a large number of input combinations and later counting the number of different attractors from the obtained pool of fixed points, we can obtain an estimate of the number of attractors for a particular set of parameter values.</p></sec><sec id="s12" sec-type="appendix"><title>Data analysis: Stimulation protocol</title><p>A given input pattern is defined as a current pulse of fixed strength (I<sub>pulse</sub> = 0.2) and duration (T<sub>pulse</sub> = 1 sec) which reaches a certain number P of cortical areas. Only one population (A or B, randomized) in each area receives the input, and the P cortical areas receiving the input are randomly selected across the top 16 areas of the spine count gradient. This decreases the amount of potential input combinations we have to deal with by acknowledging that areas with stronger recurrent connections (such as 9/46d) are more likely to be involved in distributed WM patterns than those with weaker connections (such as MT). P can take any value between one and P<sub>max</sub> = 16, and we run a certain number of trials (see below) for each of them. Different values of I<sub>pulse</sub> and T<sub>pulse</sub>, as well as setting the randomly selected areas at a high rate initial condition instead of providing an external input, have been also explored and lead to qualitatively similar results. Similar approaches regarding the use of random perturbations in high dimensional systems have been successfully used in the past (<xref ref-type="bibr" rid="bib82">Sussillo and Barak, 2013</xref>).</p><p>It is also important to consider that not all values of P have the same number of input combinations. For example, <italic>P</italic> = 1 allows for 16*2 = 32 different input combinations (if we discriminate between populations A and B), while <italic>P</italic> = 2 allows for 16*(16-1)*2 = 480 input combinations, and so on. For a given value of P, the number of possible input combinations N<sub>c</sub> is given by<disp-formula id="equ38"><label>(38)</label><mml:math id="m38"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mi> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>P</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mo>!</mml:mo><mml:mi> </mml:mi><mml:mi>P</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>By summing all values of N<sub>c</sub> for <italic>P</italic> = 1, …P<sub>max</sub>, we obtain around 43 million input combinations, which are still too many trials to simulate for a single model configuration. To simplify this further, we consider a scaling factor F<sub>c</sub> on top of N<sub>c</sub> to bring down these numbers to reasonable levels for simulations. We use F<sub>c</sub> = 0.0002 (or 0.02% of all possible combinations) for our calculations, which brings down the total number of simulated input combinations to around 9000. Other options, such as decreasing P<sub>max</sub> and using a larger scaling factor (P<sub>max</sub> = 12, F<sub>c</sub> = 0.01 or 1% or all possible combinations) give also good results. Since the rescaling can have a strong impact for small P (yielding a number of trials smaller than one), we ensure at least one trial for these cases.</p><p>To guarantee the stability of the fixed points obtained during these simulations, we simulate the system during a time window of 30 s (which is much larger than any other time scale in the system), and check that the firing rates have not fluctuated during the last 10 s before we register the final state of the system as a fixed point.</p></sec><sec id="s13" sec-type="appendix"><title>Data analysis: Estimating the number of attractors</title><p>The final step is to count how many different attractors have been reached by the system, by analyzing the pool of fixed points obtained from simulations. A simple way to do this is to consider that, for any fixed point, the state of each area can be classified as sustained activity in population A (i.e. mean firing rate above a certain threshold of 10 spikes/s), sustained activity in population B, or spontaneous activity (both A and B are below 10 spikes/s). This turns each fixed point into a vector of 30 discrete states, and the number of unique vectors among the pool of fixed points can be quickly obtained using standard routines in Matlab (e.g. 'unique' function).</p><p>A more refined way to count the number of attractors, which we use in this work, is to define the Euclidean distance to discriminate between an attractor candidate and any previously identified attractors. Once the first attractor (i.e. the first fixed point analyzed) is identified, we test whether the next fixed point is the same than the first one by computing the Euclidean distance E<sub>d</sub> between them:<disp-formula id="equ39"><label>(39)</label><mml:math id="m39"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where n = 30 is the total number of areas in the network (only one of the populations, A or B, needs to be considered here). If E<sub>d</sub> is larger than a certain threshold distance ε, we consider it a new attractor. We choose <italic>ε</italic> = 0.01, which grossly means that two fixed points are considered as different attractors if, for example, the activity of one of their cortical areas differs by 0.5 spikes/s and the activity on all other areas is the same for both. The particular value of ε does not have a strong impact on the results (aside from the fact that smaller values of ε gives us more resolution to find attractors). When several attractors are identified, each new candidate is compared to all of them using the same method.</p><p>Both the first and the second method to count attractors deliver qualitatively similar results (in terms of the dependence of the number of attractors with model parameters), although as expected the second method yields larger numbers due to its higher discriminability.</p></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.72136.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Pasternak</surname><given-names>Tatiana</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/760231" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/760231"/></front-stub><body><p>The final revision of the manuscript addressed the remaining issues raised by the reviewers. They felt that the paper is an important contribution to the field, providing new and testable insights into the interaction between cortical areas during the memory delay and that the work is likely to become &quot;an influential reference for future modeling efforts&quot; and deserves publication in <italic>eLife</italic>.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.72136.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Pasternak</surname><given-names>Tatiana</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/760231">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/760231v3">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Mechanisms of distributed working memory in a large-scale network of macaque neocortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Tirin Moore as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>The manuscript was well received by the two reviewers who felt that the large-scale distributed model of working memory has major strengths and fills an important gap in the literature. However, they also had a number of reservations and made suggestions which must be addressed for the manuscript to be accepted for publication in <italic>eLife</italic>.</p><p>Both reviewers were concerned about the lack of consideration of recent work documenting the existence silent delay activity. The concern is that the proposed model relies heavily and exclusively on persistent attractor states and the impression the manuscript created that these states are the only current thinking about working memory.</p><p>The reservations raised by the two reviewers are summarized below and along with the original critiques will provide the guide to the revision, should you decide to revise the manuscript.</p><p>1. Both reviewers recommend that the work is re-framed by taking into account newer studies and asked the authors &quot;consider changing the tone of manuscript, so that it doesn't come across as if persistent attractors are state-of-the-art thinking about working memory&quot;.</p><p>2. Abstract, Introduction and Discussion</p><p>Please clarify in the Introduction and in Discussion that you are testing one model of working memory and acknowledge that there are other models that consider more complex dynamics of activity recorded during the delay. Also, please incorporate into the Abstract and Introduction the effects of deactivation and resistance to the distractors tested by your model.</p><p>3. Please address the point questioning the idea that &quot;anatomical constraints&quot; actually play a critical role in the model. If they are indeed critical to the model, provide documentation.</p><p>4. Consider moving the simplified model into the Supplementary Materials.</p><p>5. Discuss whether and how the proposed model explains extensive reports of silent periods in delay activity. A related issue is to what extent the proposed model depends on persistent activity and whether it can incorporate an STP.</p><p>6. In the Discussion please expand the point already made in the manuscript that &quot;silent activity periods associated with silent WM (Masse et al., 2019; Mongillo et al., 2008; Stokes, 2015) could also be due to distributed WM effects&quot;.</p><p>7. Please provide the definition of &quot;persistent&quot; activity and consider the recommendation to change &quot;persistent&quot; to &quot;elevated&quot; or to &quot;delay activity. Please also address the comment that past observations of &quot;persistent&quot; activity were based on activity averaged across trials, rather than on a trial-by-trial basis.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>Overall the interesting findings seem to be obfuscated by seemingly not so relevant ones. For instance, both the abstract and introduction seem to ignore a main finding, which is the deactivation of the attractor by inactivating the top area. CIB and more resilience to distractors is not properly introduced, either (however mentioned in the abstract). Instead, the authors give relevance to a concept already in the literature, ie bistability accomplished through inter-area connectivity (Eding et al., PNAS, Guo et al., Nature) and to the fact that the model is “anatomically constrained”, which it is not clear that is indeed the case.</p><p>Anatomical constraints.</p><p>The abstract reads: “we developed an anatomically constrained model” but it is not clear in what ways the anatomical data constrains the main model. Indeed, in a supplementary figure and in the simplified model the authors show that it does not seem to matter much “Similar conclusions can be obtained when the anatomical structure of the cortical network is changed -for example, by randomly shuffling individual projection strength values”. This raises the question of which of the new insights depend on this and other “biological constraints”. Namely: “counterstream inhibitory bias”, superiority of distributed WM in resisting distractors, deactivation of global attractor by silencing a top layer, inactivation relationship with specific areas, etc. Each finding should be accompanied by how they are affected by including or not specific “biological constraints”. If some, like anatomical connectivity, are not critical, then they obfuscates the main findings and worsens the overall readability of the paper (which is very good, but a bit long) and could be removed or moved to a supplementary figure showing unequivocally in what ways it does (not) constrain the model. It is somewhat acknowledged in the paper that the main driver of the findings is the gradient of recurrent excitation (“As a matter of fact, the relevant parameter here is the strength of synaptic excitation that varies across cortical space, in the form of a macroscopic gradient”), but this is not very clear at times. Again, if this is indeed the case, less emphasis should be given to the anatomical “constraints” and instead the relevant feature should be spelled out clearly and early on (in the abstract and intro)</p><p>Simplified model.</p><p>It is not very clear what we gain with this model, if not to show that with homogeneous coupling (instead of heterogeneous from experimental data, see above) similar findings are achieved. The model is motivated by “The above model, albeit a simplification of real brain circuits, includes several biologically realistic features, which makes it difficult to identify essential ingredients for the emergence of distributed WM.” This seems a good reason to remove the “biological constraints” from the “full model” (see above). Additionally, because of where this model is introduced in the paper, it becomes unclear when the simplified or the full model is used in the following figures. This could be improved if the simplified model was introduced only in the supplementary material or in a subpanel with a clear title. At a minimum, all captions should say if the full/simplified model were used.</p><p>Previous experimental literature.</p><p>Overall we feel that several studies were not properly considered. For instance, Guo et al., Nature is not cited properly, nor discussed. Note for example that also in this paper there was a model – in addition to clear empirical evidence – with different areas and similar concepts as the ones that are explored here.</p><p>Likewise, both &quot;Cortical information flow during flexible sensorimotor decisions&quot; Markus Siegel et al., Nature and also Panichello and Buschman, Nature were not considered in this study. In both studies, they recorded from several areas across the hierarchy (from visual cortex to PFC) during WM and DM, so they seem to be extremely relevant, especially to constrain the model further in future studies. For example, Panichello and Buschman show clear WM codes in V4, not present in the current model. Another example: &quot;We observed (…) a sharp binary jump of activity, areas like LIP exhibited a more gradual ramping activity, resembling temporal accumulation of information in decision-making(Shadlen and Newsome, 2001)&quot;. Siegel et al., Science show very convincing evidence that this is actually not the case and the model does not seem to match the latencies reported here.</p><p>Of course, this mismatch between data and model is not very important and it does not reduce the value of the current model, but the authors should consider toning down claims like &quot;strong agreement with&quot; or &quot;an excellent agreement with a large body of data, from decades of monkey neurophysiological&quot; which occur throughout the study. The model is a great proof of concept that provides several important insights, but it is far from being in &quot;strong agreement&quot; with what happens in the brain.</p><p>Somatosensory WM.</p><p>Relatedly, the authors perform an experiment that simulates &quot;somatosensory WM&quot;. While the question as to which areas trigger the global attractor is interesting and would deserve to be explored further, the way this is framed (i.e. studying different WM modalities) is misleading and should be adapted. Figure2—figure supplement2 shows that the same global attractor is engaged irrespectively of which area is stimulated. The evidence points otherwise (see Christophel et al., 2017). For example Figure2—figure supplement2 shows persistent activity in IT, which would not be expected for somatosensory WM?</p><p>Inactivations.</p><p>It would be nice to have a schematic of when this inactivation is performed (which we think it is throughout the trial), like in FIGURE 7. It seems that the point made in fig6 C needs the areas to be silenced in the opposite direction (ie hierarchical order) to be conclusive. Figure F seems important, as well as the result in G, but it is very confusing. We would consider simplifying it to show more clearly the relevant features/points made. Again: how much of the findings (in particular the &quot;bowtie&quot; analyses) here depend on the &quot;anatomical constraints&quot; is unclear.</p><p>&quot;which is in agreement with classical prefrontal lesion studies(Curtis and D'esposito, 2004)&quot; The cited paper does not do what the authors did in the model. This line should be removed of better explained</p><p>&quot;In some cases, inactivating specific areas might even lead to a disinhibition of other areas and to a general reinforcement of the attractor&quot;. Again, unclear why this is. Does this depend on gradient of recurrent excitation, hierarchy location or anatomical connectivity?</p><p>Relationship with other mechanisms of working memory.</p><p>This paragraph, while important, seems a bit incomplete in the current form. In particular the part where activity-silent is discussed. The results presented here seem to depend strongly on the persistent activity hypothesis of working memory. Does it make sense to think about distributed attractors through short-term plasticity? The relationship with silent activity does not seem straightforward and this discussion failed to illuminate it.</p><p>In the next paragraph, the authors say &quot;This also means that silent activity periods associated with silent WM (Masse et al., 2019; Mongillo et al., 2008; Stokes, 2015)could also be due to distributed WM effects. Optogenetic inactivations could be used to test this result.&quot; This is an interesting idea, but could be expanded a bit more. Intriguingly, the authors cite papers (Masse et al., 2019; Mongillo et al.,) of local circuits with actual activity-siment mechanism. Instead, the author should cite empirical evidence of silent periods, of which the model proposed here offers an alternative view. For example: Wolff et al., Nature Neuroscience (Human occipital cortex), Barbosa et al., Nature Neuroscience (monkey PFC) and Akrami et al., Nature, (rodent PPC) etc.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I am not suggesting that the authors overhaul their model and start over. But a re-write (and some changing of terms, see below) would serve them well. I would encourage the authors to consider changing the tone of manuscript so that it doesn't come across as if persistent attractors are state-of-the-art thinking about working memory. I suggest a more up-front acknowledging of the newer developments (as opposed to a single paragraph near the end of the Discussion) and that their work will focus on mechanisms that allow average activity to remain elevated. Right now, it reads as if &quot;persistent activity&quot; is everything, with a disclaimer near the end.</p><p>Finally, I encourage the authors to <italic>not</italic> use the term &quot;persistent activity&quot; (try elevated or sustained elevated activity or just &quot;delay activity&quot;). As noted above, there is evidence against persistent activity. But more to the point, there is little or no evidence <italic>for</italic> persistent activity. Virtually all of the work purporting such evidence averaged neural activity across multiple trials. Across-trial averaging masks more complex dynamics like gaps of no spiking. One cannot conclude persistent firing from averaged data. It can only be addressed in real time at the single trial level. Also, there is a no definition of &quot;persistent&quot;. Is it a spike every 5 ms? Every 10 ms? Every 100 ms? Using a term like &quot;persistent activity&quot; when it is not well defined and for which there is little direct evidence muddies the waters and does not do a service to the field.</p><p>Other comments:</p><p>One cannot help but wonder how the hierarchical trends discussed here relate to other hierarchical trends. For example, there is a gradual progression from sensory-related activity to task-relevant activity as one ascends the hierarchy. Or the greater mixed selectivity in higher cortex. Maybe those are separate issues. But if the authors have any insights into how their model contributes to them, it would certainly add value to their manuscript.</p><p>Page 4: &quot;LIP exhibited a more gradual ramping activity, resembling temporal accumulation of information in decision making (Shadlen and Newsome, 2001)&quot;. Again, this was state-of-the-art like a decade ago. It ignores more recent work by Pillow, Shenoy, and others showing that the ramp-up is not gradual. When examined on the single-trial level, the activity is instead a series of discrete state changes. This does not take anything away from the elegant and important work of Shadlen and Newsome, without which the newer work would not have been possible. But, again, by focusing on older, not newer, work, the authors are not giving a full account of where we are in 2021.</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Mechanisms of distributed working memory in a large-scale network of macaque neocortex&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Tirin Moore (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>Reviewers were largely satisfied with the revised manuscript with one exception. They were concerned about the discussion of the role of plasticity in Attractor and Activity-Silent models (lines 559-566). It was felt that the work referred to in the Wang recent review which showed more spiking activity during manipulation of working memory, did not rule out synaptic plasticity. Furthermore, it was pointed out that Activity-Silent models also predict that spiking may be used to &quot;ping&quot; the network and read out the memories. In this case, the role of plasticity is to HELP the spiking, not to replace it.</p><p>To address this concern, this section should be modified. One option would be to provide clear evidence that synaptic plasticity only holds for Activity-Silent models and is not required by the attractor models. This can be done by citing specific references with the appropriate simulations/data or by providing new simulations/data.</p><p>Alternatively, this paragraph should be modified by allowing short-term plasticity to play a role in both types of models.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>With most of my initial concerns addressed and the inclusion of interesting, new simulations, I fully support the publication of the manuscript in the current form.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The authors' revisions are mostly adequate.</p><p>However, the statements that activity-silent models &quot; (1) it cannot filter out distractors that occur later in time than behavioral relevant stimuli, (2) it does not have a severely limited capacity (a characteristic of working memory) and (3) it is incapable of internal manipulation of information&quot; is not true.</p><p>The activity-silent models can explain all of this. Synaptic weight changes are driven and refreshed by spiking. Thus, they have the same features and same control as attractor-state models. 1. Distractors can be filtered out by controlling spiking. 2. They do have a severe capacity limitation due to limitations in the spiking refresh rate. Multiple memories cannot be in the active state at the same time. That leads to capacity limitations. 3. Manipulation of WM is achieved by controlling spiking episodes, just like the attractor-state models.</p><p>The issue is that in testing the activity-silent models, the author has shifted too much of the burden to synapses alone. That is a misrepresentation of the activity-silent models. It is easy to refute a model if one makes a straw model of it. In the activity-silent models, synapses don't do everything. The help activity by briefly carrying the memories between spiking. That is why they are also referred to as &quot;synaptic attractor&quot; models. Because they also involve attractor states, they have many of the same features and mechanisms as attractor-state models. As a wise colleague recently said, the attractor-state and synaptic-attractor models are more similar than different. The characterization that the former can explain a variety of WM phenomena but the latter cannot is not accurate.</p><p>I think this is a valuable review. It is well-written. Attractor dynamics are indeed important and the review offers important insights. But surely these insights can be offered with misrepresenting other models.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.72136.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>Overall the interesting findings seem to be obfuscated by seemingly not so relevant ones. For instance, both the abstract and introduction seem to ignore a main finding, which is the deactivation of the attractor by inactivating the top area. CIB and more resilience to distractors is not properly introduced, either (however mentioned in the abstract). Instead, the authors give relevance to a concept already in the literature, ie bistability accomplished through inter-area connectivity (Eding et al., PNAS, Guo et al., Nature) and to the fact that the model is &quot;anatomically constrained&quot;, which it is not clear that is indeed the case.</p></disp-quote><p>We acknowledge that some important findings were not properly highlighted in our previous version. We have now highlighted more explicitly, in the introduction, our findings regarding CIB, distractor resilience, and the control/inactivation of distributed attractors by prefrontal areas (also in the abstract now, together with the other two).</p><p>We consider, however, that the focus on the distributed bistability via large-scale cortical networks is well placed, given that while the concept was already present in the literature (e.g. Christophel et al., 2017, Leavitt et al., 2017, Guo et al., 2017) our model is the first one to provide a mechanistic and anatomically-constrained explanation about the wide multi-area distribution reported in Christophel et al., 2017 and Leavitt et al., 2017. This goes beyond relatively simpler two-area interactions (Edin et al., 2009, Guo et al., 2017, Murray et al., 2017), which can’t explain the wide activity distribution and lack the spatial extension to predict global trends like the robust transient or the counterstream inhibitory bias.</p><p>We have also elaborated on the anatomical constraints of our model and discussed previous related work (Edin et al., 2009, Guo et al., 2017), as discussed below.</p><disp-quote content-type="editor-comment"><p>Anatomical constraints.</p><p>The abstract reads: &quot;we developed an anatomically constrained model&quot; but it is not clear in what ways the anatomical data constrains the main model. Indeed, in a supplementary figure and in the simplified model the authors show that it does not seem to matter much &quot;Similar conclusions can be obtained when the anatomical structure of the cortical network is changed -for example, by randomly shuffling individual projection strength values&quot;. This raises the question of which of the new insights depend on this and other &quot;biological constraints&quot;. Namely: &quot;counterstream inhibitory bias&quot;, superiority of distributed WM in resisting distractors, deactivation of global attractor by silencing a top layer, inactivation relationship with specific areas, etc. Each finding should be accompanied by how they are affected by including or not specific &quot;biological constraints&quot;. If some, like anatomical connectivity, are not critical, then they obfuscates the main findings and worsens the overall readability of the paper (which is very good, but a bit long) and could be removed or moved to a supplementary figure showing unequivocally in what ways it does (not) constrain the model. It is somewhat acknowledged in the paper that the main driver of the findings is the gradient of recurrent excitation (&quot;As a matter of fact, the relevant parameter here is the strength of synaptic excitation that varies across cortical space, in the form of a macroscopic gradient&quot;), but this is not very clear at times. Again, if this is indeed the case, less emphasis should be given to the anatomical &quot;constraints&quot; and instead the relevant feature should be spelled out clearly and early on (in the abstract and intro)</p></disp-quote><p>It is important to clarify the differences between anatomically-constrained model and anatomically-constrained result. Our model is clearly anatomically constrained, in the sense that we use anatomical data to determine many of its parameters, such as the connectivity matrix or some local properties. However, having an anatomically-constrained model doesn’t necessarily imply that all results from such a model will depend critically on the particular anatomical values used. Indeed, some flexibility in parameter values should be expected to allow, for instance, inter-subject variability, or even robustness of the results across species. In general, results which are sensitive to changes in structural assumptions might be valid predictions for macaques, while results more resilient to these changes (like the emergence of distributed WM patterns, as Figure 3 shows) are more likely to occur in other species too.</p><p>Likewise, anatomical constrains will be more important for some brain areas but less for others. For example, the local synaptic strength assumed for V1 is not very important, as long as it remains at the bottom of the hierarchy.</p><p>In the supplementary figure mentioned by the reviewer (Figure 4 supplement 2e-h), we indeed observe that we obtain the same result <italic>globally</italic> (i.e. emergence of distributed WM patterns) when individual projection strengths are shuffled. However we also observe a clear effect in results <italic>for individual areas</italic> (see panel ‘f’, for example). More precisely, we see, as also stated in the text, that the duration of persistent activity for some areas is affected; other areas stop participating in the distributed attractor. Therefore, the anatomical constraint of projection strengths has a quantitative effect –areas may drop from the distributed WM pattern if their connectivity is altered –and therefore this constrain cannot be dropped without altering the predictions of the model.</p><p>A similar point can be made about the results of the simplified model: they indicate that the precise anatomical connectivity is not necessary to have distributed activity patters in a generic network, but the particular connectivity matters if we consider differences between concrete areas. Without the anatomical connectivity, we would not be able to make any claims about how areas like LIP, 8B or 9/46d participate or not in the distributed WM attractors, as showed in Figures 2 or 6 for example.</p><p>Following the reviewer’s advice, but also with this consideration in mind, we have added a sentence in the first paragraph of the results to summarize our clarifications from above. We have also carefully revised all the results of the manuscript and indicated, in a new paragraph in the discussion (page 15), the dependency of the results with the anatomical constrains. In particular:</p><p>– The CIB results in Figure 4 have already been shown (in Figure 3) to be the result of the concrete shape of the local strength gradient (linear vs spine count), and also not strongly dependent on the connectivity values (as similar results are found with the simplified model).</p><p>– The emergence and properties of a large number of attractors (Figure 5) are strongly dependent on the gradients, connectivity and also other choices of the model (in particular, the consideration of only two selective populations per area in the model). Therefore, although we expect that a large number of attractors will be found using, for example, connectomes for other species, we can’t predict their numbers.</p><p>– For a similar reason, the particular effects of silencing areas on the activity and number of attractors (Figures 6 and 7) will depend on the gradient and connectivity properties. These results will be therefore valid for macaque brains, but may differ for other species in which, for example, a bowtie structure is not present.</p><p>– The resistance of distributed WM patterns to distractors in Figure 8 is a property inherently linked to the existence of distributed WM patters, moderate values of Jmax, and the CIB, so as long as these two conditions are present, models of other animals’ brains and/or conditions will also display a similar behavior.</p><disp-quote content-type="editor-comment"><p>Simplified model.</p><p>It is not very clear what we gain with this model, if not to show that with homogeneous coupling (instead of heterogeneous from experimental data, see above) similar findings are achieved. The model is motivated by &quot;The above model, albeit a simplification of real brain circuits, includes several biologically realistic features, which makes it difficult to identify essential ingredients for the emergence of distributed WM.&quot; This seems a good reason to remove the &quot;biological constraints&quot; from the &quot;full model&quot; (see above). Additionally, because of where this model is introduced in the paper, it becomes unclear when the simplified or the full model is used in the following figures. This could be improved if the simplified model was introduced only in the supplementary material or in a subpanel with a clear title. At a minimum, all captions should say if the full/simplified model were used.</p></disp-quote><p>The apologize if the benefits of the simplified model were not properly explained, but we do not think that is a good idea to “remove the biological constraints from the full model”. These are two different and complementary levels of description, and they both provide useful information to the reader.</p><p>In particular, the simplified model tells us about the basic ingredients to have distributed WM (in a generic network, with simplified dynamics, etc) as explicitly stated in page 5: strong enough long-range projections and linear gradient of local couplings (or a CIB, if the gradient is sublinear). Such synthesis is not easy to do from the full model, and it could be useful, for example, to generalize to other systems in future studies (for example, brains of rodents or humans). On the other hand, the full model is needed to assess the validity of our claims in more realistic scenarios. If we only consider the results of the simplified model, it would not be clear whether these results would hold when adding more realistic considerations (i.e. real connectivity matrix, inhibitory populations, etc).</p><p>A good example from the text: the simplified model shows that distributed WM emerges for linear gradient of local recurrent strengths (Figure 3b,c). When we introduce the data about dendritic spines (Figure 3e,f), we discover that the soft saturation present in this data turns the distributed WM pattern into an unrealistic all-or-none situation. This leads us to identify CIB (or weaker excitatory FB projections, in the case of the simplified model) as a solution to have realistic WM patters in the full model (as later explored in Figure 4). The study of the simplified model alone, without data to constrain the gradient, would have not explored these effects, and the study of the full model alone might have overlooked the critical importance of CIB.</p><p>We therefore consider that both the full model and the simplified model provide important information to the reader, and we have a strong preference to maintain Figure 3 in the main text. In addition, we have now introduced a variation of the simplified model (new Figure 3 —figure supplement 1) to explore the case of distributed activity-silent memory. See response to another related comment below.</p><p>We have improved our justification for the use of the simplified model (page 5). We have also indicated clearly in the main text (page 6) that, after Figure 3, the full model is used for the rest of the paper. Furthermore, we added ‘full model’ in captions of Figures 4 and 5 to further emphasize this.</p><disp-quote content-type="editor-comment"><p>Previous experimental literature.</p><p>Overall we feel that several studies were not properly considered. For instance, Guo et al., Nature is not cited properly, nor discussed. Note for example that also in this paper there was a model – in addition to clear empirical evidence – with different areas and similar concepts as the ones that are explored here.</p><p>Likewise, both &quot;Cortical information flow during flexible sensorimotor decisions&quot; Markus Siegel et al., Nature and also Panichello and Buschman, Nature were not considered in this study. In both studies, they recorded from several areas across the hierarchy (from visual cortex to PFC) during WM and DM, so they seem to be extremely relevant, especially to constrain the model further in future studies. For example, Panichello and Buschman show clear WM codes in V4, not present in the current model. Another example: “We observed (…) a sharp binary jump of activity, areas like LIP exhibited a more gradual ramping activity, resembling temporal accumulation of information in decision-making(Shadlen and Newsome, 2001)”. Siegel et al., Science show very convincing evidence that this is actually not the case and the model does not seem to match the latencies reported here.</p><p>Of course, this mismatch between data and model is not very important and it does not reduce the value of the current model, but the authors should consider toning down claims like &quot;strong agreement with&quot; or &quot;an excellent agreement with a large body of data, from decades of monkey neurophysiological&quot; which occur throughout the study. The model is a great proof of concept that provides several important insights, but it is far from being in &quot;strong agreement&quot; with what happens in the brain.</p></disp-quote><p>Although we had previously cited Guo et al., multiple times in our manuscript, including an explicit mention to its importance to extend our model to thalamocortical loops in the future, we agree that this paper required more consideration. In addition to very relevant experimental evidence, they also presented a computational model, although consisting only of two interacting areas (similar in scope to Murray, Jaramillo and Wang 2017). In this sense, it provides a valuable starting point and we now cite it in the introduction, when other two-area WM models (Edin et al., 2009, Murray et al., 2017) are acknowledged. We also included it, together with Murray et al., 2017, in a new sentence in the discussion stating that these works previously explored inter-areal interactions to sustain WM in more limited (i.e. two-area) models.</p><p>In addition, we have now cited the studies of Siegel et al., and Panichello and Buschman. We agree with the reviewer about the importance of these works in our conclusions. Even though the tasks are different from the one we simulate with our model (and therefore their results are not directly comparable), we think that they should guide future improvements of the model once ingredients such attention and sensorimotor integration are carefully taken into account –and we have indicated this in the text (page 13). The sentence about LIP has been modified, also as a response to a comment from Reviewer 2. We have also toned down overly strong claims along the manuscript, including replacing mentions to ‘strong agreement’ with just ‘substantial agreement’ or simply ‘agreement’.</p><disp-quote content-type="editor-comment"><p>Somatosensory WM.</p><p>Relatedly, the authors perform an experiment that simulates “somatosensory WM”. While the question as to which areas trigger the global attractor is interesting and would deserve to be explored further, the way this is framed (i.e. studying different WM modalities) is misleading and should be adapted. Figure2—figure supplement2 shows that the same global attractor is engaged irrespectively of which area is stimulated. The evidence points otherwise (see Christophel et al., 2017). For example Figure2—figure supplement2 shows persistent activity in IT, which would not be expected for somatosensory WM?</p></disp-quote><p>We agree, current experimental evidence suggests that stimulation of different areas (or via different modalities) shouldn’t necessarily lead to the same attractors, as it happens with the model. We believe that the reason for this “convergence to the same attractor” is the absence of a gating mechanism in the model, which would allow some areas to participate in modality-specific global attractors. This is already tested in an extension of our model, shown in Figure 2 supplement 4, which aims to provide an explanation for such differences. We have rewritten the text of this result (page 5) so that the need of additional considerations is now clearer to the readers. As a result of this change, Figure 2 supplementary figures 3 and 4 have been swapped.</p><disp-quote content-type="editor-comment"><p>Inactivations.</p><p>It would be nice to have a schematic of when this inactivation is performed (which we think it is throughout the trial), like in Figure 7. It seems that the point made in fig6 C needs the areas to be silenced in the opposite direction (ie hierarchical order) to be conclusive. Figure F seems important, as well as the result in G, but it is very confusing. We would consider simplifying it to show more clearly the relevant features/points made. Again: how much of the findings (in particular the “bowtie” analyses) here depend on the “anatomical constraints” is unclear.</p></disp-quote><p>As the reviewer suspects, the inactivation is performed throughout the trial, we have now clearly stated in Figure 6 caption. Panel 6C shows indeed the effect of silencing the areas in the opposite hierarchical order, as the reviewer says, and the silencing is also trial-long: first a trial with the last area silenced, then a trial with last and second-to-last areas silenced, etc. The whole purpose with this approach is to test the resilience of attractors when targeting top hierarchical areas specifically for the inactivation. And as we already discussed in the point above, these results are strongly dependent on the anatomical data used –results won’t necessarily be the same for connectomes of rodents or humans, for example.</p><p>We have clarified the results of Figure 6C,F,G in the main text (pages 8-9) and in the figure caption. We have also improved the clarity of the figures and explanations of Fig6F and G (including the bowtie analysis and how it depends on the anatomical data).</p><disp-quote content-type="editor-comment"><p>“which is in agreement with classical prefrontal lesion studies(Curtis and D’esposito, 2004)” The cited paper does not do what the authors did in the model. This line should be removed of better explained</p></disp-quote><p>We have corrected this sentence.</p><disp-quote content-type="editor-comment"><p>“In some cases, inactivating specific areas might even lead to a disinhibition of other areas and to a general reinforcement of the attractor”. Again, unclear why this is. Does this depend on gradient of recurrent excitation, hierarchy location or anatomical connectivity?</p></disp-quote><p>The described effect has its origin in the hierarchical relationships between areas and the CIB –silencing a top area which is inhibiting lower ones might release the lower areas from the inhibition and increase their activity. We have included a new sentence to clarify it, in page 9.</p><disp-quote content-type="editor-comment"><p>Relationship with other mechanisms of working memory.</p><p>This paragraph, while important, seems a bit incomplete in the current form. In particular the part where activity-silent is discussed. The results presented here seem to depend strongly on the persistent activity hypothesis of working memory. Does it make sense to think about distributed attractors through short-term plasticity? The relationship with silent activity does not seem straightforward and this discussion failed to illuminate it.</p><p>In the next paragraph, the authors say “This also means that silent activity periods associated with silent WM (Masse et al., 2019; Mongillo et al., 2008; Stokes, 2015)could also be due to distributed WM effects. Optogenetic inactivations could be used to test this result.” This is an interesting idea, but could be expanded a bit more. Intriguingly, the authors cite papers (Masse et al., 2019; Mongillo et al.,) of local circuits with actual activity-siment mechanism. Instead, the author should cite empirical evidence of silent periods, of which the model proposed here offers an alternative view. For example: Wolff et al., Nature Neuroscience (Human occipital cortex), Barbosa et al., Nature Neuroscience (monkey PFC) and Akrami et al., Nature, (rodent PPC) etc.</p></disp-quote><p>In response to this comment, and also to the concerns of Reviewer #2, we have included new simulation results (new Figure 3 —figure supplement 1) showing how activity-silent memory traces could also emerge in a distributed fashion. In this case, the short-term synaptic efficacy is maintained during longer periods of time because of the long-range interactions between brain areas, rather than local recurrent input. We have rewritten parts of the text over the entire manuscript (and particularly in the introduction and discussion) to make more explicit the generality of our proposed mechanism for distributed WM beyond persistent activity, and also to improve the discussion regarding silent WM. We have also expanded our proposed optogenetic testing.</p><p>Regarding the optogenetic inactivations, we meant to suggest that they could be used to test whether information encoded in WM areas could survive short inactivations. We realize that the previous writing was confusing, and since we are addressing the activity-silent phenomenon elsewhere in the text, we have now removed this sentence.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>I am not suggesting that the authors overhaul their model and start over. But a re-write (and some changing of terms, see below) would serve them well. I would encourage the authors to consider changing the tone of manuscript so that it doesn't come across as if persistent attractors are state-of-the-art thinking about working memory. I suggest a more up-front acknowledging of the newer developments (as opposed to a single paragraph near the end of the Discussion) and that their work will focus on mechanisms that allow average activity to remain elevated. Right now, it reads as if &quot;persistent activity&quot; is everything, with a disclaimer near the end.</p></disp-quote><p>Following the reviewer’s advice, we have adapted the text along the manuscript (and especially in the introduction and discussion) to put our proposal in a more general light and acknowledging other WM mechanisms from the beginning. Our work reads now as primarily focused on the persistent activity hypothesis for practical matters but highlighting that our distributed WM proposal can be applied more generally.</p><p>To elaborate on this point a bit further, we have also investigated, using a variation of our simplified model, whether our distributed WM proposal could also facilitate the emergence of activity-silent memory traces. More precisely, we have reduced the overall synaptic strength in our simplified model and included short-term synaptic facilitation in both local and long-range connections, and tested whether activity-silent memory traces can also benefit from inter-areal interactions and ‘silent’ distributed attractors may emerge. This seems to be the case, as we show in new Figure 3 —figure supplement 1. Our model shows that silent memory traces emerge when brain areas are allowed to support each other, but it fades away if we only consider isolated areas, as in the case of the persistent activity model. While this result opens the door for more realistic simulations, we hope that this will suffice to make a point about the generality of the distributed WM hypothesis proposed here.</p><disp-quote content-type="editor-comment"><p>Finally, I encourage the authors to not use the term &quot;persistent activity&quot; (try elevated or sustained elevated activity or just &quot;delay activity&quot;). As noted above, there is evidence against persistent activity. But more to the point, there is little or no evidence for persistent activity. Virtually all of the work purporting such evidence averaged neural activity across multiple trials. Across-trial averaging masks more complex dynamics like gaps of no spiking. One cannot conclude persistent firing from averaged data. It can only be addressed in real time at the single trial level. Also, there is a no definition of &quot;persistent&quot;. Is it a spike every 5 ms? Every 10 ms? Every 100 ms? Using a term like &quot;persistent activity&quot; when it is not well defined and for which there is little direct evidence muddies the waters and does not do a service to the field.</p></disp-quote><p>This is a very interesting point, although we think that the situation might be a bit different in our case. Our model considers the macroscopic activity of brain areas, which in a real brain would be obtained by averaging over the activity of many individual neural responses in the same circuit. While single-neuron persistent activity is limited as explanation for WM, a ‘population persistent activity’ as used in our model is more plausible, and it could also arise via more flexible mechanisms which allow for a dynamics and highly-variable single-neuron activity (Goldman, Neuron 2009).</p><p>In addition, we consider that persistent activity should not be understood as a constant, fixed value of all firing rates, but as the opposite to decaying transient activity. This has been recently discussed in Wang, TiNS 2021, and it could indeed constitute a working definition for the term ‘persistent activity’. In general, persistent activity can incorporate complex dynamics and variability in the firing rates during the delay epoch, a feature of persistent activity which has been addressed in previous studies. For example, Compte et al., 2000 (see panel A in <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>) already showed the presence of rhythmic variability during the persistent activity period. Such rhythmic activity is similar to the periodic bursts required for silent-activity mechanisms –as a matter of fact, Mongillo et al., (2008) showed such an example (see panel B) with a slightly different model parameter change from that corresponding to the activity-silent state regime.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72136-sa2-fig1-v1.tif"/></fig><p>Nonetheless, we have followed the advice and adapted the terminology so that the terms ‘sustained activity’ or ‘sustained delay activity’ are used by default, and included a new section in the discussion (page 13) where these issues are explained.</p><disp-quote content-type="editor-comment"><p>Other comments:</p><p>One cannot help but wonder how the hierarchical trends discussed here relate to other hierarchical trends. For example, there is a gradual progression from sensory-related activity to task-relevant activity as one ascends the hierarchy. Or the greater mixed selectivity in higher cortex. Maybe those are separate issues. But if the authors have any insights into how their model contributes to them, it would certainly add value to their manuscript.</p></disp-quote><p>These are indeed relevant issues, as our work establishes a partial connection between structural gradients (dendritic spine count, position in the SLN-defined anatomical hierarchy) and functional ones (persistent activity being more common in higher vs lower areas in the hierarchy). Although the insight provided by our work is limited, the previous version of our manuscript provided an attempt (in the discussion) to relate our work with other hierarchical trends. We have now extended such paragraph to include the example of sensory- and task-related gradients and the mixed selectivity examples that the reviewer mentioned (page 11).</p><disp-quote content-type="editor-comment"><p>Page 4: &quot;LIP exhibited a more gradual ramping activity, resembling temporal accumulation of information in decision making (Shadlen and Newsome, 2001)&quot;. Again, this was state-of-the-art like a decade ago. It ignores more recent work by Pillow, Shenoy, and others showing that the ramp-up is not gradual. When examined on the single-trial level, the activity is instead a series of discrete state changes. This does not take anything away from the elegant and important work of Shadlen and Newsome, without which the newer work would not have been possible. But, again, by focusing on older, not newer, work, the authors are not giving a full account of where we are in 2021.</p></disp-quote><p>Following the point of population activity of our previous comment above, we think it’s important to clarify that our model focuses on population-level (rather than neuron-level) dynamics, and therefore our description is not invalidated by the recent work by Pillow, Shenoy and others. We have modified the sentence highlighted by the reviewer to make this parallelism clearer in the text (page 4).</p><p>[Editors’ note: what follows is the authors’ response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>With most of my initial concerns addressed and the inclusion of interesting, new simulations, I fully support the publication of the manuscript in the current form.</p></disp-quote><p>We thank Reviewer 1 for his work to improve our manuscript.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>The authors' revisions are mostly adequate.</p><p>However, the statements that activity-silent models &quot; (1) it cannot filter out distractors that occur later in time than behavioral relevant stimuli, (2) it does not have a severely limited capacity (a characteristic of working memory) and (3) it is incapable of internal manipulation of information&quot; is not true.</p><p>The activity-silent models can explain all of this. Synaptic weight changes are driven and refreshed by spiking. Thus, they have the same features and same control as attractor-state models. 1. Distractors can be filtered out by controlling spiking. 2. They do have a severe capacity limitation due to limitations in the spiking refresh rate. Multiple memories cannot be in the active state at the same time. That leads to capacity limitations. 3. Manipulation of WM is achieved by controlling spiking episodes, just like the attractor-state models.</p><p>The issue is that in testing the activity-silent models, the author has shifted too much of the burden to synapses alone. That is a misrepresentation of the activity-silent models. It is easy to refute a model if one makes a straw model of it. In the activity-silent models, synapses don't do everything. The help activity by briefly carrying the memories between spiking. That is why they are also referred to as &quot;synaptic attractor&quot; models. Because they also involve attractor states, they have many of the same features and mechanisms as attractor-state models. As a wise colleague recently said, the attractor-state and synaptic-attractor models are more similar than different. The characterization that the former can explain a variety of WM phenomena but the latter cannot is not accurate.</p><p>I think this is a valuable review. It is well-written. Attractor dynamics are indeed important and the review offers important insights. But surely these insights can be offered with misrepresenting other models.</p></disp-quote><p>We thank the Reviewer for elaborating on this point and help us to clarify the text. The Reviewer is correct in that all three limitations mentioned above disappear when a combination of short-term plasticity and spiking activity are considered.</p><p>Importantly, we did not mean to imply that self-sustained activity and short-term facilitation are incompatible. As a matter of fact, short-term facilitation is part of recurrent synaptic interactions that need to be sufficiently strong for maintaining self-sustained firing. The attractor scenario is differentiated from the activity-silent scenario not by the nature of the underlying biological feedback mechanism (e.g. NMDA receptor dependent transmission or synaptotagmin 7 dependent synaptic facilitation), but by whether it is above a threshold strength.</p><p>To clarify this point and avoid misrepresenting the activity-silent models, we have slightly modified the title of the corresponding subsection (to ‘Attractor model of working memory and activity-silent state models’), and replaced the sentences mentioned by the Reviewer (page 13) by the following:</p><disp-quote content-type="editor-comment"><p>“Another example is self-sustained repetition of brief bursts of spikes interspersed with long silent time epochs (Mi et al., 2017). [...] Short-term plasticity could therefore contribute to activity-silent memory traces but also to self-sustained activity.”</p></disp-quote></body></sub-article></article>