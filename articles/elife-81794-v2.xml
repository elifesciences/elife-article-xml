<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">81794</article-id><article-id pub-id-type="doi">10.7554/eLife.81794</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Spatial frequency representation in V2 and V4 of macaque monkey</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-284238"><name><surname>Zhang</surname><given-names>Ying</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9631-8280</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-287273"><name><surname>Schriver</surname><given-names>Kenneth E</given-names></name><email>kenschriver@zju.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-199674"><name><surname>Hu</surname><given-names>Jia Ming</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5306-445X</contrib-id><email>hujiaming@zju.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-158625"><name><surname>Roe</surname><given-names>Anna Wang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4146-9705</contrib-id><email>annawang@zju.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>Department of Neurosurgery of the Second Affiliated Hospital, Interdisciplinary Institute of Neuroscience and Technology, School of Medicine, Zhejiang University</institution></institution-wrap><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>Key Laboratory of Biomedical Engineering of Ministry of Education, College of Biomedical Engineering and Instrument Science, Zhejiang University</institution></institution-wrap><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>MOE Frontier Science Center for Brain Science and Brain-Machine Integration, School of Brain Science and Brain Medicine, Zhejiang University</institution></institution-wrap><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ray</surname><given-names>Supratim</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dese585</institution-id><institution>Indian Institute of Science Bangalore</institution></institution-wrap><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Howard Hughes Medical Institute, Stanford University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>06</day><month>01</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e81794</elocation-id><history><date date-type="received" iso-8601-date="2022-07-12"><day>12</day><month>07</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-01-05"><day>05</day><month>01</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-07-29"><day>29</day><month>07</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.07.27.501743"/></event></pub-history><permissions><copyright-statement>© 2023, Zhang et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Zhang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-81794-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-81794-figures-v2.pdf"/><abstract><p>Spatial frequency (SF) is an important attribute in the visual scene and is a defining feature of visual processing channels. However, there remain many unsolved questions about how extrastriate areas in primate visual cortex code this fundamental information. Here, using intrinsic signal optical imaging in visual areas of V2 and V4 of macaque monkeys, we quantify the relationship between SF maps and (1) visual topography and (2) color and orientation maps. We find that in orientation regions, low to high SF is mapped orthogonally to orientation; in color regions, which are reported to contain orthogonal axes of color and lightness, low SFs tend to be represented more frequently than high SFs. This supports a population-based SF fluctuation related to the ‘color/orientation’ organizations. We propose a generalized hypercolumn model across cortical areas, comprised of two orthogonal parameters with additional parameters.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>visual cortex</kwd><kwd>functional imaging</kwd><kwd>macaque monkey</kwd><kwd>spatial frequency</kwd><kwd>orientation</kwd><kwd>visual topography</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>China Brain Initiative</institution></institution-wrap></funding-source><award-id>2021ZD0200401</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012166</institution-id><institution>National Key Research and Development Program of China</institution></institution-wrap></funding-source><award-id>2018YFA0701400</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31627802</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>U20A20221</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>81961128029</award-id><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>The MOE Frontier Science Center for Brain Science &amp; Brain-Machine Integration</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Roe</surname><given-names>Anna Wang</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32100802</award-id><principal-award-recipient><name><surname>Hu</surname><given-names>Jia Ming</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002858</institution-id><institution>China Postdoctoral Science Foundation</institution></institution-wrap></funding-source><award-id>2020M681829</award-id><principal-award-recipient><name><surname>Hu</surname><given-names>Jia Ming</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>V2 and V4 contain orthogonal maps of orientation and spatial frequency, which indicates a fundamental principle of functional mapping across the cortical surface that ensures and optimizes the complete representation of all combinations across two coding dimensions.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Spatial frequency (SF) selectivity is a fundamental feature encoded in the visual system. Previous studies have shown that the organization of SF selectivity is related to orientation and color maps in the primary visual cortex (V1) and have a high degree of periodicity in both cats (<xref ref-type="bibr" rid="bib21">Hübener et al., 1997</xref>; <xref ref-type="bibr" rid="bib22">Issa et al., 2000</xref>; <xref ref-type="bibr" rid="bib46">Shoham et al., 1997</xref>; <xref ref-type="bibr" rid="bib52">Tootell et al., 1981</xref>) and monkeys (<xref ref-type="bibr" rid="bib47">Silverman et al., 1989</xref>). Studies have consistently shown an orthogonal mapping of SF and orientation, suggesting an efficient arrangement that provides each orientation access to a wide range of SFs (<xref ref-type="bibr" rid="bib22">Issa et al., 2000</xref>; <xref ref-type="bibr" rid="bib35">Nauhaus et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Nauhaus et al., 2016</xref>; <xref ref-type="bibr" rid="bib61">Xu et al., 2007</xref>). In contrast, color representation in V1 (the color is represented in patches commonly referred to as 'blobs' in V1) is generally associated with a range of lower SFs (<xref ref-type="bibr" rid="bib47">Silverman et al., 1989</xref>; <xref ref-type="bibr" rid="bib54">Tootell et al., 1988</xref>). Thus, in addition to a gradient from high to low of SF representation across eccentricities (<xref ref-type="bibr" rid="bib13">Foster et al., 1985</xref>; <xref ref-type="bibr" rid="bib10">De Valois et al., 1982</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Yu et al., 2010</xref>), SF organization is further specified within local distinct functional regions. This systematic architecture in V1 suggests that SF may be a fundamental feature of the cortical ‘hypercolumn’ (c.f., <xref ref-type="bibr" rid="bib47">Silverman et al., 1989</xref>: organized cortical modules; <xref ref-type="bibr" rid="bib21">Hübener et al., 1997</xref>: ‘mosaics’ of functional domains for the different properties; <xref ref-type="bibr" rid="bib49">Swindale et al., 2000</xref>: uniform coverage of cortical maps).</p><p>Whether there are systematic associations between SF and other parameters in extrastriate areas, such as V2 and V4, is not known. The traditional view of the V2 hypercolumn comprises the alternating thin-pale-thick-pale stripe cycle (<xref ref-type="bibr" rid="bib18">Horton, 1984</xref>; <xref ref-type="bibr" rid="bib30">Livingstone and Hubel, 1984</xref>; <xref ref-type="bibr" rid="bib41">Roe and Ts’o, 1995</xref>; <xref ref-type="bibr" rid="bib53">Tootell et al., 1983</xref>). Within thin stripes, surface properties, typically associated with low SF preferences, such as hue maps (<xref ref-type="bibr" rid="bib60">Xiao et al., 2003</xref>), ‘brightness’ maps (<xref ref-type="bibr" rid="bib42">Roe et al., 2005</xref>), and ON/FF maps (<xref ref-type="bibr" rid="bib57">Wang et al., 2007</xref>) are represented. Within the thick and pale stripes are higher-order orientation maps such as those defined by illusory contours (<xref ref-type="bibr" rid="bib40">Ramsden et al., 2001</xref>), motion direction maps (<xref ref-type="bibr" rid="bib32">Lu et al., 2010</xref>), and maps for motion-defined edges (<xref ref-type="bibr" rid="bib6">Chen et al., 2016</xref>), as well as stereo-defined near-to-far disparity maps (<xref ref-type="bibr" rid="bib5">Chen et al., 2008</xref>). Neuronal response for features such as texture have also been described (<xref ref-type="bibr" rid="bib14">Freeman et al., 2013</xref>), but functional organization has not yet been investigated. There is little systematic data relating SF representation in V2 to functional stripes (cf., <xref ref-type="bibr" rid="bib17">Gegenfurtner et al., 1996</xref>; <xref ref-type="bibr" rid="bib25">Levitt et al., 1994</xref>; <xref ref-type="bibr" rid="bib55">Tootell and Hamilton, 1989</xref>) and, despite previous attempts, few studies have demonstrated functional mapping of stripes based on SF alone (<xref ref-type="bibr" rid="bib31">Lu and Roe, 2007</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>).</p><p>In V4, surface and shape information are organized into, for lack of better terminology, ‘color’ and ‘orientation’ bands. Within the color bands, maps for hue and for luminance have been described (<xref ref-type="bibr" rid="bib51">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib29">Liu et al., 2020</xref>; <xref ref-type="bibr" rid="bib28">Li et al., 2022</xref>). Within orientation bands, there are maps for contrast-defined contours (<xref ref-type="bibr" rid="bib19">Hu et al., 2020</xref>; <xref ref-type="bibr" rid="bib26">Li et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Tang et al., 2020</xref>; <xref ref-type="bibr" rid="bib51">Tanigawa et al., 2010</xref>), disparity-defined contours (<xref ref-type="bibr" rid="bib11">Fang et al., 2019</xref>), as well as maps for curvature degree and curvature orientation (<xref ref-type="bibr" rid="bib19">Hu et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Ponce et al., 2017</xref>). Despite our growing understanding of functional organization in V4, how SF preference maps (first reported in <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>) relate to other feature maps in V4 remains unknown.</p><p>As part of our investigation into ‘hypercolumn’ organization in extrastriate cortical areas, we propose a general hypercolumn layout for V2 and V4 that includes SF (cf., <xref ref-type="bibr" rid="bib43">Roe et al., 2009</xref>; <xref ref-type="bibr" rid="bib56">Ts’o et al., 2009</xref>). Based on previous results reported in V1 (<xref ref-type="bibr" rid="bib13">Foster et al., 1985</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>; <xref ref-type="bibr" rid="bib35">Nauhaus et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Nauhaus et al., 2016</xref>; <xref ref-type="bibr" rid="bib47">Silverman et al., 1989</xref>; <xref ref-type="bibr" rid="bib54">Tootell et al., 1988</xref>; <xref ref-type="bibr" rid="bib62">Yu et al., 2010</xref>), we predict that in each area (1) the range of SF associations shift with the topographic location of the ‘hypercolumn’ (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), (2) orientation-selective regions (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, blue) have a range of low (light gray) to high (dark gray) SF representation; iso-SF contours (purple dashed lines) map orthogonally to iso-orientation contours (green dashed lines), and (3) color-selective regions (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, orange) exhibit an association with a range of low SFs (light gray). To address this proposal, we imaged V1, V2, and V4 of macaque monkey via intrinsic signal optical imaging (ISOI) with large cortical fields of view that contained sufficient territory to allow comparisons of functional organization at a range of eccentricities (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Quantification of the relationship between SF maps and color and orientation maps in V2 and V4 revealed organizations that generally support our proposal for a hypercolumn architecture.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Illustration of proposed hypercolumn (including spatial frequency [SF], color, and orientation domains) in the visual cortex.</title><p>(<bold>A</bold>) As eccentricity decreases from parafoveal to foveal region, the preferred SF gradually increases (represented as the brightness of the short bar). However, a local region (marked by a rectangle) covers a full range of SF representations in its corresponding topographic locations. This local region can be considered a ‘hypercolumn.’ (<bold>B</bold>) Details of structure in a single hypercolumn. In this local region, color domains (orange area) and orientation domains (blue area) exhibit different relationships with SF domains (light gray region: low SF preference domain; dark gray region: high SF preference domain). Orientation maps orthogonally to SF maps (green dashed lines: iso-orientation contours; purple dashed lines: iso-SF contours); an extensive range of SFs are available to each orientation. In comparison, color domains tend to have more spatial overlap with low SF preference domains and avoid overlap with high SF preference domains. In color domains, another orthogonal relationship exists between hue (dotted lines with different colors: iso-hue contours) and brightness (blue dashed lines: iso-brightness contours).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig1-v2.tif"/></fig><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Experimental parameters.</title><p>(<bold>A</bold>) Visual stimuli. Top and bottom rows show the black/white and green/red full screen sinusoidal gratings for four different spatial frequencies (SFs) (indicated by the numbers on top, in cycles/deg). Here for demonstration, the stimulus size is set to 2°. (<bold>B</bold>) Diagram of imaging site in the right hemisphere. L: lateral; A: anterior. (<bold>C</bold>) Lower-left visual field. Black dot: fovea. Horizontal (red) and vertical (blue) lines mapped in (<bold>D</bold>). (<bold>D</bold>) Schematic mapping of lines in (<bold>C</bold>) in V4 (corresponding to the orange disc in <bold>B</bold>). The lateral part of the imaged region corresponds to the foveal region, while the medial part corresponds to the parafoveal region. LS: lunate sulcus; STS: superior temporal sulcus; IOS: inferior occipital sulcus. Red star: estimated foveal location.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig2-v2.tif"/></fig></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Overall SF preference across imaged visual cortical areas</title><p>Imaging a large field of view of the cortex makes it possible to directly compare the response differences between different visual areas (<xref ref-type="fig" rid="fig2">Figure 2</xref>). <xref ref-type="fig" rid="fig3">Figure 3</xref> shows the blood vessel maps (A, E) and corresponding SF preference maps (B, F) for two separate cases wherein we imaged regions spanning V1, V2, and V4. The SF preference maps (<xref ref-type="fig" rid="fig3">Figure 3B and F</xref>) were generated by calculating the response amplitude of each pixel in these areas for stimuli with six different SFs, each at orientations of 45° and 135°. We found that in both cases, most of the imaged V1 region favored high SF stimuli, while most of the imaged V4 region favored low SF stimuli. To examine the proportion of cortical area dedicated to a single SF preference in each area (V1, V2, and V4), we calculated for each SF a coverage ratio (the area of SF-preferential response divided by the whole area, i.e., V1, V2, or V4, within the field of view). For V1, the coverage ratio peaks at high SF (light gray bars in <xref ref-type="fig" rid="fig3">Figure 3C and G</xref>), while for V4, the coverage ratio peaks at low SF (black bars in <xref ref-type="fig" rid="fig3">Figure 3C and G</xref>), consistent with previous findings that V4 prefers lower SF than V1 (<xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>). The preferred SFs (<xref ref-type="fig" rid="fig3">Figure 3D and H</xref>) significantly decrease from V1 to V4 (see <xref ref-type="table" rid="table1">Table 1</xref>, Kolmogorov–Smirnov test, V1 vs. V4, V2 vs. V4, V1 vs. V2, p&lt;0.001). Our maps, in contrast to earlier studies (<xref ref-type="bibr" rid="bib13">Foster et al., 1985</xref>; <xref ref-type="bibr" rid="bib25">Levitt et al., 1994</xref>; <xref ref-type="bibr" rid="bib31">Lu and Roe, 2007</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Silverman et al., 1989</xref>), directly show the overall SF preference in cortical space.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Two examples of overall spatial frequency (SF) preference in visual cortex.</title><p>(<bold>A, E</bold>) Blood vessel map of the imaged region for cases 1 and 2, respectively. V2 and V4 are separated by the lunate sulcus (LS). Red star: estimated foveal location. Scale bar here and in all subsequent figures are 1 mm. (<bold>B, F</bold>) SF preference maps for cases 1 and 2, respectively. Each SF stimulus contains two orientations, 45º and 135º. For each pixel, the preferred SF is defined as the SF corresponding to its strongest response. Different colors represent different SF preferences (see color bar at top). The border between V1 and V2 (defined by ocular dominance image) is indicated by a black dashed line. A, anterior; L, lateral. (<bold>C, G</bold>) The coverage ratio of SF preference in each visual cortical area (light gray: V1; medium gray: V2; black: V4). (<bold>D, H</bold>) Mean ± SD for the preferred SF of all pixels across V1, V2, and V4. ***Kolmogorov–Smirnov test, p&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Two examples of spatial frequency (SF) preference maps obtained with different orientations (<bold>A–F</bold>: case 1; <bold>G–L</bold>: case 2).</title><p>(<bold>A–C, G–I</bold>) SF preference maps obtained by different orientations (<bold>A, H</bold>: 45° and 135°; <bold>B, H</bold>: 45°; <bold>C, I</bold>: 135°). The color bar represents the preferred SF from 0.25 (red) to 4.0 (cyan) cycles/deg. Scale bars here and for all subsequent figures are 1 mm. (<bold>D–F, J–L</bold>) Preferred SF distribution acquired by different orientations and areas. The orientation factor does not cause significant differences (two-way ANOVA, p&gt;0.05) in the results of the SF preference (SF = 0.25), (4), while the area factor causes significant differences (two-way ANOVA, <italic>P</italic>&lt;0.05). Two-way ANOVA test. case 1: area difference (V1, V2, V4), p=0.0029 (SF = 0.25 cycles/deg); p=0.0008 (SF = 4 cycles/deg); orientation difference (45 + 135°, 45°, 135°), p=0.057 (SF = 0.25 cycles/deg); p=0.063 (SF = 4 cycles/deg). Case 2: area difference (V1, V2, V4), p=0.040 (SF = 0.25 cycles/deg); p=0.00061 (SF = 4 cycles/deg); orientation difference (45 + 135°, 45°, 135°), p=0.27 (SF = 0.25 cycles/deg); p=0.12 (SF = 4 cycles/deg).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig3-figsupp1-v2.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Summary of the preferred spatial frequencies (SFs) in different visual areas.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Preferred SF (mean ± SD cycles/deg.)</th><th align="left" valign="bottom">V1</th><th align="left" valign="bottom">V2</th><th align="left" valign="bottom">V4</th></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>Case 1</bold></td><td align="left" valign="bottom">2.86 ± 1.40<break/>N = 147,207</td><td align="left" valign="bottom">2.03 ± 1.51<break/>N = 103,377</td><td align="left" valign="bottom">1.23 ± 1.32<break/>N = 490,921</td></tr><tr><td align="left" valign="bottom"><bold>Case 2</bold></td><td align="left" valign="bottom">2.96 ± 1.37<break/>N = 194,847</td><td align="left" valign="bottom">2.20 ± 1.52<break/>N = 186,288</td><td align="left" valign="bottom">1.15 ± 1.26<break/>N = 635,679</td></tr></tbody></table></table-wrap><p>To confirm that the use of just two orientations, 45° and 135°, detects a complete picture of SF preference in the imaged area, we compared the SF preference results acquired by different orientations (45° + 135°, 45°, 135°) (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) and did two-way ANOVA analysis (nine values went into the two-way ANOVA, including coverage ratios of high SF regions or low SF regions in V1, V2, and V4 acquired from different orientation comparisons, 45°, 135°, 45 + 135°). We found that, for different orientations, there were no significant differences (two-way ANOVA, p&gt;0.05) in the coverage ratios of high SF preference (SF = 4 cycles/deg) and low SF preference (SF = 0.25 cycles/deg) regions in the imaged area. In contrast, significant differences were found for different visual areas (two-way ANOVA, p&lt;0.05).</p></sec><sec id="s2-2"><title>Foveal to parafoveal shift of SF representation in V4</title><p>The large-scale imaging allowed us to capture highly structured maps of functional domains (e.g., orientation and color domains in <xref ref-type="fig" rid="fig4">Figure 4A and B</xref>, respectively) and reveal changes to those maps for different SF conditions. Below, we present our results on orientation maps and then color maps.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Comparison of the functional maps obtained at different spatial frequencies (SFs).</title><p>(<bold>A, B</bold>) Combined results generated by superimposing pixels in (<bold>D</bold>) and (<bold>E</bold>), respectively. Scale bar, 1 mm. (<bold>C</bold>) Selective activation centers of the activated orientation domains (blue dots) and color domains (orange dots) under different SF conditions. The dots are the geometric centroid of all corresponding activated regions in V4 (two-tailed <italic>t</italic>-test, p&lt;0.01). The values indicate the SF used. (<bold>D</bold>) V4 orientation maps and corresponding activated regions for different SFs. The gratings above the maps indicate the subtraction pair for the maps. Left panel: differential maps in response to 45° (black patches) versus 135° (white patches); right panel: stimulus-activated orientation-selective regions, only pixels that can distinguish 45° (black pixels) from 135° (white pixels) are included (two-tailed <italic>t</italic>-test, p&lt;0.01), numbers in the top-right corner indicate the coverage ratio of activated regions in the imaged V4. Red star: estimated foveal location. (<bold>E</bold>) Color maps and corresponding activated regions for different SFs, acquired from the same case in panel (<bold>A</bold>). Gratings above the maps indicate the subtraction pair for the maps. Left panel: differential maps in response to R/G gratings (corresponding to the black patches) versus W/B gratings (corresponding to the white patches). Right panel: activated color preference regions for the stimuli, only pixels showing significantly stronger responses to R/G gratings (black pixels) are included (two-tailed <italic>t</italic>-test, p&lt;0.01). (<bold>F, G</bold>) Activated area histograms along the M-L axis generated from (<bold>D</bold>) and (<bold>E</bold>), respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Orientation maps obtained by using drifting gratings with different spatial frequencies (SFs).</title><p>(<bold>A</bold>) Imaging results of cortical responses to gratings with different SFs (indicated on top in each column). Maps generated from response difference of 45° gratings minus 135° gratings (each row represents results from different cases). LS, lunate sulcus; STS, superior temporal sulcus. (<bold>B</bold>) Spatial distribution of the geometric center of activated orientation domains with different SFs. Under different SF conditions, the geometric centers of the activated orientation domains were calculated (two-tailed <italic>t</italic>-test, p&lt;0.01). Light gray: low SF, 0.25–0.5 cycles/deg; gray: medium SF, 1–2 cycles/deg; dark gray: high SF, 3–4 cycles/deg. V1 and V4 activation centers were labeled separately. L, lateral; A, anterior; LS, lunate sulcus; red star, estimated foveal location. Scale bar, 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Another example of V4 color map acquired with different spatial frequencies (SFs).</title><p>(<bold>A</bold>) Color maps and corresponding activated regions with different SFs. Top panel: differential maps in response to R/G gratings (corresponding to the black patches) versus W/B gratings (corresponding to the white patches); bottom panel: activated regions by the stimuli, only including color pixels (show significantly stronger responses to R/G gratings, two-tailed <italic>t</italic>-test, p&lt;0.01). (<bold>B</bold>) Combined results from (<bold>A</bold>). Pixels in (<bold>A</bold>) are superimposed. Numbers in the upper-right corner represent the coverage ratio of activated color domains in V4. Orange dots: centers of activated color domains corresponding to different SFs. Red star: estimated foveal location. Scale bar, 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>The matrices show the correlation values for pairs of maps acquired with different spatial frequencies (SFs).</title><p>Same case as in <xref ref-type="fig" rid="fig4">Figure 4</xref>. (<bold>A</bold>) Matrices of correlation values of orientation maps. (<bold>B</bold>) Matrices of correlation values of color maps. The imaged V4 regions were divided into two halves: the left half of the region was designated as lateral, the right half was designated as medial, and the correlation value for each half was calculated separately.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig4-figsupp3-v2.tif"/></fig></fig-group><p>In the imaging results shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref> (left panel), we acquired differential orientation maps using six different SFs. We found that the functional map at a specific SF is not always easily ascertained. Gratings with low SFs (e.g., 0.25 cycles/deg, 0.5 cycles/deg) evoked clear selective responses (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, thresholded, right panel) in all imaged V4 regions, whereas gratings with high SFs only evoked responses in certain regions, mostly in the lateral part of the cortex (toward foveal representation, red star).</p><p>To quantify this, for each tested SF, we analyzed the spatial distribution of the orientation-selective domains (see <xref ref-type="fig" rid="fig4">Figure 4D</xref> right panel, only pixels with significantly differential response to 45° vs. 135° were included). For each orientation map obtained at a given SF, we defined the ‘selective activation center’ as the geometric centroid of all significantly activated pixels (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, two-tailed <italic>t</italic>-test, p&lt;0.01). As SF increases, the location of the selective activation center shifts from medial to lateral across the cortex (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, blue dots). We confirmed that this remains true for each of the other cases (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, four cases from four hemispheres of three monkeys). Thus, the lack of response in the medial region to high SFs leads to a spatial medial-to-lateral shift of the selective activation center with increasing SF (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>).</p><p>We also examined color maps. Many previous V4 imaging studies employed grating stimuli to obtain color maps. However, most of these studies (<xref ref-type="bibr" rid="bib27">Li et al., 2014</xref>; <xref ref-type="bibr" rid="bib51">Tanigawa et al., 2010</xref>) have not addressed how SF affects color selective response. To test this, we recorded cortical responses to red/green isoluminance sinusoidal gratings with six different SFs and compared these responses with those to achromatic stimuli of the same SF (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). Color domains that showed significantly stronger responses (two-tailed <italic>t</italic>-test, p&lt;0.01, N = 30) to red/green stimuli were marked in black (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, right panel). Similar to orientation domains, under low SF conditions (&lt;1 cycle/deg), color domains were detected in the medial region of the cortex. At high SF, the color-selective response is no longer easily discernible in the medial region (SF = 3, 4 cycles/deg, <xref ref-type="fig" rid="fig4">Figure 4E</xref>, right panel). But in the lateral cortical region, color-selective response was detected regardless of SF. Thus, the activation center of color-selective response also shifted from medial to lateral with increasing SF (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, orange dots). In a second case, we obtained similar results (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref>) and found the activation center shifted laterally as SF increased (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>). We found that, when only a few SFs are tested, the coverage ratio of the orientation and color domains is underestimated (see white numbers in upper corners in <xref ref-type="fig" rid="fig4">Figure 4A, B, D and E</xref>), underscoring the importance of testing a wide range of SFs.</p><p>In addition to extracting the activation centers for different SFs in V4, we also examined the spatial distributions for each SF separately. We plotted the proportion of the activated pixels at different distances from lateral (distance = 0 mm) to medial under different SF conditions (see <xref ref-type="fig" rid="fig4">Figure 4F and G</xref>). As reported in previous V4 studies (<xref ref-type="bibr" rid="bib51">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib26">Li et al., 2013</xref>), orientation domains and color domains tend to separate in space, forming different functional bands. As shown in <xref ref-type="fig" rid="fig4">Figure 4F and G</xref>, at distances of 2, 6, 10, and 14 mm, the percentages of activated orientation regions decrease while the percentage of activated color regions increases. We found that for the lateral orientation and color bands (see the two bands &lt; 6 mm), the percentage values were higher for high SFs (blue/cyan lines vs. red/orange lines). In comparison, for the medial orientation and color bands (see the two bands &gt;6 mm), the percentage values were higher for low SFs (red/orange lines vs. blue/cyan lines).</p><p>We found surprisingly that the relative proportions of high to low SF preferences differ for color and orientation. As shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>, these proportions differ markedly in foveal vs. parafoveal locations. For each SF, we divided the number of activated pixels in the lateral and the medial parts (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) by the total number of the activated pixels preferring this SF (pixels selectively activated with a single SF). We found that the proportions of activated pixels in color and orientation domains in the lateral and medial parts of V4 change with SFs in distinct ways. In parafoveal cortex (medial), for both orientation and color domains, the proportion of pixels tends to decrease with increasing SF; in foveal cortex (lateral), for both orientation and color domains, the proportion of pixels increase as SF increases.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>The percentage of selectively activated domains change according to spatial frequency (SF).</title><p>(<bold>A</bold>) Demonstration of cortical blood vessel map and the visual areas chosen for analysis. See <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for details. Scale bar, 1 mm. (<bold>B, C</bold>) The proportions of activated functional domains in the lateral and medial parts of V4 (color: orange, from four experiments in three hemispheres; orientation: blue, from seven experiments in five hemispheres) change according to SFs. Points connected by a line represent results from the same experiment.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Cortical blood vessel maps of all cases and the corresponding chosen areas for activated percentage analysis in V4.</title><p>Orange area: the chosen lateral and medial parts of V4, as mentioned in <xref ref-type="fig" rid="fig5">Figure 5D and E</xref>. L: lateral area (foveal area); M: medial area (parafoveal area). LS: lunate sulcus; STS: superior temporal sulcus. (<bold>A–G</bold>) Chosen area for activated orientation domains from seven experiments in five hemispheres. (<bold>H–K</bold>) Chosen area for activated color domains from four experiments in three hemispheres. The scale bars in all panels are 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig5-figsupp1-v2.tif"/></fig></fig-group><p>The exposed areas of V1 are in the lateral region of the hemisphere, corresponding to the eccentricity of 0–2°; here low SFs barely evoke measurable selective orientation responses (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>, left column, cases 1–3). The orientation map in the lateral region is only apparent at high SFs (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>, &gt;1 cycle/deg). Although the optimal SF differs between V1 and V4, for both areas, the selective activation center moves from medial to lateral as SF increases (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, cases 1–4, dots of different shading correspond to the activation centers at different SFs). In monkey visual cortex, the foveal regions of V1, V2, and V4 are located in the lateral part of the cortex (<xref ref-type="bibr" rid="bib15">Gattass et al., 1981</xref>; <xref ref-type="bibr" rid="bib16">Gattass et al., 1988</xref> see <xref ref-type="fig" rid="fig2">Figure 2D</xref>), in agreement with the findings from electrophysiology studies that foveal regions favor high SF (<xref ref-type="bibr" rid="bib38">Perry and Cowey, 1985</xref>; <xref ref-type="bibr" rid="bib44">Schein, 1988</xref>; <xref ref-type="bibr" rid="bib58">Wässle et al., 1989</xref>; <xref ref-type="bibr" rid="bib59">Wilder et al., 1996</xref>).</p><p>To further confirm the spatial relationship of functional maps acquired at different SFs, we calculated the cross-correlation values of these functional maps acquired at different SF conditions. Each response map was divided into two halves: foveal region, the left half close to V4 foveal region; and parafoveal region, the right half away from foveal region. The correlation values of the two halves were calculated separately (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3A and B</xref>, left matrix: foveal region; right matrix: parafoveal region). For orientation maps (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3A</xref>), high correlation values (&gt;0.5) appeared in the comparisons among high SF conditions in foveal region. In contrast, high correlation values appeared in the comparisons among low SF conditions in parafoveal region. For color functional maps (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3B</xref>), higher correlation values were measured under low SF conditions in both foveal and parafoveal regions, while high correlation values appeared only in the foveal region under high SF conditions.</p><p>These differences reflect distinct capabilities of different cortical regions (fovea vs. parafovea). Independent of the type of visual information presented (orientation or color), parafoveal regions tend to process the visual input containing relatively low SF components, while visual input containing high SF components is better processed in foveal regions. In V4, the foveal region is capable of processing visual information with a broad range of SF sensitivity.</p></sec><sec id="s2-3"><title>Relationship between SF and orientation maps in V4 and V2</title><p>Having obtained orientation and SF preference maps from the same cortical region, it becomes possible to analyze the spatial relationships between these maps. To identify the regions which are highly selective for orientation, for each pixel, we calculated normalized orientation values (from 0 untuned to 1 highly tuned) and set a threshold of 0.5 or larger (see orientation selectivity maps in <xref ref-type="fig" rid="fig6">Figure 6B</xref> and <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2B</xref>; and the selectivity thresholded orientation preference map in <xref ref-type="fig" rid="fig6">Figure 6C</xref>). We determined the iso-orientation and iso-SF contours based on the smoothed orientation preference map (see <xref ref-type="fig" rid="fig6">Figure 6A</xref>) and SF preference map (see example in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, 18 iso-orientation gradient contours and 5 iso-SF gradient contours). In V2 and V4, the iso-orientation and iso-SF contours that intersected at large angles were found most frequently (see <xref ref-type="fig" rid="fig6">Figure 6G, K and O</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2G and K</xref>). To demonstrate that the intersection angles are more frequently detected at a large angle, we divided the detected intersection angles into three groups (small: 0–30°; medium: 30–60°; large: 60–90°) and compared the percentage difference among these groups. The results indicate that there are more (percentage value) 60–90° intersection angles than other kinds of intersection angles in the orientation-selective regions (see white patches in <xref ref-type="fig" rid="fig6">Figure 6F, J and N</xref>). The percentage of the large angle group is significantly higher than the small (Wilcoxon rank-sum test, p=1.60 × 10<sup>–5</sup>, n = 15 from five regions, two V2 regions, and three V4 regions) and medium groups (Wilcoxon rank-sum test, p=1.73 × 10<sup>–4</sup>). In addition, we compare the distribution between groups with strong orientation selectivity (e.g., <xref ref-type="fig" rid="fig6">Figure 6D–O</xref>) and weak orientation selectivity (see <xref ref-type="fig" rid="fig6">Figure 6P–U</xref>). The percentage difference in large intersection angle (60–90°) is also significant (strong orientation selectivity group, n = 15 from five regions, two V2 regions, and three V4 regions; weak orientation selectivity group, labeled as '60–90° Ref.' in <xref ref-type="fig" rid="fig6">Figure 6V</xref>, n = 6 from two V4 regions; Wilcoxon rank-sum test, p=0.0057, see <xref ref-type="fig" rid="fig6">Figure 6V</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Relationship between spatial frequency (SF) and orientation maps in V4 and V2.</title><p>(<bold>A</bold>) Orientation preference map. Different colors represent different orientation preferences. (<bold>B</bold>) Orientation selectivity map. The gray scale represents the normalized orientation selectivity (0: no orientation selectivity; 1: strong specific selectivity to one single orientation). (<bold>C</bold>) Selectivity thresholded orientation preference map (combined result from <bold>A</bold> and <bold>B</bold>). Cyan boxes indicate the chosen regions for intersection angle distribution analysis: one V2 region (<bold>D–G</bold>), two V4 regions (region 1: <bold>H–K</bold>; region 2: <bold>L–O</bold>), and two V4 reference regions with weak orientation selectivity (dotted box, V4 Ref1: <bold>P–R</bold>; V4 Ref2: <bold>S–U</bold>). (<bold>D, H, L, Q, T</bold>) Iso-orientation (red lines) and Iso-SF gradient contours (blue lines). (<bold>E, I, M, P, S</bold>) Selectivity thresholded orientation preference maps corresponding to (<bold>D, H, L, Q, T</bold>). (<bold>F, J, N</bold>) Regions (white parts) with high orientation selectivity (normalized orientation selectivity &gt; 0.5) selected for calculating the intersection angle. (<bold>G, K, O, R, U</bold>) Distributions of intersection angles of the selected regions. The dashed lines indicate the expected value (11.1%) if angles are distributed randomly. (<bold>V</bold>) Percentage comparison (Wilcoxon rank-sum test) among different angle groups (0–30°, 30–60°, and 60–90° of strong orientation-selective regions, n=15, and 60–90° of weak orientation-selective regions: 60–90° [“Ref.”], n=6). Error bar: SD. Scale bars: 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Demonstration of intersections of iso-contour lines for orientation and spatial frequency (SF) maps.</title><p>Data from the same case shown in <xref ref-type="fig" rid="fig6">Figure 6</xref>, V4 part 1. (<bold>A</bold>) Iso-orientation gradient lines and orientation preference map. The values indicate the different iso-orientation gradient contours (5°, 15°, 25°, 35°, 45°, 55°, 65°, 75°, 85°, 95°, 105°, 115°, 125°, 135°, 145°, 155°, 165°, 175°). (<bold>B</bold>) Iso-SF gradient lines (0.25, 0.5, 1, 2, 3 cycles/deg) and SF preference map. (<bold>C</bold>) Iso-orientation (red lines) and iso-SF gradient contours (blue lines). Scale bar, 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>The second case of the relationship between spatial frequency (SF) and orientation maps in V4 and V2.</title><p>(<bold>A</bold>) Orientation preference maps. (<bold>B</bold>) Orientation selectivity map. The gray scale represents the normalized orientation selectivity. (<bold>C</bold>) Orientation preference-selective map. The white region in (<bold>A</bold>) and (<bold>C</bold>), and the orange region in (<bold>B</bold>): blood vessels in the cortical surface. One V2 region (<bold>D–G</bold>) and one V4 region (<bold>H–K</bold>) were chosen for intersection angle distribution analysis. (<bold>D, H</bold>) Iso-orientation (red lines) and iso-SF gradient contours (blue lines). (<bold>E, I</bold>) Enlarged view of orientation preference-selective map in (<bold>C</bold>) corresponding to (<bold>D, H</bold>). (<bold>F, J</bold>) Regions (white regions) with high orientation selectivity (normalized orientation selectivity &gt; 0.5) for calculating the intersection angle. (<bold>G, K</bold>) Distributions of intersection angles of the selected regions. Dashed lines indicate the expected value (11.1%) if angles are distributed randomly. Scale bars, 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig6-figsupp2-v2.tif"/></fig></fig-group></sec><sec id="s2-4"><title>SF bias in V4 color domains</title><p>Since the first report on V4 SF preference domains (<xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>), the relationship between V4 SF domains and V4 color domains remains unclear. It should be noted that SF preference <italic>domains</italic> (i.e., preference for low vs. high, <xref ref-type="fig" rid="fig7">Figure 7B and C</xref>) are distinct from SF preference <italic>maps</italic> (i.e., six-value SF maps, <xref ref-type="fig" rid="fig3">Figure 3B and F</xref>), as the domains are determined by statistical analysis (two-tailed <italic>t</italic>-test, p&lt;0.01) and effectively distinguish high SF from low SF. Here, by comparing cortical responses recorded using high SF stimuli at two orientations: 45°, 135°, and low SF stimuli (at the same two orientations), we generated differential SF maps (see <xref ref-type="fig" rid="fig7">Figure 7A</xref>). A distinct segregation of light and dark regions is visible in this functional map. The black patches are the regions that prefer high SF to low SF, while the white patches have the opposite preference.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Relationship between spatial frequency (SF) and color-selective domains.</title><p>(<bold>A–D</bold>) Relationship in V4 that high SF domains tend to avoid color domains. (<bold>A</bold>) Same case as in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. Differential SF map in V4 is produced by subtracting the average image of two oriented grating stimuli at a low SF (0.5 cycles/deg) from the corresponding average image at a high SF (3 cycles/deg). The dark patches correspond to regions that prefer higher SF, while the white patches prefer lower SF. (<bold>B, C</bold>) Overlay of color domains (orange) and SF domains (gray). (<bold>B</bold>) Low SF domains; (<bold>C</bold>) high SF domains. Scale bar, 1 mm. (<bold>D</bold>) The percentage of HSF/LSF (high spatial frequency/low spatial frequency) selectivity regions within color domains was calculated. Unfilled squares represent the results from each case (four cases). Filled squares are the averaged outcomes from the four cases. The mean value is shown on top of the corresponding group. For the other three cases, see <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>. (<bold>E–M</bold>) Relationship in V2 that stripe-like distribution of SF preference changes periodically. Data from the same case shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>, case 1. (<bold>E</bold>) Color map. Regions 1 (orange rectangle) and 2 (cyan rectangle) were selected for further analysis in (<bold>G–L</bold>). In V2, the yellow dashed outlines highlight the color domains. The border between V1 and V2 is indicated by a black dashed line. Scale bar, 1 mm. (<bold>F</bold>) Differential SF maps produced by subtracting the average image of two oriented grating stimuli at a low SF (0.5 cycles/deg) from the corresponding average image at a high SF (3 cycles/deg). Red dashed outlines: color domains same with those in (<bold>E</bold>). (<bold>G, H</bold>) Enlarged color maps from regions 1 and 2. (<bold>I, J</bold>) Enlarged SF maps from regions 1 and 2. (<bold>K, L</bold>) Changes of color-selective response (black lines) and SF preference (red lines) along the path parallel to V1/V2 border in V2. (<bold>M</bold>) Similar to color selective responses in V2, SF preference changes along V1/V2 border.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Relationships between V4 spatial frequency (SF) and color-selective domains in three cases.</title><p>SF domains (marked by gray) were the areas with a significant response difference (two-tailed <italic>t</italic>-test, p&lt;0.01) between low SF conditions (0.25–0.5 cycles/deg, 45° and 135°, left panel) and high SF conditions (3–6 cycles/deg, 45° and 135°, right panel). Color domains (marked by orange) were superimposed over results based on activated regions (in gray) under different SF conditions. Each row of subplots represents results from different cases. Scale bar: 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig7-figsupp1-v2.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Differential spatial frequency (SF) maps acquired by subtractions between different SF pairs (same case as <xref ref-type="fig" rid="fig7">Figure 7</xref>).</title><p>(<bold>A–C</bold>) Differential SF maps produced by subtracting the average image of two oriented grating stimuli at a low SF (<bold>A, B</bold>: 0.5 cycles/deg; <bold>C</bold>: 0.25 cycles/deg) from the corresponding average image at a higher SF (<bold>A</bold>: 3 cycles/deg; <bold>B</bold>: 1.5 cycles/deg; <bold>C</bold>: 1 cycle/deg). Red star: estimated foveal location. The arrows indicate the high SF preference regions in V2. Scale bar: 1 mm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-fig7-figsupp2-v2.tif"/></fig></fig-group><p>We compared the spatial relationship of color domains with SF domains (<xref ref-type="fig" rid="fig7">Figure 7A–D</xref>). <xref ref-type="fig" rid="fig7">Figure 7B</xref> shows the low SF preference domains color coded in gray relative to the color domains (orange patches). Similarly, high SF preference domains are color coded in gray relative to the same domains in <xref ref-type="fig" rid="fig7">Figure 7C</xref>. In this case, low SF preference domains tend to co-localize with V4 color domains to a greater extent than high SF preference domains (21.3% vs 8.3% of all pixels in color domains).</p><p>Additional examples are shown in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> (three cases from three different hemispheres). In these four cases, we found that the total amount of cortex able to discriminate high SF vs. low SF (high SF plus low SF pixels) is only a small portion of the total V4 area (coverage ratio of high SF preference domains in V4: 3.9% ± 1.5%, mean ± SD; coverage ratio of low SF preference domains in V4: 6.0% ± 3.7%, mean ± SD.; coverage ratio: the area of SF domains divided by the imaged area of V4). Although the difference is not statistically significant (four cases, Wilcoxon test, p&gt;0.05), in all cases, we found a great tendency for low SF domains to overlap with color domains (the percentage of high SF preference regions in color domains: 3.9% ± 3.3%; the percentage of low SF preference regions in color domains: 13.3% ± 8.4%, <xref ref-type="fig" rid="fig7">Figure 7D</xref>).</p></sec><sec id="s2-5"><title>Change of SF preference in V2</title><p>Previous studies in V2 have shown that relying on SF to distinguish different types of stripes (thin, pale, thick) is difficult (<xref ref-type="bibr" rid="bib25">Levitt et al., 1994</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>; <xref ref-type="bibr" rid="bib55">Tootell and Hamilton, 1989</xref>). However, one study did report a stripe specific SF selectivity (<xref ref-type="bibr" rid="bib31">Lu and Roe, 2007</xref>). We hypothesize that this controversy is due to the inability of cytochrome oxidase staining to reliably identify stripe type, which functional imaging can securely address. To further explore this, we first examined whether there were measurable SF preference differences in V2. As indicated in the map, the SF preference changed across V2 (same as V2 in <xref ref-type="fig" rid="fig3">Figure 3B</xref>, the region between lunate sulcus and V1/V2 border indicated by red arrow). We adopted the same method as Lu (<xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>) to obtain a differential SF map (<xref ref-type="fig" rid="fig7">Figure 7F</xref>). The low SF preference regions obtained using these two methods (white patches, in the differential SF map, see <xref ref-type="fig" rid="fig7">Figure 7F</xref>; red/orange regions, in the colored SF preference map, see <xref ref-type="fig" rid="fig7">Figure 7I and J</xref>) are well correlated with color preference domains (red dashed circles in <xref ref-type="fig" rid="fig7">Figure 7F</xref> and black patches in <xref ref-type="fig" rid="fig7">Figure 7G and H</xref>). In addition, we acquired differential SF maps by subtractions between different SF pairs (see <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). For subtraction between high SF (&gt;1 cycle/deg) and low SF (0.5 cycles/deg) conditions, high SF preference domains can be detected in the foveal region (red star, see black patches indicated by red arrows in <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2A and B</xref>). However, for the subtraction between medium SF (1 cycle/deg) and low SF (0.25 cycles/deg) conditions, the relatively high SF preference domains can only be detected in the parafoveal region (see black patches indicated by blue arrows in <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2C</xref>). These results indicate from parafoveal to foveal region, the preferred SF tends to increase gradually.</p><p>To provide an additional illustration of how SF preference varies along V2, we selected V2 regions that exhibited two separated color domains (<xref ref-type="fig" rid="fig7">Figure 7E</xref>, regions 1 and 2) and compared the changes of SF preference against color selectivity along the V2 long axis (parallel to the black arrows in <xref ref-type="fig" rid="fig7">Figure 7G and H</xref>). Both SF preference (red lines) and color selectivity (black lines) vary along the V1/V2 border (<xref ref-type="fig" rid="fig7">Figure 7G–L</xref>). Color selectivity was found in or near low SF preference regions (see also <xref ref-type="fig" rid="fig7">Figure 7F</xref>, red dashed circles and white patches in V2); however, not all low SF preference regions exhibited strong color selectivity. Thus, SF preference differences vary uniquely within V2 (see <xref ref-type="fig" rid="fig7">Figure 7M</xref>). The differences in SF preference between the regions on the two sides of a thin stripe (see <xref ref-type="fig" rid="fig7">Figure 7K and L</xref>, thin stripe location: around the peaks of the black lines) may correlate to the reported two types (medial vs. lateral) of pale stripes in V2 (<xref ref-type="bibr" rid="bib12">Felleman et al., 2015</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Using optical imaging of intrinsic signals in a large area of visual cortex, we were able to simultaneously characterize the functional architecture underlying color, orientation, and SF domains in areas V2 and V4. We found (1) <italic>Topography</italic>: With respect to topography, the SF population response of V4 orientation and color domains shift systematically with topographic location. To be specific, the geometric centroids of the selective response shift toward foveolar (lateral) parts of the cortex as SF increases. This finding quantifies, at a population level, the gradation of SF preference across the visual field. Interestingly, distinct from V1 fovea, which was selectively responsive to orientations of higher SFs (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>), the foveal region of V4 was responsive to a broad range of SF from high to low, suggesting greater SF integration at higher cortical levels, even in foveal regions. (2) <italic>Orthogonal primary axes</italic>: Within V4 and V2, similar to what was previously shown in V1, the gradients of orientation and SF maps tend to be orthogonal to one another. (3) Low <italic>SF bias in V4 and V2 color domains</italic>: We find there is a tendency for low SF preference domains to overlap with color domains in V4 and V2.</p><sec id="s3-1"><title>General organization rules of cortical space</title><p>As mentioned in many previous studies, orthogonal crossings between different cortical maps facilitate the maximum combination of response properties in a local area with columnar organization. This kind of spatial relationship has now been reported in different animals (cat, monkey) and between different functional maps including orientation vs. ocular dominance, orientation vs. SF in cat area 17 (<xref ref-type="bibr" rid="bib21">Hübener et al., 1997</xref>); orientation vs. ocular dominance, orientation vs. SF in monkey V1 (<xref ref-type="bibr" rid="bib2">Bartfeld and Grinvald, 1992</xref>; <xref ref-type="bibr" rid="bib35">Nauhaus et al., 2012</xref>; <xref ref-type="bibr" rid="bib37">Obermayer and Blasdel, 1993</xref>); hue vs. lightness in macaque V1 (<xref ref-type="bibr" rid="bib28">Li et al., 2022</xref>); orientation vs. disparity in macaque V2 (<xref ref-type="bibr" rid="bib5">Chen et al., 2008</xref>; <xref ref-type="bibr" rid="bib56">Ts’o et al., 2009</xref>) and, in this study, orientation vs. SF in macaque V2 and V4. These examples suggest that to effectively use cortical space, this orthogonality is established by key visual attributes.</p><p>We suggest that this orthogonality may be a common principle and reveals key parameters specific to each cortical area. Thus, for object structure, orientation and SF are two key parameters; for color, the key parameters are hue and luminance (<xref ref-type="bibr" rid="bib28">Li et al., 2022</xref>). These combinations ensure a complete representation of basic shape and surface information at each cortical level. Thus, cortical mosaics contain distinct regions of orthogonal feature parameters, as observed in the color and orientation stripes of V2 and the color and orientation bands of V4, and may present for other parameters (e.g., face space, object space) in higher cortical areas.</p></sec><sec id="s3-2"><title>Population-selective responses across the cortex</title><p>The ISOI method enables us to study the population-selective responses across a large area of the visual cortex. Consistent with previous findings (<xref ref-type="bibr" rid="bib9">Desimone and Schein, 1987</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>), our results indicate that the majority of V4 regions favor low SF relative to V1 (<xref ref-type="fig" rid="fig3">Figure 3</xref>). For both V4 orientation- and color-selective response, there is a tendency for representation to shift to higher SFs from parafovea to fovea (<xref ref-type="fig" rid="fig4">Figure 4</xref> with three supplements, and <xref ref-type="fig" rid="fig5">Figure 5</xref> with one supplement), supporting the inverse relationship between SF preference and retinal eccentricity (<xref ref-type="bibr" rid="bib9">Desimone and Schein, 1987</xref>; <xref ref-type="bibr" rid="bib33">Lu et al., 2018</xref>). However, it should be noted that in foveal V4 region, even at low SF, robust orientation- and color-selective responses are detected. This points to an important difference between V1 and V4. That is, foveal representation in V4 may be better organized for processing complex images (e.g., natural scenes) with multiple SF components.</p></sec><sec id="s3-3"><title>SF preference organization in V2</title><p>We explored whether SF is spatially organized relative to the stripes in V2. We found that similar to color-selective response, SF preference changes within the exposed V2 area, forming different SF preference patches, which supports a general functional layout for SF coding in the visual system (preference for low SF in V1 blob, V2/V4 low SF domains; preference for high SF in V1 interblob, V2/V4 high SF domains). Based on the resolution of ISOI, we cannot achieve cellular level resolution. We cannot do further analysis in regions containing neurons with complex selectivity (e.g., orientation pinwheel). These tiny structures are best studied with other methods (e.g., two-photon imaging). More evidence and new techniques (e.g., ultra-high-field 7T fMRI) could also be introduced to test whether the SF preference in the entire V2 changes periodically as other features (e.g., color, orientation, direction, disparity).</p><p>Why does SF preference in V2 change in this way? As suggested by modeling V2 retinotopic maps of tree shrews (<xref ref-type="bibr" rid="bib45">Sedigh-Sarvestani et al., 2021</xref>), in elongated cortical areas such as V2 there tend to be periodic changes in response features across the cortical surface. Another putative functional implication of this periodic distribution is to aid in the integration across features spaces (wiring minimization) via horizontal connections in V2 (<xref ref-type="bibr" rid="bib7">Chklovskii et al., 2002</xref>; <xref ref-type="bibr" rid="bib8">Cowey, 1979</xref>; <xref ref-type="bibr" rid="bib20">Hubel and Wiesel, 1977</xref>; <xref ref-type="bibr" rid="bib34">Mitchison, 1991</xref>; <xref ref-type="bibr" rid="bib24">Koulakov and Chklovskii, 2001</xref>).</p></sec><sec id="s3-4"><title>Thoughts about the hypercolumn</title><p>Based on the above findings, we suggest a nested hierarchy of organizations (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). At the scale of visual field representation, there is a broad and downward shifting range of SFs from center to periphery. Within this global SF map lie hypercolumns of repeated orientation and color representation, each of which contains two orthogonally arranged primary parameters. In the ‘orientation’ regions, SF is systematically and orthogonally mapped in relation to the orientation map (this study); in the ‘color’ regions, hue and lightness are orthogonally mapped (<xref ref-type="bibr" rid="bib28">Li et al., 2022</xref>). Analogous to how the primary parameter spaces mapped in each cortical area change from one area to another (e.g., V1: ocular dominance, orientation, color; V2: higher-order orientation, hue, disparity; V4: curvature, 3D shape from shading, hue and lightness, <xref ref-type="bibr" rid="bib19">Hu et al., 2020</xref>; <xref ref-type="bibr" rid="bib48">Srinath et al., 2021</xref>; face areas: face maps, <xref ref-type="bibr" rid="bib23">Kanwisher et al., 1997</xref>, <xref ref-type="bibr" rid="bib4">Chang and Tsao, 2017</xref>; object areas: object maps, <xref ref-type="bibr" rid="bib1">Bao et al., 2020</xref>), we hypothesize that subregions of a cortical hypercolumn also organize for different parameters. Thus, while SF is an important primary axis in orientation regions, in color regions which by nature are associated with low SFs, the rationale for a systematic SF map is weakened. One could view the color regions as evolutionary ‘add-ons,’ which became tacked on to the low end of the SF continuum. It should be noted that the functional maps or regions (e.g., orientation, color) in V2 and V4 are not simple repeats of the functional representation in V1, although here they have the same name (orientation, color). These maps or regions are dedicated to processing different visual information in different visual areas. We suggest the architecture of SF representation, which describes distinct SF representations within orientation and color regions, further extends and supports the view of continued parallel streaming of feature-specific pathways.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Data was acquired from five hemispheres of three adult macaque monkeys (one male and two female, <italic>Macaca mulatta</italic>). All procedures were performed in accordance with the National Institutes of Health Guidelines and were approved by the Zhejiang University Institutional Animal Care and Use Committee (approval no. ZJU20200022 and ZJU20200023).</p><sec id="s4-1"><title>Animal preparation</title><p>Chronic optical windows were implanted in contact with the cortex above areas V1, V2, and V4, containing lunate sulcus and superior temporal sulcus as described previously (<xref ref-type="bibr" rid="bib19">Hu et al., 2020</xref>, also see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). The eccentricity of the visual field corresponding to exposed V4 was 0–5° and for V1/V2 was 0–2°. Following the craniotomy surgery, optical images were acquired in order to generate basic functional maps. Monkeys were artificially ventilated and anesthetized with propofol (induction 5–10 mg/kg, maintenance 5–10 mg/kg/hr, i.v.) and isoflurane (0.2–1.5%). Anesthetic depth was assessed continuously by monitoring heart rate, end-tidal CO<sub>2</sub>, blood oximetry, and EEG. Rectal temperature was maintained at 38°C. Animals were paralyzed (vecuronium bromide, induction 0.25 mg/kg, maintenance 0.05–0.1 mg/kg/hr, i.v.) and respirated. Pupils were dilated (atropine sulfate 1%) and eyes fitted with contact lenses of appropriate curvature to focus on a stimulus screen 57 cm from the eyes.</p></sec><sec id="s4-2"><title>Visual stimuli for optical imaging</title><p>Visual stimuli were created using ViSaGe (Cambridge Research Systems Ltd.) and displayed on a calibrated 27-inch monitor (Philips 272G5D) operating at 60 Hz refresh rate. The luminance for white stimuli was 206.52 cd/m<sup>2</sup> and black was 0.50 cd/m<sup>2</sup>. Full-screen visual grating stimuli were used to locate different functional domains. To acquire color maps (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, <xref ref-type="fig" rid="fig7">Figure 7B, C and E</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>), red/green isoluminance (red: CIExyY, 0.662, 0.328, 40; green: CIExyY, 0.320, 0.613, 40) and black-white sine-wave drifting grating stimuli, as shown in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, were presented at two different orientations (e.g., 45° and 135°) with various SFs. To acquire orientation maps (differential orientation maps: <xref ref-type="fig" rid="fig4">Figure 4D</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>; orientation preference maps: <xref ref-type="fig" rid="fig6">Figure 6A</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2A</xref>; orientation selectivity map: <xref ref-type="fig" rid="fig6">Figure 6B</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2B</xref>; selectivity thresholded orientation preference map: <xref ref-type="fig" rid="fig6">Figure 6C</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2C</xref>) and SF maps (differential SF maps: <xref ref-type="fig" rid="fig7">Figure 7A and F</xref>, <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>; SF preference maps: <xref ref-type="fig" rid="fig3">Figure 3B and F</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A–C, G–I</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref>, <xref ref-type="fig" rid="fig7">Figure 7I and J</xref>), gratings with different orientations (0°, 45°, 90°, 135°) and different SFs (0.25, 0.5, 1, 1.5, 3, 4 cycles/deg) were presented. The temporal frequency of the gratings was fixed to 4 Hz, and the corresponding drifting speeds of these SF conditions (0.25, 0.5, 1, 1.5, 3, 4 cycle/deg) are 16, 8, 4, 2.7, 1.3, 1 deg/s. The different directions of motion were randomly interleaved.</p></sec><sec id="s4-3"><title>Optical imaging</title><p>The brain was imaged through a glass window mounted in contact with cortex. Images of cortical reflectance changes (intrinsic hemodynamic signals) corresponding to local cortical activity were acquired (Imager 3001, Optical Imaging Inc, German Town, NY) with 630 nm illumination. Image size was 1080 × 1308 pixels representing 14.4 × 17.4 or 8.7 × 10.5 mm field of view. Visual stimuli were presented in a random order. Each stimulus was presented for 3.5–4.5 s. Frames were acquired at 4 Hz for 4–5 s synchronized to respiration. Visual stimuli were presented 0.5 s after beginning image acquisition. The imaging data were stored in a block fashion. Each block contained the imaging data recorded from the stimulus conditions (presented one time). Each stimulus was presented at least 25 times.</p></sec><sec id="s4-4"><title>Data analysis</title><sec id="s4-4-1"><title>Generation of functional maps</title><p>With the following formula,<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mtext>R</mml:mtext><mml:mrow><mml:mtext>i</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mtext>1</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mtext>2</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we assessed the response differences between two comparison groups. <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mtext>1</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mtext>2</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are the mean dR/R values (<inline-formula><mml:math id="inf4"><mml:semantics><mml:mrow><mml:mi>d</mml:mi><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>9</mml:mtext><mml:mo>−</mml:mo><mml:mtext>end</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></inline-formula>, R<sub>9-end</sub> is the averaged response from frames 9 to the last frame, R<sub>1-3</sub> is the averaged response from frames 1–3) in the two compared conditions for pixel i, N is the number of trials, and Si is the standard deviation of <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Single condition maps were obtained by comparing the images acquired during stimulus and during a blank.</p><p>Color maps were obtained by comparing red/green and white/black grating images, differential SF maps were obtained by comparing high (2–6 cycles/deg) and low (0.25–0.5 cycles/deg) SF images, and differential orientation maps were obtained by comparing two orthogonal orientation images (45° vs. 135°). Maps were low-pass filtered (Gaussian filter, ~30–80 μm diameter) and low-frequency noise was reduced by convolving a given map with a~1–2 mm diameter Gaussian filter and subtracting from the original map. Within a single experimental session, the same filtering parameters were always used to ensure that this filtering procedure did not influence the observed differences. The border between V1 and V2 was determined based on color map: in V1 color response has a blob-like distribution, whereas in V2 color response has a stripe-like distribution.</p><p>To generate SF preference maps (e.g., in <xref ref-type="fig" rid="fig3">Figure 3B and F</xref>), for each pixel we compared its activation under different single SF conditions. The preferred SF of each pixel was defined as the SF at which the strongest activation signal (amplitude averaged from frame 10 to frame 20 in each condition) for that pixel was observed. The comparison includes two orientations (45° and 135°); for each orientation, six different SFs, 0.25, 0.5, 1, 1.5, 3, and 4 cycles/deg, were presented. Each pixel in a given SF preference map was assigned a unique color to represent the preferred SF. Orientation preference maps (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2A</xref>) were calculated based on single orientation condition maps (four orientations, 0°, 45°, 90°, 135°), and each pixel was assigned a unique color to represent the preferred orientation (<xref ref-type="bibr" rid="bib3">Bosking et al., 1997</xref>).</p></sec><sec id="s4-4-2"><title>Locating the positions of selective activation and determining the activation center</title><p>Functional domains were identified by selecting the pixels with a significant difference in dR/R (two-tailed <italic>t</italic>-test, p&lt;0.01) under two comparison conditions (see <xref ref-type="table" rid="table2">Table 2</xref>).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Comparisons used to generate different functional domains.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Comparison</th><th align="left" valign="bottom">Domain type</th><th align="left" valign="bottom">ΔdR/R criteria</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="2">RG vs. WB</td><td align="left" valign="bottom">Color</td><td align="char" char="." valign="bottom">&lt;0</td></tr><tr><td align="left" valign="bottom">Luminance</td><td align="char" char="." valign="bottom">&gt;0</td></tr><tr><td align="left" valign="bottom" rowspan="2">0° vs. 90°</td><td align="left" valign="bottom">0°</td><td align="char" char="." valign="bottom">&lt;0</td></tr><tr><td align="left" valign="bottom">90°</td><td align="char" char="." valign="bottom">&gt;0</td></tr><tr><td align="left" valign="bottom" rowspan="2">45° vs. 135°</td><td align="left" valign="bottom">45°</td><td align="char" char="." valign="bottom">&lt;0</td></tr><tr><td align="left" valign="bottom">135°</td><td align="char" char="." valign="bottom">&gt;0</td></tr><tr><td align="left" valign="bottom" rowspan="2">High SF (≥2 cycles/deg) vs. low SF (&lt;1.5 cycles/deg)</td><td align="left" valign="bottom">High SF</td><td align="char" char="." valign="bottom">&lt;0</td></tr><tr><td align="left" valign="bottom">Low SF</td><td align="char" char="." valign="bottom">&gt;0</td></tr></tbody></table><table-wrap-foot><fn><p>SF: spatial frequency.</p></fn></table-wrap-foot></table-wrap><p>For a given activated region, the activation center was defined as the geometric centroid of all significantly activated pixels within the region; for example, the orientation-selective activation center in <xref ref-type="fig" rid="fig4">Figure 4D</xref> is the centroid of all the pixels of 45° and 135° orientation domains under one SF condition and the color activation center in <xref ref-type="fig" rid="fig4">Figure 4E</xref> is the centroid of all the pixels of color domains under one SF condition. The overlap between different functional domains was also calculated based on these thus-defined functional domains (see <xref ref-type="fig" rid="fig7">Figure 7B–D</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>).</p></sec><sec id="s4-4-3"><title>Calculating the correlation of pairs of maps</title><p>To quantify the correlation between two functional maps, we isolated the significant responses in the imaged area of V4 (regions that were significantly activated by the visual stimuli, two-tailed <italic>t</italic>-test, p&lt;0.01) and calculated the cross-correlation values between the maps (<xref ref-type="fig" rid="fig4">Figure 4D and E</xref>, right panels) acquired under different SF conditions. To compare the difference between foveal and parafoveal regions, we divided the imaged V4 regions into two halves: the left half of the region was designated as foveal, the right half was designated as parafoveal, and the correlation value for each half was calculated separately.</p></sec><sec id="s4-4-4"><title>Comparing the spatial relationship between SF and orientation maps</title><p>Iso-orientation contours (18 contours, 5°, 15°, 25°, 35°, 45°, 55°, 65°, 75°, 85°, 95°, 105°, 115°, 125°, 135°, 145°, 155°, 165°, and 175°) and iso-SF contours (five contours, 0.25, 0.5, 1, 2, and 3 cycles/deg) were drawn based on these smoothed maps using the MATLAB ‘contour’ function. We quantified the orientation selectivity of each pixel by calculating the vector sum of the responses to the four tested orientations (0°, 45°, 90°, and 135°). The length of each vector was normalized to a range of 0–1 by dividing the largest vector length. We calculated the difference between the two gradients at each intersection within the strong orientation-selective regions (normalized orientation selectivity &gt; 0.5, e.g., <xref ref-type="fig" rid="fig6">Figure 6</xref>, V2 and V4 parts) or weak orientation-selective regions (normalized orientation selectivity &lt; 0.5, e.g., <xref ref-type="fig" rid="fig6">Figure 6</xref>, V4 refs) to determine the spatial relationship between SF and orientation maps.</p></sec><sec id="s4-4-5"><title>Characterizing the layout of SF preference in V2</title><p>As reported in previous studies, V2 color-selective response changes periodically along the long axis of V2 (<xref ref-type="bibr" rid="bib25">Levitt et al., 1994</xref>; <xref ref-type="bibr" rid="bib41">Roe and Ts’o, 1995</xref>). To characterize the periodic change of SF preference in V2, we chose a region of V2 with clearly identifiable periodic changes in color response (at least two well-separated color domains) for further analysis. We slightly rotated the selected V2 region to align the V1/V2 border horizontally in the cropped small map (see <xref ref-type="fig" rid="fig7">Figure 7G and H</xref>). For each of these small maps, we quantified and normalized color selectivity and SF preference for all pixels in the map. The average value for the pixels along each vertical line at different distances from left (distance = 0 mm) to right (distance = 4.5 mm) was then computed and plotted.</p></sec><sec id="s4-4-6"><title>Calculating the coverage ratio of selective activation</title><p>We first determined the activated orientation and color domains to calculate the proportion of activated regions in a given area. The coverage ratio (e.g., the values at the corners in <xref ref-type="fig" rid="fig4">Figure 4D and E</xref>) was calculated by dividing the number of the selectively activated pixels recorded at each SF by the total number of pixels in the given area. To evaluate the weights of the activated pixels at different distances from lateral (distance = 0 mm) to medial (<xref ref-type="fig" rid="fig4">Figure 4F and G</xref>), we calculated by dividing the number of the selectively activated pixels along each vertical line at different distances by the total number of activated pixels with the given SF. To evaluate the response weights of V4 lateral and medial parts in different SFs (<xref ref-type="fig" rid="fig5">Figure 5B and C</xref>) at each single SF condition, we calculated the ratio of the activated pixels in lateral and medial parts to all the activated pixels for a given SF.</p><p>After merging all the orientation- and color-selective pixels at different SF conditions (at least three SFs, low: 0.25–0.5 cycles/deg; medium: 1–2 cycles/deg; and high: 3–6 cycles/deg), we obtained the regions representing nearly the entirety of orientation/color domains (see example in <xref ref-type="fig" rid="fig4">Figure 4A and B</xref>) and calculated the coverage ratio of the functional domains within the area (values in <xref ref-type="fig" rid="fig4">Figure 4A and B</xref>).</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Investigation, Writing - original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Data curation, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing - original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All procedures were performed in accordance with the National Institutes of Health Guidelines and were approved by the Zhejiang University Institutional Animal Care and Use Committee (Permit Number: ZJU20200022 and ZJU20200023).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-81794-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting file. All data used in the figures have been deposited at Open Science Framework (<ext-link ext-link-type="uri" xlink:href="https://osf.io/agkr7/">https://osf.io/agkr7/</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Spatial frequency representation in V2 and V4 of macaque monkey</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/agkr7/">agkr7</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Yin Liu and Meizhen Qian for help with the animal experiments. This research was conducted at Zhejiang University and was supported by the China Brain Initiative (grant no. 2021ZD0200401 to AWR), National Key R&amp;D Program of China (grant no. 2018YFA0701400 to AWR), the National Natural Science Foundation of China (grant nos. 31627802, U20A20221, and 81961128029 to AWR; grant no. 32100802 to JMH), China Postdoctoral Science Foundation (grant no. 2020M681829 to JMH), and the MOE Frontier Science Center for Brain Science &amp; Brain-Machine Integration, Zhejiang University.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>P</given-names></name><name><surname>She</surname><given-names>L</given-names></name><name><surname>McGill</surname><given-names>M</given-names></name><name><surname>Tsao</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A map of object space in primate inferotemporal cortex</article-title><source>Nature</source><volume>583</volume><fpage>103</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2350-5</pub-id><pub-id pub-id-type="pmid">32494012</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartfeld</surname><given-names>E</given-names></name><name><surname>Grinvald</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Relationships between orientation-preference pinwheels, cytochrome oxidase blobs, and ocular-dominance columns in primate striate cortex</article-title><source>PNAS</source><volume>89</volume><fpage>11905</fpage><lpage>11909</lpage><pub-id pub-id-type="doi">10.1073/pnas.89.24.11905</pub-id><pub-id pub-id-type="pmid">1465416</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosking</surname><given-names>WH</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Schofield</surname><given-names>B</given-names></name><name><surname>Fitzpatrick</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>2112</fpage><lpage>2127</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-06-02112.1997</pub-id><pub-id pub-id-type="pmid">9045738</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>L</given-names></name><name><surname>Tsao</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The code for facial identity in the primate brain</article-title><source>Cell</source><volume>169</volume><fpage>1013</fpage><lpage>1028</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.05.011</pub-id><pub-id pub-id-type="pmid">28575666</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name><name><surname>Roe</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A map for horizontal disparity in monkey V2</article-title><source>Neuron</source><volume>58</volume><fpage>442</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.02.032</pub-id><pub-id pub-id-type="pmid">18466753</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Zhu</surname><given-names>S</given-names></name><name><surname>Han</surname><given-names>C</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Roe</surname><given-names>AW</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An orientation map for motion boundaries in macaque V2</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>279</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu235</pub-id><pub-id pub-id-type="pmid">25260703</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chklovskii</surname><given-names>DB</given-names></name><name><surname>Schikorski</surname><given-names>T</given-names></name><name><surname>Stevens</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Wiring optimization in cortical circuits</article-title><source>Neuron</source><volume>34</volume><fpage>341</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)00679-7</pub-id><pub-id pub-id-type="pmid">11988166</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowey</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Cortical maps and visual perception: the grindley memorial lecture</article-title><source>The Quarterly Journal of Experimental Psychology</source><volume>31</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1080/14640747908400703</pub-id><pub-id pub-id-type="pmid">424501</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R</given-names></name><name><surname>Schein</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Visual properties of neurons in area V4 of the macaque: sensitivity to stimulus form</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>835</fpage><lpage>868</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.57.3.835</pub-id><pub-id pub-id-type="pmid">3559704</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Valois</surname><given-names>RL</given-names></name><name><surname>Albrecht</surname><given-names>DG</given-names></name><name><surname>Thorell</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Spatial frequency selectivity of cells in macaque visual cortex</article-title><source>Vision Research</source><volume>22</volume><fpage>545</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(82)90113-4</pub-id><pub-id pub-id-type="pmid">7112954</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Han</surname><given-names>C</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Zhu</surname><given-names>S</given-names></name><name><surname>Ma</surname><given-names>H</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>An orientation map for disparity-defined edges in area V4</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>666</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx348</pub-id><pub-id pub-id-type="pmid">29329408</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname><given-names>DJ</given-names></name><name><surname>Lim</surname><given-names>H</given-names></name><name><surname>Xiao</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Eriksson</surname><given-names>A</given-names></name><name><surname>Parajuli</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The representation of orientation in macaque V2: four stripes not three</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>2354</fpage><lpage>2369</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu033</pub-id><pub-id pub-id-type="pmid">24614951</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>KH</given-names></name><name><surname>Gaska</surname><given-names>JP</given-names></name><name><surname>Nagler</surname><given-names>M</given-names></name><name><surname>Pollen</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Spatial and temporal frequency selectivity of neurones in visual cortical areas V1 and V2 of the macaque monkey</article-title><source>The Journal of Physiology</source><volume>365</volume><fpage>331</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1985.sp015776</pub-id><pub-id pub-id-type="pmid">4032318</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>J</given-names></name><name><surname>Ziemba</surname><given-names>CM</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A functional and perceptual signature of the second visual area in primates</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>974</fpage><lpage>981</lpage><pub-id pub-id-type="doi">10.1038/nn.3402</pub-id><pub-id pub-id-type="pmid">23685719</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name><name><surname>Sandell</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Visual topography of V2 in the macaque</article-title><source>The Journal of Comparative Neurology</source><volume>201</volume><fpage>519</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1002/cne.902010405</pub-id><pub-id pub-id-type="pmid">7287933</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Sousa</surname><given-names>AP</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Visuotopic organization and extent of V3 and V4 of the macaque</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>1831</fpage><lpage>1845</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-06-01831.1988</pub-id><pub-id pub-id-type="pmid">3385477</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gegenfurtner</surname><given-names>KR</given-names></name><name><surname>Kiper</surname><given-names>DC</given-names></name><name><surname>Fenstemaker</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Processing of color, form, and motion in macaque area V2</article-title><source>Visual Neuroscience</source><volume>13</volume><fpage>161</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1017/s0952523800007203</pub-id><pub-id pub-id-type="pmid">8730997</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horton</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Cytochrome oxidase patches: a new cytoarchitectonic feature of monkey visual cortex</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>304</volume><fpage>199</fpage><lpage>253</lpage><pub-id pub-id-type="doi">10.1098/rstb.1984.0021</pub-id><pub-id pub-id-type="pmid">6142484</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>JM</given-names></name><name><surname>Song</surname><given-names>XM</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Roe</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Curvature domains in V4 of macaque monkey</article-title><source>eLife</source><volume>9</volume><elocation-id>e57261</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57261</pub-id><pub-id pub-id-type="pmid">33211004</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Ferrier lecture: functional architecture of macaque monkey visual cortex</article-title><source>Proceedings of the Royal Society of London. Series B, Biological Sciences</source><volume>198</volume><fpage>1</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1098/rspb.1977.0085</pub-id><pub-id pub-id-type="pmid">20635</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hübener</surname><given-names>M</given-names></name><name><surname>Shoham</surname><given-names>D</given-names></name><name><surname>Grinvald</surname><given-names>A</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Spatial relationships among three columnar systems in cat area 17</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>9270</fpage><lpage>9284</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-23-09270.1997</pub-id><pub-id pub-id-type="pmid">9364073</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Issa</surname><given-names>NP</given-names></name><name><surname>Trepel</surname><given-names>C</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Spatial frequency maps in cat visual cortex</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>8504</fpage><lpage>8514</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-22-08504.2000</pub-id><pub-id pub-id-type="pmid">11069958</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>McDermott</surname><given-names>J</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>4302</fpage><lpage>4311</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-11-04302.1997</pub-id><pub-id pub-id-type="pmid">9151747</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koulakov</surname><given-names>AA</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Orientation preference patterns in mammalian visual cortex: a wire length minimization approach</article-title><source>Neuron</source><volume>29</volume><fpage>519</fpage><lpage>527</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(01)00223-9</pub-id><pub-id pub-id-type="pmid">11239440</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname><given-names>JB</given-names></name><name><surname>Kiper</surname><given-names>DC</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Receptive fields and functional architecture of macaque V2</article-title><source>Journal of Neurophysiology</source><volume>71</volume><fpage>2517</fpage><lpage>2542</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.71.6.2517</pub-id><pub-id pub-id-type="pmid">7931532</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Zhu</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Han</surname><given-names>C</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A motion direction preference map in monkey V4</article-title><source>Neuron</source><volume>78</volume><fpage>376</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.024</pub-id><pub-id pub-id-type="pmid">23622068</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Juusola</surname><given-names>M</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Perceptual color map in macaque visual area V4</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>202</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4549-12.2014</pub-id><pub-id pub-id-type="pmid">24381282</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Ju</surname><given-names>N</given-names></name><name><surname>Jiang</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name><name><surname>Macknik</surname><given-names>S</given-names></name><name><surname>Martinez-Conde</surname><given-names>S</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Perceptual hue, lightness, and chroma are represented in a multidimensional functional anatomical map in macaque V1</article-title><source>Progress in Neurobiology</source><volume>212</volume><elocation-id>102251</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2022.102251</pub-id><pub-id pub-id-type="pmid">35182707</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Lu</surname><given-names>Y</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Yin</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Qian</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Andolina</surname><given-names>IM</given-names></name><name><surname>Shipp</surname><given-names>S</given-names></name><name><surname>Mcloughlin</surname><given-names>N</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hierarchical representation for chromatic processing across macaque V1, V2, and V4</article-title><source>Neuron</source><volume>108</volume><fpage>538</fpage><lpage>550</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.07.037</pub-id><pub-id pub-id-type="pmid">32853551</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Livingstone</surname><given-names>MS</given-names></name><name><surname>Hubel</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Anatomy and physiology of a color system in the primate visual cortex</article-title><source>The Journal of Neuroscience</source><volume>4</volume><fpage>309</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.04-01-00309.1984</pub-id><pub-id pub-id-type="pmid">6198495</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>HD</given-names></name><name><surname>Roe</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Optical imaging of contrast response in macaque monkey V1 and V2</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>2675</fpage><lpage>2695</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl177</pub-id><pub-id pub-id-type="pmid">17264252</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>HD</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Tanigawa</surname><given-names>H</given-names></name><name><surname>Roe</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A motion direction map in macaque V2</article-title><source>Neuron</source><volume>68</volume><fpage>1002</fpage><lpage>1013</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.11.020</pub-id><pub-id pub-id-type="pmid">21145011</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Y</given-names></name><name><surname>Yin</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Qian</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>R</given-names></name><name><surname>Andolina</surname><given-names>IM</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Revealing detail along the visual hierarchy: neural clustering preserves acuity from V1 to V4</article-title><source>Neuron</source><volume>98</volume><fpage>417</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.009</pub-id><pub-id pub-id-type="pmid">29606580</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchison</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Neuronal branching patterns and the economy of cortical wiring</article-title><source>Proceedings. Biological Sciences</source><volume>245</volume><fpage>151</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1098/rspb.1991.0102</pub-id><pub-id pub-id-type="pmid">1682939</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Nielsen</surname><given-names>KJ</given-names></name><name><surname>Disney</surname><given-names>AA</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Orthogonal micro-organization of orientation and spatial frequency in primate primary visual cortex</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1683</fpage><lpage>1690</lpage><pub-id pub-id-type="doi">10.1038/nn.3255</pub-id><pub-id pub-id-type="pmid">23143516</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Nielsen</surname><given-names>KJ</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Efficient receptive field tiling in primate V1</article-title><source>Neuron</source><volume>91</volume><fpage>893</fpage><lpage>904</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.015</pub-id><pub-id pub-id-type="pmid">27499086</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Obermayer</surname><given-names>K</given-names></name><name><surname>Blasdel</surname><given-names>GG</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Geometry of orientation and ocular dominance columns in monkey striate cortex</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>4114</fpage><lpage>4129</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-10-04114.1993</pub-id><pub-id pub-id-type="pmid">8410181</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perry</surname><given-names>VH</given-names></name><name><surname>Cowey</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The ganglion cell and cone distributions in the monkey’s retina: implications for central magnification factors</article-title><source>Vision Research</source><volume>25</volume><fpage>1795</fpage><lpage>1810</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(85)90004-5</pub-id><pub-id pub-id-type="pmid">3832605</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce</surname><given-names>CR</given-names></name><name><surname>Hartmann</surname><given-names>TS</given-names></name><name><surname>Livingstone</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>End-stopping predicts curvature tuning along the ventral stream</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>648</fpage><lpage>659</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2507-16.2016</pub-id><pub-id pub-id-type="pmid">28100746</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramsden</surname><given-names>BM</given-names></name><name><surname>Hung</surname><given-names>CP</given-names></name><name><surname>Roe</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Real and illusory contour processing in area V1 of the primate: a cortical balancing act</article-title><source>Cerebral Cortex</source><volume>11</volume><fpage>648</fpage><lpage>665</lpage><pub-id pub-id-type="doi">10.1093/cercor/11.7.648</pub-id><pub-id pub-id-type="pmid">11415967</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roe</surname><given-names>AW</given-names></name><name><surname>Ts’o</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Visual topography in primate V2: multiple representation across functional stripes</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>3689</fpage><lpage>3715</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-05-03689.1995</pub-id><pub-id pub-id-type="pmid">7751939</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roe</surname><given-names>AW</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name><name><surname>Hung</surname><given-names>CP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cortical processing of a brightness illusion</article-title><source>PNAS</source><volume>102</volume><fpage>3869</fpage><lpage>3874</lpage><pub-id pub-id-type="doi">10.1073/pnas.0500097102</pub-id><pub-id pub-id-type="pmid">15738406</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Roe</surname><given-names>AW</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2009">2009</year><chapter-title>Visual system: functional architecture of area V2</chapter-title><person-group person-group-type="editor"><name><surname>Squire</surname><given-names>LR</given-names></name></person-group><source>Encyclopedia of Neuroscience</source><publisher-name>Elsevier</publisher-name><fpage>331</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1016/B978-008045046-9.00215-1</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schein</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Anatomy of macaque fovea and spatial densities of neurons in foveal representation</article-title><source>The Journal of Comparative Neurology</source><volume>269</volume><fpage>479</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1002/cne.902690403</pub-id><pub-id pub-id-type="pmid">3372725</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sedigh-Sarvestani</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>KS</given-names></name><name><surname>Jaepel</surname><given-names>J</given-names></name><name><surname>Satterfield</surname><given-names>R</given-names></name><name><surname>Shultz</surname><given-names>N</given-names></name><name><surname>Fitzpatrick</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A sinusoidal transformation of the visual field is the basis for periodic maps in area V2</article-title><source>Neuron</source><volume>109</volume><fpage>4068</fpage><lpage>4079</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.053</pub-id><pub-id pub-id-type="pmid">34687665</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shoham</surname><given-names>D</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name><name><surname>Schulze</surname><given-names>S</given-names></name><name><surname>Grinvald</surname><given-names>A</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Spatio–temporal frequency domains and their relation to cytochrome oxidase staining in cat visual cortex</article-title><source>Nature</source><volume>385</volume><fpage>529</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/385529a0</pub-id><pub-id pub-id-type="pmid">9020358</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silverman</surname><given-names>MS</given-names></name><name><surname>Grosof</surname><given-names>DH</given-names></name><name><surname>De Valois</surname><given-names>RL</given-names></name><name><surname>Elfar</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Spatial-frequency organization in primate striate cortex</article-title><source>PNAS</source><volume>86</volume><fpage>711</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1073/pnas.86.2.711</pub-id><pub-id pub-id-type="pmid">2536174</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinath</surname><given-names>R</given-names></name><name><surname>Emonds</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Lempel</surname><given-names>AA</given-names></name><name><surname>Dunn-Weiss</surname><given-names>E</given-names></name><name><surname>Connor</surname><given-names>CE</given-names></name><name><surname>Nielsen</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Early emergence of solid shape coding in natural and deep network vision</article-title><source>Current Biology</source><volume>31</volume><fpage>51</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.09.076</pub-id><pub-id pub-id-type="pmid">33096039</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swindale</surname><given-names>NV</given-names></name><name><surname>Shoham</surname><given-names>D</given-names></name><name><surname>Grinvald</surname><given-names>A</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Visual cortex maps are optimized for uniform coverage</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>822</fpage><lpage>826</lpage><pub-id pub-id-type="doi">10.1038/77731</pub-id><pub-id pub-id-type="pmid">10903576</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>R</given-names></name><name><surname>Song</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>R</given-names></name><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Curvature-processing domains in primate V4</article-title><source>eLife</source><volume>9</volume><elocation-id>e57502</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57502</pub-id><pub-id pub-id-type="pmid">33211007</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanigawa</surname><given-names>H</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name><name><surname>Roe</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional organization for color and orientation in macaque V4</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1542</fpage><lpage>1548</lpage><pub-id pub-id-type="doi">10.1038/nn.2676</pub-id><pub-id pub-id-type="pmid">21076422</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Silverman</surname><given-names>MS</given-names></name><name><surname>De Valois</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Spatial frequency columns in primary visual cortex</article-title><source>Science</source><volume>214</volume><fpage>813</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1126/science.7292014</pub-id><pub-id pub-id-type="pmid">7292014</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Silverman</surname><given-names>MS</given-names></name><name><surname>De Valois</surname><given-names>RL</given-names></name><name><surname>Jacobs</surname><given-names>GH</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Functional organization of the second cortical visual area in primates</article-title><source>Science</source><volume>220</volume><fpage>737</fpage><lpage>739</lpage><pub-id pub-id-type="doi">10.1126/science.6301017</pub-id><pub-id pub-id-type="pmid">6301017</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>R</given-names></name><name><surname>Silverman</surname><given-names>M</given-names></name><name><surname>Hamilton</surname><given-names>S</given-names></name><name><surname>Switkes</surname><given-names>E</given-names></name><name><surname>De Valois</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Functional anatomy of macaque striate cortex</article-title><source>V. Spatial Frequency. Journal of Neuroscience</source><volume>8</volume><fpage>1610</fpage><lpage>1624</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-05-01610.1988</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Hamilton</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Functional anatomy of the second visual area (V2) in the macaque</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>2620</fpage><lpage>2644</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-08-02620.1989</pub-id><pub-id pub-id-type="pmid">2769360</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ts’o</surname><given-names>DY</given-names></name><name><surname>Zarella</surname><given-names>M</given-names></name><name><surname>Burkitt</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Whither the hypercolumn?</article-title><source>The Journal of Physiology</source><volume>587</volume><fpage>2791</fpage><lpage>2805</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2009.171082</pub-id><pub-id pub-id-type="pmid">19525564</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Xiao</surname><given-names>Y</given-names></name><name><surname>Felleman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>V2 thin stripes contain spatially organized representations of achromatic luminance change</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>116</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhj131</pub-id><pub-id pub-id-type="pmid">16467565</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wässle</surname><given-names>H</given-names></name><name><surname>Grünert</surname><given-names>U</given-names></name><name><surname>Röhrenbeck</surname><given-names>J</given-names></name><name><surname>Boycott</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Cortical magnification factor and the ganglion cell density of the primate retina</article-title><source>Nature</source><volume>341</volume><fpage>643</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1038/341643a0</pub-id><pub-id pub-id-type="pmid">2797190</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilder</surname><given-names>HD</given-names></name><name><surname>Grünert</surname><given-names>U</given-names></name><name><surname>Lee</surname><given-names>BB</given-names></name><name><surname>Martin</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Topography of ganglion cells and photoreceptors in the retina of a new World monkey: the marmoset Callithrix jacchus</article-title><source>Visual Neuroscience</source><volume>13</volume><fpage>335</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1017/s0952523800007586</pub-id><pub-id pub-id-type="pmid">8737285</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Felleman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A spatially organized representation of colour in macaque cortical area V2</article-title><source>Nature</source><volume>421</volume><fpage>535</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1038/nature01372</pub-id><pub-id pub-id-type="pmid">12556893</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Anderson</surname><given-names>TJ</given-names></name><name><surname>Casagrande</surname><given-names>VA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>How do functional maps in primary visual cortex vary with eccentricity?</article-title><source>The Journal of Comparative Neurology</source><volume>501</volume><fpage>741</fpage><lpage>755</lpage><pub-id pub-id-type="doi">10.1002/cne.21277</pub-id><pub-id pub-id-type="pmid">17299757</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>H-H</given-names></name><name><surname>Verma</surname><given-names>R</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Tibballs</surname><given-names>HA</given-names></name><name><surname>Lui</surname><given-names>LL</given-names></name><name><surname>Reser</surname><given-names>DH</given-names></name><name><surname>Rosa</surname><given-names>MGP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spatial and temporal frequency tuning in striate cortex: functional uniformity and specializations related to receptive field eccentricity</article-title><source>The European Journal of Neuroscience</source><volume>31</volume><fpage>1043</fpage><lpage>1062</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2010.07118.x</pub-id><pub-id pub-id-type="pmid">20377618</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81794.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ray</surname><given-names>Supratim</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dese585</institution-id><institution>Indian Institute of Science Bangalore</institution></institution-wrap><country>India</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.07.27.501743" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.07.27.501743"/></front-stub><body><p>This article makes an important contribution to the study of early visual representation in primates by showing that intermediate cortical areas V2 and V4, as well as primary cortical area V1 (previously shown), contain orthogonal maps of orientation and spatial frequency. The authors provide convincing evidence of this fundamental principle of functional mapping across the two-dimensional cortical surface that ensures and optimizes the complete representation of these two coding dimensions.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81794.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ray</surname><given-names>Supratim</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dese585</institution-id><institution>Indian Institute of Science Bangalore</institution></institution-wrap><country>India</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Connor</surname><given-names>Charles E</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Johns Hopkins University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.07.27.501743">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.07.27.501743v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Spatial frequency representation in V2 and V4 of macaque monkey&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Tirin Moore as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Charles E Connor (Reviewer #1).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. There are five major claims. First is a replication of lower spatial frequency representation in V4. This is based on two examples shown in Figure 3. The differences look clear but should be analyzed statistically.</p><p>2. The second claim is that, on the large scale of the visual field representation in V2 and V4, spatial frequency is mapped from high to low going from fovea to periphery, here estimated as lateral to medial, as in V1. The analysis for this is to plot the geometric centroids of 6 different spatial frequency band responses, for orientation contrasts (Figure 4A) and color contrasts (Figure 4B), and show that they progress in position from lateral to medial for high to low frequencies. This seems like an unusual analysis that obscures most of the original data concerning the relationship of spatial frequency response profiles to the two-dimensional imaging area. And, the centroids do not show a continuous map, but rather a bunching of points except for the extremes. The additional data are 4 supplemental examples with three, different frequency ranges. These data are not analyzed statistically.</p><p>3. The third and most important claim is that spatial frequency and orientation are mapped orthogonally (and recursively) in V2 and V4, as seen in Figure 5 and the Figure 5 supplement. Together these figures present two regions in V4 and two regions in V2. If these are the only analyzed regions, the authors need to specify more clearly how they were selected. Presumably, though, other regions were analyzed, and the authors should present results from all analyzable regions, and use statistical analyses to establish significance.</p><p>4. The fourth claim is that color-sensitive regions in V4 are more associated with low spatial frequencies. The one significant example (the analysis and statistical tests need to be explained), shown in Figure 6, shows a weak relationship to color for both spatial frequency bands, and the other examples presented in the supplementary are not significant and have even lower absolute relationships. These results, if presented, should be considered inconclusive.</p><p>5. The fifth claim is for stripe-like periodicity of spatial frequency representation in V2, related to color tuning. This is supported by ostention to binary maps of spatial frequency tuning in Figure 7 and supplement. Establishing this periodicity would require statistical analysis, and in any case, seems impossible since only a sliver of V2 is visible in these brain surface images, so stripes orthogonal to the V1/V2 boundary (i.e. CO stripes) cannot be distinguished from other patterns of spatial frequency tuning. In fact, Figure 5E and S5I do not appear to have iso-frequency contours biased toward that orientation.</p><p>6. I recommend emphasizing the conclusion that spatial frequency and orientation are mapped orthogonally in V2 and V4, and presenting analyses of all analyzable imaged regions, with statistical tests.</p><p>7. The analysis of spatial frequency selectivity in V1 vs. V2 vs. V4 should include a statistical test. The authors might consider a newly available explanation for lower frequency tuning in V4, that the predominant fraction of V4 neurons is tuned for 3D shape from shading, which by its nature is low in spatial frequency (Srinath et al., Current Biology, 2021). This tuning is mapped into patches that are intercalated with patches tuned for 2D shapes, and the authors could consider how this 2D/3D mapping relates to the mapping they observe for spatial frequency and orientation.</p><p>8. If the authors want to present an analysis of spatial frequency as a function of laterality, a more continuous analysis like marginal response histograms for spatial frequency along the ml axis would be more informative and amenable to statistical analysis.</p><p>9. I recommend eliminating the analyses of and claims about color vs. spatial frequency and stripe-like periodicity because the data do not seem adequate for testing the hypotheses.</p><p>10. The first concert has to do with the use of just two orientation values, 45 and 135 degrees to form a neutral orientation control condition (a cocktail blank), where (I assume because the details were sketchy) responses are added, and then subtracted from the comparison condition with a different color or spatial frequency. Surely, horizontal and vertical orientation regions of the cortex will not be stimulated, or weakly at best, and it will be harder or impossible to determine the preferences of these regions for other parameters, such as SF or color. If the authors are sure this is not a problem I think it needs to be addressed directly, early on in the paper.</p><p>11. The second concern has to do with the distribution of iso-parameter contour intersection angles (e.g. Figures5d and h). The results seem, literally, too good to be true. Previous studies (e.g. Obermeyer and Blasdel, 1993; Hubener et al., 1997) have all shown very much broader distributions. It makes me wonder if the cocktail blank problem above has resulted in some kind of systematic distortion of the SF map, such that the intersection angles are biased (I do not have a more developed perspective on it than that). The second possibility is some kind of numerical error and I would urge the authors to check their code – e.g. try the same calculation with an OR map from one animal superimposed on an SF map from another and see if the expected random distribution is found.</p><p>12. I will add that the finding of decreasing SF preference with increasing distance from the fovea seems unremarkable and I would suggest de-emphasising it as a main result. It is certainly relevant to interpreting the observations of course because SF can only be interpreted with respect to eccentricity. But it is hardly a new or unexpected finding. Also, the fact that color processing is restricted to low SF values is well established in the color literature – this is probably an unavoidable consequence of the distribution of red and green cones across the retina. Some reference to these long-established results might be made.</p><p>13. I found the proposed hypercolumn architecture in Figure 1B very difficult to understand. SFs vary in a continuum, so why are only two levels (low SF and high SF) shown in two different colors? Iso-orientation and Iso-SF lines could have been shown in different colors also (say HSV colors for orientation to show the circular mapping and gray colormap for SF going from low to high). Similar to what has been done for iso-hue and iso-brightness lines in the color region. Perhaps it may be worthwhile to show the same proposed architecture in V1 as well, in which orientation maps form pinwheels and colors are in separate blobs. It was unclear to me how this architecture could have pinwheels/blobs as well.</p><p>14. It is not clear to me how the details of the functional maps depend on the choice of stimuli. In single unit studies, typically a large number of orientations and SFs are used to independently map the SF and orientation tuning preferences. In contrast, here only 2 orientations are used in one case to map the color space. Even for mapping the orientation space, only 4 orientations are used. For mapping the color space also, only the hues along the red-green axis are varied (L-M pathway). I understand that some of these choices could be due to the recording modality (imaging), but it would be very useful if the authors could discuss how/if these stimulus choices can affect their results. More details of the stimuli, such as the drift rate of the gratings, and the cie (x,y, Y) coordinates of red and green hues would be useful.</p><p>15. Can you show the iso-contour lines for orientation on the orientation maps also as a supplementary figure to see how well the algorithm works? Figure 5A shows iso-orientation lines on the SF map. The iso-SF contours shown in Figure 5B easily correspond to the colors in the SF map shown in 5A, but I had difficulty mapping the orientation. Also, I was wondering whether the way the comparisons are done to get the maps (for example, in Figure 4, the same 4 stimuli are compared in two different ways to get orientation and color maps) can potentially impose some constraints on those maps. I say this because it is striking to me that almost every red and blue line shown in 5C and 5G appears to intersect orthogonally (as also shown in 5D and 5H).</p><p>16. To me the orthogonality of SF and Orientation contours in Figure 5 was the most striking result. Can you show how this analysis looks for V1? The supplementary figure also shows only V2 and V4.</p><p>17. The claim about periodicity is not well quantified. If the authors wish to make this claim, they need to show the Fourier transform of the activation pattern as a function of space and show clear peaks in the spectrum. Also, the authors can perhaps clarify what is the spatial resolution of the imaging technique itself.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81794.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. There are five major claims. First is a replication of lower spatial frequency representation in V4. This is based on two examples shown in Figure 3. The differences look clear but should be analyzed statistically.</p></disp-quote><p>We thank the reviewers for this suggestion to include statistical analysis. The mean and standard deviation of preferred spatial frequencies in V1, V2, and V4 have now been calculated for both cases. In addition, we have tested whether the differences in distributions among these areas are significant. These statistics have been added to Figure 3 and the Results section.</p><p>Lines 106-115:</p><p>“The preferred SFs (Figure3D, H) significantly decrease from V1, to V4 (Case1: V1 mean preferred SF = 2.86 cycles/deg., SD=1.40 cycles/deg., N=147207; V2 mean preferred SF = 2.03 cycles/deg., SD=1.51 cycles/deg., N=103377; V4 mean preferred SF = 1.23 cycles/deg., SD=1.32 cycles/deg., N=490921; Case2: V1 mean preferred SF = 2.96 cycles/deg., SD=1.37 cycles/deg., N=194847; V2 mean preferred SF = 2.20 cycles/deg., SD=1.52 cycles/deg., N=186288; V4 mean preferred SF = 1.15 cycles/deg., SD=1.26 cycles/deg., N=635679; Kolmogorov-Smirnov test, V1 vs. V4, V2 vs. V4, V1 vs. V2, p&lt;0.001).”</p><disp-quote content-type="editor-comment"><p>2. The second claim is that, on the large scale of the visual field representation in V2 and V4, spatial frequency is mapped from high to low going from fovea to periphery, here estimated as lateral to medial, as in V1. The analysis for this is to plot the geometric centroids of 6 different spatial frequency band responses, for orientation contrasts (Figure 4A) and color contrasts (Figure 4B), and show that they progress in position from lateral to medial for high to low frequencies. This seems like an unusual analysis that obscures most of the original data concerning the relationship of spatial frequency response profiles to the two-dimensional imaging area. And, the centroids do not show a continuous map, but rather a bunching of points except for the extremes. The additional data are 4 supplemental examples with three, different frequency ranges. These data are not analyzed statistically.</p></disp-quote><p>We thank the reviewer for raising this question. As we claimed in the previous manuscript, we found that the activated V4 orientation domains and V4 color domains progress in position from fovea to periphery when SF is mapped from high to low, as in V1. Due to the small exposure of the V2 area, we did not show how V2 orientation/color maps change according to different SFs.</p><p>Figure 4A (orientation) and 4B (color) depict how cortical activations gradually shift with different SFs in the large imaged field. Many details are in the image results. The centroid calculations depict the general tendency of the changes. In addition to extracting the geometric centroid, we now have provided one example of how the activated region percentage (See New Figure 4C and 4D and the related description in the Results and Methods sections) changes along the M-L axis for evaluating these shifts. It details how activated domains change with topological eccentricity under each SF condition. Furthermore, we have summarized our data and provided the population tendency of how activated functional domains (orientation and color domains) gradually change in fovea vs. parafovea (see New Figure 5).</p><p>Lines 155-167:</p><p>“In addition to extracting geometric centroid with different SFs, we also draw the weights of the activated pixels at different distances from lateral (distance=0 mm) to medial under different SF conditions (see Figure 4C, D). As reported in previous studies (Tanigawa et al., 2010; Li et al., 2013), orientation domains and color domains tend to separate in space, forming different functional bands (see Figure 4C, D, at distances of 2, 6, 10, and 14 mm, the percentages of activated orientation regions decrease while the percentage of activated color regions increase). We found that for the lateral orientation and color bands (see the two bands with a distance smaller than 6 mm), the percentage values are higher in high SF conditions (blue/cyan lines vs. red/orange lines). In comparison, for the medial orientation and color bands (see the two bands with distances larger than 6 mm), the percentage values are higher in low SF conditions (red/orange lines vs. blue/cyan lines).</p><p>Lines 575-593:</p><p>“Calculating the coverage ratio of selective activation.</p><p>We first determined the activated orientation and color domains to calculate the proportion of activated regions in a given area. The coverage ratio (e.g., the values at the corners in Figure 4 A, B) was calculated by dividing the number of the selectively activated pixels recorded at each SF by the total number of pixels in the given area. To evaluate the weights of the activated pixels at different distances from lateral (distance=0 mm) to medial (Figure 4C, D), we calculated by dividing the number of the selectively activated pixels along each vertical line at different distances by the total number of activated pixels with the given SF. To evaluate the response weights of V4 lateral and medial parts in different SFs (Figure 5B, C) at each single SF condition, we calculated the ratio of the activated pixels in lateral and medial parts to all the activated pixels for a given SF.</p><p>After merging all the orientation and color selective pixels at different SF conditions (at least 3 SFs, low: 0.25-0.5 cycles/deg., medium: 1-2 cycles/deg., and high: 3-6 cycles/deg.), we obtained the regions representing nearly the entirety of orientation/color domains (see example in Figure 4F, G) and calculated the coverage ratio of the functional domains within the area (values in Figure 4F, G).”</p><p>Lines 168-178：</p><p>“We summarized our data and provided the population tendency of how activated functional domains (orientation and color domains) change in fovea vs. parafovea (see Figure 5). For each SF, we divided the number of activated pixels in the lateral or medial parts (see Figure 5—figure supplement 1) by the total number of the activated pixels in this SF (pixels selectively activated in a single SF). We found that the proportions of activated functional domains in the lateral and medial parts of V4 change with SFs in distinct ways. For both orientation and color domains, the proportions increase as SF increases in the medial part and decrease as SF increases in the lateral part. These findings also indicate a difference in SF preference between fovea and parafovea.”</p><disp-quote content-type="editor-comment"><p>3. The third and most important claim is that spatial frequency and orientation are mapped orthogonally (and recursively) in V2 and V4, as seen in Figure 5 and the Figure 5 supplement. Together these figures present two regions in V4 and two regions in V2. If these are the only analyzed regions, the authors need to specify more clearly how they were selected. Presumably, though, other regions were analyzed, and the authors should present results from all analyzable regions, and use statistical analyses to establish significance.</p></disp-quote><p>We thank the reviewers for this suggestion to improve the clarity of selected regions. As reported in previous studies (Tanigawa et al., 2010; Li et al., 2013; Hu et al., 2020) and shown in this paper (Figure 4), not all regions are orientation selective. Here we chose the regions with strong orientation selectivity (see New Figure 6 and Figure 6—figure supplement 2, intersection angles in regions with high orientation selectivity, normalized orientation selectivity&gt;0.5, were used for this analysis). We apologize that we made a mistake in calculating the histogram of the intersection angle. Intersection angles larger than 90 degrees were included in the 80-90 degrees group in the previous analysis, which causes the sharp peak at 80-90 degrees. We have corrected it in the manuscript: for the intersection angles larger than 90 degrees, we did the following transformation, 180-angle, to get the complementary acute angle.</p><p>To demonstrate that the intersection angles are more frequently detected at a large angle, we divided the detected intersection angles into three groups (small: 0°-30°, medium: 30°60°, large: 60°-90°) and compared the distribution difference among these groups. The results indicate more (percentage value) 60°-90° intersection angles than other intersection angles. The distribution of the large-angle group is significantly higher than the small and medium groups. In addition, we have compared the distributions between strong orientation selectivity and weak orientation selectivity: the difference is also significant. The statistical information has been added in Figure 6V and the Results section. Lines 234-260:</p><p>“Relationship between SF and orientation maps in V4 and V2</p><p>Having obtained orientation and SF preference maps from the same cortical region, it becomes possible to analyze the spatial relationships between these maps. We chose V4 regions, which showed strong selective orientation responses (normalized orientation selective values larger than 0.5, see Figure 6B and Figure 6—figure supplement 2B). We determined the iso-orientation and iso-SF contours based on the smoothed orientation angle preference map and SF preference map (see one example in Figure 6—figure supplement 1, 18 iso-orientation gradient contours and 5 iso-SF gradient contours). In V2 and V4, the isoorientation and iso-SF contours predominantly intersect in large angles (see Figure 6G, K, O, and Figure 6—figure supplement 2G, K). To demonstrate that the intersection angles are more frequently detected at a large angle, we divided the detected intersection angles into three groups (small: 0°-30°, medium: 30°-60°, large: 60°-90°) and compared the distribution difference among these groups. The results indicate that there are more (percentage value) 60°-90° intersection angles than other kinds of intersection angles (60°-90° Strong Ori: mean=13.56%, SD=1.87%, N=15; 0°-30° Strong Ori: mean=9.19%, SD=1.63%, N=15; 30°-60° Strong Ori: mean=10.58%, SD=1.45%, N=15; 60°-90° weak Ori: mean=10.29%, SD=1.62%, N=6). The distribution of the large angle group is significantly higher than the small (Wilcoxon range test, p=1.60×10<sup>-5</sup>, n=15 from 5 regions, 2 V2 regions, and 3 V4 regions) and medium groups (Wilcoxon rank sum test, p=1.73×10<sup>-4</sup>). In addition, we compare the distribution between groups with strong orientation selectivity and weak orientation selectivity (see Figure 6P-U). The difference is also significant (large angle group, strong orientation selectivity n=15 from 5 regions, 2 V2 regions, and 3 V4 regions, weak orientation selectivity n=6 from 2 V4 regions; Wilcoxon rank sum test, p=0.0057, see Figure 6V).”</p><disp-quote content-type="editor-comment"><p>4. The fourth claim is that color-sensitive regions in V4 are more associated with low spatial frequencies. The one significant example (the analysis and statistical tests need to be explained), shown in Figure 6, shows a weak relationship to color for both spatial frequency bands, and the other examples presented in the supplementary are not significant and have even lower absolute relationships. These results, if presented, should be considered inconclusive.</p></disp-quote><p>Thanks for raising this comment. We realized that our descriptions needed to be more explicit, we added more descriptions in the corresponding Methods section. Here we adopted the methods reported in Lu’s paper (Lu et al., 2018, Neuron) to classify the high and low SF preference domains. We now describe how we calculated the overlapping between SF and color domains in the method section. Lines 577-580:</p><p>“The coverage ratio (e.g., the values at the corners in Figure 4 A, B) was calculated by dividing the number of the selectively activated pixels recorded at each SF by the total number of pixels in the given area.”</p><p>Although the proportion of low SF preference in color domains is not very high, this proportion is still higher compared with high SF preference. We agree with the reviewers that the results are not inclusive and have reorganized the corresponding Result section (see Figure 7A-D and Figure 7—figure supplement 1) and revised the Discussion section. Lines 425-428:</p><p>“As shown in our results, orientation domains and color domains do not cover the entire site of the V4 area. Further studies are needed to bridge the results between different imaging studies and depict more details of spatial relationships among these different modules.”</p><disp-quote content-type="editor-comment"><p>5. The fifth claim is for stripe-like periodicity of spatial frequency representation in V2, related to color tuning. This is supported by ostention to binary maps of spatial frequency tuning in Figure 7 and supplement. Establishing this periodicity would require statistical analysis, and in any case, seems impossible since only a sliver of V2 is visible in these brain surface images, so stripes orthogonal to the V1/V2 boundary (i.e. CO stripes) cannot be distinguished from other patterns of spatial frequency tuning. In fact, Figure 5E and S5I do not appear to have iso-frequency contours biased toward that orientation.</p></disp-quote><p>Thanks for raising this question. We agree with reviewers that further evidence is needed to support the periodicity of spatial frequency representation in V2. However, according to previous studies (Silverman et al., 1989; Lu et al., 2007) and our results, as shown in new Figure 7 with 2 supplements, color and low SF domains tend to share similar cortical locations in the primate visual system. Due to the sliver of exposed V2, we cannot test whether there is a bias in iso-SF contour orientation (more iso-SF contours lay in the orientation parallel or orthogonal to the V1/V2 border). However, our current V2 data (Figure 7—figure supplement 2: V2 SF preference map obtained for a wide range of higher SFs vs. lower SFs) still support the idea that there is an apparent variation in SF representation in V2 (Figure 7, V2 panels).</p><p>As the reviewers suggested, we have now shortened the space and adjusted the diction in the Results section and Discussion section to present the data as an open question requiring further studies and analyses.</p><p>Lines 289, 297, 320: delete the word “periodic.”</p><p>Lines 323: Revise“Thus, there are SF preference differences in V2 that vary according to a unique periodicity” into “Thus, SF preference differences vary uniquely within V2”.</p><p>Lines 383-389:</p><p>“SF preference change in V2</p><p>We explored whether SF is spatially organized similarly to other attributes in V2. We found that similar to color selective response, SF preference changes within the exposed V2 area, forming different SF preference patches, which supports a general functional layout for SF coding in the visual system (preference for low SF in V1 blob, V2/V4 low SF domains; preference for high SF in V1 interblob, V2/V4 high SF domains).”</p><p>Lines 429-432:</p><p>“Due to the limit of ISOI, we only yielded a sliver of V2 areas. More evidence and new techniques (e.g., ultra-high field fMRI) are required to test whether the SF preference in V2 changes periodically as other features (e.g., color, orientation, direction, disparity).”</p><disp-quote content-type="editor-comment"><p>6. I recommend emphasizing the conclusion that spatial frequency and orientation are mapped orthogonally in V2 and V4, and presenting analyses of all analyzable imaged regions, with statistical tests.</p></disp-quote><p>We appreciate the opportunity to refine the key findings regarding the orthogonal mapping of SF and orientation in V4. We have presented analyses of all the chosen regions shown in figures (see New Figure 6 and Figure 6—figure supplement 2) with Wilcoxon rank sum test. Also, see the response to Essential Revision point 3.</p><disp-quote content-type="editor-comment"><p>7. The analysis of spatial frequency selectivity in V1 vs. V2 vs. V4 should include a statistical test. The authors might consider a newly available explanation for lower frequency tuning in V4, that the predominant fraction of V4 neurons is tuned for 3D shape from shading, which by its nature is low in spatial frequency (Srinath et al., Current Biology, 2021). This tuning is mapped into patches that are intercalated with patches tuned for 2D shapes, and the authors could consider how this 2D/3D mapping relates to the mapping they observe for spatial frequency and orientation.</p></disp-quote><p>We have realized that more data statistics are needed, and we thank reviewers for their suggestions. We now have provided the statistical test of SF selectivity in V1 vs. V2. vs. V4 (see the response to Essential Revision point 1).</p><p>It is an exciting research direction to associate the low SF preference to 2D/3D shapes representation. As the reviewer suggested, we also added a couple of paragraphs in the Discussion section on the possible contribution of low SF preference to 3D shape representation of V4.</p><p>Lines 421-428:</p><p>“In V4, the predominant fraction of V4 neurons are tuned for 3D shape from shading, which is low in SF (Srinath et al., 2021) and may have a close relationship with our findings that most of V4 prefer low SF. This 3D tuning is mapped into patches intercalated with patches tuned for 2D shapes (including different orientations). As shown in our results, orientation domains and color domains do not cover the entire site of the V4 area. Further studies are needed to bridge the results between different imaging studies and depict more details of spatial relationships among these different modules.”</p><disp-quote content-type="editor-comment"><p>8. If the authors want to present an analysis of spatial frequency as a function of laterality, a more continuous analysis like marginal response histograms for spatial frequency along the ml axis would be more informative and amenable to statistical analysis.</p></disp-quote><p>Thanks for this suggestion. We now have added an analysis of the spatial frequency along the M-L axis. Please also see the response to Essential Revision point 2.</p><disp-quote content-type="editor-comment"><p>9. I recommend eliminating the analyses of and claims about color vs. spatial frequency and stripe-like periodicity because the data do not seem adequate for testing the hypotheses.</p></disp-quote><p>Thanks for this suggestion. Due to the sliver of exposed V2, we agree that our current data are not adequate for claims about color vs. SF and stripe-like periodicity. We now shorten the corresponding result sections and present the data as an open question requiring further studies and analyses. Also, see the response to Essential Revision point 5.</p><disp-quote content-type="editor-comment"><p>10. The first concert has to do with the use of just two orientation values, 45 and 135 degrees to form a neutral orientation control condition (a cocktail blank), where (I assume because the details were sketchy) responses are added, and then subtracted from the comparison condition with a different color or spatial frequency. Surely, horizontal and vertical orientation regions of the cortex will not be stimulated, or weakly at best, and it will be harder or impossible to determine the preferences of these regions for other parameters, such as SF or color. If the authors are sure this is not a problem I think it needs to be addressed directly, early on in the paper.</p></disp-quote><p>We thank reviewers for remaindering us that the robustness of spatial frequency mapping needs to be clarified early in the article, despite limited orientation control. We compared the SF preference results acquired by different orientations (45°+135°, 45°, 135°). We found that different orientations do not cause significant differences in the distribution of high SF preference (SF=4 cycles/deg.) and low SF preference (SF=0.25 cycles/deg.). In contrast, different visual areas do (see New Figure 3—figure supplement 1).</p><p>Lines 117-123:</p><p>“To confirm that the use of just two orientations, 45 and 135 degrees, can detect a complete picture of SF preference in the imaged area, we compared the SF preference results acquired by different orientations (45°+135°, 45°, 135°) (See Figure 3—figure supplement 1). We found that different orientations do not cause significant differences (two-way ANOVA, p&gt;0.05) in the distribution of high SF preference (SF=4 cycles/deg.) and low SF preference (SF=0.25 cycles/deg.). In contrast, different visual areas do (two-way ANOVA, p&lt;0.05).”</p><disp-quote content-type="editor-comment"><p>11. The second concern has to do with the distribution of iso-parameter contour intersection angles (e.g. Figures5d and h). The results seem, literally, too good to be true. Previous studies (e.g. Obermeyer and Blasdel, 1993; Hubener et al., 1997) have all shown very much broader distributions. It makes me wonder if the cocktail blank problem above has resulted in some kind of systematic distortion of the SF map, such that the intersection angles are biased (I do not have a more developed perspective on it than that). The second possibility is some kind of numerical error and I would urge the authors to check their code – e.g. try the same calculation with an OR map from one animal superimposed on an SF map from another and see if the expected random distribution is found.</p></disp-quote><p>Thanks for this question. We checked our program. We apologize for the mistake in calculating the distribution of the intersection angle. All angles larger than 90° were counted as 90°. Now we have corrected the codes and all relative analyses. Although there is no sharp peak at 80°-90°, the large intersection angles (60-90°) were detected more frequently than other angles (Also see the response to Essential Revision point 3 and New Figure 6 and New Figure 6—figure supplement 2).</p><disp-quote content-type="editor-comment"><p>12. I will add that the finding of decreasing SF preference with increasing distance from the fovea seems unremarkable and I would suggest de-emphasising it as a main result. It is certainly relevant to interpreting the observations of course because SF can only be interpreted with respect to eccentricity. But it is hardly a new or unexpected finding. Also, the fact that color processing is restricted to low SF values is well established in the color literature – this is probably an unavoidable consequence of the distribution of red and green cones across the retina. Some reference to these long-established results might be made.</p></disp-quote><p>Thanks for raising this question. In the new results, we chose two distinct regions, one in the fovea and one far from the fovea (parafovea), for further analysis. These two areas are distinct in their responses to different SFs (see New Figure 5B, C). Instead of showing response amplitude differences among different SFs, our results presented how SF affects the orientation/color selective responses in fovea and parafovea at a functional domain level. The reviewer mentioned that color processing is restricted to low SF values. However, there is a controversy in V2 studies. Some studies showed that there is no clear relationship (e.g., Lu et al., 2018) between SF preference and V2 stripe (most color selective neurons locate in V2 thin stripe), while another study indicates there is a correlation (e.g., Lu et al., 2007). Our results support that there is such a correlation in V2.</p><disp-quote content-type="editor-comment"><p>13. I found the proposed hypercolumn architecture in Figure 1B very difficult to understand. SFs vary in a continuum, so why are only two levels (low SF and high SF) shown in two different colors? Iso-orientation and Iso-SF lines could have been shown in different colors also (say HSV colors for orientation to show the circular mapping and gray colormap for SF going from low to high). Similar to what has been done for iso-hue and iso-brightness lines in the color region. Perhaps it may be worthwhile to show the same proposed architecture in V1 as well, in which orientation maps form pinwheels and colors are in separate blobs. It was unclear to me how this architecture could have pinwheels/blobs as well.</p></disp-quote><p>We have revised the marked colors in this model (see New Figure 1B). This proposed model is based on the results from V2 and V4. The imaged V1 covers an eccentricity of 0-1 degrees. In this imaged region, the preferred SF is within a limited range (3.5-4 cycles/deg., Lu et al., 2018). To map the gradient of SF in this region, more SFs ranging from 3.5 to 4 cycles/deg. should be tested. Based on our current tested SFs, it is hard to describe a detailed gradient change in V1.</p><p>Based on our data from V4 and results shown in Nauhaus et al., 2012, some orientation pinwheel centers locate in low SF domains, while others locate in high SF domains. Based on these known results, we proposed in V1 that the architecture may have a layout as shown in <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>. This architecture requires further tests and correction.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>Illustration of the architecture in V1.</title><p>Some of the pinwheel centers are in low SF, and some are in high SF. The iso-SF contours (achromatic dashed lines) intersect with iso-orientation contours (red lines connecting two neighboring pinwheel centers) mostly at a right angle. Low SF preference regions (circled by light gray dashed lines) are filled with orientation domains that prefer low SF and color blobs (orange patches).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-sa2-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>14. It is not clear to me how the details of the functional maps depend on the choice of stimuli. In single unit studies, typically a large number of orientations and SFs are used to independently map the SF and orientation tuning preferences. In contrast, here only 2 orientations are used in one case to map the color space. Even for mapping the orientation space, only 4 orientations are used. For mapping the color space also, only the hues along the red-green axis are varied (L-M pathway). I understand that some of these choices could be due to the recording modality (imaging), but it would be very useful if the authors could discuss how/if these stimulus choices can affect their results. More details of the stimuli, such as the drift rate of the gratings, and the cie (x,y, Y) coordinates of red and green hues would be useful.</p></disp-quote><p>Thanks for raising this question. As the reviewer mentioned, more stimulus conditions will provide more detailed SF and orientation response features. However, for intrinsic optical imaging studies, it is usually hard to record that many conditions due to the imaging time for each condition. Although we used a few conditions, we now show evidence that this will not dramatically influence our SF and orientation/color preference results. 1. The SF preference map of V2 and V4 are similar, using different orientations (see Figure 3—figure supplement 1). 2. The color maps obtained using different orientations are similar (<xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>).</p><p>For overlapping results between different functional domains, the limited number of tested stimuli may cause an underestimate of the coverage of functional domains. However, as we calculate the ratio of overlapping regions to detected functional domains, the sizes of both areas are underestimated, so the results will not be strongly influenced compared to calculating the actual sizes of overlapping regions.</p><p>In our experiment, the temporal frequency of the gratings was fixed to 4 Hz, and corresponding drifting speeds of these SF conditions (0.25, 0.5, 1, 1.5, 3, 4 cycle/deg.) are 16, 8, 4, 2.7, 1.3, 1 deg./sec. The CIE (x, y, Y) coordinates of red and green hues are 0.662, 0.328,40 (Red), 0.320,0.613, 40 (Green). The information has been added in the “Visual stimuli for optical imaging” section.</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>Color maps obtained by comparing red/green and white/black gratings with different orientations.</title><p>A. Used orientations: 45° and 135°. B. Used orientations: 45°. C. Used orientations: 135°.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81794-sa2-fig2-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>15. Can you show the iso-contour lines for orientation on the orientation maps also as a supplementary figure to see how well the algorithm works? Figure 5A shows iso-orientation lines on the SF map. The iso-SF contours shown in Figure 5B easily correspond to the colors in the SF map shown in 5A, but I had difficulty mapping the orientation. Also, I was wondering whether the way the comparisons are done to get the maps (for example, in Figure 4, the same 4 stimuli are compared in two different ways to get orientation and color maps) can potentially impose some constraints on those maps. I say this because it is striking to me that almost every red and blue line shown in 5C and 5G appears to intersect orthogonally (as also shown in 5D and 5H).</p></disp-quote><p>As the reviewer suggested, we now have provided one more figure supplement on an example that shows the iso-orientation gradient lines for the orientation map and iso-SF gradient lines for the SF map (see New Figure 6—figure supplement 1). Lines 239-242:</p><p>“We determined the iso-orientation and iso-SF contours based on the smoothed orientation angle preference map and SF preference map (see one example in Figure 6—figure supplement 1, 18 iso-orientation gradient contours and 5 iso-SF gradient contours).”</p><disp-quote content-type="editor-comment"><p>16. To me the orthogonality of SF and Orientation contours in Figure 5 was the most striking result. Can you show how this analysis looks for V1? The supplementary figure also shows only V2 and V4.</p></disp-quote><p>Thanks for raising this question. For V1, its preferred SF is relatively high at the lateral part. In figure 2, most parts of V1 are blue (which means high SF preference).</p><p>The imaged region covers an eccentricity of 0-1 degrees. In this imaged region, the SF preference of V1 is within a limited range (~3.5-4 cycles/deg., Lu et al., 2018). In order to map the gradient of SF in this region, more SFs should be tested. Based on our current tested SFs, it is hard to describe a detailed gradient change in V1. However, based on the previous studies (Silverman et al., 1989 and Nauhaus et al., 2012), we proposed that the spatial-frequency organization in V1 is also well organized and follows a similar way as those in V2 and V4 (Also see the response to Essential Revision point 13).</p><disp-quote content-type="editor-comment"><p>17. The claim about periodicity is not well quantified. If the authors wish to make this claim, they need to show the Fourier transform of the activation pattern as a function of space and show clear peaks in the spectrum. Also, the authors can perhaps clarify what is the spatial resolution of the imaging technique itself.</p></disp-quote><p>Thanks for raising this question. Based on our current data, we cannot directly quantify the periodicity of the SF preference in V2 as there are very few repetition cycles detected along the exposed V2 area. However, our results showed a correlation between SF preference and color selectivity in V2. It is well established that in V2, color selectivity varied periodically across different stripes. Thus, our results indicate that SF preferences in V2 may also vary periodically across different stripes. We agree that our current data are not adequate for claims about stripe-like periodicity. We now shorten the corresponding result sections and present the data as an open question requiring further studies and analyses.</p><p>Based on the resolution of ISOI, we cannot achieve the resolution at the cellular level. We cannot further analyze regions containing neurons with complex selectivity (e.g., orientation pinwheel). For these tiny delicate structures, methods (e.g., Two-photon imaging) with a high spatial resolution are required. We clarified this in the Discussion section.</p></body></sub-article></article>