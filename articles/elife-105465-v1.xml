<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">105465</article-id><article-id pub-id-type="doi">10.7554/eLife.105465</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.105465.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>DANCE provides an open-source and low-cost approach to quantify aggression and courtship in <italic>Drosophila</italic></article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Yadav</surname><given-names>R Sai Prathap</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0005-1577-1945</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Dey</surname><given-names>Paulami</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4303-4510</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="pa1">‡</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Ansari</surname><given-names>Faizah</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6453-7179</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Kottat</surname><given-names>Tanvi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Vasam</surname><given-names>Manohar</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3148-8729</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Prabhu</surname><given-names>P Pallavi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Ayyangar</surname><given-names>Shrinivas</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>S</surname><given-names>Swathi Bhaskar</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Prabhu</surname><given-names>Krishnananda</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3479-9597</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Ghosh</surname><given-names>Monalisa</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="pa2">§</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Agrawal</surname><given-names>Pavan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4494-7859</contrib-id><email>pavan.agrawal@manipal.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02xzytt36</institution-id><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal Academy of Higher Education</institution></institution-wrap><addr-line><named-content content-type="city">Manipal</named-content></addr-line><country>India</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02xzytt36</institution-id><institution>Department of Biochemistry, Kasturba Medical College, Manipal Academy of Higher Education</institution></institution-wrap><addr-line><named-content content-type="city">Manipal</named-content></addr-line><country>India</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Cardona</surname><given-names>Albert</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Cardona</surname><given-names>Albert</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="present-address" id="pa1"><label>‡</label><p>Institute for Developmental Biology and Neurobiology, Johannes Gutenberg University Mainz, Biozentrum I, Mainz, Germany</p></fn><fn fn-type="present-address" id="pa2"><label>§</label><p>Gottfried Schatz Research Center, Molecular Biology and Biochemistry, Medical University of Graz, Graz, Austria</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>29</day><month>12</month><year>2025</year></pub-date><volume>14</volume><elocation-id>RP105465</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2025-01-28"><day>28</day><month>01</month><year>2025</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2025-01-04"><day>04</day><month>01</month><year>2025</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.01.03.631168"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-03-25"><day>25</day><month>03</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.105465.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-12-09"><day>09</day><month>12</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.105465.2"/></event></pub-history><permissions><copyright-statement>© 2025, Yadav, Dey et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Yadav, Dey et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-105465-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-105465-figures-v1.pdf"/><abstract><p>Quantifying animal behavior is pivotal for identifying the neuronal and genetic mechanisms involved. Computational approaches have enabled automated analysis of complex behaviors such as aggression and courtship in <italic>Drosophila</italic>. However, existing approaches rely on rule-based algorithms and expensive hardware, limiting sensitivity to behavioral variations and accessibility. Here, we present the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE), a low-cost, open-source platform that combines machine learning-based classifiers and inexpensive hardware to quantify aggression and courtship. DANCE consists of six novel behavioral classifiers trained using a supervised machine learning algorithm. DANCE classifiers address key limitations of rule-based algorithms, capturing dynamic behavioral variations more effectively. DANCE hardware is constructed using medicine blister packs and acrylic sheets, with recordings acquired using smartphones, making it affordable and accessible. Benchmarking demonstrated that DANCE hardware performs comparably to high-cost setups. We validated DANCE in diverse contexts, including social isolation vs. enrichment, which modulates aggression and courtship; RNAi-mediated downregulation of the neuropeptide Dsk; and optogenetic silencing of dopaminergic neurons, which promotes aggression. DANCE provides a cost-effective and portable solution for studying behaviors in resource-limited settings or near natural habitats. Its accessibility and robust performance democratize behavioral neuroscience, enabling rapid screening of genes and neuronal circuits underlying complex social behaviors.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd><italic>Drosophila</italic></kwd><kwd>aggression</kwd><kwd>courtship</kwd><kwd>machine learning</kwd><kwd>computer vision</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03tjsyq23</institution-id><institution>Department of Biotechnology, India</institution></institution-wrap></funding-source><award-id>BT/RLF</award-id><principal-award-recipient><name><surname>Agrawal</surname><given-names>Pavan</given-names></name><name><surname>Ansari</surname><given-names>Faizah</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03tjsyq23</institution-id><institution>Department of Biotechnology, India</institution></institution-wrap></funding-source><award-id>Re-entry/34/2018</award-id><principal-award-recipient><name><surname>Agrawal</surname><given-names>Pavan</given-names></name><name><surname>Ansari</surname><given-names>Faizah</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03tjsyq23</institution-id><institution>Department of Biotechnology, India</institution></institution-wrap></funding-source><award-id>BT/PR36166/BRB/10/1859/2020</award-id><principal-award-recipient><name><surname>Agrawal</surname><given-names>Pavan</given-names></name><name><surname>Yadav</surname><given-names>R Sai Prathap</given-names></name><name><surname>Kottat</surname><given-names>Tanvi</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03emtbt60</institution-id><institution>Anusandhan National Research Foundation (ANRF), Ministry of Science and Technology, Government of India</institution></institution-wrap></funding-source><award-id>CRG/2022/006846</award-id><principal-award-recipient><name><surname>Agrawal</surname><given-names>Pavan</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/036h6g940</institution-id><institution>NFST, Ministry of Tribal Affairs, Government of India</institution></institution-wrap></funding-source><award-id>201516-NFST-2015-17-ST-TEL-806-RENEWAL-2021-22</award-id><principal-award-recipient><name><surname>Vasam</surname><given-names>Manohar</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>MAHE, India</institution></institution-wrap></funding-source><award-id>TMA Pai fellowship</award-id><principal-award-recipient><name><surname>Prabhu</surname><given-names>P Pallavi</given-names></name><name><surname>Yadav</surname><given-names>R Sai Prathap</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0101xrq71</institution-id><institution>Department of Science and Technology (DST)</institution></institution-wrap></funding-source><award-id>DST/INSPIRE/03/2023/001786</award-id><principal-award-recipient><name><surname>Ayyangar</surname><given-names>Shrinivas</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A low-cost, portable platform combining machine learning–based classifiers enables accurate quantification of <italic>Drosophila</italic> aggression and courtship, expanding access to behavioral neuroscience in resource-limited settings.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Detailed and accurate annotation and analysis of complex behaviors are necessary for understanding the underlying neural and molecular mechanisms. The fruit fly <italic>Drosophila melanogaster</italic> is one of the most accessible and well-studied model organisms for identifying the neuronal and molecular underpinnings of behavior. Multiple large-scale screens have been conducted in <italic>Drosophila</italic> to study complex social behaviors such as aggression and courtship (<xref ref-type="bibr" rid="bib6">Asahina, 2017</xref>; <xref ref-type="bibr" rid="bib32">Greenspan and Ferveur, 2000</xref>; <xref ref-type="bibr" rid="bib34">Hall, 2002</xref>; <xref ref-type="bibr" rid="bib49">Kravitz and Fernandez, 2015</xref>) to identify the underlying neural circuitry (<xref ref-type="bibr" rid="bib1">Agrawal et al., 2020</xref>; <xref ref-type="bibr" rid="bib5">Asahina et al., 2014</xref>; <xref ref-type="bibr" rid="bib20">Davis et al., 2018</xref>; <xref ref-type="bibr" rid="bib38">Hoopfer et al., 2015</xref>; <xref ref-type="bibr" rid="bib81">Yadav et al., 2024</xref>) and genes involved (<xref ref-type="bibr" rid="bib1">Agrawal et al., 2020</xref>; <xref ref-type="bibr" rid="bib10">Benzer, 1967</xref>; <xref ref-type="bibr" rid="bib28">Gill, 1963</xref>; <xref ref-type="bibr" rid="bib33">Hall, 1978</xref>; <xref ref-type="bibr" rid="bib40">Ishii et al., 2022</xref>; <xref ref-type="bibr" rid="bib78">Wang et al., 2008</xref>). These behaviors exhibit distinct, stereotyped patterns. For example, aggression involves chasing, fencing (<xref ref-type="bibr" rid="bib41">Jacobs, 1960</xref>), wing threats, boxing (<xref ref-type="bibr" rid="bib24">Dow and von Schilcher, 1975</xref>), lunging, and tussling (<xref ref-type="bibr" rid="bib36">Hoffmann, 1987a</xref>; <xref ref-type="bibr" rid="bib37">Hoffmann, 1987b</xref>). Similarly, courtship consists of multiple stereotyped behaviors exhibited by the male fly, such as orienting, circling, and following the female (<xref ref-type="bibr" rid="bib16">Cook and Cook, 1975</xref>; <xref ref-type="bibr" rid="bib54">Markow, 1987</xref>; <xref ref-type="bibr" rid="bib58">O’Dell, 2003</xref>). To stimulate the female to be more receptive, the male produces a species-specific song by vibrating and extending its wing (<xref ref-type="bibr" rid="bib8">Bennet-Clark and Ewing, 1969</xref>; <xref ref-type="bibr" rid="bib75">Swain and von Philipsborn, 2021</xref>). The male then attempts copulation by curling its abdomen and finally mounts the female for copulation (<xref ref-type="bibr" rid="bib7">Bastock and Manning, 1955</xref>; <xref ref-type="bibr" rid="bib73">Spieth, 1974</xref>).</p><p>Manual analysis by trained observers is considered the gold standard in behavioral analysis, but it is time-consuming and unsuitable for large-scale screens (<xref ref-type="bibr" rid="bib30">Gomez-Marin et al., 2014</xref>; <xref ref-type="bibr" rid="bib64">Robie et al., 2017a</xref>). ‘Computational ethology’ (<xref ref-type="bibr" rid="bib3">Anderson and Perona, 2014</xref>; <xref ref-type="bibr" rid="bib18">Datta et al., 2019</xref>) helps address this challenge by automating behavioral annotation by leveraging advances in computer vision and machine learning (<xref ref-type="bibr" rid="bib65">Robie et al., 2017b</xref>). This enables high-throughput behavioral screening to identify responsible genes and circuits.</p><p>A typical computational ethology workflow involves recording animal behaviors and tracking their positions along with body movements. This is followed by the analysis and classification of the observed behaviors from hundreds to thousands of video frames capturing behavioral instances. Several software programs, such as Ctrax, Caltech FlyTracker, and Deep Lab Cut (<xref ref-type="bibr" rid="bib11">Branson et al., 2009</xref>; <xref ref-type="bibr" rid="bib26">Eyjolfsdottir et al., 2014</xref>; <xref ref-type="bibr" rid="bib55">Mathis et al., 2018</xref>), are widely used for tracking behaviors in <italic>Drosophila</italic>. Each comes with strengths and weaknesses. Ctrax (<xref ref-type="bibr" rid="bib11">Branson et al., 2009</xref>) can accurately track fly position and movement, but identity switches remain a challenge, especially when tracking groups of flies. While both Ctrax and FlyTracker (<xref ref-type="bibr" rid="bib26">Eyjolfsdottir et al., 2014</xref>) may produce identity switches, when groups of flies were tracked simultaneously, Ctrax led to inaccuracies that required manual correction using specialized algorithms such as FixTrax (<xref ref-type="bibr" rid="bib9">Bentzur et al., 2021</xref>).</p><p>The effectiveness of various machine learning pipelines is eventually measured by comparing their output to human annotation, called ‘ground-truthing’. A rule-based algorithm such as CADABRA (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>) is used to quantify aggression, but it can lead to mis-scoring and identity switches, as revealed by ground-truthing (<xref ref-type="bibr" rid="bib68">Simon and Heberlein, 2020</xref>), which needs to be corrected in a semiautomated manner (<xref ref-type="bibr" rid="bib47">Kim et al., 2018</xref>). MateBook (<xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>) is another rule-based algorithm used to quantify courtship; however, similar to CADABRA, it tends to miss true-positive events, leading to significant mis-scoring of behaviors under certain experimental conditions.</p><p>The Janelia Automatic Animal Behavior Annotator (JAABA) (<xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref>) addresses the challenges of rigid rule-based approaches by employing a supervised learning approach. In the JAABA pipeline, user-labeled data are utilized for training to encompass the dynamic variations in behaviors, allowing it to predict behaviors on the basis of learning from input data.</p><p>Several studies have developed JAABA-based behavioral classifiers for measuring aggression (<xref ref-type="bibr" rid="bib14">Chiu et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>; <xref ref-type="bibr" rid="bib25">Duistermars et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Leng et al., 2020</xref>; <xref ref-type="bibr" rid="bib76">Tao et al., 2024</xref>) and courtship (<xref ref-type="bibr" rid="bib29">GilMartí et al., 2023</xref>; <xref ref-type="bibr" rid="bib60">Pantalia et al., 2023</xref>). However, many of these studies did not make these classifiers publicly available (<xref ref-type="bibr" rid="bib25">Duistermars et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">GilMartí et al., 2023</xref>; <xref ref-type="bibr" rid="bib60">Pantalia et al., 2023</xref>). In other cases, the reported approaches relied on specialized hardware, such as custom 3D-printed parts (<xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>; <xref ref-type="bibr" rid="bib29">GilMartí et al., 2023</xref>), or high-end machine-vision cameras (<xref ref-type="bibr" rid="bib14">Chiu et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>; <xref ref-type="bibr" rid="bib25">Duistermars et al., 2018</xref>; <xref ref-type="bibr" rid="bib35">Hindmarsh Sten et al., 2025</xref>; <xref ref-type="bibr" rid="bib50">Leng et al., 2020</xref>; <xref ref-type="bibr" rid="bib76">Tao et al., 2024</xref>), limiting their accessibility and wider adoption.</p><p>Here, we describe DANCE (<italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator), an open-source, user-friendly analysis and hardware pipeline to simplify and automate the process of robustly quantifying aggression and courtship behaviors. DANCE has two components: (1) A set of robust, machine vision-based behavioral classifiers developed using JAABA to quantify aggression and courtship. (2) An inexpensive hardware setup built from off-the-shelf materials and consumer smartphones for behavioral recording. Compared with previous methods (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>), the DANCE classifiers improved accuracy and reliability, while its low-cost hardware eliminates the need for specialized arenas and cameras. All classifiers and analysis codes are publicly available, enabling broad adoption, especially in resource-limited settings. Together, DANCE provides a powerful, accessible platform for behavioral screening and the discovery of mechanisms underlying complex social behaviors and neurological disorders.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>DANCE assay analysis pipeline</title><p>To overcome the challenge of time-consuming manual behavioral annotation or resource-intensive, complex hardware, we developed an automated, high-throughput quantification pipeline—DANCE and trained new behavioral classifiers using an existing machine learning algorithm, JAABA (<xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref>)—to robustly quantify aggression and courtship in <italic>Drosophila</italic> (<xref ref-type="fig" rid="fig1">Figure 1</xref>). We also designed a simple, low-cost recording setup constructed from repurposed transparent medicine blister packs, acrylic sheets, and paper tape, enabling easy behavioral recordings. To record these behaviors, we used Android smartphone cameras and an electronic tablet or smartphone serving as a backlight illumination source (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, Materials and methods).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) assay provides an accessible approach for quantifying aggression and courtship behaviors.</title><p>(<bold>A</bold>) Comparison of existing machine-vision camera hardware (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib48">Koemans et al., 2017</xref>) with the simplified, low-cost DANCE hardware for behavior acquisition. (<bold>B</bold>) Workflow for developing DANCE classifiers, including training, benchmarking against existing methods and manual ground-truth annotations to generate behavioral scores. (<bold>C</bold>) Behavioral classifiers developed to quantify male aggression (lunge) and courtship (wing extension, circling, following, attempted copulation, and copulation). (<bold>D</bold>) Representative raster plots comparing ground-truth, DANCE, CADABRA, and Divider assay performance for aggression. (<bold>E</bold>) Representative raster plots comparing ground-truth, DANCE, and MateBook performance for courtship. Created in <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/h60u049">BioRender</ext-link>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Aggression chamber described by <xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>.</title><p>The setup consists of a bottom food plate, 12 wells (aggression arenas), and a top plate with fly-loading holes and a screw slot that allows sliding of the loading plate.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Courtship setup described by <xref ref-type="bibr" rid="bib48">Koemans et al., 2017</xref>.</title><p>The setup consists of 18 wells (courtship arenas), a top cover plate, a sliding loading plate, and a sliding divider assembly used to separate male and female flies.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig1-figsupp2-v1.tif"/></fig></fig-group><p>We quantify these behaviors using our DANCE classifiers. Unlike existing setups that cost approximately USD 3500, DANCE hardware can be assembled from off-the-shelf components for less than USD 0.30 (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). To benchmark the performance of the DANCE classifiers, we used pre-existing setups and rule-based methods for quantifying courtship and aggression and compared their performance with that of the DANCE classifiers (<xref ref-type="fig" rid="fig1">Figure 1B and C</xref>).</p><p>To train the DANCE classifiers using JAABA (<xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref>), for aggressive lunges, we used an existing setup described in <xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>, modified from <xref ref-type="bibr" rid="bib23">Dierick, 2007</xref>; <xref ref-type="fig" rid="fig1">Figure 1A</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, and for courtship behaviors, we used a pre-existing setup described in <xref ref-type="bibr" rid="bib48">Koemans et al., 2017</xref>; <xref ref-type="fig" rid="fig1">Figure 1A</xref>; <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>. We tracked the position, motion, and interactions of pairs of flies across video frames using the Caltech FlyTracker (<xref ref-type="bibr" rid="bib26">Eyjolfsdottir et al., 2014</xref>). To avoid data leakage, we randomly divided the acquired videos into two categories, ‘training videos’ and ‘test videos’, to train and evaluate the DANCE classifiers. These test videos were also manually ‘ground-truthed’ frame by frame, which is considered the gold standard for behavioral annotation (<xref ref-type="fig" rid="fig1">Figure 1B, D, and E</xref>).</p><p>We benchmarked the performance of the DANCE classifiers against existing rule-based algorithms, CADABRA (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>) and MateBook (<xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>), and an existing JAABA aggression classifier (<xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>). Comparisons with manual ground-truth data revealed that the performance of the DANCE classifiers is comparable to that of human annotations and has higher sensitivity than rule-based algorithms (<xref ref-type="fig" rid="fig1">Figure 1D and E</xref>). The subsequent sections describe the quantitative analysis of individual DANCE classifiers and benchmarking of DANCE hardware.</p></sec><sec id="s2-2"><title>DANCE lunge classifier to quantify aggressive behavior</title><p>Aggression is an innate, complex behavior, and <italic>Drosophila</italic> males exhibit several stereotyped behavioral patterns during aggressive encounters, with lunging used widely as a measure of overall aggression in males (<xref ref-type="bibr" rid="bib1">Agrawal et al., 2020</xref>; <xref ref-type="bibr" rid="bib5">Asahina et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Chiu et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>; <xref ref-type="bibr" rid="bib19">Davis et al., 2014</xref>; <xref ref-type="bibr" rid="bib23">Dierick, 2007</xref>; <xref ref-type="bibr" rid="bib36">Hoffmann, 1987a</xref>; <xref ref-type="bibr" rid="bib38">Hoopfer et al., 2015</xref>; <xref ref-type="bibr" rid="bib39">Hoyer et al., 2008</xref>; <xref ref-type="bibr" rid="bib43">Jung et al., 2020</xref>; <xref ref-type="bibr" rid="bib57">Nilsen et al., 2004</xref>; <xref ref-type="bibr" rid="bib79">Watanabe et al., 2017</xref>; <xref ref-type="bibr" rid="bib81">Yadav et al., 2024</xref>). A lunge is defined as a male fly raising its front legs and hitting down on the other fly.</p><p>We developed a new classifier using JAABA (<xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref>) to robustly quantify aggressive lunges in <italic>Drosophila</italic>, hereafter referred to as the DANCE lunge classifier. We quantified lunges using our classifier from 20-min-long videos and compared the output with manual ground-truth and existing methods—CADABRA (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>) and the Divider assay classifier (<xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>). CADABRA tends to miss several true-positive lunges, likely because of its rigid, rule-based framework, which cannot adapt to the dynamic variations in behavior. <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows the lunge scores from 40 different videos using the ground-truth, the DANCE lunge classifier, CADABRA, and the Divider assay classifier. While the ground-truth and DANCE classifiers’ outputs are comparable, CADABRA and the Divider assay classifier underscore lunges across videos. We ground-truthed the DANCE lunge classifier against 40 ‘test videos’ (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, Materials and methods). Inter-observer validation confirmed that there were no significant differences between the two independent manual annotations (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Validation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) lunge classifier for quantifying male aggression.</title><p>(<bold>A</bold>) Lunge scores from 20-min-long videos scored using ground-truth annotations (gray), the DANCE lunge classifier (orange), CADABRA (purple), and Divider assay classifier (green). (<bold>B–E</bold>) Comparison of lunge scores across different aggression levels, based on manual scoring and predictions from DANCE, CADABRA, and Divider: (<bold>B</bold>) 0–70 lunges ‘low aggressive’ (n=10; ground-truth vs. DANCE ns, p&gt;0.9951, ground-truth vs. CADABRA ns, p&gt;0.3405, ground-truth vs. Divider assay classifier **p&lt;0.0017, DANCE vs. CADABRA **p&lt;0.0060, DANCE vs. Divider assay classifier ****p&lt;0.0001, CADABRA vs. Divider assay classifier ns, p&gt;0.4996). (<bold>C</bold>) 71–160 lunges, 'moderately aggressive’ (n=11; ground-truth vs. DANCE ns, p&gt;0.9999, ground-truth vs. CADABRA ns, p&gt;0.1247, ground-truth vs. Divider assay classifier ***p&lt;0.0002, DANCE vs. CADABRA *p&lt;0.0102, DANCE vs. Divider assay classifier ****p&lt;0.0001, CADABRA vs. Divider assay classifier ns, p&gt;0.4157). (<bold>D</bold>) 161–300 lunges, ‘highly aggressive’ (n=11; ground-truth vs. DANCE ns, p&gt;0.9999, ground-truth vs. CADABRA, **p&gt;0.0057, ground-truth vs. Divider assay classifier *p&lt;0.0102, DANCE vs. CADABRA ***p&lt;0.0002, DANCE vs. Divider assay classifier ***p&lt;0.0004, CADABRA vs. Divider assay classifier ns, p&gt;0.9999), and (<bold>E</bold>) &gt;300 lunges, ‘hyper-aggressive’ (n=8; ground-truth vs. DANCE ns, p&gt;0.9999, ground-truth vs. CADABRA, ***p&gt;0.0006, ground-truth vs. Divider assay classifier **p&lt;0.0029, DANCE vs. CADABRA, *p&lt;0.0402, DANCE vs. Divider assay classifier *p&lt;0.0102, CADABRA vs. Divider assay classifier ns, p&gt;0.9999; Friedman’s ANOVA with Dunn’s test). (<bold>F</bold>) Regression analysis of the DANCE ‘lunge classifier’ vs. manual scores (R<sup>2</sup>=0.9760, n=40). (<bold>G</bold>) Regression of the CADABRA vs. the DANCE lunge classifier (R<sup>2</sup>=0.9, n=40). (<bold>H</bold>) Regression of the Divider assay lunge classifier score vs. manual score (R<sup>2</sup>=0.7739, n=40). (<bold>I</bold>) Precision, recall, and F1 scores of the DANCE lunge classifier compared with those of CADABRA and Divider.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig2">Figure 2</xref> showing quantitative aggressive lunge counts and performance metrics for DANCE and existing methods used to quantify aggressive behavior in male flies.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Comparison of annotations by two independent evaluators to assess observer bias during ground-truthing.</title><p>(<bold>A</bold>) Aggressive lunges, ns, p=0.8789, n=15. (<bold>B</bold>) Courtship wing extension, ns, p=0.9999, n=13. (<bold>C</bold>) Attempted copulation, ns, p=0.0571, n=16. (<bold>D</bold>) Circling, ns, p=0.4343, n=12. (<bold>E</bold>) Following, ns, p=0.4405, n=13. (<bold>F</bold>) Copulation, ns, p=0.9221, n=25. (<bold>A–F</bold>) All comparisons were performed using the Mann‒Whitney U test.</p><p><supplementary-material id="fig2s1sdata1"><label>Figure 2—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> comparing behavioral annotations across multiple behaviors (lunges, wing extension, attempted copulation, following, circling, and copulation indices) independently scored by two observers to assess observer bias during ground-truthing.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig2-figsupp1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Evaluation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) lunge classifier predictions across training videos.</title><p>(<bold>A–D</bold>) Scatter plots showing the correlation between manual ground-truth annotations and DANCE-predicted frame counts across four independent training videos (Videos 8–11). (<bold>A</bold>) R<sup>2</sup>=0.9794, (<bold>B</bold>) R<sup>2</sup>=0.9760, (<bold>C</bold>) R<sup>2</sup>=0.9847, and (<bold>D</bold>) R<sup>2</sup>=0.9893, demonstrating close agreement between automated classification and manual scoring. (<bold>E–H</bold>) Bar plots showing the precision, recall, and F1 score of the DANCE classifier for the corresponding videos. Video 9, which yielded the highest overall performance, was also used in <xref ref-type="fig" rid="fig2">Figure 2</xref> for inter-method comparison with CADABRA and the Divider assay to maintain consistency across analyses.</p><p><supplementary-material id="fig2s2sdata1"><label>Figure 2—figure supplement 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> comparing aggressive lunge metrics and performance of different classifiers across training videos to assess robustness and reproducibility.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig2-figsupp2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig2-figsupp2-v1.tif"/></fig></fig-group><p>Since aggressive lunges have a large dynamic range, we benchmarked our classifier across a range of aggressive behaviors and subdivided the ground-truth videos into four categories: (1) low aggressive, 0–70 lunges (<xref ref-type="fig" rid="fig2">Figure 2B</xref>); (2) moderately aggressive, 71–160 lunges (<xref ref-type="fig" rid="fig2">Figure 2C</xref>); (3) highly aggressive, 161–300 lunges (<xref ref-type="fig" rid="fig2">Figure 2D</xref>); and (4) hyperaggressive, &gt;300 lunges (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). DANCE scores remained comparable to ground-truth scores across all categories, whereas CADABRA and Divider underestimated the lunge counts (<xref ref-type="fig" rid="fig2">Figure 2B–E</xref>). Correlation analysis revealed a strong relationship between DANCE and ground-truth scores (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). In comparison, CADABRA and the Divider assay classifier showed a weaker correlation (<xref ref-type="fig" rid="fig2">Figure 2G–H</xref>, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). We reasoned that CADABRA’s lower performance is most likely due to the rigid rules used to define a lunge (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>), whereas the Divider assay classifier, although also JAABA-based, was trained using data from a rectangular arena. Because JAABA classifiers rely on features influenced by the arena geometry, this mismatch likely reduced its accuracy in our circular setup. To further evaluate the performance, we computed the precision, recall, and F1 score (<xref ref-type="fig" rid="fig2">Figure 2I</xref>). The DANCE lunge classifier achieved a precision of 78.7%, recall of 73.1%, and an overall F1 score of 75.8%, exceeding the values obtained with other methods. Classifier robustness across multiple training videos, including the dataset used for inter-method comparisons (Video 9), is summarized in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>. Together, our analysis suggests that the DANCE lunge classifier performs with high precision and quantifies lunge numbers robustly over a broad range of fighting intensities.</p></sec><sec id="s2-3"><title>DANCE classifiers to quantify courtship behaviors in <italic>Drosophila</italic></title><p>The first report of <italic>Drosophila</italic> courtship behavior described stereotypic behaviors such as wing ‘scissor-like’ movements, with males ‘swaying around the female’, licking, tapping, and mounting (<xref ref-type="bibr" rid="bib74">Sturtevant, 1915</xref>). By the 2000s, studies revealed genes and neural circuits involved in courtship (<xref ref-type="bibr" rid="bib22">Dickson, 2008</xref>; <xref ref-type="bibr" rid="bib61">Pavlou and Goodwin, 2013</xref>). Automated analysis techniques for courtship exist, but their adoption has been limited by expensive hardware, reliance on custom parts, or a lack of publicly available code and classifiers (<xref ref-type="bibr" rid="bib25">Duistermars et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">GilMartí et al., 2023</xref>; <xref ref-type="bibr" rid="bib48">Koemans et al., 2017</xref>; <xref ref-type="bibr" rid="bib62">Reza et al., 2013</xref>; <xref ref-type="bibr" rid="bib76">Tao et al., 2024</xref>).</p><p>MateBook is a recent rule-based pipeline for automating the quantification of courtship behavior (<xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>). It relies on predefined rules derived from CADABRA (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>). To resolve ambiguities in the two overlapping flies when their trajectories are estimated from the video recordings, identities are assigned by relying on the distinct body sizes of the male and female flies, as the females are larger than the males. This size assumption is problematic in assays that use decapitated virgin females, which approximate male size. Such conditions are often used to assess male courtship independent of female behavioral feedback, e.g., when evaluating pheromone effects (<xref ref-type="bibr" rid="bib16">Cook and Cook, 1975</xref>; <xref ref-type="bibr" rid="bib71">Spieth, 1966</xref>). In these contexts, rule-based approaches can introduce false positives and false negatives because the body-size criterion is not met.</p><p>To overcome these limitations, we trained and validated five new courtship classifiers using JAABA (<xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref>). These classifiers quantify distinct stages of the male courtship ritual (<xref ref-type="bibr" rid="bib69">Sokolowski, 2001</xref>), including wing extension, following, circling, attempted copulation, and copulation. To ensure robustness across conditions, training datasets included videos with both decapitated and intact females (mated or virgin). We evaluated the DANCE classifier performance by comparing the outputs with the manual ground-truth and MateBook results. Because courtship behaviors differ in duration, we calculated a behavior index to enable direct comparisons between methods. Details of the classifier thresholds and criteria are provided in the Materials and methods and in <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>. To assess observer bias, annotations from two independent evaluators were compared, revealing no significant differences (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B–F</xref>, <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref>).</p></sec><sec id="s2-4"><title>Wing extension</title><p>During unilateral wing extension, a male vibrates its wing at a specific frequency to produce a species-specific courtship song to attract the female (<xref ref-type="bibr" rid="bib67">Shorey, 1962</xref>; <xref ref-type="bibr" rid="bib70">Spieth, 1952</xref>).</p><p><xref ref-type="fig" rid="fig3">Figure 3A</xref> shows wing extension indices derived from manual ground-truth (gray) and the DANCE wing extension classifier (orange) across 15 videos with decapitated virgin females; the two measures are comparable, whereas MateBook (purple) systematically reports lower scores in most videos (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The DANCE wing extension index is strongly correlated with the ground-truth scores (<xref ref-type="fig" rid="fig3">Figure 3B and C</xref>) but weakly correlated with MateBook (<xref ref-type="fig" rid="fig3">Figure 3B and D</xref>). The classifier performance metrics confirm high reliability (precision 92.2%, recall 98.1%, F1 95.1%) (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Similar trends were observed in the mated female dataset (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Evaluation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) wing extension classifier for quantifying courtship behavior.</title><p>(<bold>A</bold>) Wing extension index of males from 15-min-long videos scored using manual ground-truth annotations (gray), the DANCE wing extension classifier (orange), and MateBook (purple), with decapitated virgin females. MateBook underscored wing extension across multiple videos (Friedman’s ANOVA with Dunn’s test: ground-truth vs. MateBook **p=0.0020, ground-truth vs. DANCE ns, p&gt;0.9999; n=15). (<bold>B</bold>) Comparison of ground-truth, DANCE, and MateBook wing extension scores (Kruskal‒Wallis ANOVA with Dunn’s test, ground-truth vs. DANCE ns, p&gt;0.9999, ground-truth vs. MateBook *p=0.0436; n=15). (<bold>C</bold>) Regression analysis of the DANCE wing extension classifier vs. ground-truth (R<sup>2</sup>=0.9831, n=15). (<bold>D</bold>) Regression of MateBook vs. ground-truth (R<sup>2</sup>=0.1054, n=15). (<bold>E</bold>) Precision, recall, and F1 score of the DANCE wing extension classifier and MateBook relative ground-truth scores.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3">Figure 3</xref> showing quantitative behavioral indices and performance metrics (bout-level analysis) for DANCE and existing methods used to quantify wing-extension behavior in decapitated virgin female flies.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Evaluation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) wing extension classifier in the mated-female dataset.</title><p>(<bold>A</bold>) Wing extension of males from 15 min videos scored using manual ground-truth annotations (gray), DANCE classifier (orange), and MateBook (purple) with mated females. MateBook underscored wing extension across multiple videos (Friedman’s ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p=0.3582, ground-truth vs. MateBook p&lt;0.0001; n=25). (<bold>B</bold>) Comparison of wing extension scores from ground-truth, DANCE, and MateBook datasets (Kruskal–Wallis ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p&gt;0.9999, ground-truth vs. MateBook ns, p=0.1039; n=25). (<bold>C</bold>) Regression of DANCE classifier scores vs. ground-truth (R<sup>2</sup>=0.9951, n=25). (<bold>D</bold>) Regression of MateBook vs. ground-truth (R<sup>2</sup>=0.8282, n=25). (<bold>E</bold>) Precision, recall, and F1 scores of the DANCE classifier and MateBook relative to ground-truth annotations.</p><p><supplementary-material id="fig3s1sdata1"><label>Figure 3—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> showing quantitative behavioral indices and performance metrics (bout-level analysis) for DANCE and existing methods used to quantify wing-extension behavior in mated female flies.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig3-figsupp1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig3-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-5"><title>Attempted copulation and copulation</title><p>Copulation typically lasts for approximately 15–25 min, and its duration is primarily determined by the male (<xref ref-type="bibr" rid="bib53">MacBean and Parsons, 1967</xref>). Interrupted mating experiments have shown that sperm are transferred several minutes after copulation begins (<xref ref-type="bibr" rid="bib27">Fowler, 1973</xref>; <xref ref-type="bibr" rid="bib77">Tompkins et al., 1980</xref>). This distinction separates mounting into two outcomes—successful copulation and unsuccessful attempted copulation—for which we developed separate classifiers (see Materials and methods).</p><p>The DANCE attempted copulation classifier closely matched the ground-truth across videos (<xref ref-type="fig" rid="fig4">Figure 4A and B</xref>). Compared with MateBook, which often overestimates attempted copulation events, the DANCE classifier provides more consistent detection. The correlation with the ground-truth was stronger for DANCE as compared to MateBook (<xref ref-type="fig" rid="fig4">Figure 4C and D</xref>), and the performance metrics for DANCE were robust (precision 82.6%, recall 89.2%, F1 85.8%; <xref ref-type="fig" rid="fig4">Figure 4E</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Validation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) attempted-copulation classifier.</title><p>(<bold>A</bold>) Attempted copulation index of males from 15-min-long videos scored using manual ground-truth annotations (gray), the ‘DANCE attempted copulation classifier’ (orange), and the MateBook (purple) with both mated and decapitated females (Friedman’s ANOVA with Dunn’s test: ground-truth vs. MateBook ****p&lt;0.0001, ground-truth vs. DANCE ns, p&gt;0.9999; n=32). (<bold>B</bold>) Comparison of ground-truth, DANCE attempted-copulation classifier, and MateBook scores (Kruskal‒Wallis ANOVA with Dunn’s test, ground-truth vs. DANCE ns, p&gt;0.9999; ground-truth vs. MateBook ****p&lt;0.0001, n=32). (<bold>C</bold>) Regression analysis of the attempted-copulation classifier vs. ground-truth (R<sup>2</sup>=0.9565, n=32). (<bold>D</bold>) Regression analysis of MateBook vs. ground-truth (R<sup>2</sup>=2115, n=32). (<bold>E</bold>) Precision, recall, and F1 score of the DANCE and MateBook attempted-copulation classifiers relative to the ground-truth scores.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4</xref> showing quantitative behavioral indices and performance metrics (bout-level analysis) for DANCE and existing methods used to quantify attempted-copulation behavior in both decapitated virgin and mated female flies.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig4-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Evaluation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) copulation classifier in the mixed-female dataset.</title><p>(<bold>A</bold>) Copulation scores from 15 min videos obtained using manual ground-truth annotations (gray), the DANCE copulation classifier (orange), and MateBook (purple) (Friedman’s ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p&gt;0.9999; ground-truth vs. MateBook ns, p&gt;0.9999; n=21). (<bold>B</bold>) Box plot comparison of the manual ground-truth, DANCE copulation classifier, and MateBook (Kruskal‒Wallis ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p&gt;0.9999; ground-truth vs. MateBook ns, p&gt;0.9999; n=21). (<bold>C</bold>) Regression of DANCE classifier scores vs. manual ground-truth (R<sup>2</sup>=0.98, n=21). (<bold>D</bold>) Regression of MateBook vs. manual ground-truth (R<sup>2</sup>=0.81, n=21). (<bold>E</bold>) Precision, recall, and F1 score of the DANCE copulation classifier and MateBook relative to the ground-truth score.</p><p><supplementary-material id="fig4s1sdata1"><label>Figure 4—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> showing quantitative behavioral indices and performance metrics (bout-level analysis) for DANCE and existing methods used to quantify copulation behavior in mixed female dataset.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig4-figsupp1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig4-figsupp1-v1.tif"/></fig></fig-group><p>For copulation, which is trained on videos using mated and decapitated virgin females, the DANCE copulation classifier also matches the ground-truth with near-perfect performance (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). MateBook performs reasonably well for copulation, but alignment or arena-detection errors in some recordings cause occasional false negatives or positives (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>, videos 13 and 18).</p></sec><sec id="s2-6"><title>Circling</title><p>A male circling around a female is a distinct courtship element implicated in female re-stimulation (<xref ref-type="bibr" rid="bib45">Kessler, 1962</xref>). Variations in circling frequency across species contribute to reproductive isolation (<xref ref-type="bibr" rid="bib12">Brown, 1965</xref>).</p><p>We evaluated the DANCE circling classifier on both the decapitated-virgin and mated-female datasets (<xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). The circling indices from ground-truth and DANCE were comparable across videos (<xref ref-type="fig" rid="fig5">Figure 5A and B</xref>), whereas MateBook often under-represented circling in individual recordings (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). The DANCE circling index correlated strongly with ground-truth scores as compared to MateBook (<xref ref-type="fig" rid="fig5">Figure 5C and D</xref>), and classifier metrics indicated robust performance (precision 98.0%, recall 92.1%, F1 95.0%; <xref ref-type="fig" rid="fig5">Figure 5E</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Evaluation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) circling classifier.</title><p>(<bold>A</bold>) Circling index of males from 15-min-long videos scored using manual ground-truth annotations (gray), ‘DANCE circling classifier’ (orange), and MateBook (purple) with decapitated virgin females (Friedman’s ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p=0.2049, ground-truth vs. MateBook ****p&lt;0.0001, n=12). (<bold>B</bold>) Comparison of the ground-truth, DANCE, and MateBook circling classifiers (ordinary one-way ANOVA with Dunnett’s test, ground-truth vs. DANCE ns, p=0.8014; ground-truth vs. MateBook *p=0.0157, n=12). (<bold>C</bold>) Regression analysis of the DANCE circling classifier vs. ground-truth (R<sup>2</sup>=0.92, n=12). (<bold>D</bold>) Regression of MateBook vs. ground-truth (R<sup>2</sup>=0.88, n=12). (<bold>E</bold>) Precision, recall, and F1 score of the DANCE and MateBook circling classifiers relative to the ground-truth score.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5</xref> showing quantitative behavioral indices and performance metrics (bout-level analysis) for DANCE and existing methods used to quantify circling behavior in decapitated virgin female flies.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig5-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Evaluation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) circling classifier in the mated-female dataset.</title><p>(<bold>A</bold>) Circling index of males from 15 min videos scored using manual ground-truth annotations (gray), the DANCE circling classifier (orange), and the MateBook (purple) with mated females (Friedman’s ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p&gt;0.9999; ground-truth vs. MateBook, p&lt;0.0001; n=19). (<bold>B</bold>) Comparison of circling scores from ground-truth, DANCE, and MateBook datasets (Kruskal‒Wallis ANOVA, ground-truth vs. DANCE ns, p&gt;0.9999; ground-truth vs. MateBook ns, p=0.0822; n=19). (<bold>C</bold>) Regression of DANCE classifier scores vs. ground-truth (R<sup>2</sup>=0.9494, n=19). (<bold>D</bold>) Regression of MateBook vs. ground-truth (R<sup>2</sup>=0.6938, n=19). (<bold>E</bold>) Precision, recall, and F1 scores of the DANCE and MateBook circling classifiers relative to the ground-truth scores.</p><p><supplementary-material id="fig5s1sdata1"><label>Figure 5—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> showing quantitative behavioral indices and performance metrics (bout-level analysis) for DANCE and existing methods used to quantify circling behavior in mated female flies.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig5-figsupp1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Evaluation of the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) following classifier in the mated-female dataset.</title><p>(<bold>A</bold>) Following the index of males from 15 min videos scored using manual ground-truth annotations (gray), DANCE following classifier (orange), and MateBook (purple) with mated females (Friedman’s ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p=0.1794; ground-truth vs. MateBook p=0.0029; n=25). (<bold>B</bold>) Box plot comparison of the following scores from the ground-truth, DANCE, and MateBook datasets (Kruskal‒Wallis ANOVA with Dunn’s test: ground-truth vs. DANCE ns, p&gt;0.9999; ground-truth vs. MateBook ns, p=0.5287; n=25). (<bold>C</bold>) Regression analysis of the following classifier vs. ground-truth (R<sup>2</sup>=0.9894, n=25). (<bold>D</bold>) Regression of MateBook vs. ground-truth (R<sup>2</sup>=0.9204, n=25). (<bold>E</bold>) Precision, recall, and F1 scores of DANCE and MateBook following classifiers relative to ground-truth annotations.</p><p><supplementary-material id="fig5s2sdata1"><label>Figure 5—figure supplement 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> showing quantitative behavioral indices and performance metrics (bout-level analysis) for DANCE and existing methods used to quantify following behavior in mated female flies.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig5-figsupp2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Frame-level analysis of duration-based courtship classifiers.</title><p>(<bold>A–G</bold>) Bar plots showing precision, recall, and F1 scores for <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) (orange) and MateBook (purple) across different behaviors: (<bold>A</bold>) wing extension toward decapitated females, (<bold>B</bold>) wing extension toward mated females, (<bold>C</bold>) copulation, (<bold>D</bold>) attempted copulation (mixed dataset), (<bold>E</bold>) circling toward decapitated females, (<bold>F</bold>) circling toward mated females, and (<bold>G</bold>) following. Percent error rates are shown above each bar.</p><p><supplementary-material id="fig5s3sdata1"><label>Figure 5—figure supplement 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref> showing performance metrics (frame-level analysis) for DANCE and existing methods used to quantify multiple courtship behaviors.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig5-figsupp3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig5-figsupp3-v1.tif"/></fig></fig-group></sec><sec id="s2-7"><title>Following</title><p>During following, the male tracks the female’s movement to initiate subsequent courtship acts (<xref ref-type="bibr" rid="bib72">Spieth, 1968</xref>). Because following is a relatively continuous and readily defined behavior, both the MateBook and the DANCE following classifier performed well (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A–D</xref>). However, the DANCE following classifier produced more balanced scores (precision 91.2%, recall 91.1%, F1 91.1%) compared with MateBook (precision 65.8%, recall 83.4%, F1 73.5%; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2E</xref>), indicating lower rates of false positives and false negatives for DANCE.</p><p>Finally, we performed frame-level analyses in addition to bout-level evaluations to provide a more granular assessment of the courtship classifiers (see Materials and methods). Frame-level metrics showed only marginal reductions in performance compared with bout-level metrics (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). Together, these results demonstrate that the DANCE classifiers provide a reliable and accurate means to quantify both aggression and courtship behaviors, supporting subsequent benchmarking using the DANCE hardware.</p></sec><sec id="s2-8"><title>DANCE hardware</title><p>Existing setups for recording <italic>Drosophila</italic> aggression and courtship (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplements 1</xref> and <xref ref-type="fig" rid="fig1s2">2</xref>) present several practical challenges that limit their broad adoption. These include the need for complex, custom-fabricated components, 3D-printed parts, specialized machine-vision cameras and backlights, and considerable technical expertise for data acquisition and processing (<xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>; <xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib29">GilMartí et al., 2023</xref>; <xref ref-type="bibr" rid="bib48">Koemans et al., 2017</xref>). Setting up some aggression assays (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib23">Dierick, 2007</xref>) also requires coating chambers with fluon to prevent flies from walking on the walls, which is labor-intensive.</p><p>To provide a low-cost, easy-to-assemble alternative, we developed the DANCE hardware (<xref ref-type="fig" rid="fig6">Figure 6</xref>), an inexpensive, scalable, and robust system for recording <italic>Drosophila</italic> aggression and courtship behaviors.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title><italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) hardware and recording setup.</title><p>(<bold>A</bold>) DANCE aggression setup. (<bold>B</bold>) 3D-rendered components of the aggression setup. (<bold>C</bold>) DANCE courtship setup. (<bold>D</bold>) 3D-rendered components of the courtship setup, showing males and females separated by an X-ray film separator or ‘divider comb’. (<bold>E–G</bold>) Top and side views of the DANCE setup with a smartphone camera for recording and an electronic tablet as the backlight. Created in <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/rv0eefi">BioRender</ext-link>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig6-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-105465-fig6-video1.mp4" id="fig6video1"><label>Figure 6—video 1.</label><caption><title>3D-rendered <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) aggression hardware.</title></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-105465-fig6-video2.mp4" id="fig6video2"><label>Figure 6—video 2.</label><caption><title>Using the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) hardware setup for recording aggression.</title></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-105465-fig6-video3.mp4" id="fig6video3"><label>Figure 6—video 3.</label><caption><title>3D-rendered <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) courtship hardware.</title></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-105465-fig6-video4.mp4" id="fig6video4"><label>Figure 6—video 4.</label><caption><title>Using the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) hardware setup for recording courtship.</title></caption></media></fig-group><p>The DANCE hardware consists of readily available off-the-shelf components, including transparent medicine blister packs (tablet foils) used as recording chambers, which are mounted on 2 mm acrylic base plates and secured with paper tape (<xref ref-type="fig" rid="fig6">Figure 6A–D</xref>, <xref ref-type="video" rid="fig6video1 fig6video2">Figure 6—video 1; Figure 6—video 2</xref>). Instead of using machine-vision cameras, DANCE employs widely available Android smartphones for recording and substitutes backlights with tablets or smartphones displaying a white screen to provide uniform illumination (<xref ref-type="fig" rid="fig6">Figure 6E–G</xref>). Aggression and courtship behaviors were recorded at 30 fps and 1080p resolution.</p><p>For the aggression assays (<xref ref-type="fig" rid="fig6">Figure 6A–B and E</xref>), the blister foil was slid over a base plate containing an apple‒juice agar food layer, which served as the interaction arena (<xref ref-type="video" rid="fig6video1 fig6video2">Figure 6—video 1; Figure 6—video 2</xref>). For courtship assays, the blister foil was bisected and fitted with a thin X-ray film separator comb that kept males and females apart until the start of recording, when the comb was removed to allow interaction (<xref ref-type="video" rid="fig6video3 fig6video4">Figure 6—video 3; Figure 6—video 4</xref>). Because the tablet or smartphone screens used as the backlight generate heat, we placed a transparent acrylic spacer above the backlight to create a 4 mm air gap for heat dissipation (<xref ref-type="fig" rid="fig6">Figure 6E–G</xref>; <xref ref-type="video" rid="fig6video2 fig6video4">Figure 6—video 2; Figure 6—video 4</xref>). This modification was essential for maintaining consistent behavioral recordings (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Benchmarking <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) hardware and application to neurogenetic tools.</title><p>(<bold>A–B</bold>) Courtship behaviors recorded using a pre-existing circular setup (<xref ref-type="bibr" rid="bib48">Koemans et al., 2017</xref>) and DANCE setup in group-housed (GH) and single-housed (SH) flies for (<bold>C–D</bold>) wing extension, (<bold>C</bold>) GH vs. SH ***p&lt;0.0010, n=23; (<bold>D</bold>) GH vs. SH ****p&lt;0.0001, GH, n=22 and SH, n=33. (<bold>E–F</bold>) Attempted copulation, (<bold>E</bold>) GH vs. SH ***p&lt;0.0002, n=23; (<bold>F</bold>) GH vs. SH **p&lt;0.0022, GH, n=21 and SH, n=33. (<bold>G–H</bold>) Following, (<bold>G</bold>) GH vs. SH ns, p&gt;0.0959, n=23; (<bold>H</bold>) GH vs. SH ns, p&lt;0.2537, GH, n=22 and SH, n=32. (<bold>I–J</bold>) Circling, (<bold>I</bold>) GH vs. SH *p&lt;0.012, n=23; (<bold>J</bold>) GH vs. SH *p&lt;0.0104, GH, n=24 and SH, n=31. (<bold>K–L</bold>) Aggressive lunges were recorded using a pre-existing circular setup (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>) and a DANCE setup. (M‒N) Lunges of SH flies compared with those of GH flies reared on food with yeast granules. (<bold>M</bold>) GH vs. SH **p&lt;0.0138, n=36; (<bold>N</bold>) GH vs. SH **p&lt;0.0372, n=40. (<bold>O</bold>) Effect of yeast extract food on aggressive behavior; GH vs. SH ****p&lt;0.0001, n=38–39. (<bold>P–Q</bold>) Genetic knockdown of the neuropeptide Drosulfakinin (Dsk) in insulin-producing neurons using <italic>dilp2-</italic>GAL4. (<bold>P</bold>) <italic>Dilp2-GAL4</italic>-GAL4&gt;attp2 GH vs. SH ns, p&lt;0.0502; <italic>Dilp2-GAL4</italic>-GAL4&gt;attp2 GH vs. <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi GH ns, p&gt;0.9999; <italic>Dilp2-GAL4</italic>-GAL4&gt;attp2 SH vs. <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi SH ****p&lt;0.0001; <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi SH vs. <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi SH ****p&lt;0.0001; n=24. (<bold>Q</bold>) <italic>Dilp2-GAL4</italic>-GAL4&gt;attp2 GH vs. SH ****p&lt;0.0001, <italic>Dilp2-GAL4</italic>-GAL4&gt;attp2 GH vs. <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi GH ns, p&gt;0.9999, <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi SH vs. <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi SH ****p&lt;0.0001, <italic>Dilp2-GAL4</italic>-GAL4&gt;attp2 SH vs. <italic>Dilp2-GAL4</italic>-GAL4&gt;<italic>Dsk</italic> RNAi SH *p&gt;0.0210, n=24. (<bold>R</bold>) Optogenetic silencing of dopaminergic neurons with <italic>UAS-GtACR1</italic> driven by the <italic>TH</italic>-GAL4 driver; <italic>UAS-GtACR1</italic> SH vs. GH ns, p=0.0986; <italic>TH-GAL4</italic> SH vs. GH ns, p=0.9999; <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH vs. GH ****p&lt;0.0001; <italic>UAS-GtACR1</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH **p&lt;0.0012; <italic>TH-GAL4</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH **p&lt;0.0013; n=21–24. (C‒J and M‒O) Mann‒Whitney U test; (P‒R) Kruskal‒Wallis test with Dunn’s multiple comparisons.</p><p><supplementary-material id="fig7sdata1"><label>Figure 7—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig7">Figure 7</xref> showing for quantitative behavioral counts across aggression and courtship assays used to benchmark DANCE hardware and neurogenetic manipulations.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig7-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title><italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) optogenetic recording setup for behavioral experiments.</title><p>(<bold>A</bold>) Schematic of the setup showing green LEDs (520–540 nm) controlled by an Arduino and powered via a PC, with illumination directed onto blister-pack arenas placed on an electronic tablet. The tablet provides an adjustable backlight via screen-light software and a smartphone camera records behavior. (<bold>B</bold>) Photograph of the complete setup, showing the smartphone, tablet, LED stands, Arduino controller, and arenas under green LED illumination. Created in <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/bztoh8y">BioRender</ext-link>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Effect of optogenetic silencing of dopaminergic neurons on daytime activity.</title><p>(<bold>A–B</bold>) Transient silencing of dopaminergic neurons using <italic>UAS-GtACR1</italic> did not affect daytime activity between single-housing (SH) and group-housed (GH) flies. (<bold>A</bold>) On day 1 (no green-light silencing), one-way ANOVA with Tukey’s multiple comparisons revealed no differences for <italic>TH-GAL4</italic> (ns, p=0.7383; GH, n=43; SH, n=43), <italic>UAS-GtACR1</italic> (ns, p=0.4812; GH, n=51; SH, n=42), and <italic>TH-GAL4&gt;UAS-GtACR1</italic> (ns, p=0.9942; GH, n=54; SH, n=51). (<bold>B</bold>) On day 2 (with green-light silencing), no differences were observed for <italic>TH-GAL4</italic> (ns, p=0.9976; GH, n=43; SH, n=43), <italic>UAS-GtACR1</italic> (ns, p=0.9779; GH, n=51; SH, n=42), and <italic>TH-GAL4&gt;UAS-GtACR1</italic> (ns, p=0.9974; GH, n=54; SH, n=51). Two-way ANOVA across days revealed no significant interaction or main effects for <italic>TH-GAL4</italic> (interaction: ns, p=0.5504; silencing: ns, p=0.5172; housing: ns, p=0.1602), <italic>UAS-GtACR1</italic> (interaction: ns, p=0.4533; silencing: ns, p=0.3602; housing: p=0.255; GH, n=51; SH, n=42), or <italic>TH-GAL4&gt;UAS-GtACR1</italic> (interaction: ns, p=0.9977; silencing: ns, p=0.2454; housing: ns, p=0.5868). Within-day comparisons were performed using one-way ANOVA with Tukey’s multiple comparisons; across-day comparisons were performed using two-way ANOVA.</p><p><supplementary-material id="fig7s2sdata1"><label>Figure 7—figure supplement 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref> showing daytime activity counts across days and housing conditions during optogenetic silencing of dopaminergic neurons.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig7-figsupp2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig7-figsupp2-v1.tif"/></fig><fig id="fig7s3" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 3.</label><caption><title>Effect of optogenetic silencing of dopaminergic neurons on male aggression across arena sizes.</title><p>(<bold>A–C</bold>) Number of lunges performed in 20 min by <italic>TH-GAL4&gt;UAS-GtACR1</italic> males tested in arenas of different diameters: (<bold>A</bold>) 13 mm (n=29–38), <italic>UAS-GtACR1</italic> SH vs. GH ns, p=0.9741; <italic>TH-GAL4</italic> SH vs. GH ns, p=0.9866; <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH vs. GH ****p&lt;0.0001; <italic>UAS-GtACR1</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH ****p&lt;0.0001; <italic>TH-GAL4</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH ****p&lt;0.0001. (<bold>B</bold>) 17 mm (n=27–32), <italic>UAS-GtACR1</italic> SH vs. GH ns, p=0.9807; <italic>TH-GAL4</italic> SH vs. GH ns, p=0.8195; <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH vs. GH ****p&lt;0.0001; <italic>UAS-GtACR1</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH ****p&lt;0.0001; <italic>TH-GAL4</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH ****p&lt;0.0001. (<bold>C</bold>) 21 mm (n=12–16), <italic>UAS-GtACR1</italic> SH vs. GH ns, p=0.9981; <italic>TH-GAL4</italic> SH vs. GH ns, p=0.9999; <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH vs. GH ****p&lt;0.0001; <italic>UAS-GtACR1</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH ****p&lt;0.0001; <italic>TH-GAL4</italic> SH vs. <italic>TH-GAL4&gt;UAS-GtACR1</italic> SH ****p&lt;0.0001. Lunges of flies with <italic>GtACR1</italic>-mediated silencing were significantly greater than those of GH and control flies across all arena sizes. Statistical comparisons are indicated: ****p&lt;0.0001; ns, not significant; ordinary one-way ANOVA followed by Tukey’s multiple comparisons test.</p><p><supplementary-material id="fig7s3sdata1"><label>Figure 7—figure supplement 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5s3">Figure 7—figure supplement 3</xref> showing aggressive lunge counts during optogenetic silencing of dopaminergic neurons across different arena sizes.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig7-figsupp3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig7-figsupp3-v1.tif"/></fig><fig id="fig7s4" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 4.</label><caption><title>Quantification of wild-type <italic>Drosophila</italic> courtship behavior in <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) chambers of varying diameters.</title><p>(<bold>A–C</bold>) Wing extension bouts (<bold>A</bold>: n=22, 33, ****p&lt;0.0001; <bold>B</bold>: n=25, 28, ****p&lt;0.0001; <bold>C</bold>: n=20, 25, ****p&lt;0.0001). (<bold>D–F</bold>) Attempted copulation bouts (D: n=21, 33, **p&lt;0.0022; E: n=25, 28, ****p&lt;0.0001; F: n=20, 25, ****p&lt;0.0001). (<bold>G–I</bold>) Following bouts (<bold>G</bold>: n=22, 32, ns, nonsignificant p&gt;0.2537; <bold>H</bold>: n=25, 28, ns, nonsignificant p&gt;0.7917; <bold>I</bold>: n=21, 24, ns, nonsignificant p&gt;0.0705). (<bold>J–L</bold>) Circling bouts (<bold>J</bold>: n=24, 31, *p&lt;0.0104; <bold>K</bold>: n=26, 24, **p&lt;0.0048; <bold>L</bold>: n=18, 23, **p&lt;0.0032). Data were obtained from Canton-S (CS) males paired with either group-housed (GH) or single-housed (SH) females over 15 min in chambers of 11 mm, 13 mm, or 17 mm diameter. Each bar represents the median. Statistical differences are indicated as *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001, ****p&lt;0.0001; ns, not significant (Mann–Whitney U test).</p><p><supplementary-material id="fig7s4sdata1"><label>Figure 7—figure supplement 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig7s4">Figure 7—figure supplement 4</xref> showing behavioral counts across multiple courtship behaviors in wild-type Drosophila measured in arenas of different sizes.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105465-fig7-figsupp4-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105465-fig7-figsupp4-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-105465-fig7-video1.mp4" id="fig7video1"><label>Figure 7—video 1.</label><caption><title>Aggression and courtship behaviors recorded in <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) hardware.</title></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-105465-fig7-video2.mp4" id="fig7video2"><label>Figure 7—video 2.</label><caption><title>Optogenetic silencing of dopaminergic neurons in <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) shows increased aggression.</title></caption></media></fig-group><p>The DANCE hardware is intentionally modular, allowing users to adapt the setup to their experimental needs. The detailed assembly, cleaning, and reuse protocols are provided in the Materials and methods and on the GitHub page of the project.</p></sec><sec id="s2-9"><title>Benchmarking DANCE hardware</title><p>We benchmarked the DANCE hardware by applying the validated DANCE classifiers to videos recorded in the DANCE setup and comparing the results with those from established recording systems. Wild-type males displayed quantitatively similar levels of courtship and aggression in DANCE arenas and in pre-existing setups (<xref ref-type="fig" rid="fig7">Figure 7</xref>; <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>).</p><p>To test whether DANCE reproduces established behavioral findings, we examined the effects of social isolation and enrichment on aggression and courtship. Previous studies have shown that single-housing (SH) increases courtship attempts (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib46">Kim and Ehrman, 1998</xref>; <xref ref-type="bibr" rid="bib59">Pan and Baker, 2014</xref>) and promotes aggression (<xref ref-type="bibr" rid="bib1">Agrawal et al., 2020</xref>; <xref ref-type="bibr" rid="bib78">Wang et al., 2008</xref>; <xref ref-type="bibr" rid="bib81">Yadav et al., 2024</xref>). We found that both the DANCE and pre-existing setups captured similar and statistically significant differences in courtship behaviors between SH and group-housed (GH) males (<xref ref-type="fig" rid="fig7">Figure 7C–J</xref>). These results confirm that DANCE reliably detects behavioral modulation by social experience.</p><p>We next compared an established aggression assay (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="fig" rid="fig7">Figure 7K</xref>) with the DANCE aggression setup (<xref ref-type="fig" rid="fig7">Figure 7L</xref>). Both systems detected aggressive lunges in SH flies and showed consistent differences between SH and GH conditions (<xref ref-type="fig" rid="fig7">Figure 7M–N</xref>). Thus, DANCE hardware provides comparable sensitivity to conventional machine-vision-based setups while being more accessible.</p><p>We also tested whether diet composition alters aggression in DANCE assays, as nutrient availability and microbiome interactions can influence male aggression (<xref ref-type="bibr" rid="bib42">Jia et al., 2021</xref>; <xref ref-type="bibr" rid="bib51">Lim et al., 2014</xref>). Replacing yeast granules in the diet with yeast extract powder reduced baseline aggression (<xref ref-type="fig" rid="fig7">Figure 7O</xref>). These findings demonstrate that the DANCE hardware is sensitive enough to detect diet-dependent behavioral differences.</p><p>To test whether DANCE is compatible with neurogenetic manipulations, we used RNAi-mediated knockdown of the neuropeptide Drosulfakinin (Dsk) in insulin-producing neurons using the <italic>dilp2-</italic>GAL4 driver. Consistent with our previous findings (<xref ref-type="bibr" rid="bib1">Agrawal et al., 2020</xref>), SH males with Dsk knockdown exhibited significantly increased aggressive lunges compared to controls (<xref ref-type="fig" rid="fig7">Figure 7P and Q</xref>).</p><p>We then evaluated DANCE’s suitability for optogenetic assays, a common approach to dissect neural circuits underlying aggression (<xref ref-type="bibr" rid="bib38">Hoopfer et al., 2015</xref>; <xref ref-type="bibr" rid="bib80">Wohl et al., 2023</xref>; <xref ref-type="bibr" rid="bib81">Yadav et al., 2024</xref>). An earlier study has shown that constitutive silencing of broad populations of dopaminergic neurons using <italic>TH-</italic>GAL4 produces unhealthy flies with impaired locomotion that rarely fight (<xref ref-type="bibr" rid="bib2">Alekseyenko et al., 2013</xref>). We reasoned that transient, light-controlled silencing could overcome these limitations and tested this using an optogenetic module integrated with DANCE (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1A and B</xref>; DANCE GitHub).</p><p>Optogenetic silencing of dopaminergic neurons expressing the green-light-sensitive anion channelrhodopsin GtACR1 (<xref ref-type="bibr" rid="bib31">Govorunova et al., 2015</xref>; <xref ref-type="bibr" rid="bib56">Mohammad et al., 2017</xref>) during 20 min interactions resulted in a significant increase in aggressive lunges in SH flies (<xref ref-type="fig" rid="fig7">Figure 7R</xref>). In addition, we observed higher frequencies of wing flicks and high-intensity aggressive behaviors such as boxing and tussling (<xref ref-type="video" rid="fig7video2">Figure 7—video 2</xref>). Importantly, continuous silencing for 12 hr did not alter general locomotor activity between the GH and SH flies (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>), confirming that these effects were not due to impaired movement.</p><p>We also examined whether arena size influenced behavior. <italic>TH-</italic>GAL4&gt;<italic>UAS-GtACR1</italic> males showed increased lunging vs. controls across all sizes tested (13, 17, and 21 mm; <xref ref-type="fig" rid="fig7s3">Figure 7—figure supplement 3A–C</xref>), indicating the optogenetic effect was robust to chamber dimensions. In courtship assays (11, 13, and 17 mm arenas; <xref ref-type="fig" rid="fig7s4">Figure 7—figure supplement 4A–L</xref>), single-housed males exhibited more wing extension, attempted copulation, and circling than group-housed males, while following was similar. Although statistical tests were limited to within-size comparisons, the distributions suggest a modest decrease in interaction frequency in larger arenas, consistent with previous observations that larger chambers reduce encounter rates (<xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>).</p><p>Taken together, these results show that DANCE hardware provides reliable, reproducible behavioral measurements and is compatible with genetic and optogenetic manipulations, as well as environmental perturbations.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here, we present the DANCE assay, an easy-to-use, modular, and robust analysis pipeline with inexpensive hardware to record and quantify aggression and courtship behaviors. We developed six novel behavioral classifiers using supervised machine learning to accurately quantify the aggression and courtship behaviors of <italic>Drosophila</italic> males. The hardware component of DANCE, fabricated from repurposed and low-cost materials, provides a practical alternative to conventional machine-vision setups. The DANCE setup can be built for less than 0.30 USD, representing an approximately 10,000-fold reduction in cost compared with standard systems. Despite this simplicity, its performance was comparable to that of more specialized and expensive hardware, validating DANCE as a reliable and accessible behavioral platform. This accessibility enables rapid behavioral screening and wider adoption by the neuroscience community, including resource-limited laboratories and teaching environments.</p><p>Various components of the DANCE assay, such as the behavioral classifiers, hardware design, and analysis code, are publicly available and can be used independently. This open, modular design gives researchers the flexibility to customize classifiers for specific behavioral paradigms or incorporate new data without developing a classifier from scratch. Although not implemented here, DANCE can be readily extended to real-time feedback experiments using open-source reactive programming tools such as Bonsai (<xref ref-type="bibr" rid="bib52">Lopes et al., 2015</xref>). This framework can also support the development of future classifiers for additional social behaviors, including aggressive acts such as fencing, wing flicking, tussling, chasing, or female headbutting (<xref ref-type="bibr" rid="bib13">Chen et al., 2002</xref>; <xref ref-type="bibr" rid="bib57">Nilsen et al., 2004</xref>), and courtship behaviors such as male tapping, licking, or female rejection (<xref ref-type="bibr" rid="bib69">Sokolowski, 2001</xref>).</p><p>Such high-resolution analysis of complex social interactions can provide deeper understanding of mating dynamics, sexual selection, and the influence of genetics and evolution. Further, quantifying behavioral dynamics can reveal the temporal organization of individual components of behavior (<xref ref-type="bibr" rid="bib57">Nilsen et al., 2004</xref>; <xref ref-type="bibr" rid="bib66">Seeds et al., 2014</xref>; <xref ref-type="bibr" rid="bib68">Simon and Heberlein, 2020</xref>; <xref ref-type="bibr" rid="bib82">Zhang et al., 2020</xref>). DANCE can also serve as a flexible framework for studying complex behaviors across multiple <italic>Drosophila</italic> species and other insects, enabling comparative and evolutionary analyses. The adaptability and portability of the DANCE assay make it particularly useful for ethologists examining insect behavior in seminatural or field-like environments. Together, these features position DANCE as a bridge between laboratory-based ethology and ecological studies of natural behavior.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Reagent type (species) or resource</th><th align="left" valign="top">Designation</th><th align="left" valign="top">Source or reference</th><th align="left" valign="top">Identifiers</th><th align="left" valign="top">Additional information</th></tr></thead><tbody><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Sigmacote</td><td align="left" valign="top">Sigma-Aldrich</td><td align="left" valign="top">Cat#: SL2</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Alcojet</td><td align="left" valign="top">Alconox</td><td align="left" valign="top">Cat#: 1401-1</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Sucrose</td><td align="left" valign="top">HiMedia</td><td align="left" valign="top">Cat#: GRM601</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Agar</td><td align="left" valign="top">HiMedia</td><td align="left" valign="top">Cat#: GRM026</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Yeast extract powder</td><td align="left" valign="top">HiMedia</td><td align="left" valign="top">Cat#: RM0271</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Yeast granules</td><td align="left" valign="top">AB Mauri, India</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Apple juice</td><td align="left" valign="top">Commercial</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Chemical compound, drug</td><td align="left" valign="top">Fluon (Insect-a-Slip)</td><td align="left" valign="top">BioQuip</td><td align="left" valign="top">Cat#: 2871B</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Strain, strain background (<italic>Drosophila melanogaster</italic>, male)</td><td align="left" valign="top">Canton-S</td><td align="left" valign="top">Ulrike Heberlein (HHMI Janelia)</td><td align="left" valign="top"/><td align="left" valign="top">Wild-type strain</td></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top"><italic>TH-</italic>GAL4</td><td align="left" valign="top">Bloomington Drosophila Stock Center</td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_51982">BDSC_51982</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top"><italic>dilp2-</italic>GAL4</td><td align="left" valign="top">Bloomington Drosophila Stock Center</td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_37516">BDSC_37516</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top"><italic>Dsk-RNAi</italic></td><td align="left" valign="top">Bloomington Drosophila Stock Center</td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_25869">BDSC_25869</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">attP2 empty vector control</td><td align="left" valign="top">Bloomington Drosophila Stock Center</td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_36303">BDSC_36303</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top"><italic>UAS-GtACR1</italic></td><td align="left" valign="top"><xref ref-type="bibr" rid="bib56">Mohammad et al., 2017</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_92983">BDSC_92983</ext-link></td><td align="left" valign="top">Gift from Gaurav Das, (NCCS, Pune)</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">JAABA</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_027430">SCR_027430</ext-link></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://jaaba.sourceforge.net/">https://jaaba.sourceforge.net/</ext-link></td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">Caltech FlyTracker</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib26">Eyjolfsdottir et al., 2014</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_027431">SCR_027431</ext-link></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://kristinbranson.github.io/FlyTracker/">https://kristinbranson.github.io/FlyTracker/</ext-link></td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">MateBook</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref></td><td align="left" valign="top"/><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/Dicksonlab/MateBook">https://github.com/Dicksonlab/MateBook</ext-link></td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">CADABRA</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref></td><td align="left" valign="top"/><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.vision.caltech.edu/cadabra/">https://www.vision.caltech.edu/cadabra/</ext-link></td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">GraphPad Prism 8</td><td align="left" valign="top">GraphPad Software</td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_002798">SCR_002798</ext-link></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="http://www.graphpad.com/">http://www.graphpad.com/</ext-link></td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">DANCE classifiers and code</td><td align="left" valign="top">This paper</td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_027812">SCR_027812</ext-link></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/agrawallab/DANCE">https://github.com/agrawallab/DANCE</ext-link></td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">BioRender</td><td align="left" valign="bottom">BioRender Software</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_018361">SCR_018361</ext-link></td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.biorender.com/">https://www.biorender.com/</ext-link></td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Inkscape</td><td align="left" valign="bottom">Inkscape Software</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_014479">SCR_014479</ext-link></td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://github.com/inkscape/inkscape">https://github.com/inkscape/inkscape</ext-link></td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">LEDs (520–540 nm)</td><td align="left" valign="top">Lumileds, SM Electronic Technologies Pvt Ltd. Bangalore</td><td align="left" valign="top">Model: 2835</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">DMK 33UX252 USB 3.0 monochrome camera</td><td align="left" valign="top">Menzel Vision and Robotics Pvt Ltd. Mumbai</td><td align="left" valign="top">Model: DMK 33UX252</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">Metaphase backlight</td><td align="left" valign="top">Alpha Techsys, Pune</td><td align="left" valign="top">Model: TMS, BHS4-00100-X-W-24V</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">Huawei Y9 2019 smartphone</td><td align="left" valign="top">Huawei</td><td align="left" valign="top">Model: Y9 2019</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">OnePlus Nord CE 2 Lite 5G smartphone</td><td align="left" valign="top">OnePlus</td><td align="left" valign="top">Model: CPH2381</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">Redmi Note 11 Pro+ 5G smartphone</td><td align="left" valign="top">Xiaomi</td><td align="left" valign="top">Model: 221116SI</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">iPad Air (5th Generation)</td><td align="left" valign="top">Apple</td><td align="left" valign="top">Model: iPad Air 5</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">iPhone 13</td><td align="left" valign="top">Apple</td><td align="left" valign="top">Model: 13</td><td align="left" valign="top">Hardware and equipment</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">White-screen light app</td><td align="left" valign="top">App Store/Play Store</td><td align="left" valign="top"/><td align="left" valign="top">Hardware and equipment</td></tr></tbody></table></table-wrap><p>The details of all the custom codes, analysis pipelines, sample files used to run the analysis and DANCE classifiers are available in our GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/agrawallab/DANCE">https://github.com/agrawallab/DANCE</ext-link>, copy archived at <xref ref-type="bibr" rid="bib21">Dey and Agrawal, 2025</xref>.</p><sec id="s4-1"><title>Fly husbandry</title><p>Flies were reared on standard food at 25°C and 65% relative humidity with a 12 hr:12 hr light‒dark cycle. All the assays were performed at 25°C with 65% relative humidity, unless mentioned otherwise. For the aggression and courtship experiments, Canton-S (CS) male flies were collected within 24 hr of eclosion and housed in groups (20 male flies per vial, 90 mm in length and 25 mm in diameter) or isolated (1 male fly per vial, 70 mm in length and 10 mm in diameter) for 6 days. Randomization was not performed for behavioral experiments because flies were grouped by genotype and housing condition, and all cohorts were handled identically.</p><p>The following fly lines were acquired from the Bloomington Drosophila Stock Center (BDSC), USA: <italic>TH</italic>-GAL4 (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_51982">BDSC_51982</ext-link>), <italic>Dilp2-</italic>GAL4 (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_37516">BDSC_37516</ext-link>), <italic>Dsk</italic>-RNAi (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_25869">BDSC_25869</ext-link>), and attP2 empty vector control (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:BDSC_36303">BDSC_36303</ext-link>). <italic>UAS-GtACR1</italic> flies were a gift from Gaurav Das, NCCS, Pune, India, and CS flies were obtained from Ulrike Heberlein, HHMI, Janelia Research Campus, Ashburn, VA, USA.</p></sec><sec id="s4-2"><title>Aggression assay</title><p>Aggression assays were performed as described previously (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib23">Dierick, 2007</xref>). In brief, the behavioral chamber is made up of 12 well-aggressive arenas (10 mm in height and 16 mm in diameter/arena). These arenas were covered by a sliding lid with 2 mm loading holes to facilitate the introduction of flies. A pair of male flies that were housed either as GH or SH was introduced into the arena wells by gentle mouth aspiration through the loading holes. After the flies were loaded, the sliding lid was tightened with screws. Fluon (Insect-a-slip, Bioquip: Cat#: 2871B) was applied to the arena walls, which were left to dry overnight to create a slippery surface and prevent climbing. Sigmacote (Sigma-Aldrich: SL2) was used to coat the sliding lid to reduce walking on the arena ceiling. The chamber was placed on a food plate containing commercial apple juice (without added sugars), 2.5% wt/vol sucrose (HiMedia: GRM601), and 2.25% wt/vol agar (HiMedia: GRM026). For experiments to test the effects of fly food nutrients, either 2.4% yeast extract powder (HiMedia: RM0271) or 2.4% yeast granules (Prime Instant Dry Yeast, AB Maury, India) were mixed in the fly food. Optogenetic experiments were performed essentially as described earlier (<xref ref-type="bibr" rid="bib31">Govorunova et al., 2015</xref>; <xref ref-type="bibr" rid="bib56">Mohammad et al., 2017</xref>). LEDs emitting 520–540 nm light, peak emission 530 nm (Lumileds: High Power LEDs—single color: L128-GRN1003500000) were controlled via an Arduino microcontroller and powered through a computer to deliver illumination onto the blister-pack arenas. The LEDs were used at an intensity of 0.0004 µW, which was measured with a power meter (Newport: 843R). For all the aggression assays, the flies were allowed to acclimatize in the arena for 5 min, after which the activity was recorded for 20 min. The assays were performed during ZT0–ZT2.5, i.e., during the first 2.5 hr of the morning activity peak.</p></sec><sec id="s4-3"><title>Courtship assay</title><p>Courtship assays were performed as described previously (<xref ref-type="bibr" rid="bib48">Koemans et al., 2017</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>). Single pairs of males and females were introduced into individual arenas of an 18-well courtship chamber (10 mm diameter). Male and female flies were introduced into one half of the chamber by sliding entry holes with a removable separator that divided the chamber into two halves. The flies were allowed to acclimatize to the arena for 5 min, after which the separator was removed, and courtship behavior was recorded for 15 min at 30 fps using a white backlight. The assay was performed from ZT0 to ZT3 or ZT9 to ZT12 (during peak activity windows). For mated females, 20 females were housed with 10 males for 4–6 days. For decapitated virgin females, 2- to 4-day-old virgins were anesthetized with CO<sub>2</sub> and decapitated immediately before the assay.</p></sec><sec id="s4-4"><title>DANCE hardware</title><p>Circular transparent medicine blister packs serve as aggression or courtship arenas. Blister packs were mounted on 2 mm acrylic base plates and secured with paper tape. The arena dimensions were as follows: aggression, 13 mm × 5.5 mm (diameter ×height) (also tested: 17 mm×4 mm and 21 mm×8 mm); courtship, 11 mm × 4.5 mm (also tested: 13 mm×5.5 mm and 17 mm×4 mm). Arena walls and roofs were coated with Sigmacote (Sigma-Aldrich: SL2) using cotton swabs (Solimo, Amazon India) to prevent flies from climbing.</p><p>A thin 2 mm acrylic base plate carrying the food layer (2.25% wt/vol agar in commercial apple juice with 2.5% wt/vol sucrose) and a side spacer were assembled and held together with paper tape (<xref ref-type="video" rid="fig6video1">Figure 6—video 1</xref>). The tip of the food plate was covered with paper tape to allow smooth sliding of the blister foil without damaging the food surface. Flies were introduced through loading holes (2 mm diameter), and paper tape strips were used to prevent food damage during assembly and to seal small gaps to avoid escape (<xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>).</p><p>Arenas were reusable for approximately 30–40 times when washed in 0.05% Alcojet (Alconox: 1401-1) and air-dried. Heat exposure during cleaning was avoided to prevent deformation.</p><p>The standard DANCE courtship arena used transparent medicine blister packs measuring 11 mm in diameter and 4.5 mm in height. Additional arena sizes of 13 mm×5.5 mm and 17 mm×4 mm (diameter × height) were also tested. The top surface of each arena strip (five wells in a row) was modified by cutting thin slits with a sharp razor to insert a separator comb made from repurposed X-ray film. The foil and 2 mm acrylic base plate, which contained a loading hole (2 mm diameter), were joined with paper tape. The courtship base plate contained two loading holes so that male and female flies could be introduced on either side of the separator comb. The assembly was sealed at both ends with paper tape to prevent gaps from escaping (<xref ref-type="video" rid="fig6video3">Figure 6—video 3</xref>).</p><p>Before recording, the separator comb was gently lifted to allow interaction between the flies, taking care to keep the slit edges intact and avoid distortion during filming (<xref ref-type="video" rid="fig6video4">Figure 6—video 4</xref>). Blister packs modified with slits and separator combs are typically reusable for ~10–15 experiments, after which the slits tend to widen, and new blister packs are recommended.</p></sec><sec id="s4-5"><title>Video acquisition</title><p>For the traditional setup, the interaction of the flies was recorded using machine-vision cameras (DMK 33UX252 USB 3.0 monochrome camera). White backlight (TMS, BHS4-00-100-X-W-24V) provided the light source for both the courtship and aggression experiments. Videos were recorded at 30 frames per second (fps) for 15 min for courtship or 20 min for aggression in H.264 (.mp4) format with 1440×1080 resolution. These videos were used for training, testing, and validating the DANCE classifiers.</p><p>For DANCE hardware testing, various Android smartphone cameras were used (Huawei Y9 2019; OnePlus Nord CE 2 Lite 5G, model: CPH2381; Redmi Note 11 Pro+ 5G, model: 221116SI) at 30 fps, 1080p resolution in H.264 (.mp4) format for 15 min (courtship) or 20 min (aggression). An electronic tablet (iPad Air, 5th Generation) or smartphone (iPhone 13) running a ‘white screen light app’ served as the background illumination source. The screen brightness was adjusted within the app to optimize contrast for fly tracking. A transparent acrylic sheet with 4 mm spacers was kept on top of this ‘backlight’ to create an air gap to ensure heat exchange and prevent the DANCE arenas from becoming hot. Devices were recommended to be placed in airplane mode during recordings to avoid interruptions.</p></sec><sec id="s4-6"><title>Tracking flies using FlyTracker</title><p>Fly locations, body orientations, and interactions were tracked using Caltech FlyTracker (<xref ref-type="bibr" rid="bib26">Eyjolfsdottir et al., 2014</xref>). These data were then pushed to the JAABA pipeline to develop DANCE classifiers. Occurrences of identity switches were corrected using the FlyTracker ‘visualizer’ identity-correction tool. Tracking accuracy and identity swap quantification were validated by a semi-manual inspection of flagged frames and intervals (see <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref> for details).</p></sec><sec id="s4-7"><title>Pre-existing algorithms used for benchmarking</title><sec id="s4-7-1"><title>CADABRA</title><p>CADABRA (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>) analyzes two-fly interactions based on spatial and postural features, classifying lunges, wing threats, circling, wing extension, and copulation based on fixed rules. The specific CADABRA definitions are described in the subsequent section.</p></sec><sec id="s4-7-2"><title>Divider assay</title><p>The Divider assay (<xref ref-type="bibr" rid="bib15">Chowdhury et al., 2021</xref>) uses a 3D-printed rectangular chamber with 12 arenas (13 mm × 4.5 mm, W×H), each separated by an opaque divider. Behavioral data are analyzed with a custom FlyTracker-JAABA pipeline. Since the Divider assay classifier was trained on recordings from a rectangular geometry, it can affect transferability to circular arenas.</p></sec><sec id="s4-7-3"><title>MateBook</title><p>MateBook (<xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/Dicksonlab/MateBook">https://github.com/Dicksonlab/MateBook</ext-link> copy archived at <xref ref-type="bibr" rid="bib4">Arthur, 2025</xref>) uses machine vision to track flies and classify male courtship behaviors (following, wing extension, orientation, copulation, and circling). The outputs include a .tsv file with bout statistics and an ethogram. For comparison with the DANCE classifiers, the MateBook persistence filters were adjusted so that the minimum bout duration threshold was 0.33 s (10 frames at 30 fps) for all behaviors except copulation, which retained a 45 s threshold. This adjustment ensured comparable persistence criteria between the MateBook and DANCE analyses.</p></sec><sec id="s4-7-4"><title>Developing DANCE classifiers</title><p>JAABA (<xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref>) was used to train classifiers iteratively: true bouts were labeled, obvious non-bouts assigned as ‘None’, and false positives were relabeled until performance plateaued.</p><p>The DANCE lunge classifier was trained on 11 independent videos with classifier accuracy improving progressively from Video 1 to Video 9. Peak performance was achieved after inclusion of the ninth training video<bold>,</bold> which provided the best balance of precision, recall, and F1 score. Adding further data (Videos 10 and 11) did not enhance classifier accuracy and instead produced a slight reduction in precision and recall, likely due to increased behavioral variability across sessions. Therefore, the final lunge classifier was trained on nine videos, which yielded the most robust and generalizable model.</p><p>Courtship classifiers were developed following the same iterative procedure. Training sets included videos with both decapitated and intact females (mated or virgin) to capture behavioral variability and ensure robust generalization. Independent classifiers were trained for wing extension, following, circling, attempted copulation, and copulation. All classifiers were validated using manually annotated ‘ground-truth’ test videos that were not included in the training set.</p><p>Courtship training sets included decapitated virgin videos to enrich attempted copulation and circling bouts and to balance ‘None’ class examples for following and copulation. Wing extension used mated females only.</p><p>The training data volumes (frames and approximate durations) were as follows:</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Behavior</th><th align="left" valign="bottom">Frames</th><th align="left" valign="bottom">Approx. duration (s)</th></tr></thead><tbody><tr><td align="left" valign="top">Lunge</td><td align="left" valign="top">1449</td><td align="left" valign="top">~48</td></tr><tr><td align="left" valign="top">Wing extension</td><td align="char" char="." valign="top">99,947</td><td align="left" valign="top">~3332</td></tr><tr><td align="left" valign="top">Attempted copulation</td><td align="char" char="." valign="top">39,513</td><td align="left" valign="top">~1317</td></tr><tr><td align="left" valign="top">Copulation</td><td align="char" char="." valign="top">56,979</td><td align="left" valign="top">~1899</td></tr><tr><td align="left" valign="top">Circling</td><td align="char" char="." valign="top">14,396</td><td align="left" valign="top">~480</td></tr><tr><td align="left" valign="top">Following</td><td align="char" char="." valign="top">25,787</td><td align="left" valign="top">~860</td></tr></tbody></table></table-wrap><p>Test videos were manually annotated in JAABA ground-truthing mode before any classifier predictions were examined, and annotations were performed independently of classifier outputs.</p></sec></sec><sec id="s4-8"><title>Manual behavioral annotations and inter-annotator reliability</title><p>Manual annotations (‘ground-truth’) were generated using JAABA’s ground-truthing mode by labeling behavioral bouts frame by frame. To assess observer bias, subsets of videos were annotated independently by two evaluators and compared using non-parametric tests. Where relevant, the results describe inter-annotator comparisons. Blinding was not performed because genotypes and experimental conditions were known during experiments and analysis.</p></sec><sec id="s4-9"><title>Characterization of male aggression and courtship behaviors</title><p>The DANCE classifiers were trained and validated in JAABA using established behavioral definitions from previous studies (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>), with input from experienced users (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>).</p></sec><sec id="s4-10"><title>Behavior definitions</title><sec id="s4-10-1"><title>Lunge</title><p>As defined by <xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>, ‘the attacking fly rises on hind legs, lifting its long body axis by 45°, then snaps down on its opponent’s body with its head at ~200 mm/s’.</p></sec><sec id="s4-10-2"><title>Wing extension</title><p>The angle between the body axis and wing tip line exceeds 30°, persisting for at least 13 frames (0.5 s at 25 fps) (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>).</p></sec><sec id="s4-10-3"><title>Attempted copulation</title><p>Abdominal curling without mounting, or mounting lasting ≥0.33 s but &lt;45 s (10–1350 frames at 30 fps).</p></sec><sec id="s4-10-4"><title>Copulation</title><p>Mounting lasting ≥45 s (&gt;1350 frames at 30 fps), adapted from <xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>.</p></sec><sec id="s4-10-5"><title>Circling</title><p>Sideways drift around the female in a circular path at constant velocity, persisting for ≥13 frames (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>).</p></sec><sec id="s4-10-6"><title>Following</title><p>The male remains 2–5 mm behind the female while both walk at ≥2 mm/s, persisting for ≥25 frames (<xref ref-type="bibr" rid="bib17">Dankert et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ribeiro et al., 2018</xref>). To account for variability in female mating condition and body size, training datasets included videos of males paired with decapitated virgin, intact virgin, and mated females. For the copulation classifier, videos in which males were paired with virgin females to capture prolonged occlusion events characteristic of mating were used for training.</p><p>For duration-based classifiers, a post-processing filter was applied to exclude bouts shorter than 98% of those observed in manual annotations, ensuring consistency with human-defined behavioral durations.</p><p>This framework can be readily adapted by the research community to develop additional behavioral classifiers. Owing to file size limitations, training videos are not hosted online but are available upon request.</p></sec></sec><sec id="s4-11"><title>Manual behavioral annotations</title><p>To quantitatively evaluate classifier performance, manual behavioral annotations (‘ground-truth’) were generated using JAABA’s ground-truthing mode (<xref ref-type="bibr" rid="bib44">Kabra et al., 2013</xref>). Classifier robustness was assessed on unseen videos comprising the testing set. Each testing video was first manually annotated by identifying behavioral bouts as ‘true behavior’, independent of the classifier’s output. These same videos were then processed through the trained classifier using JAABAPlot, and the results were compared as described below.</p></sec><sec id="s4-12"><title>Comparison of manual and DANCE annotations</title><p>The classifier outputs were compared with manually annotated ground-truth data at both the bout and frame levels, depending on the classifier type. For the single-frame lunge classifier, comparisons were based on total bout counts, whereas for all duration-based courtship classifiers (wing extension, following, circling, attempted copulation, and copulation), comparisons were made using bout durations and frame-level annotations.</p><p>For each assay, a behavioral index was calculated as the proportion of frames in which the male engaged in the specified behavior. This was obtained by dividing the total number of frames annotated for that behavior by the total number of frames in the recording. Regression analyses and performance metrics were computed using either bout counts or behavioral indices, depending on the classifier type, in GraphPad Prism 8 (GraphPad Software). Manual annotations and classifier outputs were compared to identify true positives (TP), false positives (FP), and false negatives (FN), at either frame level or bout level.</p></sec><sec id="s4-13"><title>Bout-level analysis</title><p>A predicted bout was scored as a TP if it overlapped with a ground-truth bout by at least one frame (~33 ms at 30 fps), consistent with previous studies (<xref ref-type="bibr" rid="bib50">Leng et al., 2020</xref>). When multiple predicted bouts overlapped a single ground-truth bout, they were collectively counted as one TP. Conversely, when a single predicted bout overlapped multiple ground-truth bouts, the TP count equaled the number of ground-truth bouts. Predicted bouts with no overlap were scored as FP, and ground-truth bouts with no overlapping prediction were scored as FN. These same criteria were applied to both bout-level and frame-level evaluations, with the latter accounting for the total number of frames contributing to TP, FP, and FN classifications to provide a more granular measure of accuracy (see <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>).</p></sec><sec id="s4-14"><title>Frame-level analysis</title><p>A predicted frame was scored TP if it matched the ground-truth frame; frames predicted as behavior only by the classifier were FP; frames annotated as behavior only by ground-truth were FN. These frame-level TP, FP, FN were then similarly used to calculate precision, recall, and F1 score, providing a more granular measure of classifier accuracy.</p></sec><sec id="s4-15"><title>Performance metrics</title><p>A custom Python script was used to calculate overlaps and derive standard classification metrics. The precision, recall, and F1 scores were computed using the following formulas:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle precision=\frac{\left (number\, of\, true\, positives\right)}{\left (number\, of\, true\, positives\right)+\left (number\, of\, false\, positives\right)}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle recall=\frac{\left (number\, of\, true\, positives\right)}{\left (number\, of\, true\, positives\right)+\left (number\, of\, false\, negatives\right)}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ3"><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle F1\, score=2\, x\, \frac{\left (precision\, x\, recall\right)}{\left (precision+\, recall\right)}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Precision represents the fraction of correctly predicted positive observations among all predicted positives, recall represents the fraction of correctly predicted positive observations among all actual positives, and the F1 score provides the harmonic mean of precision and recall. These metrics were used to quantify and compare the performance of the DANCE classifiers against manually annotated ground-truth and existing algorithms.</p><p>For duration-based behaviors, the behavioral index was used as a continuous variable in regression and performance analyses. For the lunge classifier, which identifies discrete one-frame events, comparisons were made using total bout counts.</p></sec><sec id="s4-16"><title>Statistical analysis</title><p>All the statistical analyses were performed using <italic>GraphPad Prism 8</italic>, custom Python scripts, or <italic>Microsoft Excel</italic>. For non-normally distributed data, non-parametric tests such as the Mann–Whitney U test or Kruskal–Wallis ANOVA with appropriate post hoc corrections were used. Formal power calculations were not performed, as sample sizes were chosen based on established standards in <italic>Drosophila</italic> behavioral studies. No animals or data points were excluded from analysis due to attrition; all recorded flies were included unless excluded a priori based on predefined criteria (e.g. physical injury or tracking failure).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>RSPY, FA and PA are listed as inventors on a published patent related to this work by the Indian patent office, titled 'Device For Measuring Complex Social Behaviors In Small Insects', Application No. 202441072884</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Software, Formal analysis, Validation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Software, Formal analysis, Validation, Visualization, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Validation, Visualization, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con10"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Conceptualization, Resources, Supervision, Funding acquisition, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Bill of materials for the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) setup and comparison with existing setups.</title></caption><media xlink:href="elife-105465-supp1-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Comparison between the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) lunge classifier, ground-truth, and existing methods.</title></caption><media xlink:href="elife-105465-supp2-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>Definitions of the behavioral classifiers.</title></caption><media xlink:href="elife-105465-supp3-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp4"><label>Supplementary file 4.</label><caption><title>Comparison between the <italic><underline>D</underline>rosophila</italic> <underline>A</underline>ggression a<underline>n</underline>d <underline>C</underline>ourtship <underline>E</underline>valuator (DANCE) courtship classifiers, ground-truth, and MateBook.</title></caption><media xlink:href="elife-105465-supp4-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp5"><label>Supplementary file 5.</label><caption><title>Quantifying identity swaps to validate tracking across setups.</title></caption><media xlink:href="elife-105465-supp5-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-105465-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Source data files have been provided for all quantitative analyses presented in the figures. Figure 2-source data 1, Figure 2-figure supplement 1-source data 1, and Figure 2-figure supplement 2-source data 1 contain the numerical data used to generate Figure 2 and its supplements. Figure 3-source data 1 and Figure 3-figure supplement 1-source data 1 contain the numerical data used to generate Figure 3 and its supplement. Figure 4-source data 1 and Figure 4-figure supplement 1-source data 1 contain the numerical data used to generate Figure 4 and its supplement. Figure 5-source data 1, Figure 5-figure supplement 1-source data 1, Figure 5-figure supplement 2-source data 1, and Figure 5-figure supplement 3-source data 1 contain the numerical data used to generate Figure 5 and its supplements. Figure 7-source data 1, Figure 7-figure supplement 2-source data 1, Figure 7-figure supplement 3-source data 1, and Figure 7-figure supplement 4-source data 1 contain the numerical data used to generate Figure 7 and its supplements. All custom analysis scripts, DANCE classifiers, and documentation used in this study are publicly available in GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/agrawallab/DANCE">https://github.com/agrawallab/DANCE</ext-link> (copy archived at <xref ref-type="bibr" rid="bib21">Dey and Agrawal, 2025</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Barry Dickson (Queensland Brain Institute, Australia) for insightful discussions and suggestions related to MateBook and Ben Arthur (HHMI, Janelia Research Campus, USA) for guidance in setting up the MateBook analysis. We are grateful to Mayank Kabra, Kristin Branson, and colleagues for developing JAABA and for their ongoing support to the user community. We thank Ulrike Heberlein (HHMI, Janelia Research Campus, USA), Gaurav Das (NCCS, Pune), and the Bloomington Drosophila Stock Center (NIH P40OD018537) for providing fly stocks. We acknowledge Santhosh Chidangil (MAHE) for assisting with the LED power measurements and Santosh D’Mello (LSU Shreveport) for helpful discussions. We are also grateful to Gaurav Das and Toshiharu Ichinose (Tohoku University, Japan) for critical reading and feedback on the manuscript. Figures were created with <ext-link ext-link-type="uri" xlink:href="https://www.biorender.com/">BioRender.com</ext-link> and Inkscape. This work was supported by funding to PA from the Department of Biotechnology (DBT), Ramalingaswami Re-entry Fellowship (BT/RLF, Re-entry/34/2018), and DBT, Research grant (BT/PR36166/BRB/10/1859/2020) by the DBT, Ministry of Science and Technology, Government of India. RSPY was supported by a TMA Pai fellowship from MAHE and DBT, Research grant to PA. FA was supported by Ramalingaswami fellowship, DBT, India to PA. TK was supported by DBT, Research grant to PA. MV is supported by NFST, Ministry of Tribal Affairs, Government of India. SA is supported by the Department of Science and Technology (DST) INSPIRE Fellowship. PPP is supported by a TMA Pai fellowship from MAHE, India. SBS is supported by the Anusandhan National Research Foundation (ANRF), Ministry of Science and Technology, Government of India, grant to PA (CRG/2022/006846).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agrawal</surname><given-names>P</given-names></name><name><surname>Kao</surname><given-names>D</given-names></name><name><surname>Chung</surname><given-names>P</given-names></name><name><surname>Looger</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The neuropeptide Drosulfakinin regulates social isolation-induced aggression in <italic>Drosophila</italic></article-title><source>The Journal of Experimental Biology</source><volume>223</volume><elocation-id>jeb207407</elocation-id><pub-id pub-id-type="doi">10.1242/jeb.207407</pub-id><pub-id pub-id-type="pmid">31900346</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alekseyenko</surname><given-names>OV</given-names></name><name><surname>Chan</surname><given-names>YB</given-names></name><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Kravitz</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Single dopaminergic neurons that modulate aggression in Drosophila</article-title><source>PNAS</source><volume>110</volume><fpage>6151</fpage><lpage>6156</lpage><pub-id pub-id-type="doi">10.1073/pnas.1303446110</pub-id><pub-id pub-id-type="pmid">23530210</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>DJ</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Toward a science of computational ethology</article-title><source>Neuron</source><volume>84</volume><fpage>18</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.005</pub-id><pub-id pub-id-type="pmid">25277452</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Arthur</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>MateBook</data-title><version designator="swh:1:rev:22142bc7ebdd7f8cb3f3da17c4bba1df04486e1b">swh:1:rev:22142bc7ebdd7f8cb3f3da17c4bba1df04486e1b</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d82c8e0968ac3ba3ca0e924291a737b6b953e14e;origin=https://github.com/Dicksonlab/MateBook;visit=swh:1:snp:57d90a1bd5f40793f6bdeea528d08e355cca0343;anchor=swh:1:rev:22142bc7ebdd7f8cb3f3da17c4bba1df04486e1b">https://archive.softwareheritage.org/swh:1:dir:d82c8e0968ac3ba3ca0e924291a737b6b953e14e;origin=https://github.com/Dicksonlab/MateBook;visit=swh:1:snp:57d90a1bd5f40793f6bdeea528d08e355cca0343;anchor=swh:1:rev:22142bc7ebdd7f8cb3f3da17c4bba1df04486e1b</ext-link></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asahina</surname><given-names>K</given-names></name><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Duistermars</surname><given-names>BJ</given-names></name><name><surname>Hoopfer</surname><given-names>E</given-names></name><name><surname>González</surname><given-names>CR</given-names></name><name><surname>Eyjólfsdóttir</surname><given-names>EA</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Tachykinin-expressing neurons control male-specific aggressive arousal in <italic>Drosophila</italic></article-title><source>Cell</source><volume>156</volume><fpage>221</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2013.11.045</pub-id><pub-id pub-id-type="pmid">24439378</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asahina</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neuromodulation and strategic action choice in <italic>Drosophila</italic> aggression</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>51</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031240</pub-id><pub-id pub-id-type="pmid">28375770</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastock</surname><given-names>M</given-names></name><name><surname>Manning</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>The courtship of <italic>Drosophila melanogaster</italic></article-title><source>Behaviour</source><volume>8</volume><fpage>85</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1163/156853955X00184</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennet-Clark</surname><given-names>HC</given-names></name><name><surname>Ewing</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Pulse interval as a critical parameter in the courtship song of <italic>Drosophila melanogaster</italic></article-title><source>Animal Behaviour</source><volume>17</volume><fpage>755</fpage><lpage>759</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(69)80023-0</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bentzur</surname><given-names>A</given-names></name><name><surname>Ben-Shaanan</surname><given-names>S</given-names></name><name><surname>Benichou</surname><given-names>JIC</given-names></name><name><surname>Costi</surname><given-names>E</given-names></name><name><surname>Levi</surname><given-names>M</given-names></name><name><surname>Ilany</surname><given-names>A</given-names></name><name><surname>Shohat-Ophir</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Early life experience shapes male behavior and social networks in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>31</volume><fpage>486</fpage><lpage>501</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.10.060</pub-id><pub-id pub-id-type="pmid">33186552</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benzer</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Behavioral mutants of drosophila isolated by countercurrent distribution</article-title><source>PNAS</source><volume>58</volume><fpage>1112</fpage><lpage>1119</lpage><pub-id pub-id-type="doi">10.1073/pnas.58.3.1112</pub-id><pub-id pub-id-type="pmid">16578662</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Bender</surname><given-names>J</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>High-throughput ethomics in large groups of <italic>Drosophila</italic></article-title><source>Nature Methods</source><volume>6</volume><fpage>451</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1328</pub-id><pub-id pub-id-type="pmid">19412169</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Courtship behaviour in the <italic>Drosophila obscura</italic> group II comparative studies</article-title><source>Behaviour</source><volume>25</volume><fpage>281</fpage><lpage>323</lpage><pub-id pub-id-type="doi">10.1163/156853965x00174</pub-id><pub-id pub-id-type="pmid">5824950</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>AY</given-names></name><name><surname>Bowens</surname><given-names>NM</given-names></name><name><surname>Huber</surname><given-names>R</given-names></name><name><surname>Kravitz</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Fighting fruit flies: a model system for the study of aggression</article-title><source>PNAS</source><volume>99</volume><fpage>5664</fpage><lpage>5668</lpage><pub-id pub-id-type="doi">10.1073/pnas.082102599</pub-id><pub-id pub-id-type="pmid">11960020</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiu</surname><given-names>H</given-names></name><name><surname>Hoopfer</surname><given-names>ED</given-names></name><name><surname>Coughlan</surname><given-names>ML</given-names></name><name><surname>Pavlou</surname><given-names>HJ</given-names></name><name><surname>Goodwin</surname><given-names>SF</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A circuit logic for sexually shared and dimorphic aggressive behaviors in <italic>Drosophila</italic></article-title><source>Cell</source><volume>184</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.11.048</pub-id><pub-id pub-id-type="pmid">33382967</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chowdhury</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Gnerer</surname><given-names>JP</given-names></name><name><surname>Dierick</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The divider assay is a high-throughput pipeline for aggression analysis in <italic>Drosophila</italic></article-title><source>Communications Biology</source><volume>4</volume><elocation-id>85</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-020-01617-6</pub-id><pub-id pub-id-type="pmid">33469118</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>R</given-names></name><name><surname>Cook</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>The attractiveness to males of female <italic>Drosophila melanogaster</italic>: effects of mating, age and diet</article-title><source>Animal Behaviour</source><volume>23</volume><fpage>521</fpage><lpage>526</lpage><pub-id pub-id-type="doi">10.1016/0003-3472(75)90129-3</pub-id><pub-id pub-id-type="pmid">808987</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dankert</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Hoopfer</surname><given-names>ED</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Automated monitoring and analysis of social behavior in <italic>Drosophila</italic></article-title><source>Nature Methods</source><volume>6</volume><fpage>297</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1310</pub-id><pub-id pub-id-type="pmid">19270697</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname><given-names>SR</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Leifer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational neuroethology: a call to action</article-title><source>Neuron</source><volume>104</volume><fpage>11</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.038</pub-id><pub-id pub-id-type="pmid">31600508</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>SM</given-names></name><name><surname>Thomas</surname><given-names>AL</given-names></name><name><surname>Nomie</surname><given-names>KJ</given-names></name><name><surname>Huang</surname><given-names>L</given-names></name><name><surname>Dierick</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Tailless and Atrophin control <italic>Drosophila</italic> aggression by regulating neuropeptide signalling in the pars intercerebralis</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>3177</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms4177</pub-id><pub-id pub-id-type="pmid">24495972</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>SM</given-names></name><name><surname>Thomas</surname><given-names>AL</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Campbell</surname><given-names>IM</given-names></name><name><surname>Dierick</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Isolation of aggressive behavior mutants in <italic>Drosophila</italic> using a screen for wing damage</article-title><source>Genetics</source><volume>208</volume><fpage>273</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1534/genetics.117.300292</pub-id><pub-id pub-id-type="pmid">29109180</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Dey</surname><given-names>P</given-names></name><name><surname>Agrawal</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>DANCE</data-title><version designator="swh:1:rev:f99faedf0c9600ea687e7a15d61e627b9ed33289">swh:1:rev:f99faedf0c9600ea687e7a15d61e627b9ed33289</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:aa1b0b2cf0981001b1424903eb302f6f7b48c9b9;origin=https://github.com/agrawallab/DANCE;visit=swh:1:snp:6a3b26630011b2d975f61b07e8217e6d1d9d393b;anchor=swh:1:rev:f99faedf0c9600ea687e7a15d61e627b9ed33289">https://archive.softwareheritage.org/swh:1:dir:aa1b0b2cf0981001b1424903eb302f6f7b48c9b9;origin=https://github.com/agrawallab/DANCE;visit=swh:1:snp:6a3b26630011b2d975f61b07e8217e6d1d9d393b;anchor=swh:1:rev:f99faedf0c9600ea687e7a15d61e627b9ed33289</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dickson</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Wired for sex: the neurobiology of <italic>Drosophila</italic> mating decisions</article-title><source>Science</source><volume>322</volume><fpage>904</fpage><lpage>909</lpage><pub-id pub-id-type="doi">10.1126/science.1159276</pub-id><pub-id pub-id-type="pmid">18988843</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dierick</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A method for quantifying aggression in male <italic>Drosophila melanogaster</italic></article-title><source>Nature Protocols</source><volume>2</volume><fpage>2712</fpage><lpage>2718</lpage><pub-id pub-id-type="doi">10.1038/nprot.2007.404</pub-id><pub-id pub-id-type="pmid">18007606</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dow</surname><given-names>MA</given-names></name><name><surname>von Schilcher</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Aggression and mating success in <italic>Drosophila melanogaster</italic></article-title><source>Nature</source><volume>254</volume><fpage>511</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1038/254511a0</pub-id><pub-id pub-id-type="pmid">804664</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duistermars</surname><given-names>BJ</given-names></name><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Hoopfer</surname><given-names>ED</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A brain module for scalable control of complex, multi-motor threat displays</article-title><source>Neuron</source><volume>100</volume><fpage>1474</fpage><lpage>1490</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.027</pub-id><pub-id pub-id-type="pmid">30415997</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eyjolfsdottir</surname><given-names>E</given-names></name><name><surname>Branson</surname><given-names>S</given-names></name><name><surname>Burgos-Artizzu</surname><given-names>XP</given-names></name><name><surname>Hoopfer</surname><given-names>ED</given-names></name><name><surname>Schor</surname><given-names>J</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Detecting social actions of fruit flies</article-title><source>Computer Vision – ECCV</source><volume>8690</volume><fpage>772</fpage><lpage>787</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-10605-2_50</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fowler</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="1973">1973</year><chapter-title>Some aspects of the reproductive biology of drosophila: sperm transfer, sperm storage, and sperm utilization in</chapter-title><person-group person-group-type="editor"><name><surname>Caspari</surname><given-names>EW</given-names></name></person-group><source>Advances in Genetics</source><publisher-name>Academic Press</publisher-name><fpage>293</fpage><lpage>360</lpage></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gill</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>A mutation causing abnormal courtship and mating behavior in males of <italic>Drosophila melanogaster</italic></article-title><source>American Zoologist</source><volume>3</volume><elocation-id>507</elocation-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>GilMartí</surname><given-names>B</given-names></name><name><surname>Barredo</surname><given-names>CG</given-names></name><name><surname>Pina-Flores</surname><given-names>S</given-names></name><name><surname>Poza-Rodriguez</surname><given-names>A</given-names></name><name><surname>Treves</surname><given-names>G</given-names></name><name><surname>Rodriguez-Navas</surname><given-names>C</given-names></name><name><surname>Camacho</surname><given-names>L</given-names></name><name><surname>Pérez-Serna</surname><given-names>A</given-names></name><name><surname>Jimenez</surname><given-names>I</given-names></name><name><surname>Brazales</surname><given-names>L</given-names></name><name><surname>Fernandez</surname><given-names>J</given-names></name><name><surname>Martin</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A simplified courtship conditioning protocol to test learning and memory in Drosophila</article-title><source>STAR Protocols</source><volume>4</volume><elocation-id>101572</elocation-id><pub-id pub-id-type="doi">10.1016/j.xpro.2022.101572</pub-id><pub-id pub-id-type="pmid">36633946</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname><given-names>A</given-names></name><name><surname>Paton</surname><given-names>JJ</given-names></name><name><surname>Kampff</surname><given-names>AR</given-names></name><name><surname>Costa</surname><given-names>RM</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Big behavioral data: psychology, ethology and the foundations of neuroscience</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1455</fpage><lpage>1462</lpage><pub-id pub-id-type="doi">10.1038/nn.3812</pub-id><pub-id pub-id-type="pmid">25349912</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Govorunova</surname><given-names>EG</given-names></name><name><surname>Sineshchekov</surname><given-names>OA</given-names></name><name><surname>Janz</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Spudich</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuroscience natural light-gated anion channels: a family of microbial rhodopsins for advanced optogenetics</article-title><source>Science</source><volume>349</volume><fpage>647</fpage><lpage>650</lpage><pub-id pub-id-type="doi">10.1126/science.aaa7484</pub-id><pub-id pub-id-type="pmid">26113638</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenspan</surname><given-names>RJ</given-names></name><name><surname>Ferveur</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Courtship in <italic>Drosophila</italic></article-title><source>Annual Review of Genetics</source><volume>34</volume><fpage>205</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1146/annurev.genet.34.1.205</pub-id><pub-id pub-id-type="pmid">11092827</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Courtship among males due to a male-sterile mutation in <italic>Drosophila melanogaster</italic></article-title><source>Behavior Genetics</source><volume>8</volume><fpage>125</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1007/BF01066870</pub-id><pub-id pub-id-type="pmid">99136</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Courtship lite: a personal history of reproductive behavioral neurogenetics in <italic>Drosophila</italic></article-title><source>Journal of Neurogenetics</source><volume>16</volume><fpage>135</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1080/01677060215307</pub-id><pub-id pub-id-type="pmid">12696670</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hindmarsh Sten</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Hollunder</surname><given-names>F</given-names></name><name><surname>Eleazer</surname><given-names>S</given-names></name><name><surname>Ruta</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Male-male interactions shape mate selection in <italic>Drosophila</italic></article-title><source>Cell</source><volume>188</volume><fpage>1486</fpage><lpage>1503</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2025.01.008</pub-id><pub-id pub-id-type="pmid">39952248</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="1987">1987a</year><article-title>A laboratory study of male territoriality in the sibling species <italic>Drosophila melanogaster</italic> and D. simulans</article-title><source>Animal Behaviour</source><volume>35</volume><fpage>807</fpage><lpage>818</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(87)80117-3</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="1987">1987b</year><article-title>Territorial encounters between <italic>Drosophila</italic> males of different sizes</article-title><source>Animal Behaviour</source><volume>35</volume><fpage>1899</fpage><lpage>1901</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(87)80085-4</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoopfer</surname><given-names>ED</given-names></name><name><surname>Jung</surname><given-names>Y</given-names></name><name><surname>Inagaki</surname><given-names>HK</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>P1 interneurons promote a persistent internal state that enhances inter-male aggression in <italic>Drosophila</italic></article-title><source>eLife</source><volume>4</volume><elocation-id>e11346</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11346</pub-id><pub-id pub-id-type="pmid">26714106</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoyer</surname><given-names>SC</given-names></name><name><surname>Eckart</surname><given-names>A</given-names></name><name><surname>Herrel</surname><given-names>A</given-names></name><name><surname>Zars</surname><given-names>T</given-names></name><name><surname>Fischer</surname><given-names>SA</given-names></name><name><surname>Hardie</surname><given-names>SL</given-names></name><name><surname>Heisenberg</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Octopamine in male aggression of <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>18</volume><fpage>159</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2007.12.052</pub-id><pub-id pub-id-type="pmid">18249112</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishii</surname><given-names>K</given-names></name><name><surname>Cortese</surname><given-names>M</given-names></name><name><surname>Leng</surname><given-names>X</given-names></name><name><surname>Shokhirev</surname><given-names>MN</given-names></name><name><surname>Asahina</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A neurogenetic mechanism of experience-dependent suppression of aggression</article-title><source>Science Advances</source><volume>8</volume><elocation-id>eabg3203</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abg3203</pub-id><pub-id pub-id-type="pmid">36070378</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>Influence of light on mating of <italic>Drosophila melanogaster</italic></article-title><source>Ecology</source><volume>41</volume><fpage>182</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.2307/1931952</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jia</surname><given-names>Y</given-names></name><name><surname>Jin</surname><given-names>S</given-names></name><name><surname>Hu</surname><given-names>K</given-names></name><name><surname>Geng</surname><given-names>L</given-names></name><name><surname>Han</surname><given-names>C</given-names></name><name><surname>Kang</surname><given-names>R</given-names></name><name><surname>Pang</surname><given-names>Y</given-names></name><name><surname>Ling</surname><given-names>E</given-names></name><name><surname>Tan</surname><given-names>EK</given-names></name><name><surname>Pan</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Gut microbiome modulates <italic>Drosophila</italic> aggression through octopamine signaling</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>2698</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-23041-y</pub-id><pub-id pub-id-type="pmid">33976215</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>Y</given-names></name><name><surname>Kennedy</surname><given-names>A</given-names></name><name><surname>Chiu</surname><given-names>H</given-names></name><name><surname>Mohammad</surname><given-names>F</given-names></name><name><surname>Claridge-Chang</surname><given-names>A</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neurons that function within an integrator to promote a persistent behavioral state in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>105</volume><fpage>322</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.10.028</pub-id><pub-id pub-id-type="pmid">31810837</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kabra</surname><given-names>M</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Rivera-Alba</surname><given-names>M</given-names></name><name><surname>Branson</surname><given-names>S</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>JAABA: interactive machine learning for automatic annotation of animal behavior</article-title><source>Nature Methods</source><volume>10</volume><fpage>64</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2281</pub-id><pub-id pub-id-type="pmid">23202433</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kessler</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Courtship rituals and reproductive isolation between the races or incipient species of <italic>Drosophila</italic> paulistorum</article-title><source>The American Naturalist</source><volume>96</volume><fpage>117</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1086/282212</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>YK</given-names></name><name><surname>Ehrman</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Developmental isolation and subsequent adult behavior of <italic>Drosophila</italic> paulistorum IV courtship</article-title><source>Behavior Genetics</source><volume>28</volume><fpage>57</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1023/A:1021460832378</pub-id><pub-id pub-id-type="pmid">9573647</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>Y-K</given-names></name><name><surname>Saver</surname><given-names>M</given-names></name><name><surname>Simon</surname><given-names>J</given-names></name><name><surname>Kent</surname><given-names>CF</given-names></name><name><surname>Shao</surname><given-names>L</given-names></name><name><surname>Eddison</surname><given-names>M</given-names></name><name><surname>Agrawal</surname><given-names>P</given-names></name><name><surname>Texada</surname><given-names>M</given-names></name><name><surname>Truman</surname><given-names>JW</given-names></name><name><surname>Heberlein</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Repetitive aggressive encounters generate a long-lasting internal state in <italic>Drosophila melanogaster</italic> males</article-title><source>PNAS</source><volume>115</volume><fpage>1099</fpage><lpage>1104</lpage><pub-id pub-id-type="doi">10.1073/pnas.1716612115</pub-id><pub-id pub-id-type="pmid">29339481</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koemans</surname><given-names>TS</given-names></name><name><surname>Oppitz</surname><given-names>C</given-names></name><name><surname>Donders</surname><given-names>RAT</given-names></name><name><surname>van Bokhoven</surname><given-names>H</given-names></name><name><surname>Schenck</surname><given-names>A</given-names></name><name><surname>Keleman</surname><given-names>K</given-names></name><name><surname>Kramer</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title><italic>Drosophila</italic> courtship conditioning as a measure of learning and memory</article-title><source>Journal of Visualized Experiments</source><volume>2017</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.3791/55808</pub-id><pub-id pub-id-type="pmid">28605393</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kravitz</surname><given-names>EA</given-names></name><name><surname>Fernandez</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Aggression in <italic>Drosophila</italic></article-title><source>Behavioral Neuroscience</source><volume>129</volume><fpage>549</fpage><lpage>563</lpage><pub-id pub-id-type="doi">10.1037/bne0000089</pub-id><pub-id pub-id-type="pmid">26348714</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leng</surname><given-names>X</given-names></name><name><surname>Wohl</surname><given-names>M</given-names></name><name><surname>Ishii</surname><given-names>K</given-names></name><name><surname>Nayak</surname><given-names>P</given-names></name><name><surname>Asahina</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Quantifying influence of human choice on the automated detection of <italic>Drosophila</italic> behavior by a supervised machine learning algorithm</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0241696</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0241696</pub-id><pub-id pub-id-type="pmid">33326445</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>RS</given-names></name><name><surname>Eyjólfsdóttir</surname><given-names>E</given-names></name><name><surname>Shin</surname><given-names>E</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>How food controls aggression in <italic>Drosophila</italic></article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e105626</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0105626</pub-id><pub-id pub-id-type="pmid">25162609</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lopes</surname><given-names>G</given-names></name><name><surname>Bonacchi</surname><given-names>N</given-names></name><name><surname>Frazão</surname><given-names>J</given-names></name><name><surname>Neto</surname><given-names>JP</given-names></name><name><surname>Atallah</surname><given-names>BV</given-names></name><name><surname>Soares</surname><given-names>S</given-names></name><name><surname>Moreira</surname><given-names>L</given-names></name><name><surname>Matias</surname><given-names>S</given-names></name><name><surname>Itskov</surname><given-names>PM</given-names></name><name><surname>Correia</surname><given-names>PA</given-names></name><name><surname>Medina</surname><given-names>RE</given-names></name><name><surname>Calcaterra</surname><given-names>L</given-names></name><name><surname>Dreosti</surname><given-names>E</given-names></name><name><surname>Paton</surname><given-names>JJ</given-names></name><name><surname>Kampff</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Bonsai: an event-based framework for processing and controlling data streams</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00007</pub-id><pub-id pub-id-type="pmid">25904861</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacBean</surname><given-names>IT</given-names></name><name><surname>Parsons</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Directional selection for duration of copulation in <italic>Drosophila melanogaster</italic></article-title><source>Genetics</source><volume>56</volume><fpage>233</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1093/genetics/56.2.233</pub-id><pub-id pub-id-type="pmid">6040493</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markow</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Behavioral and sensory basis of courtship success in <italic>Drosophila melanogaster</italic></article-title><source>PNAS</source><volume>84</volume><fpage>6200</fpage><lpage>6204</lpage><pub-id pub-id-type="doi">10.1073/pnas.84.17.6200</pub-id><pub-id pub-id-type="pmid">3114743</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohammad</surname><given-names>F</given-names></name><name><surname>Stewart</surname><given-names>JC</given-names></name><name><surname>Ott</surname><given-names>S</given-names></name><name><surname>Chlebikova</surname><given-names>K</given-names></name><name><surname>Chua</surname><given-names>JY</given-names></name><name><surname>Koh</surname><given-names>TW</given-names></name><name><surname>Ho</surname><given-names>J</given-names></name><name><surname>Claridge-Chang</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Optogenetic inhibition of behavior with anion channelrhodopsins</article-title><source>Nature Methods</source><volume>14</volume><fpage>271</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4148</pub-id><pub-id pub-id-type="pmid">28114289</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nilsen</surname><given-names>SP</given-names></name><name><surname>Chan</surname><given-names>YB</given-names></name><name><surname>Huber</surname><given-names>R</given-names></name><name><surname>Kravitz</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Gender-selective patterns of aggressive behavior in <italic>Drosophila melanogaster</italic></article-title><source>PNAS</source><volume>101</volume><fpage>12342</fpage><lpage>12347</lpage><pub-id pub-id-type="doi">10.1073/pnas.0404693101</pub-id><pub-id pub-id-type="pmid">15302936</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Dell</surname><given-names>KMC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The voyeurs’ guide to <italic>Drosophila melanogaster</italic> courtship</article-title><source>Behavioural Processes</source><volume>64</volume><fpage>211</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1016/s0376-6357(03)00136-0</pub-id><pub-id pub-id-type="pmid">14556953</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>Y</given-names></name><name><surname>Baker</surname><given-names>BS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Genetic identification and separation of innate and experience-dependent courtship behaviors in <italic>Drosophila</italic></article-title><source>Cell</source><volume>156</volume><fpage>236</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2013.11.041</pub-id><pub-id pub-id-type="pmid">24439379</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pantalia</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Tener</surname><given-names>SJ</given-names></name><name><surname>Qiao</surname><given-names>B</given-names></name><name><surname>Tang</surname><given-names>G</given-names></name><name><surname>Ulgherait</surname><given-names>M</given-names></name><name><surname>O’Connor</surname><given-names>R</given-names></name><name><surname>Delventhal</surname><given-names>R</given-names></name><name><surname>Volpi</surname><given-names>J</given-names></name><name><surname>Syed</surname><given-names>S</given-names></name><name><surname>Itzhak</surname><given-names>N</given-names></name><name><surname>Canman</surname><given-names>JC</given-names></name><name><surname>Fernández</surname><given-names>MP</given-names></name><name><surname>Shirasu-Hiza</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Drosophila mutants lacking the glial neurotransmitter-modifying enzyme Ebony exhibit low neurotransmitter levels and altered behavior</article-title><source>Scientific Reports</source><volume>13</volume><elocation-id>10411</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-023-36558-7</pub-id><pub-id pub-id-type="pmid">37369755</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlou</surname><given-names>HJ</given-names></name><name><surname>Goodwin</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Courtship behavior in <italic>Drosophila melanogaster</italic>: towards a “courtship connectome”</article-title><source>Current Opinion in Neurobiology</source><volume>23</volume><fpage>76</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.09.002</pub-id><pub-id pub-id-type="pmid">23021897</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reza</surname><given-names>MA</given-names></name><name><surname>Mhatre</surname><given-names>SD</given-names></name><name><surname>Morrison</surname><given-names>JC</given-names></name><name><surname>Utreja</surname><given-names>S</given-names></name><name><surname>Saunders</surname><given-names>AJ</given-names></name><name><surname>Breen</surname><given-names>DE</given-names></name><name><surname>Marenda</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Automated analysis of courtship suppression learning and memory in <italic>Drosophila melanogaster</italic></article-title><source>Fly</source><volume>7</volume><fpage>105</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.4161/fly.24110</pub-id><pub-id pub-id-type="pmid">23644900</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ribeiro</surname><given-names>IMA</given-names></name><name><surname>Drews</surname><given-names>M</given-names></name><name><surname>Bahl</surname><given-names>A</given-names></name><name><surname>Machacek</surname><given-names>C</given-names></name><name><surname>Borst</surname><given-names>A</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Visual projection neurons mediating directed courtship in <italic>Drosophila</italic></article-title><source>Cell</source><volume>174</volume><fpage>607</fpage><lpage>621</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.020</pub-id><pub-id pub-id-type="pmid">30033367</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Hirokawa</surname><given-names>J</given-names></name><name><surname>Edwards</surname><given-names>AW</given-names></name><name><surname>Umayam</surname><given-names>LA</given-names></name><name><surname>Lee</surname><given-names>A</given-names></name><name><surname>Phillips</surname><given-names>ML</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name><name><surname>Korff</surname><given-names>W</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name><name><surname>Reiser</surname><given-names>MB</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Mapping the neural substrates of behavior</article-title><source>Cell</source><volume>170</volume><fpage>393</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.06.032</pub-id><pub-id pub-id-type="pmid">28709004</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Seagraves</surname><given-names>KM</given-names></name><name><surname>Egnor</surname><given-names>SER</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Machine vision methods for analyzing social interactions</article-title><source>Journal of Experimental Biology</source><volume>220</volume><fpage>25</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1242/jeb.142281</pub-id><pub-id pub-id-type="pmid">28057825</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeds</surname><given-names>AM</given-names></name><name><surname>Ravbar</surname><given-names>P</given-names></name><name><surname>Chung</surname><given-names>P</given-names></name><name><surname>Hampel</surname><given-names>S</given-names></name><name><surname>Midgley</surname><given-names>FM</given-names><suffix>Jr</suffix></name><name><surname>Mensh</surname><given-names>BD</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A suppression hierarchy among competing motor programs drives sequential grooming in Drosophila</article-title><source>eLife</source><volume>3</volume><elocation-id>e02951</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.02951</pub-id><pub-id pub-id-type="pmid">25139955</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shorey</surname><given-names>HH</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Nature of the sound produced by <italic>Drosophila melanogaster</italic> during courtship</article-title><source>Science</source><volume>137</volume><fpage>677</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1126/science.137.3531.677</pub-id><pub-id pub-id-type="pmid">17770950</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>JC</given-names></name><name><surname>Heberlein</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Social hierarchy is established and maintained with distinct acts of aggression in male <italic>Drosophila</italic></article-title><source>Journal of Experimental Biology</source><volume>223</volume><elocation-id>jeb232439</elocation-id><pub-id pub-id-type="doi">10.1242/jeb.232439</pub-id><pub-id pub-id-type="pmid">33268534</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokolowski</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title><italic>Drosophila</italic>: genetics meets behaviour</article-title><source>Nature Reviews. Genetics</source><volume>2</volume><fpage>879</fpage><lpage>890</lpage><pub-id pub-id-type="doi">10.1038/35098592</pub-id><pub-id pub-id-type="pmid">11715043</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spieth</surname><given-names>HT</given-names></name></person-group><year iso-8601-date="1952">1952</year><source>Mating Behavior Within the Genus Drosophila Diptera</source><publisher-name>Bulletin of the AMNH</publisher-name></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spieth</surname><given-names>HT</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Drosophilid mating behaviour: The behaviour of decapitated females</article-title><source>Animal Behaviour</source><volume>14</volume><fpage>226</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(66)80076-3</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spieth</surname><given-names>HT</given-names></name></person-group><year iso-8601-date="1968">1968</year><chapter-title>Evolutionary implications of sexual behavior in drosophila in</chapter-title><person-group person-group-type="editor"><name><surname>Dobzhansky</surname><given-names>T</given-names></name><name><surname>Hecht</surname><given-names>MK</given-names></name><name><surname>Steere</surname><given-names>WC</given-names></name></person-group><source>Evolutionary Biology</source><publisher-loc>Boston, MA</publisher-loc><publisher-name>Springer US</publisher-name><fpage>157</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1007/978-1-4684-8094-8_4</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spieth</surname><given-names>HT</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Courtship behavior in <italic>Drosophila</italic></article-title><source>Annual Review of Entomology</source><volume>19</volume><fpage>385</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1146/annurev.en.19.010174.002125</pub-id><pub-id pub-id-type="pmid">4205689</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sturtevant</surname><given-names>AH</given-names></name></person-group><year iso-8601-date="1915">1915</year><article-title>Experiments on sex recognition and the problem of sexual selection in <italic>Drosoophilia</italic></article-title><source>Journal of Animal Behavior</source><volume>5</volume><fpage>351</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1037/h0074109</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swain</surname><given-names>B</given-names></name><name><surname>von Philipsborn</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Sound production in <italic>Drosophila melanogaster</italic>: Behaviour and neurobiology</article-title><source>Advances in Insect Physiology</source><volume>61</volume><fpage>141</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/bs.aiip.2021.08.001</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tao</surname><given-names>L</given-names></name><name><surname>Ayambem</surname><given-names>D</given-names></name><name><surname>Barranca</surname><given-names>VJ</given-names></name><name><surname>Bhandawat</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Neurons underlying aggression-like actions that are shared by both males and females in <italic>Drosophila</italic></article-title><source>The Journal of Neuroscience</source><volume>44</volume><elocation-id>e0142242024</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0142-24.2024</pub-id><pub-id pub-id-type="pmid">39317475</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tompkins</surname><given-names>L</given-names></name><name><surname>Hall</surname><given-names>JC</given-names></name><name><surname>Hall</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Courtship-stimulating volatile compounds from normal and mutant <italic>Drosophila</italic></article-title><source>Journal of Insect Physiology</source><volume>26</volume><fpage>689</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1016/0022-1910(80)90042-6</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Dankert</surname><given-names>H</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A common genetic target for environmental and heritable influences on aggressiveness in <italic>Drosophila</italic></article-title><source>PNAS</source><volume>105</volume><fpage>5657</fpage><lpage>5663</lpage><pub-id pub-id-type="doi">10.1073/pnas.0801327105</pub-id><pub-id pub-id-type="pmid">18408154</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Chiu</surname><given-names>H</given-names></name><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Wong</surname><given-names>AM</given-names></name><name><surname>Hoopfer</surname><given-names>ED</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A circuit node that integrates convergent input from neuromodulatory and social behavior-promoting neurons to control aggression in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>95</volume><fpage>1112</fpage><lpage>1128</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.08.017</pub-id><pub-id pub-id-type="pmid">28858617</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wohl</surname><given-names>MP</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Asahina</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title><italic>Drosophila</italic> tachykininergic neurons modulate the activity of two groups of receptor-expressing neurons to regulate aggressive tone</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>3394</fpage><lpage>3420</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1734-22.2023</pub-id><pub-id pub-id-type="pmid">36977580</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yadav</surname><given-names>RSP</given-names></name><name><surname>Ansari</surname><given-names>F</given-names></name><name><surname>Bera</surname><given-names>N</given-names></name><name><surname>Kent</surname><given-names>C</given-names></name><name><surname>Agrawal</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Lessons from lonely flies: Molecular and neuronal mechanisms underlying social isolation</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>156</volume><elocation-id>105504</elocation-id><pub-id pub-id-type="doi">10.1016/j.neubiorev.2023.105504</pub-id><pub-id pub-id-type="pmid">38061597</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Guo</surname><given-names>L</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Spatial comparisons of mechanosensory information govern the grooming sequence in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>30</volume><fpage>988</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.01.045</pub-id><pub-id pub-id-type="pmid">32142695</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105465.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cardona</surname><given-names>Albert</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This study presents a <bold>valuable</bold> open-source and cost-effective method for automating the quantification of male aggression and courtship in <italic>Drosophila melanogaster</italic>. The work as presented provides <bold>solid</bold> evidence that the use of the behavioral setup that the authors designed - using readily available laboratory equipment and standardised high-performing classifiers they developed using existing software packages - accurately and reliably characterises social behavior in Drosophila. The work will be of interest to Drosophila neurobiologists and particularly to those working on male social behaviors.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105465.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The study introduces an open-source, cost-effective method for automating the quantification of male social behaviors in <italic>Drosophila melanogaster</italic>. It combines machine-learning based behavioral classifiers developed using JAABA (Janelia Automatic Animal Behavior Annotator) with inexpensive hardware constructed from off-the-shelf components. This approach addresses the limitations of existing methods, which often require expensive hardware and specialized setups. The authors demonstrate that their new &quot;DANCE&quot; classifiers accurately identify aggression (lunges) and courtship behaviors (wing extension, following, circling, attempted copulation, and copulation), closely matching manually annotated ground-truth data. Furthermore, DANCE classifiers outperform existing rule-based methods in accuracy. Finally, the study shows that DANCE classifiers perform as well when used with low-cost experimental hardware as with standard experimental setups across multiple paradigms, including RNAi knockdown of the neuropeptide Dsk and optogenetic silencing of dopaminergic neurons.</p><p>The authors make creative use of existing resources and technology to develop an inexpensive, flexible, and robust experimental tool for the quantitative analysis of Drosophila behavior. A key strength of this work is the thorough benchmarking of both the behavioral classifiers and the experimental hardware against existing methods. In particular, the direct comparison of their low-cost experimental system with established systems across different experimental paradigms is compelling. A weakness of the study is that the use of JAABA-based classifiers to analyze aggression and courtship is not novel (Tao et al., J. Neurosci., 2024; Sten et al., Cell, 2023; Chiu et al., Cell, 2021; Isshi et al., eLife, 2020; Duistermars et al., Neuron, 2018). However, the demonstration the JAABA classifiers they developed work as well without expensive experimental hardware opens the door to more low-cost systems for quantitative behavior analysis.</p><p>In summary, this work provides a practical and accessible approach to quantifying Drosophila behavior, reducing the economic barriers to the study of the neural and molecular mechanisms underlying social behavior.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105465.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This manuscript addresses the development of a low-cost behavioural setup and standardised open-source high performing classifiers for aggression and courtship behaviour. It does so by using readily available laboratory equipment and previously developed software packages. By comparing the performance of the setup and the classifiers to previously developed ones, this study shows the classifier's overperformance and the reliability of the low-cost setup in recapitulating previously described effects of different manipulations on aggression and courtship.</p><p>Strengths:</p><p>The newly developed classifiers for lunges, wing extension, attempted copulation, copulation, following, circling, perform better than previously available developed ones. The behavioural setup developed is low cost and reliably allows analysis of both aggression and courtship behaviour, validated through social experience manipulation (social isolation), gene knock (Dsk in Dilp2 neurons) and neuronal inactivation (dopaminergic neurons) know to affect courtship and aggression.</p><p>Weaknesses:</p><p>This framework only encompasses analysis of lunges, while aggression encompasses multiple behaviours. Even though DANCE can serve as a template allowing future development of additional classifiers, the current study compares performance to CADABRA which analyses further aggression behaviours, making the comparisons incomplete.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105465.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The study by Yadav et al. describes a new setup to quantify a number of aggression and mating behaviors in <italic>Drosophila melanogaster</italic>. The investigation of these behaviors requires the analysis of large number of videos to identify each kind of behavior displayed by a fly. Several approaches to automatize this process have been published before, but each of them has their limitations. The authors set out to develop a new setup that includes a very low-cost, easy to acquire hardware and open-source machine-learning classifiers to identify and quantify the behavior.</p><p>Strengths:</p><p>(1) The study demonstrates that their cheap, simple, and easy to obtain hardware works just as well as custom-made, specialized hardware for analyzing aggression and mating behavior. This enables the setup to be used in a wide range of settings, from research with limited resources to classroom teaching.</p><p>(2) The authors used previously published software to train new classifiers for detecting a range of behaviors related to aggression and mating and make them freely available. The classifiers are very positively benchmarked against a manually acquired ground-truth as well as existing algorithms.</p><p>(3) The study demonstrates the applicability of the setup (hardware and classifiers) to common methods in the field by confirming a number of expected phenotypes with their setup.</p><p>Taken together, this work can greatly facilitate research of aggression and mating in Drosophila. The combination of low-cost, off-the-shelf hardware and open-source, robust software enables researchers with very little funding or technical expertise to contribute to the scientific process, and also allows large-scale experiments, for example, in classroom teaching with many students, or for systematic screenings.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105465.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Yadav</surname><given-names>R Sai Prathap</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Dey</surname><given-names>Paulami</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Ansari</surname><given-names>Faizah</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Kottat</surname><given-names>Tanvi</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Vasam</surname><given-names>Manohar</given-names></name><role specific-use="author">Author</role><aff><institution>Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Manipal</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Prabhu</surname><given-names>P Pallavi</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Ayyangar</surname><given-names>Shrinivas</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>S</surname><given-names>Swathi Bhaskar</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Prabhu</surname><given-names>Krishnananda</given-names></name><role specific-use="author">Author</role><aff><institution>Department of Biochemistry, Kasturba Medical College, Manipal, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Ghosh</surname><given-names>Monalisa</given-names></name><role specific-use="author">Author</role><aff><institution>Centre for Molecular Neurosciences, Kasturba Medical College, Manipal, Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="author"><name><surname>Agrawal</surname><given-names>Pavan</given-names></name><role specific-use="author">Author</role><aff><institution>Manipal Academy of Higher Education</institution><addr-line><named-content content-type="city">Udupi</named-content></addr-line><country>India</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public review):</bold></p><p>The study introduces an open-source, cost-effective method for automating the quantification of male social behaviors in <italic>Drosophila melanogaster</italic>. It combines machine-learning-based behavioral classifiers developed using JAABA (Janelia Automatic Animal Behavior Annotator) with inexpensive hardware constructed from off-the-shelf components. This approach addresses the limitations of existing methods, which often require expensive hardware and specialized setups. The authors demonstrate that their new &quot;DANCE&quot; classifiers accurately identify aggression (lunges) and courtship behaviors (wing extension, following, circling, attempted copulation, and copulation), closely matching manually annotated groundtruth data. Furthermore, DANCE classifiers outperform existing rule-based methods in accuracy. Finally, the study shows that DANCE classifiers perform as well when used with low-cost experimental hardware as with standard experimental setups across multiple paradigms, including RNAi knockdown of the neuropeptide Dsk and optogenetic silencing of dopaminergic neurons.</p><p>The authors make creative use of existing resources and technology to develop an inexpensive, flexible, and robust experimental tool for the quantitative analysis of Drosophila behavior. A key strength of this work is the thorough benchmarking of both the behavioral classifiers and the experimental hardware against existing methods. In particular, the direct comparison of their low-cost experimental system with established systems across different experimental paradigms is compelling.</p><p>While JAABA-based classifiers have been previously used to analyze aggression and courtship (Tao et al., J. Neurosci., 2024; Sten et al., Cell, 2023; Chiu et al., Cell, 2021; Isshi et al., eLife, 2020; Duistermars et al., Neuron, 2018), the demonstration that they work as well without expensive experimental hardware opens the door to more low-cost systems for quantitative behavior analysis.</p></disp-quote><p>We thank the reviewer for their positive assessment and constructive suggestions. We have cited these additional JAABA studies in the Introduction<bold>.</bold> We clarified that several prior JAABA-based classifiers were developed using specialized machinevision cameras or custom setups, and that in some cases the original code and classifiers were not made publicly available, which limits reproducibility and wider adoption. To address this, we explicitly note in the revised manuscript that DANCE was developed with accessibility in mind.</p><disp-quote content-type="editor-comment"><p>Although the study provides a detailed evaluation of DANCE classifier performance, its conclusions would be strengthened by a more comprehensive analysis. The authors assess classifier accuracy using a bout-level comparison rather than a frame-level analysis, as employed in previous studies (Kabra et al., Nat Methods, 2013). They define a true positive as any instance where a DANCE-detected bout overlaps with a manually annotated ground-truth bout by at least one frame. This criterion may inflate true positive rates and underestimate false positives, particularly for longer-duration courtship behaviors. For example, a 15-second DANCE-classified wing extension bout that overlaps with ground truth for only one frame would still be considered a true positive. A frame-level analysis performance would help address this possibility.</p></disp-quote><p>We thank the reviewer for raising this important point. Our original use of bout-level analysis followed existing literature (Duistermars et al., 2018; Ishii et al., 2020; Chiu et al., 2021; Tao et al., 2024; Hindmarsh Sten et al., 2025). While our lunge classifier already operates at the frame level, we have now performed additional frame-level evaluations for the duration based courtship classifiers. These analyses revealed only minor differences in precision, recall, and F1 scores compared with the original bout-level approach (see new Figure 5—Figure Supplement 3). Details of this analysis are now included in the Materials and Methods.</p><disp-quote content-type="editor-comment"><p>In summary, this work provides a practical and accessible approach to quantifying Drosophila behavior, reducing the economic barriers to the study of the neural and molecular mechanisms underlying social behavior.</p></disp-quote><p>We thank the reviewer for their encouraging comments and for recognizing the accessibility and practical value of our approach. We appreciate the constructive suggestions, which have helped strengthen the manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>This manuscript addresses the development of a low-cost behavioural setup and standardised open-source high-performing classifiers for aggression and courtship behaviour. It does so by using readily available laboratory equipment and previously developed software packages. By comparing the performance of the setup and the classifiers to previously developed ones, this study shows the classifier's overperformance and the reliability of the low-cost setup in recapitulating previously described effects of different manipulations on aggression and courtship.</p><p>Strengths:</p><p>The newly developed classifiers for lunges, wing extension, attempted copulation, copulation, following, and circling, perform better than available previously developed ones. The behavioural setup developed is low cost and reliably allows analysis of both aggression and courtship behaviour, validated through social experience manipulation (social isolation), gene knock (Dsk in Dilp2 neurons) and neuronal inactivation (dopaminergic neurons) known to affect courtship and aggression.</p></disp-quote><p>We thank the reviewer for the clear summary of our work and for highlighting its strengths. We appreciate these positive comments and suggestions, which have helped improve the clarity of the manuscript.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>Aggression encompasses multiple defined behaviours, yet only lunges were analysed. Moreover, the CADABRA software to which DANCE was compared analyses further aggression behaviours, making their comparisons incomplete. In addition, though DANCE performs better than CADABRA and Divider in classifying lunges in the behavioural setup tested, it did not yield very high recall and F1 scores.</p></disp-quote><p>We thank the reviewer for raising this important point. We focused on lunges because they are widely used as a standard proxy for male aggression across multiple laboratories (Agrawal et al., 2020; Asahina et al., 2014; Chiu et al., 2021; Chowdhury et al., 2021; Dierick et al., 2007; Hoyer et al., 2008; Jung et al., 2020; Nilsen et al., 2004; Watanabe et al., 2017). As noted in the Discussion, our study also provides a template for the future development of additional aggression classifiers (fencing, wing flick, tussle, chase, female headbutt) and courtship classifiers (tapping, licking, rejection), which can be trained and shared through the same DANCE framework. Developing and validating these was beyond the scope of the present work.</p><p>To address the concern regarding precision, recall, and F1 scores, we performed additional analyses across all training videos and compiled these results in the new Figure 2—Figure Supplement 2. Our earlier lunge classifier had performance metrics obtained after training on a total of 11 videos. Our analysis shows performance metrics for classifiers trained on four independent datasets (Videos 8– 11). We found that the classifier trained on nine videos provided the best balance of precision, recall, and F1 (78.73%, 73.07%, and 75.79%, respectively), which was slightly better than the earlier classifier. We therefore updated the main figure, text, and Materials and Methods to use this version and uploaded the corresponding classifier and training details to the GitHub repository.</p><disp-quote content-type="editor-comment"><p>DANCE is of limited use for neuronal circuit-level enquiries, since mechanisms for intensity and temporally controlled optogenetic manipulations, which are nowadays possible with open-source software and low-cost hardware, were not embedded in its development.</p></disp-quote><p>We thank the reviewer for this valuable point. The primary aim of DANCE is to provide an accessible, modular, and low-cost behavioural recording and analysis platform. It was designed so that users can readily integrate additional components such as optogenetic control when needed. As a proof of concept, we implemented optogenetic silencing of dopaminergic neurons using the DANCE hardware and confirmed that this manipulation increased aggression (Figure 7R).</p><p>To facilitate adoption, we now provide schematic diagrams, LED control code, and instructions on our GitHub page and setup photographs in the manuscript (see new Figure 7—Figure Supplement 1). The released code allows programmable timing and intensity control, enabling users to reproduce temporally precise optogenetic protocols or extend the system for other stimulation paradigms.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public review):</bold></p><p>The preprint by Yadav et al. describes a new setup to quantify a number of aggression and mating behaviors in <italic>Drosophila melanogaster</italic>. The investigation of these behaviors requires the analysis of a large number of videos to identify each kind of behavior displayed by a fly. Several approaches to automatize this process have been published before, but each of them has its limitations. The authors set out to develop a new setup that includes very low-cost, easy-to-acquire hardware and open-source machine-learning classifiers to identify and quantify the behavior.</p><p>Strengths:</p><p>(1) The study demonstrates that their cheap, simple, and easy-to-obtain hardware works just as well as custom-made, specialized hardware for analyzing aggression and mating behavior. This enables the setup to be used in a wide range of settings, from research with limited resources to classroom teaching.</p><p>(2) The authors used previously published software to train new classifiers for detecting a range of behaviors related to aggression and mating and to make them freely available. The classifiers are very positively benchmarked against a manually acquired ground truth as well as existing algorithms.</p><p>(3) The study demonstrates the applicability of the setup (hardware and classifiers) to common methods in the field by confirming a number of expected phenotypes with their setup.</p></disp-quote><p>We thank the reviewer for the positive assessment of our work and for highlighting its strengths. We appreciate these encouraging comments and suggestions, which have helped improve the clarity and presentation of the manuscript.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>(1) When measuring the performance of the duration-based classifiers, the authors count any bout of behavior as true positive if it overlaps with a ground-truth positive for only 1 frame - despite the minimal duration of a bout is 10 frames, and most bouts are much longer. That way, true positives could contain cases that are almost totally wrong as long there was an overlap of a single frame. For the mating behaviors that are classified in ongoing bouts, I think performance should be evaluated based on the % of correctly classified frames, not bouts.</p></disp-quote><p>We thank the reviewer for raising this concern. In response to this point, and to Reviewer #1’s similar comment, we performed a frame-level evaluation of all duration-based courtship classifiers. The analysis revealed only minor differences compared with the original bout-level metrics (see new Figure 5—Figure Supplement 3), confirming the robustness of our classifiers. We have also added a description of this analysis in the Materials and Methods section.</p><disp-quote content-type="editor-comment"><p>(2) In the methods part, only one of the pre-existing algorithms (MateBook), is described. Given that the comparison with those algorithms is a so central part of the manuscript, each of them should be briefly explained and the settings used in this study should be described.</p></disp-quote><p>We thank the reviewer for this helpful suggestion. In the revised manuscript, we expanded the Materials and Methods to include concise descriptions and parameter settings for all pre-existing algorithms used for comparison. This includes dedicated subsections for CADABRA and the Divider assay, with explicit reference to their rulebased or geometric features. For MateBook, we specified the persistence filters used and the adjustments made for fair benchmarking. These changes ensure transparency and reproducibility.</p><disp-quote content-type="editor-comment"><p>Taken together, this work can greatly facilitate research on aggression and mating in Drosophila. The combination of low-cost, off-the-shelf hardware and open-source, robust software enables researchers with very little funding or technical expertise to contribute to the scientific process and also allows large-scale experiments, for example in classroom teaching with many students, or for systematic screenings.</p></disp-quote><p>We thank the reviewer for the encouraging comments and for recognizing the accessibility and broad applicability of DANCE. We believe these revisions have further strengthened the manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>The following comments highlight areas where additional context, clarification, or further analysis could strengthen the manuscript. I hope these suggestions will be useful in refining your work.</p><p>(1) Lines 71-73: The authors state that Ctrax &quot;leads to frequent identity switches among tracked flies, which is not the case while using FlyTracker.&quot; However, Ctrax was specifically designed to minimize identity errors, and Kabra et al. (2013) reported a low frequency of such errors-approximately one per five fly-hours in 10-fly videos. In contrast, Caltech FlyTracker does not correct identity errors automatically, requiring manual corrections, as noted in the Methods section of this study. If this is not an oversight, please provide further context to clarify this distinction.</p></disp-quote><p>We thank the reviewer for raising this clarification. As reported by Bentzur et al. (2021), when groups of flies were tracked simultaneously, Ctrax often generated multiple identities for the same individual, sometimes producing more trajectories than the actual number of flies. To prevent ambiguity, we revised the text to read: “While both Ctrax and FlyTracker (Eyjolfsdottir et al., 2014) may produce identity switches, when groups of flies were tracked simultaneously, Ctrax led to inaccuracies that required manual correction using specialized algorithms such as FixTrax (Bentzur et al., 2021).” We also quantified FlyTracker identity-switch rates in our datasets and report them in new Supplementary File 5, confirming that such events were rare (&lt; 2% of tracked intervals). We believe, this updated version provides the necessary context and ensures accuracy in describing each tracker’s limitations.</p><disp-quote content-type="editor-comment"><p>(2) Line 85: Providing additional context on how this study builds on previous work using JAABA-based classifiers for fly social behavior and comparing these classifiers to rule-based methods would more accurately situate it within the field. The authors state that &quot;recently, a few JAABA-based classifiers have been developed for measuring aggression and courtship&quot; and cite four related studies. However, this statement seems to underrepresent the use of JAABA-based classifiers for quantifying fly social behavior, which has become common in the field. Several additional studies (as noted in the public review) have developed JAABA-based classifiers for scoring aggression or courtship. Furthermore, other studies have compared the performance of JAABA-based classifiers with rule-based classifiers like CADABRA (e.g., Chowdhury et al., Comm Biology 2021; Leng et al., PlosOne 2020; Kabra et al., Nat Methods 2013). Mentioning the similar findings in those studies and your own helps strengthen the conclusion that machine-learning-based classifiers outperform rule-based classifiers in several experimental contexts.</p></disp-quote><p>We thank the reviewer for this helpful suggestion. We have revised the Introduction to include additional references to studies that applied JAABA-based classifiers for aggression and courtship and made textual edits to reflect this. We further noted that, unlike several previous studies, all DANCE classifiers and analysis code are publicly available.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>(1) Suggestions for improved or additional experiments, data or analyses: As mentioned in the description of the effect of optogenetic inactivation of dopaminergic neurons, in the conclusion and also reported in the literature, there are other important identified aggression behaviours, such as fencing, wing flick, tussle, and chase. Similarly, for courtship, tapping and licking have also been defined. This study, as opposed to proposed future studies, would benefit from creating opensource classifiers for these established behaviours, which are important for the analysis of aggression and courtship.</p></disp-quote><p>We thank the reviewer for this valuable suggestion. As clarified in the Discussion, this manuscript intentionally focuses on six core, well-validated aggression and courtship behaviors to demonstrate DANCE’s modularity and reproducibility. Developing additional classifiers such as fencing, wing flick, tussle, chase, tapping, and licking would require extensive annotation and validation beyond the present scope. To address this point, we explicitly note in the revised text that the DANCE pipeline is readily extendable, allowing the community to build new classifiers within the same framework.</p><disp-quote content-type="editor-comment"><p>In terms of observer bias assessment for ground-truthing in courtship, this was only presented for circling and it would be beneficial to have encompassed all behaviours analysed.</p></disp-quote><p>We thank the reviewer for this suggestion. Observer-bias comparisons for all six classifiers are presented in Figure 2—Figure Supplement 1 (panels A–F). We clarified in the Results that annotations from two independent evaluators were compared for all classifiers, with no significant differences observed, confirming their robustness.</p><disp-quote content-type="editor-comment"><p>Finally, intensity and temporal optogenetic control are important for neuronal circuit analysis of underlying behaviour. The authors could embed this aspect in DANCE by integrating control of the green light LED strip used in this study using, for example, the open-source visual reactive programming software Bonsai (Lopes et al., 2015) and open-source electronics platform Arduino. This is an important and valuable addition in line with maintaining low cost.</p></disp-quote><p>We thank the reviewer for this valuable suggestion. DANCE was designed to be modular, allowing integration of temporal optogenetic control. To support immediate adoption, we now provide Arduino LED control code, setup schematics, and photographs (new Figure 7—Figure Supplement 1) along with step-by-step instructions on our GitHub page. We also note that Bonsai and Arduino frameworks are compatible with DANCE, enabling future extensions for closed-loop or behaviortriggered stimulation.</p><disp-quote content-type="editor-comment"><p>(2) Minor corrections to the text and figures:</p><p>Figure Supplement 1 refers only to Figure 2, yet panels D-F refer to the behaviour circling in courtship and therefore should be assigned to the respective figure.</p></disp-quote><p>Thanks, we have corrected this.</p><disp-quote content-type="editor-comment"><p>In lines 315-316, the cumbersome task of fluon coating for aggression assays seems to be ubiquitous across assays which is not the case, and therefore the sentence should include the word 'some'.</p></disp-quote><p>Thanks, we have edited this.</p><disp-quote content-type="editor-comment"><p>The cost of the phone and/or tablet should be included in the DANCE setup costs, as presumably these devices will be dedicated to the behavioural studies, for consistency purposes.</p></disp-quote><p>We thank the reviewer for this comment. We intentionally did not include smartphones or tablets in the setup cost because, in our experiments, these devices were not dedicated exclusively to DANCE but were repurposed from routine personal use. Our aim was to leverage readily available consumer electronics so that their cost does not become a barrier to adoption. We confirmed that commonly available Android phones capable of 30 fps at 1080p in H.264 format, as well as tablets or phones running a simple white-screen light app, are sufficient for reliable behavior classification and illumination. Since these devices can be returned to regular use after recordings, including their cost in the setup would not accurately reflect the intended accessibility of DANCE. For consistency, we now clarify in the Materials and Methods that such devices should be placed in airplane mode during recordings.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations for the authors):</bold></p><p>(1) For my taste, the authors put too much emphasis on the point that their method outperforms existing methods. I understand the value in comparing to published methods and it is of course fully justified to state the advantages of the new method. But the whole preprint is set up as a competition with the old algorithms, and the conclusion that the new classifier is better is repeated in each figure caption and after each paragraph of the results. This competitive mindset also extends to the selection of which results are presented as main figures and which as supplements - all cases in which the previous methods actually perform well are only presented in the supplement. I think this is simply unnecessary as the authors' results speak for themselves, and do not need the continuous competitive comparison.</p></disp-quote><p>We thank the reviewer for this thoughtful suggestion. Our intention was to benchmark DANCE rigorously against existing methods, not to frame the study competitively. We agree that repeated emphasis on relative performance was unnecessary. In the revised version, we streamlined figure captions and text throughout the manuscript to balance comparisons and removed redundant phrasing. Instances where other methods performed well are now presented with equal clarity to maintain a neutral and informative tone.</p><disp-quote content-type="editor-comment"><p>(2) When describing the DANCE hardware, as a reader I would find it interesting to also read about potential issues that the authors encountered. For example, how difficult is it to handle the materials without breaking or deforming them, which could affect the behavioral assays? How critical is it to use specific blister packs - the availability of which will likely vary strongly between countries? Did the authors try different sizes, and products? Such information, even as a supplement, could be very helpful for the widespread use of the hardware.</p></disp-quote><p>We thank the reviewer for this important point. To address this, we conducted additional tests comparing DANCE arenas of different diameters (new Figure 7— Figure Supplement 3A–C and new Figure 7—Figure Supplement 4A–L). We also consulted colleagues in multiple countries and verified that the blister packs used in our assays are readily available. The Materials and Methods now include practical handling notes: blister foils can be reused ~30–40 times for aggression assays and ~10–15 times for courtship assays before deformation. We also describe how to prevent agar surface damage during assembly and how to wash and dry the arenas for optimal reusability.</p><disp-quote content-type="editor-comment"><p>(3) I find the arrows pointing to several videos in a number of figures rather distracting and redundant, and suggest omitting them.</p></disp-quote><p>Thanks<bold>,</bold> we have omitted these arrows from all relevant figures and clarified the figure legends to enhance readability.</p><disp-quote content-type="editor-comment"><p>(4) P8, line 169 ff: this is a very long sentence that should be separated into several sentences.</p></disp-quote><p>We have rewritten this as follows: “DANCE scores remained comparable to groundtruth scores across all categories, whereas CADABRA and Divider underestimated the lunge counts (Figure 2B–E). Correlation analysis revealed a strong relationship between DANCE and ground-truth scores (Figure 2F, Supplementary File 2). In comparison, CADABRA and the Divider assay classifier showed a weaker correlation (Figure 2G-H, Supplementary File 2).”</p><disp-quote content-type="editor-comment"><p>(5) P10, line 216: please explain, here and in the methods, how these behavioral indices are calculated. I did not find this information anywhere in the paper.</p></disp-quote><p>We thank the reviewer for pointing this out. We now define the behavioral index explicitly in Materials and Methods: “For each assay, a behavioral index was calculated as the proportion of frames in which the male engaged in the specified behavior. This was obtained by dividing the total number of frames annotated for that behavior by the total number of frames in the recording.”</p><disp-quote content-type="editor-comment"><p>(6) P11, line 253: I don't understand the modifications to MateBook regarding attempted copulations, neither in the results nor the methods section. I would ask the authors to explain more explicitly what was done.</p></disp-quote><p>We thank the reviewer for this helpful suggestion. We have re-written several parts of the Materials and methods to clarify these details and streamline the text. To train the attempted copulation classifier, we combined datasets from assays with mated and decapitated virgin females, using manual annotations as ground truth. We also adapted MateBook’s persistence filters (Ribeiro et al., 2018) and defined thresholds explicitly: mounting lasting &gt;45 s (&gt;1350 frames at 30 fps) was defined as copulation, whereas abdominal curling without mounting, or mounting lasting 0.33– 45 s, was defined as attempted copulation.</p><disp-quote content-type="editor-comment"><p>(7) Figure 7F: this is the only case with a significant difference between the two setups. What explanations do the authors have for the discrepancy?</p></disp-quote><p>We thank the reviewer for raising this point<bold>.</bold> After repeating the experiments, we no longer found a significant difference between the setups. Figure 7 and its legend have been updated to reflect these results.</p><disp-quote content-type="editor-comment"><p>(8) Figure 2 - Supplement 1: I do not understand why the boxes for Observer 1 have different colors in different figures. Does this have a meaning?</p></disp-quote><p>Thanks for pointing this out. The color differences had no intended meaning, and we have corrected the figure for consistency across panels.</p><disp-quote content-type="editor-comment"><p>(9) P22, line 517ff: It would be interesting to know how frequently identity switches occurred. For large-scale, automatic behavioral screenings that step could be a crucial bottleneck.</p></disp-quote><p>We thank the reviewer for this valuable suggestion. We analyzed identity switches using the FlyTracker “Visualizer” package, which flags frames with possible overlaps or jumps. Flagged intervals were manually verified, and we report these data in new Supplementary File 5. Identity switch rates were very low: 0.66% for high-resolution recordings and 1.9% for smartphone DANCE videos in the most challenging decapitated-virgin dataset. These findings demonstrate robust tracking performance under both setups.</p></body></sub-article></article>