<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">71069</article-id><article-id pub-id-type="doi">10.7554/eLife.71069</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group></article-categories><title-group><article-title>Simplifying the development of portable, scalable, and reproducible workflows</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-36092"><name><surname>Piccolo</surname><given-names>Stephen R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2001-5640</contrib-id><email>stephen_piccolo@byu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242291"><name><surname>Ence</surname><given-names>Zachary E</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242292"><name><surname>Anderson</surname><given-names>Elizabeth C</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242293"><name><surname>Chang</surname><given-names>Jeffrey T</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-116338"><name><surname>Bild</surname><given-names>Andrea H</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution>Department of Biology, Brigham Young University</institution><addr-line><named-content content-type="city">Provo</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Department of Integrative Biology and Pharmacology, University of Texas Health Science Center at Houston</institution><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Department of Medical Oncology and Therapeutics, City of Hope Comprehensive Cancer Institute</institution><addr-line><named-content content-type="city">Monrovia</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Robles-Espinoza</surname><given-names>C Daniela</given-names></name><role>Reviewing Editor</role><aff><institution>International Laboratory for Human Genome Research</institution><country>Mexico</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Walczak</surname><given-names>Aleksandra M</given-names></name><role>Senior Editor</role><aff><institution>École Normale Supérieure</institution><country>France</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>13</day><month>10</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e71069</elocation-id><history><date date-type="received" iso-8601-date="2021-06-09"><day>09</day><month>06</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-09-27"><day>27</day><month>09</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-05-01"><day>01</day><month>05</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.04.30.442204"/></event></pub-history><permissions><copyright-statement>© 2021, Piccolo et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Piccolo et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-71069-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-71069-figures-v1.pdf"/><abstract><p>Command-line software plays a critical role in biology research. However, processes for installing and executing software differ widely. The Common Workflow Language (CWL) is a community standard that addresses this problem. Using CWL, tool developers can formally describe a tool’s inputs, outputs, and other execution details. CWL documents can include instructions for executing tools inside software containers. Accordingly, CWL tools are portable—they can be executed on diverse computers—including personal workstations, high-performance clusters, or the cloud. CWL also supports workflows, which describe dependencies among tools and using outputs from one tool as inputs to others. To date, CWL has been used primarily for batch processing of large datasets, especially in genomics. But it can also be used for analytical steps of a study. This article explains key concepts about CWL and software containers and provides examples for using CWL in biology research. CWL documents are text-based, so they can be created manually, without computer programming. However, ensuring that these documents conform to the CWL specification may prevent some users from adopting it. To address this gap, we created ToolJig, a Web application that enables researchers to create CWL documents interactively. ToolJig validates information provided by the user to ensure it is complete and valid. After creating a CWL tool or workflow, the user can create ‘input-object’ files, which store values for a particular invocation of a tool or workflow. In addition, ToolJig provides examples of how to execute the tool or workflow via a workflow engine. ToolJig and our examples are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/srp33/ToolJig">https://github.com/srp33/ToolJig</ext-link>.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>computational workflows</kwd><kwd>research reproducibility</kwd><kwd>learn by example</kwd><kwd>Web application</kwd><kwd>Common Workflow Language</kwd><kwd>command-line software</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>U54CA209978</award-id><principal-award-recipient><name><surname>Piccolo</surname><given-names>Stephen R</given-names></name><name><surname>Ence</surname><given-names>Zachary E</given-names></name><name><surname>Chang</surname><given-names>Jeffrey T</given-names></name><name><surname>Bild</surname><given-names>Andrea</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Descriptions, examples, and tools to enable biologists to use the Common Workflow Language for data processing and to facilitate computational reproducibility.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Software is fundamental to modern scientific research (<xref ref-type="bibr" rid="bib23">Hey et al., 2009</xref>; <xref ref-type="bibr" rid="bib49">Wilson, 2014</xref>). It can accelerate the pace of research, formalize algorithmic logic, and support reproducibility (<xref ref-type="bibr" rid="bib40">Piccolo and Frampton, 2016</xref>). In a 2014 survey, 92% of academic scientists reported using software in their research (<xref ref-type="bibr" rid="bib25">Hong, 2014</xref>). Our article focuses on command-line <italic>tools</italic>, which scientists use in many disciplines (<xref ref-type="bibr" rid="bib30">Kumar and Dudley, 2007</xref>) and which provide advantages over point-and-click tools. In particular, the process of executing command-line tools can be formalized (<xref ref-type="bibr" rid="bib30">Kumar and Dudley, 2007</xref>; <xref ref-type="bibr" rid="bib40">Piccolo and Frampton, 2016</xref>). Our article also focuses on computational <italic>workflows</italic>, which are defined series of steps for processing or analyzing data (<xref ref-type="bibr" rid="bib33">Leipzig, 2017</xref>). Each step in a workflow applies one or more command-line tools to the data with specific inputs, outputs, and configuration settings. A <italic>workflow engine</italic> is a software system for executing workflows. For example, the Snakemake and Nextflow workflow engines facilitate execution of workflows and are used widely for scientific research (<xref ref-type="bibr" rid="bib15">Di Tommaso et al., 2017</xref>; <xref ref-type="bibr" rid="bib28">Köster and Rahmann, 2012</xref>). These and other workflow engines provide flexibility regarding the computing environment in which a workflow is executed, allowing researchers to use local, cluster-, or cloud-based computers. In many cases, workflow steps can be executed in parallel. With this flexibility comes the challenge of ensuring that operating system and tool configurations are consistent across all computers used. This process is made easier when workflows provide instructions for executing the steps within software containers (<xref ref-type="bibr" rid="bib7">Boettiger, 2015</xref>).</p><p>In scientific research, the use of workflows can be classified into two main categories. One category includes <italic>orchestration</italic> systems, in which workflow engines repeatedly process data of a given type. For example, a genomics core facility might use a workflow to ingest DNA-sequencing data, align reads to a reference genome, and call DNA variants, as well as other steps in between. The core facility might have other workflows for processing RNA-sequencing or bisulfite-sequencing data. In some cases, a modular design might be useful; for example, some command-line tools could be reused in multiple workflows. In this scenario, data throughput is a key concern, so the workflow engine might be connected to cluster- or cloud-based computer environments, allowing throughput to scale as needs fluctuate. Arvados and Tibanna are examples of cloud-based orchestration systems (<xref ref-type="bibr" rid="bib1">Amstutz, 2015</xref>; <xref ref-type="bibr" rid="bib32">Lee et al., 2019</xref>). Scientists might also take advantage of error handling provided by some workflow engines. For example, if a power outage occurred while a workflow was being executed, it would be possible to restart the workflow at the point of failure rather than needing to rerun the entire workflow. A second way that workflows are used in scientific research is to support reproducibility of a particular analysis. When performing research studies, scientists often use existing software and write custom code to process data, apply statistical tests, create graphics, etc. Inherently, the particular combination of computational tasks used in a given study should be unique. Therefore, there is no need to orchestrate the tasks for repeated execution. However, much benefit can come from sharing the code with the scientific community and ensuring that others can easily re-execute the code (<xref ref-type="bibr" rid="bib40">Piccolo and Frampton, 2016</xref>). Workflows aid in this process because they provide a way to encapsulate the logic for executing code in a fully specified computational environment with all necessary software dependencies installed. For many studies, a relatively simple workflow engine like <italic>cwltool</italic> (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_015528">SCR_015528</ext-link>) can be used to re-execute the analyses.</p><p>Different workflow engines use different methodologies and vocabularies for defining workflows and for interfacing with software within those workflows (<xref ref-type="bibr" rid="bib33">Leipzig, 2017</xref>). For example, to use Snakemake or Nextflow, a researcher can specify a workflow using a custom programming language that is specific to either workflow engine. These languages are extensions of Python and Groovy, respectively. Python and Groovy are familiar to many researchers, making them relatively easy for these researchers to adopt. However, if a researcher does not have programming expertise, is not familiar with these programming languages, or wants to switch between workflow engines, workflow creation might be difficult or time-consuming. Such challenges motivated creation of the Common Workflow Language (CWL), a formal specification for describing command-line tools and workflows (<xref ref-type="bibr" rid="bib2">Amstutz et al., 2016</xref>). The CWL project is a community-based, collaborative effort driven by individuals and institutions across diverse disciplines; participation is open to anyone. These efforts should help to ensure the project’s longevity and acceptance among researchers. Indeed, CWL documents are already recognized by many workflow engines, including Snakemake (<xref ref-type="bibr" rid="bib28">Köster and Rahmann, 2012</xref>), <italic>cwltool</italic>, Toil (<xref ref-type="bibr" rid="bib46">Vivian et al., 2017</xref>), Apache Airflow (<xref ref-type="bibr" rid="bib29">Kotliar et al., 2019</xref>), Tibanna (<xref ref-type="bibr" rid="bib32">Lee et al., 2019</xref>), and Arvados (<xref ref-type="bibr" rid="bib1">Amstutz, 2015</xref>).</p><p>By creating CWL documents, scientists can describe tools and workflows in a way that is standards-based and agnostic to the workflow engine(s) on which they are executed. CWL documents are text-based files and thus can be created via a text editor without doing any computer programming. Despite this simplicity, many researchers have yet to adopt CWL. Useful tutorials are available online (<xref ref-type="bibr" rid="bib11">Common Workflow Language working group, 2021</xref>), but the CWL specification provides great flexibility, so researchers face a learning curve to ensure that documents are specified correctly. Some software applications are available to aid in this process. For example, <italic>Rabix Composer</italic> is a desktop application that enables researchers to create and edit CWL documents (<xref ref-type="bibr" rid="bib3">Amstutz et al., 2021</xref>). This application supports many features in the CWL specification and provides text-based as well as visual editors. However, researchers unfamiliar with nuanced details of the CWL specification may find Rabix Composer too advanced for their needs, and it does not support the latest versions of CWL. Alternatively, CWL plugins exist for many code editors (<xref ref-type="bibr" rid="bib11">Common Workflow Language working group, 2021</xref>). In addition, developers have created application programming interfaces that enable researchers to build CWL documents. However, many researchers who could benefit from CWL lack the programming expertise to use these resources.</p><p>In this article, we illustrate how to use CWL to describe command-line tools and workflows and to perform reproducible research analyses. We provide 27 examples of CWL documents for completing diverse types of research tasks, ranging from simple (e.g., printing custom messages to the console) to advanced (identifying differentially expressed genes or calling somatic mutations in cancer genomes). In addition, we introduce <italic>ToolJig</italic>, a Web application that enables researchers to create CWL documents. <italic>ToolJig</italic> provides a simple, interactive interface that requires no installation and includes prompts to guide the user. Via <italic>ToolJig</italic>, a researcher can specify details about a tool’s expected inputs and outputs, operating-system environment, and auxiliary files (e.g., scripts, configuration files). Researchers can also create workflows that integrate these tools. <italic>ToolJig</italic> checks the information provided by the user to ensure it is complete and valid. After successfully describing a tool or workflow, the researcher can download CWL files and use <italic>ToolJig</italic> to create ‘input-object’ files, which store input values for a particular invocation of a tool or workflow. In addition, <italic>ToolJig</italic> provides examples of how to execute the tool or workflow via a workflow engine.</p><sec id="s1-1"><title>Using containers to manage software installation and configuration</title><p>First, we address software installation and configuration, which are essential steps to creating CWL tools and workflows. These seemingly simple steps are fraught with challenges. Although the software may be downloadable from a public website, installation instructions are sometimes vague, the process may involve many steps, and these steps may differ for each operating system. Such challenges led computational biologist Ian Holmes to quip, “You can download our code from the URL supplied. Good luck downloading the only postdoc who can get it to run” (<xref ref-type="bibr" rid="bib24">Holmes, 2013</xref>). Package managers, such as <italic>bioconda</italic> and <italic>bioconductor</italic>, have helped to ameliorate these challenges, providing mechanisms for installing software dependencies and tracking versions. These package managers function in a way that is mostly agnostic to the user’s operating system (<xref ref-type="bibr" rid="bib20">Grüning et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Huber et al., 2015</xref>). However, some software tools are not available via package managers, package managers may depend on operating-system components that cannot be installed using the package managers themselves, and package managers may not guarantee that older versions of software and their dependencies remain available (<xref ref-type="bibr" rid="bib40">Piccolo and Frampton, 2016</xref>). Software <italic>containers</italic> have gained popularity among scientists in recent years because they help to overcome these limitations.</p><p>Software containers provide a mechanism to encapsulate specific versions of software and their dependencies in a fully configured, operating-system environment (<xref ref-type="bibr" rid="bib7">Boettiger, 2015</xref>). Here, we focus on the <italic>Docker</italic> ecosystem, which is commonly used for building, managing, and sharing software containers (<xref ref-type="bibr" rid="bib7">Boettiger, 2015</xref>). Other containerization systems are also available (<ext-link ext-link-type="uri" xlink:href="https://coreos.com/rkt">https://coreos.com/rkt</ext-link>; <xref ref-type="bibr" rid="bib18">Gomes et al., 2018</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/hpc/charliecloud">https://github.com/hpc/charliecloud</ext-link>, <xref ref-type="bibr" rid="bib10">Charliecloud collaborators, 2021</xref>; <xref ref-type="bibr" rid="bib41">Priedhorsky and Randles, 2017</xref>; <ext-link ext-link-type="uri" xlink:href="https://podman.io">https://podman.io</ext-link>); these systems are typically compatible with Docker. In academic-computing environments, such as university-run cluster computers, Singularity has gained popularity because containers can be executed without administrative privileges (<xref ref-type="bibr" rid="bib31">Kurtzer et al., 2017</xref>).</p><p>Steps for configuring the operating-system environment and installing software within a container are documented in a ‘Dockerfile’. Using such a file, researchers can build a container <italic>image</italic>, a layered set of operating-system components. Commonly, the base layer is a minimal implementation of a Linux distribution (e.g., Debian 10.3 or Ubuntu 18.04). Subsequent layers consist of software dependencies, configuration files, environment variables, etc. Once a container image has been created, it is portable and immutable. This is advantageous for computational reproducibility because one researcher can share an image with another researcher and know that its contents have remained static.</p><p>Docker Hub (<ext-link ext-link-type="uri" xlink:href="https://hub.docker.com">https://hub.docker.com</ext-link>) is a common way to share container images. After building an image on a local computer, a researcher can ‘push’ the image to Docker Hub using a single command. Subsequently, others can ‘pull’ the image and reuse it on a different computer (again, using a single command). Tags can be attached to each image for versioning. Currently, Docker Hub is free to use when specific requirements have been met. The Docker engine also provides a ‘registry’ tool that enables individuals or organizations to host their own registry of container images. For example, Red Hat, Inc offers <ext-link ext-link-type="uri" xlink:href="https://quay.io">https://quay.io</ext-link>, which hosts the container images from the BioContainers project (<xref ref-type="bibr" rid="bib12">da Veiga Leprevost et al., 2017</xref>).</p><p>A software <italic>container</italic> is an actively executing instance of a particular container image. Multiple containers of the same image can be executing simultaneously on the same computer (or different computers). Docker containers are always Linux-based; this is convenient for biology research because bioinformatics software is predominantly designed for Linux. But even though a container is Linux-based, it can be executed on non-Linux operating systems, such as Windows or Mac OS, via a container <italic>engine</italic>. Container engines use virtual machines to facilitate this interaction (<xref ref-type="bibr" rid="bib40">Piccolo and Frampton, 2016</xref>).</p><p>In addition to packaging scientific software, container images can package analysis code. For example, upon analyzing a given dataset, a researcher may wish to share the code with the research community. Many researchers post analysis code on websites such as GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com">https://github.com</ext-link>) or Open Science Framework (<xref ref-type="bibr" rid="bib17">Foster and Deardorff, 2017</xref>). This practice can enable others to verify and reuse the code; it also benefits the original researcher who otherwise might lose track of analysis details (<xref ref-type="bibr" rid="bib40">Piccolo and Frampton, 2016</xref>). But even when analysis code resides in the public domain, third-party researchers may experience difficulty executing it. Scripting languages like Python (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_008394">SCR_008394</ext-link>) and R (R Project for Statistical Computing, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001905">SCR_001905</ext-link>) require interpreters. Analysis scripts may depend on specific versions of interpreters, but the third-party researcher may have a different version on their computer. In addition, most analyses rely on ancillary software packages. Such packages provide logic for parsing a certain type of file, performing statistical tests, creating graphics, etc. Versioning is critical: older (or newer) versions of software packages may be incompatible with the analysis code. Researchers can facilitate reproducibility by providing container images that include specific versions of any script interpreters or software packages that are necessary to execute an analysis.</p><p><italic>Binder</italic> facilitates the containerization process for analysis code stored in GitHub repositories (<xref ref-type="bibr" rid="bib42">Project Jupyter et al., 2018</xref>). To use Binder, a researcher creates a configuration file that indicates which software is needed in the container image. For Python and R analyses, these configuration files indicate packages that must be installed, as well as version information. In other cases, a Dockerfile can be used to configure the environment more flexibly. After the researcher places the configuration file (and analysis code) in a GitHub repository, other researchers can visit the Binder website and re-execute the analysis. Behind the scenes, Binder provisions a cloud-based computer and executes the code within a container. This solution is effective for relatively short-running analyses that require modest computational resources, that use small datasets, and that are ready to be released publicly. However, many analyses do not meet these criteria. Longer, more data-intensive analyses are a better fit for workflow engines.</p></sec><sec id="s1-2"><title>Basic elements of a CWL tool description</title><p>To describe execution of a command-line tool, a researcher creates a text-based file according to the CWL Command Line Tool Description specification (<xref ref-type="bibr" rid="bib2">Amstutz et al., 2016</xref>). CWL files can be structured using either the YAML or JSON data-serialization formats (<ext-link ext-link-type="uri" xlink:href="https://yaml.org">https://yaml.org</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://www.json.org">https://www.json.org</ext-link>). Here, we provide an overview of key components of CWL tool descriptions.</p><p>A CWL tool describes inputs that will be used when the command-line tool is executed. A data type (or schema) should be defined for each input, indicating whether it represents a string, number, Boolean value, file, directory, or array (a data structure with multiple values). In practice, these inputs are generally data files and configuration settings for the software. These definitions help users of the tool understand the nature of each input and make it easier for inputs to be validated. For example, if a command-line tool expects a particular input value to be an integer (e.g., number of threads), a workflow engine can verify that the user has specified an integer before executing the tool.</p><p>After inputs have been defined, a tool description must provide instructions for constructing a command from the inputs. These commands can be based on a sorted ordering of the inputs. Alternatively, the researcher can specify a template for the command, using placeholders for the inputs. Such templates can represent either a single command or multiple commands.</p><p>As a tool executes, it can generate three types of outputs that might be useful to a researcher: (1) standard output, (2) standard error, and (3) new files. <italic>Standard output</italic> often consists of informational messages printed to the console; but it may also contain data to be used as input for another tool. <italic>Standard error</italic> typically consists of errors, warnings, or diagnostic information printed to the console. Many command-line tools produce new data files that have resulted from execution of the tool. A CWL tool description must indicate which of these outputs are expected so that a workflow engine can “collect” them after executing the tool.</p></sec><sec id="s1-3"><title>CWL tool examples for printing simple command-line messages</title><p>In the GitHub repository that accompanies this article, we have provided example tool descriptions, formatted in YAML according to the CWL specification (<ext-link ext-link-type="uri" xlink:href="https://github.com/srp33/ToolJig/tree/master/examples">https://github.com/srp33/ToolJig/tree/master/examples</ext-link>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:3e7275dd8056207f3f9c2d7af2143ae59325b606;origin=https://github.com/srp33/ToolJig;visit=swh:1:snp:f8ea5fce17127ca3aace81ffa4e20f50a1d8a5d8;anchor=swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832">swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832</ext-link>, <xref ref-type="bibr" rid="bib44">Stephen, 2021</xref>). The first series of examples is stored in the hello subdirectory.</p><p>The first example, 01_hello.cwl, requires two inputs: (1) a person’s given name and (2) the person’s surname. It uses the baseCommand field to construct a command based on ordinal positions specified for the inputs; the resulting command prints a greeting for that person. In this simple example, the only output is the greeting sent to standard output, which is redirected to a file called 01_output.txt. In the GitHub repository, hello_objects.yml is an example input-object file for this tool. It species a person’s given name (‘Fernanda’) and surname (‘Dantas’). The user could execute the tool via the <italic>cwl</italic> workflow engine using this command: cwltool 01_hello.cwl hello_objects.yml. The output would be, ‘Hello, Fernanda Dantas’.</p><p>Suppose we wished to alter the greeting to include an exclamation point and to indicate the person’s age. First, we would add an input for the person’s age (an integer). Second, we would update the command that will be executed. However, CWL’s baseCommand field provides limited flexibility for constructing commands. Instead, our example provides a command template using the ShellCommandRequirement and arguments fields and uses placeholders within the template for each input. As shown in 02_hello.cwl (and <xref ref-type="fig" rid="fig1">Figure 1A</xref>), we use the following template: echo Hello, $(inputs.given_name) $(inputs.surname)! You are $(inputs.age) years old.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Illustration of tool descriptions for printing simple greetings.</title><p>In the examples associated with this article, we provide tool descriptions that illustrate how to print custom greetings at the command line. These diagrams illustrate the 02_hello.cwl (<bold>A</bold>) and 03_hello.cwl (<bold>B</bold>) examples. In (<bold>A</bold>), the tool description indicates which inputs that must be specified, along with a template for executing the command; it also indicates that a message will be printed to standard output and that this message should be stored in a file called 02_output.txt. The hello_objects_age.yml input-object file stores values for a particular invocation of the tool. In (<bold>A</bold>), the cwltool workflow engine uses the host computer’s operating system to execute the tool; thus, the echo command must be supported on that operating system. In (<bold>B</bold>), the tool description defines a software container environment; thus, cwltool executes the command within a container, which provides the echo command (packaged with the Debian Linux operating system).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71069-fig1-v1.tif"/></fig><p>We use a $ character and parentheses to indicate placeholders for input variables. We prefix each input variable with ‘inputs’ to indicate that they will be specified as inputs.</p><p>By default, the above two examples would be executed within the same operating-system environment as the workflow engine. Accordingly, these tools could only be executed on operating systems that support the echo command. Many commands, including echo, are only supported on particular operating systems—or their behaviors differ by operating system. So in 03_hello.cwl (and <xref ref-type="fig" rid="fig1">Figure 1B</xref>), we use a Docker image based on the ‘buster’ release (version 10.3) of the Debian Linux operating system. The DockerRequirement field is added (in this case, two lines of text). Before executing the tool, a researcher would install a container engine such as Docker Desktop (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_016445">SCR_016445</ext-link>). Then, when executing the tool, the workflow engine would integrate itself with the container engine, which would identify any input files or directories and create container <italic>volumes</italic> so that the files or directories could be accessed from within the container. When a command-line tool executes within a Docker container, it becomes portable—it can be executed on any computer that supports the container and workflow engines.</p></sec><sec id="s1-4"><title>CWL tool examples for performing simple data analyses</title><p>The second series of examples is stored in the examples/bmi subdirectory on the GitHub site. The 01_bmi.cwl tool provides a simple example of a reproducible, quantitative analysis that could be performed using CWL. It accepts as input a tab-separated file containing names, weights, and heights of (fictional) individuals. A second input specifies the name of the column in the tab-separated file that contains weight information. The third input specifies the column name containing height information. The fourth input is the name of an output file that will be created. This example illustrates the use of an <italic>auxiliary file</italic>. Under the InitialWorkDirRequirement field, the contents of a Python script are stored. This script is used to calculate body mass index (BMI) values for each person in the input file and store those values in a <italic>BMI</italic> column in the output file. Below is the command template that we use.</p><p><monospace>python calculate_bmi.py &quot;$(inputs.input_file.path)&quot; &quot;$(inputs.weight_column_name)&quot; &quot;$(inputs.height_column_name)&quot; &quot;$(inputs.output_file_name)&quot;</monospace></p><p>The command template specifies the inputs as arguments to the Python script. When a file input is used, the workflow engine stores metadata about the file in an object with multiple attributes. Thus to reference the file’s path within the command template, we append ‘path’ to the input name. As the workflow engine executes the tool, it stores the auxiliary Python script inside the container, invokes the script, and collects the output file that the script generates.</p><p>If a researcher wished to ensure that others could reproduce the BMI calculations, they would need only to share the CWL file, the input-object file (01_bmi_objects.yml), and the data file (biometric_data.tsv). However, many analyses use data stored in online repositories. In such cases, it is convenient for a CWL tool to pull data directly from an online repository. The 02_bmi.cwl tool description and <xref ref-type="fig" rid="fig2">Figure 2</xref> illustrate this approach. Similar to the previous example, it extracts names, weights, and heights from a tab-separated file and adds a BMI column. However, it pulls the file from a Web server (in this case, our GitHub repository). The command template is similar to the previous example. Again, we use a software container based on Debian Linux. But this time, we also use the NetworkAccess field to enable the container to connect to external computers. The tool emits messages to both standard output and standard error; these messages are stored in files called ‘02_output.txt’ and ‘02_error.txt’, respectively.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Illustration of tool descriptions for calculating individuals’ body mass index (BMI).</title><p>In the examples associated with this article, we provide tool descriptions that illustrate how to calculate BMI values based on individuals’ weights and heights stored in a tab-separated value file. This diagram illustrates the 02_bmi.cwl example. The tool description indicates the expected inputs. In this case, the URL of a data file must be provided. That file must contain a column that stores weights (in kilograms) and a column that stores heights (in centimeters). In the input-objects file (02_bmi_objects.yml), the user specifies the names of these columns. The final input is the name of an output file that will be generated. This file will store the original data and a new column with the calculated BMI value for each individual. As the tool executes, Python (within a software container) downloads the input file, performs the calculations, generates the output file, and stores the standard output and standard error in text files.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71069-fig2-v1.tif"/></fig></sec><sec id="s1-5"><title>CWL tool examples for processing transcriptomic data</title><p>The third series of examples (examples/transcriptomic subdirectory) are wrappers around existing tools for processing transcriptomic data. In both cases, we use R packages from the Bioconductor suite (<xref ref-type="bibr" rid="bib26">Huber et al., 2015</xref>). Although R and Bioconductor are designed to be compatible with all major operating systems, some packages require dependencies that are operating system-specific. Furthermore, many Bioconductor packages provide a large number of functions and options. Researchers can create CWL tool descriptions that install dependencies (within a container image) and support a narrower range of options. The researchers might then share this tool with other researchers, enabling them to apply the tool more easily to their own data. Alternatively, they might use the tool as a way to support reproducibility for their own analyses.</p><p>The single-channel array normalization (SCAN) algorithm normalizes data from gene-expression microarrays, correcting for background noise and oligonucleotide-binding biases (<xref ref-type="bibr" rid="bib39">Piccolo and Sun, 2012</xref>). The SCAN method is implemented in the SCAN.UPC package in Bioconductor. It can download data directly from Gene Expression Omnibus (GEO) (<xref ref-type="bibr" rid="bib4">Barrett et al., 2011</xref>). The scan_normalize.cwl example illustrates how this functionality could be incorporated into a CWL tool. The base container image in this example includes the core Bioconductor components; our Dockerfile extends this image by installing the SCAN.UPC package. In addition, our example uses an auxiliary file containing R code that invokes the SCAN function within this package to normalize a given GEO series. Upon executing, this tool produces a tab-separated output file containing normalized measurements for all biological samples in the series. The tool could be customized further, for example, to perform gene-level rather than probeset-level summarization or to perform a quality-control analysis.</p><p>Commonly, researchers seek to identify genes that are differentially expressed between two conditions. The DESeq2 package is popular for performing such analyses with RNA-sequencing data (<xref ref-type="bibr" rid="bib36">Love et al., 2014</xref>). Our deseq2.cwl example illustrates how this process could be incorporated into a CWL tool. Similar to the previous example, this tool uses a container image with Bioconductor core components and installs the ‘DESeq2’ package. In addition, it installs the readr and dplyr packages (<xref ref-type="bibr" rid="bib47">Wickham, 2018a</xref>; <xref ref-type="bibr" rid="bib48">Wickham, 2018b</xref>), which we use to read and parse the data before identifying differentially expressed genes. The first two inputs are URLs to data files containing gene counts and phenotype information in tab-separated formats. The third input is a string representing a design formula; users of the tool can customize the differential-expression calculations based on the dependent variable of interest as well as any covariates. In the example input-object file (deseq2_objects.yml), we use data from an RNA-sequencing experiment that compared two inbred mouse strains commonly used for neuroscience research (<xref ref-type="bibr" rid="bib8">Bottomly et al., 2011</xref>); the data had been aligned to a reference genome, and gene counts had been quantified previously.</p></sec><sec id="s1-6"><title>CWL workflow examples for performing mathematical calculations</title><p>The examples so far have illustrated how to execute command-line tools in isolation, whereas workflows execute multiple tools in defined sequences. CWL workflows must specify at least one input(s) and one output(s) for the entire workflow. In addition, the researcher must define steps that each consist of a tool with input(s) and output(s). The researcher indicates whether each step’s input should be populated by an input for the entire workflow or by the output of a previously completed step. The workflow’s output(s) consist of the output(s) of one or more of the steps. As with CWL tools, the researcher must create an input-object file that provides input values for a particular execution of the workflow. Upon executing the workflow, the workflow engine evaluates the sequence of steps that must be executed and connects inputs with outputs, as needed.</p><p>We provide three example workflows in the examples/workflows/math subdirectory of the GitHub repository. The add_sqrt_workflow.cwl example accepts two integers as inputs, sums them, calculates the square root of the sum, and then stores the square root of the sum in an output file. This example illustrates the basic process of using an output from one tool as input to another. The recursive_sqrt_workflow.cwl example reads a number from a file, calculates the square root of that number, calculates the square root of the resulting number, and saves the output to a file. This workflow demonstrates the ability to invoke the same tool recursively. The secondary_sqrt_workflow.cwl example calculates the square root of a number stored in a file and saves the result to an output file. It does the same for two secondary files. It then sums those values and writes the sum to a file. This example demonstrates using secondary files within a workflow. Secondary files are commonly used in genomics and simplify the process of working with groups of related files that are necessary to complete a particular task.</p></sec><sec id="s1-7"><title>CWL workflow example for identifying somatic variants in a cancer genome</title><p>The examples in the examples/workflows/somatic subdirectory demonstrate a process for calling somatic variants from Illumina sequencing reads. We use paired-end reads from tumor and normal cells for an individual from the Texas Cancer Research Biobank (<xref ref-type="bibr" rid="bib5">Becnel et al., 2016</xref>). (Although these data are publicly available, they are subject to some data-use restrictions; <xref ref-type="bibr" rid="bib5">Becnel et al., 2016</xref>.) To shorten execution times, we use a subset of the data: the first 10,000,000 reads from lane 2 of the sequencing run. Furthermore, our analysis is limited to essential steps for preparing the data and calling variants. Additional steps like annotation and filtering would improve sensitivity and specificity of the variant calls; accordingly, researchers should interpret our variant calls with caution.</p><p>In these examples, somatic-variant calling occurs in a series of steps (<xref ref-type="fig" rid="fig3">Figure 3</xref>):</p><list list-type="order"><list-item><p><italic>Download and index a human reference genome</italic> (version hg38). We use the Linux wget and gunzip utilities to download and decompress a FASTA file from the UCSC genome repository (<xref ref-type="bibr" rid="bib22">Haeussler et al., 2019</xref>). We also use bwa, samtools, and Picard Tools to index the FASTA file and create a sequence dictionary (<xref ref-type="bibr" rid="bib35">Li et al., 2009</xref>; <xref ref-type="bibr" rid="bib34">Li and Durbin, 2009</xref>; Picard, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_006525">SCR_006525</ext-link>).</p></list-item><list-item><p><italic>Preprocess reference files containing known polymorphic sites in preparation for base-quality score recalibration</italic> (BQSR). We download Variant Call Format files (<xref ref-type="bibr" rid="bib13">Danecek et al., 2011</xref>) from the Genome Analysis Toolkit (GATK) resource bundle (<xref ref-type="bibr" rid="bib14">Depristo et al., 2011</xref>) and use a custom Python script to adjust chromosome identifiers that may differ across reference genomes. We also use Picard Tools to sort the reference files.</p></list-item><list-item><p><italic>Download the raw sequencing reads</italic> (FASTQ files). The files are stored in a publicly available, Open Science Framework repository (<xref ref-type="bibr" rid="bib17">Foster and Deardorff, 2017</xref>).</p></list-item><list-item><p><italic>Trim adapter sequences and low-quality bases</italic> using atropos (<xref ref-type="bibr" rid="bib16">Didion et al., 2017</xref>).</p></list-item><list-item><p><italic>Align the trimmed reads to the reference genome</italic> using bwa mem (<xref ref-type="bibr" rid="bib34">Li and Durbin, 2009</xref>). A read-group string is also specified.</p></list-item><list-item><p><italic>Sort and index the resulting BAM files</italic> (<xref ref-type="bibr" rid="bib35">Li et al., 2009</xref>) using sambamba (<xref ref-type="bibr" rid="bib45">Tarasov, 2015</xref>).</p></list-item><list-item><p><italic>Mark duplicate reads and re-index the resulting BAM files</italic> using sambamba.</p></list-item><list-item><p><italic>Derive a BQSR table from each BAM file</italic> using GATK.</p></list-item><list-item><p><italic>Apply the BQSR table to the BAM files</italic> using GATK.</p></list-item><list-item><p><italic>Call somatic single-nucleotide variants and small insertions/deletions</italic> using Mutect2 (<xref ref-type="bibr" rid="bib6">Benjamin et al., 2019</xref>). This step produces a VCF file.</p></list-item><list-item><p><italic>Call somatic structural variants</italic> using Delly (<xref ref-type="bibr" rid="bib43">Rausch, 2012</xref>). This step produces a VCF file.</p></list-item></list><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Illustration of tool descriptions for calling somatic variants from a cancer genome.</title><p>In the examples associated with this article, we provide tool descriptions that illustrate how to call somatic variants from second-generation sequencing data for a cancer genome (compared against a normal genome from the same patient). This process requires execution of 11 distinct tools in a defined succession of steps (a workflow). Two tools (prep_ref_genome.cwl and prep_recalibration_vcf.cwl) prepare reference files associated with a given human reference genome. These tools download data files from public Internet servers and then create index files and standardize contig identifiers. The third tool (download_file.cwl) downloads FASTQ files from an Internet server. The remaining tools process the normal and tumor sequences separately before comparing the tumor genome against the normal genome to identify single-nucleotide variants, indels, and structural variants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71069-fig3-v1.tif"/></fig><p>This workflow executes many of the same steps for a normal DNA sample and a tumor DNA sample. These steps are independent of each other. Accordingly, when multiple computing cores are available, the workflow engine may execute these steps in parallel.</p><p>Most of the tools in this workflow use container images from the BioContainers project, which provides thousands of Docker images that encapsulate biology-related software (<xref ref-type="bibr" rid="bib12">da Veiga Leprevost et al., 2017</xref>). In some cases, we used a BioContainers image that had been built for a specific version of a software package in the Bioconda project (<xref ref-type="bibr" rid="bib20">Grüning et al., 2018</xref>). In cases where we used multiple packages for a given task, we started with a base image from BioContainers and used Bioconda to install the packages. In the case of GATK, we used container images that had been created by the Broad Institute and stored on Docker Hub.</p><p>In most cases, we followed the recommendation that a single container image use only a single software package (<xref ref-type="bibr" rid="bib19">Gruening et al., 2019</xref>). However, in some cases, we determined that it was more sensible to use multiple software packages in a single CWL tool. For example, when preparing index files for the reference genome, we use three separate software packages. In contrast, sometimes we used the same software in multiple CWL tools. For example, the BQSR steps are computationally intensive; thus, we separated them into distinct CWL tools so that computational resources can be allocated at a more granular level. In this sense, each CWL tool represents a practical unit for data processing, not necessarily a particular software package.</p></sec></sec><sec id="s2" sec-type="materials|methods"><title>Materials and methods</title><sec id="s2-1"><title>Using ToolJig to create CWL tool descriptions</title><p>In manufacturing, a ‘jig’ is used by toolmakers to ensure that products are created in a repeatable, consistent pattern. Similarly, ToolJig provides a means to generate CWL tool descriptions, workflows, and input-object files in a repeatable, consistent manner. ToolJig is a Web application that uses the Vue.js framework (<ext-link ext-link-type="uri" xlink:href="https://vuejs.org">https://vuejs.org</ext-link>). Its functionality is divided into two pages: one for creating CWL tools and one for creating workflows. It is available from <ext-link ext-link-type="uri" xlink:href="https://srp33.github.io/ToolJig">https://srp33.github.io/ToolJig</ext-link>. To create a tool description in ToolJig, users specify the following:</p><list list-type="order"><list-item><p>A unique identifier. This identifier is used in the name of the CWL file that is generated, as well as for tagging the Docker image.</p></list-item><list-item><p>A short label that describes the tool’s purpose and function.</p></list-item><list-item><p>Optionally, a longer description that provides more detailed documentation about the tool.</p></list-item><list-item><p>Dockerfile contents. These instructions indicate the base container image that should be used and any additional commands necessary to build and configure a container image for the tool. A tutorial by Nüst, et al. provides recommendations on authoring Dockerfiles (<xref ref-type="bibr" rid="bib37">Nüst et al., 2020</xref>).</p></list-item><list-item><p>Author information. Optionally, the tool author can specify their name and ORCID identifier (<xref ref-type="bibr" rid="bib21">Haak et al., 2012</xref>). This information helps to ensure that authors are credited for their work.</p></list-item><list-item><p>Software license. The tool author can select from among seven popular licenses, thus indicating conditions under which others can use the CWL document. This license may or may not be identical to the license specified for the software itself.</p></list-item><list-item><p>Inputs. Users specify a name, type, and description for each input. Supported types are integer, string, File, and ‘Output File’. The File type allows the user to indicate that an input file is expected and asks the user to specify the EDAM format of the file (<xref ref-type="bibr" rid="bib27">Ison et al., 2013</xref>). Additionally, input files may be associated with secondary files. For instance, as our examples illustrate for somatic-variant calling, BAM files must be accompanied by index files. Rather than specify these as two separate inputs, we indicate that an index file is secondary to a BAM file. ‘Output File’ is a convenience type that is used when a tool author wants users to be able to specify the <italic>name</italic> of an output file that will be generated as the tool executes. Because this requires user input, ToolJig provides it as an input option. When a tool author specifies this type, ToolJig creates a <italic>string</italic> input for the file name, along with a corresponding output <italic>file</italic>, thus simplifying this process for the user.</p></list-item><list-item><p>Auxiliary files. The tool author can enter the name and contents of any auxiliary files that will be used. Commonly, these tools are programming scripts and can be written in any programming language that the Docker image supports.</p></list-item><list-item><p>Command template. The tool author specifies a template for executing the tool at the command line. Each input must be specified at least once in this template; ToolJig provides syntax suggestions to the user. ToolJig uses these command templates as an alternative to the baseCommand field. As our examples illustrate (<xref ref-type="fig" rid="fig4">Figure 4</xref>), command templates provide flexibility in the ways that commands are constructed and support the use of multiple commands. They provide the additional benefit that inputs do not have an inherent order and thus can be specified in the command template in any order (and multiple times, if desired).</p></list-item><list-item><p>Outputs. Aside from any ‘Output Files’ that may have been specified as inputs, the user may declare output files. For instance, the somatic/trim_fastq.cwl example specifies that trimmed FASTQ files should have the same names as the corresponding input FASTQ files. To indicate this, the user specifies a CWL-based expression: $(inputs.fastq_file.basename). Additionally, if the user wishes to collect standard output or standard error, they may specify the names of files that will store these messages.</p></list-item></list><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Examples of command templates used in Common Workflow Language (CWL) tool descriptions.</title><p>These examples illustrate diverse types of command templates for configuring execution of CWL tools. In each example, placeholders are used for inputs. When the tools are executed, the placeholders are replaced with input-object values. (<bold>A</bold>) A simple greeting is printed to standard output. (<bold>B</bold>) An R script (stored as an auxiliary file within the tool description) is executed; this script performs a differential-expression analysis using the DESeq2 package. (<bold>C</bold>) The <italic>bwa</italic> software aligns FASTQ files to a reference genome and pipes the output to <italic>samtools</italic>; the output is then converted to BAM format. This example illustrates a scenario in which two complementary software packages are used to perform a data-analysis task. Although these packages could be incorporated into distinct CWL tools, we combine them because read alignment and BAM conversion are typically performed jointly. (<bold>D</bold>) The <italic>sambamba</italic> software sorts and then indexes a BAM file. (<bold>E</bold>) The <italic>Delly</italic> software identifies structural variants in a cancer genome. <italic>Delly</italic> can be configured to exclude telomere and centromere regions as well as unplaced contigs. This example downloads an exclusion file, invokes <italic>Delly</italic>, and converts the output to VCF format. Examples (<bold>D</bold>) and (<bold>E</bold>) illustrate additional scenarios in which related tasks are executed as practical units.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71069-fig4-v1.tif"/></fig><p>After a user has specified all required elements, ToolJig generates a YAML document that conforms to the CWL specification; the user may download this document. ToolJig also generates a form in which the user can indicate a value for each input. Subsequently, the user can download an input-object file in YAML format.</p></sec><sec id="s2-2"><title>Using ToolJig to create CWL workflows</title><p>When using ToolJig to create a workflow, researchers first enter metadata: a unique identifier, label, description, author information, and software license. Subsequently, the researcher uploads at least one tool description. The researcher then defines two or more workflow steps. For each step, they specify a unique name and the tool that will be used in that step. For each of the tool’s inputs, the researcher indicates whether the input will be populated from the output of a preceding step or from a workflow input. The user may also indicate that any of the tool’s outputs will become outputs for the overall workflow. As with tool descriptions, ToolJig validates the user’s input and then generates a CWL document and input-object file that can be downloaded.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Progress in biology research is hindered when software tools are difficult to install, when inputs and outputs are inadequately or inconsistently specified, and when it is difficult to combine tools into workflows. The CWL specifications—in combination with package managers and software containers—are helping to alleviate these longstanding challenges. Moreover, CWL tool and workflow descriptions can facilitate reproducible research. Rather than simply providing analysis code alongside journal manuscripts, researchers can provide CWL documents. As illustrated in our examples, CWL documents provide instructions for executing analyses in software containers that encapsulate all relevant dependencies (<xref ref-type="fig" rid="fig5">Figure 5</xref>), along with ancillary scripts and instructions for accessing data files. People who read (or review) the manuscripts can then repeat the analyses, without needing to install any software other than a relevant workflow engine and container engine, even if their operating system or configuration differs from the authors’.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Examples of DockerRequirement specifications used in Common Workflow Language (CWL) tool descriptions.</title><p>These examples illustrate diverse ways to configure CWL tools to be executed in software containers. In (<bold>A</bold>), a container image is pulled from Docker Hub; this image encapsulates a minimal (‘slim’) version of Debian Linux 10.3 (‘buster’) and includes the Python 3.9 interpreter. In (<bold>B</bold>), the contents of a Dockerfile are included within the CWL description. In this case, the Dockerfile is simple—it pulls an existing image from <ext-link ext-link-type="uri" xlink:href="https://quay.io">https://quay.io</ext-link>. This image is provided as part of the BioContainers project and includes the Picard Tools software. (<bold>C</bold>) uses a base image from BioContainers and the Bioconda package manager to install the <italic>Delly</italic> and <italic>bcftools</italic> software within the image. (<bold>D</bold>) uses a base image from Bioconductor and executes R code to install the SCAN.UPC package within the image.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71069-fig5-v1.tif"/></fig><p>Multiple online repositories provide CWL documents, including the Dockstore tool registry (<xref ref-type="bibr" rid="bib38">O’Connor et al., 2017</xref>) and GitHub. For example, a search on GitHub for CWL documents that use the FastQC software (<xref ref-type="bibr" rid="bib9">Brown et al., 2017</xref>) resulted in 667 matches (August 30, 2021). Researchers can reuse and adapt these documents. However, in cases where reuse is infeasible or extensive adaptations are necessary, scientific progress may be accelerated as researchers, including non-bioinformaticians, gain greater efficiency in creating CWL documents. ToolJig aims to facilitate this process, enabling researchers to build CWL tools interactively, without needing to gain a deep understanding of the CWL specification or YAML syntax.</p><p>One advantage of CWL is that it can be used with diverse workflow engines. Whether or not they support CWL, most workflow engines provide custom languages or programming interfaces for creating workflows. Relatively little support is available for migrating from these engine-specific solutions to CWL in an automated manner. However, when these engines support execution within Docker-compatible containers, researchers can migrate these tools manually using ToolJig (or other means). Providing better support in existing workflow engines for exporting to CWL will be a positive step toward ensuring that CWL truly becomes a common language for command-line tools and workflows.</p><p>The CWL specification provides considerable flexibility for describing command-line tools and workflows. Our goal was to support common use cases for biology research. For the sake of simplicity and to reduce barriers of entry for new creators of CWL documents, ToolJig does <italic>not</italic> support some optional features within the CWL specification. These include input directories, dependent and exclusive parameters, process requirements, hints, and output directories. The CWL specifications provide details about these features.</p><p>ToolJig has no dependencies other than a modern Web browser. Accordingly, it can be used from virtually any computer with no installation process. When ToolJig is updated, the user simply needs to refresh their browser. A tradeoff to this simplicity is that ToolJig does not provide a direct means of testing tools or workflows. However, the cwltest utility provides a command-line testing framework, enabling researchers to compare tool and workflow outputs with expected results. In particular, researchers implementing CWL in production systems would benefit from using such a utility for validation.</p><sec id="s3-1"><title>Conclusions</title><p>CWL documents can formalize execution of command-line tools and workflows. We have summarized the key components of these documents and provided examples to illustrate key concepts. In addition, we have described ToolJig, a Web application that enables researchers to create CWL documents interactively. We hope these resources will benefit researchers from diverse training backgrounds to more easily create CWL documents and thus advance sharing of methods and computational reproducibility.</p></sec></sec></body><back><sec id="s4" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Funding acquisition, Software, Supervision, Visualization, Writing - original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Funding acquisition, Writing – review and editing</p></fn></fn-group></sec><sec id="s5" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-71069-transrepform1-v1.docx"/></supplementary-material></sec><sec id="s6" sec-type="data-availability"><title>Data availability</title><p>We did not generate data for this manuscript. However, we did create software for this manuscript. The full code for the software are available on GitHub using a liberal, open-source license: <ext-link ext-link-type="uri" xlink:href="https://github.com/srp33/ToolJig">https://github.com/srp33/ToolJig</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832">https://archive.softwareheritage.org/swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832</ext-link>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We acknowledge the Texas Cancer Research Biobank and Baylor College of Medicine Human Genome Sequencing Center for providing cancer-genome data used in some of our examples.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amstutz</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Portable, reproducible analysis with Arvados</article-title><source>F1000Research</source><volume>4</volume><elocation-id>114</elocation-id><pub-id pub-id-type="doi">10.7490/f1000research.1110114.1</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Amstutz</surname><given-names>P</given-names></name><name><surname>Crusoe</surname><given-names>MR</given-names></name><name><surname>Tijanić</surname><given-names>N</given-names></name><name><surname>Chapman</surname><given-names>B</given-names></name><name><surname>Chilton</surname><given-names>J</given-names></name><name><surname>Heuer</surname><given-names>M</given-names></name><name><surname>Kartashov</surname><given-names>A</given-names></name><name><surname>Leehr</surname><given-names>D</given-names></name><name><surname>Ménager</surname><given-names>H</given-names></name><name><surname>Nedeljkovich</surname><given-names>M</given-names></name><name><surname>Scales</surname><given-names>M</given-names></name><name><surname>Soiland-Reyes</surname><given-names>S</given-names></name><name><surname>Stojanovic</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Common workflow language, v1.0</data-title><source>Figshare</source><ext-link ext-link-type="uri" xlink:href="https://figshare.com/articles/dataset/Common_Workflow_Language_draft_3/3115156/2">https://figshare.com/articles/dataset/Common_Workflow_Language_draft_3/3115156/2</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Amstutz</surname><given-names>P</given-names></name><name><surname>Soiland-Reyes</surname><given-names>S</given-names></name><name><surname>Crusoe</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Rabix: Power tools for the Common Workflow Language</data-title><source>Seven Bridges</source><ext-link ext-link-type="uri" xlink:href="http://www.rabix.io">http://www.rabix.io</ext-link></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>T</given-names></name><name><surname>Troup</surname><given-names>DB</given-names></name><name><surname>Wilhite</surname><given-names>SE</given-names></name><name><surname>Ledoux</surname><given-names>P</given-names></name><name><surname>Evangelista</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>IF</given-names></name><name><surname>Tomashevsky</surname><given-names>M</given-names></name><name><surname>Marshall</surname><given-names>KA</given-names></name><name><surname>Phillippy</surname><given-names>KH</given-names></name><name><surname>Sherman</surname><given-names>PM</given-names></name><name><surname>Muertter</surname><given-names>RN</given-names></name><name><surname>Holko</surname><given-names>M</given-names></name><name><surname>Ayanbule</surname><given-names>O</given-names></name><name><surname>Yefanov</surname><given-names>A</given-names></name><name><surname>Soboleva</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>NCBI GEO: archive for functional genomics data sets--10 years on</article-title><source>Nucleic Acids Research</source><volume>39</volume><fpage>D1005</fpage><lpage>D1010</lpage><pub-id pub-id-type="doi">10.1093/nar/gkq1184</pub-id><pub-id pub-id-type="pmid">21097893</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becnel</surname><given-names>LB</given-names></name><name><surname>Pereira</surname><given-names>S</given-names></name><name><surname>Drummond</surname><given-names>JA</given-names></name><name><surname>Gingras</surname><given-names>MC</given-names></name><name><surname>Covington</surname><given-names>KR</given-names></name><name><surname>Kovar</surname><given-names>CL</given-names></name><name><surname>Doddapaneni</surname><given-names>HV</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Muzny</surname><given-names>D</given-names></name><name><surname>McGuire</surname><given-names>AL</given-names></name><name><surname>Wheeler</surname><given-names>DA</given-names></name><name><surname>Gibbs</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An open access pilot freely sharing cancer genomic data from participants in Texas</article-title><source>Scientific Data</source><volume>3</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1038/sdata.2016.10</pub-id><pub-id pub-id-type="pmid">26882539</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Benjamin</surname><given-names>D</given-names></name><name><surname>Sato</surname><given-names>T</given-names></name><name><surname>Cibulskis</surname><given-names>K</given-names></name><name><surname>Getz</surname><given-names>G</given-names></name><name><surname>Stewart</surname><given-names>C</given-names></name><name><surname>Lichtenstein</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Calling Somatic Snvs and Indels with Mutect2</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/861054</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boettiger</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>An introduction to Docker for reproducible research</article-title><source>ACM SIGOPS Oper Syst Rev</source><volume>49</volume><fpage>71</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1145/2723872.2723882</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bottomly</surname><given-names>D</given-names></name><name><surname>Walter</surname><given-names>NAR</given-names></name><name><surname>Hunter</surname><given-names>JE</given-names></name><name><surname>Darakjian</surname><given-names>P</given-names></name><name><surname>Kawane</surname><given-names>S</given-names></name><name><surname>Buck</surname><given-names>KJ</given-names></name><name><surname>Searles</surname><given-names>RP</given-names></name><name><surname>Mooney</surname><given-names>M</given-names></name><name><surname>McWeeney</surname><given-names>SK</given-names></name><name><surname>Hitzemann</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Evaluating Gene Expression in C57BL/6J and DBA/2J Mouse Striatum Using RNA-Seq and Microarrays</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e17820</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0017820</pub-id><pub-id pub-id-type="pmid">21455293</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>J</given-names></name><name><surname>Pirrung</surname><given-names>M</given-names></name><name><surname>McCue</surname><given-names>LA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>FQC Dashboard: Integrates FastQC results into a web-based, interactive, and extensible FASTQ quality control tool</article-title><source>Bioinformatics</source><volume>33</volume><fpage>3137</fpage><lpage>3139</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx373</pub-id><pub-id pub-id-type="pmid">28605449</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Charliecloud collaborators</collab></person-group><year iso-8601-date="2021">2021</year><data-title>Charliecloud</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/hpc/charliecloud">https://github.com/hpc/charliecloud</ext-link></element-citation></ref><ref id="bib11"><element-citation publication-type="web"><person-group person-group-type="author"><collab>Common Workflow Language working group</collab></person-group><year iso-8601-date="2021">2021</year><article-title>Common Workflow Language User Guide</article-title><ext-link ext-link-type="uri" xlink:href="https://www.commonwl.org/user_guide/index.html">https://www.commonwl.org/user_guide/index.html</ext-link><date-in-citation iso-8601-date="2021-09-10">September 10, 2021</date-in-citation></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>da Veiga Leprevost</surname><given-names>F</given-names></name><name><surname>Grüning</surname><given-names>BA</given-names></name><name><surname>Alves Aflitos</surname><given-names>S</given-names></name><name><surname>Röst</surname><given-names>HL</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Barsnes</surname><given-names>H</given-names></name><name><surname>Vaudel</surname><given-names>M</given-names></name><name><surname>Moreno</surname><given-names>P</given-names></name><name><surname>Gatto</surname><given-names>L</given-names></name><name><surname>Weber</surname><given-names>J</given-names></name><name><surname>Bai</surname><given-names>M</given-names></name><name><surname>Jimenez</surname><given-names>RC</given-names></name><name><surname>Sachsenberg</surname><given-names>T</given-names></name><name><surname>Pfeuffer</surname><given-names>J</given-names></name><name><surname>Vera Alvarez</surname><given-names>R</given-names></name><name><surname>Griss</surname><given-names>J</given-names></name><name><surname>Nesvizhskii</surname><given-names>AI</given-names></name><name><surname>Perez-Riverol</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>BioContainers: An open-source and community-driven framework for software standardization</article-title><source>Bioinformatics</source><volume>33</volume><fpage>2580</fpage><lpage>2582</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx192</pub-id><pub-id pub-id-type="pmid">28379341</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danecek</surname><given-names>P</given-names></name><name><surname>Auton</surname><given-names>A</given-names></name><name><surname>Abecasis</surname><given-names>G</given-names></name><name><surname>Albers</surname><given-names>CA</given-names></name><name><surname>Banks</surname><given-names>E</given-names></name><name><surname>DePristo</surname><given-names>MA</given-names></name><name><surname>Handsaker</surname><given-names>RE</given-names></name><name><surname>Lunter</surname><given-names>G</given-names></name><name><surname>Marth</surname><given-names>GT</given-names></name><name><surname>Sherry</surname><given-names>ST</given-names></name><name><surname>McVean</surname><given-names>G</given-names></name><name><surname>Durbin</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The variant call format and VCFtools</article-title><source>Bioinformatics</source><volume>27</volume><fpage>2156</fpage><lpage>2158</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr330</pub-id><pub-id pub-id-type="pmid">21653522</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Depristo</surname><given-names>MA</given-names></name><name><surname>Banks</surname><given-names>E</given-names></name><name><surname>Poplin</surname><given-names>R</given-names></name><name><surname>Garimella</surname><given-names>KV</given-names></name><name><surname>Maguire</surname><given-names>JR</given-names></name><name><surname>Hartl</surname><given-names>C</given-names></name><name><surname>Del Angel</surname><given-names>G</given-names></name><name><surname>a</surname><given-names>RM</given-names></name><name><surname>Hanna</surname><given-names>M</given-names></name><name><surname>McKenna</surname><given-names>A</given-names></name><name><surname>Fennell</surname><given-names>TJ</given-names></name><name><surname>Kernytsky</surname><given-names>AM</given-names></name><name><surname>Sivachenko</surname><given-names>AY</given-names></name><name><surname>Cibulskis</surname><given-names>K</given-names></name><name><surname>Gabriel</surname><given-names>SB</given-names></name><name><surname>Altshuler</surname><given-names>D</given-names></name><name><surname>Daly</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A framework for variation discovery and genotyping using next-generation DNA sequencing data</article-title><source>Nature Genetics</source><volume>43</volume><fpage>491</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1038/ng.806</pub-id><pub-id pub-id-type="pmid">21478889</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Tommaso</surname><given-names>P</given-names></name><name><surname>Chatzou</surname><given-names>M</given-names></name><name><surname>Floden</surname><given-names>EW</given-names></name><name><surname>Barja</surname><given-names>PP</given-names></name><name><surname>Palumbo</surname><given-names>E</given-names></name><name><surname>Notredame</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Nextflow enables reproducible computational workflows</article-title><source>Nature Biotechnology</source><volume>35</volume><fpage>316</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1038/nbt.3820</pub-id><pub-id pub-id-type="pmid">28398311</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Didion</surname><given-names>JP</given-names></name><name><surname>Martin</surname><given-names>M</given-names></name><name><surname>Collins</surname><given-names>FS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Atropos: Specific, sensitive, and speedy trimming of sequencing reads</article-title><source>PeerJ</source><volume>5</volume><elocation-id>e3720</elocation-id><pub-id pub-id-type="doi">10.7717/peerj.3720</pub-id><pub-id pub-id-type="pmid">28875074</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>ED</given-names></name><name><surname>Deardorff</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Open Science Framework (OSF)</article-title><source>Journal of the Medical Library Association</source><volume>105</volume><fpage>203</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.5195/jmla.2017.88</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomes</surname><given-names>J</given-names></name><name><surname>Bagnaschi</surname><given-names>E</given-names></name><name><surname>Campos</surname><given-names>I</given-names></name><name><surname>David</surname><given-names>M</given-names></name><name><surname>Alves</surname><given-names>L</given-names></name><name><surname>Martins</surname><given-names>J</given-names></name><name><surname>Pina</surname><given-names>J</given-names></name><name><surname>López-García</surname><given-names>A</given-names></name><name><surname>Orviz</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Enabling rootless Linux Containers in multi-user environments: The udocker tool</article-title><source>Computer Physics Communications</source><volume>232</volume><fpage>84</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1016/j.cpc.2018.05.021</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruening</surname><given-names>B</given-names></name><name><surname>Sallou</surname><given-names>O</given-names></name><name><surname>Moreno</surname><given-names>P</given-names></name><name><surname>da Veiga Leprevost</surname><given-names>F</given-names></name><name><surname>Ménager</surname><given-names>H</given-names></name><name><surname>Søndergaard</surname><given-names>D</given-names></name><name><surname>Röst</surname><given-names>H</given-names></name><name><surname>Sachsenberg</surname><given-names>T</given-names></name><name><surname>O’Connor</surname><given-names>B</given-names></name><name><surname>Madeira</surname><given-names>F</given-names></name><name><surname>Angel</surname><given-names>DD</given-names></name><name><surname>Crusoe</surname><given-names>MR</given-names></name><name><surname>Varma</surname><given-names>S</given-names></name><name><surname>Blankenberg</surname><given-names>D</given-names></name><name><surname>Jimenez</surname><given-names>RC</given-names></name><name><surname>Community</surname><given-names>B</given-names></name><name><surname>Perez-Riverol</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Recommendations for the packaging and containerizing of bioinformatics software</article-title><source>F1000Research</source><volume>7</volume><elocation-id>742</elocation-id><pub-id pub-id-type="doi">10.12688/f1000research.15140.2</pub-id><pub-id pub-id-type="pmid">31543945</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grüning</surname><given-names>B</given-names></name><name><surname>Dale</surname><given-names>R</given-names></name><name><surname>Sjödin</surname><given-names>A</given-names></name><name><surname>Chapman</surname><given-names>BA</given-names></name><name><surname>Rowe</surname><given-names>J</given-names></name><name><surname>Tomkins-Tinch</surname><given-names>CH</given-names></name><name><surname>Valieris</surname><given-names>R</given-names></name><name><surname>Köster</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Bioconda: Sustainable and comprehensive software distribution for the life sciences</article-title><source>Nature Methods</source><volume>15</volume><fpage>475</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0046-7</pub-id><pub-id pub-id-type="pmid">29967506</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haak</surname><given-names>LL</given-names></name><name><surname>Fenner</surname><given-names>M</given-names></name><name><surname>Paglione</surname><given-names>L</given-names></name><name><surname>Pentz</surname><given-names>E</given-names></name><name><surname>Ratner</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>ORCID: A system to uniquely identify researchers</article-title><source>Learned Publishing</source><volume>25</volume><fpage>259</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1087/20120404</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haeussler</surname><given-names>M</given-names></name><name><surname>Zweig</surname><given-names>AS</given-names></name><name><surname>Tyner</surname><given-names>C</given-names></name><name><surname>Speir</surname><given-names>ML</given-names></name><name><surname>Rosenbloom</surname><given-names>KR</given-names></name><name><surname>Raney</surname><given-names>BJ</given-names></name><name><surname>Lee</surname><given-names>CM</given-names></name><name><surname>Lee</surname><given-names>BT</given-names></name><name><surname>Hinrichs</surname><given-names>AS</given-names></name><name><surname>Gonzalez</surname><given-names>JN</given-names></name><name><surname>Gibson</surname><given-names>D</given-names></name><name><surname>Diekhans</surname><given-names>M</given-names></name><name><surname>Clawson</surname><given-names>H</given-names></name><name><surname>Casper</surname><given-names>J</given-names></name><name><surname>Barber</surname><given-names>GP</given-names></name><name><surname>Haussler</surname><given-names>D</given-names></name><name><surname>Kuhn</surname><given-names>RM</given-names></name><name><surname>Kent</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The UCSC Genome Browser database: 2019 update</article-title><source>Nucleic Acids Research</source><volume>47</volume><fpage>D853</fpage><lpage>D858</lpage><pub-id pub-id-type="doi">10.1093/nar/gky1095</pub-id><pub-id pub-id-type="pmid">30407534</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hey</surname><given-names>T</given-names></name><name><surname>Tansley</surname><given-names>S</given-names></name><name><surname>Tolle</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>The Fourth Paradigm: Data-Intensive Scientific Discovery</source><publisher-name>Microsoft research</publisher-name></element-citation></ref><ref id="bib24"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Holmes</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>You can download our code from the URL supplied. Good luck downloading the only postdoc who can get it to [Tweet]. Twitter</article-title><ext-link ext-link-type="uri" xlink:href="https://twitter.com/ianholmes/status/288689712636493824">https://twitter.com/ianholmes/status/288689712636493824</ext-link><date-in-citation iso-8601-date="2021-09-10">September 10, 2021</date-in-citation></element-citation></ref><ref id="bib25"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>NC</given-names></name></person-group><year iso-8601-date="2014">2014</year><data-title>We are the 92%</data-title><source>Figshare</source><ext-link ext-link-type="uri" xlink:href="https://figshare.com/articles/presentation/We_are_the_92_/1243288/1">https://figshare.com/articles/presentation/We_are_the_92_/1243288/1</ext-link></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huber</surname><given-names>W</given-names></name><name><surname>Carey</surname><given-names>VJ</given-names></name><name><surname>Gentleman</surname><given-names>R</given-names></name><name><surname>Anders</surname><given-names>S</given-names></name><name><surname>Carlson</surname><given-names>M</given-names></name><name><surname>Carvalho</surname><given-names>BS</given-names></name><name><surname>Bravo</surname><given-names>HC</given-names></name><name><surname>Davis</surname><given-names>S</given-names></name><name><surname>Gatto</surname><given-names>L</given-names></name><name><surname>Girke</surname><given-names>T</given-names></name><name><surname>Gottardo</surname><given-names>R</given-names></name><name><surname>Hahne</surname><given-names>F</given-names></name><name><surname>Hansen</surname><given-names>KD</given-names></name><name><surname>a</surname><given-names>IR</given-names></name><name><surname>Lawrence</surname><given-names>M</given-names></name><name><surname>Love</surname><given-names>MI</given-names></name><name><surname>Macdonald</surname><given-names>J</given-names></name><name><surname>Obenchain</surname><given-names>V</given-names></name><name><surname>Oleś</surname><given-names>AK</given-names></name><name><surname>Pagès</surname><given-names>H</given-names></name><name><surname>Reyes</surname><given-names>A</given-names></name><name><surname>Shannon</surname><given-names>P</given-names></name><name><surname>Smyth</surname><given-names>GK</given-names></name><name><surname>Tenenbaum</surname><given-names>D</given-names></name><name><surname>Waldron</surname><given-names>L</given-names></name><name><surname>Morgan</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Orchestrating high-throughput genomic analysis with Bioconductor</article-title><source>Nature Methods</source><volume>12</volume><fpage>115</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3252</pub-id><pub-id pub-id-type="pmid">25633503</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ison</surname><given-names>J</given-names></name><name><surname>Kalaš</surname><given-names>M</given-names></name><name><surname>Jonassen</surname><given-names>I</given-names></name><name><surname>Bolser</surname><given-names>D</given-names></name><name><surname>Uludag</surname><given-names>M</given-names></name><name><surname>McWilliam</surname><given-names>H</given-names></name><name><surname>Malone</surname><given-names>J</given-names></name><name><surname>Lopez</surname><given-names>R</given-names></name><name><surname>Pettifer</surname><given-names>S</given-names></name><name><surname>Rice</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>EDAM: An ontology of bioinformatics operations, types of data and identifiers, topics and formats</article-title><source>Bioinformatics</source><volume>29</volume><fpage>1325</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btt113</pub-id><pub-id pub-id-type="pmid">23479348</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Köster</surname><given-names>J</given-names></name><name><surname>Rahmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Snakemakea scalable bioinformatics workflow engine</article-title><source>Bioinformatics</source><volume>28</volume><fpage>2520</fpage><lpage>2522</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bts480</pub-id><pub-id pub-id-type="pmid">22908215</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kotliar</surname><given-names>M</given-names></name><name><surname>Kartashov</surname><given-names>AV</given-names></name><name><surname>Barski</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>CWL-Airflow: A lightweight pipeline manager supporting Common Workflow Language</article-title><source>GigaScience</source><volume>8</volume><elocation-id>giz084</elocation-id><pub-id pub-id-type="doi">10.1093/gigascience/giz084</pub-id><pub-id pub-id-type="pmid">31321430</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Dudley</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Bioinformatics software for biologists in the genomics era</article-title><source>Bioinformatics</source><volume>23</volume><fpage>1713</fpage><lpage>1717</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btm239</pub-id><pub-id pub-id-type="pmid">17485425</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurtzer</surname><given-names>GM</given-names></name><name><surname>Sochat</surname><given-names>V</given-names></name><name><surname>Bauer</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Singularity: Scientific containers for mobility of compute</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0177459</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0177459</pub-id><pub-id pub-id-type="pmid">28494014</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>J</given-names></name><name><surname>Vitzthum</surname><given-names>C</given-names></name><name><surname>Kırlı</surname><given-names>K</given-names></name><name><surname>Alver</surname><given-names>BH</given-names></name><name><surname>Park</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Tibanna: Software for scalable execution of portable pipelines on the cloud</article-title><source>Bioinformatics</source><volume>35</volume><fpage>4424</fpage><lpage>4426</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz379</pub-id><pub-id pub-id-type="pmid">31077294</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leipzig</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A review of bioinformatic pipeline frameworks</article-title><source>Brief Bioinform</source><volume>18</volume><fpage>530</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1093/bib/bbw020</pub-id><pub-id pub-id-type="pmid">27013646</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Durbin</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fast and accurate short read alignment with Burrows-Wheeler transform</article-title><source>Bioinforma Oxf Engl</source><volume>25</volume><fpage>1754</fpage><lpage>1760</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp324</pub-id><pub-id pub-id-type="pmid">19451168</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Handsaker</surname><given-names>B</given-names></name><name><surname>Wysoker</surname><given-names>A</given-names></name><name><surname>Fennell</surname><given-names>T</given-names></name><name><surname>Ruan</surname><given-names>J</given-names></name><name><surname>Homer</surname><given-names>N</given-names></name><name><surname>Marth</surname><given-names>G</given-names></name><name><surname>Abecasis</surname><given-names>G</given-names></name><name><surname>Durbin</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The Sequence Alignment/Map format and SAMtools</article-title><source>Bioinforma Oxf Engl</source><volume>25</volume><fpage>2078</fpage><lpage>2079</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id><pub-id pub-id-type="pmid">19505943</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Love</surname><given-names>MI</given-names></name><name><surname>Huber</surname><given-names>W</given-names></name><name><surname>Anders</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2</article-title><source>Genome Biology</source><volume>15</volume><elocation-id>550</elocation-id><pub-id pub-id-type="doi">10.1186/s13059-014-0550-8</pub-id><pub-id pub-id-type="pmid">25516281</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nüst</surname><given-names>D</given-names></name><name><surname>Sochat</surname><given-names>V</given-names></name><name><surname>Marwick</surname><given-names>B</given-names></name><name><surname>Eglen</surname><given-names>SJ</given-names></name><name><surname>Head</surname><given-names>T</given-names></name><name><surname>Hirst</surname><given-names>T</given-names></name><name><surname>Evans</surname><given-names>BD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Ten simple rules for writing Dockerfiles for reproducible data science</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008316</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008316</pub-id><pub-id pub-id-type="pmid">33170857</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>BD</given-names></name><name><surname>Yuen</surname><given-names>D</given-names></name><name><surname>Chung</surname><given-names>V</given-names></name><name><surname>Duncan</surname><given-names>AG</given-names></name><name><surname>Liu</surname><given-names>XK</given-names></name><name><surname>Patricia</surname><given-names>J</given-names></name><name><surname>Paten</surname><given-names>B</given-names></name><name><surname>Stein</surname><given-names>L</given-names></name><name><surname>Ferretti</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The Dockstore: Enabling modular, community-focused sharing of Docker-based genomics tools and workflows</article-title><source>F1000Research</source><volume>6</volume><elocation-id>52</elocation-id><pub-id pub-id-type="doi">10.12688/f1000research.10137.1</pub-id><pub-id pub-id-type="pmid">28344774</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piccolo</surname><given-names>SR</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A single-sample microarray normalization method to facilitate personalized-medicine workflows</article-title><source>Genomics</source><volume>100</volume><fpage>337</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1016/j.ygeno.2012.08.003</pub-id><pub-id pub-id-type="pmid">22959562</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piccolo</surname><given-names>SR</given-names></name><name><surname>Frampton</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Tools and techniques for computational reproducibility</article-title><source>GigaScience</source><volume>5</volume><elocation-id>30</elocation-id><pub-id pub-id-type="doi">10.1186/s13742-016-0135-4</pub-id><pub-id pub-id-type="pmid">27401684</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priedhorsky</surname><given-names>R</given-names></name><name><surname>Randles</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Charliecloud: unprivileged containers for user-defined software stacks in HPC</article-title><source>SC ’17: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</source><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1145/3126908.3126925</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="confproc"><person-group person-group-type="author"><collab>Project Jupyter</collab><name><surname>Bussonnier</surname><given-names>M</given-names></name><name><surname>Forde</surname><given-names>J</given-names></name><name><surname>Freeman</surname><given-names>J</given-names></name><name><surname>Granger</surname><given-names>B</given-names></name><name><surname>Head</surname><given-names>T</given-names></name><name><surname>Holdgraf</surname><given-names>C</given-names></name><name><surname>Kelley</surname><given-names>K</given-names></name><name><surname>Nalvarte</surname><given-names>G</given-names></name><name><surname>Osheroff</surname><given-names>A</given-names></name><name><surname>Pacer</surname><given-names>M</given-names></name><name><surname>Panda</surname><given-names>Y</given-names></name><name><surname>Perez</surname><given-names>F</given-names></name><name><surname>Ragan-Kelley</surname><given-names>B</given-names></name><name><surname>Willing</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><conf-name>Binder 2.0 - Reproducible, interactive, sharable environments for science at scale</conf-name><article-title>Python in Science Conference</article-title><conf-loc>Austin, Texas</conf-loc><fpage>113</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.25080/Majora-4af1f417-011</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rausch</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>DELLY: Structural variant discovery by integrated paired-end and split-read analysis</article-title><source>Bioinformatics</source><volume>28</volume><fpage>i333</fpage><lpage>i339</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bts378</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Stephen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Tooljig: An app for building simplified common workflow language tool and workflow descriptions</data-title><version designator="swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832">swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:3e7275dd8056207f3f9c2d7af2143ae59325b606;origin=https://github.com/srp33/ToolJig;visit=swh:1:snp:f8ea5fce17127ca3aace81ffa4e20f50a1d8a5d8;anchor=swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832">https://archive.softwareheritage.org/swh:1:dir:3e7275dd8056207f3f9c2d7af2143ae59325b606;origin=https://github.com/srp33/ToolJig;visit=swh:1:snp:f8ea5fce17127ca3aace81ffa4e20f50a1d8a5d8;anchor=swh:1:rev:ae8d3b358ccc44e45604125257c5361d20c26832</ext-link></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tarasov</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sambamba: Fast processing of NGS alignment formats</article-title><source>Bioinformatics</source><volume>31</volume><fpage>2032</fpage><lpage>2034</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btv098</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vivian</surname><given-names>J</given-names></name><name><surname>Rao</surname><given-names>AA</given-names></name><name><surname>Nothaft</surname><given-names>FA</given-names></name><name><surname>Ketchum</surname><given-names>C</given-names></name><name><surname>Armstrong</surname><given-names>J</given-names></name><name><surname>Novak</surname><given-names>A</given-names></name><name><surname>Pfeil</surname><given-names>J</given-names></name><name><surname>Narkizian</surname><given-names>J</given-names></name><name><surname>Deran</surname><given-names>AD</given-names></name><name><surname>Musselman-Brown</surname><given-names>A</given-names></name><name><surname>Schmidt</surname><given-names>H</given-names></name><name><surname>Amstutz</surname><given-names>P</given-names></name><name><surname>Craft</surname><given-names>B</given-names></name><name><surname>Goldman</surname><given-names>M</given-names></name><name><surname>Rosenbloom</surname><given-names>K</given-names></name><name><surname>Cline</surname><given-names>M</given-names></name><name><surname>O’Connor</surname><given-names>B</given-names></name><name><surname>Hanna</surname><given-names>M</given-names></name><name><surname>Birger</surname><given-names>C</given-names></name><name><surname>Kent</surname><given-names>WJ</given-names></name><name><surname>Patterson</surname><given-names>DA</given-names></name><name><surname>Joseph</surname><given-names>AD</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Zaranek</surname><given-names>S</given-names></name><name><surname>Getz</surname><given-names>G</given-names></name><name><surname>Haussler</surname><given-names>D</given-names></name><name><surname>Paten</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Toil enables reproducible, open source, big biomedical data analyses</article-title><source>Nature Biotechnology</source><volume>35</volume><fpage>314</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1038/nbt.3772</pub-id><pub-id pub-id-type="pmid">28398314</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Wickham</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018a</year><data-title>Dplyr: A grammar of data manipulation</data-title><source>Dplyr</source></element-citation></ref><ref id="bib48"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Wickham</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018b</year><data-title>Readr: Read Rectangular Text Data</data-title><source>Readr</source></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Best Practices for Scientific Computing</article-title><source>PLOS Biology</source><volume>12</volume><elocation-id>e1001745</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001745</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.71069.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Robles-Espinoza</surname><given-names>C Daniela</given-names></name><role>Reviewing Editor</role><aff><institution>International Laboratory for Human Genome Research</institution><country>Mexico</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Robles-Espinoza</surname><given-names>C Daniela</given-names></name><role>Reviewer</role><aff><institution>International Laboratory for Human Genome Research</institution><country>Mexico</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.04.30.442204">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.04.30.442204v1">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>In this manuscript, Piccolo and collaborators provide a detailed overview of the Common Workflow Language (CWL) for beginner bioinformaticians, and perhaps more experienced workers that may not be up-to-date with the latest developments in reproducible research. They also provide a tool, ToolJig, to create CWL documents without needing to install any software nor to learn the specifications of the format. Written in the form of a tutorial, its major strengths are that explanations are very clear, and are accompanied by illustrative figures and examples in a Github repository. As science is currently undergoing a major reproducibility crisis, we think that it is crucial that detailed and accessible pieces such as this one are published to teach scientists to create fully reproducible code.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Simplifying the development of portable, scalable, and reproducible workflows&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, including C Daniela Robles-Espinoza as Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Aleksandra Walczak as the Senior Editor.</p><p>This is an accessible tutorial that illustrates the basics of Common Workflow Language (CWL), intended both for students beginning their scientific formation and for more experienced bioinformaticians that have not adopted this community standard yet. The adoption of CWL has the potential to help alleviate the reproducibility crisis ongoing in scientific publishing. The reviewers have agreed that the figures are very clear, and the examples available on Github are helpful and they go from simple tasks to illustrating a more complex biological analysis. A webtool is also provided for easily creating CWL documents. There are a few revisions that the reviewers have recommended to make the work clearer before publication:</p><p>1. There is some confusion regarding the usage of containers in regards to the location of the workflow manager (production vs publication workflows). A container with all required analysis software, CWL document and a workflow manager seems well suited for distribution with a publication for reproducible calculations. However for production needs, a modular design with various containers and a workflow manager outside of the containers seem a better choice. It's hard to distinguish these two usages in the manuscript. Can a few lines be devoted to making these clarifications, please?</p><p>2. A reviewer notes, &quot;I think it would be useful to beginners to see more information on the benefits of using CWL over some of the alternatives (Nextflow, Snakemake). There are quite a few ways of handling bioinformatic pipelines and in my experience I been overwhelmed by the decision of having to choose one over the rest.&quot;. Can a few lines be devoted to discussing the benefits/weaknesses of these other alternatives?</p><p>3. There is no mention of the benefits of error handling and restarts when using a workflow manager. For production environments this is a key benefit, so could this be incorporated please?</p><p>4. A reviewer mentions. &quot;The manuscript does a good exposition of Docker and containers. However, I didn't find much mention of Docker Hub. Being that Docker Hub was a key element in the prominence of containers I think there should be a bit more details about it on the paper.&quot;. Could some lines about Docker Hub be incorporated please?</p><p>5. About figures 1 and 2 – should the name of the program in the yellow square be changed to match the .yml found in the GitHUb repository?</p><p>6. Would it be possible to add a button to ToolJig that would populate the fields, as a pre-filled example? It may be easier for beginners to illustrate how the information should be input. Perhaps following the example of one of the ones that are already in the GitHub repository so it's more easily comparable.</p><p>7. Could you please specify If the YAML document created by a user is saved by ToolJig, or is it deleted when the user closes the webpage?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.71069.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>1. There is some confusion regarding the usage of containers in regards to the location of the workflow manager (production vs publication workflows). A container with all required analysis software, CWL document and a workflow manager seems well suited for distribution with a publication for reproducible calculations. However for production needs, a modular design with various containers and a workflow manager outside of the containers seem a better choice. It's hard to distinguish these two usages in the manuscript. Can a few lines be devoted to making these clarifications, please?</p></disp-quote><p>Yes, thank you. We have reworked and expanded the second paragraph of the Introduction to address these points. We have pasted this paragraph below for your convenience. (We use the term &quot;orchestration systems&quot; rather than &quot;production systems&quot; because the former appears to be used more commonly in the literature.)</p><p>&quot;In scientific research, the use of workflows can be classified into two main categories. One category includes orchestration systems, in which workflow engines repeatedly process data of a given type. […] Workflows aid in this process because they provide a way to encapsulate the logic for executing code in a fully specified computational environment with all necessary software dependencies installed. For many studies, a relatively simple workflow engine like cwltool can be used to re-execute the analyses.&quot;</p><disp-quote content-type="editor-comment"><p>2. A reviewer notes, &quot;I think it would be useful to beginners to see more information on the benefits of using CWL over some of the alternatives (Nextflow, Snakemake). There are quite a few ways of handling bioinformatic pipelines and in my experience I been overwhelmed by the decision of having to choose one over the rest.&quot;. Can a few lines be devoted to discussing the benefits/weaknesses of these other alternatives?</p></disp-quote><p>Yes, thank you. We have added text to the Introduction section on this topic, as shown below:</p><p>&quot;Different workflow engines use different methodologies and vocabularies for defining workflows and for interfacing with software within those workflows (Leipzig, 2017). […] Indeed, CWL documents are already recognized by many workflow engines, including Snakemake (Köster and Rahmann, 2012), cwltool, Toil (Vivian et al., 2017), Apache Airflow (Kotliar et al., 2019), Tibanna (Lee et al., 2019), and Arvados (Amstutz, 2015).&quot;</p><disp-quote content-type="editor-comment"><p>3. There is no mention of the benefits of error handling and restarts when using a workflow manager. For production environments this is a key benefit, so could this be incorporated please?</p></disp-quote><p>Yes, thank you. We have added text to the Introduction section on this topic, as shown below:</p><p>&quot;Scientists might also take advantage of error handling provided by some workflow engines. For example, if a power outage occurred while a workflow was being executed, it would be possible to restart the workflow at the point of failure rather than needing to rerun the entire workflow.&quot;</p><disp-quote content-type="editor-comment"><p>4. A reviewer mentions. &quot;The manuscript does a good exposition of Docker and containers. However, I didn't find much mention of Docker Hub. Being that Docker Hub was a key element in the prominence of containers I think there should be a bit more details about it on the paper.&quot;. Could some lines about Docker Hub be incorporated please?</p></disp-quote><p>Yes, thank you. We have added a paragraph on this topic to the &quot;Using containers to manage software installation and configuration&quot; subsection, as shown below:</p><p>&quot;Docker Hub (https://hub.docker.com) is a common way to share container images. After building an image on a local computer, a researcher can “push” the image to Docker Hub using a single command. Subsequently, others can “pull” the image and reuse it on a different computer (again, using a single command). Tags can be attached to each image for versioning. Currently, Docker Hub is free to use when specific requirements have been met. The Docker engine also provides a “registry” tool that enables individuals or organizations to host their own registry of container images. For example, Red Hat, Inc offers https://quay.io, which hosts the container images from the Biocontainers project(da Veiga Leprevost et al., 2017).&quot;</p><disp-quote content-type="editor-comment"><p>5. About figures 1 and 2 – should the name of the program in the yellow square be changed to match the.yml found in the GitHUb repository?</p></disp-quote><p>Thank you for noticing this. We have modified Figures 1 and 2 to be consistent with what we have in the GitHub repository.</p><disp-quote content-type="editor-comment"><p>6. Would it be possible to add a button to ToolJig that would populate the fields, as a pre-filled example? It may be easier for beginners to illustrate how the information should be input. Perhaps following the example of one of the ones that are already in the GitHub repository so it's more easily comparable.</p></disp-quote><p>Thank you for the suggestion. We want to make sure the tool is as useful and user-friendly as possible. We have added &quot;Show/hide example&quot; links to ToolJig. These links enable users to see examples of what to specify.</p><disp-quote content-type="editor-comment"><p>7. Could you please specify If the YAML document created by a user is saved by ToolJig, or is it deleted when the user closes the webpage?</p></disp-quote><p>The YAML document created by a user is <italic>not</italic> saved by ToolJig. It will be deleted when the user closes the webpage. However, if they download the file, they can upload it back into ToolJig. We have added a comment to the app to clarify this for users.</p></body></sub-article></article>