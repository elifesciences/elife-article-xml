<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">76120</article-id><article-id pub-id-type="doi">10.7554/eLife.76120</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Binary and analog variation of synapses between cortical pyramidal neurons</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-191744"><name><surname>Dorkenwald</surname><given-names>Sven</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2352-319X</contrib-id><email>svenmd@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-254241"><name><surname>Turner</surname><given-names>Nicholas L</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-191745"><name><surname>Macrina</surname><given-names>Thomas</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-254242"><name><surname>Lee</surname><given-names>Kisuk</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-191746"><name><surname>Lu</surname><given-names>Ran</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-191754"><name><surname>Wu</surname><given-names>Jingpeng</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-254239"><name><surname>Bodor</surname><given-names>Agnes L</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-263038"><name><surname>Bleckert</surname><given-names>Adam A</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-254240"><name><surname>Brittain</surname><given-names>Derrick</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-191748"><name><surname>Kemnitz</surname><given-names>Nico</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254249"><name><surname>Silversmith</surname><given-names>William M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254250"><name><surname>Ih</surname><given-names>Dodam</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-254251"><name><surname>Zung</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254252"><name><surname>Zlateski</surname><given-names>Aleksandar</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254253"><name><surname>Tartavull</surname><given-names>Ignacio</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con15"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-166367"><name><surname>Yu</surname><given-names>Szi-Chieh</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con16"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254254"><name><surname>Popovych</surname><given-names>Sergiy</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con17"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254255"><name><surname>Wong</surname><given-names>William</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con18"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-191750"><name><surname>Castro</surname><given-names>Manuel</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con19"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-191752"><name><surname>Jordan</surname><given-names>Chris S</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con20"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-263039"><name><surname>Wilson</surname><given-names>Alyssa M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con21"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254154"><name><surname>Froudarakis</surname><given-names>Emmanouil</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3249-3845</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con22"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-53087"><name><surname>Buchanan</surname><given-names>JoAnn</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con23"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254244"><name><surname>Takeno</surname><given-names>Marc M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8384-7500</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con24"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254245"><name><surname>Torres</surname><given-names>Russel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2876-4382</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con25"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254246"><name><surname>Mahalingam</surname><given-names>Gayathri</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con26"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-140148"><name><surname>Collman</surname><given-names>Forrest</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0280-7022</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con27"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-218643"><name><surname>Schneider-Mizell</surname><given-names>Casey M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9477-3853</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con28"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-136118"><name><surname>Bumbarger</surname><given-names>Daniel J</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con29"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-60001"><name><surname>Li</surname><given-names>Yang</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con30"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254256"><name><surname>Becker</surname><given-names>Lynne</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con31"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-254257"><name><surname>Suckow</surname><given-names>Shelby</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con32"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-97783"><name><surname>Reimer</surname><given-names>Jacob</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con33"/><xref ref-type="fn" rid="conf4"/></contrib><contrib contrib-type="author" id="author-179925"><name><surname>Tolias</surname><given-names>Andreas S</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con34"/><xref ref-type="fn" rid="conf4"/></contrib><contrib contrib-type="author" id="author-264772"><name><surname>Macarico da Costa</surname><given-names>Nuno</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2001-4568</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con35"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-4315"><name><surname>Reid</surname><given-names>R Clay</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8697-6797</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con36"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-40953"><name><surname>Seung</surname><given-names>H Sebastian</given-names></name><email>sseung@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="fn" rid="con37"/><xref ref-type="fn" rid="conf3"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Computer Science Department, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/042nb2s44</institution-id><institution>Brain &amp; Cognitive Sciences Department, Massachusetts Institute of Technology</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00dcv1019</institution-id><institution>Allen Institute for Brain Science</institution></institution-wrap><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02pttbw34</institution-id><institution>Department of Neuroscience, Baylor College of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02pttbw34</institution-id><institution>Center for Neuroscience and Artificial Intelligence, Baylor College of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/008zs3103</institution-id><institution>Department of Electrical and Computer Engineering, Rice University</institution></institution-wrap><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>O'Leary</surname><given-names>Timothy</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Huguenard</surname><given-names>John R</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Stanford University School of Medicine</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>16</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e76120</elocation-id><history><date date-type="received" iso-8601-date="2021-12-13"><day>13</day><month>12</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-11-15"><day>15</day><month>11</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2019-12-31"><day>31</day><month>12</month><year>2019</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2019.12.29.890319"/></event></pub-history><permissions><copyright-statement>© 2022, Dorkenwald, Turner, Macrina et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Dorkenwald, Turner, Macrina et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-76120-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-76120-figures-v2.pdf"/><abstract><p>Learning from experience depends at least in part on changes in neuronal connections. We present the largest map of connectivity to date between cortical neurons of a defined type (layer 2/3 [L2/3] pyramidal cells in mouse primary visual cortex), which was enabled by automated analysis of serial section electron microscopy images with improved handling of image defects (250 × 140 × 90 μm<sup>3</sup> volume). We used the map to identify constraints on the learning algorithms employed by the cortex. Previous cortical studies modeled a continuum of synapse sizes by a log-normal distribution. A continuum is consistent with most neural network models of learning, in which synaptic strength is a continuously graded analog variable. Here, we show that synapse size, when restricted to synapses between L2/3 pyramidal cells, is well modeled by the sum of a binary variable and an analog variable drawn from a log-normal distribution. Two synapses sharing the same presynaptic and postsynaptic cells are known to be correlated in size. We show that the binary variables of the two synapses are highly correlated, while the analog variables are not. Binary variation could be the outcome of a Hebbian or other synaptic plasticity rule depending on activity signals that are relatively uniform across neuronal arbors, while analog variation may be dominated by other influences such as spontaneous dynamical fluctuations. We discuss the implications for the longstanding hypothesis that activity-dependent plasticity switches synapses between bistable states.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>synapses</kwd><kwd>connectivity diagram</kwd><kwd>pyramidal cell</kwd><kwd>electron microscopy</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011039</institution-id><institution>Intelligence Advanced Research Projects Activity</institution></institution-wrap></funding-source><award-id>D16PC00003</award-id><principal-award-recipient><name><surname>Dorkenwald</surname><given-names>Sven</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011039</institution-id><institution>Intelligence Advanced Research Projects Activity</institution></institution-wrap></funding-source><award-id>D16PC00004</award-id><principal-award-recipient><name><surname>Dorkenwald</surname><given-names>Sven</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011039</institution-id><institution>Intelligence Advanced Research Projects Activity</institution></institution-wrap></funding-source><award-id>D16PC00005</award-id><principal-award-recipient><name><surname>Dorkenwald</surname><given-names>Sven</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>U19 NS104648</award-id><principal-award-recipient><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000183</institution-id><institution>Army Research Office</institution></institution-wrap></funding-source><award-id>W911NF-12-1-0594</award-id><principal-award-recipient><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R01 EY027036</award-id><principal-award-recipient><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>U01 MH114824</award-id><principal-award-recipient><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>R01 NS104926</award-id><principal-award-recipient><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>RF1MH117815</award-id><principal-award-recipient><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011671</institution-id><institution>G. Harold and Leila Y. Mathers Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Sizes of synapses between layer 2/3 pyramidal cells in mouse primary visual cortex are well modeled by the sum of a binary variable and an analog variable drawn from a log-normal distribution.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Synapses between excitatory neurons in the cortex and hippocampus are typically made onto spines, tiny thorn-like protrusions from dendrites (<xref ref-type="bibr" rid="bib91">Yuste, 2010</xref>). In the 2000s, long-term in vivo microscopy studies showed that dendritic spines change in shape and size, and can appear and disappear (<xref ref-type="bibr" rid="bib6">Bhatt et al., 2009</xref>; <xref ref-type="bibr" rid="bib25">Holtmaat and Svoboda, 2009</xref>). Spine dynamics were interpreted as synaptic plasticity, because spine volume is well correlated with physiological strength of a synapse (<xref ref-type="bibr" rid="bib48">Matsuzaki et al., 2001</xref>; <xref ref-type="bibr" rid="bib52">Noguchi et al., 2011</xref>; <xref ref-type="bibr" rid="bib23">Holler et al., 2021</xref>). The plasticity was thought to be in part activity-dependent, because spine volume increases with long-term potentiation (<xref ref-type="bibr" rid="bib49">Matsuzaki et al., 2004</xref>; <xref ref-type="bibr" rid="bib37">Kopec et al., 2006</xref>; <xref ref-type="bibr" rid="bib53">Noguchi et al., 2019</xref>). Given that the sizes of other synaptic structures (postsynaptic density, presynaptic active zone, and so on) are well correlated with spine volume and with each other (<xref ref-type="bibr" rid="bib20">Harris and Stevens, 1989</xref>), we use the catch-all term ‘synapse size’ to refer to the size of any synaptic structure, and ‘synapse strength’ as a synonym.</p><p>In the 2000s, some hypothesized the existence of ‘learning spines’ and ‘memory spines’, appearing to define two discrete categories that are structurally and functionally different (<xref ref-type="bibr" rid="bib30">Kasai et al., 2003</xref>; <xref ref-type="bibr" rid="bib8">Bourne and Harris, 2007</xref>). Quantitative studies of cortical synapses, however, found no evidence for discreteness (<xref ref-type="bibr" rid="bib20">Harris and Stevens, 1989</xref>; <xref ref-type="bibr" rid="bib2">Arellano, 2007</xref>; <xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>; <xref ref-type="bibr" rid="bib45">Loewenstein et al., 2015</xref>; <xref ref-type="bibr" rid="bib15">de Vivo et al., 2017</xref>; <xref ref-type="bibr" rid="bib64">Santuy et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Kasai et al., 2021</xref>). Whether in theoretical neuroscience or artificial intelligence, it is common for the synaptic strengths in a neural network model to be continuously variable, enabling learning to proceed by the accumulation of arbitrarily small synaptic changes over time.</p><p>Here, we reexamine the discrete versus continuous dichotomy using a wiring diagram between 334 layer 2/3 pyramidal cells (L2/3 PyCs) reconstructed from serial section electron microscopy (ssEM) images of mouse primary visual cortex. We show that synapses between L2/3 PyCs are well modeled as a binary mixture of log-normal distributions. If we further restrict consideration to dual connections, two synapses sharing the same presynaptic and postsynaptic cells, the binary mixture exhibits a statistically significant bimodality. It is therefore plausible that the binary mixture reflects two underlying structural states, and is more than merely an improvement in curve fitting.</p><p>According to our best fitting mixture model, synapse size is the sum of a binary variable and a log-normal continuous variable. To probe whether these variables are modified by synaptic plasticity, we examined dual connections. Previous analyses of dual connections examined pairs of synapses between the same axon and same dendrite branches (SASD) (<xref ref-type="bibr" rid="bib75">Sorra and Harris, 1993</xref>; <xref ref-type="bibr" rid="bib36">Koester and Johnston, 2005</xref>; <xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Kasthuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Dvorkin and Ziv, 2016</xref>; <xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>). They found that such synapse pairs are correlated in size, and the correlations have been attributed to activity-dependent plasticity. In contrast, our population of synapse pairs includes distant synapses made on different branches and is constrained to one cell type (L2/3 PyC). We find that the binary variables are highly correlated, while the continuous variables are not. If we expand the analysis to include a broader population of cortical synapses, bimodality is no longer observed.</p><p>The specificity of our synaptic population was made possible because each of the 334 neurons taking part in the 1735 connections in our cortical wiring diagram could be identified as an L2/3 PyC based on a soma and sufficient dendrite and axon contained in the ssEM volume. The closest precedents for wiring diagrams between cortical neurons of a defined type had 29 connections between 43 L2/3 PyCs in mouse visual cortex (<xref ref-type="bibr" rid="bib39">Lee et al., 2016</xref>), 63 connections between 22 L2 excitatory neurons in mouse medial entorhinal cortex (<xref ref-type="bibr" rid="bib66">Schmidt et al., 2017</xref>), and 32 connections between 89 L4 neurons in mouse somatosensory cortex (<xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>).</p><p>Our cortical reconstruction has been made publicly available and used concurrently in other studies (<ext-link ext-link-type="uri" xlink:href="https://www.microns-explorer.org/phase1">https://www.microns-explorer.org/phase1</ext-link>)(<xref ref-type="bibr" rid="bib67">Schneider-Mizell et al., 2021</xref>; <xref ref-type="bibr" rid="bib85">Turner et al., 2022</xref>). The code that generated the reconstruction is already freely available.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Handling of ssEM image defects</title><p>We acquired a 250 × 140 × 90 μm<sup>3</sup> ssEM dataset (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) from L2/3 primary visual cortex of a P36 male mouse at 3.58 × 3.58 × 40 nm<sup>3</sup> resolution. When we aligned a pilot subvolume and applied state-of-the-art convolutional nets, we found many reconstruction errors, mainly due to misaligned images and damaged or incompletely imaged sections. This was disappointing given reports that convolutional nets can approach human-level performance on one benchmark ssEM image dataset (<xref ref-type="bibr" rid="bib4">Beier et al., 2017</xref>; <xref ref-type="bibr" rid="bib92">Zeng et al., 2017</xref>). The high error rate could be explained by the fact that image defects are difficult to escape in large volumes, though they may be rare in small (&lt;1000 μm<sup>3</sup>) benchmark datasets.</p><p>Indeed, ssEM images were historically considered problematic for automated analysis (<xref ref-type="bibr" rid="bib9">Briggman and Bock, 2012</xref>; <xref ref-type="bibr" rid="bib41">Lee et al., 2019</xref>) because they were difficult to align, contained defects caused by lost or damaged serial sections, and had inferior axial resolution (<xref ref-type="bibr" rid="bib35">Knott et al., 2008</xref>). These difficulties were the motivation for developing block face electron microscopy (bfEM) as an alternative to ssEM (<xref ref-type="bibr" rid="bib14">Denk and Horstmann, 2004</xref>). Most large-scale ssEM reconstructions have been completely manual, while many large-scale bfEM reconstructions have been semi-automated (19/20 and 5/10 in Table 1 of <xref ref-type="bibr" rid="bib38">Kornfeld and Denk, 2018</xref>). On the other hand, the higher imaging throughput of ssEM (<xref ref-type="bibr" rid="bib51">Nickell and Zeidler, 2019</xref>; <xref ref-type="bibr" rid="bib90">Yin et al., 2019</xref>) makes it suitable for scaling up to volumes that are large enough to encompass the arbors of mammalian neurons.</p><p>We supplemented existing algorithms for aligning ssEM images (<xref ref-type="bibr" rid="bib62">Saalfeld et al., 2012</xref>) with human-in-the-loop capabilities. After manual intervention by a human expert, large misalignments were resolved but small ones still remained near damaged locations and near the borders of the volume. Therefore, we augmented the training data for our convolutional net with simulated misalignments and missing sections (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). The resulting net was better able to trace neurites through such image defects (<xref ref-type="fig" rid="fig1">Figure 1b</xref>, quantification in <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). Other methods for handling ssEM image defects are being proposed (<xref ref-type="bibr" rid="bib42">Li, 2019</xref>), and we can look forward to further gains in automated reconstruction accuracy in the future.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Reconstructing cortical circuits in spite of serial section electron microscopy (ssEM) image defects.</title><p>(<bold>a</bold>) Ideally, imaging serial sections followed by computational alignment would create an image stack that reflects the original state of the tissue (left). In practice, image stacks end up with missing sections (blue) and misalignments (green). Both kinds of defects are easily simulated when training a convolutional net to detect neuronal boundaries. Small subvolumes are depicted rather than the entire stack, and image defects are typically local rather than extending over an entire section. (<bold>b</bold>) The resulting net can trace more accurately, even in images not previously seen during training. Here, a series of five sections contains a missing section (blue frame) and a misalignment (green). The net ‘imagines’ the neurites through the missing section, and traces correctly in spite of the misalignment. (<bold>c</bold>) 3D reconstructions of the neurites exhibit discontinuities at the misalignment, but are correctly traced. (<bold>d</bold>) All 362 pyramidal cells with somas in the volume (gray), cut away to reveal a few examples (colors). (<bold>e</bold>) Layer 2/3 (L2/3) pyramidal cell reconstructed from ssEM images of mouse visual cortex. Scale bars: 300 nm (<bold>b</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Reconstruction of connections between layer 2/3 (L2/3) pyramidal cells.</title><p>250×140×90 µm<sup>3</sup> 3D image stack from L2/3 of mouse primary visual cortex.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Examples of reconstructed neurites near image defects.</title><p>(<bold>a</bold>) Illustration of a possible pair of neurites that pass through both missing section (cyan) and misalignment (orange) defects. (<bold>b</bold>) Illustration of a naive segmentation of the pair in (<bold>a</bold>). (<bold>c</bold>) Same examples as in <xref ref-type="fig" rid="fig1">Figure 1</xref>, accompanied by affinity map. Scale bar: 300 nm. (<bold>d</bold>) Near a larger misalignment, the displacement is larger than the width of a thin neurite, and the convolutional net is unable to trace through the misalignment. Scale bar 300 nm. (<bold>e</bold>) A proofread neuron (gray) with segments merged during proofreading (colored). Scale bar: 10 μm. (<bold>f</bold>) The same proofread neuron in (<bold>e</bold>) with pieces split during proofreading (colored).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Quantitative evidence for the effectiveness of training data augmentation.</title><p>Robustness of three boundary detectors trained with no data augmentation (‘baseline’, blue), simulated missing section (‘missing section’, red), and simulated misalignment (‘misalignment’, yellow) to (<bold>a</bold>) increasingly large displacement of simulated misalignment and (<bold>b</bold>) increasing number of simulated consecutive missing sections.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig1-figsupp3-v2.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Wiring diagram between cells in L2/3</title><p>After alignment and automatic segmentation (Materials and methods), we semi-automatically identified 417 PyCs and 34 inhibitory cells with somas in the volume based on morphological characteristics and automated nucleus detection (<xref ref-type="fig" rid="fig1">Figure 1d and e</xref>, Materials and methods). We then chose a subset of 362 PyCs and 34 inhibitory cells with sufficient neurite length within the volume for proofreading. Remaining errors in the segmentation of these cells were corrected using an interactive system that enabled human experts to split and merge objects.</p><p>We estimate that the PyC reconstructions were corrected through ~1300 hr of human proofreading to yield 670 mm cable length (axon: 100 mm, dendrite: 520 mm, perisomatic: 40 mm, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). We examined 12 randomly sampled axons and conservatively estimated that 0.28 merge errors per millimeter remain after proofreading (see Materials and methods for other estimates). The dendrites of the PyCs receive more than one-quarter of the 3.2 million synapses that were automatically detected in the volume (Materials and methods, <xref ref-type="bibr" rid="bib82">Turner et al., 2020</xref>). However, the synapses onto PyC dendrites are almost all from ‘orphan’ axons, defined as those axonal fragments that belong to somas of unknown location outside the volume. Using these automatically detected synapses as a starting point, we mapped all connections between this set of PyCs and inhibitory cells (Materials and methods). The end result was a wiring diagram of 6210 synapses from 3347 connections in the dataset. The subgraph of PyCs contained 1960 synapses from 1735 connections between 334 L2/3 PyCs (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). Note that some connections are multisynaptic, that is, they are mediated by multiple synapses sharing the same presynaptic and postsynaptic cells (<xref ref-type="fig" rid="fig2">Figure 2b</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, see <xref ref-type="table" rid="table1">Table 1</xref> for a tabular overview of these statistics).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Wiring diagram for cortical neurons including multisynaptic connections.</title><p>(<bold>a</bold>) Wiring diagram of 362 proofread layer 2/3 (L2/3) pyramidal cells (PyCs) as a directed graph. Two orthogonal views with nodes at 3D locations of cell bodies. Single (gray), dual (blue), and triple, quadruple, quintuple (red) connections. (<bold>b</bold>) Dual connection from a presynaptic cell (orange) to a postsynaptic cell (gray). Ultrastructure of both synapses can be seen in closeups from the electron microscopy (EM) images. The Euclidean distance between the synapses is 64.3 μm. (<bold>c</bold>) Normalized distributions of synapses sizes for L2/3 PyCs synapses separated by postsynaptic cell type. (<bold>d</bold>) Same as (<bold>c</bold>) for inhibitory cells in layer 2/3. (<bold>e</bold>) Cumulative distributions of the number of synapses per connection for different pre- and postsynaptic cell types. (<bold>f</bold>) Distribution of Euclidean distances between synapse pairs of dual connections. Median distance is 46.5 μm. Scale bars: 10 μm (<bold>a</bold>), 500 nm (<bold>b</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Renderings of all synapses from multisynaptic connections between layer 2/3 (L2/3) pyramidal cells.</title><p>Dendritic spines (yellow) and synaptic clefts (red) are rendered in 3D. Most are dual connections (160), but there are also triples (24), quadruples (3), and quintuples (2).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Examples of synapses between layer 2/3 (L2/3) pyramidal cells.</title><p>Scale bar: 500nm. In each pair of images, the left shows one section through a synapse, and the right adds the automatically detected cleft as an overlay. Note here that the clefts are associated with postsynaptic densities.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig2-figsupp2-v2.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Overview of number of data points obtained in this study.</title></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="bottom">Number of L2/3 PyCs in dataset</td><td align="left" valign="middle">417</td></tr><tr><td align="left" valign="bottom">Number of L2/3 PyCs selected for proofreading</td><td align="left" valign="middle">362</td></tr><tr><td align="left" valign="bottom">Number of proofread L2/3 PyCs connecting to any other L2/3 PyCs</td><td align="left" valign="middle">334</td></tr><tr><td align="left" valign="bottom">Number of inhibitory cells in dataset</td><td align="left" valign="middle">34</td></tr><tr><td align="left" valign="bottom">Number of synapses (automated) in the dataset</td><td align="left" valign="middle">3,239,275</td></tr><tr><td align="left" valign="bottom">Number of outgoing synapses (automated) in the dataset from proofread L2/3 PyCs</td><td align="left" valign="middle">10,788</td></tr><tr><td align="left" valign="bottom">Number of synapses between L2/3 PyCs</td><td align="left" valign="middle">1960</td></tr><tr><td align="left" valign="bottom">Number of connections between L2/3 PyCs</td><td align="left" valign="middle">1735</td></tr><tr><td align="left" valign="bottom">Number of connections between L2/3 PyCs with one synapse</td><td align="left" valign="middle">1546</td></tr><tr><td align="left" valign="bottom">Number of connections between L2/3 PyCs with two synapses</td><td align="left" valign="middle">160</td></tr><tr><td align="left" valign="bottom">Number of connections between L2/3 PyCs with three synapses</td><td align="left" valign="middle">24</td></tr><tr><td align="left" valign="bottom">Number of connections between L2/3 PyCs with four synapses</td><td align="left" valign="middle">3</td></tr><tr><td align="left" valign="bottom">Number of connections between L2/3 PyCs with five synapses</td><td align="left" valign="middle">2</td></tr></tbody></table></table-wrap><p>For clarity, we emphasize that our usage of the term ‘multisynaptic’ refers to multiple synapses between a single cell pair. A connection between two PyCs usually (89.1%) contains one synapse, but can contain up to five synapses (2: 9.22%, 3: 1.38%, 4: 0.17%, 5: 0.12%, <xref ref-type="fig" rid="fig2">Figure 2c</xref>) (these numbers should be taken with the caveat that the observed number of synapses for a connection is a lower bound for the true number of synapses, because two PyCs with cell bodies in our EM volume could synapse with each other outside the bounds of the volume.). In comparison, only 60.3% of connections from PyCs on inhibitory cells were monosynaptic. Similarly, 62.1% connections made by inhibitory neurons were monosynaptic when targeting other inhibitory neurons, which reduces to only 42.6% when targeting PyCs. While the number of synapses per PyC-PyC connection varies least compared to the other three categories, we observed the highest variance in synapse sizes for these connections (<xref ref-type="fig" rid="fig2">Figure 2d and e</xref>). Here, we quantified synaptic cleft size as the number of voxels labeled by the output of our automated cleft detector (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). The dimensions of our reconstructions allowed us to observe dual connections with two synapses more than 100 μm apart (<xref ref-type="fig" rid="fig2">Figure 2b and f</xref>), involving different axonal and dendritic branches. Previous analyses reporting correlations between synapses from dual synaptic connections only included synapses that were close to another and were between the SASD.</p></sec><sec id="s2-3"><title>Binary latent states</title><p>Previous studies of cortical synapses have found a continuum of synapse sizes (<xref ref-type="bibr" rid="bib2">Arellano, 2007</xref>) that is approximated by a log-normal distribution (<xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>; <xref ref-type="bibr" rid="bib15">de Vivo et al., 2017</xref>; <xref ref-type="bibr" rid="bib64">Santuy et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Kasai et al., 2021</xref>). Even researchers who report bimodally distributed synapse size on a log-scale in hippocampus (<xref ref-type="bibr" rid="bib77">Spano et al., 2019</xref>) still find log-normally distributed synapse size in neocortex (<xref ref-type="bibr" rid="bib15">de Vivo et al., 2017</xref>) by the same methods.</p><p>We quantified the size of each synapse by the volume of the spine head (<xref ref-type="fig" rid="fig2">Figures 2b</xref> and <xref ref-type="fig" rid="fig3">3a</xref>) (spine head volume excludes the spine neck, which is at most only weakly correlated in size with other synaptic structures [<xref ref-type="bibr" rid="bib2">Arellano, 2007</xref>]). In the following, ‘spine volume’ will serve as a synonym for spine head volume. Spine volumes spanned over two orders of magnitude, though 75% of spines lie within a single order of magnitude. The distribution of spine volumes is highly skewed, with a long tail of large spines (<xref ref-type="fig" rid="fig3">Figure 3b</xref>) as observed before (<xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>; <xref ref-type="bibr" rid="bib64">Santuy et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Kasai et al., 2021</xref>). Because of the skew, it is helpful to visualize the distribution using a logarithmic scale for spine volume (<xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>; <xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>). We were surprised to find that the distribution deviated from normality, due to a ‘knee’ on the right side of the histogram (<xref ref-type="fig" rid="fig3">Figure 3c</xref>) (multiple researchers have proposed dynamical models of spine size that are consistent with approximately log-normal stationary distributions [<xref ref-type="bibr" rid="bib31">Kasai et al., 2021</xref>]). A mixture of two normal distributions was a better fit than a single normal distribution when accounting for the number of free parameters (likelihood ratio test: p&lt;1e-39, <italic>n</italic>=1960, Materials and methods).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Modeling spine head volume with a mixture of two log-normal distributions.</title><p>(<bold>a</bold>) Dendritic spine heads (yellow) and clefts (red) of dual connections between layer 2/3 pyramidal cells (L2/3) PyCs. The associated electron microscopy (EM) cutout shows a 2D slice through the synapse. The synapses are centered in the EM images. (<bold>b</bold>) Skewed histogram of spine volume for all 1960 recurrent synapses between L2/3 PyCs, with a long tail of large spines. (<bold>c</bold>) Histogram of the spine volumes in (<bold>b</bold>), logarithmic scale. A mixture (red, solid) of two log-normal distributions (red, dashed) fits better (likelihood ratio test, p&lt;1e-39, <italic>n</italic>=1960) than a single normal (blue). (<bold>d</bold>) Spine volumes belonging to dual connections between L2/3 PyCs, modeled by a mixture (red, solid) of two log-normal distributions (red, dashed). (<bold>e</bold>) Dual connections between L2/3 PyCs, each summarized by the geometric mean of two spine volumes, modeled by a mixture (red, solid) of two log-normal distributions (red, dashed). (<bold>f</bold>) Mixture of two normal distributions as a probabilistic latent variable model. Each synapse is described by a latent state <italic>H</italic> that takes on values ‘S’ and ‘L’ according to the toss of a biased coin. Spine volume <italic>V</italic> is drawn from a log-normal distribution with mean and variance determined by latent state. The curves shown here represent the best fit to the data in (<bold>d</bold>). Heights are scaled by the probability distribution of the biased coin, known as the mixture weights. (<bold>g</bold>) Comparison of spine volumes for single (black) and dual (red) connections. (<bold>h</bold>) Probability of the ‘L’ state (mixture weight) versus number of synapses in the connection. Error bars are standard deviations estimated by bootstrap sampling. Scale bar: 500nm (<bold>a</bold>). Error bars are <inline-formula><mml:math id="inf1"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit (<bold>c, d, e</bold>) and standard deviation from bootstrapping (<bold>h</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Linear spine head volume distributions.</title><p>(<bold>a</bold>) Spine volumes belonging to dual connections between layer 2/3 pyramidal cells (L2/3 PyCs). (<bold>b</bold>) Dual connections between L2/3 PyCs, each summarized by the geometric mean of two spine volumes.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Arithmetic means.</title><p>(<bold>a</bold>) Dual connections between layer 2/3 pyramidal cells (L2/3 PyCs), each summarized by the arithmetic mean of two spine volumes, modeled by a mixture (red, solid) of two normal distributions (red, dashed). (<bold>b</bold>) Dual connections between L2/3 PyCs, each summarized by the arithmetic mean of two cleft sizes, modeled by a mixture (red, solid) of two normal distributions (red, dashed). Error bars are <inline-formula><mml:math id="inf2"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Fits versus raw data histograms.</title><p>Plots are analogous to <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>. (<bold>a</bold>) Histogram of same spine volumes, logarithmic scale. A mixture (red, solid) of two log-normal distributions (red, dashed) is shown. (<bold>b</bold>) Spine volumes belonging to dual connections between layer 2/3 pyramidal cells (L2/3 PyCs), modeled by a mixture (red, solid) of two log-normal distributions (red, dashed). (<bold>c</bold>) Dual connections between L2/3 PyCs, each summarized by the geometric mean of two spine volumes, modeled by a mixture (red, solid) of two log-normal distributions (red, dashed). (<bold>d</bold>) Dual connections between L2/3 PyCs, each summarized by the arithmetic mean of two spine volumes, modeled by a mixture (red, solid) of two log-normal distributions (red, dashed).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Modeling spine volume with a bimodal versus unimodal mixture of two normal distributions.</title><p>(<bold>a</bold>) Spine volumes belonging to dual connections between layer 2/3 (L2/3) pyramidal cells. A bimodal mixture (red, solid) of two normal distributions (red, dashed) is a better fit than a unimodal mixture (blue, solid) of two normal distributions (blue, dashed) (see <xref ref-type="bibr" rid="bib26">Holzmann and Vollmer, 2008</xref>; p=0.0425, <italic>n</italic>=320). The bimodal mixture weights are 60:40. (<bold>b</bold>) Dual connections between L2/3 pyramidal cells, each summarized by the geometric mean of spine volumes. A bimodal mixture (red, solid) of two normal distributions (red, dashed) is a better fit than a unimodal mixture (blue, solid) of two normal distributions (blue, dashed) (likelihood ratio test, p=0.0059, <italic>n</italic>=160). Error bars are <inline-formula><mml:math id="inf3"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Modeling cleft size with a mixture of two normal distributions.</title><p>(<bold>a</bold>) Spine volume versus cleft size for all layer 2/3 pyramidal cell (L2/3 PyC)-L2/3 PyC synapses. (<bold>b</bold>) Histogram of same spine volumes, logarithmic scale. A mixture (red, solid) of two normal distributions (red, dashed) fits better (likelihood ratio test, p&lt;1e-63, <italic>n</italic>=1960) than a single normal (blue). (<bold>c</bold>) Cleft sizes belonging to dual connections between L2/3 PyCs, modeled by a mixture (red, solid) of two normal distributions (red, dashed, likelihood ratio test, p=0.02, <italic>n</italic>=320). (<bold>d</bold>) Dual connections between L2/3 PyCs, each summarized by the geometric mean of two cleft sizes, modeled by a mixture (red, solid) of two normal distributions (red, dashed, likelihood ratio test, p=0.037, <italic>n</italic>=160). (<bold>e</bold>) Comparison of cleft sizes for single (black) and dual (red) connections. (<bold>f</bold>) Probability of the ‘L’ state (mixture weight) versus number of synapses in the connection. Error bars are <inline-formula><mml:math id="inf4"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-figsupp5-v2.tif"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 6.</label><caption><title>Synapse size by connection type.</title><p>(<bold>a</bold>) Bottom: Spine head volume distribution for single connections (gray) along with synapses for all connections (black). Top: parameter estimates for the component means of single connections, as well as dual connections (red), and triple connections (cyan) and all connections (black). Gray line indicates 90% bootstrap interval over the single connection synapses (1000 samples). Points jittered for clarity. (<bold>b</bold>) Parameter estimates for component means of the same populations in (<bold>a</bold>). Box indicates interquartile range across bootstrap samples. Whiskers show 90% bootstrap interval. (<bold>c</bold>) Parameter estimates for component standard deviations of the same populations in (<bold>a</bold>). (<bold>d</bold>) Second component mean estimate from GMM fits on samples of the full dataset model. Full dataset model used for sampling had component weights taken from single connection model, dual connection model, or triple connection model. Points show parameter estimate from the original GMM fit for that connection type. (<bold>e</bold>) Spine head volume by the number of synapses in a connection.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-figsupp6-v2.tif"/></fig><fig id="fig3s7" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 7.</label><caption><title>Relation of dendritic spine volume to spine apparatus.</title><p>(<bold>a</bold>) Examples of spine apparatus (SA) in electron microscopy (EM) images. Scale bar: 300 nm. (<bold>b</bold>) Spine volume distributions of synapses with no endoplasmic reticulum (ER) (blue), smooth ER (yellow), and SA (red). (<bold>c</bold>) Likelihood of SA (red) and ‘L’ state (black) conditioned on spine volume. (<bold>d</bold>) Spine volume distribution conditioned on SA (red) compared with size distribution conditioned on ‘L’ state (black). Inset: Joint probability distribution of SA within dual connections. Error bars are <inline-formula><mml:math id="inf5"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig3-figsupp7-v2.tif"/></fig></fig-group><p>We next restricted our consideration to the 320 synapses belonging to 160 dual connections between the PyCs. Again, a binary mixture of normal distributions was a better fit (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> for linear plots) than a single normal distribution (normal fit not shown, likelihood ratio test: p&lt;1e-7, <italic>n</italic>=320). Next, we made use of the fact that synapses from dual connections are paired. For each pair, we computed the geometric mean (i.e., mean in log-space) of spine volumes and found that this quantity is also well modeled by a binary mixture of normal distributions (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> for the arithmetic mean, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref> for histograms without model fits and <xref ref-type="table" rid="table2">Table 2</xref> for fit results).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Overview of results from log-normal mixture fits for different synapse subpopulations.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="2">Subset of L2/3 L2/3 PyC synapses</th><th align="center" valign="bottom" colspan="3">S</th><th align="center" valign="bottom" colspan="3">L</th><th align="center" valign="bottom" rowspan="2"><italic>N</italic></th></tr><tr><th align="center" valign="bottom">Mean(log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">Std(log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">Weight</th><th align="center" valign="bottom">Mean (log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">Std(log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">Weight</th></tr></thead><tbody><tr><td align="left" valign="bottom">All synapses</td><td align="center" valign="bottom">–1.42</td><td align="center" valign="bottom">0.24</td><td align="center" valign="bottom">0.77</td><td align="center" valign="bottom">–0.77</td><td align="center" valign="bottom">0.22</td><td align="center" valign="bottom">0.23</td><td align="center" valign="bottom">1960</td></tr><tr><td align="left" valign="bottom">Single synapses</td><td align="center" valign="bottom">–1.41</td><td align="center" valign="bottom">0.24</td><td align="center" valign="bottom">0.81</td><td align="center" valign="bottom">–0.76</td><td align="center" valign="bottom">0.21</td><td align="center" valign="bottom">0.19</td><td align="center" valign="bottom">1546</td></tr><tr><td align="left" valign="bottom">Dual synapses</td><td align="center" valign="bottom">–1.44</td><td align="center" valign="bottom">0.23</td><td align="center" valign="bottom">0.64</td><td align="center" valign="bottom">–0.77</td><td align="center" valign="bottom">0.21</td><td align="center" valign="bottom">0.36</td><td align="center" valign="bottom">320</td></tr><tr><td align="left" valign="bottom">Triple synapses</td><td align="center" valign="bottom">–1.49</td><td align="center" valign="bottom">0.17</td><td align="center" valign="bottom">0.36</td><td align="center" valign="bottom">–0.86</td><td align="center" valign="bottom">0.30</td><td align="center" valign="bottom">0.64</td><td align="center" valign="bottom">72</td></tr><tr><td align="left" valign="bottom">All synapses with weights refitted to single synapses</td><td align="center" valign="bottom">(–1.42)</td><td align="center" valign="bottom">(0.24)</td><td align="center" valign="bottom">0.80</td><td align="center" valign="bottom">(–0.77)</td><td align="center" valign="bottom">(0.248)</td><td align="center" valign="bottom">0.20</td><td align="center" valign="bottom">1960 and 1546</td></tr><tr><td align="left" valign="bottom">All synapses with weights refitted to dual synapses</td><td align="center" valign="bottom">(–1.42)</td><td align="center" valign="bottom">(0.24)</td><td align="center" valign="bottom">0.66</td><td align="center" valign="bottom">(–0.77)</td><td align="center" valign="bottom">(0.248)</td><td align="center" valign="bottom">0.34</td><td align="center" valign="bottom">1960 and 320</td></tr><tr><td align="left" valign="bottom">All synapses with weights refitted to triple synapses</td><td align="center" valign="bottom">(–1.42)</td><td align="center" valign="bottom">(0.24)</td><td align="center" valign="bottom">0.52</td><td align="center" valign="bottom">(–0.77)</td><td align="center" valign="bottom">(0.248)</td><td align="center" valign="bottom">0.48</td><td align="center" valign="bottom">1960 and 72</td></tr><tr><td align="left" valign="bottom">Geometric mean of dual synapses</td><td align="center" valign="bottom">–1.44</td><td align="center" valign="bottom">0.16</td><td align="center" valign="bottom">0.58</td><td align="center" valign="bottom">–0.87</td><td align="center" valign="bottom">0.18</td><td align="center" valign="bottom">0.42</td><td align="center" valign="bottom">160</td></tr><tr><td align="left" valign="bottom">Arithmetic mean of dual synapses</td><td align="center" valign="bottom">–1.43</td><td align="center" valign="bottom">0.16</td><td align="center" valign="bottom">0.53</td><td align="center" valign="bottom">–0.85</td><td align="center" valign="bottom">0.18</td><td align="center" valign="bottom">0.47</td><td align="center" valign="bottom">160</td></tr></tbody></table></table-wrap><p>A binary mixture model might merely be a convenient way of approximating deviations from normality. We would like to know whether the components of our binary mixture could correspond to two structural states of synapses. A mixture of two normal distributions can be unimodal or bimodal, depending on the model parameters (for example, if the two normal distributions have the same weight and standard deviation, then the mixture is unimodal if and only if the separation between the means is at most twice the standard deviation) (<xref ref-type="bibr" rid="bib60">Robertson and Fryer, 1969</xref>). When comparing best fit unimodal and bimodal mixtures we found that a bimodal model yields a significantly superior fit for spine volume and geometric mean of spine volume (p=0.0425, <italic>n</italic>=320; <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, see <xref ref-type="bibr" rid="bib26">Holzmann and Vollmer, 2008</xref>, for statistical methods).</p><p>A binary mixture model can be interpreted in terms of a binary latent variable. According to such an interpretation, synapses are drawn from two latent states (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). In ‘S’ and ‘L’ states, spine volumes are drawn from log-normal distributions with small and large means, respectively. It should be noted that there is some overlap between mixture components (<xref ref-type="fig" rid="fig3">Figure 3f</xref>), so that an S synapse can be larger than an L synapse.</p><p>To validate this finding with a different measurement of synapse size, the number of voxels labeled by the output of our automated cleft detector. We found a close relationship between spine volume and cleft size in our data (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5a</xref>), in accord with previous studies (<xref ref-type="bibr" rid="bib20">Harris and Stevens, 1989</xref>; <xref ref-type="bibr" rid="bib2">Arellano, 2007</xref>; <xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>). When spine volume is replaced by cleft size in the preceding analysis, we obtain similar results (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>).</p><p>According to our two-state model, the parameters of the mixture components should stay roughly constant for the distribution of any subset of synapses between L2/3 PyCs. To probe model dependence on the number of synapses per connection, we individually fit a Gaussian mixture to the population of synapses from single, dual, and triple connections and found that their mixture components were not significantly different. Parameter estimates for these fits lie within sampling error of the single connection dataset (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>). When comparing these distributions we observed an overrepresentation of large synapses for dual connections compared to single connections (<xref ref-type="fig" rid="fig3">Figure 3g</xref>). We wondered if the previously reported mean spine volume increase with the number of synapses per connection (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>, <xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>) could be explained with a synapse redistribution between the latent states. This time, we only fit the component weights to single, dual, triple connections while keeping the Gaussian components constant (see Materials and methods). We found a linear increase in fraction of synapses in the ‘L’ state with the number of synapses per connection (<xref ref-type="fig" rid="fig3">Figure 3h</xref>). (This relationship was found for the <italic>observed</italic> number of synapses. On average, this number is expected to increase with the <italic>true</italic> number of synapses. Therefore, mean spine volume is also expected to increase with the true number of synapses per connection)</p><p>Large spines have been reported to contain an intracellular organelle called a spine apparatus (SA), which is a specialized form of smooth endoplasmic reticulum (ER) (<xref ref-type="bibr" rid="bib56">Peters and Kaiserman-Abramof, 1970</xref>; <xref ref-type="bibr" rid="bib76">Spacek, 1985</xref>; <xref ref-type="bibr" rid="bib20">Harris and Stevens, 1989</xref>). We manually annotated SA in all dendritic spines of all synapses between L2/3 PyCs, and confirmed quantitatively that the probability of an SA increases with spine volume (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7</xref>, Materials and methods).</p></sec><sec id="s2-4"><title>Correlations at dual connections</title><p>Positive correlation between synapse sizes at dual connections has been reported previously in hippocampus (<xref ref-type="bibr" rid="bib75">Sorra and Harris, 1993</xref>; <xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>) and neocortex (<xref ref-type="bibr" rid="bib32">Kasthuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>) for synapse pairs formed by the same axonal and dendritic branches. According to our binary mixture model, synapse size is the sum of a binary variable and a log-normal continuous variable. We decided to quantify the contributions of these variables to synapse size correlations.</p><p>The dendritic spines for all dual connections between L2/3 PyCs are rendered in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. A positive correlation between the two spine volumes of each dual connection is evident in a scatter plot of the spine volume pairs (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for an unoccluded plot; Pearson’s <italic>r</italic>=0.418). We fit the joint distribution of the spine volumes by a mixture model like <xref ref-type="fig" rid="fig3">Figure 3f</xref>, while allowing the latent states to be correlated (<xref ref-type="fig" rid="fig4">Figure 4a and f</xref>, see <xref ref-type="table" rid="table3">Table 3</xref> for fit results, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> for the same analysis for synaptic cleft sizes). In the best-fitting model, SS occurs roughly half the time, LL one-third of the time, and the mixed states (SL, LS) occur more rarely (<xref ref-type="fig" rid="fig4">Figure 4e</xref>). The low probability of the mixed states can be seen directly in the scarcity of points in the upper left and lower right corners of the scatter plot (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). Pearson’s phi coefficient, the specialization of Pearson’s correlation coefficient to binary variables, is 0.637.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Latent state correlations between spines at dual connections.</title><p>(<bold>a</bold>) Scatter plot of spine volumes (black, lexicographic ordering) for dual connections. Data points are mirrored across the diagonal (gray). The joint distribution is fit by a mixture model (orange) like that of <xref ref-type="fig" rid="fig3">Figure 3f</xref>, but with latent states correlated as in (<bold>e</bold>). (<bold>b</bold>) Projecting the points onto the vertical axis yields a histogram of spine volumes for dual connections (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). Model is derived from the joint distribution. (<bold>c</bold>) Projecting onto the <italic>x</italic>=<italic>y</italic> diagonal yields a histogram of the geometric mean of spine volumes (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). Model is derived from the joint distribution. (<bold>d</bold>) Projecting onto the <italic>x</italic>=−<italic>y</italic> diagonal yields a histogram of the ratio of spine volumes. (<bold>e</bold>) The latent states of synapses in a dual connection (<bold>H<sub>1</sub> and H<sub>2</sub></bold>) are more likely to be the same (SS or LL) than different (SL/LS), as shown by the joint probability distribution. (<bold>f</bold>) When conditioned on the latent states, the spine volumes (<bold>V<sub>1</sub> and V<sub>2</sub></bold>) are statistically independent, as shown in this dependency diagram of the model. (<bold>g</bold>), (<bold>h</bold>) Sampling synapse pairs to SS and LL states according to their state probabilities. The top shows a kernel density estimation of multiple iterations of sampling. The bottom shows the distribution of Pearson’s <italic>r</italic> correlations across many sampling rounds (<italic>N</italic>=10,000). Error bars are <inline-formula><mml:math id="inf6"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Fits versus raw distributions.</title><p>Plots are analogous to <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>. (<bold>a</bold>) Synapse pairs from all dual connections. (<bold>b</bold>) Dual connections of synapse pairs less than the median distance apart. (<bold>c</bold>) Dual connections of synapse pairs more than the median distance apart.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Latent state correlations between clefts at dual connections.</title><p>(<bold>a</bold>) The latent states of synapses in a dual connection are positively correlated with each other. The latent states are more likely to be the same (SS or LL) rather than different (SL or LS), as shown by the joint probability distribution. (<bold>b</bold>) Scatter plot of cleft sizes (black, lexicographic ordering) for dual connections between layer 2/3 (L2/3) pyramidal cells. Scatter plot points are mirrored across the diagonal (gray). The joint distribution is fit by a mixture model (orange) like that of <xref ref-type="fig" rid="fig3">Figure 3f</xref>, but with latent states that are correlated as described below. (<bold>c</bold>) Projecting the points onto the vertical axis yields a histogram of cleft sizes for dual connections, the same as in <xref ref-type="fig" rid="fig3">Figure 3d</xref>. Model is derived from the joint distribution. (<bold>d</bold>) Projecting the points onto the <italic>x</italic>=<italic>y</italic> diagonal yields a histogram of the geometric mean of cleft sizes for dual connections, the same as in <xref ref-type="fig" rid="fig3">Figure 3e</xref>. Model is derived from the joint distribution. (<bold>e</bold>) Projecting the points onto the <italic>x</italic>=−<italic>y</italic> diagonal yields a histogram of the ratio of cleft sizes for dual connections. Error bars are <inline-formula><mml:math id="inf7"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Residuals spine head volume after subtracting binary components.</title><p>We assigned the synapse pairs from the 160 dual synaptic connections to their most likely state (SS, SL, LS, LL) and subtracted the mean of the binary components. (<bold>a</bold>) shows the residual components. (<bold>b</bold>) shows the residual components when restricting assignments to SS and LL states.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig4-figsupp3-v2.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Synapses in a dual connection: near versus far pairs.</title><p>Spine volumes (left) and cleft sizes (right). (<bold>a</bold>) Dual connections of synapse pairs less than 46.5 μm apart (phi = 0.534). (<bold>b</bold>) Dual connections of synapse pairs more than 46.5 μm apart (phi = 0.745). (<bold>c</bold>) Mixture component means of model fits as a function of the minimum distance separating synapse pairs. (<bold>d</bold>) Mixture component means of model fits as a function of the maximum distance separating synapse pairs. Error bars are <inline-formula><mml:math id="inf8"><mml:mo>±</mml:mo><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:math></inline-formula> of the model fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig4-figsupp4-v2.tif"/></fig><fig id="fig4s5" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 5.</label><caption><title>Dual connection correlations are not a result of axon or dendrite biases.</title><p>Synapses are shuffled between dual connections to measure the correlations between synapses that have the same axon (red) or the same dendrite (blue) against a fully random baseline (black). Shuffled synapses are not allowed to be paired with other synapses within their original connection. Each shuffling procedure was performed on a subset of data where at least one valid shuffling exists for each synapse (e.g. where each dendrite receives at least two dual connections). (<bold>a–c</bold>) Joint distributions of spine head volumes in the dual connections used for shuffling. Slope of linear fit shows Pearson’s <italic>r</italic> value. (<bold>a</bold>) Subset of data used for random shuffling (all 160 synapse pairs). <italic>r</italic>=0.42. (<bold>b</bold>) Subset of data used for axon-preserved shuffling (141 pairs). <italic>r</italic>=0.45. (<bold>c</bold>) Subset of data used for dendrite-preserved shuffling (89 pairs). <italic>r</italic>=0.51. (<bold>d</bold>) Example shuffle of data in (<bold>a</bold>). <italic>r</italic>=0.00. (<bold>e</bold>) Example shuffle of data in (<bold>b</bold>). <italic>r</italic>=–0.08. (<bold>f</bold>) Example shuffle of data in (<bold>c</bold>). <italic>r</italic>=–0.11. (<bold>g</bold>) Diagram of a possible shuffle of two dual synaptic connections onto the same dendrite. (<bold>h</bold>) Distribution of Pearson’s <italic>r</italic> correlation for paired spine head volumes after shuffling (100,000 shuffles each). Dashed lines indicate correlation value for the unshuffled subset. (<bold>i</bold>) Distribution of Pearson’s phi correlation for paired spine head volumes after shuffling.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig4-figsupp5-v2.tif"/></fig><fig id="fig4s6" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 6.</label><caption><title>Removing constraints on the synaptic population eliminates bimodality and reduces correlations.</title><p>Spine volumes (top) and cleft sizes (bottom). (<bold>a</bold>) Distribution of synapse sizes in dual connections received by layer 2/3 (L2/3) pyramidal cells, including those from orphan axons (566 synapses). (<bold>b</bold>) Distribution of geometric means of synapse sizes in same dual connections as in (<bold>a</bold>) (283 pairs). (<bold>c</bold>) Joint distribution of synapse sizes in dual connections received by L2/3 pyramidal cells, including those from orphan axons (283 pairs). (<bold>d</bold>) Distribution of synapse sizes for excitatory synapses received by L2/3 pyramidal cells, including those from orphan axons (700 synapses).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76120-fig4-figsupp6-v2.tif"/></fig></fig-group><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Overview of results from hidden Markov model (HMM) log-normal component fits for different dual synaptic connection subpopulations.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="2">Subset of L2/3 L2/3 PyC dual synaptic connections</th><th align="center" valign="bottom" colspan="2">S</th><th align="center" valign="bottom" colspan="2">L</th><th align="center" valign="bottom" colspan="3">Weights</th><th align="center" valign="bottom" rowspan="2">Pearson’s phi</th><th align="center" valign="bottom" rowspan="2"><italic>N</italic></th></tr><tr><th align="center" valign="bottom">Mean(log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">Std(log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">Mean (log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">Std(log<sub>10</sub> µm<sup>3</sup>)</th><th align="center" valign="bottom">SS</th><th align="center" valign="bottom">SL+LS</th><th align="center" valign="bottom">LL</th></tr></thead><tbody><tr><td align="left" valign="bottom">All connections</td><td align="center" valign="bottom">–1.470</td><td align="center" valign="bottom">0.216</td><td align="center" valign="bottom">–0.833</td><td align="center" valign="bottom">0.244</td><td align="center" valign="bottom">0.490</td><td align="center" valign="bottom">0.177</td><td align="center" valign="bottom">0.333</td><td align="center" valign="bottom">0.637</td><td align="center" valign="bottom">160</td></tr><tr><td align="left" valign="bottom">Dist &lt;median dist</td><td align="center" valign="bottom">–1.506</td><td align="center" valign="bottom">0.212</td><td align="center" valign="bottom">–0.861</td><td align="center" valign="bottom">0.243</td><td align="center" valign="bottom">0.427</td><td align="center" valign="bottom">0.232</td><td align="center" valign="bottom">0.342</td><td align="center" valign="bottom">0.534</td><td align="center" valign="bottom">80</td></tr><tr><td align="left" valign="bottom">Dist &gt;median dist</td><td align="center" valign="bottom">–1.449</td><td align="center" valign="bottom">0.207</td><td align="center" valign="bottom">–0.818</td><td align="center" valign="bottom">0.251</td><td align="center" valign="bottom">0.529</td><td align="center" valign="bottom">0.123</td><td align="center" valign="bottom">0.348</td><td align="center" valign="bottom">0.745</td><td align="center" valign="bottom">80</td></tr></tbody></table></table-wrap><p>Our mixture model assumes that the spine volumes are independent when conditioned on the latent states. To visualize whether this assumption is justified by the data, <xref ref-type="fig" rid="fig4">Figure 4</xref> shows 1D projections of the joint distribution onto different axes. The projection onto the vertical axis (<xref ref-type="fig" rid="fig4">Figure 4b</xref>) is the marginal distribution, the overall size distribution for all synapses that belong to dual connections (same as <xref ref-type="fig" rid="fig3">Figure 3d</xref>). The projection onto the <italic>x</italic>=<italic>y</italic> diagonal (<xref ref-type="fig" rid="fig4">Figure 4c</xref>) is the distribution of the geometric mean of spine volume for each dual connection (same as <xref ref-type="fig" rid="fig3">Figure 3e</xref>). The projection onto the <italic>x</italic>=−<italic>y</italic> diagonal (<xref ref-type="fig" rid="fig4">Figure 4d</xref>) is the distribution of the ratio of spine volumes for each dual connection. For all three projections, the good fit suggests that the data are consistent with the mixture model’s assumption of isotropic normal distributions for the LL and SS states. (The <italic>x</italic>=<italic>y</italic> and vertical histograms look bimodal because they are different projections of the same two ‘bumps’ in the joint distribution. If the probability of the mixed state (LS/SL) were high, there would be two additional off-diagonal bumps in the joint distribution, and the <italic>x</italic>=<italic>y</italic> diagonal histogram would acquire another peak in the middle. In reality the probability of the mixed state is low, so the <italic>x</italic>=<italic>y</italic> diagonal histogram is well modeled by two mixture components. The widths of the bumps are the same in both projections, but the distance between the bumps is longer in the <italic>x</italic>=<italic>y</italic> diagonal histogram by a factor of root two. This explains why the mixture components are better separated in the distribution of geometric means (<xref ref-type="fig" rid="fig3">Figure 3e</xref>) than in the marginal distribution (<xref ref-type="fig" rid="fig3">Figure 3d</xref>), and hence why the statistical significance of bimodality is stronger for the geometric means.)</p><p>For a quantitative test of the isotropy assumption, we resampled observed spine volume pairs with weightings computed from the posterior probabilities of the SS and LL states (<xref ref-type="fig" rid="fig4">Figure 4g and h</xref>). If the model were consistent with the data, the resampled data would obey an isotropic normal distribution. Indeed, Pearson’s correlation for the resampled data is not significantly greater than zero (<xref ref-type="fig" rid="fig4">Figure 4g and h</xref>). Therefore, the spine volumes in a dual connection are approximately uncorrelated when conditioned on the latent states. We validated this result by examining the residual synapse sizes after subtracting the binary components and found no remaining correlation between then synapse pairs (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>).</p></sec><sec id="s2-5"><title>Specificity of latent state correlations</title><p>Could the observed correlations between synapses in dual connections be caused by crosstalk between plasticity of neighboring synapses (&lt;10 μm separation), which has been reported previously (<xref ref-type="bibr" rid="bib21">Harvey and Svoboda, 2007</xref>; <xref ref-type="bibr" rid="bib22">Harvey et al., 2008</xref>)? We looked for dependence of latent state correlations on separation by splitting dual connections into two groups, those with synapses nearer or farther than the median Euclidean distance in the volume of 46.5 μm. Both groups were fit by mixture models with positive correlations between latent variables (near: <italic>φ</italic> = 0.53, far: <italic>φ</italic> = 0.75, see Materials and methods, <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>). In other words, for dual connections involving pairs of distant synapses, the latent state correlations are still strong.</p><p>We also considered the possibility of correlations in pairs of synapses sharing the same presynaptic cell but not the same postsynaptic cell, or pairs of synapses sharing the same postsynaptic cell but not the same presynaptic cell (<xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Kasthuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Dvorkin and Ziv, 2016</xref>; <xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>). We randomly drew such synapse pairs from the set of synapses that belong to dual connections (and hence belong to PyCs that participate in dual connections). Correlations in the latent state or synapse size were negligible (same axon: <italic>φ</italic> = −0.11±0.08 SD, <italic>r</italic> = −0.06±0.06 SD; same dendrite: <italic>φ</italic> = −0.06±0.06 SD, <italic>r</italic> = −0.13±0.05 SD; <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>), similar to previous findings (<xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our synapse size correlations are specific to pairs of synapses that share both the same presynaptic and postsynaptic L2/3 PyCs, similar to previous findings (<xref ref-type="bibr" rid="bib75">Sorra and Harris, 1993</xref>; <xref ref-type="bibr" rid="bib36">Koester and Johnston, 2005</xref>; <xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Kasthuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Dvorkin and Ziv, 2016</xref>; <xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>). We have further demonstrated that the correlations exist even for large spatial separations between synapses. More importantly, we have shown the correlations are confined to the binary latent variables in our synapse size model; the log-normal analog variables exhibit little or no correlation.</p><p>The correlations in the binary variables could arise from a Hebbian or other synaptic plasticity rule driven by presynaptic and postsynaptic activity signals that are relatively uniform across neuronal arbors. Such signals are shared by synapses in a multisynaptic connection (<xref ref-type="bibr" rid="bib75">Sorra and Harris, 1993</xref>; <xref ref-type="bibr" rid="bib36">Koester and Johnston, 2005</xref>; <xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Kasthuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Dvorkin and Ziv, 2016</xref>; <xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>).</p><p>We speculate that much of the analog variation arises from the spontaneous dynamical fluctuations that have been observed at single dendritic spines through time-lapse imaging. Computational models of this temporal variance suggest that it can account for much of the population variance (<xref ref-type="bibr" rid="bib89">Yasumatsu et al., 2008</xref>; <xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>; <xref ref-type="bibr" rid="bib78">Statman et al., 2014</xref>). Experiments have shown that large dynamical fluctuations persist even after activity is pharmacologically blocked (<xref ref-type="bibr" rid="bib89">Yasumatsu et al., 2008</xref>; <xref ref-type="bibr" rid="bib78">Statman et al., 2014</xref>; <xref ref-type="bibr" rid="bib63">Sando et al., 2017</xref>; <xref ref-type="bibr" rid="bib70">Sigler, 2017</xref>). Another possibility is that the analog variation arises from plasticity driven by activity-related signals that are local to neighborhoods within neuronal arbors.</p><p>It remains unclear whether the binary latent variable in our model reflects some underlying bistable mechanism or is merely a convenient statistical description. Our latent variable model is consistent with the scenario in which synapses behave like binary switches that are flipped by activity-dependent plasticity. Switch-like behavior could arise from bistable networks of molecular interactions at synapses (<xref ref-type="bibr" rid="bib43">Lisman, 1985</xref>), has been observed in physiology experiments on synaptic plasticity (<xref ref-type="bibr" rid="bib57">Petersen et al., 1998</xref>; <xref ref-type="bibr" rid="bib54">O’Connor et al., 2005</xref>), and has been the basis of a number of computational models of memory (<xref ref-type="bibr" rid="bib80">Tsodyks, 1990</xref>; <xref ref-type="bibr" rid="bib1">Amit and Fusi, 1994</xref>; <xref ref-type="bibr" rid="bib19">Fusi et al., 2005</xref>). In this scenario, synapses only appear volatile due to fluctuations in the analog variable (<xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>), which obscures an underlying bistability.</p><p>In a second scenario, the bimodality of synapse size does not reflect an underlying bistability. For example, models of activity-dependent plasticity can cause synapses to partition into two clusters located at upper and lower bounds for synaptic size (<xref ref-type="bibr" rid="bib73">Song et al., 2000</xref>; <xref ref-type="bibr" rid="bib86">van Rossum et al., 2000</xref>; <xref ref-type="bibr" rid="bib61">Rubin et al., 2001</xref>). In this scenario, synapses are intrinsically volatile, and bimodality arises because learning drives them to extremes.</p><p>We would like to suggest that the first scenario of binary switches is somewhat more plausible, for two reasons. First, it is unclear how the second scenario could lead to strong correlations in the binary variable. Second, it is unclear how the second scenario could be consistent with the little or no correlation that remains in our data once the contribution from the binary latent variables is removed. This argument is tentative; more experimental and theoretical studies are needed to draw firmer conclusions.</p><p>Bimodality and strong correlations were found for a restricted ensemble of synapses, those belonging to dual connections between L2/3 PyCs. However, bimodality is not observed for the ensemble of all excitatory synapses onto L2/3 PyCs, including those from orphan axons (<xref ref-type="fig" rid="fig4s6">Figure 4—figure supplement 6</xref>). This ensemble is similar to ones studied previously, that is, synapses onto L2/3 PyCs (<xref ref-type="bibr" rid="bib2">Arellano, 2007</xref>), L4 neurons (<xref ref-type="bibr" rid="bib50">Motta et al., 2019</xref>), or L5 PyCs (<xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>). Bimodality and strong correlations are also not observed for the ensemble of all dual connections received by L2/3 PyCs, including those from orphan axons (<xref ref-type="fig" rid="fig4s6">Figure 4—figure supplement 6</xref>). Because our findings are based on a highly specific population of synapses, they are not inconsistent with previous studies that failed to find evidence for discreteness of cortical synapses (<xref ref-type="bibr" rid="bib20">Harris and Stevens, 1989</xref>; <xref ref-type="bibr" rid="bib2">Arellano, 2007</xref>; <xref ref-type="bibr" rid="bib44">Loewenstein et al., 2011</xref>; <xref ref-type="bibr" rid="bib45">Loewenstein et al., 2015</xref>; <xref ref-type="bibr" rid="bib15">de Vivo et al., 2017</xref>; <xref ref-type="bibr" rid="bib64">Santuy et al., 2018</xref>).</p><p>Why does the bimodality disappear when one includes dual connections with orphan axons? In our view, the simplest explanation is that this is due to the fact that orphan axons come from a mixed population of cell types, each one with its different distribution of synapse sizes. While each cell type to cell type connection might have its unique properties, they are lost to the observer when combining connections between different cell types together.</p><p>Bimodality and correlations may turn out to be heterogeneous across classes of neocortical synapses. Heterogeneity in the hippocampus has been demonstrated by the finding that dual connections onto granule cell dendrites in the middle molecular layer of dentate gyrus (<xref ref-type="bibr" rid="bib10">Bromer et al., 2018</xref>) do not exhibit the correlations that are found in stratum radiatum of CA1 (<xref ref-type="bibr" rid="bib3">Bartol et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Bloss et al., 2018</xref>).</p><p>Since the physiological strength of a multisynaptic connection can be approximately predicted from the sum of synaptic sizes (<xref ref-type="bibr" rid="bib24">Holler-Rickauer et al., 2019</xref>), our S and L latent states and their correlations have implications for the debate over whether infrequent strong connections play a disproportionate role in cortical computation (<xref ref-type="bibr" rid="bib74">Song et al., 2005</xref>; <xref ref-type="bibr" rid="bib13">Cossell et al., 2015</xref>; <xref ref-type="bibr" rid="bib68">Scholl, 2019</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Mouse</title><p>All procedures were in accordance with the Institutional Animal Care and Use Committees at the Baylor College of Medicine and the Allen Institute for Brain Science. Same sex littermates were housed together in individual cages with one to four mice per cage. Mice were maintained on a regular diurnal lighting cycle (12:12 light:dark) with ad libitum access to food and water and nesting material for environmental enrichment. Mice were housed in the Taub Mouse Facility of Baylor College of Medicine, accredited by AAALAC (The Association for Assessment and Accreditation of Laboratory Animal Care International). The animal used for this experiment was healthy and not involved in any previous procedure or experiment.</p></sec><sec id="s4-2"><title>Mouse line</title><p>Functional imaging was performed in a transgenic mouse expressing fluorescent GCaMP6f. For this dataset, the mouse we used was a triple heterozygote for the following three genes: (1) Cre driver: CamKIIa-Cre (Jax: 005359 <ext-link ext-link-type="uri" xlink:href="https://www.jax.org/strain/005359">https://www.jax.org/strain/005359</ext-link>), (2) tTA driver: B6;CBA-Tg(Camk2a-tTA)1Mmay/J (Jax: 003010 <ext-link ext-link-type="uri" xlink:href="https://www.jax.org/strain/003010">https://www.jax.org/strain/003010</ext-link>), (3) GCaMP6f Reporter: Ai93 (Allen Institute).</p></sec><sec id="s4-3"><title>Cranial window surgery</title><p>Anesthesia was induced with 3% isoflurane and maintained with 1.5–2% isoflurane during the surgical procedure. Mice were injected with 5–10 mg/kg ketoprofen subcutaneously at the start of the surgery. Anesthetized mice were placed in a stereotaxic head holder (Kopf Instruments) and their body temperature was maintained at 37°C throughout the surgery using a homeothermic blanket system (Harvard Instruments). After shaving the scalp, bupivicane (0.05 cc, 0.5%, Marcaine) was applied subcutaneously, and after 10–20 min an approximately 1 cm<sup>2</sup> area of skin was removed above the skull and the underlying fascia was scraped and removed. The wound margins were sealed with a thin layer of surgical glue (VetBond, 3 M), and a 13 mm stainless-steel washer clamped in the headbar was attached with dental cement (Dentsply Grip Cement). At this point, the mouse was removed from the stereotax and the skull was held stationary on a small platform by means of the newly attached headbar. Using a surgical drill and HP 1/2 burr, a 3 mm craniotomy was made centered on the primary visual cortex (V1; 2.7 mm lateral of the midline, contacting the lambda suture), and the exposed cortex was washed with ACSF (125 mM NaCl, 5 mM KCl, 10 mM glucose, 10 mM HEPES, 2 mM CaCl<sub>2</sub>, 2 mM MgSO<sub>4</sub>). The cortical window was then sealed with a 3 mm coverslip (Warner Instruments), using cyanoacrylate glue (VetBond). The mouse was allowed to recover for 1–2 hr prior to the imaging session. After imaging, the washer was released from the headbar and the mouse was returned to the home cage.</p></sec><sec id="s4-4"><title>Widefield imaging</title><p>Prior to two-photon imaging, we acquired a low-magnification image of the 3 mm craniotomy under standard illumination.</p></sec><sec id="s4-5"><title>Two-photon imaging</title><p>Imaging for candidate mice was performed in V1, in a 400 × 400 × 200 µm<sup>3</sup> volume with the superficial surface of the volume at the border of L1 and L2/3, approximately 100 µm below the pia. Laser excitation was at 920 nm at 25–45 mW depending on depth. The objective used was a 25× Nikon objective with a numerical aperture of 1.1, and the imaging point spread function was measured with 500 nm beads and was approximately 0.5 × 0.5 × 3 µm<sup>3</sup> in <italic>x</italic>, <italic>y</italic>, and <italic>z</italic>. Pixel dimensions of each imaging frame were 256×256.</p></sec><sec id="s4-6"><title>Tissue preparation and staining</title><p>The protocol of <xref ref-type="bibr" rid="bib27">Hua et al., 2015</xref>, was combined with the protocol of <xref ref-type="bibr" rid="bib79">Tapia et al., 2012</xref>, to accommodate a smaller tissue size and to improve TEM contrast. Mice were transcardially perfused with 2.5% paraformaldehyde and 1.25% glutaraldehyde. After dissection, 200 μm thick coronal slices were cut with a vibratome and post-fixed for 12–48 hr. Following several washes in CB (0.1 M cacodylate buffer pH 7.4), the slices were fixed with 2% osmium tetroxide in CB for 90 min, immersed in 2.5% potassium ferricyanide in CB for 90 min, washed with deionized (DI) water for 2× 30 min, and treated with freshly made and filtered 1% aqueous thiocarbohydrazide at 40°C for 10 min. The slices were washed 2× 30 min with DI water and treated again with 2% osmium tetroxide in water for 30 min. Double washes in DI water for 30 min each were followed by immersion in 1% aqueous uranyl acetate overnight at 4°C. The next morning, the slices in the same solution were placed in a heat block to raise the temperature to 50°C for 2 hr. The slices were washed twice in DI water for 30 min each, and then incubated in Walton’s lead aspartate pH 5.0 for 2 hr at 50°C in the heat block. After another double wash in DI water for 30 min each, the slices were dehydrated in an ascending ethanol series (50%, 70%, 90%, 100%×3) 10 min each and two transition fluid steps of 100% acetonitrile for 20 min each. Infiltration with acetonitrile:resin dilutions (2p:1p, 1p:1p and 2p:1p) were performed on a gyratory shaker overnight for 4 days. Slices were placed in 100% resin for 24 hr followed by embedding in Hard Plus resin (EMS, Hatfield, PA). Slices were cured in a 60°C oven for 96 hr. The best slice based on tissue quality and overlap with the 2p region was selected.</p></sec><sec id="s4-7"><title>Sectioning and collection</title><p>A Leica EM UC7 ultramicrotome and a Diatome 35-degree diamond ultra-knife were used for sectioning at a speed of 0.3 mm/s. Eight to ten serial sections were cut at 40 nm thickness to form a ribbon, after which the microtome thickness setting was set to 0 in order to release the ribbon from the knife. Using an eyelash probe, pairs of ribbons were collected onto copper grids covered by 50 nm thick LUXEL film.</p></sec><sec id="s4-8"><title>Transmission electron microscopy</title><p>We made several custom modifications to a JEOL-1200EXII 120 kV transmission electron microscope (<xref ref-type="bibr" rid="bib90">Yin et al., 2019</xref>). A column extension and scintillator magnified the nominal field of view by 10-fold with negligible loss of resolution. A high-resolution, large-format camera allowed fields of view as large as (13 µm)<sup>2</sup> at 3.58 nm resolution. Magnification reduced the electron density at the phosphor, so a high-sensitivity sCMOS camera was selected and the scintillator composition tuned to generate high-quality EM images with exposure times of 90–200 ms. Sections were acquired as a grid of 3840 × 3840 px images (‘tiles’) with 15% overlap.</p></sec><sec id="s4-9"><title>Alignment in two blocks</title><p>The dataset was divided by sections into two blocks (1216 and 970 sections), with the first block containing substantially more folds. Initial alignment and reconstruction tests proceeded on the second block of the dataset. After achieving satisfactory results, the first block was added, and the whole dataset was further aligned to produce the final 3D image. The alignment process included stitching (assembling all tiles into a single image per section), rough alignment (aligning the set of section images with one affine per section), coarse alignment (nonlinear alignment on lower resolution data), and fine alignment (nonlinear alignment on higher resolution data).</p></sec><sec id="s4-10"><title>Alignment, block one</title><p>The tiles of the first block were stitched into one montaged image per section and rough aligned using a set of customized and automated modules based on the ‘TrakEM2’ (<xref ref-type="bibr" rid="bib11">Cardona et al., 2012</xref>) and ‘Render’ (<xref ref-type="bibr" rid="bib93">Zheng et al., 2018</xref>) software packages.</p><sec id="s4-10-1"><title>Stitching</title><p>After acquisition, a multiplicative intensity correction based on average pixel intensity was applied to the images followed by a lens distortion of individual tiles using nonlinear transformations (<xref ref-type="bibr" rid="bib33">Kaynig et al., 2010</xref>). Once these corrections were applied, correspondences between tiles within a section were computed using SIFT features, and each tile was modeled with a rigid transform.</p></sec><sec id="s4-10-2"><title>Rough alignment</title><p>Using 20× downsampled stitched images, neighboring sections were roughly aligned (<xref ref-type="bibr" rid="bib62">Saalfeld et al., 2012</xref>). Correspondences were again computed using SIFT features, and each section was modeled with a regularized affine transform (90% affine+10% rigid), and all correspondences and constraints were used to generate the final model of one affine transform per tile. These models were used to render the final stitched section image into rough alignment with block two.</p></sec></sec><sec id="s4-11"><title>Alignment, block two</title><p>The second block was stitched and aligned using the methods of <xref ref-type="bibr" rid="bib62">Saalfeld et al., 2012</xref>, as implemented in Alembic (<xref ref-type="bibr" rid="bib46">Macrina and Ih, 2019</xref>).</p><sec id="s4-11-1"><title>Stitching</title><p>For each section, tiles containing tissue without clear image defects were contrast normalized by centering the intensities at the same location in each tile, stretching the overall distribution between the 5th and 95th intensity percentiles. During imaging, a 20× downsampled overview image of the section was also acquired. Each tile was first placed according to stage coordinates, approximately translated based on normalized cross-correlation (NCC) with the overview image, and then finely translated based on NCC with neighboring tiles. Block matching was performed in the regions of overlap between tiles using NCC with 140 px block radius, 400 px search radius, and a spacing of 200 px. Matches were manually inspected with 1× coverage, setting per-tile-pair thresholds for peak of match correlogram, distance between first and second peaks of match correlograms, and correlogram covariance, and less frequently, targeted match removal. A graphical user interface was developed to allow the operator to fine-tune parameters on a section-by-section basis, so that a skilled operator completed inspection in 40 hr. Each tile was modeled as a spring mesh, with nodes located at the center of each blockmatch operation, spring constants 1/100th of the constant for the between-tile springs, and the energy of all spring meshes within a section were minimized to a fractional tolerance of 10<sup>–8</sup> using nonlinear conjugate gradient. The final render used a piecewise affine model defined by the mesh before and after relaxation, and maximum intensity blending.</p></sec><sec id="s4-11-2"><title>Rough alignment</title><p>Using 20× downsampled images, block matching between neighboring sections proceeded using NCC with 50 px block radius, 125 px search radius, and 250 px spacing. Matches were computed between nearest neighbor section pairs, then filtered manually in 8 hr. Correspondences were used to develop a regularized affine model per section (90% affine+10% rigid), which was rendered at full image resolution.</p></sec><sec id="s4-11-3"><title>Coarse alignment</title><p>Using 4× downsampled images, NCC-based block matching proceeded 300 px block radius, 200 px search radius, and 500 px spacing. Matches were computed between nearest and next-nearest section pairs, then manually filtered by a skilled operator in 24 hr. Each section was modeled as a spring mesh with spring constants 1/10th of the constant for the between-section springs, and the energy of all spring meshes within the block were minimized to a fractional tolerance of 10<sup>–8</sup> using nonlinear conjugate gradient. The final render used a piecewise affine model defined by the mesh.</p></sec><sec id="s4-11-4"><title>Fine alignment</title><p>Using 2× downsampled images, NCC-based block matching proceeded 200 px block radius, 113 px search radius, and 100 px spacing. Matches were computed between nearest and next-nearest section pairs, then manually filtered by a skilled operator in 24 hr. Modeling and rendering proceeded as with coarse alignment, using spring constants were 1/20th of the constant for the between-section springs.</p></sec></sec><sec id="s4-12"><title>Alignment, whole dataset</title><p>Blank sections were inserted manually between sections where the cutting thickness appeared larger than normal (11). The alignment of the whole dataset was further refined using the methods of <xref ref-type="bibr" rid="bib62">Saalfeld et al., 2012</xref>, as implemented in Alembic (<xref ref-type="bibr" rid="bib46">Macrina and Ih, 2019</xref>).</p><sec id="s4-12-1"><title>Coarse alignment</title><p>Using 64× downsampled images, NCC-based block matching proceeded 128 px block radius, 512 px search radius, and 128 px spacing. Matches were computed between neighboring and next-nearest neighboring sections, as well as 24 manually identified section pairs with greater separation, then manually inspected in 70 hr. Section spring meshes had spring constants 1/20th of the constant for the between-section springs. Mesh relaxation was completed in blocks of 15 sections, 5 of which were overlapping with the previous block (2 sections fixed), each block relaxing to a fractional tolerance of 10<sup>–8</sup>. Rendering proceeded similarly as before.</p></sec><sec id="s4-12-2"><title>Fine alignment</title><p>Using 4× downsampled images, NCC-based block matching proceeded 128 px block radius, 512 px search radius, and 128 px spacing. Matches were computed between the same section pairs as in coarse alignment. Matches were excluded only by heuristics. Modeling and rendering proceeded similar to coarse alignment, with spring constants 1/100th the constant for the between-section springs. Rendered image intensities were linearly rescaled in each section based on the 5th and 95th percentile pixel values.</p></sec></sec><sec id="s4-13"><title>Image volume estimation</title><p>The imaged tissue has a trapezoidal shape in the sectioning plane. Landmark points were placed in the aligned images to measure this shape. We report cuboid dimensions for simplicity and comparison using the trapezoid midsegment length. The original trapezoid has a short base length of 216.9 μm, long base length of 286.2 μm, and height 138.3 μm. The imaged data has 2176 sections, which measures 87.04 μm with a 40 nm slice thickness.</p></sec><sec id="s4-14"><title>Image defect handling</title><p>Cracks, folds, and contaminants were manually annotated as binary masks on 256× downsampled images, dilated by 2 px, then inverted to form a defect mask. A tissue mask was created using nonzero pixels in the 256× downsampled image, then eroded by 2 px to exclude misalignments at the edge of the image. The image mask is the union of the tissue and defect masks, and it was upsampled and applied during the final render to set pixels not included in the mask to zero. We created a segmentation mask by excluding voxels that had been excluded by the image mask for three consecutive sections. The segmentation mask was applied after affinity prediction to set affinities not included in the mask to zero.</p></sec><sec id="s4-15"><title>Affinity prediction</title><p>Human experts used VAST (<xref ref-type="bibr" rid="bib5">Berger et al., 2018</xref>) to manually segment multiple subvolumes from the current dataset and a similar dataset from mouse V1. Annotated voxels totaled 1.29 billion at full image resolution.</p><p>We trained a 3D convolutional network to generate 3 nearest neighbor (<xref ref-type="bibr" rid="bib81">Turaga et al., 2010</xref>) and 13 long-range affinity maps (<xref ref-type="bibr" rid="bib40">Lee, 2017</xref>). Each long-range affinity map was constructed by comparing an equivalence relation (<xref ref-type="bibr" rid="bib29">Jain et al., 2010</xref>) of pairs of voxels spanned by an ‘offset’ edge (to preceding voxels at distances of 4, 8, 12, and 16 in <italic>x</italic> and <italic>y</italic>, and 2, 3, 4 in <italic>z</italic>). Only the nearest neighbor affinities were used beyond inference time; long-range affinities were used solely for training. The network architecture was modified from the ‘Residual Symmetric U-Net’ of <xref ref-type="bibr" rid="bib40">Lee, 2017</xref>. We trained on input patches of size 128 × 128 × 20 at 7.16 × 7.16 × 40 nm<sup>3</sup> resolution. The prediction during training was bilinearly upsampled to full image resolution before calculating the loss.</p><p>Training utilized synchronous gradient updates computed by four Nvidia Titan X Pascal GPUs each with a different input patch. We used the AMSGrad variant (<xref ref-type="bibr" rid="bib59">Reddi et al., 2019</xref>) of the Adam optimizer (<xref ref-type="bibr" rid="bib34">Kingma and Ba, 2014</xref>), with PyTorch’s default settings except step size parameter <italic>α</italic>=0.001. We used the binary cross-entropy loss with ‘inverse margin’ of 0.1 <xref ref-type="bibr" rid="bib28">Huang and Jain, 2013</xref>; patch-wise class rebalancing (<xref ref-type="bibr" rid="bib40">Lee, 2017</xref>) to compensate for the lower frequency of boundary voxels; training data augmentation including flip/rotate by 90 degrees, brightness and contrast perturbations, warping distortions, misalignment/missing section simulation, and out-of-focus simulation (<xref ref-type="bibr" rid="bib40">Lee, 2017</xref>); and lastly several new types of data augmentation including the simulation of lost section and co-occurrence of misalignment/missing/lost section.</p><p>Distributed computation of affinity maps used chunkflow (<xref ref-type="bibr" rid="bib88">Wu et al., 2019</xref>). The computation was done with images at 7.16 × 7.16 × 40 nm<sup>3</sup> resolution. The whole volume was divided into 1280 × 1280 × 140 chunks overlapping by 128 × 128 × 10, and each chunk was processed as a task. The tasks were injected into a queue (Amazon Web Service Simple Queue Service). For 2.5 days, 1000 workers (Google Cloud n1-highmem-4 with 4 vCPUs and 26 GB RAM, deployed in Docker image using Kubernetes) fetched and executed tasks from the queue as follows. The worker read the corresponding chunk from Google Cloud Storage using CloudVolume (<xref ref-type="bibr" rid="bib71">Silversmith et al., 2021</xref>), and applied previously computed masks to black out regions with image defects. The chunk was divided into 256 × 256 × 20 patches with 50% overlap. Each patch was processed to yield an affinity map using PZNet, a CPU inference framework (<xref ref-type="bibr" rid="bib58">Popovych, 2020</xref>). The overlapping output patches were multiplied by a bump function, which weights the voxels according to the distance from patch center, for smooth blending and then summed. The result was cropped to 1024 × 1024 × 120 vx and then previously computed segmentation masks were applied (see Image defect handling above).</p></sec><sec id="s4-16"><title>Watershed and size-dependent single linkage clustering</title><p>The affinity map was divided into 514 × 514 × 130 chunks that overlapped by 2 voxels in each direction. For each chunk we ran a watershed and clustering algorithm (<xref ref-type="bibr" rid="bib94">Zlateski and Seung, 2015</xref>) with special handling of chunk boundaries. If the descending flow of watershed terminated prematurely at a chunk boundary, the voxels around the boundary were saved to disk so that domain construction could be completed later on. Decisions about merging boundary domains were delayed, and information was written to disk so decisions could be made later. After the chunks were individually processed, they were stitched together in a hierarchical fashion. Each level of the hierarchy processed the previously delayed domain construction and clustering decisions in chunk interiors. Upon reaching the top of the hierarchy, the chunk encompassed the entire volume, and all previously delayed decisions were completed.</p></sec><sec id="s4-17"><title>Mean affinity agglomeration</title><p>The watershed supervoxels and affinity map were divided into 513 × 513 × 129 chunks that overlapped by 1 in each direction. Each chunk was processed using mean affinity agglomeration (<xref ref-type="bibr" rid="bib40">Lee, 2017</xref>; <xref ref-type="bibr" rid="bib18">Funke et al., 2019</xref>). Agglomeration decisions at chunk boundaries were delayed, and information about the decisions was saved to disk. After the chunks were individually processed, they were combined in a hierarchical fashion similar to the watershed process.</p></sec><sec id="s4-18"><title>Training with data augmentations</title><p>We performed preliminary experiments on the effect of training data augmentation by simulating image defects on the publicly available SNEMI3D challenge dataset (<ext-link ext-link-type="uri" xlink:href="http://brainiac2.mit.edu/SNEMI3D">http://brainiac2.mit.edu/SNEMI3D</ext-link>). We partitioned the SNEMI3D training volume of 1024 × 1024 × 100 voxels into the center crop of 512 × 512 × 100 voxels for validation, and the rest for training. Then we trained three convolutional nets to detect neuronal boundaries, one without any data augmentation (‘baseline’), and the other two with simulated missing section (‘missing section’) and simulated misalignment (‘misalignment’) data augmentation, respectively. After training the three nets, we measured the robustness of each net to varying degrees of simulated image defects on the validation set (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). In the first measurement, we simulated a misalignment at the middle of the validation volume with varying numbers of pixel displacement. In the second measurement, we introduced varying numbers of consecutive missing sections at the middle of the validation volume. For each configuration of simulation, we ran an inference pipeline with the three nets to produce respective segmentations, and computed the variation of information error metric to measure the quality of the segmentations. For the measurement against simulated misalignment, we applied connected components to recompute the ground truth segmentation after introducing a misalignment, such that we separated a single object into two distinct objects if the object is completely broken by the misalignment (e.g. the displacement of misalignment larger than the diameter of neurite).</p></sec><sec id="s4-19"><title>Synaptic cleft detection</title><p>Synaptic clefts were annotated by human annotators within a 310.7 μm<sup>3</sup> volume, which was split into 203.2 μm<sup>3</sup> training, 53.7 μm<sup>3</sup> validation, and 53.7 μm<sup>3</sup> test sets. We trained a version of the Residual Symmetric U-Net (<xref ref-type="bibr" rid="bib40">Lee, 2017</xref>) with 3 downsampling levels instead of 4, 90 feature maps at the third downsampling instead of 64, and ‘resize’ upsampling rather than strided transposed convolution. Images and labels were downsampled to 7.16 × 7.16 × 40 nm<sup>3</sup> image resolution. To augment the training data, input patches were transformed by (1) introducing misalignments of up to 17 pixels, (2) blacking out up to five sections, (3) blurring up to five sections, (4) warping, (5) varying brightness and contrast, and (6) flipping and rotating by multiples of 90 degrees. Training used PyTorch (<xref ref-type="bibr" rid="bib55">Paszke et al., 2017</xref>) and the Adam optimizer (<xref ref-type="bibr" rid="bib34">Kingma and Ba, 2014</xref>). The learning rate started from 10<sup>−3</sup>, and was manually annealed three times (505k training updates), before adding 67.2 μm<sup>3</sup> of extra training data for another 670k updates. The extra training data focused on false positive examples from the network’s predictions at 505k training updates, mostly around blood vessels. The trained network achieved 93.0% precision and 90.9% recall in detecting clefts of the test set. This network was applied to the entire dataset using the same distributed inference setup as affinity map inference. Connected components of the thresholded network output that were at least 50 voxels at 7.16 × 7.16 × 40 nm<sup>3</sup> resolution were retained as predicted synaptic clefts.</p></sec><sec id="s4-20"><title>Synaptic partner assignment</title><p>Presynaptic and postsynaptic partners were annotated for 387 clefts, which were split into 196, 100, and 91 examples for training, validation, and test sets. A network was trained to perform synaptic partner assignment via a voxel association task (<xref ref-type="bibr" rid="bib82">Turner et al., 2020</xref>). Architecture and augmentations were the same as for the synaptic cleft detector. Test set accuracy was 98.9% after 710k training iterations. The volume was separated into non-overlapping chunks of size 7.33 × 7.33 × 42.7 μm<sup>3</sup> (1024 × 1024 × 1068 voxels), and the net was applied to each cleft in each chunk. This yielded a single prediction for interior clefts. For a cleft that crossed at least one boundary, we chose the prediction from the chunk which contained the most voxels of that cleft. Cleft predictions were merged if they connected the same synaptic partners and their centers-of-mass were within 1 μm. This resulted in 3,556,643 final cleft predictions.</p></sec><sec id="s4-21"><title>PyC proofreading</title><p>The mean affinity graph of watershed supervoxels was stored in our PyChunkedGraph backend, which uses an octree to provide spatial embedding for fast updates of the connected component sets from local edits. We modified the Neuroglancer frontend (<xref ref-type="bibr" rid="bib47">Maitin-Shepard et al., 2019</xref>) to interface with this backend so users directly edit the agglomerations by adding and removing edges in the supervoxel graph (merge and split agglomerations). Connected components of this graph are meshed in chunks of supervoxels, and chunks affected by edits are updated in real time so users can always see a 3D representation of the current segmentation. Using a keypoint for each object (e.g. soma centroid), objects are assigned the unique ID of the connected component for the supervoxel which contains that location. This provides a means to update the object’s ID as edits are made.</p><p>Cell bodies in the EM volume were semi-automatically identified. PyCs were identified by morphological features, including density of dendritic spines, presence of apical and basal dendrites, direction of main axon trunk, and cell body shape. We selected a subset of the 417 PyCs for proofreading based on the amount of visible neurite within the volume. A team of annotators used the meshes to detect errors in dendritic trunks and axonal arbors, then to correct those errors with 50,000 manual edits in 1044 person-hours. After these edits, PyCs were skeletonized, and both the branch and end points of these skeletons were identified automatically (with false negative rates of 1.7% and 1.4%, as estimated by annotators). Human annotators reviewed each point to ensure no merge errors and extend split errors where possible (210 person-hours). Putative broken spines targeted by PyCs were identified by selecting objects that received one or two synapses. Annotators reviewed, and attached these with 174 edits in 24 person-hours. Some difficult mergers came from small axonal boutons merged to dendrites. We identified these cases by inspecting any predicted presynaptic site that resided within 7.5 μm of a postsynaptic site of the same cell, and corrected them with 50 person-hours.</p></sec><sec id="s4-22"><title>Estimation of final error rates</title><p>After proofreading was complete, a single annotator inspected 12 PyCs and spent 18 hr to identify all remaining errors in dendritic trunks and axonal arbors. The PyC proofreading protocol was designed to correct all merge errors, though not necessarily correct split errors caused by a masked segmentation. So this error estimation includes all merge errors identified and only split errors caused by less than three consecutive sections of masked segmentation. For 18.7 mm of dendritic path length inspected, three false splits (falsely excluding 160 synapses) and three false merges (falsely including 117 synapses) were identified (99% precision and 99% recall for incoming synapses). For 3.6 mm of axonal path length inspected, two false splits (falsely excluding four synapses) and one false merge (falsely including nine synapses) were identified (98% precision and 99% recall for outgoing synapses). We also sampled four dendritic branches with a collective 0.7 mm of path length, and identified 126 false negative and 0 false positive spines (88% recall of spines).</p></sec><sec id="s4-23"><title>PyC-PyC synapse proofreading</title><p>Synapses between PyC were extracted from the automatically detected and assigned synapses. We reviewed these synapses manually with 2× redundancy (1972 correct synapses out of 2433 putative synapses). Two predicted synapses out of these were ‘merged’ with other synaptic clefts. These cases were excluded from further analysis. One synapse was incorrectly assigned to a PyC and removed from the analysis. One other synapse was ‘split’ into two predictions, and these predictions were merged for analysis. We were not able to calculate spine head volumes for 8 out of these 1968 synapses and they were excluded from the analysis. This left 1960 synapses admitted into the analysis.</p></sec><sec id="s4-24"><title>Synapses from other excitatory axons</title><p>We randomly sampled synapses onto the PyCs and evaluated whether they are excitatory or inhibitory based on their shape, appearance, and targeted compartment (<italic>n</italic>=881 single excitatory synapses). We randomly sampled connections of two synapses onto PyCs and evaluated whether their presynaptic axon is excitatory or inhibitory and checked for reconstruction errors. Here, we manually checked that the automatically reconstructed path between the two synapses along the 3D mesh of the axon was error free (<italic>n</italic>=446 pairs of excitatory synapses). Those axons were allowed to contain errors elsewhere and we did not proofread any axons to obtain these pairs.</p></sec><sec id="s4-25"><title>Dendritic spine heads</title><p>We extracted a 7.33 × 7.33 × 4 μm<sup>3</sup> cutout around the centroid of each synapse. The postsynaptic segment within that cutout was skeletonized using kimimaro (<ext-link ext-link-type="uri" xlink:href="https://github.com/seung-lab/kimimaro">https://github.com/seung-lab/kimimaro</ext-link>; <xref ref-type="bibr" rid="bib72">Silversmith and Wu, 2022</xref>), yielding a set of paths traveling from a root node to each leaf. The root node was defined as the node furthest from the synapse coordinate. Skeleton nodes participating in fewer than three paths were labeled as ‘spine’ while others were labeled as ‘shaft’. The shaft labels were dilated along the skeleton until either (1) the distance to the segment boundary of the next node was more than 50 nm less than that of the closest (shaft) branch point, or (2) dilation went 200 nodes beyond the branch point. Each synapse was associated with its closest skeleton node, and a contiguous set of ‘spine’ labeled nodes. We finally separated spine head from neck by analyzing the distance to the segment boundary (DB) moving from the root of the spine to the tip. After segmenting the spine from the rest of the segment, we chose two anchor points: (1) the point with minimum DB value across the half of the spine toward the dendritic shaft and (2) the point with maximum DB value across the other half. A cut point was defined as the first skeleton node moving from anchor 1 to anchor 2 whose DB value was greater than ⅓ DB<sub>anchor1</sub> + ⅔ DB<sub>anchor2</sub>. Accounting for slight fluctuations in the DB value, we started the scan for the cut point at the closest node to anchor 2 that had DB value less than ⅕ DB<sub>anchor1</sub> + ⅘ DB<sub>anchor2</sub>. The skeleton of the spine head was defined as the nodes beyond this cut point to a leaf node, and the spine head mesh was defined as all spine mesh vertices which were closest to the spine head skeleton. The mesh of each head was identified as the subset of the postsynaptic segment mesh whose closest skeleton node was contained within the nodes labeled as spine head. We then estimated the volume of this spine head by computationally sealing this mesh and computing its volume.</p><p>We identified poor extractions by computing the distance between each synapse centroid and the nearest node of its inferred spine head mesh. We inspected each inferred spine head for which this distance was greater than 35 nm, and corrected the mesh estimates of mistakes by relabeling mesh vertices using a 3D voronoi tessellation of points placed by a human annotator.</p></sec><sec id="s4-26"><title>Endoplasmic reticulum</title><p>We manually evaluated all spine heads between PyCs admitted to the analysis for whether they contained an SA, ER that is not an SA (ER), or none (no ER). We required the presence of at least two (usually parallel) membrane saccules for SA. Dense plate/region (synaptopodin and actin) in-between membrane saccules was an indicator. We found SA in spine heads and spine necks. We considered single lumens of organelles connecting to the ER network in the shaft as ER. We required that every ER could be traced back to the ER network in the dendritic shaft.</p></sec><sec id="s4-27"><title>Mixture models</title><p>Spine volumes and synapse sizes were log<sub>10</sub>-transformed before statistical modeling. Maximum likelihood estimation for a binary mixture of normal distributions used the expectation-maximization algorithm as implemented by Pomegranate (<xref ref-type="bibr" rid="bib69">Schreiber, 2017</xref>). The algorithm was initialized using the k-means algorithm with the number of clusters set to equal the number of mixture components. For cleft size, the normal distributions were truncated at a lower bound of log<sub>10</sub>(50) voxels, the same cutoff used in cleft detection. The truncation was implemented by modifications to the source code of Pomegranate. In this mixture model, each fitted distribution is parameterized with a mean, standard deviation, and weight per mixture component. In the case of two components we also refer to the weights as S and L state fractions. We used the square root of the estimated counts as errors on the fitted distributions (<xref ref-type="fig" rid="fig3">Figure 3c, d and e</xref>). To estimate errors on the state weights, we bootstrapped the population of synapses and reported the standard deviation of the fitted weights.</p></sec><sec id="s4-28"><title>Hidden Markov models</title><p>The joint distribution at dual connections was fitted by hidden Markov models (HMMs) with two latent states and emission probabilities given by normal distributions as described in the previous section. In total this resulted in four state probabilities (SS, SL, LS, LL). HMMs are trained on ordered pairs. Because there is no inherent order of the synapse pair from dual connections, we included each synapse pair twice in the dataset, one for each order.</p></sec><sec id="s4-29"><title>Correlation analysis</title><p>We assigned state probabilities to each dual synaptic pair using the best fit HMM. The following was done for SS and LL states independently. In each sampling iteration (<italic>n</italic>=10,000) we assigned individual synapse pairs to the state in question based on independent biased coin flips weighted by their respective state probability. For every such obtained sample we computed the Pearson’s correlation of the sampled population of synapses (<xref ref-type="fig" rid="fig4">Figure 4g and h</xref>). For visualization in <xref ref-type="fig" rid="fig4">Figure 4g and h</xref> we applied a kernel density estimation (bw = 0.15 in log<sub>10</sub>-space).</p></sec><sec id="s4-30"><title>Parametric test for bimodality</title><p>For binary mixtures of normal distributions, the parameter regimes for bimodal and unimodal behaviors are known (<xref ref-type="bibr" rid="bib60">Robertson and Fryer, 1969</xref>). The likelihood ratio of the best-fitting bimodal and unimodal models can be used for model selection (<xref ref-type="bibr" rid="bib26">Holzmann and Vollmer, 2008</xref>). Mixture models were fit using Sequential Least Squares Programming using constraints on the parameter regimes for unimodal fits. We computed p-values using Chernoff’s extension to boundary points of hypothesis sets (<xref ref-type="bibr" rid="bib12">Chernoff, 1954</xref>) of Wilks’ theorem governing asymptotics of the likelihood ratio (<xref ref-type="bibr" rid="bib87">Wilks, 1938</xref>).</p></sec><sec id="s4-31"><title>Skeletonization</title><p>We developed a skeletonization algorithm similar to <xref ref-type="bibr" rid="bib65">Sato et al., 2000</xref>, that operates on meshes. For each connected component of the mesh graph, we identify a root and find the shortest path to the farthest node. This procedure is repeated after invalidating all mesh nodes within the proximity of the visited nodes until no nodes are left to visit. We make our implementation available through our package MeshParty (<ext-link ext-link-type="uri" xlink:href="https://github.com/sdorkenw/MeshParty">https://github.com/sdorkenw/MeshParty</ext-link>; <xref ref-type="bibr" rid="bib16">Dorkenwald et al., 2020</xref>).</p></sec><sec id="s4-32"><title>Estimation of path lengths</title><p>We skeletonized all PyCs and labeled their first branch points close to the soma according to the compartment type of the downstream branches (axon, dendrite, ambiguous). If no branch point existed in close proximity a point at similar distance was placed. All skeleton nodes downstream from these nodes seen from the soma were labeled according to these labels. This allowed us to estimate path lengths for each compartment with the path up to the first branch point labeled as perisomatic (axon: 100 mm, dendrite: 520 mm, perisomatic: 40 mm, ambiguous: 10 mm). We estimated that our skeletons were overestimated by 11% due to following the mesh edges and corrected all reported pathlengths accordingly.</p></sec><sec id="s4-33"><title>Code availability</title><p>All software is open source and available at <ext-link ext-link-type="uri" xlink:href="http://github.com/seung-lab">http://github.com/seung-lab</ext-link> if not otherwise mentioned.</p><list list-type="simple"><list-item><p>Alembic: Stitching and alignment.</p></list-item><list-item><p>CloudVolume: Reading and writing volumetric data, meshes, and skeletons to and from the cloud.</p></list-item><list-item><p>Chunkflow: Running convolutional nets on large datasets.</p></list-item><list-item><p>DeepEM: Training convolutional nets to detect neuronal boundaries.</p></list-item><list-item><p>CAVE: Proofreading and connectome updates (visit <ext-link ext-link-type="uri" xlink:href="https://github.com/seung-lab/AnnotationPipelineOverview">https://github.com/seung-lab/AnnotationPipelineOverview</ext-link> for repository list).</p></list-item><list-item><p>Igneous: Coordinating downsampling, meshing, and data management.</p></list-item><list-item><p>MeshParty: Interaction with meshes and mesh-based skeletonization (<ext-link ext-link-type="uri" xlink:href="https://github.com/sdorkenw/MeshParty">https://github.com/sdorkenw/MeshParty</ext-link>, <xref ref-type="bibr" rid="bib16">Dorkenwald et al., 2020</xref>).</p></list-item><list-item><p>MMAAPP: Watershed, size-dependent single linkage clustering, and mean affinity agglomeration.</p></list-item><list-item><p>PyTorchUtils: Training convolutional nets for synapse detection and partner assignment (<ext-link ext-link-type="uri" xlink:href="https://github.com/nicholasturner1/PyTorchUtils">https://github.com/nicholasturner1/PyTorchUtils</ext-link>, <xref ref-type="bibr" rid="bib83">Turner, 2021</xref>).</p></list-item><list-item><p>Synaptor: Processing output of the convolutional net for predicting synaptic clefts (<ext-link ext-link-type="uri" xlink:href="https://github.com/nicholasturner1/Synaptor">https://github.com/nicholasturner1/Synaptor</ext-link>, <xref ref-type="bibr" rid="bib84">Turner et al., 2021</xref>).</p></list-item><list-item><p>TinyBrain and zmesh: Downsampling and meshing (precursors of the libraries that were used).</p></list-item></list></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf3"><p>discloses financial interests in Zetta AI LLC</p></fn><fn fn-type="COI-statement" id="conf4"><p>discloses financial interests in Vathes LLC</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Software, Supervision, Investigation, Methodology, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Software, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Data curation, Software</p></fn><fn fn-type="con" id="con6"><p>Data curation, Software</p></fn><fn fn-type="con" id="con7"><p>Data curation</p></fn><fn fn-type="con" id="con8"><p>Data curation</p></fn><fn fn-type="con" id="con9"><p>Data curation</p></fn><fn fn-type="con" id="con10"><p>Data curation, Software, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Data curation, Software</p></fn><fn fn-type="con" id="con12"><p>Data curation, Software</p></fn><fn fn-type="con" id="con13"><p>Software</p></fn><fn fn-type="con" id="con14"><p>Software</p></fn><fn fn-type="con" id="con15"><p>Software</p></fn><fn fn-type="con" id="con16"><p>Data curation, Supervision</p></fn><fn fn-type="con" id="con17"><p>Data curation, Software</p></fn><fn fn-type="con" id="con18"><p>Software</p></fn><fn fn-type="con" id="con19"><p>Software</p></fn><fn fn-type="con" id="con20"><p>Software</p></fn><fn fn-type="con" id="con21"><p>Supervision</p></fn><fn fn-type="con" id="con22"><p>Data curation</p></fn><fn fn-type="con" id="con23"><p>Data curation</p></fn><fn fn-type="con" id="con24"><p>Data curation, Writing – review and editing</p></fn><fn fn-type="con" id="con25"><p>Data curation, Software</p></fn><fn fn-type="con" id="con26"><p>Data curation, Software</p></fn><fn fn-type="con" id="con27"><p>Data curation, Software, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con28"><p>Data curation, Software, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con29"><p>Data curation</p></fn><fn fn-type="con" id="con30"><p>Data curation, Software</p></fn><fn fn-type="con" id="con31"><p>Project administration</p></fn><fn fn-type="con" id="con32"><p>Project administration</p></fn><fn fn-type="con" id="con33"><p>Supervision, Funding acquisition, Project administration</p></fn><fn fn-type="con" id="con34"><p>Supervision, Funding acquisition, Project administration</p></fn><fn fn-type="con" id="con35"><p>Data curation, Supervision, Funding acquisition, Investigation, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con36"><p>Supervision, Funding acquisition, Investigation, Project administration</p></fn><fn fn-type="con" id="con37"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal procedures were approved by the Institutional Animal Care and Use Committee at the Allen Institute for Brain Science (1503 and 1804) or Baylor College of Medicine (AN-4703).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-76120-transrepform1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data acquired and produced for this project are available on <ext-link ext-link-type="uri" xlink:href="https://www.microns-explorer.org/phase1">https://www.microns-explorer.org/phase1</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>L</given-names></name><name><surname>Bleckert</surname><given-names>AL</given-names></name><name><surname>Brittain</surname><given-names>D</given-names></name><name><surname>Buchanan</surname><given-names>J</given-names></name><name><surname>Bumbarger</surname><given-names>DJ</given-names></name><name><surname>Castro</surname><given-names>M</given-names></name><name><surname>Cobos</surname><given-names>E</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name><name><surname>Elabbady</surname><given-names>L</given-names></name><name><surname>Dorkenwald</surname><given-names>S</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Ih</surname><given-names>D</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Jordan</surname><given-names>CS</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>R</given-names></name><name><surname>MaçaricodaCosta</surname><given-names>N</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Mahalingam</surname><given-names>G</given-names></name><name><surname>Mu</surname><given-names>S</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Polleux</surname><given-names>F</given-names></name><name><surname>Popovych</surname><given-names>S</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Seung</surname><given-names>SH</given-names></name><name><surname>Schneider-Mizell</surname><given-names>C</given-names></name><name><surname>Silversmith</surname><given-names>W</given-names></name><name><surname>Suckow</surname><given-names>S</given-names></name><name><surname>Takeno</surname><given-names>M</given-names></name><name><surname>Turner</surname><given-names>NL</given-names></name><name><surname>Tartavull</surname><given-names>I</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name><name><surname>Torres</surname><given-names>R</given-names></name><name><surname>Wilson</surname><given-names>AM</given-names></name><name><surname>Wong</surname><given-names>W</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Yang</surname><given-names>R</given-names></name><name><surname>S-C</surname><given-names>Yu</given-names></name><name><surname>Zhou</surname><given-names>P</given-names></name><name><surname>Zlateski</surname><given-names>A</given-names></name><name><surname>Zung</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>MICrONS Layer 2/3 Data Tables</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.5579388</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>Supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DoI/IBC) contract numbers D16PC00003, D16PC00004, and D16PC0005. The US Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. HSS also acknowledges support from NIH/NINDS U19 NS104648, ARO W911NF-12-1-0594, NIH/NEI R01 EY027036, NIH/NIMH U01 MH114824, NIH/NINDS R01NS104926, NIH/NIMH RF1MH117815, and the Mathers Foundation, as well as assistance from Google, Amazon, and Intel. We thank S Koolman, M Moore, S Morejohn, B Silverman, K Willie, and R Willie for their image analyses, Garrett McGrath for computer system administration, and May Husseini and Larry and Janet Jackel for project administration. We are grateful to J Maitin-Shepard for neuroglancer and PH Li and V Jain for helpful discussions. We thank DW Tank, K Li, Y Loewenstein, J Kornfeld, A Wanner, M Tsodyks, D Markowitz, and G Ocker for advice and feedback. We thank the Allen Institute for Brain Science founder, Paul G Allen, for his vision, encouragement, and support. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/IBC, or the US Government.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amit</surname><given-names>DJ</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Learning in neural networks with material synapses</article-title><source>Neural Computation</source><volume>6</volume><fpage>957</fpage><lpage>982</lpage><pub-id pub-id-type="doi">10.1162/neco.1994.6.5.957</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arellano</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Ultrastructure of dendritic spines: correlation between synaptic and spine morphologies</article-title><source>Front Neurosci Medline</source><volume>1</volume><fpage>131</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.3389/neuro.01.1.1.010.2007</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartol</surname><given-names>TM</given-names></name><name><surname>Bromer</surname><given-names>C</given-names></name><name><surname>Kinney</surname><given-names>J</given-names></name><name><surname>Chirillo</surname><given-names>MA</given-names></name><name><surname>Bourne</surname><given-names>JN</given-names></name><name><surname>Harris</surname><given-names>KM</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Nanoconnectomic upper bound on the variability of synaptic plasticity</article-title><source>eLife</source><volume>4</volume><elocation-id>e10778</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10778</pub-id><pub-id pub-id-type="pmid">26618907</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beier</surname><given-names>T</given-names></name><name><surname>Pape</surname><given-names>C</given-names></name><name><surname>Rahaman</surname><given-names>N</given-names></name><name><surname>Prange</surname><given-names>T</given-names></name><name><surname>Berg</surname><given-names>S</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Knott</surname><given-names>GW</given-names></name><name><surname>Plaza</surname><given-names>SM</given-names></name><name><surname>Scheffer</surname><given-names>LK</given-names></name><name><surname>Koethe</surname><given-names>U</given-names></name><name><surname>Kreshuk</surname><given-names>A</given-names></name><name><surname>Hamprecht</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Multicut brings automated neurite segmentation closer to human performance</article-title><source>Nature Methods</source><volume>14</volume><fpage>101</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4151</pub-id><pub-id pub-id-type="pmid">28139671</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname><given-names>DR</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vast (volume annotation and segmentation tool): efficient manual and semi-automatic labeling of large 3D image stacks</article-title><source>Frontiers in Neural Circuits</source><volume>12</volume><elocation-id>88</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2018.00088</pub-id><pub-id pub-id-type="pmid">30386216</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhatt</surname><given-names>DH</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Gan</surname><given-names>WB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dendritic spine dynamics</article-title><source>Annual Review of Physiology</source><volume>71</volume><fpage>261</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1146/annurev.physiol.010908.163140</pub-id><pub-id pub-id-type="pmid">19575680</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bloss</surname><given-names>EB</given-names></name><name><surname>Cembrowski</surname><given-names>MS</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Colonell</surname><given-names>J</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Spruston</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single excitatory axons form clustered synapses onto CA1 pyramidal cell dendrites</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>353</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0084-6</pub-id><pub-id pub-id-type="pmid">29459763</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bourne</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Do thin spines learn to be mushroom spines that remember?</article-title><source>Current Opinion in Neurobiology</source><volume>17</volume><fpage>381</fpage><lpage>386</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2007.04.009</pub-id><pub-id pub-id-type="pmid">17498943</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggman</surname><given-names>KL</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Volume electron microscopy for neuronal circuit reconstruction</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>154</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2011.10.022</pub-id><pub-id pub-id-type="pmid">22119321</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bromer</surname><given-names>C</given-names></name><name><surname>Bartol</surname><given-names>TM</given-names></name><name><surname>Bowden</surname><given-names>JB</given-names></name><name><surname>Hubbard</surname><given-names>DD</given-names></name><name><surname>Hanka</surname><given-names>DC</given-names></name><name><surname>Gonzalez</surname><given-names>PV</given-names></name><name><surname>Kuwajima</surname><given-names>M</given-names></name><name><surname>Mendenhall</surname><given-names>JM</given-names></name><name><surname>Parker</surname><given-names>PH</given-names></name><name><surname>Abraham</surname><given-names>WC</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name><name><surname>Harris</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Long-term potentiation expands information content of hippocampal dentate gyrus synapses</article-title><source>PNAS</source><volume>115</volume><fpage>E2410</fpage><lpage>E2418</lpage><pub-id pub-id-type="doi">10.1073/pnas.1716189115</pub-id><pub-id pub-id-type="pmid">29463730</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Schindelin</surname><given-names>J</given-names></name><name><surname>Arganda-Carreras</surname><given-names>I</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>Longair</surname><given-names>M</given-names></name><name><surname>Tomancak</surname><given-names>P</given-names></name><name><surname>Hartenstein</surname><given-names>V</given-names></name><name><surname>Douglas</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>TrakEM2 software for neural circuit reconstruction</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e38011</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0038011</pub-id><pub-id pub-id-type="pmid">22723842</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chernoff</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1954">1954</year><article-title>On the distribution of the likelihood ratio</article-title><source>The Annals of Mathematical Statistics</source><volume>25</volume><fpage>573</fpage><lpage>578</lpage><pub-id pub-id-type="doi">10.1214/aoms/1177728725</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cossell</surname><given-names>L</given-names></name><name><surname>Iacaruso</surname><given-names>MF</given-names></name><name><surname>Muir</surname><given-names>DR</given-names></name><name><surname>Houlton</surname><given-names>R</given-names></name><name><surname>Sader</surname><given-names>EN</given-names></name><name><surname>Ko</surname><given-names>H</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional organization of excitatory synaptic strength in primary visual cortex</article-title><source>Nature</source><volume>518</volume><fpage>399</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1038/nature14182</pub-id><pub-id pub-id-type="pmid">25652823</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denk</surname><given-names>W</given-names></name><name><surname>Horstmann</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Serial block-face scanning electron microscopy to reconstruct three-dimensional tissue nanostructure</article-title><source>PLOS Biology</source><volume>2</volume><elocation-id>e329</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0020329</pub-id><pub-id pub-id-type="pmid">15514700</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vivo</surname><given-names>L</given-names></name><name><surname>Bellesi</surname><given-names>M</given-names></name><name><surname>Marshall</surname><given-names>W</given-names></name><name><surname>Bushong</surname><given-names>EA</given-names></name><name><surname>Ellisman</surname><given-names>MH</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ultrastructural evidence for synaptic scaling across the wake/sleep cycle</article-title><source>Science</source><volume>355</volume><fpage>507</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1126/science.aah5982</pub-id><pub-id pub-id-type="pmid">28154076</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Dorkenwald</surname><given-names>S</given-names></name><name><surname>Schneider-Mizel</surname><given-names>C</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Sdorkenw/meshparty</data-title><version designator="v1.9.0">v1.9.0</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3710398">https://doi.org/10.5281/zenodo.3710398</ext-link></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dvorkin</surname><given-names>R</given-names></name><name><surname>Ziv</surname><given-names>NE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relative contributions of specific activity histories and spontaneous processes to size remodeling of glutamatergic synapses</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002572</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002572</pub-id><pub-id pub-id-type="pmid">27776122</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funke</surname><given-names>J</given-names></name><name><surname>Tschopp</surname><given-names>F</given-names></name><name><surname>Grisaitis</surname><given-names>W</given-names></name><name><surname>Sheridan</surname><given-names>A</given-names></name><name><surname>Singh</surname><given-names>C</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Turaga</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Large scale image segmentation with structured loss based deep learning for connectome reconstruction</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>41</volume><fpage>1669</fpage><lpage>1680</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2018.2835450</pub-id><pub-id pub-id-type="pmid">29993708</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Drew</surname><given-names>PJ</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cascade models of synaptically stored memories</article-title><source>Neuron</source><volume>45</volume><fpage>599</fpage><lpage>611</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.02.001</pub-id><pub-id pub-id-type="pmid">15721245</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KM</given-names></name><name><surname>Stevens</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Dendritic spines of ca 1 pyramidal cells in the rat hippocampus: serial electron microscopy with reference to their biophysical characteristics</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>2982</fpage><lpage>2997</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.09-08-02982.1989</pub-id><pub-id pub-id-type="pmid">2769375</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Locally dynamic synaptic learning rules in pyramidal neuron dendrites</article-title><source>Nature</source><volume>450</volume><fpage>1195</fpage><lpage>1200</lpage><pub-id pub-id-type="doi">10.1038/nature06416</pub-id><pub-id pub-id-type="pmid">18097401</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Yasuda</surname><given-names>R</given-names></name><name><surname>Zhong</surname><given-names>H</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The spread of Ras activity triggered by activation of a single dendritic spine</article-title><source>Science</source><volume>321</volume><fpage>136</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1126/science.1159675</pub-id><pub-id pub-id-type="pmid">18556515</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holler</surname><given-names>S</given-names></name><name><surname>Köstinger</surname><given-names>G</given-names></name><name><surname>Martin</surname><given-names>KAC</given-names></name><name><surname>Schuhknecht</surname><given-names>GFP</given-names></name><name><surname>Stratford</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Structure and function of a neocortical synapse</article-title><source>Nature</source><volume>591</volume><fpage>111</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-03134-2</pub-id><pub-id pub-id-type="pmid">33442056</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Holler-Rickauer</surname><given-names>S</given-names></name><name><surname>Köstinger</surname><given-names>G</given-names></name><name><surname>Martin</surname><given-names>KAC</given-names></name><name><surname>Schuhknecht</surname><given-names>GFP</given-names></name><name><surname>Stratford</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Structure and Function of a Neocortical Synapse</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2019.12.13.875971</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holtmaat</surname><given-names>A</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Experience-dependent structural synaptic plasticity in the mammalian brain</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>647</fpage><lpage>658</lpage><pub-id pub-id-type="doi">10.1038/nrn2699</pub-id><pub-id pub-id-type="pmid">19693029</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holzmann</surname><given-names>H</given-names></name><name><surname>Vollmer</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A likelihood ratio test for bimodality in two-component mixtures with application to regional income distribution in the EU</article-title><source>AStA Advances in Statistical Analysis</source><volume>92</volume><fpage>57</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1007/s10182-008-0057-2</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hua</surname><given-names>Y</given-names></name><name><surname>Laserstein</surname><given-names>P</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Large-Volume en-bloc staining for electron microscopy-based connectomics</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>7923</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms8923</pub-id><pub-id pub-id-type="pmid">26235643</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>GB</given-names></name><name><surname>Jain</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Deep and Wide Multiscale Recursive Networks for Robust Image Labeling</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1310.0354</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jain</surname><given-names>V</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Turaga</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Machines that learn to segment images: a crucial technology for connectomics</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>653</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.07.004</pub-id><pub-id pub-id-type="pmid">20801638</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasai</surname><given-names>H</given-names></name><name><surname>Matsuzaki</surname><given-names>M</given-names></name><name><surname>Noguchi</surname><given-names>J</given-names></name><name><surname>Yasumatsu</surname><given-names>N</given-names></name><name><surname>Nakahara</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Structure-stability-function relationships of dendritic spines</article-title><source>Trends in Neurosciences</source><volume>26</volume><fpage>360</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(03)00162-0</pub-id><pub-id pub-id-type="pmid">12850432</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasai</surname><given-names>H</given-names></name><name><surname>Ziv</surname><given-names>NE</given-names></name><name><surname>Okazaki</surname><given-names>H</given-names></name><name><surname>Yagishita</surname><given-names>S</given-names></name><name><surname>Toyoizumi</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Spine dynamics in the brain, mental disorders and artificial neural networks</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>407</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00467-3</pub-id><pub-id pub-id-type="pmid">34050339</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasthuri</surname><given-names>N</given-names></name><name><surname>Hayworth</surname><given-names>KJ</given-names></name><name><surname>Berger</surname><given-names>DR</given-names></name><name><surname>Schalek</surname><given-names>RL</given-names></name><name><surname>Conchello</surname><given-names>JA</given-names></name><name><surname>Knowles-Barley</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Vázquez-Reina</surname><given-names>A</given-names></name><name><surname>Kaynig</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>TR</given-names></name><name><surname>Roberts</surname><given-names>M</given-names></name><name><surname>Morgan</surname><given-names>JL</given-names></name><name><surname>Tapia</surname><given-names>JC</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Roncal</surname><given-names>WG</given-names></name><name><surname>Vogelstein</surname><given-names>JT</given-names></name><name><surname>Burns</surname><given-names>R</given-names></name><name><surname>Sussman</surname><given-names>DL</given-names></name><name><surname>Priebe</surname><given-names>CE</given-names></name><name><surname>Pfister</surname><given-names>H</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Saturated reconstruction of a volume of neocortex</article-title><source>Cell</source><volume>162</volume><fpage>648</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.06.054</pub-id><pub-id pub-id-type="pmid">26232230</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaynig</surname><given-names>V</given-names></name><name><surname>Fischer</surname><given-names>B</given-names></name><name><surname>Müller</surname><given-names>E</given-names></name><name><surname>Buhmann</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Fully automatic stitching and distortion correction of transmission electron microscope images</article-title><source>Journal of Structural Biology</source><volume>171</volume><fpage>163</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1016/j.jsb.2010.04.012</pub-id><pub-id pub-id-type="pmid">20450977</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adam: A Method for Stochastic Optimization</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1412.6980</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Marchman</surname><given-names>H</given-names></name><name><surname>Wall</surname><given-names>D</given-names></name><name><surname>Lich</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Serial section scanning electron microscopy of adult brain tissue using focused ion beam milling</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>2959</fpage><lpage>2964</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3189-07.2008</pub-id><pub-id pub-id-type="pmid">18353998</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koester</surname><given-names>HJ</given-names></name><name><surname>Johnston</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Target cell-dependent normalization of transmitter release at neocortical synapses</article-title><source>Science</source><volume>308</volume><fpage>863</fpage><lpage>866</lpage><pub-id pub-id-type="doi">10.1126/science.1100815</pub-id><pub-id pub-id-type="pmid">15774725</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Li</surname><given-names>B</given-names></name><name><surname>Wei</surname><given-names>W</given-names></name><name><surname>Boehm</surname><given-names>J</given-names></name><name><surname>Malinow</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Glutamate receptor exocytosis and spine enlargement during chemically induced long-term potentiation</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>2000</fpage><lpage>2009</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3918-05.2006</pub-id><pub-id pub-id-type="pmid">16481433</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kornfeld</surname><given-names>J</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Progress and remaining challenges in high-throughput volume electron microscopy</article-title><source>Current Opinion in Neurobiology</source><volume>50</volume><fpage>261</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2018.04.030</pub-id><pub-id pub-id-type="pmid">29758457</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>WCA</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Reed</surname><given-names>M</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Hood</surname><given-names>G</given-names></name><name><surname>Glattfelder</surname><given-names>K</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Anatomy and function of an excitatory network in the visual cortex</article-title><source>Nature</source><volume>532</volume><fpage>370</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1038/nature17192</pub-id><pub-id pub-id-type="pmid">27018655</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Superhuman Accuracy on the SNEMI3D Connectomics Challenge</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1706.00120</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Turner</surname><given-names>N</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Lu</surname><given-names>R</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Convolutional nets for reconstructing neural circuits from brain images acquired by serial section electron microscopy</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>188</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.04.001</pub-id><pub-id pub-id-type="pmid">31071619</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Li</surname><given-names>PH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Automated Reconstruction of a Serial-Section EM <italic>Drosophila</italic> Brain with Flood-Filling Networks and Local Realignment</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/605634v1</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>A mechanism for memory storage insensitive to molecular turnover: A bistable autophosphorylating kinase</article-title><source>PNAS</source><volume>82</volume><fpage>3055</fpage><lpage>3057</lpage><pub-id pub-id-type="doi">10.1073/pnas.82.9.3055</pub-id><pub-id pub-id-type="pmid">2986148</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loewenstein</surname><given-names>Y</given-names></name><name><surname>Kuras</surname><given-names>A</given-names></name><name><surname>Rumpel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multiplicative dynamics underlie the emergence of the log-normal distribution of spine sizes in the neocortex in vivo</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>9481</fpage><lpage>9488</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6130-10.2011</pub-id><pub-id pub-id-type="pmid">21715613</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loewenstein</surname><given-names>Y</given-names></name><name><surname>Yanover</surname><given-names>U</given-names></name><name><surname>Rumpel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Predicting the dynamics of network connectivity in the neocortex</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>12535</fpage><lpage>12544</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2917-14.2015</pub-id><pub-id pub-id-type="pmid">26354919</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Ih</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Alembic</data-title><version designator="0.3">0.3</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/seung-lab/Alembic">https://github.com/seung-lab/Alembic</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maitin-Shepard</surname><given-names>M</given-names></name><name><surname>McCullough</surname><given-names>ML</given-names></name><name><surname>Bandera</surname><given-names>EV</given-names></name><name><surname>Basen-Engquist</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>U.S. dietary guidelines and cancer prevention: your input is needed!</article-title><source>Cancer Epidemiology, Biomarkers &amp; Prevention</source><volume>29</volume><fpage>257</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1158/1055-9965.EPI-19-1456</pub-id><pub-id pub-id-type="pmid">31843873</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsuzaki</surname><given-names>M</given-names></name><name><surname>Ellis-Davies</surname><given-names>GC</given-names></name><name><surname>Nemoto</surname><given-names>T</given-names></name><name><surname>Miyashita</surname><given-names>Y</given-names></name><name><surname>Iino</surname><given-names>M</given-names></name><name><surname>Kasai</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dendritic spine geometry is critical for AMPA receptor expression in hippocampal CA1 pyramidal neurons</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>1086</fpage><lpage>1092</lpage><pub-id pub-id-type="doi">10.1038/nn736</pub-id><pub-id pub-id-type="pmid">11687814</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsuzaki</surname><given-names>M</given-names></name><name><surname>Honkura</surname><given-names>N</given-names></name><name><surname>Ellis-Davies</surname><given-names>GCR</given-names></name><name><surname>Kasai</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Structural basis of long-term potentiation in single dendritic spines</article-title><source>Nature</source><volume>429</volume><fpage>761</fpage><lpage>766</lpage><pub-id pub-id-type="doi">10.1038/nature02617</pub-id><pub-id pub-id-type="pmid">15190253</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motta</surname><given-names>A</given-names></name><name><surname>Berning</surname><given-names>M</given-names></name><name><surname>Boergens</surname><given-names>KM</given-names></name><name><surname>Staffler</surname><given-names>B</given-names></name><name><surname>Beining</surname><given-names>M</given-names></name><name><surname>Loomba</surname><given-names>S</given-names></name><name><surname>Hennig</surname><given-names>P</given-names></name><name><surname>Wissler</surname><given-names>H</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dense connectomic reconstruction in layer 4 of the somatosensory cortex</article-title><source>Science</source><volume>366</volume><elocation-id>eaay3134</elocation-id><pub-id pub-id-type="doi">10.1126/science.aay3134</pub-id><pub-id pub-id-type="pmid">31649140</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nickell</surname><given-names>S</given-names></name><name><surname>Zeidler</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A 331-beam scanning electron microscope’, microscopy and microanalysis</article-title><source>Journal of Microscopy Society of America</source><volume>25</volume><fpage>568</fpage><lpage>569</lpage><pub-id pub-id-type="doi">10.1017/S1431927621013593</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noguchi</surname><given-names>J</given-names></name><name><surname>Nagaoka</surname><given-names>A</given-names></name><name><surname>Watanabe</surname><given-names>S</given-names></name><name><surname>Ellis-Davies</surname><given-names>GCR</given-names></name><name><surname>Kitamura</surname><given-names>K</given-names></name><name><surname>Kano</surname><given-names>M</given-names></name><name><surname>Matsuzaki</surname><given-names>M</given-names></name><name><surname>Kasai</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>In vivo two-photon uncaging of glutamate revealing the structure-function relationships of dendritic spines in the neocortex of adult mice</article-title><source>The Journal of Physiology</source><volume>589</volume><fpage>2447</fpage><lpage>2457</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2011.207100</pub-id><pub-id pub-id-type="pmid">21486811</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noguchi</surname><given-names>J</given-names></name><name><surname>Nagaoka</surname><given-names>A</given-names></name><name><surname>Hayama</surname><given-names>T</given-names></name><name><surname>Ucar</surname><given-names>H</given-names></name><name><surname>Yagishita</surname><given-names>S</given-names></name><name><surname>Takahashi</surname><given-names>N</given-names></name><name><surname>Kasai</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Bidirectional in vivo structural dendritic spine plasticity revealed by two-photon glutamate uncaging in the mouse neocortex</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>13922</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-50445-0</pub-id><pub-id pub-id-type="pmid">31558759</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>DH</given-names></name><name><surname>Wittenberg</surname><given-names>GM</given-names></name><name><surname>Wang</surname><given-names>SSH</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Graded bidirectional synaptic plasticity is composed of switch-like unitary events</article-title><source>PNAS</source><volume>102</volume><fpage>9679</fpage><lpage>9684</lpage><pub-id pub-id-type="doi">10.1073/pnas.0502332102</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><name><surname>Gross</surname><given-names>S</given-names></name><name><surname>Chintala</surname><given-names>S</given-names></name><name><surname>Chanan</surname><given-names>G</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>DeVito</surname><given-names>Z</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Desmaison</surname><given-names>A</given-names></name><name><surname>Antiga</surname><given-names>L</given-names></name><name><surname>Lerer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automatic differentiation in PyTorch</article-title><conf-name>NIPS 2017 Workshop on Autodiff</conf-name></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>A</given-names></name><name><surname>Kaiserman-Abramof</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>The small pyramidal neuron of the rat cerebral cortex; the perikaryon, dendrites and spines</article-title><source>The American Journal of Anatomy</source><volume>127</volume><fpage>321</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1002/aja.1001270402</pub-id><pub-id pub-id-type="pmid">4985058</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>CC</given-names></name><name><surname>Malenka</surname><given-names>RC</given-names></name><name><surname>Nicoll</surname><given-names>RA</given-names></name><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>All-or-none potentiation at CA3-CA1 synapses</article-title><source>PNAS</source><volume>95</volume><fpage>4732</fpage><lpage>4737</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.8.4732</pub-id><pub-id pub-id-type="pmid">9539807</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Popovych</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>PZnet: Efficient 3D Convnet Inference on Manycore Cpus</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1903.07525</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Reddi</surname><given-names>SJ</given-names></name><name><surname>Kale</surname><given-names>S</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>On the Convergence of Adam and Beyond</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1904.09237</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>CA</given-names></name><name><surname>Fryer</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Some descriptive properties of normal mixtures</article-title><source>Scandinavian Actuarial Journal</source><volume>1969</volume><fpage>137</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1080/03461238.1969.10404590</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>J</given-names></name><name><surname>Lee</surname><given-names>DD</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Equilibrium properties of temporally asymmetric Hebbian plasticity</article-title><source>Physical Review Letters</source><volume>86</volume><fpage>364</fpage><lpage>367</lpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.86.364</pub-id><pub-id pub-id-type="pmid">11177832</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Fetter</surname><given-names>R</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Tomancak</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Elastic volume reconstruction from series of ultra-thin microscopy sections</article-title><source>Nature Methods</source><volume>9</volume><fpage>717</fpage><lpage>720</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2072</pub-id><pub-id pub-id-type="pmid">22688414</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sando</surname><given-names>R</given-names></name><name><surname>Bushong</surname><given-names>E</given-names></name><name><surname>Zhu</surname><given-names>Y</given-names></name><name><surname>Huang</surname><given-names>M</given-names></name><name><surname>Considine</surname><given-names>C</given-names></name><name><surname>Phan</surname><given-names>S</given-names></name><name><surname>Ju</surname><given-names>S</given-names></name><name><surname>Uytiepo</surname><given-names>M</given-names></name><name><surname>Ellisman</surname><given-names>M</given-names></name><name><surname>Maximov</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Assembly of excitatory synapses in the absence of glutamatergic neurotransmission</article-title><source>Neuron</source><volume>94</volume><fpage>312</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.047</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santuy</surname><given-names>A</given-names></name><name><surname>Rodríguez</surname><given-names>JR</given-names></name><name><surname>DeFelipe</surname><given-names>J</given-names></name><name><surname>Merchán-Pérez</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Study of the size and shape of synapses in the juvenile rat somatosensory cortex with 3D electron microscopy</article-title><source>Eneuro</source><volume>5</volume><elocation-id>ENEURO</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0377-17.2017</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>M</given-names></name><name><surname>Bitter</surname><given-names>I</given-names></name><name><surname>Bender</surname><given-names>MA</given-names></name><name><surname>Kaufman</surname><given-names>AE</given-names></name><name><surname>Nakajima</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>TEASAR: tree-structure extraction algorithm for accurate and robust skeletons</article-title><conf-name>the Eighth Pacific Conference on Computer Graphics and Applications</conf-name><conf-loc>Hong Kong, China</conf-loc><pub-id pub-id-type="doi">10.1109/PCCGA.2000.883951</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>H</given-names></name><name><surname>Gour</surname><given-names>A</given-names></name><name><surname>Straehle</surname><given-names>J</given-names></name><name><surname>Boergens</surname><given-names>KM</given-names></name><name><surname>Brecht</surname><given-names>M</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Axonal synapse sorting in medial entorhinal cortex</article-title><source>Nature</source><volume>549</volume><fpage>469</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.1038/nature24005</pub-id><pub-id pub-id-type="pmid">28959971</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider-Mizell</surname><given-names>CM</given-names></name><name><surname>Bodor</surname><given-names>AL</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name><name><surname>Brittain</surname><given-names>D</given-names></name><name><surname>Bleckert</surname><given-names>A</given-names></name><name><surname>Dorkenwald</surname><given-names>S</given-names></name><name><surname>Turner</surname><given-names>NL</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Lu</surname><given-names>R</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Zhuang</surname><given-names>J</given-names></name><name><surname>Nandi</surname><given-names>A</given-names></name><name><surname>Hu</surname><given-names>B</given-names></name><name><surname>Buchanan</surname><given-names>J</given-names></name><name><surname>Takeno</surname><given-names>MM</given-names></name><name><surname>Torres</surname><given-names>R</given-names></name><name><surname>Mahalingam</surname><given-names>G</given-names></name><name><surname>Bumbarger</surname><given-names>DJ</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Chartrand</surname><given-names>T</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Silversmith</surname><given-names>WM</given-names></name><name><surname>Ih</surname><given-names>D</given-names></name><name><surname>Zung</surname><given-names>J</given-names></name><name><surname>Zlateski</surname><given-names>A</given-names></name><name><surname>Tartavull</surname><given-names>I</given-names></name><name><surname>Popovych</surname><given-names>S</given-names></name><name><surname>Wong</surname><given-names>W</given-names></name><name><surname>Castro</surname><given-names>M</given-names></name><name><surname>Jordan</surname><given-names>CS</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Becker</surname><given-names>L</given-names></name><name><surname>Suckow</surname><given-names>S</given-names></name><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Costa</surname><given-names>N da</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Structure and function of axo-axonic inhibition</article-title><source>eLife</source><volume>10</volume><elocation-id>e783</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.73783</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Scholl</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical Neuron Response Selectivity Derives from Strength in Numbers of Synapses</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2019.12.24.887422</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreiber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Pomegranate: fast and flexible probabilistic modeling in python</article-title><source>Journal of Machine Learning Research: JMLR</source><volume>18</volume><fpage>5992</fpage><lpage>5997</lpage><pub-id pub-id-type="doi">10.5555/3122009.3242021</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sigler</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Formation and maintenance of functional spines in the absence of presynaptic glutamate release</article-title><source>Neuron</source><volume>94</volume><fpage>304</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.029</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Silversmith</surname><given-names>W</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Castro</surname><given-names>M</given-names></name><name><surname>Falk</surname><given-names>B</given-names></name><name><surname>Roat</surname><given-names>C</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Perlman</surname><given-names>E</given-names></name><name><surname>shangmu</surname><given-names>AH</given-names></name><name><surname>Gunn</surname><given-names>P</given-names></name><name><surname>Jagannathan</surname><given-names>S</given-names></name><name><surname>Hoag</surname><given-names>A</given-names></name><name><surname>Turner</surname><given-names>N</given-names></name><name><surname>Dorkenwald</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Seung-lab/cloud-volume: zenodo release</data-title><version designator="v1 (5.3.2)">v1 (5.3.2)</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5671443">https://doi.org/10.5281/zenodo.5671443</ext-link></element-citation></ref><ref id="bib72"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Silversmith</surname><given-names>W</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Kimimaro: skeletonize densely labeled images</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/seung-lab/kimimaro">https://github.com/seung-lab/kimimaro</ext-link></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Competitive Hebbian learning through spike-timing-dependent synaptic plasticity</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>919</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1038/78829</pub-id><pub-id pub-id-type="pmid">10966623</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Sjöström</surname><given-names>PJ</given-names></name><name><surname>Reigl</surname><given-names>M</given-names></name><name><surname>Nelson</surname><given-names>S</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title><source>PLOS Biology</source><volume>3</volume><elocation-id>e68</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0030068</pub-id><pub-id pub-id-type="pmid">15737062</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorra</surname><given-names>KE</given-names></name><name><surname>Harris</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Occurrence and three-dimensional structure of multiple synapses between individual radiatum axons and their target pyramidal cells in hippocampal area CA1</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>3736</fpage><lpage>3748</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-09-03736.1993</pub-id><pub-id pub-id-type="pmid">8366344</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spacek</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Three-Dimensional analysis of dendritic spines. II. spine apparatus and other cytoplasmic components</article-title><source>Anatomy and Embryology</source><volume>171</volume><fpage>235</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1007/BF00341418</pub-id><pub-id pub-id-type="pmid">3985372</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spano</surname><given-names>GM</given-names></name><name><surname>Banningh</surname><given-names>SW</given-names></name><name><surname>Marshall</surname><given-names>W</given-names></name><name><surname>de Vivo</surname><given-names>L</given-names></name><name><surname>Bellesi</surname><given-names>M</given-names></name><name><surname>Loschky</surname><given-names>SS</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sleep deprivation by exposure to novel objects increases synapse density and axon-spine interface in the hippocampal CA1 region of adolescent mice</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>6613</fpage><lpage>6625</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0380-19.2019</pub-id><pub-id pub-id-type="pmid">31263066</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Statman</surname><given-names>A</given-names></name><name><surname>Kaufman</surname><given-names>M</given-names></name><name><surname>Minerbi</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>NE</given-names></name><name><surname>Brenner</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Synaptic size dynamics as an effectively stochastic process</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003846</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003846</pub-id><pub-id pub-id-type="pmid">25275505</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tapia</surname><given-names>JC</given-names></name><name><surname>Kasthuri</surname><given-names>N</given-names></name><name><surname>Hayworth</surname><given-names>KJ</given-names></name><name><surname>Schalek</surname><given-names>R</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name><name><surname>Smith</surname><given-names>SJ</given-names></name><name><surname>Buchanan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>High-Contrast en bloc staining of neuronal tissue for field emission scanning electron microscopy</article-title><source>Nature Protocols</source><volume>7</volume><fpage>193</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1038/nprot.2011.439</pub-id><pub-id pub-id-type="pmid">22240582</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsodyks</surname><given-names>MV</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Associative memory in neural networks with binary synapses</article-title><source>Modern Physics Letters B</source><volume>04</volume><fpage>713</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1142/S0217984990000891</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turaga</surname><given-names>SC</given-names></name><name><surname>Murray</surname><given-names>JF</given-names></name><name><surname>Jain</surname><given-names>V</given-names></name><name><surname>Roth</surname><given-names>F</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name><name><surname>Briggman</surname><given-names>K</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Convolutional networks can learn to generate affinity graphs for image segmentation</article-title><source>Neural Computation</source><volume>22</volume><fpage>511</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1162/neco.2009.10-08-881</pub-id><pub-id pub-id-type="pmid">19922289</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>NL</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Lu</surname><given-names>R</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Ih</surname><given-names>D</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Synaptic Partner Assignment Using Attentional Voxel Association Networks</article-title><conf-name>2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI</conf-name><pub-id pub-id-type="doi">10.1109/ISBI45749.2020.9098489</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>PyTorchUtils</data-title><version designator="50ea71c">50ea71c</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/nicholasturner1/PyTorchUtils">https://github.com/nicholasturner1/PyTorchUtils</ext-link></element-citation></ref><ref id="bib84"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>N</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Silversmith</surname><given-names>W</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Synaptor</data-title><version designator="76084be">76084be</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/nicholasturner1/Synaptor">https://github.com/nicholasturner1/Synaptor</ext-link></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>NL</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Bae</surname><given-names>JA</given-names></name><name><surname>Yang</surname><given-names>R</given-names></name><name><surname>Wilson</surname><given-names>AM</given-names></name><name><surname>Schneider-Mizell</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Lu</surname><given-names>R</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Bodor</surname><given-names>AL</given-names></name><name><surname>Bleckert</surname><given-names>AA</given-names></name><name><surname>Brittain</surname><given-names>D</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Dorkenwald</surname><given-names>S</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Ih</surname><given-names>D</given-names></name><name><surname>Silversmith</surname><given-names>WM</given-names></name><name><surname>Zung</surname><given-names>J</given-names></name><name><surname>Zlateski</surname><given-names>A</given-names></name><name><surname>Tartavull</surname><given-names>I</given-names></name><name><surname>Yu</surname><given-names>SC</given-names></name><name><surname>Popovych</surname><given-names>S</given-names></name><name><surname>Mu</surname><given-names>S</given-names></name><name><surname>Wong</surname><given-names>W</given-names></name><name><surname>Jordan</surname><given-names>CS</given-names></name><name><surname>Castro</surname><given-names>M</given-names></name><name><surname>Buchanan</surname><given-names>J</given-names></name><name><surname>Bumbarger</surname><given-names>DJ</given-names></name><name><surname>Takeno</surname><given-names>M</given-names></name><name><surname>Torres</surname><given-names>R</given-names></name><name><surname>Mahalingam</surname><given-names>G</given-names></name><name><surname>Elabbady</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Cobos</surname><given-names>E</given-names></name><name><surname>Zhou</surname><given-names>P</given-names></name><name><surname>Suckow</surname><given-names>S</given-names></name><name><surname>Becker</surname><given-names>L</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Polleux</surname><given-names>F</given-names></name><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>da Costa</surname><given-names>NM</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Reconstruction of neocortex: organelles, compartments, cells, circuits, and activity</article-title><source>Cell</source><volume>185</volume><fpage>1082</fpage><lpage>1100</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2022.01.023</pub-id><pub-id pub-id-type="pmid">35216674</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Rossum</surname><given-names>MCW</given-names></name><name><surname>Bi</surname><given-names>GQ</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Stable Hebbian learning from spike timing-dependent plasticity</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>8812</fpage><lpage>8821</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-23-08812.2000</pub-id><pub-id pub-id-type="pmid">11102489</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilks</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="1938">1938</year><article-title>The large-sample distribution of the likelihood ratio for testing composite hypotheses</article-title><source>The Annals of Mathematical Statistics</source><volume>9</volume><fpage>60</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1214/aoms/1177732360</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Silversmith</surname><given-names>WM</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Chunkflow: Distributed Hybrid Cloud Processing of Large 3D Images by Convolutional Nets</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1904.10489</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yasumatsu</surname><given-names>N</given-names></name><name><surname>Matsuzaki</surname><given-names>M</given-names></name><name><surname>Miyazaki</surname><given-names>T</given-names></name><name><surname>Noguchi</surname><given-names>J</given-names></name><name><surname>Kasai</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Principles of long-term dynamics of dendritic spines</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>13592</fpage><lpage>13608</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0603-08.2008</pub-id><pub-id pub-id-type="pmid">19074033</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>W</given-names></name><name><surname>Brittain</surname><given-names>D</given-names></name><name><surname>Borseth</surname><given-names>J</given-names></name><name><surname>Scott</surname><given-names>ME</given-names></name><name><surname>Williams</surname><given-names>D</given-names></name><name><surname>Perkins</surname><given-names>J</given-names></name><name><surname>Own</surname><given-names>C</given-names></name><name><surname>Murfitt</surname><given-names>M</given-names></name><name><surname>Torres</surname><given-names>RM</given-names></name><name><surname>Kapner</surname><given-names>D</given-names></name><name><surname>Bleckert</surname><given-names>A</given-names></name><name><surname>Castelli</surname><given-names>D</given-names></name><name><surname>Reid</surname><given-names>D</given-names></name><name><surname>Lee</surname><given-names>WCA</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Takeno</surname><given-names>M</given-names></name><name><surname>Bumbarger</surname><given-names>DJ</given-names></name><name><surname>Farrell</surname><given-names>C</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>da Costa</surname><given-names>NM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Petascale Automated Imaging Pipeline for Mapping Neuronal Circuits with High-Throughput Transmission Electron Microscopy</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/791889</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><source>Dendritic Spines</source><publisher-loc>Cambridge, Massachusetts</publisher-loc><publisher-name>The MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/9780262013505.001.0001</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>T</given-names></name><name><surname>Wu</surname><given-names>B</given-names></name><name><surname>Ji</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>DeepEM3D: approaching human-level performance on 3D anisotropic em image segmentation</article-title><source>Bioinformatics</source><volume>33</volume><fpage>2555</fpage><lpage>2562</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx188</pub-id><pub-id pub-id-type="pmid">28379412</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Z</given-names></name><name><surname>Lauritzen</surname><given-names>JS</given-names></name><name><surname>Perlman</surname><given-names>E</given-names></name><name><surname>Robinson</surname><given-names>CG</given-names></name><name><surname>Nichols</surname><given-names>M</given-names></name><name><surname>Milkie</surname><given-names>D</given-names></name><name><surname>Torrens</surname><given-names>O</given-names></name><name><surname>Price</surname><given-names>J</given-names></name><name><surname>Fisher</surname><given-names>CB</given-names></name><name><surname>Sharifi</surname><given-names>N</given-names></name><name><surname>Calle-Schuler</surname><given-names>SA</given-names></name><name><surname>Kmecova</surname><given-names>L</given-names></name><name><surname>Ali</surname><given-names>IJ</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Hanslovsky</surname><given-names>P</given-names></name><name><surname>Jefferis</surname><given-names>GSXE</given-names></name><name><surname>Kazhdan</surname><given-names>M</given-names></name><name><surname>Khairy</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A complete electron microscopy volume of the brain of adult <italic>Drosophila melanogaster</italic></article-title><source>Cell</source><volume>174</volume><fpage>730</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id><pub-id pub-id-type="pmid">30033368</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zlateski</surname><given-names>A</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Image Segmentation by Size-Dependent Single Linkage Clustering of a Watershed Basin Graph</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1505.00249</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76120.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>O'Leary</surname><given-names>Timothy</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2019.12.29.890319" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2019.12.29.890319"/></front-stub><body><p>Cortical synaptic plasticity mechanisms shape excitatory connectivity during learning and development. A long-standing question is whether these processes are determined by pre- and postsynaptic activity and whether the resulting synaptic changes result in a continuous, graded distribution of strengths. Dorkenwald and colleagues use extensive ultrastructural data to study cortical excitatory synaptic spines and demonstrate that the population is a very well-described discrete mix of &quot;small&quot; and &quot;large&quot; connections, with graded variability around these dominant modes. Co-innervated connections result in strong correlations between the discrete small/large variable, but not the graded component, supporting a model in which correlated activity results in jumps between small and large synaptic strengths.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76120.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>O'Leary</surname><given-names>Timothy</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Kasai</surname><given-names>Haruo</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/057zh3y96</institution-id><institution>The University of Tokyo School of Medicine</institution></institution-wrap><country>Japan</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Bartol</surname><given-names>Thomas M</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2019.12.29.890319">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2019.12.29.890319v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Binary and analog variation of synapses between cortical pyramidal neurons&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by John Huguenard as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Haruo Kasai (Reviewer #2); Thomas M Bartol (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Mechanistic claims, statistical analyses and their interpretation: please take on board reviewer's comments about the causal interpretations of these findings and adjust the claims and language in the manuscript to acknowledge that the findings are observational. In several places the writing appears to claim that statistical analyses alone can reveal causal mechanisms, which is misleading. Please revise the writing to more clearly delineate hypotheses and interpretations from empirical observations. Finally, address Reviewer #1's concern about bias in the analysis of size distribution.</p><p>2) Potential control/comparative data: consider suggestions from Reviewer #3 for comparative analysis of other synapse types that may be available within the dataset. If these data are not readily available please provide a brief explanation in a rebuttal.</p><p>3) Literature: review the paper's treatment of previous work in line with some of the suggestions made by reviewer #2. You do not have to adopt the reviewer's interpretations of the data, but it is worth reviewing some of the suggested references to ensure the manuscript does justice to existing work and current thinking on the relationship between plasticity mechanisms and synapse size distributions.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>I think the paper is excellent overall and I only have two comments about the wording and interpretation of some of the findings and about one part of the statistical analysis.</p><p>1. Interpretations. In several places in the manuscript the authors make statements about the findings being biologically meaningful *as opposed to being statistical observations*. The fact is there are compelling observations and sound analyses and interpretations of these observations, but this does not transform the study from being observational in nature. A key example is in the paragraph at the top of page 8:</p><p>&quot;A binary mixture model might merely be a convenient way of approximating deviations from normality. We would like to know whether the components of our binary mixture really have a biological basis, i.e., whether they correspond to two structural states of synapses. A mixture of two normal distributions can be unimodal or bimodal, depending on the model parameters3 (Robertson and Fryer, 1969). When comparing best fit unimodal and bimodal mixtures we found that a bimodal model yields a significantly superior fit for spine volume and geometric mean of spine volume (p=0.0425, n=320; Extended Data Figure 4, see (Holzmann and Vollmer, 2008) for statistical methods). This bimodality makes it plausible that the mixture components correspond to biological states of synapses.&quot;</p><p>The analyses they have performed to test for bimodality and the interpretation they have for its presence are both sound. However, the authors are saying that statistical modelling alone can reveal whether measurements &quot;really have a biological basis&quot;. It cannot. Only a further (experimental) intervention could begin to do this. I want to say very clearly that I don't think the observational nature of the study is a weak point at all. The authors should accept it is observational and describe it as such. They have produced a very compelling and sophisticated piece of science, but it is incorrect (and slightly dangerous for more naïve readers) to blur the lines between the reasoning that motivates a hypothesis, and the statistical means of evaluating evidence for it.</p><p>I would hazard a guess that the authors are aware of this issue but are dealing with the rather unscientific way our community treats/labels observational work. I think this is excellent work and it doesn't need to disguise the epistemology at all.</p><p>Finally, I'd like to point out that a bimodal distribution is still a 'continuum'. The authors don't contradict this, but they come close to contrasting continual synaptic variation with their findings in the abstract which I find potentially misleading if readers are sloppy.</p><p>2. Statistical analysis. I have a simple query about the way the authors rule out a trend between the analog component of spine volume correlation between multiple connections (Figure 4 and associated analyses).</p><p>My understanding is that they resampled from the data based on mixture component weight (i.e. preferentially sample from points close to an effective cluster) THEN perform correlation analysis on these two resampled populations.</p><p>Is this biased? i.e. would it tend to dilute residual correlation that cannot be accounted for by the binary components because it over-represents data points close to the centroids of clusters? I'm not sure, but I think they could check this through simulation very easily.</p><p>An alternative method for asking about 'analog covariation' would be to simply look at residuals of the model with the binary component subtracted, as is done in standard mixed statistical models. In this case a significant trend in the residuals would be evidence for analog covariation.</p><p>Finally, the pedant in me wants them to be more careful about absence of evidence not being evidence for absence, so they could tighten their language in places when describing these results in the event of a robust null finding.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>1) Abstract: &quot;Previous cortical studies modelled a continuum of synapse sizes (Arellano et al., 2007)”</p><p>The continuum of spine sizes has already been shown in old ssEM papers, such as Harris, K. M. and Stevens, J Neurosci 9, 2982-2997 (1989). The same applied to all the rest of the text.</p><p>2) Abstract: &quot;by a log-normal distribution (Loewenstein, Kuras and Rumpel, 2011; de Vivo et al., 2017; Santuy et al. , 2018)&quot;.</p><p>These papers do not provide a rationale for a log-normal distribution of spine sizes and are misleading. There is no reason and evidence why spine distribution is log-normal. Note that the multiplicative dynamics do not simply predict a log-normal distribution. The most comprehensive review on an approximately log-normal distribution has been provided in the following review, which should be cited to help readers: Kasai, H., Ziv, N. E., Okazaki, H., Yagishita, S. and Toyoizumi, Nature reviews. Neuroscience 22, 407-422, doi:10.1038/s41583-021-00467-3 (2021).</p><p>3) Introduction: &quot;In the 2000s, some hypothesized that long-term plasticity involves discrete transitions of synapses between two structural states (Kasai et al., 2003; Bourne and Harris, 2007).&quot;</p><p>This sentence is wrong. None of the two papers claimed the discrete transition of synapses between two states. They describe the spines as a continuum, emphasizing that learning changes smaller spines to bigger ones, consistent with the binary and analogue variation of synapses proposed in this study.</p><p>Bistability was predicted only theoretically as winner-takes-all situations, ex. Gilson, M. and Fukai, T. PloS one 6, e25339, doi:10.1371/journal.pone.0025339 (2011).</p><p>4) Page 7 &quot;Even researchers who report bimodally distributed synapse size in the hippocampus (Spano et al., 2019) still find log-normally distributed synapse size in the neocortex (de Vivo et al., 2017) by the same methods.&quot;</p><p>These statements make sense only when the spine volumes are plotted on a logarithmic scale. The authors should consider using &quot;bimodal on the semi-logarithmic scale&quot; whenever the bimodality matters. Also, by comparing Figure 3b and c, the authors should explicitly describe that the bimodality only becomes evident when a semi-logarithmic plot is used.</p><p>5) The authors should display the linear plots also for Figure 1d and 1e.</p><p>6) The authors should provide more detailed descriptions of the behavioural states of mice, as the results should depend on how mice were rared. Say, there should be more binary mode on a semi-logarithmic plot in mice rared in an environment enriched cage.</p><p>7) Methods section states two-photon imaging, but the study does not seem to use two-photon data.</p><p>8) Discussion: &quot;Experiments have shown that large dynamical fluctuations persist even after activity is pharmacologically blocked (Yasumatsu et al. , 2008; Statman et al. , 2014).&quot;</p><p>They are also supported by more recent data by Sigler et al. Neuron 94:304(2017) and Sando et al. Neuron 94:312(2017).</p><p>9) Discussion: &quot;It has been argued that the observed structural volatility of synapses is challenging to reconcile with the stability of memory (Loewenstein, Kuras and Rumpel, 2011). Our findings suggest two possible resolutions of the stability-plasticity dilemma……. In a second scenario…&quot;</p><p>These discussions do not provide a resolution. As described in Kasai et al. (Nat Rev Neurosci 2021), we should be aware that most daily memories are forgotten in a few days to 1 week, and longer-lasting memories need repeated recall, as initially described by Ebbinghaus (1885). There is no stability-plasticity dilemma when we take these memory properties into account. The spine fluctuations also naturally explain the memory persistence and spine volume distributions. The author should rewrite the discussion incorporating this coherent view.</p><p>9) The authors find that the dual connections by the axons from outside the 250*140*90um volume were not bimodal in the semi-logarithmic plot (EFigure 10), suggesting that a cell assembly is more often formed within the volume than distant cortices. The authors should explicitly describe and discuss this scenario.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>1) In the Abstract it would helpful to state the animal and cortical region studied and the size of the dataset (volume, number of connections).</p><p>2) Near the end of Abstract, perhaps give a few examples of the &quot;other influences&quot; that contribute to the analog variation of synapse size in dual connections.</p><p>3) At the end of the Abstract, &quot;stability-plasticity dilemma&quot; might be a bit vague for some readers.</p><p>4) In Introduction, first paragraph, &quot;Spine dynamics were interpreted as synaptic plasticity&quot; is an odd statement since &quot;dynamics&quot; means change and &quot;plasticity&quot; means change. Please reword.</p><p>5) In Introduction, paragraph 4, the authors seem to equate their definition of &quot;paired connections&quot; (or &quot;dual connections&quot;) with that used in Bartol et al., 2015. The authors should clearly define their use of the term &quot;paired (or dual) connection&quot; and the definition of &quot;Same Dendrite, Same Axon pairs (SDSA pairs)&quot; used in Bartol et al., 2015. This distinction is important and could explain some of the differences observed in their new results here compared to the earlier observations in the literature.</p><p>6) Bartol et al. 2015 showed that the sizes of SDSA pairs in hippocampus are highly correlated along the whole continuum with no binary component. Which differs from the authors' results. This difference is interesting for further discussion.</p><p>7) Introduction paragraph 5, please be specific about the &quot;specificity of the synaptic population&quot;. Please state again that these are connections between L2/3 PyCs. Also, again Bartol et al. 2015 showed strong corellation in the continuum among all SDSA pairs, from smallest to largest, though in Rat hippocampus, not Mouse neocortex.</p><p>8) Handling of Image Defects. In discussing the defects it helps the reader to give the xyz resolution of the ssEM images here. 3.58 nm in plane, 40 nm axial.</p><p>9) Page 7, paragraph 7, please be more clear about parallel and serial multisynaptic connections. By parallel do you mean multiple synapses made by separate branches of branching axons? And would series mean en-passant synapses of a single stretch of axon? Please note that the SDSA pairs of Bartol et al., were always en-passant synapses of single axons on to the same dendritic branch within just a few microns, not different branches.</p><p>10) Page 9 last paragraph, please be clear about dual connections vs. SDSA pairs here.</p><p>11) Page 10 last paragraph, by separation distance do you mean along the same dendrite, different dendrites, same axon, different axons, Euclidean distance in the volume?</p><p>12) Page 11, second paragraph, why not draw random pairs from the whole set, n=1960, of synapses?</p><p>13) Discussion, paragraph 1, again please don't equate your dual connections with the SDSA pairs of Bartol et al., 2015.</p><p>14) Discussion, paragraph 3, there could also be differences in synaptic plasticity mechanisms in different brain regions and cell types, neural subcircuits, etc…</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76120.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Mechanistic claims, statistical analyses and their interpretation: please take on board reviewer's comments about the causal interpretations of these findings and adjust the claims and language in the manuscript to acknowledge that the findings are observational. In several places the writing appears to claim that statistical analyses alone can reveal causal mechanisms, which is misleading. Please revise the writing to more clearly delineate hypotheses and interpretations from empirical observations. Finally, address Reviewer #1's concern about bias in the analysis of size distribution.</p></disp-quote><p>We adjusted the language accordingly and addressed reviewer #1’s concern about bias in the analysis.</p><disp-quote content-type="editor-comment"><p>2) Potential control/comparative data: consider suggestions from Reviewer #3 for comparative analysis of other synapse types that may be available within the dataset. If these data are not readily available please provide a brief explanation in a rebuttal.</p></disp-quote><p>We included a comparison with synapses with inhibitory neurons in the dataset and extended Figure 2.</p><disp-quote content-type="editor-comment"><p>3) Literature: review the paper's treatment of previous work in line with some of the suggestions made by reviewer #2. You do not have to adopt the reviewer's interpretations of the data, but it is worth reviewing some of the suggested references to ensure the manuscript does justice to existing work and current thinking on the relationship between plasticity mechanisms and synapse size distributions.</p></disp-quote><p>We included new citations as suggested by the reviewers and adjusted the text to more reflect the reviewer’s interpretations of the data.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>I think the paper is excellent overall and I only have two comments about the wording and interpretation of some of the findings and about one part of the statistical analysis.</p><p>1. Interpretations. In several places in the manuscript the authors make statements about the findings being biologically meaningful *as opposed to being statistical observations*. The fact is there are compelling observations and sound analyses and interpretations of these observations, but this does not transform the study from being observational in nature. A key example is in the paragraph at the top of page 8:</p><p>&quot;A binary mixture model might merely be a convenient way of approximating deviations from normality. We would like to know whether the components of our binary mixture really have a biological basis, i.e., whether they correspond to two structural states of synapses. A mixture of two normal distributions can be unimodal or bimodal, depending on the model parameters3 (Robertson and Fryer, 1969). When comparing best fit unimodal and bimodal mixtures we found that a bimodal model yields a significantly superior fit for spine volume and geometric mean of spine volume (p=0.0425, n=320; Extended Data Figure 4, see (Holzmann and Vollmer, 2008) for statistical methods). This bimodality makes it plausible that the mixture components correspond to biological states of synapses.&quot;</p><p>The analyses they have performed to test for bimodality and the interpretation they have for its presence are both sound. However, the authors are saying that statistical modelling alone can reveal whether measurements &quot;really have a biological basis&quot;. It cannot. Only a further (experimental) intervention could begin to do this. I want to say very clearly that I don't think the observational nature of the study is a weak point at all. The authors should accept it is observational and describe it as such. They have produced a very compelling and sophisticated piece of science, but it is incorrect (and slightly dangerous for more naïve readers) to blur the lines between the reasoning that motivates a hypothesis, and the statistical means of evaluating evidence for it.</p></disp-quote><p>We have toned down the biological interpretation.</p><disp-quote content-type="editor-comment"><p>I would hazard a guess that the authors are aware of this issue but are dealing with the rather unscientific way our community treats/labels observational work. I think this is excellent work and it doesn't need to disguise the epistemology at all.</p><p>Finally, I'd like to point out that a bimodal distribution is still a 'continuum'. The authors don't contradict this, but they come close to contrasting continual synaptic variation with their findings in the abstract which I find potentially misleading if readers are sloppy.</p><p>2. Statistical analysis. I have a simple query about the way the authors rule out a trend between the analog component of spine volume correlation between multiple connections (Figure 4 and associated analyses).</p><p>My understanding is that they resampled from the data based on mixture component weight (i.e. preferentially sample from points close to an effective cluster) THEN perform correlation analysis on these two resampled populations.</p><p>Is this biased? i.e. would it tend to dilute residual correlation that cannot be accounted for by the binary components because it over-represents data points close to the centroids of clusters? I'm not sure, but I think they could check this through simulation very easily.</p><p>An alternative method for asking about 'analog covariation' would be to simply look at residuals of the model with the binary component subtracted, as is done in standard mixed statistical models. In this case a significant trend in the residuals would be evidence for analog covariation.</p></disp-quote><p>We re-analyzed the set of 160 synaptic pairs from dual-synaptic connections accordingly. We assigned pairs to their most likely state (SS, SL, LS, LL), subtracted the mean of the assigned state and plotted the residuals in Figure 4—figure supplement 3. We repeated this analysis while restricting assignments to SS and LL. We did not find a significant correlation in the residuals.</p><disp-quote content-type="editor-comment"><p>Finally, the pedant in me wants them to be more careful about absence of evidence not being evidence for absence, so they could tighten their language in places when describing these results in the event of a robust null finding.</p><p>Reviewer #2 (Recommendations for the authors):</p><p>1) Abstract: &quot;Previous cortical studies modelled a continuum of synapse sizes (Arellano et al., 2007)</p><p>The continuum of spine sizes has already been shown in old ssEM papers, such as Harris, K. M. and Stevens, J Neurosci 9, 2982-2997 (1989). The same applied to all the rest of the text.</p></disp-quote><p>We now cite this paper throughout the manuscript.</p><disp-quote content-type="editor-comment"><p>2) Abstract: &quot;by a log-normal distribution (Loewenstein, Kuras and Rumpel, 2011; de Vivo et al., 2017; Santuy et al. , 2018)&quot;.</p><p>These papers do not provide a rationale for a log-normal distribution of spine sizes and are misleading. There is no reason and evidence why spine distribution is log-normal. Note that the multiplicative dynamics do not simply predict a log-normal distribution. The most comprehensive review on an approximately log-normal distribution has been provided in the following review, which should be cited to help readers: Kasai, H., Ziv, N. E., Okazaki, H., Yagishita, S. and Toyoizumi, Nature reviews. Neuroscience 22, 407-422, doi:10.1038/s41583-021-00467-3 (2021).</p></disp-quote><p>We appreciate the suggested reference and added it to the manuscript. The original language “well-modeled by a log-normal distribution” has been toned down to “approximated by a log-normal distribution.”</p><p>Our original text does not mention multiplicative dynamics. We have added a footnote saying that there are dynamical models that yield approximately log-normal distributions, with a reference to the 2021 review.</p><disp-quote content-type="editor-comment"><p>3) Introduction: &quot;In the 2000s, some hypothesized that long-term plasticity involves discrete transitions of synapses between two structural states (Kasai et al., 2003; Bourne and Harris, 2007).&quot;</p><p>This sentence is wrong. None of the two papers claimed the discrete transition of synapses between two states. They describe the spines as a continuum, emphasizing that learning changes smaller spines to bigger ones, consistent with the binary and analogue variation of synapses proposed in this study.</p><p>Bistability was predicted only theoretically as winner-takes-all situations, ex. Gilson, M. and Fukai, T. PloS one 6, e25339, doi:10.1371/journal.pone.0025339 (2011).</p></disp-quote><p>We have changed the text to read, “In the 2000s, some hypothesized the existence of “learning spines” and “memory spines,” appearing to define two discrete categories that are structurally and functionally different.” We hope that this description of the two papers is accurate.</p><disp-quote content-type="editor-comment"><p>4) Page 7 &quot;Even researchers who report bimodally distributed synapse size in the hippocampus (Spano et al., 2019) still find log-normally distributed synapse size in the neocortex (de Vivo et al., 2017) by the same methods.&quot;</p><p>These statements make sense only when the spine volumes are plotted on a logarithmic scale. The authors should consider using &quot;bimodal on the semi-logarithmic scale&quot; whenever the bimodality matters. Also, by comparing Figure 3b and c, the authors should explicitly describe that the bimodality only becomes evident when a semi-logarithmic plot is used.</p></disp-quote><p>We adjusted the text in several places to now clarify that the observation of the bimodality requires the log-scale.</p><disp-quote content-type="editor-comment"><p>5) The authors should display the linear plots also for Figure 1d and 1e.</p></disp-quote><p>We added the linear plots for Figures 3d and e (Figure 3—figure supplement 1).</p><disp-quote content-type="editor-comment"><p>6) The authors should provide more detailed descriptions of the behavioural states of mice, as the results should depend on how mice were rared. Say, there should be more binary mode on a semi-logarithmic plot in mice rared in an environment enriched cage.</p></disp-quote><p>We added a description of the upbringing of the mouse to the methods section.</p><disp-quote content-type="editor-comment"><p>7) Methods section states two-photon imaging, but the study does not seem to use two-photon data.</p></disp-quote><p>We added the two-photon imaging to the methods section to give context about the experimental circumstances of the mice prior to EM acquisition to the reader. The two-photon data was not used in this paper.</p><disp-quote content-type="editor-comment"><p>8) Discussion: &quot;Experiments have shown that large dynamical fluctuations persist even after activity is pharmacologically blocked (Yasumatsu et al. , 2008; Statman et al. , 2014).&quot;</p><p>They are also supported by more recent data by Sigler et al. Neuron 94:304(2017) and Sando et al. Neuron 94:312(2017).</p></disp-quote><p>We appreciate the suggested references and added them to the manuscript.</p><disp-quote content-type="editor-comment"><p>9) Discussion: &quot;It has been argued that the observed structural volatility of synapses is challenging to reconcile with the stability of memory (Loewenstein, Kuras and Rumpel, 2011). Our findings suggest two possible resolutions of the stability-plasticity dilemma……. In a second scenario…&quot;</p><p>These discussions do not provide a resolution. As described in Kasai et al. (Nat Rev Neurosci 2021), we should be aware that most daily memories are forgotten in a few days to 1 week, and longer-lasting memories need repeated recall, as initially described by Ebbinghaus (1885). There is no stability-plasticity dilemma when we take these memory properties into account. The spine fluctuations also naturally explain the memory persistence and spine volume distributions. The author should rewrite the discussion incorporating this coherent view.</p></disp-quote><p>We have removed the sentence about “resolutions of the stability-plasticity dilemma,” which in retrospect was perhaps too sweeping a claim.</p><disp-quote content-type="editor-comment"><p>10) The authors find that the dual connections by the axons from outside the 250*140*90um volume were not bimodal in the semi-logarithmic plot (EFigure 10), suggesting that a cell assembly is more often formed within the volume than distant cortices. The authors should explicitly describe and discuss this scenario.</p></disp-quote><p>Another possible explanation is that observation of bimodality requires restricting to synapses between a particular cell type, e.g., L2/3 pyramidal neurons in this case. We have added a new paragraph to clarify this idea.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>1) In the Abstract it would helpful to state the animal and cortical region studied and the size of the dataset (volume, number of connections).</p></disp-quote><p>We added volume, region, animal and number information to the abstract.</p><disp-quote content-type="editor-comment"><p>2) Near the end of Abstract, perhaps give a few examples of the &quot;other influences&quot; that contribute to the analog variation of synapse size in dual connections.</p><p>3) At the end of the Abstract, &quot;stability-plasticity dilemma&quot; might be a bit vague for some readers.</p></disp-quote><p>We replaced this sentence with “implications for the longstanding hypothesis that activity-dependent plasticity switches synapses between bistable states.”</p><disp-quote content-type="editor-comment"><p>4) In Introduction, first paragraph, &quot;Spine dynamics were interpreted as synaptic plasticity&quot; is an odd statement since &quot;dynamics&quot; means change and &quot;plasticity&quot; means change. Please reword.</p></disp-quote><p>We see the reviewers' concern about redundant phrasing. In this sentence we linked the terms “dynamic” and “plasticity” to different structures.</p><disp-quote content-type="editor-comment"><p>5) In Introduction, paragraph 4, the authors seem to equate their definition of &quot;paired connections&quot; (or &quot;dual connections&quot;) with that used in Bartol et al., 2015. The authors should clearly define their use of the term &quot;paired (or dual) connection&quot; and the definition of &quot;Same Dendrite, Same Axon pairs (SDSA pairs)&quot; used in Bartol et al., 2015. This distinction is important and could explain some of the differences observed in their new results here compared to the earlier observations in the literature.</p><p>6) Bartol et al. 2015 showed that the sizes of SDSA pairs in hippocampus are highly correlated along the whole continuum with no binary component. Which differs from the authors' results. This difference is interesting for further discussion.</p><p>7) Introduction paragraph 5, please be specific about the &quot;specificity of the synaptic population&quot;. Please state again that these are connections between L2/3 PyCs. Also, again Bartol et al. 2015 showed strong corellation in the continuum among all SDSA pairs, from smallest to largest, though in Rat hippocampus, not Mouse neocortex.</p></disp-quote><p>We thank the reviewer for highlighting the problem of ambiguity when comparing the work of Bartol et al.. We now differentiate our work from previous work more clearly by clarifying the difference in the studied synapse populations.</p><disp-quote content-type="editor-comment"><p>8) Handling of Image Defects. In discussing the defects it helps the reader to give the xyz resolution of the ssEM images here. 3.58 nm in plane, 40 nm axial.</p></disp-quote><p>We added the resolution to the text as suggested.</p><disp-quote content-type="editor-comment"><p>9) Page 7, paragraph 7, please be more clear about parallel and serial multisynaptic connections. By parallel do you mean multiple synapses made by separate branches of branching axons? And would series mean en-passant synapses of a single stretch of axon? Please note that the SDSA pairs of Bartol et al., were always en-passant synapses of single axons on to the same dendritic branch within just a few microns, not different branches.</p></disp-quote><p>We clarified this in the text.</p><disp-quote content-type="editor-comment"><p>10) Page 9 last paragraph, please be clear about dual connections vs. SDSA pairs here.</p></disp-quote><p>We clarified this in the text.</p><disp-quote content-type="editor-comment"><p>11) Page 10 last paragraph, by separation distance do you mean along the same dendrite, different dendrites, same axon, different axons, Euclidean distance in the volume?</p></disp-quote><p>We clarified this in the text. We referred to the median euclidean distance in the volume.</p><disp-quote content-type="editor-comment"><p>12) Page 11, second paragraph, why not draw random pairs from the whole set, n=1960, of synapses?</p></disp-quote><p>Unfortunately, we could not find out what part of the analysis this comment is referring to.</p><disp-quote content-type="editor-comment"><p>13) Discussion, paragraph 1, again please don't equate your dual connections with the SDSA pairs of Bartol et al., 2015.</p></disp-quote><p>We incorporated this comment by weakening the comparative language.</p><disp-quote content-type="editor-comment"><p>14) Discussion, paragraph 3, there could also be differences in synaptic plasticity mechanisms in different brain regions and cell types, neural subcircuits, etc…</p></disp-quote><p>We thank the reviewers for their feedback and suggestions!</p></body></sub-article></article>