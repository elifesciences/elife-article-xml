<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">55490</article-id><article-id pub-id-type="doi">10.7554/eLife.55490</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Lapses in perceptual decisions reflect exploration</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-174587"><name><surname>Pisupati</surname><given-names>Sashank</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0923-0585</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-174586"><name><surname>Chartarifsky-Lynn</surname><given-names>Lital</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2446-9842</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-174588"><name><surname>Khanal</surname><given-names>Anup</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8929-7984</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-18851"><name><surname>Churchland</surname><given-names>Anne K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3205-3794</contrib-id><email>AChurchland@mednet.ucla.edu</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Cold Spring Harbor Laboratory, Cold Spring Harbor</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>CSHL School of Biological Sciences, Cold Spring Harbor</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>University of California, Los Angeles</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Lee</surname><given-names>Daeyeol</given-names></name><role>Reviewing Editor</role><aff><institution>Johns Hopkins University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>11</day><month>01</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e55490</elocation-id><history><date date-type="received" iso-8601-date="2020-01-26"><day>26</day><month>01</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-01-10"><day>10</day><month>01</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Pisupati et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Pisupati et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-55490-v2.pdf"/><abstract><p>Perceptual decision-makers often display a constant rate of errors independent of evidence strength. These ‘lapses’ are treated as a nuisance arising from noise tangential to the decision, e.g. inattention or motor errors. Here, we use a multisensory decision task in rats to demonstrate that these explanations cannot account for lapses’ stimulus dependence. We propose a novel explanation: lapses reflect a strategic trade-off between exploiting known rewarding actions and exploring uncertain ones. We tested this model’s predictions by selectively manipulating one action’s reward magnitude or probability. As uniquely predicted by this model, changes were restricted to lapses associated with that action. Finally, we show that lapses are a powerful tool for assigning decision-related computations to neural structures based on disruption experiments (here, posterior striatum and secondary motor cortex). These results suggest that lapses reflect an integral component of decision-making and are informative about action values in normal and disrupted brain states.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>vision</kwd><kwd>audition</kwd><kwd>computational modeling</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000183</institution-id><institution>Army Research Office</institution></institution-wrap></funding-source><award-id>W911NF-16-1-0368</award-id><principal-award-recipient><name><surname>Pisupati</surname><given-names>Sashank</given-names></name><name><surname>Chartarifsky-Lynn</surname><given-names>Lital</given-names></name><name><surname>Khanal</surname><given-names>Anup</given-names></name><name><surname>Churchland</surname><given-names>Anne K</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 EY022979</award-id><principal-award-recipient><name><surname>Churchland</surname><given-names>Anne K</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>During perceptual decision-making, some errors on easy decisions (lapses) are not simply mistakes, but instead reflect strategic decisions to explore actions associated with uncertain rewards.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Perceptual decisions are often modeled using noisy ideal observers (e.g., Signal detection theory, <xref ref-type="bibr" rid="bib28">Green and Swets, 1966</xref>; Bayesian decision theory, <xref ref-type="bibr" rid="bib13">Dayan and Daw, 2008</xref>) that explain subjects’ errors as a consequence of noise in sensory evidence. This predicts an error rate that decreases with increasing sensory evidence, capturing the sigmoidal relationship often seen between evidence strength and subjects’ decision probabilities (i.e. the psychometric function).</p><p>Human and nonhuman subjects often deviate from these predictions, displaying an additional constant rate of errors independent of the evidence strength known as ‘lapses’, leading to errors even on extreme stimulus levels (<xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>; <xref ref-type="bibr" rid="bib9">Busse et al., 2011</xref>; <xref ref-type="bibr" rid="bib27">Gold and Ding, 2013</xref>; <xref ref-type="bibr" rid="bib10">Carandini and Churchland, 2013</xref>). Despite the knowledge that ignoring or improperly fitting lapses can lead to serious mis-estimation of psychometric parameters (<xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>; <xref ref-type="bibr" rid="bib49">Prins and Kingdom, 2018</xref>), the cognitive mechanisms underlying lapses remain poorly understood. A number of possible sources of noise have been proposed to explain lapses, typically tangential to the decision-making process.</p><p>One class of explanations for lapses relies on pre-decision noise added due to fluctuating attention, which is often operationalized as a small fraction of trials on which the subject fails to attend to the stimulus (<xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>). On these trials, it is assumed that the subject cannot specify the stimulus (i.e. sensory noise with infinite variance, <xref ref-type="bibr" rid="bib5">Bays et al., 2009</xref>) and hence guesses randomly or in proportion to prior beliefs. This model can be thought of as a limiting case of the Variable Precision model, which assumes that fluctuating attention has a more graded effect of scaling the sensory noise variance (<xref ref-type="bibr" rid="bib24">Garrido et al., 2011</xref>), giving rise to heavy tailed estimate distributions, resembling lapses in the limit of high variability (<xref ref-type="bibr" rid="bib55">Shen and Ma, 2019</xref>; <xref ref-type="bibr" rid="bib69">Zhou et al., 2018</xref>). Temporal forms of inattention have also been proposed to give rise to lapses, where the animal ignores early or late parts of the evidence (impulsive or leaky integration, <xref ref-type="bibr" rid="bib18">Erlich et al., 2015</xref>).</p><p>An alternative class of explanations for lapses relies on a fixed amount of noise added after a decision has been made, commonly referred to as ‘post-categorization’ noise (<xref ref-type="bibr" rid="bib18">Erlich et al., 2015</xref>) or decision noise (<xref ref-type="bibr" rid="bib33">Law and Gold, 2009</xref>). Such noise could arise from errors in motor execution (e.g. finger errors, <xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>), non-stationarities in the decision rule arising from computational imprecision (<xref ref-type="bibr" rid="bib21">Findling et al., 2018</xref>), suboptimal weighting of choice or outcome history (<xref ref-type="bibr" rid="bib53">Roy et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">Busse et al., 2011</xref>), or random variability added for the purpose of exploration (e.g. ‘ε-greedy’ decision rules).</p><p>A number of recent observations have cast doubt on fixed early- or late-stage noise as satisfactory explanations for lapses. For instance, many of these explanations predict that lapses should occur at a constant rate, while in reality, lapses are known to reduce in frequency with learning in nonhuman primates (<xref ref-type="bibr" rid="bib33">Law and Gold, 2009</xref>; <xref ref-type="bibr" rid="bib12">Cloherty et al., 2019</xref>). Further, they can occur with different frequencies for different stimuli even within the same subject (in rodents, <xref ref-type="bibr" rid="bib43">Nikbakht et al., 2018</xref>; and humans, <xref ref-type="bibr" rid="bib42">Mihali et al., 2018</xref>; <xref ref-type="bibr" rid="bib7">Bertolini et al., 2015</xref>; <xref ref-type="bibr" rid="bib22">Flesch et al., 2018</xref>), suggesting that they may reflect task-specific, associative processes that can vary within a subject.</p><p>Lapse frequencies are even more variable across subjects and can depend on the subject’s age and state of brain function. For instance, lapses are significantly higher in children and patient populations than in healthy adult humans (<xref ref-type="bibr" rid="bib52">Roach et al., 2004</xref>; <xref ref-type="bibr" rid="bib65">Witton et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Manning et al., 2018</xref>). Moreover, a number of recent studies in rodents have found that perturbing neural activity in secondary motor cortex (<xref ref-type="bibr" rid="bib18">Erlich et al., 2015</xref>) and striatum (<xref ref-type="bibr" rid="bib66">Yartsev et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Guo et al., 2018</xref>) has dramatic, asymmetric effects on lapses in auditory decision-making tasks. Because these perturbations were made in structures known to be involved in action selection, an intriguing possibility is that lapses reflect an integral part of the decision-making process, rather than a peripheral source of noise. However, because these studies only tested auditory stimuli, they did not afford the opportunity to distinguish sensory modality-specific deficits from general decision-related deficits. Taken together, these observations point to the need for a deeper understanding of lapses that accounts for effects of stimulus set, learning, age, and neural perturbations.</p><p>Here, we leverage a multisensory decision-making task in rodents to reveal the inadequacy of traditional models. We challenge a key assumption of perceptual decision-making theories, i.e. subjects’ perfect knowledge of expected rewards (<xref ref-type="bibr" rid="bib13">Dayan and Daw, 2008</xref>), to uncover a novel explanation for lapses: uncertainty-guided exploration, a well-known strategy for balancing exploration and exploitation in value-based decisions. We test the predictions of the exploration model for perceptual decisions by manipulating the magnitude and probability of reward under conditions of varying uncertainty. Finally, we demonstrate that suppressing secondary motor cortex or posterior striatum unilaterally has an asymmetric effect on lapses that generalizes across sensory modalities, but only in uncertain conditions. This can be accounted for by an action value deficit contralateral to the inactivated side, reconciling the proposed perceptual and value-related roles of these areas and suggesting that lapses are informative about the subjective values of actions, reflecting a core component of decision-making.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Testing ideal observer predictions in perceptual decision-making</title><p>We leveraged an established decision-making task (<xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Sheppard et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Licata et al., 2017</xref>) in which freely moving rats judge whether the fluctuating rate of a 1000 ms series of auditory clicks and/or visual flashes (rate range: 9–16 Hz) is high or low compared with an abstract category boundary of 12.5 Hz (<xref ref-type="fig" rid="fig1">Figure 1a–c</xref>). Using Bayesian decision theory, we constructed an ideal observer for our task that selects choices that maximize expected reward (see Materials and methods: Modeling). To test whether behavior matches ideal observer predictions, we presented multisensory trials with matched visual and auditory rates (i.e., both modalities carried the same number of events per second; <xref ref-type="fig" rid="fig1">Figure 1c</xref>, bottom) interleaved with visual-only or auditory-only trials. This allowed us to separately estimate the sensory noise in the animal’s visual and auditory system, and compare the measured performance on multisensory trials to the predictions of the ideal observer.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Testing ideal observer predictions in perceptual decision-making.</title><p>(<bold>a</bold>) Schematic drawing of rate discrimination task. Rats initiate trials by poking into a center port. Trials consist of visual stimuli presented via a panel of diffused LEDs, auditory stimuli presented via a centrally positioned speaker, or multisensory stimuli presented from both. Rats are rewarded with a 24 μL drop of water for reporting high-rate stimuli (greater than 12.5 Hz) with rightward choices and low-rate stimuli (lower than 12.5 Hz) with leftward choices. (<bold>b</bold>) Timeline of task events. (<bold>c</bold>) Example stimulus on auditory (top), visual (middle), and multisensory trials (bottom). Stimuli consist of a stream of events separated by long (100 ms) or short (50 ms) intervals. Multisensory stimuli consist of visual and auditory streams carrying the same underlying rate. Visual, auditory, and multisensory trials were randomly interleaved (40% visual, 40% auditory, and 20% multisensory). (<bold>d</bold>) Schematic outlining the computations of a Bayesian ideal observer. Stimulus belonging to a true category <italic>c</italic> with a true underlying rate <italic>s</italic> gives rise to noisy observations <inline-formula><mml:math id="inf1"><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:msub><mml:mi>x</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>, which are then integrated with each other and with prior beliefs to form a multisensory posterior belief about the category, and further combined with reward information to form expected action values <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The ideal observer selects the action <inline-formula><mml:math id="inf4"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> with maximum expected value. Lightning bolts denote proposed sources of noise that can give rise to (red) or exacerbate (gray) lapses, causing deviations from the ideal observer. (<bold>e</bold>) Posterior beliefs on an example trial assuming flat priors. Solid black line denotes true rate, and blue and green dotted lines denote noisy visual and auditory observations, with corresponding unisensory posteriors shown in solid blue and green. Solid red denotes the multisensory posterior, centered around the maximum a posteriori rate estimate in dotted red. Shaded fraction denotes the probability of the correct choice being rightward, with μ denoting the category boundary. (<bold>f</bold>) Ideal observer predictions for the psychometric curve, that is, proportion of high-rate choices for each rate. Inverse slopes of the curves in each condition are reflective of the posterior widths on those conditions, assuming flat priors. The value on the abscissa corresponding to the curve’s midpoint indicates the subjective category boundary, assuming equal rewards and flat priors.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig1-v2.tif"/></fig><p>Performance was assessed using a psychometric curve, that is, the probability of high-rate decisions as a function of stimulus rate (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). The ideal observer model predicts a relationship between the slope of the psychometric curve and noise in the animal’s estimate: the higher the standard deviation (σ) of sensory noise, the more uncertain the animal’s estimate of the rate and the shallower the psychometric curve. On multisensory trials, the ideal observer should have a more certain estimate of the rate (<xref ref-type="fig" rid="fig1">Figure 1e</xref>, visual [blue] and auditory [green] σ values are larger than multisensory σ [red]), driving a steeper psychometric curve (<xref ref-type="fig" rid="fig1">Figure 1f</xref>, red curve is steeper than green and blue curves). Since this model does not take lapses into account, it would predict perfect performance on the easiest stimuli on all conditions, and thus all curves should asymptote at 0 and 1 (<xref ref-type="fig" rid="fig1">Figure 1f</xref>).</p></sec><sec id="s2-2"><title>Lapses cause deviations from ideal observer and are reduced on multisensory trials</title><p>In practice, the shapes of empirically obtained psychometric curves do not perfectly match the ideal observer (<xref ref-type="fig" rid="fig2">Figure 2</xref>) since they asymptote at values that are less than 1 or greater than 0. This is a well-known phenomenon in psychophysics (<xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>), requiring two additional lapse parameters to precisely capture the asymptotes. To account for lapses, we fit a four-parameter psychometric function to the subjects’ choice data (<xref ref-type="fig" rid="fig2">Figure 2a</xref> – red, <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> in Materials and methods) with the Palamedes toolbox (<xref ref-type="bibr" rid="bib49">Prins and Kingdom, 2018</xref>). γ and λ are the lower and upper asymptotes of the psychometric function, which parameterize lapses on low and high rates respectively; <inline-formula><mml:math id="inf5"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> is a sigmoidal function, in our case the cumulative normal distribution; <italic>x</italic> is the event rate, that is, the average number of flashes or beeps presented during the 1 s stimulus period; μ parameterizes the midpoint of the psychometric function and σ describes the inverse slope after correcting for lapses.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Deviations from ideal observer reflect lapses in judgment.</title><p>(<bold>a</bold>) Schematic psychometric performance of an ideal observer (black) vs. a model that includes lapses (red). The ideal observer model includes two parameters: midpoint (μ) and inverse slope (σ). The four-parameter model includes μ, σ, and lapse probabilities for low-rate (γ) and high-rate choices (λ). Dotted line shows the true category boundary (12.5 Hz). (<bold>b</bold>) Subject data was fit with a two-parameter model without lapses (black) and a four-parameter model with lapses (red). (<bold>c and d</bold>) Ideal observer predictions vs. measured multisensory sigma for fits with and without variable lapses across conditions. (<bold>c</bold>) Multisensory integration seems supra-optimal if lapses are not accounted for (no lapses, black), fixed across conditions (fixed lapses, purple), or assumed to be less than 0.1 (restricted lapses, yellow). (<bold>d</bold>) Optimal multisensory integration is restored when allowing lapses to vary freely across conditions (n = 17 rats. Points represent individual rats. Data points that lie on the unity line represent cases in which the measured sigma was equal to the optimal prediction). (<bold>e</bold>) Rats’ psychometric curves on auditory (green), visual (blue), and multisensory (red) trials. Points represent data pooled across 17 rats, and lines represent separate four-parameter fits to each condition. (<bold>f</bold>) Fit values of sigma (top) and lapse parameters (bottom) on unisensory and multisensory conditions. Both parameters showed significant reduction on the multisensory conditions (paired t-test, p&lt;0.05); n = 17 rats (347,537 trials). (<bold>g</bold>) Model comparison using Bayes Information Criterion (pink) and Akaike Information Criterion (blue) for fits to pooled data across subjects (top) and to individual subject data (bottom). Lower scores indicate better fits. Both metrics favor a model where lapses are allowed to vary freely across conditions (‘Variable lapse’) over one without lapses (‘No lapses’), one with a fixed probability of lapses (‘Fixed lapse’), or where the lapses are restricted to being less than 0.1 (‘Restricted lapse’).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig2-v2.tif"/></fig><p>How can we be sure that the asymptotes seen in the data truly reflect nonzero asymptotes rather than fitting artifacts or insufficient data at the asymptotes? To test whether lapses were truly necessary to explain the behavior, we fit the curves with and without lapses (<xref ref-type="fig" rid="fig2">Figure 2b</xref>) and tested whether the lapse parameters were warranted. The fit without lapses was rejected in 15/17 rats by the Bayes Information Criterion (BIC) and in all rats by the Akaike Information Criterion (AIC). Fitting a fixed lapse rate across conditions was not sufficient to capture the data, nor was fitting a lapse rate that was constrained to be less than 0.1 (<xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>). Both data pooled across subjects and individual subject data warranted fitting separate lapse rates to each condition (‘variable lapses’ model outperforms ‘fixed lapses’, ‘restricted lapses’ or ‘no lapses’ in 13/17 individuals based on BIC, all individuals based on AIC and in pooled data based on both, <xref ref-type="fig" rid="fig2">Figure 2g</xref>).</p><p>Multisensory trials offer an additional, strong test of ideal observer predictions. In addition to perfect performance on the easiest stimuli, the ideal observer model predicts the minimum possible perceptual uncertainty achievable on multisensory trials through optimal integration (<xref ref-type="bibr" rid="bib19">Ernst and Bülthoff, 2004</xref>; <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> in Materials and methods). By definition, better-than-optimal performance is impossible. However, studies in humans, rodents, and nonhuman primates performing multisensory decision-making tasks suggest that in practice, performance occasionally exceeds optimal predictions (<xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>; <xref ref-type="bibr" rid="bib43">Nikbakht et al., 2018</xref>; <xref ref-type="bibr" rid="bib30">Hou et al., 2018</xref>), seeming, at first, to violate the ideal observer model. Moreover, in these data sets, performance on the easiest stimuli was not perfect and asymptotes deviated from 0 and 1. As in these previous studies, when we fit performance without lapses, multisensory performance was significantly supra-optimal (p=0.0012, paired t-test), i.e. better than the ideal observer prediction (<xref ref-type="fig" rid="fig2">Figure 2c</xref>, black points are above the unity line). This was also true when lapse probabilities were assumed to be fixed across conditions (p=0.0018, <xref ref-type="fig" rid="fig2">Figure 2c</xref>, purple) or when they were assumed to be less than 0.1 (p=0.0003, <xref ref-type="fig" rid="fig2">Figure 2c</xref>, yellow). However, when we allowed lapses to vary freely across conditions, performance was indistinguishable from optimal (<xref ref-type="fig" rid="fig2">Figure 2d</xref>, data points are on the unity line). This reaffirms that proper treatment of lapses is crucial for accurate estimation of perceptual parameters and offers a potential explanation for previous reports of supra-optimality.</p><p>Using this improved fitting method, we replicated previous observations <xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref> showing that animals have improved sensitivity (lower σ) on multisensory vs. unisensory trials (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, red curve is steeper than green/blue curves; <xref ref-type="fig" rid="fig2">Figure 2f</xref>, top). Interestingly, we observed that animals also had a lower lapse probability (<inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula>) on multisensory trials (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, asymptotes for red curve are closer to 0 and 1; n = 17 rats, 347,537 trials). This was consistently observed across animals (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, bottom; the probability of lapses on multisensory trials was 0.06 on average, compared to 0.17 on visual, p=1.4e-4 and 0.21 on auditory, p=1.5e-5). We also noticed that compared to unisensory trials, multisensory trials were slightly biased toward high rates. This bias may reflect that animals’ decisions do not exclusively depend on the rate of events, but are additionally weakly influenced by the total event count, as has been previously reported on a visual variant of the task (<xref ref-type="bibr" rid="bib44">Odoemene et al., 2018</xref>).</p></sec><sec id="s2-3"><title>Uncertainty-guided exploration offers a novel explanation for lapses where traditional explanations fail</title><p>What could account for the reduction in lapse probability on multisensory trials? While adding extra parameters to the ideal observer model fit the behavioral data well and accurately captured the reduction in inverse-slope on multisensory trials, this success does not provide an explanation for why lapses are present in the first place, nor why they differ between stimulus conditions.</p><p>To investigate this, we examined possible sources of noise that have traditionally been invoked to explain lapses (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). The first of these explanations is that lapses might be due to a fixed amount of noise added once the decision has been made. These sources of noise could include decision noise due to imprecision (<xref ref-type="bibr" rid="bib21">Findling et al., 2018</xref>) or motor errors (<xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>). However, these sources should hinder decisions equally across stimulus conditions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref>), which cannot explain our observation of condition-dependent lapse rates (<xref ref-type="fig" rid="fig2">Figure 2f</xref>).</p><p>A second explanation is that lapses arise due to inattention on a small fraction of trials. Inattention would drive the animal to guess randomly, producing lapse rates whose sum should reflect the probability of not attending (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, Materials and methods). According to this explanation, the lower lapse rate on multisensory trials could reflect increased attention on those trials, perhaps due to their increased bottom-up salience (i.e. two streams of stimuli instead of one). To examine this possibility, we leveraged a multisensory condition that has been used to manipulate perceptual uncertainty without changing salience in rats and humans (<xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>). Specifically, we interleaved standard matched-rate multisensory trials with ‘neutral’ multisensory trials for which the rate of the auditory stimuli ranged from 9 to 16 Hz, while the visual stimuli was always 12 Hz. This rate was so close to the category boundary (12.5 Hz) that it did not provide compelling evidence for one choice or the other (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, left), thus reducing the information in the multisensory stimulus and increasing perceptual uncertainty on ‘neutral’ trials. However, since both ‘neutral’ and ‘matched’ conditions are multisensory, they should be equally salient, and since they are interleaved, the animal would be unable to identify the condition without actually attending to the stimulus. According to the inattention model, matched and neutral trials should have the same rate of lapses, only differing in their inverse-slope σ (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Uncertainty-guided exploration offers a novel explanation for lapses.</title><p>Models of lapses in decision-making: (<bold>a</bold>) Inattention model of lapses. Left panel: Observer’s posterior belief about rate. On a large fraction of trials given by <inline-formula><mml:math id="inf7"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the observer attends to the stimulus and has a peaked belief about the rate whose width reflects perceptual uncertainty (red curve on matched trials, orange curve on neutral trials), but on a small fraction of trials given by <inline-formula><mml:math id="inf8"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the observer does not attend to the stimulus (black curve), leading to equal posterior beliefs of rates being high or low (shaded, clear regions of curves respectively) and guesses according to the probability <inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>, giving rise to lapses (right panel). The sum of lapse rates then reflects <inline-formula><mml:math id="inf10"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, while their ratio reflects the <inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>. Since matched and neutral trials are equally salient, they are expected to have the same <inline-formula><mml:math id="inf12"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and hence similar overall lapse rates. (<bold>b</bold>) Fixed error model of lapses. Lapses could arise due to motor errors occurring on ε fraction of trials, or from decision rules that explore on a fixed proportion ε of trials (black), rather than always maximizing reward (blue). The sum of lapses reflects ε while their ratio reflects any <inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> in motor errors or exploration, leading to a fixed rate of lapses across conditions. (<bold>c</bold>) Uncertainty-guided exploration model. Lapses can also arise from more sophisticated exploratory decision rules such as the ‘softmax’ decision rule. Since the difference in expected value from right and left actions (<inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) is bounded by the maximum reward magnitudes <inline-formula><mml:math id="inf15"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf16"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, even when the stimulus is very easy, the maximum probability of choosing the higher value option is not 1, giving rise to lapses. Lapse rates on either side are then proportional to the reward magnitude on that side, and to a ‘temperature’ parameter β that is modulated by the uncertainty in action values. Conditions with higher overall perceptual uncertainty (e.g. neutral, orange) are expected to have higher value uncertainty, and hence higher lapses. (<bold>d</bold>) Left: multisensory stimuli designed to distinguish between attentional and non-attentional sources of lapses. Standard multisensory stimuli with matched visual and auditory rates (top) and ‘neutral’ stimuli where one modality has a rate very close to the category boundary and is uninformative (bottom). Both stimuli are multisensory and designed to have equal bottom-up salience, and can only be distinguished by attending to them and accumulating evidence. Right: rat performance on interleaved matched (red) and neutral (orange) trials. (<bold>e</bold>) Model fits (solid lines) overlaid on average data points. Deviations from model fits are denoted with arrows. The exploration model (bottom) provides a better fit than the inattention model (top), since it predicts higher lapse rates on neutral trials (orange). (<bold>f</bold>) Model comparison using Bayes Information Criterion (pink) and Akaike Information Criterion (blue) both favor the uncertainty-guided exploration model for pooled data (top) as well as individual subject data (bottom).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Uncertainty-dependent exploration is the only model that accounts for behavioral data from all three manipulations.</title><p>Columns: data/predictions for three experimental manipulations. Left: unisensory (blue, green) vs. multisensory (red). Middle: matched (red) vs. neutral (orange) multisensory. Right: increased (green) or decreased (red) rightward reward vs. equal reward (black) on auditory trials. (<bold>a–d</bold>): Four candidate models. (<bold>a</bold>) Ideal observer model predicts no lapses and only changes in sensitivity/bias across conditions. (<bold>b</bold>) Fixed motor error model predicts a constant rate of lapses across conditions in addition to changes in sensitivity/bias predicted from the ideal observer. (<bold>c</bold>) Inattention model predicts that the overall lapse rate (sum of lapses on both sides) depends on the level of bottom-up attentional salience, allowing for different rates for unisensory and multisensory trials. It also predicts that the lapse rate on neutral trials should be equal to that on multisensory trials, and that manipulating rightward reward should affect both lapse rates. (<bold>d</bold>) Uncertainty-dependent exploration model predicts that overall lapse rate depends on the level of exploratoriness and hence uncertainty associated with that condition, allowing for different lapse rates on unisensory and multisensory trials. It also predicts that the lapse rate on neutral trials should be equal to that on auditory trials and manipulating rightward reward should only affect high-rate lapses. (<bold>e</bold>) Data from an example rat on all three manipulations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Thompson sampling, which balances exploration and exploitation, predicts lapses that increase with perceptual noise.</title><p>(<bold>a</bold>) Formulation of perceptual decision-making task as a partially observable contextual bandit. To solve this task, an observer needs to infer the true category of the stimulus (Low or High) based on noisy observations, and pick the best action given the inferred category (Left for Low, Right for High). This requires accurately learning the expected rewards from all four state-action pairs. (<bold>b</bold>) Schematic illustrating the explore–exploit tradeoff: Leftward state-action value beliefs i.e. expected reward from leftward actions (L) performed in different states (Hi, Lo) showing different levels of uncertainty depending on policy. Beliefs are updated based on outcomes using a Bayesian update rule that takes into account uncertainty in state estimation. A greedy policy (top left) that always picks the best action maximizes reward and learns well about the preferred state-action pairs (i.e. Lo-L) but has high uncertainty about the non-preferred pairs (Hi–L). A random policy (top right) earns reward at chance, but learns equally well about all state-action pairs. An ε-greedy policy (bottom left) learns well about the non-preferred pair, but leaves the choice of ε unspecified, and continues exploring even after it has learnt the values well, continuing to forego rewards. Thompson sampling (bottom right) tunes the amount of exploration to the current uncertainties in each value, and balances immediately reward-maximizing decisions with decisions that reduce uncertainty, maximizing average reward in the long term. (<bold>c</bold>) Cumulative regret, i.e. foregone reward accrued by different policies on the rate discrimination task as a function of training, with lower regret being more desirable. Black – random exploration, Pink – greedy, Purple – ε-greedy, and Yellow – Thompson sampling. Thompson sampling outperforms all other policies by achieving the minimum regret. (<bold>d</bold>) Learnt beliefs about expected reward with Thompson sampling at various levels of perceptual uncertainty. Low levels of sensory noise (left top) produce more separable beliefs, while higher levels of sensory noise (left bottom) lead to large perceptual uncertainty, yielding highly overlapping belief distributions owing to a reduced ability to assign obtained rewards to one of the states. (Right) Simulated performance averaged across 2000 trials of the Bayesian observer, under a Thompson sampling policy. The observer makes fewer exploratory choices for lower levels of sensory noise (orange) owing to the more separable value beliefs, giving rise to lower lapse rates. (<bold>e</bold>) Session-averaged lapse rates as a function of sensory noise in simulations (left, center) and multisensory rat data (right). Simulations were done under increasing levels of sensory noise (colors going from hot to cold) under beliefs that action values are stationary (left) or non-stationary (center), solid lines indicate linear best-fit. Individual rat data was fit with a constrained version of the exploration model where total lapse rate was constrained to be linearly related to sensory noise across all modality conditions (auditory – green, multisensory – red, and visual – blue). Lines indicate best fit linear constraints for each rat. (<bold>f</bold>) Learnt beliefs about expected reward with Thompson sampling during early (left top) and late (left bottom) stages of training. Training reduces uncertainty about expected rewards, producing more separable beliefs and yielding less exploration and lower lapse rates over time (right – simulated average performance). (<bold>g</bold>) Session-wise lapse rates in simulated (left, center) and rat data (right) as a function of both training and sensory noise. Simulations show decreasing lapse rates over training that asymptote at zero under stationary beliefs (left) and to nonzero values dictated by sensory noise under non-stationary beliefs (center). Rat data was separated by session starting from the earliest day of training with all three modalities, and combined across rats to produce session-wise fits, and the resulting lapse rates were fit with an exponential curve for each modality (solid lines indicate best-fit curves for multisensory – red, visual – blue, and auditory – green).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Uncertainty guided exploration outperforms competing models for average and individual data.</title><p>(<bold>a</bold>) Fits of the four models (ideal observer, fixed motor error, inattention, and exploration) to average rat data on unisensory (blue – visual, green – auditory) and multisensory (red) trials. (<bold>b</bold>) Exploration model fits to unisensory and multisensory data for 17 individual animals. (<bold>c</bold>) Model comparison for individual animals using Bayes Information Criterion (BIC; left), Akaike Information Criterion (AIC; right) of the four aforementioned models, plus a constrained version of the exploration model corresponding to Thompson sampling. Darker colors are lower BICs/AICs, denoting a better fit. (<bold>d</bold>) Summed model comparison metrics across animals, showing that inattention and exploration models fit the data equally well, and much better than the ideal observer or fixed error models. Thompson sampling is preferred by BIC, since it fits as well as exploration model but with fewer effective parameters. (<bold>e</bold>) Fits of the four models to average data including neutral trials (orange) provide a stronger test of the inattention model. (<bold>f</bold>) Exploration model fits to multisensory data including neutral trials for five individual animals. (<bold>g</bold>) Model comparison for individual animals. (<bold>h</bold>) Summed model comparison metrics across animals shows that the uncertainty-guided exploration model performs better than other models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig3-figsupp3-v2.tif"/></fig></fig-group><p>Contrary to this prediction, we observed higher lapse rates in the ‘neutral’ condition, where trials had higher perceptual uncertainty on average, compared to the ‘matched’ condition (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). This correlation between the average perceptual uncertainty in a condition and its frequency of lapses was reminiscent of the correlation observed while comparing unisensory and multisensory trials (<xref ref-type="fig" rid="fig2">Figure 2e,f</xref>; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1e</xref>).</p><p>Having observed that traditional explanations of lapses fail to account for the behavioral observations, we re-examined a key assumption of ideal observer models used in perceptual decision-making – that subjects have complete knowledge about the rules and rewards (<xref ref-type="bibr" rid="bib13">Dayan and Daw, 2008</xref>). In general, this assumption may not hold true for a number of reasons – even when the stimulus category is known with certainty, subjects might have uncertainty about the values of different actions because they are still in the process of learning (<xref ref-type="bibr" rid="bib33">Law and Gold, 2009</xref>), because they incorrectly assume that their environment is nonstationary (<xref ref-type="bibr" rid="bib67">Yu and Cohen, 2008</xref>), or because they forget over time (<xref ref-type="bibr" rid="bib25">Gershman, 2015</xref>; <xref ref-type="bibr" rid="bib16">Drugowitsch and Pouget, 2018</xref>). In such situations, rather than always ‘exploiting’ (i.e. picking the action currently assumed to have the highest value), it is advantageous to ‘explore’ (i.e. occasionally pick actions whose value the subject is uncertain about), in order to gather more information and maximize reward in the long term (<xref ref-type="bibr" rid="bib13">Dayan and Daw, 2008</xref>). Exploratory choices of the lower value action for the easiest stimuli would resemble lapses, and the sum of lapses would reflect the overall degree of exploration.</p><p>Choosing how often to explore is challenging and requires trading off immediate rewards for potential gains in information – random exploration would reward subjects at chance, but would reduce uncertainty uniformly about the value of all possible stimulus-action pairs, while a greedy policy (i.e. always exploiting) would yield many immediate rewards while leaving lower value stimulus-action pairs highly uncertain (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a,b</xref>). Policies that explore randomly on a small fraction of trials (e.g. ‘ε-Greedy’ policies) do not make prescriptions about how often the subject should explore, and are behaviorally indistinguishable from motor errors when the fraction is fixed (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). One elegant way to automatically balance exploration and exploitation is to explore more often when one is more uncertain about action values. In particular, a form of uncertainty-guided exploration called Thompson sampling is asymptotically optimal in many general environments (<xref ref-type="bibr" rid="bib36">Leike et al., 2016</xref>), achieving lower regret than other forms of exploration (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c</xref>). This can be thought of as a dynamic ‘softmax’ policy (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), whose ‘inverse temperature’ parameter (β) scales with uncertainty (<xref ref-type="bibr" rid="bib26">Gershman, 2018</xref>). This predicts a lower β when values are more uncertain, encouraging more exploration and more frequent lapses, and a higher β when values are more certain, encouraging exploitation. The limiting case of perfect knowledge (<inline-formula><mml:math id="inf17"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></inline-formula>) reduces to the reward-maximizing ideal observer.</p><p>Subjects’ uncertainty about stimulus-action values is compounded by perceptual uncertainty – on trials where the stimulus category is not fully known, credit cannot be unambiguously assigned to one stimulus-action pair when rewards are obtained and value uncertainty is only marginally reduced. Hence conditions where trials have higher perceptual uncertainty on average (e.g. unisensory or neutral trials) will have more overlapping value beliefs, encouraging more exploration and giving rise to more frequent lapses (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2d</xref>).</p><p>As a result, on neutral multisensory trials, the uncertainty-guided exploration model predicts an increase not only in the inverse slope parameter σ, but also in the rate of lapses, just as we observed (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). In fact, this model predicts that both slope and lapse parameters on neutral trials should match those on auditory trials, since these conditions have comparable levels of perceptual uncertainty. The data was well fit by the exploration model (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, bottom) and satisfied both predictions (<xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>, Neutral has higher σ and lower β than Multisensory, and matched σ and β to Auditory) . By contrast, the inattention model predicts that both conditions would have the same lapse rates, with the neutral condition simply having a larger inverse slope σ. This model provided a worse fit to the data, particularly missing the data at extreme stimulus values where lapses are most clearly apparent (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, top). Model comparison using BIC and AIC favored the exploration model over the inattention model, both for fits to pooled data across subjects (<xref ref-type="fig" rid="fig3">Figure 3f</xref>, top) and fits to individual subject data (<xref ref-type="fig" rid="fig3">Figure 3f</xref>, bottom, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>, for the 3/5 subjects rejected by ideal observer model that is, with sizable lapses. Both predictions of the exploration model were confirmed using unconstrained descriptive fits to individuals, and held up for 4/5 subjects).</p><p>To further understand the precise relationship between perceptual uncertainty and lapses under this form of exploration, we simulated learning in a Thompson sampling agent for various levels of sensory noise, and found a roughly linear relationship between sensory noise and average lapse rate. Hence we fit a constrained version of the exploration model to the multisensory data from 17 rats, where the degree of exploratory lapses was constrained to be a linear function of that condition’s sensory noise (with two free parameters – slope and intercept, rather than three free parameters for the three conditions). This model yielded lower BIC than the unconstrained exploration model in all 14/17 rats that were rejected by the ideal observer model (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3c</xref>), and yielded similar slope and intercept parameters across animals (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2e</xref>).</p></sec><sec id="s2-4"><title>Reward manipulations confirm predictions of exploration model</title><p>One of the key claims of the uncertainty-guided exploration model is that lapses are exploratory choices made with full knowledge of the stimulus, and should therefore depend only on the expected rewards associated with that stimulus category (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). This is in stark contrast to the inattention model and many other kinds of disengagement (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), according to which lapses are caused by the observer disregarding the stimulus, and hence lapses at the two extreme stimulus levels are influenced by a common underlying guessing process that depends on expected rewards from both stimulus categories. This is also in contrast to fixed error models such as motor error or ε-greedy models in which lapses are independent of expected reward (<xref ref-type="fig" rid="fig3">Figure 3b</xref>).</p><p>Therefore, a unique prediction of the exploration model is that selectively manipulating expected rewards associated with one of the stimulus categories should only change the explore–exploit tradeoff for that stimulus category, selectively affecting lapses at one extreme of the psychometric function. Conversely, inattention and other kinds of disengagement predict that both lapses should be affected, while fixed error models predict that neither should be affected (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Reward manipulations match predictions of the exploration model.</title><p>(<bold>a</bold>) The inattention, fixed error, and exploration models make different predictions for increases and decreases in the reward magnitude for rightward (high-rate) actions. The inattention model (left panel) predicts changes in lapses for both high- and low-rate choices, while fixed error models such as motor error or ε-greedy (center) predict changes in neither lapse, and the uncertainty-dependent exploration model (right) predicts changes in lapses only for high-rate choices. Black line denotes equal rewards on both sides; green, increased rightward reward; red, decreased rightward reward. (<bold>b</bold>) Schematic of rate discrimination trials and interleaved ‘sure bet’ trials. The majority of the trials (94%) were rate discrimination trials as described in <xref ref-type="fig" rid="fig1">Figure 1</xref>. On sure-bet trials, a pure tone was played during a 0.2 s fixation period and one of the side ports was illuminated once the tone ended to indicate that reward was available there. Rate discrimination and sure-bet trials were randomly interleaved, as were left and right trials, and the rightward reward magnitude was either increased (36 μL) or decreased (16 μL) while maintaining the leftward reward at 24 μL. (<bold>c</bold>) Rats’ behavior on rate discrimination trials following reward magnitude manipulations. High-rate lapses decrease when water reward for high-rate choices is increased (left panel; n = 3 rats, 6976 trials), while high-rate lapses increase when reward on that side is decreased (right panel; n = 3 rats, 11,164 trials). Solid curves are exploration model fits with a single parameter change accounting for the manipulation. (<bold>d</bold>) Rats show nearly perfect performance on sure-bet trials and are unaffected by reward manipulations on these trials. (<bold>e</bold>) Reward probability manipulation. (Left) Schematic of probabilistic reward trials, incorrect (leftward) choices on high rates were rewarded with a probability of 0.5, and all other rewards were left unchanged. (Right) Rats’ behavior and exploration model fits showing a selective increase in high-rate lapses (n = 5 rats, 34,292 trials). (<bold>f</bold>) Rats’ behavior on equal reward trials conditioned on successes (green) or failures (red) on the right on the previous trials resembles effects of reward size manipulations. (<bold>g</bold>) Model comparison showing that Akaike Information Criterion and Bayes Information Criterion both favor the exploration model on data from all three manipulations.</p><p> <supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Fit parameters to pooled data across rats.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-55490-fig4-data1-v2.xlsx"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Alternative models of inattentional lapses.</title><p>Predictions of alternative models of lapses. (<bold>a</bold>) Effort-dependent disengagement model: In this model, there is an additional cost or mental effort to being engaged in the task which could vary with condition, and an additional random guessing action. If the net payoff of engagement is not greater than the average value of a guess, then it guesses randomly. Such a model does not produce lapses if the effort is fixed across trials (left), but could produce lapses if the effort fluctuates from trial to trial (center). (<bold>b</bold>) Proportion of trials on which the animal withdrew prematurely does not vary between matched and neutral trials, suggesting that rats are not disengaging preferentially on neutral trials. (<bold>c</bold>) Predictions of the effort-dependent disengagement model. The model accurately predicts increased lapses on unisensory trials (left panel, green/blue traces) and neutral multisensory trials (middle left panel, orange trace). However, for asymmetric reward manipulations (middle right – reward magnitude, right – reward probability), the model fails to predict our behavioral observation (<xref ref-type="fig" rid="fig4">Figure 4d</xref>) that only lapses on the manipulated side are affected. (<bold>d</bold>) Temporal inattention model: in this model, temporal weighting of evidence differs between matched and neutral trials. To test this, we compared psychophysical kernels on matched and neutral trials. The temporal dynamics of attention are unchanged between the two kinds of trials, arguing against the temporal inattention model. (<bold>e</bold>) Variable precision model: in this model, the sensory noise (or its inverse, precision) fluctuates from trial to trial, producing heavy tailed performance curves with apparent 'lapses’. The model accurately predicts increased apparent lapses on unisensory trials (left panel, green/blue traces) and neutral multisensory trials (middle left panel, orange trace). However, for asymmetric reward manipulations (middle right, right), the model fails to predict our behavioral observation (<xref ref-type="fig" rid="fig4">Figure 4d</xref>) that lapses only on the manipulated side are affected. Like other models of inattention, it predicts that manipulating reward on one side should affect both lapses. (<bold>f</bold>) Motivation + salience-dependent inattention: in this model, inattention is determined not just by salience, but also motivation, which in turn depends on average reward. This model’s predictions on unisensory, multisensory (left) and neutral (middle left) trials are identical to the inattention model, but on asymmetric reward manipulations, it predicts that total lapse rate should change as a function of total reward. As a result, when reward magnitude on one side is increased or decreased (middle right), total lapse rate also increases or decreases, in addition to the vertical shifts predicted by inattention. However, on the reward probability manipulation (right), it predicts a *decrease* in total lapse rate owing to the overall higher average reward, in addition to a downward shift predicted by inattention, unlike the rat data (<xref ref-type="fig" rid="fig4">Figure 4e</xref>) where overall lapse rate *increases* as a consequence of high-rate lapses selectively *increasing*.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Psychometric functions with lapses make it possible to assign perturbations effects to specific stages of decision-making.</title><p>(<bold>a</bold>) (Top row) Model predictions for biased sensory evidence (left), enhanced rightward action value (center), and reduced effort in performing rightward movements (right) in an exploratory regime where lapses are sizeable. The three kinds of perturbations affect decisions at the sensory, value, or motor stages and predict different effects on lapses. (Middle row) Effects of the three manipulations on the four stimulus-action value pairs. Biasing rightward evidence (left) leaves stimulus-action value pairs unchanged, while biasing the learnt rightward values (center) selectively affects rightward action values on high rates and biasing rightward effort (right) affects both high- and low-rate action values equally. (Bottom row) All three perturbations reduce to the same effect (horizontal shift) in the absence of lapses, that is, in the exploit regime. (<bold>b</bold>) Example data from two rats that experienced the same perturbation: increased rewards on the right port. The rats differ in the extent to which their psychometric functions have lapses. Top: In a psychometric function with lapses, the perturbation (green trace) leads to an interpretable change: the asymmetric change in lapses is only consistent with the explanation that the perturbation enhanced the value of rightward choices (as in [<bold>a</bold>], top, middle). The perturbation did not drive a change consistent with biased evidence or biased effort. Bottom: In a psychometric function with negligible lapses, the perturbation (red trials) lead to a cryptic change in the psychometric function: the observed shift could equivalently have been driven by biased evidence, value, or effort (as in [<bold>a</bold>], bottom three panels). Therefore, although the perturbation likely caused the same change in the two rats, an experimenter is only able to accurately explain this change in a rat with lapses.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig4-figsupp2-v2.tif"/></fig></fig-group><p>To experimentally test these predictions, we tested rats on the rate discrimination task with asymmetric rewards (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, top). Instead of rewarding high- and low-rate choices equally, we increased the water amount on the reward port associated with high rates (rightward choices) so it was 1.5 times larger than before, without changing the reward on the low-rate side (leftward choices). In a second rat cohort we did the opposite: we devalued the choices associated with high-rate trials by decreasing the water amount on that side port, and so it was 1.5 times smaller than before, without changing the reward on the low-rate side.</p><p>The animals’ behavior on the asymmetric-reward task matched the predictions of the exploration model. Increasing the reward size on choices associated with high rates led to a decrease in lapses for the highest rates and no changes in lapses for the lowest rates (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, left; n = 3 rats, 6976 trials). Decreasing the reward of choices associated with high rates led to an increase in lapses for the highest rates and no changes in lapses for the lower rates (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, right; n = 3 rats, 11,164 trials). This shows that both increasing and decreasing the value of actions associated with one of the stimulus categories selectively affects lapses on that stimulus category, unlike the predictions of the inattention model.</p><p>A key claim of the uncertainty-guided exploration model is that the effects of reward manipulations on lapses arise from a selective shift in the trade-off between exploiting the most rewarding action and exploring uncertain ones, rather than from a non-selective bias toward the side with bigger rewards. Importantly, the model predicts that in the absence of uncertainty, decisions should be perfectly exploitative and unaffected by reward imbalances, since subjects would always be comparing perfectly certain, nonzero rewards to zero. To determine whether the effects that we observed were truly driven by uncertainty, we examined performance on randomly interleaved ‘sure bet’ trials on which the uncertainty was very low (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, bottom). On these trials, a pure tone was played during the fixation period, after which an LED at one of the side ports was clearly illuminated, indicating a reward. Sure-bet trials comprised 6% of the total trials, and as with the rate discrimination trials, left and right trials were interleaved. Owing to the low perceptual uncertainty and consequently low value uncertainty, the model predicts that animals would quickly reach an ‘exploit’ regime, achieving perfect performance on these trials. Importantly, our model predicts that performance on these ‘sure-bet’ trials would be unaffected by imbalances in reward magnitude, since the ‘exploit’ action remains unchanged.</p><p>In keeping with this prediction, performance on sure-bet trials was near perfect (rightward probabilities of 0.003 [0.001,0.01] and 0.989 [0.978,0.995] on go-left and go-right trials respectively) and unaffected following reward manipulations (<xref ref-type="fig" rid="fig4">Figure 4d</xref>: Rightward probabilities of 0.004 [0.001, 0.014] and 0.996 [0.986,0.999] on increased reward, 0.006 [0.003,0.012] and 0.99 [0.983,0.994] on decreased reward). This suggests that the effects of reward manipulations that we observed (<xref ref-type="fig" rid="fig4">Figure 4c</xref>) are not a default consequence of reward imbalance, but a consequence of a reward-dependent trade-off between exploitation and uncertainty-guided exploration.</p><p>As an additional test of the model, we manipulated expected rewards by probabilistically rewarding incorrect choices for one of the stimulus categories. Here, leftward choices on high-rate (‘go right’) trials were rewarded with a probability of 0.5, while leaving all other rewards unchanged (<xref ref-type="fig" rid="fig4">Figure 4e</xref> left). The exploration model predicts that this should selectively increase the value of leftward actions on high-rate trials, hence shifting the trade-off toward exploration on high rates and increasing high-rate lapses. Indeed, this is what we observed (<xref ref-type="fig" rid="fig4">Figure 4e</xref> right, n = 5 animals, 347,537 trials), and the effect was strikingly similar to the decreased reward experiment, even though the two manipulations affect high-rate action values through changes on opposite actions. This experiment in particular distinguishes the exploration model from motivation-dependent models of disengagement or inattention in which overall reward modulates the total lapse rate through a nonspecific process that averages over stimulus categories (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a–c,f</xref>). Moreover, this suggests that lapses reflect changes in stimulus-specific action value caused by changing either reward magnitudes or reward probabilities, as one would expect from the exploration model. Across experiments (<xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>) and individuals, these changes were captured by selectively changing the relevant baseline action value in the model, despite variability in these baselines.</p><p>An added consequence of uncertainty in action values is that it should encourage continued learning even in the absence of explicit reward manipulations. This means that animals should continue to use the outcomes of previous trials to update the values of different actions as long as this uncertainty persists. Such persistent learning has been observed in a number of studies (<xref ref-type="bibr" rid="bib9">Busse et al., 2011</xref>; <xref ref-type="bibr" rid="bib32">Lak et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Mendonca et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Odoemene et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Pinto et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Scott et al., 2015</xref>). The uncertainty-dependent exploration model predicts that the effect of recent outcome history on action values should manifest as changes in lapse rates, rather than as horizontal biases caused by irrelevant, non-sensory evidence as is often assumed (<xref ref-type="bibr" rid="bib9">Busse et al., 2011</xref>). For example, the action value of rightward choices should increase following a rightward success, producing similar changes to lapses as increased rightward reward magnitude. As predicted, trials following rewarded and unrewarded rightward choices showed decreased and increased lapses, respectively (<xref ref-type="fig" rid="fig4">Figure 4f</xref>; same rats and trials as in <xref ref-type="fig" rid="fig2">Figure 2e</xref>). Taken together, manipulations of value confirm the predictions of the uncertainty-dependent exploration model (<xref ref-type="fig" rid="fig4">Figure 4g</xref>).</p></sec><sec id="s2-5"><title>Lapses are a powerful tool for assigning decision-related computations to neural structures based on disruption experiments</title><p>The results of the behavioral manipulations (above) predict that unilateral disruption of neural regions that leads to a one-sided scaling of learnt stimulus-action values should affect lapse rates asymmetrically. In contrast, disruptions to areas that process sensory evidence would lead to horizontal biases without affecting action values or lapses, and disruptions to motor areas that make one of the actions harder to perform irrespective of the stimulus would affect both lapses (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a</xref> top, middle). Crucially, in the absence of lapses, all three of these disruptions would drive an identical behavioral effect, a horizontal shift of the psychometric function (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a</xref> bottom). Indeed, the same reward manipulations that gave rise to distinct value biases in rats with sizeable lapses (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2b</xref> top) led to horizontal shifts indistinguishable from sensory biases in highly trained rats with negligible lapses on multisensory trials (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2b</xref> bottom). This suggests that lapses are actually informative about decision-making computations and can be used as a tool to determine which computations are affected by disruptions of a candidate brain region. To demonstrate this, we identified two candidate areas, secondary motor cortex (M2) and posterior striatum (pStr), that receive convergent input from primary visual and auditory cortices (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, results of simultaneous anterograde tracing from V1 and A1; also see <xref ref-type="bibr" rid="bib31">Jiang and Kim, 2018</xref>; <xref ref-type="bibr" rid="bib4">Barthas and Kwan, 2017</xref>). In previous work, disruptions of these areas had effects on auditory decisions, including changes in lapses (<xref ref-type="bibr" rid="bib18">Erlich et al., 2015</xref>; <xref ref-type="bibr" rid="bib29">Guo et al., 2018</xref>). However, considerable controversy remains as to which computations were affected by those disruptions. The effects were largely interpreted in terms of traditional ideal observer models (see <xref ref-type="bibr" rid="bib57">Siniscalchi et al., 2019</xref> for a notable exception), and thus attributed to perceptual biases (<xref ref-type="bibr" rid="bib29">Guo et al., 2018</xref>), leaky accumulation (<xref ref-type="bibr" rid="bib18">Erlich et al., 2015</xref>) or post-categorization biases (<xref ref-type="bibr" rid="bib46">Piet et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Erlich et al., 2015</xref>). Notably, the asymmetric effects on lapses seen in these studies resembled the effects of the reward manipulations in our task, hinting that they may actually arise from action value changes. Importantly, these existing studies used only auditory stimuli, so were limited in their ability to distinguish sensory-specific deficits from action value deficits.</p><p>Here, we used analyses of lapses to determine the decision-related computations altered by unilateral disruption of M2 and pStr. If these disruptions affected action values, the exploration model makes three strong predictions. First, because action values are computed late in the decision-making process, the model predicts that the effects should not depend on the modality of the stimulus. We therefore performed disruptions in animals doing interleaved auditory, visual, and multisensory trials. If pStr and M2 indeed compute action value, then following unilateral disruption of these areas, our model should capture changes to all three modalities by a single parameter change to the contralateral action value. Second, these disruptions should selectively affect lapses on stimuli associated with contralateral actions, irrespective of the stimulus-response contingency. To test this, we performed disruptions on animals trained on standard and reversed contingencies. Finally, because altered action values should have no effect when there is no uncertainty and consequently no exploration, disruption to pStr and M2 should spare performance on sure-bet trials (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, bottom).</p><p>We suppressed activity of neurons in each of these areas using muscimol, a GABAA agonist, during our multisensory rate discrimination task. We implanted bilateral cannulae in M2 (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2b</xref>; n = 5 rats; +2 mm AP 1.3 mm ML, 0.3 mm DV) and pStr (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2a</xref>; n = 6 rats; −3.2 mm AP, 5.4 mm ML, 4.1 mm DV). On control days, rats were infused unilaterally with saline, followed by unilateral muscimol infusion the next day (M2: 0.1–0.5 μg, pStr 0.075–0.125 μg). We compared performance on the multisensory rate discrimination task for muscimol days with preceding saline days. Inactivation of the side associated with low-rate choices biased the animals to make more low-rate choices (<xref ref-type="fig" rid="fig5">Figure 5b</xref>; left six panels: empty circles, inactivation sessions; full circles, control sessions), while inactivation of the side associated with high rates biased them to make more high-rate choices (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, right six panels). The inactivations largely affected lapses on the stimulus rates associated with contralateral actions, while sparing those associated with ipsilateral actions (<xref ref-type="fig" rid="fig5">Figure 5c</xref>). These results recapitulated previous findings and were strikingly similar to the effects we observed following reward manipulations (as seen in <xref ref-type="fig" rid="fig4">Figure 4c</xref>, right panel). These effects were seen across areas (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, top, M2; bottom, pStr) and modalities (<xref ref-type="fig" rid="fig5">Figure 5b</xref>; green, auditory; blue, visual and red, multisensory).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Inactivation of secondary motor cortex and posterior striatum affects lapses, suggesting a role in action value encoding.</title><p>(<bold>a</bold>) Schematic of cannulae implants in M2 (top) and pStr (bottom) and representative coronal slices. For illustration purposes only, the schematic shows implants in the right hemisphere; however, the inactivations shown in panel (<bold>b</bold>) were performed unilaterally on both hemispheres. (<bold>b</bold>) Unilateral inactivation of M2 (top) and pStr (bottom). Left six plots: inactivation of the side associated with low rates shows increased lapses for high rates on visual (blue), auditory (green), and multisensory (red) trials (M2: n = 5 rats; 10,329 control trials, full line; 6174 inactivation trials, dotted line; pStr: n = 5 rats; 10,419 control trials; 6079 inactivation trials). Right six plots: inactivation of the side associated with high rates shows increased lapses for low rates on visual, auditory, and multisensory trials (M2: n = 3 rats; 5678 control trials; 3816 inactivation trials; pStr: n = 6 rats; 11,333 control trials; 6838 inactivation trials). Solid lines are exploration model fits, accounting for inactivation effects across all three modalities by scaling all contralateral values by a single parameter. (<bold>c</bold>) Increased high-rate lapses following unilateral inactivation of the side associated with low rates (top left); no change in low-rate lapses (bottom left) and vice versa for inactivation of the side associated with high rates (top, bottom right). Control data on the abscissa is plotted against inactivation data on the ordinate. Same animals as in b. Green, auditory trials; blue, visual trials; red, multisensory trials. Abbreviations: posterior striatum (pStr), secondary motor cortex (M2). (<bold>d</bold>) Sure bet trials are unaffected following inactivation. Pooled data shows that rats that were inactivated on the side associated with high rates make near perfect rightward and leftward choices Top, M2 (three rats); bottom, pStr (six rats). (<bold>e</bold>) Model comparison of three possible multisensory deficits – reduction of contralateral evidence by a fixed amount (left), reduction of contralateral value by a fixed amount (center), or an increased contralateral effort by a fixed amount (right). Both Akaike Information Criterion and Bayes Information Criterion suggest a value deficit. (<bold>f</bold>) Proposed computational role of M2 and striatum. Lateralized encoding of left and right action values by right and left M2/pStr (bottom) explains the asymmetric effect of unilateral inactivations on lapses (top).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>pStr and M2 receive direct projections from visual and auditory cortex.</title><p>(<bold>a</bold>) Schematic of tracing experiments. AAV2.CB7.CI.EGFP.WPRE.RBG and AAV2.CAG.tdTomato.WPRE.SV40 constructs were injected unilaterally to primary visual (V1) and auditory (A1) cortices, respectively (V1 coordinates: 6.9 mm posterior to Bregma; 4.2 mm to the right of midline; A1 coordinates: 4.7 mm posterior to Bregma; 7 mm to the right of midline). (<bold>b</bold>) Secondary motor cortex (M2) receives inputs from V1 and A1 as shown by green and red fluorescence. (<bold>c</bold>) Posterior striatum (pStr) receives direct inputs from V1 and A1 as shown by green and red fluorescence. Yellow signal medial to pStr reflects overlapping passing fibers.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Histological slices of implanted rats.</title><p>Representative coronal slices of all rats implanted with cannulae for muscimol inactivation experiments. (<bold>a</bold>) Six rats were bilaterally implanted in posterior striatum (pStr). (<bold>b</bold>) Five rats were implanted in secondary motor cortex (M2).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Single rat performance following M2 inactivation.</title><p>Left: inactivation of the low-rate associated side. Rat shows increased lapses on high-rate trials on all sensory modalities. Right: inactivation of the high-rate associated side. Rat shows increased lapses on low-rate trials on all sensory modalities. Auditory (green), visual (blue), and multisensory (red).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-figsupp3-v2.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>Single rat performance following pStr inactivation.</title><p>Left: inactivation of the low-rate associated side. Rat shows increased lapses on high-rate trials on all sensory modalities. Right: inactivation of the high-rate associated side. Rat shows increased lapses on low-rate trials on all sensory modalities. Auditory (green), visual (blue), and multisensory (red).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-figsupp4-v2.tif"/></fig><fig id="fig5s5" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 5.</label><caption><title>Unilateral inactivation of M2 or pStr biases performance ipsilaterally and increases contralateral lapses.</title><p>Performance of the same rats shown in <xref ref-type="fig" rid="fig5">Figure 5b</xref> depicted as a function of the inactivated side (right or left) and the rate-contingency in which they were trained (standard or reverse), along with fits from the biased value model (solid lines – saline, dotted lines - muscimol). Standard contingency: high rate = go right, low rate = go left; reverse contingency: high rate = go left, low rate = go right. Each quadrant shows four plots: three psychometrics for rate discrimination trials and one for performance on sure-bet trials. auditory (green), visual (blue), and multisensory (red). (<bold>a–d</bold>) M2 inactivation. (<bold>e–h</bold>) pStr inactivation. (<bold>a</bold>), (<bold>d</bold>) Rats trained on the standard contingency and inactivated on the left hemisphere show increased lapses on the high rates (i.e., fewer rightward choices on high rates). No effect on sure-bet trials. (<bold>b</bold>), (<bold>f</bold>) Rats trained on the standard contingency and inactivated on the right hemisphere show increased lapses on the low rates (i.e., fewer leftward choices on low rates). No effect on sure-bet trials. (<bold>c</bold>), (<bold>g</bold>) Rats trained on the reverse contingency and inactivated on the left hemisphere show increased lapses on the low rates (i.e., fewer rightward choices on low rates). No effect on sure-bet trials. No data for this condition for M2 inactivation. (<bold>d</bold>), (<bold>h</bold>) Rats trained on the reverse contingency and inactivated on the right hemisphere show increased lapses on the high rates (i.e., fewer leftward choices on high rates). No effect on sure-bet trials for pStr inactivated animals; no data for M2 inactivated animals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-figsupp5-v2.tif"/></fig><fig id="fig5s6" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 6.</label><caption><title>Inactivations devalue contralateral actions irrespective of associated stimulus.</title><p>(<bold>a</bold>) Model predictions for rightward inactivations on standard (top) and reversed (bottom) stimulus-response contingencies – in both cases, the model predicts that reduced leftward action values should only affect lapses on the side associated with leftward movements. (<bold>b</bold>) Inactivation data on visual trials from M2 (left) or pStr (right) along with fits from the biased value model (solid lines – saline, dotted lines – muscimol) shows a pattern of effects consistent with action value deficits, irrespective of the contingency.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-figsupp6-v2.tif"/></fig><fig id="fig5s7" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 7.</label><caption><title>No significant effect on movement parameters following muscimol inactivation.</title><p>(<bold>a</bold>) Mean movement times from the center port to the side ports were not significantly different following muscimol inactivation of M2 (left; p=0.9554 for contralateral, 0.9852 for ipsilateral movements; n = 5 rats) or pStr (right; p=0.6629 for contra, p=0.2615 for ipsi, n = 6 rats). Control data on the abscissa is plotted against inactivation data on the ordinate. Purple, movement toward the side ipsilateral to the inactivation site; blue, movement toward the side contralateral to the inactivation site; error bars (s.e.m.) are not visible because they were obscured by the markers in all cases. (<bold>b</bold>) Mean wait times in the center port were not significantly different following muscimol inactivation of M2 (left; p=0.7612 for contra, p=0.8896 for ipsi, n = 5 rats) or pStr (right; p=0.9128 for contra, p=0.9412 for ipsi, n = 6 rats). All p-values were computed from paired t-tests. Error bars (s.e.m.) are not visible because they were obscured by the markers in all cases.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-fig5-figsupp7-v2.tif"/></fig></fig-group><p>Fitting averaged data across rats with the exploration model revealed that, in keeping with the first model prediction, the effects on lapses in all modalities could be captured by scaling the contralateral action value by a single parameter (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, joint fits to control [solid lines] and inactivation trials [dotted lines] across modalities with the ‘biased value’ model, differing only by a single parameter), similar to the reward manipulation experiments. Animals that were inactivated on the side associated with high rates showed increased lapses on low-rate trials (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, bottom right; data points are above the unity line; n = 9 rats), but unchanged lapses on high-rate trials (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, top right; data points are on the unity line). This was consistent across areas and modalities (<xref ref-type="fig" rid="fig5">Figure 5c</xref>; M2, triangles; pStr, circles; blue, visual; green, auditory; red, multisensory). Similarly, animals that were inactivated on the side associated with low rates showed the opposite effect: increased lapses on high-rate trials (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, top left; n = 10 rats), while lapses did not change for low-rate trials (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, bottom left). Fits to individual animals revealed that the majority of animals were best fit by the ‘biased value’ model (6/8 rats in M2 – <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>, 7/11 in pStr – <xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>), and the remaining animals were best fit by the ‘biased effort’ model.</p><p>In keeping with the second prediction, when we compared the effects of the disruptions in animals trained on standard and reversed contingencies (low rates rewarded with leftward or rightward actions respectively), the effects were always restricted to lapses on the stimuli associated with the side contralateral to the inactivation (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5</xref>), always resembling a devaluation of contralateral actions (<xref ref-type="fig" rid="fig5s6">Figure 5—figure supplement 6</xref>).</p><p>A model comparison across rats revealed that a fixed multiplicative scaling of contralateral value captured the inactivation effects much better than a fixed reduction in contralateral sensory evidence or a fixed addition of contralateral motor effort, both for M2 (<xref ref-type="fig" rid="fig5">Figure 5e</xref>, top) and pStr (<xref ref-type="fig" rid="fig5">Figure 5e</xref>, bottom). In uncertain conditions, this reduced contralateral value gives rise to more exploratory choices and hence more lapses on one side (<xref ref-type="fig" rid="fig5">Figure 5f</xref>, top).</p><p>The final prediction of the exploration model is that changes in action value will only affect trials in which there was uncertainty about the outcome. In keeping with that prediction, performance was spared on sure-bet trials (<xref ref-type="fig" rid="fig5">Figure 5d</xref>): rats made correct rightward and leftward choices regardless of the side that was inactivated. This observation provides further reassurance that the changes we observed on more uncertain conditions did not simply reflect motor impairments that drove a tendency to favor ipsilateral movements. Additional movement parameters such as wait time in the center port and movement times to ipsilateral and contralateral reward ports were likewise largely spared (<xref ref-type="fig" rid="fig5s7">Figure 5—figure supplement 7</xref>), suggesting that effects on decision outcome were not due to an inactivation-induced motor impairment.</p><p>Together, these results demonstrate that lapses are a powerful tool for interpreting behavioral changes in disruption experiments. For M2 and pStr disruptions, our analysis of lapses and deployment of the exploration model allowed us to reconcile previous inactivation studies. Our results suggest that M2 and pStr have a lateralized, modality-independent role in computing the expected value of actions (<xref ref-type="fig" rid="fig5">Figure 5f</xref>, bottom).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Perceptual decision-makers have long been known to display a small fraction of errors even on easy trials. Until now, these ‘lapses’ were largely regarded as a nuisance and lacked a comprehensive, normative explanation. Here, we propose a novel explanation for lapses: that they reflect a strategic balance between exploiting known rewarding options and exploring uncertain ones. Our model makes strong predictions for lapses under diverse decision-making contexts, which we have tested here. First, the model predicts more lapses on conditions with higher perceptual uncertainty, such as unisensory (<xref ref-type="fig" rid="fig2">Figure 2</xref>) or neutral (<xref ref-type="fig" rid="fig3">Figure 3</xref>), compared to matched multisensory or sure-bet conditions. Second, the model predicts that stimulus-specific reward manipulations should produce stimulus-specific effects on lapses, sparing decisions about un-manipulated or highly certain stimulus-action pairs (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Finally, the model predicts that lapses should be affected by perturbations to brain regions that encode action value. Accordingly, we observed that inactivations of secondary motor cortex and posterior striatum affected lapses similarly across auditory, visual and multisensory decisions, and could be accounted for by a one-parameter change to the action value (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Taken together, our model and experimental data argue strongly that far from being a nuisance, lapses are informative about animals’ subjective action values and reflect a trade-off between exploration and exploitation.</p><p>Considerations of value have provided many useful insights into aspects of behavior that seem sub-optimal at first glance from the perspective of perceptual ideal observers. For instance, many perceptual tasks are designed with accuracy in mind – defining an ideal observer as one who maximizes accuracy, in line with classical signal detection theory. However, in practice, the success or failure of different actions may be of unequal value to subjects, especially if reward or punishment is delivered explicitly, as is often the case with nonhuman subjects. This may give rise to biases that can only be explained by an observer that maximizes expected utility (<xref ref-type="bibr" rid="bib13">Dayan and Daw, 2008</xref>). Similarly, outcomes on a given trial can influence decisions about stimuli on subsequent trials through reinforcement learning, giving rise to serial biases. These biases occur even though the ideal observer should treat the evidence on successive trials as independent (<xref ref-type="bibr" rid="bib32">Lak et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Mendonca et al., 2018</xref>). When subjects can control how long they sample the stimulus, subjects maximizing reward rate may choose to make premature decisions, sacrificing accuracy for speed (<xref ref-type="bibr" rid="bib8">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib14">Drugowitsch et al., 2014</xref>). Finally, additional costs of exercising mental effort could lead to bounded optimality through ‘satisficing’ or finding good enough solutions (<xref ref-type="bibr" rid="bib40">Mastrogiorgio and Petracca, 2018</xref>; <xref ref-type="bibr" rid="bib20">Fan et al., 2018</xref>).</p><p>Here, we take further inspiration from considerations of value to provide a novel, normative explanation for lapses in perceptual decisions. Our results argue that lapses are not simply accidental errors made as a consequence of attentional ‘blinks’ or motor ‘slips’, but can reflect a deliberate, internal source of behavioral variability that facilitates learning and information gathering when the values of different actions are uncertain. This explanation connects a well-known strategy in value-based decision-making to a previously mysterious phenomenon in perceptual decision-making.</p><p>Although exploration no longer yields the maximum utility on any given trial, it is critical for environments in which there is uncertainty about expected reward or stimulus-response contingency, especially if these need to be learnt or refined through experience. By encouraging subjects to sample multiple options, exploration can potentially improve subjects’ knowledge of the rules of the task, helping them to increase long-term utility. This offers an explanation for the higher rate of lapses seen in humans on tasks with abstract (<xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>), non-intuitive (<xref ref-type="bibr" rid="bib42">Mihali et al., 2018</xref>), or non-verbalizable (<xref ref-type="bibr" rid="bib22">Flesch et al., 2018</xref>) rules. Exploration is also critical for dynamic environments in which rules or rewards drift or change over time. Subjects adapted to such dynamic real-world environments might entertain the possibility of non-stationarity even in tasks or periods where rewards are truly stationary, and such mismatched beliefs predict residual levels of exploration even in well-trained subjects (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2g</xref>, middle). Such beliefs could be probed by challenging subjects with unsignalled changes in rewards and measuring how quickly they recover from these change-points. For instance, primates with higher levels of tonic exploration on cognitive set-shifting tasks (<xref ref-type="bibr" rid="bib17">Ebitz et al., 2019</xref>) are more flexible and make fewer perseverative errors at change-points, at the cost of more lapses in rule adherence during stable periods.</p><p>Balancing exploration and exploitation is computationally challenging, and the mechanism we propose here, Thompson sampling, is an elegant heuristic for achieving this balance. This strategy has been shown to be utilized by humans in value-based decision-making tasks (<xref ref-type="bibr" rid="bib64">Wilson et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Speekenbrink and Konstantinidis, 2015</xref>; <xref ref-type="bibr" rid="bib26">Gershman, 2018</xref>) and is asymptotically optimal even in partially observable environments involving perceptual uncertainty such as ours (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c</xref>, <xref ref-type="bibr" rid="bib36">Leike et al., 2016</xref>). It can be naturally implemented through a sampling scheme where the subject samples action values from a learnt distribution and then maximizes with respect to the sample. This strategy predicts that conditions with higher perceptual uncertainty and consequently higher value uncertainty should have more exploration, and consequently higher lapse rates, explaining the pattern of lapse rates we observed on unisensory vs. multisensory trials as well as on neutral vs. matched trials. A lower rate of lapses on multisensory trials has also been reported on a visual-tactile task in rats (<xref ref-type="bibr" rid="bib43">Nikbakht et al., 2018</xref>) and a vestibular integration task in humans (<xref ref-type="bibr" rid="bib7">Bertolini et al., 2015</xref>) and can potentially account for the apparent supra-optimal integration that has been reported in a number of rodent, nonhuman primate and human studies (<xref ref-type="bibr" rid="bib43">Nikbakht et al., 2018</xref>; <xref ref-type="bibr" rid="bib30">Hou et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>). A strong prediction of uncertainty guided exploration is that the animal should quickly learn to exploit on conditions with little or no uncertainty, as we observed on sure-bet trials (<xref ref-type="fig" rid="fig4">Figures 4d</xref> and <xref ref-type="fig" rid="fig5">5d</xref>).</p><p>Uncertainty-guided exploration also predicts that exploratory choices, and consequently lapses, should decrease with training as the animal becomes more certain of the rules and expected rewards, explaining training-dependent effects on lapses in our rats (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2g,</xref> right) and similar effects reported in primates (<xref ref-type="bibr" rid="bib33">Law and Gold, 2009</xref>; <xref ref-type="bibr" rid="bib12">Cloherty et al., 2019</xref>). This can also potentially explain why children have higher lapse rates (<xref ref-type="bibr" rid="bib65">Witton et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Manning et al., 2018</xref>), as they have been shown to be more exploratory in their decisions than adults (<xref ref-type="bibr" rid="bib38">Lucas et al., 2014</xref>).</p><p>A unique prediction of the exploration model is that one-sided reward manipulations should have one-sided effects on lapses, unlike the inattention or motor error models. These predictions are borne out in our data (<xref ref-type="fig" rid="fig4">Figure 4c</xref>); moreover, they offer a principled, theoretically grounded way to distinguish between different sources of lapses. This approach can be extended to connect richer statistical descriptions of behavior to psychological variables such as evidence and action value. For instance, some authors have proposed that some of the variance attributed to lapses can be accounted for by allowing psychometric parameters to drift across trials (<xref ref-type="bibr" rid="bib53">Roy et al., 2018</xref>) or switch between different settings (<xref ref-type="bibr" rid="bib2">Ashwood et al., 2019</xref>). Whether this parametric non-stationarity arises from non-stationary evidence weighting across trials caused by inattention, variable attention (<xref ref-type="bibr" rid="bib55">Shen and Ma, 2019</xref>) or attention to irrelevant evidence (<xref ref-type="bibr" rid="bib9">Busse et al., 2011</xref>), or whether it arises from non-stationary beliefs about action values that encourage continued learning (<xref ref-type="bibr" rid="bib32">Lak et al., 2018</xref>) and bouts of exploration (<xref ref-type="bibr" rid="bib17">Ebitz et al., 2019</xref>) can be tested using one-sided reward manipulations, and by extending our model to include trial-by-trial updates of action value based on the history of evidence and outcomes (<xref ref-type="bibr" rid="bib48">Pisupati et al., 2019</xref>). By decoupling the values of different actions on the two stimulus categories, one-sided reward manipulations distinguish between incorrect decisions made due to a lack of knowledge about the stimulus category (i.e. inattention) and those made despite this knowledge, due to uncertainty about action values (i.e. exploration). An alternative way to decouple these two kinds of errors would be to offer subjects additional actions, e.g. by adding explicit ‘opt-out’ actions (<xref ref-type="bibr" rid="bib68">Zatka-Haas et al., 2019</xref>), or by adding task-irrelevant actions that subjects need to learn to avoid (<xref ref-type="bibr" rid="bib42">Mihali et al., 2018</xref>), affording more opportunities to distinguish exploratory and inattentive decisions than tasks with two alternative actions.</p><p>In addition to diagnosing or remedying lapses, the exploration model can be used to harness lapses to pinpoint decision-making computations in the brain. Our model suggests that the asymmetric effects on lapses seen during unilateral inactivations of prefrontal and striatal regions (<xref ref-type="fig" rid="fig5">Figure 5b</xref>) arise from a selective devaluation of learnt contralateral stimulus-action values. This interpretation reconciles a number of studies that have found asymmetric effects of inactivating these areas during perceptual decisions (<xref ref-type="bibr" rid="bib18">Erlich et al., 2015</xref>; <xref ref-type="bibr" rid="bib68">Zatka-Haas et al., 2019</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Guo et al., 2018</xref>) with their established roles in encoding action value (<xref ref-type="bibr" rid="bib60">Sul et al., 2011</xref>) during value-based decisions , and strengthens previous proposals that these areas arbitrate between perceptual and value-based influences on decisions (<xref ref-type="bibr" rid="bib35">Lee et al., 2015</xref>; <xref ref-type="bibr" rid="bib4">Barthas and Kwan, 2017</xref>; <xref ref-type="bibr" rid="bib57">Siniscalchi et al., 2019</xref>). The effects of inactivation in these studies are consistent with a ‘devaluation’ deficit, or multiplicative scaling of learnt stimulus-action values, resembling the majority of our inactivations (6/8 rats in M2, 7/11 in pStr) and selectively affecting lapses on stimuli strongly associated with the devalued actions. However, inactivations sometimes resembled additive deficits in action value (2/8 rats in M2, 4/11 in pStr), akin to an added ‘effort’ in performing the associated action irrespective of its learnt value, consistent with some reports in striatum (<xref ref-type="bibr" rid="bib61">Tai et al., 2012</xref>). Further work will be needed to precisely understand the nature of value representations in these regions and why they are sometimes multiplicatively and sometimes additively impacted by inactivations.</p><p>An open question that remains is how the brain might tune the degree of exploration in proportion to uncertainty. An intriguing candidate for this is dopamine, whose phasic responses have been shown to reflect state uncertainty (<xref ref-type="bibr" rid="bib59">Starkweather et al., 2017</xref>; <xref ref-type="bibr" rid="bib3">Babayan et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Lak et al., 2018</xref>), and whose tonic levels have been shown to modulate exploration in mice on a lever-press task (<xref ref-type="bibr" rid="bib6">Beeler et al., 2010</xref>), and context-dependent song variability in songbirds (<xref ref-type="bibr" rid="bib34">Leblois et al., 2010</xref>). Dopaminergic genes have been shown to predict individual differences in uncertainty-guided exploration in humans (<xref ref-type="bibr" rid="bib23">Frank et al., 2009</xref>), and dopaminergic disorders such as Parkinson’s disease have been shown to disrupt the uncertainty-dependence of lapses across conditions on a multisensory task (<xref ref-type="bibr" rid="bib7">Bertolini et al., 2015</xref>), while L-Dopa, a Parkinson’s drug and dopamine precursor, has been shown to attentuate uncertainty-guided exploration (<xref ref-type="bibr" rid="bib11">Chakroun et al., 2019</xref>). Patients with ADHD, another disorder associated with dopaminergic dysfunction, have been shown to display both increased perceptual variability and increased task-irrelevant motor output, a measure that correlates with lapses (<xref ref-type="bibr" rid="bib42">Mihali et al., 2018</xref>). Finally, tonic exploration and lapses of rule adherence are reduced in nonhuman primates that are administered cocaine (<xref ref-type="bibr" rid="bib17">Ebitz et al., 2019</xref>), which interferes with dopamine transport. A promising avenue for future studies is to leverage the informativeness of lapses and the precise control of uncertainty afforded by multisensory tasks, in conjunction with perturbations or recordings of dopaminergic circuitry, to further elucidate the connections between perceptual and value-based decision-making systems.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type (species) or <break/>resource</th><th>Designation</th><th>Source or <break/>reference</th><th>Identifiers</th><th>Additional information</th></tr></thead><tbody><tr><td>Strain, strain background <break/>(<italic>Rattus norvegicus</italic> <break/>domestica, male and <break/>female)</td><td>Long-Evans Rat</td><td>Taconic Farms</td><td>SimTac:LE</td><td>TAC: LONGEV-M, TAC: <break/>LONGEV-F</td></tr><tr><td>Recombinant DNA reagent</td><td>AAV2.CB7.CI.EGFP.WPRE.RBG</td><td>UPenn Vector Core</td><td/><td>Obtained from the <break/>laboratory of Dr. <break/>Partha Mitra at CSHL</td></tr><tr><td>Recombinant DNA reagent</td><td>AAV2.CAG.tdTomato.WPRE.SV40</td><td>UPenn Vector Core</td><td/><td>Obtained from the <break/>laboratory of Dr. <break/>Partha Mitra at CSHL</td></tr><tr><td>Chemical compound, drug</td><td>Muscimol</td><td>abcam</td><td>ab120094</td><td/></tr><tr><td>Software, algorithm</td><td>PALAMEDES toolbox</td><td><xref ref-type="bibr" rid="bib49">Prins and Kingdom, 2018</xref></td><td/><td>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2018.01250">10.3389/fpsyg.2018.01250</ext-link></td></tr><tr><td>Software, algorithm</td><td>MATLAB</td><td>The Mathworks, Inc</td><td/><td/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Behavior</title><sec id="s4-1-1"><title>Animal subjects and housing</title><p>All animal procedures and experiments were in accordance with the National Institutes of Health's Guide for the Care and Use of Laboratory Animals and were approved by the Cold Spring Harbor Laboratory Animal Care and Use Committee. Experiments were conducted with 34 adult male and female Long Evans rats (250–350 g, Taconic Farms) that were housed with free access to food and restricted access to water starting from the onset of behavioral training. Rats were housed on a reversed light–dark cycle; experiments were run during the dark part of the cycle. Rats were pair-housed during the whole training period.</p></sec><sec id="s4-1-2"><title>Animal training and behavioral task</title><p>Rats were trained following previously established methods (<xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Sheppard et al., 2013</xref>; <xref ref-type="bibr" rid="bib51">Raposo et al., 2014</xref>; <xref ref-type="bibr" rid="bib37">Licata et al., 2017</xref>). Briefly, rats were trained to wait in the center port for 1000 ms while stimuli were presented, and to associate stimuli with left/right reward ports. Stimuli for each trial consisted of a series of events: auditory clicks from a centrally positioned speaker, full-field visual flashes, or both together. Stimulus events were separated by either long (100 ms) or short (50 ms) intervals. For the easiest trials, all inter-event intervals were identical, generating rates that were nine events per second (all long intervals) or 16 events per second (all short intervals). More difficult trials included a mixture of long and short intervals, generating stimulus rates that were intermediate between the two extremes and therefore more difficult for the animal to judge. The stimulus began after a variable delay following when the rats snout broke the infrared beam in the center port. The length of this delay was selected from a truncated exponential distribution (λ = 30 ms, minimum = 10 ms, maximum = 200 ms) to generate an approximately flat hazard function. The total time of the stimulus was usually 1000 ms. Trials of all modalities and stimulus strengths were interleaved. For multisensory trials, the same number of auditory and visual events were presented (except for a subset of neutral trials). Auditory and visual stimulus event times were generated independently, as our previous work has demonstrated that rats make nearly identical decisions regardless of whether stimulus events are presented synchronously or independently (<xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>). For most experiments, rats were rewarded with a drop of water for moving to the left reward port following low-rate trials and to the right reward port following high-rate trials. For muscimol inactivation experiments, half of the rats were rewarded according to the reverse contingency. Animals typically completed between 700 and 1200 trials per day. Most experiments had 18 conditions (three modalities, eight stimulus strengths), leading to 29–50 trials per condition per day.</p><p>To probe the effect of uncertainty on lapses, rats received catch trials consisting of multisensory neutral trials, where only the auditory modality provided evidence for a particular choice, whereas the visual modality provided evidence that was so close to the category boundary (12 Hz) that it did not support one choice or the other (<xref ref-type="bibr" rid="bib50">Raposo et al., 2012</xref>).</p><p>To probe the effect of value on lapses, we manipulated either reward magnitude or reward probability associated with high rates, while keeping low-rate trials unchanged. To increase or decrease reward magnitude associated with high rates, the amount of water dispensed on the right port was increased or decreased to 36 μL or 16 μL respectively, while the reward on the left port was maintained at 24 μL. To manipulate reward probability, we occasionally rewarded rats on the (incorrect) left port on high-rate trials with a probability of 0.5. The right port was still rewarded with a probability of 1 on high rates, and reward probabilities on low-rate trials were unchanged (one on the left port, 0 on the right).</p></sec></sec><sec id="s4-2"><title>Analysis of behavioral data</title><sec id="s4-2-1"><title>Psychometric curves</title><p>Descriptive four-parameter psychometric functions were fit to choice data using the Palamedes toolbox (<xref ref-type="bibr" rid="bib49">Prins and Kingdom, 2018</xref>). Psychometric functions were parameterized as:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>where γ and λ are the lower and upper asymptote of the psychometric function, which parametrize the lapse rates on low and high rates, respectively. <inline-formula><mml:math id="inf18"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> is a cumulative normal function; <italic>x</italic> is the event rate, that is, the number of flashes or beeps presented during the 1 s stimulus period; <italic>μ</italic> parametrizes the <italic>x</italic>-value at the midpoint of the psychometric function and <italic>σ</italic> describes the inverse slope. 95% Confidence intervals on these parameters were generated via bootstrapping based on 1000 simulations.</p><p>Our definition of lapses is restricted to strictly <italic>asymptotic</italic> errors following <xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>, and not simply errors on the easiest stimuli tested. Errors on the easiest stimuli could in general arise not just from lapses (strictly defined) but also from perceptual errors caused by low sensitivity to the stimulus, an insufficient stimulus range or non-stationary weights (<xref ref-type="bibr" rid="bib9">Busse et al., 2011</xref>; <xref ref-type="bibr" rid="bib53">Roy et al., 2018</xref>). However, we do not consider easy errors alone to be evidence of lapses and only consider asymptotic errors. To confirm the necessity of including the lapse parameters, we fit the following variants of the model above, including lapse parameters when warranted by model comparison using AIC/BIC:</p><sec id="s4-2-1-1"><title>No lapses</title><p>This model forces <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all conditions (visual, auditory, and multisensory) and only allows <italic>σ</italic> and <italic>μ</italic> parameters to vary across conditions.</p></sec><sec id="s4-2-1-2"><title>Fixed lapses</title><p>This model allows for a fixed <italic>λ</italic> and <italic>γ</italic> (which may be unequal) across all conditions.</p></sec><sec id="s4-2-1-3"><title>Restricted lapses</title><p>This model allows <italic>λ</italic> and <italic>γ</italic> to vary across conditions, but restricts <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to be less than 0.1. This corresponds to an often used prior over total lapse rates, embodying the belief that lapse trials are infrequent (<xref ref-type="bibr" rid="bib63">Wichmann and Hill, 2001</xref>; <xref ref-type="bibr" rid="bib49">Prins and Kingdom, 2018</xref>).</p></sec><sec id="s4-2-1-4"><title>Variable lapses</title><p>This model allows both <italic>λ</italic> and <italic>γ</italic> to vary freely across conditions, allowing them each to take any value between 0 and 1 (as long as their sum also lies between 0 and 1).</p></sec></sec></sec><sec id="s4-3"><title>Modeling</title><sec id="s4-3-1"><title>Ideal observer model</title><p>We can specify an ideal observer model for our task using Bayesian Decision Theory (<xref ref-type="bibr" rid="bib13">Dayan and Daw, 2008</xref>). This observer maintains probability distributions over previously experienced stimuli and choices, computes the posterior probability of each action being correct given its observations, and picks the action that yields the highest expected reward.</p><p>Let the true category on any given trial be <inline-formula><mml:math id="inf21"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the true stimulus rate be <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and the animal’s noisy visual and auditory observations of <inline-formula><mml:math id="inf23"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> be <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>x</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf25"><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula>, respectively. We assume that the two sensory channels are corrupted by independent Gaussian noise with standard deviation <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>σ</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>, respectively, giving rise to conditionally independent observations.<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The ideal observer can use this knowledge to compute the likelihood of seeing the current trial’s observations as a function of the hypothesized stimulus rate <italic>s</italic>. This likelihood <inline-formula><mml:math id="inf28"><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi></mml:math></inline-formula> is a Gaussian function of <italic>s</italic> with a mean given by a weighted sum of the observations <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf30"><mml:msub><mml:mi>x</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∝</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The likelihood of seeing the observations as a function of the hypothesized category <italic>c</italic> is given by marginalizing over all possible hypothesized stimulus rates. Let the experimentally imposed category boundary be <inline-formula><mml:math id="inf31"><mml:msub><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, such that stimulus rates are considered high when <inline-formula><mml:math id="inf32"><mml:mrow><mml:mi>s</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and low when <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>s</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Then,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="script">ℒ</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mtext>High</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mtext>High</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mtext>High</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mtext>High</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mspace width="2em"/><mml:mo>∵</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo>⊥</mml:mo><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∝</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf34"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math></inline-formula> is the cumulative normal function. Using Bayes’ rule, the ideal observer can then compute the probability that the current trial was high or low rate given the observations, that is, the posterior probability.<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">⟹</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mtext>High</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∝</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">⟹</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mtext>Low</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∝</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf36"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the prior probabilities of high and low rates respectively. The expected value <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of choosing right or left actions (also known as the action values) is obtained by marginalizing the learnt value of state-action pairs <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> over the unobserved state <italic>c</italic>.<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>High</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>Low</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>High</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>Low</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Under the standard contingency, high rates are rewarded on the right and low rates on the left, so for a trained observer that has fully learnt the contingency, <inline-formula><mml:math id="inf39"><mml:mrow><mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf40"><mml:msub><mml:mi>r</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf41"><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula> being reward magnitudes for rightward and leftward actions. This simplifies the action values to:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>High</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>Low</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The max-reward decision rule involves picking the action <inline-formula><mml:math id="inf42"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> with the highest expected reward:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mtext>argmax</mml:mtext></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>i.e. </mml:mtext><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟺</mml:mo><mml:mspace width="thickmathspace"/><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>&gt;</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟺</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟺</mml:mo><mml:mspace width="thickmathspace"/><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>&gt;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟺</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>&gt;</mml:mo><mml:msup><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In the special case of equal rewards and uniform stimulus and category priors, this reduces to choosing right when the weighted sum of observations is to the right of the true category boundary, that is, <inline-formula><mml:math id="inf43"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Note that this is a deterministic decision rule for any given observations <inline-formula><mml:math id="inf44"><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf45"><mml:msub><mml:mi>x</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>; however, since these are noisy and Gaussian distributed around the true stimulus rate <inline-formula><mml:math id="inf46"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the likelihood of making a rightward decision is given by the cumulative Gaussian function <inline-formula><mml:math id="inf47"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>For</mml:mtext><mml:mspace width="1em"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We can measure this probability empirically through the psychometric curve. Fitting it with a two-parameter cumulative Gaussian function yields <italic>μ</italic> and <italic>σ</italic> which can be compared to ideal observer predictions. The <italic>σ</italic> parameter is then taken to reflect sensory noise; and with the assumption of uniform priors and equal rewards, the <italic>μ</italic> parameter is taken to reflect the subjective category boundary. For the purpose of assessing optimality of integration, <italic>σ</italic> was individually fit to each condition and compared to ideal observer predictions, but for the purpose of comparing theoretical models of lapses, <italic>σ</italic> on multisensory conditions was constrained to be optimal for all models. Although <italic>μ</italic> should equal <inline-formula><mml:math id="inf48"><mml:msub><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> for the ideal observer, in practice it is treated as a free parameter in all models, and deviations of <italic>μ</italic> from <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> could reflect any of three possible suboptimalities: (1) a subjective category boundary mismatched to the true one, possibly arising from the use of irrelevant features such as total event count (<xref ref-type="bibr" rid="bib44">Odoemene et al., 2018</xref>), (2) mismatched priors, or (3) unequal subjective rewards <inline-formula><mml:math id="inf50"><mml:msub><mml:mi>r</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf51"><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula> of the two actions.</p></sec><sec id="s4-3-2"><title>Inattention model</title><p>The traditional model for lapse rates assumes that on a fixed proportion of trials, the animal fails to pay attention to the stimulus, guessing randomly between the two actions. We can incorporate this suboptimality into the ideal observer above as follows: Let the probability of attending be <inline-formula><mml:math id="inf52"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Then, on <inline-formula><mml:math id="inf53"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> fraction of trials, the animal does not attend to the stimulus (i.e. receives no evidence), effectively making <inline-formula><mml:math id="inf54"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></inline-formula> and giving rise to a posterior that is equal to the prior. On these trials, the animal may choose to maximize this prior (always picking the option that is more likely a priori, guessing with 50–50 probability if both options are equally likely), or probability-match the prior (guessing in proportion to its prior). Let us call this guessing probability <inline-formula><mml:math id="inf55"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Then, the probability of a rightward decision is given by marginalizing over the attentional state:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mtext>attend</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>attend</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mtext>attend</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>∼</mml:mo><mml:mtext>attend</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Comparing this with the standard four-parameter sigmoid used in psychometric fitting, we obtain<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟹</mml:mo><mml:mspace width="thickmathspace"/><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mfrac><mml:mi>γ</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where γ and λ are the lower and upper asymptotes respectively, collectively known as ‘lapses’. In this model, the sum of the two lapses depends on the probability of attending, which could be modulated in a bottom-up fashion by the salience of the stimulus; their ratio depends on the guessing probability, which in turn depends on the observer’s priors and subjective rewards <inline-formula><mml:math id="inf56"><mml:msub><mml:mi>r</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf57"><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula>.</p></sec><sec id="s4-3-3"><title>Motor error/<inline-formula><mml:math id="inf58"><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula> greedy model</title><p>Lapses can also occur if the observer does not always pick the reward-maximizing or ‘exploit’ decision. This might occur due to random errors in motor execution on a small fraction of trials given by ε, or it might reflect a deliberate propensity to occasionally make random ‘exploratory’ choices to gather information about rules and rewards. This is known as an ε-greedy decision rule, where the observer chooses randomly (or according to <inline-formula><mml:math id="inf59"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) on ε fraction of trials. Both these models yield predictions similar to those of the inattention model:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟹</mml:mo><mml:mspace width="thickmathspace"/><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mfrac><mml:mi>γ</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-3-4"><title>Uncertainty guided exploration model</title><p>A more sophisticated form of exploration is the ‘softmax’ decision rule, which explores options in proportion to their expected rewards, allowing for a balance between exploration and exploitation through the tuning of a parameter β known as inverse temperature. In particular, in conditions of greater uncertainty about rules or rewards, it is advantageous to be more exploratory and have a lower β. This form of uncertainty-guided exploration is known as Thompson sampling. It can be implemented by sampling from a belief distribution over expected rewards and maximizing with respect to the sample, reducing to a softmax rule whose <italic>β</italic> depends on the total uncertainty in expected reward (<xref ref-type="bibr" rid="bib26">Gershman, 2018</xref>).<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The proportion of rightward choices conditioned on the true stimulus rate is then obtained by marginalizing over the latent action values <inline-formula><mml:math id="inf60"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, using the fact that the choice depends on <italic>s</italic> only through its effect on <inline-formula><mml:math id="inf61"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>ρ</italic> is the animal’s posterior belief in a high-rate stimulus, that is, <inline-formula><mml:math id="inf62"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. <italic>ρ</italic> is often referred to as the <italic>belief state</italic> in reinforcement learning problems involving partial observability such as our task.<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>Q</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>Q</mml:mi><mml:mspace width="1em"/><mml:mo>∵</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>⊥</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:mi>ρ</mml:mi></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Since lapses are the asymptotic probabilities of the lesser rewarding action at extremely easy stimulus rates, we can derive them from this expression by setting <inline-formula><mml:math id="inf63"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf64"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This yields<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Critically, in this model, the upper and lower lapses are dissociable, depending only on the rightward or leftward rewards, respectively. In practice since <italic>β</italic> can only be specified up to an arbitrary scaling of reward magnitudes, we either fix <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula>=1 and fit <italic>β</italic> and a reward bias <inline-formula><mml:math id="inf66"><mml:mfrac><mml:msub><mml:mi>r</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:math></inline-formula> in units of <inline-formula><mml:math id="inf67"><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula> (for conditions with different expected β), or fix <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and fit <inline-formula><mml:math id="inf69"><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf70"><mml:msub><mml:mi>r</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> in units of <italic>β</italic> (for conditions with the same <italic>β</italic> where one of the rewards is expected to change).</p><p>Such a softmax decision rule has been used to account for suboptimalities in value-based decisions (<xref ref-type="bibr" rid="bib13">Dayan and Daw, 2008</xref>); however, it has not been used to account for lapses in perceptual decisions. Other suboptimal decision rules described in perceptual decisions, such as generalized probability matching or posterior sampling (<xref ref-type="bibr" rid="bib1">Acerbi et al., 2014</xref>; <xref ref-type="bibr" rid="bib15">Drugowitsch et al., 2016</xref>; <xref ref-type="bibr" rid="bib45">Ortega and Braun, 2013</xref>), amount to a softmax on log-posteriors or log-expected values, rather than on expected values, and do not produce lapses since in these decision rules, when the posterior probability goes to 1, so does the decision probability.<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mi>β</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>L</mml:mi><mml:mi>β</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mi>β</mml:mi></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>⇒</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo><mml:mn>1</mml:mn><mml:mo>⇒</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn><mml:mo>⇒</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-3-5"><title>Inactivation modeling</title><p>Inactivations were modeled using the following one-parameter perturbations to the decision-making process, while keeping all other parameters fixed:</p><sec id="s4-3-5-1"><title>Biased evidence</title><p>A fixed amount of evidence was added to all modalities. This corresponds to adding a rate bias of <inline-formula><mml:math id="inf71"><mml:mrow><mml:mi>K</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for a condition with sensory noise <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> with <inline-formula><mml:math id="inf73"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> fixed across modalities, leading to bigger biases for conditions with higher sensory noise.</p></sec><sec id="s4-3-5-2"><title>Biased value</title><p>The expected values of one of the actions was scaled down by a fixed factor of <inline-formula><mml:math id="inf74"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> across all modalities. For instance, <inline-formula><mml:math id="inf75"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>→</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> produced a rightward biased value for a condition with baseline leftward expected value <inline-formula><mml:math id="inf76"><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. This led to a stimulus-dependent bias in action value and consequently lapses, since <inline-formula><mml:math id="inf77"><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is large and heavily affected for low-rate trials, and close to zero and largely unaffected for high-rate trials.</p></sec><sec id="s4-3-5-3"><title>Biased effort</title><p>A fixed ‘effort’ cost (i.e. negative value) <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>K</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> was added to the expected values of one of the actions for all modalities. This added a stimulus-independent bias in action values, since the difference in expected values was biased away from the effortful action by the same amount irrespective of the stimulus rate.</p></sec></sec></sec><sec id="s4-4"><title>Model fitting</title><p>Model fits were obtained from custom maximum likelihood fitting code using MATLAB’s fmincon, by maximizing the marginal likelihood of rightward choices given the stimulus on each trial as computed from each model. Confidence intervals for fit parameters were generated using the hessian obtained from fmincon. Fits to multiple conditions were performed jointly, taking into account any linear or nonlinear (e.g. optimality) constraints on parameters across conditions. Model comparisons were done using AIC and BIC. For comparisons of fits to data pooled across subjects, AIC/BIC values were computed with respect to the best fit model, so that the best model had an AIC/BIC of 0. For comparisons of fits to individual subject data, AIC/BIC values for each subject were computed with respect to the best fit model for each subject, so that the best model for that subject had an AIC/BIC of 0, and then summed across subjects.</p></sec><sec id="s4-5"><title>Surgical procedures</title><p>All rats subject to surgery were anesthetized with 1–3% isoflurane. Isoflurane anesthesia was maintained by monitoring respiration, heart rate, oxygen, and CO<sub>2</sub> levels, as well as foot pinch responses throughout the surgical procedure. Ophthalmic ointment was applied to keep the eyes moistened throughout surgery. After scalp shaving, the skin was cleaned with 70% ethanol and 5% betadine solution. Lidocaine solution was injected below the scalp to provide local analgesia prior to performing scalp incisions. Meloxicam (5 mg/mL) was administered subcutaneously (2 mg/kg) for analgesia at the beginning of the surgery, and daily 2–3 days post-surgery. The animals were allowed at least 7 days to recover before behavioral training.</p><sec id="s4-5-1"><title>Viral injections</title><p>Two rats, 15 weeks of age, were anesthetized and placed in a stereotaxic apparatus (Kopf Instruments). Small craniotomies were made in the center of primary visual cortex (V1; 6.9 mm posterior to Bregma, 4.2 mm to the right of midline) and primary auditory cortex (A1; 4.7 mm posterior to Bregma, 7 mm to the right of midline). Small durotomies were performed at each craniotomy and virus was pressure injected at depths of 600, 800, and 1000 μm below the pia (150 nL/depth). Virus injections were performed using Drummond Nanoject III, which enables automated delivery of small volumes of virus. To minimize virus spread, the Nanoject was programmed to inject slowly: fifteen 10 nL boluses, 30 s apart. Each bolus was delivered at 10 nL/s. Two to three minutes were allowed following injection at each depth to allow for diffusion of virus. The AAV2.CB7.CI.EGFP.WPRE.RBG construct was injected in V1, and the AAV2.CAG.tdTomato.WPRE.SV40 construct was injected in A1. Viruses were obtained from the University of Pennsylvania vector core.</p></sec><sec id="s4-5-2"><title>Cannulae implants</title><p>Rats were anesthetized and placed in the stereotax as described above. After incision and skull cleaning, two skull screws were implanted to add more surface area for the dental cement. For striatal implants, two craniotomies were made, one each side of the skull (3.2 mm posterior to Bregma; 5.4 mm to the right and left of midline). Durotomies were performed and a guide cannula (22 gauge, 8.5 mm long; PlasticsOne) was placed in the brain, 4.1 mm below the pia at each craniotomy. For secondary motor cortex implants, one large craniotomy spanning the right and left M2 was performed (∼5 mm × ∼2 mm in size centered around 2 mm anterior to Bregma and 3.1 mm to the right and left of midline). A durotomy was performed and a double guide cannula (22 gauge, 4 mm long; PlasticsOne) was placed in the brain, 300 μm below the pia. The exposed brain was covered with sterile Vaseline and cannulae were anchored to the skull with dental acrylic (Relyx). Single or double dummy cannulae protruding 0.7 mm below the guide cannulae were inserted.</p></sec></sec><sec id="s4-6"><title>Inactivation with muscimol</title><p>Rats were lightly anesthetized with isoflurane. Muscimol was unilaterally infused into pStr or M2 with a final concentration of 0.075–0.125 μg and 0.1–0.5 μg, respectively. A single/double-internal cannula (PlasticsOne), connected to a 2 μL syringe (Hamilton microliter syringe, 7000 series), was inserted into each previously implanted guide cannula. Internal cannulae protruded 0.5 mm below the guide. Muscimol was delivered using an infusion pump (Harvard PHD 22/2000) at a rate of 0.1 μL/min. Internal cannulae were kept in the brain for three additional minutes to allow for diffusion of muscimol. Rats were removed from anesthesia and returned to cages for 15 min before beginning behavioral sessions. The same procedure was used in control sessions, where muscimol was replaced with sterile saline.</p></sec><sec id="s4-7"><title>Histology</title><p>At the conclusion of inactivation experiments, animals were deeply anesthetized with Euthasol (pentobarbital and phenytoin). Animals were perfused transcardially with 4% paraformaldehyde. Brains were extracted and post-fixed in 4% paraformaldehyde for 24–48 hr. After post-fixing, 50–100 μm coronal sections were cut on a vibratome (Leica) and imaged.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Matt Kaufman, Simon Musall, Onyekachi Odoemene, Ashley Juavinett, Farzaneh Najafi, Akihiro Funamizu, Priyanka Gupta, Anne Urai, James Roach, Colin Stoneking, Diksha Gupta, Tatiana Engel, Rob Phillips, Tony Zador, Steve Shea, and Bo Li for scientific advice and discussions, and Angela Licata, Steven Gluf, Liete Einchorn, Dennis Maharjan, Alexa Pagliaro, Edward Lu, and Barry Burbach for technical assistance. We thank Partha Mitra, Alexander Tolpygo, and Stephen Savoia for help with slicing and imaging virus-injected brains. This work was supported by the Simons Collaboration on the Global Brain, ONR MURI, the Eleanor Schwartz Fund, the Pew Charitable Trust, and the Watson School of Biological Sciences. [Competing Interests] The authors declare that they have no competing financial interests. [Correspondence] Correspondence and requests for materials should be addressed to Anne K Churchland (email: <ext-link ext-link-type="uri" xlink:href="https://www.cshl.edu/research/faculty-staff/anne-churchland/">churchland@cshl.edu</ext-link>).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Validation, Investigation, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Investigation, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Data curation, Supervision, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All animal procedures and experiments were in accordance with the National Institutes of Healths Guide for the Care and Use of Laboratory Animals and were approved by the Cold Spring Harbor Laboratory Animal Care and Use Committee (protocol 19-16-13-10-7).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-55490-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data are publicly available: <ext-link ext-link-type="uri" xlink:href="http://repository.cshl.edu/id/eprint/38957/">http://repository.cshl.edu/id/eprint/38957/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Pisupati</surname><given-names>S</given-names></name><name><surname>Chartarifsky</surname><given-names>L</given-names></name><name><surname>Khanal</surname><given-names>A</given-names></name><name><surname>Churchland</surname><given-names>A K</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Dataset from: Lapses in perceptual decisions reflect exploration</data-title><source>CSHL</source><pub-id assigning-authority="other" pub-id-type="doi">10.14224/1.38957</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acerbi</surname> <given-names>L</given-names></name><name><surname>Vijayakumar</surname> <given-names>S</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>On the origins of suboptimality in human probabilistic inference</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003661</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003661</pub-id><pub-id pub-id-type="pmid">24945142</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ashwood</surname> <given-names>ZC</given-names></name><name><surname>Roy</surname> <given-names>NA</given-names></name><name><surname>Urai</surname> <given-names>AE</given-names></name><name><surname>Aguillon Rodriguez</surname> <given-names>V</given-names></name><name><surname>Bonacchi</surname> <given-names>N</given-names></name><name><surname>Cazettes</surname> <given-names>F</given-names></name><name><surname>Chapuis</surname> <given-names>GA</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name><name><surname>Faulkner</surname> <given-names>M</given-names></name><name><surname>Hu</surname> <given-names>F</given-names></name><name><surname>Krasniak</surname> <given-names>C</given-names></name><name><surname>Laranjeira</surname> <given-names>IC</given-names></name><name><surname>Meijer</surname> <given-names>GT</given-names></name><name><surname>Miska</surname> <given-names>NJ</given-names></name><name><surname>Noel</surname> <given-names>JP</given-names></name><name><surname>Pan-vazquez</surname> <given-names>A</given-names></name><name><surname>Rossant</surname> <given-names>C</given-names></name><name><surname>Socha</surname> <given-names>KZ</given-names></name><name><surname>Stone</surname> <given-names>IR</given-names></name><name><surname>Wells</surname> <given-names>MJ</given-names></name><name><surname>Wilson</surname> <given-names>CJ</given-names></name><name><surname>Winter</surname> <given-names>O</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name><collab>IBL Collaboration</collab></person-group><year iso-8601-date="2019">2019</year><article-title>State-dependent modeling of psychophysical behavior during decision making. program No. 241.11. 2019</article-title><conf-name>Neuroscience Meeting Planner Society for Neuroscience</conf-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babayan</surname> <given-names>BM</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Belief state representation in the dopamine system</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1891</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04397-0</pub-id><pub-id pub-id-type="pmid">29760401</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barthas</surname> <given-names>F</given-names></name><name><surname>Kwan</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Secondary motor cortex: where 'Sensory' Meets 'Motor' in the Rodent Frontal Cortex</article-title><source>Trends in Neurosciences</source><volume>40</volume><fpage>181</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2016.11.006</pub-id><pub-id pub-id-type="pmid">28012708</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname> <given-names>PM</given-names></name><name><surname>Catalao</surname> <given-names>RF</given-names></name><name><surname>Husain</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The precision of visual working memory is set by allocation of a shared resource</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/9.10.7</pub-id><pub-id pub-id-type="pmid">19810788</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beeler</surname> <given-names>JA</given-names></name><name><surname>Daw</surname> <given-names>N</given-names></name><name><surname>Frazier</surname> <given-names>CR</given-names></name><name><surname>Zhuang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Tonic dopamine modulates exploitation of reward learning</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>4</volume><elocation-id>170</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2010.00170</pub-id><pub-id pub-id-type="pmid">21120145</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bertolini</surname> <given-names>G</given-names></name><name><surname>Wicki</surname> <given-names>A</given-names></name><name><surname>Baumann</surname> <given-names>CR</given-names></name><name><surname>Straumann</surname> <given-names>D</given-names></name><name><surname>Palla</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Impaired tilt perception in Parkinson's disease: a central vestibular integration failure</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0124253</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0124253</pub-id><pub-id pub-id-type="pmid">25874868</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname> <given-names>R</given-names></name><name><surname>Brown</surname> <given-names>E</given-names></name><name><surname>Moehlis</surname> <given-names>J</given-names></name><name><surname>Holmes</surname> <given-names>P</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname> <given-names>L</given-names></name><name><surname>Ayaz</surname> <given-names>A</given-names></name><name><surname>Dhruv</surname> <given-names>NT</given-names></name><name><surname>Katzner</surname> <given-names>S</given-names></name><name><surname>Saleem</surname> <given-names>AB</given-names></name><name><surname>Schölvinck</surname> <given-names>ML</given-names></name><name><surname>Zaharia</surname> <given-names>AD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The detection of visual contrast in the behaving mouse</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>11351</fpage><lpage>11361</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6689-10.2011</pub-id><pub-id pub-id-type="pmid">21813694</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Probing perceptual decisions in rodents</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>824</fpage><lpage>831</lpage><pub-id pub-id-type="doi">10.1038/nn.3410</pub-id><pub-id pub-id-type="pmid">23799475</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chakroun</surname> <given-names>K</given-names></name><name><surname>Mathar</surname> <given-names>D</given-names></name><name><surname>Wiehler</surname> <given-names>A</given-names></name><name><surname>Ganzer</surname> <given-names>F</given-names></name><name><surname>Peters</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dopaminergic modulation of the exploration/exploitation trade-off in human decision-making</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/706176</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cloherty</surname> <given-names>SL</given-names></name><name><surname>Yates</surname> <given-names>JL</given-names></name><name><surname>Graf</surname> <given-names>D</given-names></name><name><surname>DeAngelis</surname> <given-names>GC</given-names></name><name><surname>Mitchell</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Motion perception in the common marmoset</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/522888</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Decision theory, reinforcement learning, and the brain</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>8</volume><fpage>429</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.3758/CABN.8.4.429</pub-id><pub-id pub-id-type="pmid">19033240</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>DeAngelis</surname> <given-names>GC</given-names></name><name><surname>Klier</surname> <given-names>EM</given-names></name><name><surname>Angelaki</surname> <given-names>DE</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Optimal multisensory decision-making in a reaction-time task</article-title><source>eLife</source><volume>3</volume><elocation-id>e03005</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.03005</pub-id><pub-id pub-id-type="pmid">24929965</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name><name><surname>Devauchelle</surname> <given-names>AD</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational precision of mental inference as critical source of human choice suboptimality</article-title><source>Neuron</source><volume>92</volume><fpage>1398</fpage><lpage>1411</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.005</pub-id><pub-id pub-id-type="pmid">27916454</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning optimal decisions with confidence</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/244269</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebitz</surname> <given-names>RB</given-names></name><name><surname>Sleezer</surname> <given-names>BJ</given-names></name><name><surname>Jedema</surname> <given-names>HP</given-names></name><name><surname>Bradberry</surname> <given-names>CW</given-names></name><name><surname>Hayden</surname> <given-names>BY</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Tonic exploration governs both flexibility and lapses</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007475</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007475</pub-id><pub-id pub-id-type="pmid">31703063</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Brunton</surname> <given-names>BW</given-names></name><name><surname>Duan</surname> <given-names>CA</given-names></name><name><surname>Hanks</surname> <given-names>TD</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct effects of prefrontal and parietal cortex inactivations on an accumulation of evidence task in the rat</article-title><source>eLife</source><volume>4</volume><elocation-id>e05457</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05457</pub-id><pub-id pub-id-type="pmid">25869470</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ernst</surname> <given-names>MO</given-names></name><name><surname>Bülthoff</surname> <given-names>HH</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Merging the senses into a robust percept</article-title><source>Trends in Cognitive Sciences</source><volume>8</volume><fpage>162</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.02.002</pub-id><pub-id pub-id-type="pmid">15050512</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname> <given-names>Y</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Ding</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Ongoing, rational calibration of reward-driven perceptual biases</article-title><source>eLife</source><volume>7</volume><elocation-id>e36018</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.36018</pub-id><pub-id pub-id-type="pmid">30303484</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Findling</surname> <given-names>C</given-names></name><name><surname>Skvortsova</surname> <given-names>V</given-names></name><name><surname>Dromnelle</surname> <given-names>R</given-names></name><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Computational noise in reward-guided learning drives behavioral variability in volatile environments</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/439885</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flesch</surname> <given-names>T</given-names></name><name><surname>Balaguer</surname> <given-names>J</given-names></name><name><surname>Dekker</surname> <given-names>R</given-names></name><name><surname>Nili</surname> <given-names>H</given-names></name><name><surname>Summerfield</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Comparing continual task learning in minds and machines</article-title><source>PNAS</source><volume>115</volume><fpage>E10313</fpage><lpage>E10322</lpage><pub-id pub-id-type="doi">10.1073/pnas.1800755115</pub-id><pub-id pub-id-type="pmid">30322916</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Doll</surname> <given-names>BB</given-names></name><name><surname>Oas-Terpstra</surname> <given-names>J</given-names></name><name><surname>Moreno</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1062</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1038/nn.2342</pub-id><pub-id pub-id-type="pmid">19620978</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrido</surname> <given-names>MI</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Surprise leads to noisier perceptual decisions</article-title><source>I-Perception</source><volume>2</volume><fpage>112</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1068/i0411</pub-id><pub-id pub-id-type="pmid">23145228</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A unifying probabilistic view of associative learning</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004567</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004567</pub-id><pub-id pub-id-type="pmid">26535896</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deconstructing the human algorithms for exploration</article-title><source>Cognition</source><volume>173</volume><fpage>34</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.12.014</pub-id><pub-id pub-id-type="pmid">29289795</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Ding</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How mechanisms of perceptual decision-making affect the psychometric function</article-title><source>Progress in Neurobiology</source><volume>103</volume><fpage>98</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.05.008</pub-id><pub-id pub-id-type="pmid">22609483</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname> <given-names>DM</given-names></name><name><surname>Swets</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-name>Wiley</publisher-name><pub-id pub-id-type="doi">10.1901/jeab.1969.12-475</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>L</given-names></name><name><surname>Walker</surname> <given-names>WI</given-names></name><name><surname>Ponvert</surname> <given-names>ND</given-names></name><name><surname>Penix</surname> <given-names>PL</given-names></name><name><surname>Jaramillo</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Stable representation of sounds in the posterior striatum during flexible auditory decisions</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1534</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-03994-3</pub-id><pub-id pub-id-type="pmid">29670112</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hou</surname> <given-names>H</given-names></name><name><surname>Zheng</surname> <given-names>Q</given-names></name><name><surname>Zhao</surname> <given-names>Y</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name><name><surname>Gu</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural correlates of optimal multisensory decision making</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/480178</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname> <given-names>H</given-names></name><name><surname>Kim</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Anatomical inputs from the sensory and value structures to the tail of the rat striatum</article-title><source>Frontiers in Neuroanatomy</source><volume>12</volume><elocation-id>30</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2018.00030</pub-id><pub-id pub-id-type="pmid">29773980</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lak</surname> <given-names>A</given-names></name><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Moss</surname> <given-names>M</given-names></name><name><surname>Gurnani</surname> <given-names>H</given-names></name><name><surname>Wells</surname> <given-names>MJ</given-names></name><name><surname>Reddy</surname> <given-names>CB</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dopaminergic and frontal signals for decisions guided by sensory evidence and reward value</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/411413</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Law</surname> <given-names>CT</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reinforcement learning can account for associative and perceptual learning on a visual-decision task</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>655</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1038/nn.2304</pub-id><pub-id pub-id-type="pmid">19377473</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leblois</surname> <given-names>A</given-names></name><name><surname>Wendel</surname> <given-names>BJ</given-names></name><name><surname>Perkel</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Striatal dopamine modulates basal ganglia output and regulates social context-dependent behavioral variability through D1 receptors</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>5730</fpage><lpage>5743</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5974-09.2010</pub-id><pub-id pub-id-type="pmid">20410125</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>AM</given-names></name><name><surname>Tai</surname> <given-names>LH</given-names></name><name><surname>Zador</surname> <given-names>A</given-names></name><name><surname>Wilbrecht</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Between the primate and 'reptilian' brain: Rodent models demonstrate the role of corticostriatal circuits in decision making</article-title><source>Neuroscience</source><volume>296</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2014.12.042</pub-id><pub-id pub-id-type="pmid">25575943</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Leike</surname> <given-names>J</given-names></name><name><surname>Lattimore</surname> <given-names>T</given-names></name><name><surname>Orseau</surname> <given-names>L</given-names></name><name><surname>Hutter</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Thompson sampling is asymptotically optimal in general environments</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1602.07905">https://arxiv.org/abs/1602.07905</ext-link></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Licata</surname> <given-names>AM</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Ryan</surname> <given-names>MB</given-names></name><name><surname>Sheppard</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Posterior parietal cortex guides visual decisions in rats</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>4954</fpage><lpage>4966</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0105-17.2017</pub-id><pub-id pub-id-type="pmid">28408414</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lucas</surname> <given-names>CG</given-names></name><name><surname>Bridgers</surname> <given-names>S</given-names></name><name><surname>Griffiths</surname> <given-names>TL</given-names></name><name><surname>Gopnik</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>When children are better (or at least more open-minded) learners than adults: developmental differences in learning the forms of causal relationships</article-title><source>Cognition</source><volume>131</volume><fpage>284</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2013.12.010</pub-id><pub-id pub-id-type="pmid">24566007</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manning</surname> <given-names>C</given-names></name><name><surname>Jones</surname> <given-names>PR</given-names></name><name><surname>Dekker</surname> <given-names>TM</given-names></name><name><surname>Pellicano</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Psychophysics with children: investigating the effects of attentional lapses on threshold estimates</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>80</volume><fpage>1311</fpage><lpage>1324</lpage><pub-id pub-id-type="doi">10.3758/s13414-018-1510-2</pub-id><pub-id pub-id-type="pmid">29582387</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastrogiorgio</surname> <given-names>A</given-names></name><name><surname>Petracca</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Satisficing as an alternative to optimality and suboptimality in perceptual decision making</article-title><source>Behavioral and Brain Sciences</source><volume>41</volume><elocation-id>e235</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X18001358</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mendonca</surname> <given-names>AG</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Vicente</surname> <given-names>MI</given-names></name><name><surname>DeWitt</surname> <given-names>E</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The impact of learning on perceptual decisions and its implication for speed-accuracy tradeoffs</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/501858</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mihali</surname> <given-names>A</given-names></name><name><surname>Young</surname> <given-names>AG</given-names></name><name><surname>Adler</surname> <given-names>LA</given-names></name><name><surname>Halassa</surname> <given-names>MM</given-names></name><name><surname>Ma</surname> <given-names>WJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Low-Level perceptual correlate of behavioral and clinical deficits in ADHD</article-title><source>Computational Psychiatry</source><volume>2</volume><fpage>141</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1162/cpsy_a_00018</pub-id><pub-id pub-id-type="pmid">30381800</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikbakht</surname> <given-names>N</given-names></name><name><surname>Tafreshiha</surname> <given-names>A</given-names></name><name><surname>Zoccolan</surname> <given-names>D</given-names></name><name><surname>Diamond</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Supralinear and supramodal integration of visual and tactile signals in rats: psychophysics and neuronal mechanisms</article-title><source>Neuron</source><volume>97</volume><fpage>626</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.003</pub-id><pub-id pub-id-type="pmid">29395913</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Odoemene</surname> <given-names>O</given-names></name><name><surname>Pisupati</surname> <given-names>S</given-names></name><name><surname>Nguyen</surname> <given-names>H</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Visual evidence accumulation guides Decision-Making in unrestrained mice</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>10143</fpage><lpage>10155</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3478-17.2018</pub-id><pub-id pub-id-type="pmid">30322902</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ortega</surname> <given-names>PA</given-names></name><name><surname>Braun</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Thermodynamics as a theory of decision-making with information-processing costs</article-title><source>Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</source><volume>469</volume><elocation-id>20120683</elocation-id><pub-id pub-id-type="doi">10.1098/rspa.2012.0683</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piet</surname> <given-names>AT</given-names></name><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Kopec</surname> <given-names>CD</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Rat prefrontal cortex inactivations during decision making are explained by bistable attractor dynamics</article-title><source>Neural Computation</source><volume>29</volume><fpage>2861</fpage><lpage>2886</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01005</pub-id><pub-id pub-id-type="pmid">28777728</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname> <given-names>L</given-names></name><name><surname>Koay</surname> <given-names>SA</given-names></name><name><surname>Engelhard</surname> <given-names>B</given-names></name><name><surname>Yoon</surname> <given-names>AM</given-names></name><name><surname>Deverett</surname> <given-names>B</given-names></name><name><surname>Thiberge</surname> <given-names>SY</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>An Accumulation-of-Evidence task using visual pulses for mice navigating in virtual reality</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>12</volume><elocation-id>36</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2018.00036</pub-id><pub-id pub-id-type="pmid">29559900</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pisupati</surname> <given-names>S</given-names></name><name><surname>Musall</surname> <given-names>SM</given-names></name><name><surname>Urai</surname> <given-names>AE</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A two stage bayesian observer predicts the effects of learning on perceptual decisions. program No. 756.01. 2019</article-title><conf-name>Neuroscience Meeting Planner Society for Neuroscience</conf-name></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prins</surname> <given-names>N</given-names></name><name><surname>Kingdom</surname> <given-names>FAA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Applying the Model-Comparison approach to test specific research hypotheses in psychophysical research using the palamedes toolbox</article-title><source>Frontiers in Psychology</source><volume>9</volume><elocation-id>1250</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2018.01250</pub-id><pub-id pub-id-type="pmid">30083122</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Sheppard</surname> <given-names>JP</given-names></name><name><surname>Schrater</surname> <given-names>PR</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Multisensory decision-making in rats and humans</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>3726</fpage><lpage>3735</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4998-11.2012</pub-id><pub-id pub-id-type="pmid">22423093</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A category-free neural population supports evolving demands during decision-making</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1784</fpage><lpage>1792</lpage><pub-id pub-id-type="doi">10.1038/nn.3865</pub-id><pub-id pub-id-type="pmid">25383902</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roach</surname> <given-names>NW</given-names></name><name><surname>Edwards</surname> <given-names>VT</given-names></name><name><surname>Hogben</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The tale is in the tail: an alternative hypothesis for psychophysical performance variability in dyslexia</article-title><source>Perception</source><volume>33</volume><fpage>817</fpage><lpage>830</lpage><pub-id pub-id-type="doi">10.1068/p5207</pub-id><pub-id pub-id-type="pmid">15460509</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Roy</surname> <given-names>NA</given-names></name><name><surname>Bak</surname> <given-names>JH</given-names></name><name><surname>Akrami</surname> <given-names>A</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Efficient inference for time-varying behavior during learning</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>5695</fpage><lpage>5705</lpage></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname> <given-names>BB</given-names></name><name><surname>Constantinople</surname> <given-names>CM</given-names></name><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sources of noise during accumulation of evidence in unrestrained and voluntarily head-restrained rats</article-title><source>eLife</source><volume>4</volume><elocation-id>e11308</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11308</pub-id><pub-id pub-id-type="pmid">26673896</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname> <given-names>S</given-names></name><name><surname>Ma</surname> <given-names>WJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Variable precision in visual perception</article-title><source>Psychological Review</source><volume>126</volume><fpage>89</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1037/rev0000128</pub-id><pub-id pub-id-type="pmid">30335411</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheppard</surname> <given-names>JP</given-names></name><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dynamic weighting of multisensory stimuli shapes decision-making in rats and humans</article-title><source>Journal of Vision</source><volume>13</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/13.6.4</pub-id><pub-id pub-id-type="pmid">23658374</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siniscalchi</surname> <given-names>MJ</given-names></name><name><surname>Wang</surname> <given-names>H</given-names></name><name><surname>Kwan</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Enhanced population coding for rewarded choices in the medial frontal cortex of the mouse</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>4090</fpage><lpage>4106</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy292</pub-id><pub-id pub-id-type="pmid">30615132</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Speekenbrink</surname> <given-names>M</given-names></name><name><surname>Konstantinidis</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Uncertainty and exploration in a restless bandit problem</article-title><source>Topics in Cognitive Science</source><volume>7</volume><fpage>351</fpage><lpage>367</lpage><pub-id pub-id-type="doi">10.1111/tops.12145</pub-id><pub-id pub-id-type="pmid">25899069</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Starkweather</surname> <given-names>CK</given-names></name><name><surname>Babayan</surname> <given-names>BM</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dopamine reward prediction errors reflect hidden-state inference across time</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>581</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1038/nn.4520</pub-id><pub-id pub-id-type="pmid">28263301</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sul</surname> <given-names>JH</given-names></name><name><surname>Jo</surname> <given-names>S</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Jung</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Role of rodent secondary motor cortex in value-based action selection</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1202</fpage><lpage>1208</lpage><pub-id pub-id-type="doi">10.1038/nn.2881</pub-id><pub-id pub-id-type="pmid">21841777</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tai</surname> <given-names>LH</given-names></name><name><surname>Lee</surname> <given-names>AM</given-names></name><name><surname>Benavidez</surname> <given-names>N</given-names></name><name><surname>Bonci</surname> <given-names>A</given-names></name><name><surname>Wilbrecht</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Transient stimulation of distinct subpopulations of striatal neurons mimics changes in action value</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/nn.3188</pub-id><pub-id pub-id-type="pmid">22902719</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>L</given-names></name><name><surname>Rangarajan</surname> <given-names>KV</given-names></name><name><surname>Gerfen</surname> <given-names>CR</given-names></name><name><surname>Krauzlis</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Activation of striatal neurons causes a perceptual decision Bias during visual change detection in mice</article-title><source>Neuron</source><volume>97</volume><fpage>1369</fpage><lpage>1381</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.049</pub-id><pub-id pub-id-type="pmid">29503185</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wichmann</surname> <given-names>FA</given-names></name><name><surname>Hill</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The psychometric function: I. fitting, sampling, and goodness of fit</article-title><source>Perception &amp; Psychophysics</source><volume>63</volume><fpage>1293</fpage><lpage>1313</lpage><pub-id pub-id-type="doi">10.3758/BF03194544</pub-id><pub-id pub-id-type="pmid">11800458</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Geana</surname> <given-names>A</given-names></name><name><surname>White</surname> <given-names>JM</given-names></name><name><surname>Ludvig</surname> <given-names>EA</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Humans use directed and random exploration to solve the explore-exploit dilemma</article-title><source>Journal of Experimental Psychology: General</source><volume>143</volume><fpage>2074</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1037/a0038199</pub-id><pub-id pub-id-type="pmid">25347535</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witton</surname> <given-names>C</given-names></name><name><surname>Talcott</surname> <given-names>JB</given-names></name><name><surname>Henning</surname> <given-names>GB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Psychophysical measurements in children: challenges, pitfalls, and considerations</article-title><source>PeerJ</source><volume>5</volume><elocation-id>e3231</elocation-id><pub-id pub-id-type="doi">10.7717/peerj.3231</pub-id><pub-id pub-id-type="pmid">28507816</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname> <given-names>MM</given-names></name><name><surname>Hanks</surname> <given-names>TD</given-names></name><name><surname>Yoon</surname> <given-names>AM</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Causal contribution and dynamical encoding in the striatum during evidence accumulation</article-title><source>eLife</source><volume>7</volume><elocation-id>e34929</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34929</pub-id><pub-id pub-id-type="pmid">30141773</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>AJ</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sequential effects: superstition or rational behavior?</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>1873</fpage><lpage>1880</lpage></element-citation></ref><ref id="bib68"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zatka-Haas</surname> <given-names>P</given-names></name><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distinct contributions of mouse cortical areas to visual discrimination</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/501627</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>B</given-names></name><name><surname>Hofmann</surname> <given-names>D</given-names></name><name><surname>Pinkoviezky</surname> <given-names>I</given-names></name><name><surname>Sober</surname> <given-names>SJ</given-names></name><name><surname>Nemenman</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Chance, long tails, and inference in a non-Gaussian, bayesian theory of vocal learning in songbirds</article-title><source>PNAS</source><volume>115</volume><fpage>E8538</fpage><lpage>E8546</lpage><pub-id pub-id-type="doi">10.1073/pnas.1713020115</pub-id><pub-id pub-id-type="pmid">30127024</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.55490.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Lee</surname><given-names>Daeyeol</given-names></name><role>Reviewing Editor</role><aff><institution>Johns Hopkins University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Ding</surname><given-names>Long</given-names> </name><role>Reviewer</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Kwan</surname><given-names>Alex C</given-names></name><role>Reviewer</role><aff><institution>Yale University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This manuscript presents a novel explanation for lapses in perceptual decision making. Using precise computational models to analyze the data from a click-rate discrimination task, the authors show that lapses might be due to the rats' uncertainty-dependent exploration strategy rather than inattention or motor errors.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Lapses in perceptual decisions reflect exploration&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Long Ding (Reviewer #1); Alex C Kwan (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This manuscript presents an interesting explanation for lapses in perceptual decision making. The authors showed that rats showed imperfect performance on a click-rate-discrimination task. They showed that the amount of lapse depended on whether the decision was based on uni- or multi-sensory stimulus, whether the reward associations were equal or asymmetric for the two choices, and whether M2/pStr was intact. Using precise computational models, they proposed that these lapses were due to the rats' uncertainty-dependent exploration strategy. The results are somewhat consistent with the uncertainty-dependent exploration strategy, but some features that are inconsistent with this strategy appear to be ignored. A critical analysis to directly relate uncertainty and lapse across sessions was also missing. Therefore, although the manuscript has the potential of establishing the uncertainty-dependent exploration strategy as one of the factors contributing to lapses, additional analyses/explanations are needed.</p><p>Essential revisions:</p><p>1) The contrast between regular multisensory trials and &quot;neutral&quot; trials is a clever design. However, the results did not convincingly support the uncertainty-dependent exploration model. As the authors stated &quot;the lapse parameter on neutral trials should match those on auditory trials, since these conditions have comparable levels of perceptual uncertainty&quot;. Judging from Figure 3—figure supplement 1E, this prediction did not hold for the example rat. It is unclear how well it held for the other four rats.</p><p>2) Model comparison results in Figure 3—figure supplement 3C suggest that the inattention model performed as well as the Exploration model for fitting uni/multi-sensory data. However, the results of the model fitting should be more fully disclosed. The results in Figure 3—figure supplement 3G were not conclusive. Namely, the inattention model seemed to outperform the Exploration model for rat#4; both models performed similarly for rat #5, and the Exploration model was better for the other three rats. The example rat in Figure 3—figure supplement 1E also showed other behavioral patterns that are puzzling. When reward was increased for the Right choice, there appeared to be a leftward bias (comparing the &quot;Multisensory&quot; curve in the left panel and the &quot;Increased Right&quot; curve in the right panel). The &quot;equal reward&quot; curve in the right panel showed significantly worse performance than other curves. How representative were these behavioral patterns? Do these patterns invalidate the uncertainty-dependent exploration model?</p><p>3) The two models (inattention and fixed error) used to compare against the exploration model are simplistic and may not serve as a fair comparison. In particular, based on prior literature on similar rodent task, it seems that another model based on motivation + inattention might be a more relevant and reasonable explanation, and should be compared against the exploration model. There is evidence that in sensory discrimination tasks, rodent's behavior exhibits serial choice bias. Specifically, if the last trial yielded a reward, then that could influence the current decision (Busse et al., 2011; Siniscalchi et al., 2019). One reasonable interpretation is that this is a motivational component that is dependent on the prior trial's outcome. Given this, one model that may be worthwhile to try is an outcome-dependent inattention model, where the amount of inattention differs depending on whether the last trial was rewarded or not. Namely, if the last trial was rewarded, then animal has fewer lapses, whereas if the last trial was not rewarded, then animal has more lapses. There is indication that some aspects of the current data support this idea (Figure 4F). How would this type of model contrast with the exploration model? One specific question is, similar to Figure 4F, but if we additionally plot previous L success and previous L failure, then does the reward history for prior L choices influence the proportion of choosing R at high stimulus rate?</p><p>The premise is that the exploratory choices would resemble lapses. This is true in a task design involving two choice options, but probably should be considered as a caveat of the task design. If the task has more than two choices, then one may more confidently distinguish these processes and identify periods of exploration. Some considerations as to how such a task design (or the fact that the current finding only has two options) influences the conclusions should be added in the Discussion.</p><p>4) The claim is that there is uncertainty-driven exploration that could explain the lapse rate. However, the task always employs the same criterion boundary for the discrimination problem, and the stimulus set is fixed across sessions. The animals are presumably over-trained and expert in this task, so it is unclear why they would be incentivized to update values for the stimuli in this sensory discrimination task. The authors presented some data to suggest they continuously learn. Is there a normative explanation for why they should be doing this in the current experiments?</p><p>5) Although the data in Figure 4C appear to support the uncertainty-dependent exploration model, it is possible that, on equal reward trials, the three rats trained for the &quot;increased r<sub>Right</sub>&quot; condition performed much worse than the three rats trained for the &quot;decreased r<sub>Right</sub>&quot; condition. The difference in &quot;Proportion choose high&quot; at 16Hz between the two cohorts for equal reward trials appeared as large as the effects of changing reward. The differences between equal reward trials and &quot;increased/decreased r<sub>Right</sub>&quot; trials might be due to some factors beyond value associations (e.g., how the two cohorts were trained).</p><p>6) There are many variants of models in the manuscript, but they were not presented in sufficient details, making it hard to track what parameters were fixed or fitted separately for different types of trials in a given experiment. For example, for the data in Figure 5, the legend says that the model fits scaled all contralateral values by a single parameter. Does it mean that this scaler was the only free parameter for the inactivation data, after fitting the control data? Or the model was fitted to both control and inactivation data simultaneously, with all but the scaler fixed between the two datasets? If a single scaling parameter can account for the inactivation effects, similar effects would be expected for auditory, visual and multi-sensory decisions for a given rat. But this does not seem to be the case. For example, Rats 8,9,10 in Figure 5—figure supplement 3 showed very different effects between auditory and visual decisions for M2-low rate side inactivation. Similarly, rats 2,3,6 in Figure 9—figure supplement 4 for pStr-low rate side inactivation. It would be helpful to have a table with the fitted parameter values for each experiment/rat, so that readers can better track how the model fitting was done and develop a better sense of how changes in model parameters affect the psychometric curves.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Lapses in perceptual decisions reflect exploration&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Long Ding (Reviewer #1); Alex C Kwan (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require a modest amount of additional new data, as they do with your paper, we are asking that the manuscript be revised to either limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Our expectation is that the authors will eventually carry out the additional experiments and report on how they affect the relevant conclusions either in a preprint on bioRxiv or medRxiv, or if appropriate, as a Research Advance in <italic>eLife</italic>, either of which would be linked to the original paper.</p><p>Summary:</p><p>This manuscript presents an interesting explanation for lapses in perceptual decision making. The authors showed that rats showed imperfect performance on a click-rate-discrimination task. They showed that the amount of lapse depended on whether the decision was based on uni- or multi-sensory stimulus, whether the reward associations were equal or asymmetric for the two choices, and whether M2/pStr was intact. Using precise computational models, they proposed that these lapses were due to the rats' uncertainty-dependent exploration strategy. The authors have addressed most of the concerns raised by the reviewers appropriately, but there is one issue that requires additional clarification.</p><p>Revisions for this paper:</p><p>The original figure of concern actually showed example neutral/auditory trials from different rats. The authors generated new figures showing both types of trials from 5 rats separately (Figure 3—figure supplement 1E and Author response image 2C). In three out of the five rats, for the LOW choice, the lapse was larger for neutral trials; for the HIGH choice, the lapse was larger for auditory trials. This kind of asymmetric difference in lapse appears similar to the predictions for effort manipulation in Figure 4—figure supplement 2. If there was no category-specific value/effort manipulation between neutral and auditory trials, it is not intuitive how the uncertainty-dependent exploration model can account for this asymmetry. An explanation would be helpful.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.55490.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The contrast between regular multisensory trials and &quot;neutral&quot; trials is a clever design. However, the results did not convincingly support the uncertainty-dependent exploration model. As the authors stated &quot;the lapse parameter on neutral trials should match those on auditory trials, since these conditions have comparable levels of perceptual uncertainty&quot;. Judging from Figure 3—figure supplement 1E, this prediction did not hold for the example rat. It is unclear how well it held for the other four rats.</p></disp-quote><p>We thank the reviewers for these kind words about the experimental design and we are very grateful that they brought this issue to our attention. The example rats in Figure 3—figure supplement 1E were intended to demonstrate the relationship between conditions <italic>within</italic> each manipulation, hence a different example rat was chosen for each manipulation (<xref ref-type="fig" rid="respfig1">Author response image 1A</xref> shows the original figure). This yielded misleading patterns <italic>across</italic> manipulations, especially since these were incorrectly labelled &quot;example rat&quot; in the figure and legend. We thank the reviewer for bringing these discrepancies to our attention – we have corrected this and chosen the same example rat across all manipulations (same rat, lc40, as reward panel – <xref ref-type="fig" rid="respfig1">Author response image 1B</xref>) in order to facilitate across-manipulation comparisons. We hope that this revised version of the figure makes it clear that the total lapses on neutral trials (<xref ref-type="fig" rid="respfig1">Author response image 1B</xref>, middle panel, orange trace) are similar to those on auditory trials (<xref ref-type="fig" rid="respfig1">Author response image 1B</xref>, left panel, green trace).</p><fig id="respfig1"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig1-v2.tif"/></fig><p>In addition:(1) An unconstrained descriptive model ( &quot;variable lapse&quot; i.e. 4 independent parameters per condition) fit to all 5 rats reveals that slope and lapse parameters on neutral and auditory conditions lie along the unity line for 4/5 rats (<xref ref-type="fig" rid="respfig2">Author response image 2A</xref>) We have updated the Results section to reflect this.</p><p>(2) The exploration model fits (<xref ref-type="fig" rid="respfig2">Author response image 2C</xref>) demonstrate that the prediction *did* hold for the example rat (1st panel) as well as the other 4 rats: auditory and neutral conditions were constrained to have the same σ and lapse parameters in the exploration model (<xref ref-type="fig" rid="respfig2">Author response image 2B</xref>), and this provides a good fit to the data.</p><fig id="respfig2"><label>Author response image 2.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig2-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>2) Model comparison results in Figure 3—figure supplement 3C suggest that the inattention model performed as well as the Exploration model for fitting uni/multi-sensory data. However, the results of the model fitting should be more fully disclosed. The results in Figure 3—figure supplement 3G were not conclusive. Namely, the inattention model seemed to outperform the Exploration model for rat#4; both models performed similarly for rat #5, and the Exploration model was better for the other three rats. The example rat in Figure 3—figure supplement 1E also showed other behavioral patterns that are puzzling. When reward was increased for the Right choice, there appeared to be a leftward bias (comparing the &quot;Multisensory&quot; curve in the left panel and the &quot;Increased Right&quot; curve in the right panel). The &quot;equal reward&quot; curve in the right panel showed significantly worse performance than other curves. How representative were these behavioral patterns? Do these patterns invalidate the uncertainty-dependent exploration model?</p></disp-quote><p>The reviewer is correct in pointing out that there is individual variability in the best fitting model in Figure 3—figure supplement 3; however it is important to note that the ideal observer model is a limiting case of the inattention/exploration models, and for animals with very small lapse rates, these models are indistinguishable so BIC would strongly prefer the more parsimonious ideal observer model ​ -​ this is the case for both rats 4 and 5 for which the ideal observer provides the best fit according to BIC, suggesting that these rats have very small lapse rates. All 3 rats that are rejected by the ideal observer model i.e. have sizable lapse rates, are best fit by the exploration model. In the revised version of the manuscript, we acknowledge this variability in individuals that are best fit by the ideal observer vs exploration models (Results).</p><p>As for the rat in (Figure 3—figure supplement 1E), the &quot;equal reward&quot; and &quot;increased Right&quot; conditions on the rightmost panel both consist of auditory trials, and the performance on “equal reward” trials is comparable to performance on auditory trials in the “multisensory” or “neutral” experiments (updated left, center panel from the same example rat). We have clarified this in the legend.</p><disp-quote content-type="editor-comment"><p>3) The two models (inattention and fixed error) used to compare against the exploration model are simplistic and may not serve as a fair comparison. In particular, based on prior literature on similar rodent task, it seems that another model based on motivation + inattention might be a more relevant and reasonable explanation, and should be compared against the exploration model. There is evidence that in sensory discrimination tasks, rodent's behavior exhibits serial choice bias. Specifically, if the last trial yielded a reward, then that could influence the current decision (Busse et al., 2011; Siniscalchi et al., 2019). One reasonable interpretation is that this is a motivational component that is dependent on the prior trial's outcome. Given this, one model that may be worthwhile to try is an outcome-dependent inattention model, where the amount of inattention differs depending on whether the last trial was rewarded or not. Namely, if the last trial was rewarded, then animal has fewer lapses, whereas if the last trial was not rewarded, then animal has more lapses. There is indication that some aspects of the current data support this idea (Figure 4F). How would this type of model contrast with the exploration model? One specific question is, similar to Figure 4F, but if we additionally plot previous L success and previous L failure, then does the reward history for prior L choices influence the proportion of choosing R at high stimulus rate?</p><p>The premise is that the exploratory choices would resemble lapses. This is true in a task design involving two choice options, but probably should be considered as a caveat of the task design. If the task has more than two choices, then one may more confidently distinguish these processes and identify periods of exploration. Some considerations as to how such a task design (or the fact that the current finding only has two options) influences the conclusions should be added in the Discussion.</p></disp-quote><p>We fully agree with the reviewers here. If the level of attention were changed following correct/error trials, this could potentially account for the trial history effects: an increase/decrease in attention following success/failure, in combination with an upward or downward shift due to changes in guessing probabilities emerging from updates to the prior/action values (i.e. following success/failure on the R, animal assumes that High/Low rates are more likely -or- assumes that R actions are more/less rewarding.)</p><p>Importantly, in order for this to capture the asymmetry in the data, the two effects would have to be fine-tuned to cancel each other out at low rates and add up at high rates. Further, since this model invokes trial-by-trial updates, a fair comparison to it would be an exploration model combined with trial-by-trial updates of the values of chosen actions based on past outcomes (thus producing the asymmetry, which is seen following both leftward and rightward actions – <xref ref-type="fig" rid="respfig3">Author response image 3</xref>), which is how we currently propose outcomes affect subsequent trials, as we allude to in the discussion on trial-by-trial modeling.</p><fig id="respfig3"><label>Author response image 3.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig3-v2.tif"/></fig><p>However, we can still make predictions for trial-averaged behavior from this model for the different manipulations, by assuming that p(Attend) is modulated by average reward i.e. higher average rewards give rise to greater overall motivation, more attention and fewer lapses. This allows us to compare its predictions with other models on the neutral and reward manipulations:(1) Predictions for matched v. neutral: Since the “matched” and “neutral” trial types are randomized and uncued, the animal doesn't know what the upcoming condition is and the average rewards preceding the two trials should be the same. Hence, the motivated inattention model predicts the same level of attention across the two conditions, just like the regular inattention model, predicting equal lapses (unlike those observed in the data)</p><p>(2) Predictions for reward magnitude manipulation: The motivated inattention​ model can indeed explain the effects of the reward magnitude experiment, by assuming that the higher/lower average reward on increased/decreased reward conditions gives rise to more/less attention, and fewer/more lapses in conjunction with the upward/downward shifts predicted by the regular inattention model. Once again, this does require fine-tuning of the two effects in order to cancel out at low rates. (<xref ref-type="fig" rid="respfig4">Author response image 4</xref> left, center panels)</p><p>3) Predictions for reward probability experiment: In this experiment, leftward actions are probabilistically rewarded (50%) on <italic>highrates</italic> (instead of yielding 0 reward), and always rewarded on low rates – thus increasing the overall proportion of rewarded outcomes and increasing the proportion of leftward trials rewarded, compared to rightward trials.</p><p>– This predicts an increase in overall attention (to both stimulus categories) due to the higher levels of motivation, and hence a decrease in overall lapses</p><p>– It also predicts a non-specific increase in leftward choices due to the leftward biased average rewards yielding more leftward inattentive guesses.</p><p>In particular, these two effects should lead to a bigger downward shift in low rates (as shown in <xref ref-type="fig" rid="respfig4">Author response image 4</xref> right panel)</p><p>However, this is not the effect observed in the data, instead the manipulation only increases leftward choices <italic>for high rates</italic>, thus <italic>increasing</italic> lapses on high rates, and consequently increasing the overall lapse rate – which matches the predictions of the exploration model.</p><fig id="respfig4"><label>Author response image 4.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig4-v2.tif"/></fig><p>We thank the reviewers for the motivated inattention model, and have added it as a new panel (Figure 4—figure supplement 1F). We have also added text in the Discussion about the caveats of a task design with two options, and cited emerging work that offers a possible remedy (Zatka-Haas et al., 2018, Mihali et al., 2018).​</p><disp-quote content-type="editor-comment"><p>4) The claim is that there is uncertainty-driven exploration that could explain the lapse rate. However, the task always employs the same criterion boundary for the discrimination problem, and the stimulus set is fixed across sessions. The animals are presumably over-trained and expert in this task, so it is unclear why they would be incentivized to update values for the stimuli in this sensory discrimination task. The authors presented some data to suggest they continuously learn. Is there a normative explanation for why they should be doing this in the current experiments?</p></disp-quote><p>The reviewers are correct that in the current task, the true category boundary, stimulus-action contingency and expected rewards are fixed. Therefore the normative strategy is to explore until the uncertainty in action values reduces to zero, and then stop exploring. While some features of the task, such as sensory uncertainty, abstractness of the stimulus-response contingency and arbitrariness of the category boundary could lead to increased action value uncertainty to begin with, this normative strategy still predicts zero lapses in the asymptotic limit of training (e.g. <xref ref-type="fig" rid="respfig5">Author response image 5A</xref> simulation with belief in stationary rewards, increasing sensory uncertainty – indicated by cooler colors – reduces speed of reduction in lapse rates, but asymptotic lapse rate is 0).</p><p>A possible normative explanation for the fact that the animals are continuously learning/exploring is that they do <italic>not</italic> assume that the action values are static, but instead entertain the possibility that they drift/change over time (possibly reflecting the statistics of real world rewards). While this model is clearly mismatched to the current task, under this model (i.e. in truly non-stationary worlds) the normative solution is to maintain a low level of exploration to test whether the world has changed or not – we can simulate this using a model that assumes a small rate of non-stationarity in values (<xref ref-type="fig" rid="respfig5">Author response image 5B</xref>.) This model predicts a residual level of uncertainty that never goes to 0, and consequently a residual asymptotic lapse rate scaled by sensory uncertainty. Some animals do indeed achieve close-to-zero lapse rates after extensive training (e.g. Figure 4—figure supplement 2), but for animals that still have residual lapses, it is difficult to distinguish these models with finite training data.</p><p>Fortunately, a unique prediction of a mismatched world model is that it predicts that in the event of a contingency change, subjects should unlearn old contingencies much faster than predicted by a stationary belief model (which would display perseveration and take as many examples to unlearn a contingency as it did to learn it – akin to Ebitz et al., 2019). We have performed preliminary tests of this prediction by reversing the contingency in a small cohort of rats. We observed that rats did indeed unlearn old contingencies much faster than predicted from the stationary belief model, and resembled a model that entertains a small possibility of non-stationarity in values.</p><fig id="respfig5"><label>Author response image 5.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig5-v2.tif"/></fig><p>We have expanded on this point about normativity and included predictions for matched/mismatched world models and tests of contingency change in the Discussion. However, we have not included the results of our contingency change experiments in this manuscript since they are quite preliminary.</p><disp-quote content-type="editor-comment"><p>5) Although the data in Figure 4C appear to support the uncertainty-dependent exploration model, it is possible that, on equal reward trials, the three rats trained for the &quot;increased r<sub>Right</sub>&quot; condition performed much worse than the three rats trained for the &quot;decreased r<sub>Right</sub>&quot; condition. The difference in &quot;Proportion choose high&quot; at 16Hz between the two cohorts for equal reward trials appeared as large as the effects of changing reward. The differences between equal reward trials and &quot;increased/decreased r<sub>Right</sub>&quot; trials might be due to some factors beyond value associations (e.g., how the two cohorts were trained).</p></disp-quote><p>The reviewer is correct in pointing out that there are individual differences between cohorts at baseline, possibly due to differences between the precise history of training data each rat has seen (which we expect to reflect in the subjective action values learnt by each rat).</p><p>For this reason, we restrict all our reward comparisons in Figure 4C to within-cohort comparisons – each rat is first trained on equal reward, then tested with a reward manipulation (either increase or decrease) to measure the effect of the reward manipulation on its behavior relative to baseline (which in the exploration model is captured by scaling only the relevant baseline value). Neither of the cohorts have baseline lapses at ceiling/floor, allowing for measurement of the effect of reward manipulation on both lapses and hence a comparison of the different models. Moreover, the exploration model captures within-individual comparisons relative to baseline by changing high rate action values on the right alone, even though individuals vary substantially in their baseline left/right values (Table 2). We have clarified this in the Results.</p><disp-quote content-type="editor-comment"><p>6) There are many variants of models in the manuscript, but they were not presented in sufficient details, making it hard to track what parameters were fixed or fitted separately for different types of trials in a given experiment. For example, for the data in Figure 5, the legend says that the model fits scaled all contralateral values by a single parameter. Does it mean that this scaler was the only free parameter for the inactivation data, after fitting the control data? Or the model was fitted to both control and inactivation data simultaneously, with all but the scaler fixed between the two datasets? If a single scaling parameter can account for the inactivation effects, similar effects would be expected for auditory, visual and multi-sensory decisions for a given rat. But this does not seem to be the case. For example, Rats 8,9,10 in Figure 5—figure supplement 3 showed very different effects between auditory and visual decisions for M2-low rate side inactivation. Similarly, rats 2,3,6 in Figure 5—figure supplement 4 for pStr-low rate side inactivation. It would be helpful to have a table with the fitted parameter values for each experiment/rat, so that readers can better track how the model fitting was done and develop a better sense of how changes in model parameters affect the psychometric curves.</p></disp-quote><p>We agree. First, to address the point about clarifying models and parameters in the paper, we generated a new table with fit parameters for all the experiments and models in order to clarify parameters and constraints for each of the fits. (Table 1 i.e. Figure 4—source data 1: fits to pooled data across individuals. We generated a second table, Table 2, with individual fits. However, we did not include this in the revised manuscript because we feared this might be cumbersome to include in the supplement).</p><p>As for inactivation fits, the model was fit to both control and inactivation data simultaneously, with a single scalar being the only parameter differing between the two datasets. We have added a separate section describing inactivation modeling in the Materials and methods to clarify this point.</p><p>Second, we have addressed the issue that the fits in (Figure 5—figure supplement 3,4) were unclear. In the original manuscript, they were indeed all descriptive, unconstrained fits (i.e. 4 parameters per fit x 3 modalities x 2 perturbation conditions = 24 params per rat). We have updated this figure with individual fits of the best fitting model for each rat (biased evidence/value/effort, which have 11 control + scalar = 12 params per rat). Despite being heavily constrained, these account for all rats quite well.</p><p>All three models of inactivation are capable of producing effects with differing strengths across modalities: the key intuition is that these effects interact with the baseline sensory noise (biased evidence) and baseline values/exploratoriness (biased value and biased effort), producing the strongest effects for modalities with the highest sensory noise/exploration. The simulation (<xref ref-type="fig" rid="respfig6">Author response image 6</xref>) illustrates this difference. Performance on control trials for left- and right-biased baseline action valus shows only subtle differences (compare solid traces on top, bottom). However, the same inactivation strength (i.e. multiplicative/additive factor) drives strikingly different effects on these conditions (compare dashed traces for top, bottom). This highlights the strength of a model that can estimate action values from lapse rates. This approach can reconcile seemingly different effects across conditions within the same animal (or across animals) with a single change in action value, without needing to invoke separate mechanisms for each condition.</p><fig id="respfig6"><label>Author response image 6.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig6-v2.tif"/></fig><p>However despite the ability of the model to account for disparate changes in the psychometric function, we agree with the reviewer's assessment that the biased value model does not fully account for the effects in some rats. In Rats 8,9 (M2 low rate), 2(pStr High),3(pStr low) and 6(pStr high and low), the best fitting model was still one in which action values changed. But, importantly, the winning model for those rats was the one in which a single scalar 'effort' (i.e. negative, stimulus-independent value) was added to the contralateral side, rather than a single multiplicative (i.e. stimulus-dependent) value scaling. This suggests that the inactivations affected value additively, rather than multiplicatively in these rats. In the revised version of the text, we address these individual differences (and display fits from the best fitting model for each rat in Figure 5—figure supplements 3,4), and acknowledge that additional recording and inactivation studies might shed light on why disruptions drive changes that are sometimes additive and sometimes multiplicative. We argue that our approach nonetheless gives an experimenter considerable power in interpreting inactivations that diverge across conditions.[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Revisions for this paper:</p><p>The original figure of concern actually showed example neutral/auditory trials from different rats. The authors generated new figures showing both types of trials from 5 rats separately (Figure 3—figure supplement 1E and <xref ref-type="fig" rid="respfig2">Author response image 2C</xref>). In three out of the five rats, for the LOW choice, the lapse was larger for neutral trials; for the HIGH choice, the lapse was larger for auditory trials. This kind of asymmetric difference in lapse appears similar to the predictions for effort manipulation in Figure 4—figure supplement 2. If there was no category-specific value/effort manipulation between neutral and auditory trials, it is not intuitive how the uncertainty-dependent exploration model can account for this asymmetry. An explanation would be helpful.</p></disp-quote><p>The reviewers have correctly identified that while auditory and neutral trials have comparable sigmas and total lapse rates, some rats indeed show a slight low-rate bias on auditory trials compared to neutral and multisensory trials (<xref ref-type="fig" rid="respfig8">Author response image 8</xref>). While all models considered can account for this through their free “bias” and “lapse-bias” parameters (hence not affecting model comparisons), none of them explain its existence.</p><p>Instead, we think that this bias can be explained by animals not using a pure &quot;flash/pulse rate&quot; decoder to solve the task, but instead using a hybrid decoder that incorporates both &quot;flash/pulse rate&quot; and &quot;total flash/pulse count&quot; information. These two features are correlated with each other and with reward on all trial types, making them both susceptible to reward-based credit assignment – we reported a similar hybrid &quot;rate+count&quot; strategy in rats and mice on a visual-only variant of the rate task (Odoemene et al., 2018, Figure 3). Note that neutral and multisensory trials however are offset on the &quot;count&quot; dimension compared to auditory trials, since they have additional events for the same &quot;rate&quot; (twice as many on multisensory, 12 additional on neutral – First column in <xref ref-type="fig" rid="respfig7">Author response image 7</xref>).</p><p>As a result, only an observer that uses a pure &quot;rate&quot; decoder would have an unbiased psychometric across all conditions, centered at the true category boundary of 12.5 (First row in <xref ref-type="fig" rid="respfig7">Author response image 7</xref>) – this is true of rat 5 in <xref ref-type="fig" rid="respfig8">Author response image 8</xref>. However, even a weak influence of count would bias conditions with respect to each other. For instance, an animal that uses a &quot;hybrid&quot; decoder that is unbiased for multisensory and neutral conditions would be biased towards low rates on auditory trials, with increasing use of count information producing greater biases (Second, third, fourth rows of <xref ref-type="fig" rid="respfig7">Author response image 7</xref> – effects of count information adding 1/15th as much, 1/7th as much or just as much evidence as rate information).</p><p>Such a hybrid decoder would translate into different <italic>effective</italic> state-action value pairs for different conditions based on their position in this 2-d space, with unisensory conditions having the highest asymmetry between low and high rate action values. In the fixed error model, this asymmetry would simply produce horizontal biases in the psychometric function, but in both inattention and exploration models, this asymmetry would additionally bias the lapses. Hence, the varying biases and lapse biases seen in the other 4 rats (<xref ref-type="fig" rid="respfig8">Author response image 8</xref>) could arise from varying degrees of use of count information. Note that if an animal using a hybrid decoder was unbiased on auditory trials, then it would show a high-rate bias on multisensory trials, as is observed in some of the animals in the 1st cohort (unisensory vs. multisensory)</p><p>We tested this “hybrid decoder” hypothesis in an independent cohort of rats where we increased/decreased the duration of auditory trials to increase/decrease count information without changing rate information (as per Odoemene et al., 2018), and indeed found evidence for a hybrid decoder with a weak influence of count (<xref ref-type="fig" rid="respfig9">Author response image 9</xref>), however we think these results are outside the scope of the current manuscript. In case other readers share the reviewers’ concern about bias, we now mention the count bias and refer to previous work.</p><fig id="respfig7"><label>Author response image 7.</label><caption><title>Use of count information generates bias in psychometric functions.</title><p>Simulations demonstrating the effect of 4 different linear decoders (1st column) on psychometric functions under the fixed error (2nd column), inattention (3rd column) and exploration (4th column) models. Dotted black lines indicate the true category boundary that separates “low” and “high” stimulus categories, solid black lines indicate the subjective category boundary for each decoder. Colored dots indicate stimulus sets in auditory (green), neutral (orange) and multisensory (red) conditions. Open circles indicate point of subjective equality i.e. stimulus that produces equal “high” and “low” evidence for each condition. Rate-only decoder (1st row) aligns with the true category boundary, producing unbiased psychometric functions across conditions, with models differing only in the total lapse rate of each condition. Hybrid decoders incorporating a small amount of count information (2nd row: 1/15th as much as rate, 3rd row: 1/5th as much as rate, 4th row: just as much as rate) that are unbiased on multisensory, neutral conditions produce a low-rate bias on auditory trials, with more use of count information producing higher bias. This produces horizontal shifts (i.e. bias) across models, and additionally produces vertical shifts (i.e. lapse bias) in inattention, exploration models, while preserving the predictions for total lapse rates across models/conditions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig7-v2.tif"/></fig><fig id="respfig8"><label>Author response image 8.</label><caption><title>Bias in psychometric functions of individual rats.</title><p>Data from the 5 rats used in the neutral experiment, on auditory (green), neutral (orange) and multisensory (red) conditions, demonstrating individual variability in low-rate bias on auditory trials, compared to neutral/multisensory trials. Some rats (e.g. rightmost panel) show almost no bias, resembling the “rate-only” decoders, while others resemble “hybrid” decoders with weak influences fromcount information.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig8-v2.tif"/></fig><fig id="respfig9"><label>Author response image 9.</label><caption><title>Duration manipulation on auditory trials confirms weak influence of count.</title><p>Data from 4 rats (right) shows that increasing (light green) or decreasing (brown) the duration of auditory trials produces slight high- or low-rate biases, resembling a hybrid decoder with a weak influence of count information(middle panel left).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55490-resp-fig9-v2.tif"/></fig></body></sub-article></article>