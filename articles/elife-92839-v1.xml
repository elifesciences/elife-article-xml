<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">92839</article-id><article-id pub-id-type="doi">10.7554/eLife.92839</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.92839.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Ocular dominance-dependent binocular combination of monocular neuronal responses in macaque V1</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-336400"><name><surname>Zhang</surname><given-names>Sheng-Hui</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-336401"><name><surname>Zhao</surname><given-names>Xing-Nan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-360727"><name><surname>Jiang</surname><given-names>Dan-Qing</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-100693"><name><surname>Tang</surname><given-names>Shi-Ming</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0294-3259</contrib-id><email>tangshm@pku.edu.cn</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-49953"><name><surname>Yu</surname><given-names>Cong</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8453-6974</contrib-id><email>yucong@pku.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>School of Psychological and Cognitive Sciences, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>PKU-Tsinghua Center for Life Sciences, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>School of Life Sciences, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>IDG-McGovern Institute for Brain Research, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gaier</surname><given-names>Eric D</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00dvg7y05</institution-id><institution>Boston Children's Hospital</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>03</day><month>04</month><year>2024</year></pub-date><volume>13</volume><elocation-id>RP92839</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-10-25"><day>25</day><month>10</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-10-27"><day>27</day><month>10</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.10.27.564359"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-02-02"><day>02</day><month>02</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.92839.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-03-19"><day>19</day><month>03</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.92839.2"/></event></pub-history><permissions><copyright-statement>© 2024, Zhang, Zhao et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Zhang, Zhao et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-92839-v1.pdf"/><abstract><p>Primates rely on two eyes to perceive depth, while maintaining stable vision when either one eye or both eyes are open. Although psychophysical and modeling studies have investigated how monocular signals are combined to form binocular vision, the underlying neuronal mechanisms, particularly in V1 where most neurons exhibit binocularity with varying eye preferences, remain poorly understood. Here, we used two-photon calcium imaging to compare the monocular and binocular responses of thousands of simultaneously recorded V1 superficial-layer neurons in three awake macaques. During monocular stimulation, neurons preferring the stimulated eye exhibited significantly stronger responses compared to those preferring both eyes. However, during binocular stimulation, the responses of neurons preferring either eye were suppressed on the average, while those preferring both eyes were enhanced, resulting in similar neuronal responses irrespective of their eye preferences, and an overall response level similar to that with monocular viewing. A neuronally realistic model of binocular combination, which incorporates ocular dominance-dependent divisive interocular inhibition and binocular summation, is proposed to account for these findings.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>binocular combination</kwd><kwd>ocular dominance</kwd><kwd>gain control</kwd><kwd>primary visual cortex</kwd><kwd>two-photon imaging</kwd><kwd>macaque</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>2022ZD0204600</award-id><principal-award-recipient><name><surname>Tang</surname><given-names>Shi-Ming</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31230030</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Cong</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31730109</award-id><principal-award-recipient><name><surname>Tang</surname><given-names>Shi-Ming</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100007937</institution-id><institution>Peking University</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Tang</surname><given-names>Shi-Ming</given-names></name><name><surname>Yu</surname><given-names>Cong</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Binocular combination of monocular neuronal responses involves response suppression for neurons more preferring one eye and response enhancement for neurons more preferring both eyes in macaque V1.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Human and non-human primates often rely on binocular disparity, which refers to the differences between the retinal images of the two eyes, to perceive depth (stereopsis). In the meantime, the brain maintains a stable perception of the visual world when either one eye or both eyes are open and the light entering the brain is either halved or doubled. Much has been known regarding the neural foundations of stereopsis (<xref ref-type="bibr" rid="bib2">Barlow et al., 1967</xref>; <xref ref-type="bibr" rid="bib13">Henriksen et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Parker et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Welchman, 2016</xref>; <xref ref-type="bibr" rid="bib28">Read, 2021</xref>). Nevertheless, whether and how the neurons respond differently to monocular and binocular stimulations is less studied (<xref ref-type="bibr" rid="bib26">Poggio and Fischer, 1977</xref>; <xref ref-type="bibr" rid="bib27">Prince et al., 2002</xref>; <xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Mitchell et al., 2022</xref>). Adding to the complexity is the fact that many V1 neurons, although responding to stimulations from both eyes, have various degrees of eye preferences (<xref ref-type="bibr" rid="bib15">Hubel and Wiesel, 1962</xref>; <xref ref-type="bibr" rid="bib29">Shatz and Stryker, 1978</xref>). Thus, a more complete picture of binocular combination of monocular responses shall consider the potential role of eye preference. This forms the basis of the current study, aiming to provide a more detailed understanding of how V1 neurons with varying eye preferences contribute to binocular vision.</p><p>Previous neurophysiological recording studies have revealed that, overall, the binocular responses of macaque V1 neurons are lower than the arithmetic sum of their respective monocular responses to the left and right eyes (<xref ref-type="bibr" rid="bib27">Prince et al., 2002</xref>; <xref ref-type="bibr" rid="bib21">Mitchell et al., 2022</xref>), but are stronger than the monocular responses when the neurons’ preferred eye is stimulated (<xref ref-type="bibr" rid="bib21">Mitchell et al., 2022</xref>). Furthermore, there is evidence suggesting that neurons’ eye preferences play important functional roles. In a study by <xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref>, it was reported that the responses of monocular neurons are more likely to be suppressed than facilitated by binocular stimulation. As our forthcoming results will indicate, this conclusion holds true when considering the monocular baseline as either the sum of the monocular responses or the monocular responses of either eye. <xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref> also documented similar responses to monocular stimulation between neurons with monocular and binocular preferences, as well as comparable responses of binocular neurons to monocular and binocular stimulations, which are not supported by our data. In addition, <xref ref-type="bibr" rid="bib22">Mitchell et al., 2023</xref> reported that the binocular combination of monocular stimuli with different contrasts is also influenced by neurons’ eye preferences.</p><p>A more comprehensive understanding of binocular combination of monocular responses, as well as the influences of eye preferences, can be obtained from large samples of neurons in neighboring ocular dominance columns. This approach allows for quantitative descriptions with sufficient statistical power and analysis through computational modeling. Two-photon calcium imaging is well-suited for this task as it can record thousands of neurons simultaneously at single-neuron resolution. In this study, we used a two-photon calcium imaging setup that was custom-tailored for recording in awake macaques (<xref ref-type="bibr" rid="bib19">Li et al., 2017</xref>) to measure the responses of V1 superficial-layer neurons to monocular and binocular stimulations. Additionally, we propose a neuronally realistic binocular combination model that takes into account ocular dominance-dependent interocular divisive inhibition and binocular summation to interpret the gathered data.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We recorded responses of V1 superficial-layer neurons to monocular (contralateral and ipsilateral) and binocular stimulations in three awake, fixating macaques. The stimulus was a high-contrast (0.9) Gabor grating presented at various orientations and spatial frequencies (SFs). Recordings were performed within the same response field of view (FOV) at two cortical depths in first two monkeys (MA &amp; MB), and at a single depth in the third monkey (MC) as the first two monkeys had displayed similar results at two depths (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). A total of 10,168 neurons were identified through imaging processing, with 9390 (92.3%) tuned to orientation, SF, or both. Results from these orientation- and/or SF-tuned neurons were used in subsequent data analysis.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Eye preferences of V1 superficial-layer neurons in three macaques.</title><p>(<bold>A</bold>) Two-photon imaging. Average two-photon images over a recording session for each response FOV. MA_200: Monkey A at a 200 μm cortical depth. (<bold>B</bold>) Ocular dominance functional maps of each FOV/depth at single-neuron resolution. (<bold>C</bold>) Frequency distributions of neurons of each FOV/depth as a function of ocular dominance index. Relevant data are provided in the source data file: <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Source data of <xref ref-type="fig" rid="fig1">Figure 1B-C</xref>.</title></caption><media mimetype="application" mime-subtype="matlab-mat" xlink:href="elife-92839-fig1-data1-v1.mat"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-92839-fig1-v1.tif"/></fig><p>V1 superficial-layer neurons exhibited various degrees of eye preferences, consistent with the classical findings of <xref ref-type="bibr" rid="bib16">Hubel and Wiesel, 1968</xref>. An ocular dominance index (ODI) was calculated to characterize each neuron’s eye preference: ODI = (R<sub>i</sub> – R<sub>c</sub>)/(R<sub>i</sub> +R<sub>c</sub>), in which R<sub>i</sub> and R<sub>c</sub> represented the neuron’s respective peak responses to ipsilateral and contralateral stimulations on the basis of data fitting (see Materials and methods). An ODI of –1 or 1 would indicate complete contralateral or ipsilateral eye preference, respectively, while an ODI of 0 would indicate equal preferences to both eyes. The ocular dominance functional maps at single-neuron resolution, especially those of Monkeys A and C, revealed regions of neurons preferring either the contralateral (blue) or the ipsilateral eye (red), along with transitional zones where neurons showed preferences for both eyes (white) (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The ocular dominance maps were similar at two cortical depths in Monkeys A and B, suggesting the presence of ocular dominance columns (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The frequency distributions of ODIs suggest more binocular neurons than monocular neurons in V1 superficial layers (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), similar to the normal distribution of ocularity index in <xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref>.</p><p>The responses of individual neurons were plotted against the ocular dominance index (ODI) when monocular stimulation was presented through the contralateral eye (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) or the ipsilateral eye (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). As expected, neurons with more negative ODIs responded stronger when the contralateral eye was stimulated, and those with more positive ODIs responded stronger when the ipsilateral eye was stimulated. The responses declined as neurons became more binocular. Interestingly, when both eyes were stimulated, the response differences among neurons of different eye preferences became not obvious (<xref ref-type="fig" rid="fig2">Figure 2C</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>A comparison of neuronal responses to monocular and binocular stimulations.</title><p>(<bold>A</bold>) Responses of individual neurons against their ocular dominance indices with contralateral stimulation. (<bold>B</bold>) Responses of the same neurons against their ocular dominance indices with ipsilateral stimulation. (<bold>C</bold>) Binocular responses of the same neurons. (<bold>D</bold>) The difference between binocular and monocular responses (R<sub>b</sub> – max(R<sub>i</sub>, R<sub>c</sub>)). Each vertical line represents one neuron. To summarize the results, neurons of each FOV/depth are evenly divided into 60 bins in the order of the ocular dominance index. White dots represent the median responses of respective bins and are connected with a black line. (<bold>E</bold>) The differences between binocular and monocular responses of individual neurons pooled over five FOVs/depths. (<bold>F</bold>) Binocular modulation index as a function of absolute ODI and the linear fit. The binocular modulation index of each neuron was defined as (R<sub>b</sub> – max (R<sub>i</sub>, R<sub>c</sub>))/(R<sub>b</sub> +max (R<sub>i</sub>, R<sub>c</sub>)). Relevant data are provided in the source data file: <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Source data of <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title></caption><media mimetype="application" mime-subtype="matlab-mat" xlink:href="elife-92839-fig2-data1-v1.mat"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-92839-fig2-v1.tif"/></fig><p>These trends are more easily appreciated when comparing the differences between binocular and monocular responses of the same neurons for each FOV/depth in <xref ref-type="fig" rid="fig2">Figure 2D</xref>. The response changes varied among individual neurons - some showing response enhancement and some showing inhibition - likely reflecting the behaviors of tuned excitatory and inhibitory neurons, respectively (<xref ref-type="bibr" rid="bib26">Poggio and Fischer, 1977</xref>). However, the overall response changes (represented by white dots connected by a black line, <xref ref-type="fig" rid="fig2">Figure 2D and E</xref>) are consistent among all five datasets. Specifically, under monocular stimulation, when only considering the neuronal responses to the preferred eye (i.e. a neuron’s higher response to ipsilateral vs. contralateral stimulations), more monocular neurons (ODIs farther from 0) tended to exhibit stronger responses compared to more binocular neurons (ODIs closer to 0). However, under binocular stimulation, the overall responses of more monocular neurons were suppressed, and those of more binocular neurons were enhanced, by binocular stimulation. These trends are best appreciated in pooled data over five FOVs/depths (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). Furthermore, linear regression verified a significant dependence of binocular modulation on absolute ODI (y=–0.36 x+0.14, p&lt;0.001) (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). This means that the responses of neurons with lower absolute ODI (i.e., binocular neurons) tended to be more enhanced, and responses of neurons with higher absolute ODI (i.e. monocular neurons) tended to be more suppressed.</p><sec id="s2-1"><title>Modeling monocular and binocular responses</title><p>We used the following steps to develop a model that can account for the current monocular responses and their binocular combination. Monocular and binocular data of each FOV/depth, as well as the pooled data, were first normalized by the respective median of the binocular responses of all neurons in the same FOV/depth. The normalized data were then divided into 60 bins in the order of the ocular dominance index, and the median values of 60 bins were used for model fitting (<xref ref-type="fig" rid="fig3">Figure 3A–C</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Modeling monocular and binocular responses.</title><p>(<bold>A</bold>, <bold>B</bold>) Median neuronal responses to contralateral and ipsilateral stimulations as a function of ocular dominance index and respective data fitting with <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. Neurons are evenly divided into 60 bins in the order of the ocular dominance index, with each bin containing 29–33 neurons that varied among different FOVs/depths (156 neurons for the pooled data). Each datum represents the median response of a bin. Free parameter k was kept equal during contralateral and ipsilateral data fitting. (<bold>C</bold>) Binocular responses as a function of ocular dominance index and data fitting with <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> for the same bins of neurons. During binocular data fitting, parameters k, m<sub>i</sub>, and m<sub>c</sub> were inherited from monocular data fitting, and only b was a free-changing parameter. (<bold>D</bold>) The values of free parameters from monocular and binocular data fitting.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-92839-fig3-v1.tif"/></fig></sec><sec id="s2-2"><title>Monocular responses</title><p>First, a neuron’s monocular responses to contralateral and ipsilateral stimulations were respectively described by a divisive gain control model:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:mo>.</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:mo>.</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Here, S<sub>c</sub> and S<sub>i</sub> were stimulus contrasts, w<sub>c</sub> and w<sub>i</sub> were linear transformations of a neuron’s ocular dominance index from [–1 1] to [0 1]: w<sub>c</sub> = (ODI +1)/2 and w<sub>i</sub> = 1 – w<sub>c</sub>, m<sub>c</sub> and m<sub>i</sub> represented monocular nonlinearity, and k represented divisive gain control. Because S<sub>c</sub> and S<sub>i</sub> in our experiments were 0.9, which were about equal to 1 (full contrast) due to neuronal response saturation, the above equations were simplified as<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p><xref ref-type="disp-formula" rid="equ2">Equation 2</xref> was used to fit the binned median contralateral and ipsilateral data (<xref ref-type="fig" rid="fig3">Figure 3A &amp; B</xref>), with the parameter k being equal for contralateral and ipsilateral responses. The fitting revealed that m<sub>c</sub> and m<sub>i</sub> were negative and close to –1, which resulted in a quick decline of <inline-formula><mml:math id="inf1"><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:math></inline-formula> and a quick increase of <inline-formula><mml:math id="inf2"><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:math></inline-formula> as a function of the ocular dominance index since w<sub>c</sub> and w<sub>i</sub> ϵ [0, 1]. The fit quality indices (<xref ref-type="bibr" rid="bib3">Busse et al., 2009</xref>) ranged 0.92–0.94 for the contralateral condition (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) and 0.87–0.93 for the ipsilateral condition (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), suggesting adequate goodness of fit. The fitting parameters are listed in <xref ref-type="fig" rid="fig3">Figure 3D</xref>.</p></sec><sec id="s2-3"><title>Binocular responses</title><p><xref ref-type="fig" rid="fig2">Figure 2D–F</xref> earlier has indicated that the overall neuronal responses to binocular stimulation change from suppression to enhancement as neurons’ ocular dominance changes from monocular to binocular, which may reflect the ocular dominance-dependent net effect of interocular suppression and binocular summation. Therefore, we added interocular response suppression to <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> by letting monocular responses from each eye be further normalized by an interocular suppression factor w<sub>i</sub><sup>b</sup> or w<sub>c</sub><sup>b</sup> (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). In other words, the strength of interocular response suppression was decided by the linearly transformed ODI with a nonlinear exponent b. Finally, the normalized responses from two eyes were summed to simulate the binocular responses of neurons R<sub>b</sub>, completing the model of binocular combination (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>).<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Although not shown in <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, we also assumed that the nonlinear exponent b also depends on the contrast of the stimulus presented to the other eye (i.e., S<sub>c</sub> or S<sub>i</sub>). Consequently, when S<sub>c</sub> or S<sub>i</sub> = 0 under monocular stimulation, R<sub>c</sub> or R<sub>i</sub> = 0 (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>), and interocular suppression w<sub>i</sub><sup>b</sup> or wc<sub>b</sub> = 1, so <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> changes back to <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. It is only when S<sub>c</sub> and S<sub>i</sub> are equal and close to 1, as in the current study, that interocular suppression and binocular combination would be in the current <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> format.</p><p>When fitting binocular responses, the parameters m<sub>i</sub>, m<sub>c</sub>, and k were inherited from earlier monocular data fitting and remained fixed. Only b was allowed to change. Data fitting resulted in flat binocular response functions (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) with satisfactory goodness-of-fit (fit quality index = 0.88–0.92).</p><p>The effects of interocular suppression and binocular summation in the model, as well as their contributions to the binocular response, may be better appreciated in <xref ref-type="fig" rid="fig4">Figure 4</xref>. <xref ref-type="fig" rid="fig4">Figure 4A</xref> uses <xref ref-type="disp-formula" rid="equ2 equ3">Equations 2 and 3</xref> and the parameters from fitting of pooled data (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) to simulate the contralateral (blue curve with label R<sub>c</sub>), ipsilateral (red curve with label R<sub>i</sub>), and binocular (black curve) response functions against the ocular dominance index. The arithmetic sum of contralateral and ipsilateral response functions was also simulated (grey dashed curve labeled R<sub>i</sub> +R<sub>c</sub>). In addition, neuronal responses to preferred eye stimulation would consist of the higher branches of contralateral and ipsilateral response functions. It is apparent that binocular responses cannot be explained by the sum of monocular responses, as binocular responses are substantially lower than the summed monocular responses for both monocular and binocular neurons. Nor can binocular responses be explained by the responses to the preferred eye, as binocular responses are also mostly lower than those to the preferred eye (the larger of the two monocular responses) for monocular neurons. Instead, the median of the binocular response function (black arrow by y-axis) in each data set is close to but still more or less higher than the median of the contralateral (blue arrow) or ipsilateral response function (red arrow), which is consistent with previous reports (<xref ref-type="bibr" rid="bib27">Prince et al., 2002</xref>; <xref ref-type="bibr" rid="bib21">Mitchell et al., 2022</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Monocular and binocular responses modeled with binocular suppression and binocular summation.</title><p>(<bold>A</bold>) The solid blue, red, and black curves are respectively simulations of the contralateral, ipsilateral, and binocular responses on the basis of fitting of pooled data (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). The grey dashed curve simulates binocular responses as the arithmetic sum of contralateral and ipsilateral responses. The higher branches of contralateral and ipsilateral response functions represent monocular responses with preferred eye stimulation. The black, blue, and red arrows indicate the median binocular, contralateral, and ipsilateral responses, respectively, from pooled data. The shadowed area indicates the region where actual neurons existed on the basis of the ocular dominance index. (<bold>B</bold>) Interocular suppression. The contralateral and ipsilateral responses (R<sub>c</sub> &amp; R<sub>i</sub>) are divided by respective interocular suppression factors W<sub>c</sub><sup>b</sup> and W<sub>i</sub><sup>b</sup> to produce interocular-suppressed responses R<sub>c</sub>/w<sub>c</sub><sup>b</sup> and R<sub>i</sub>/w<sub>i</sub><sup>b</sup>. (<bold>C</bold>) Binocular summation. R<sub>c</sub>/w<sub>c</sub><sup>b</sup> and R<sub>i</sub>/w<sub>i</sub><sup>b</sup> are summed to produce the final binocular responses R<sub>b</sub>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-92839-fig4-v1.tif"/></fig><p><xref ref-type="fig" rid="fig4">Figure 4B</xref> plots the interocular suppression factor w<sub>c</sub><sup>b</sup> (dotted blue curve) for the contralateral response R<sub>c</sub> (solid blue curve from 4 A), and w<sub>i</sub><sup>b</sup> (dotted red curve) for the ipsilateral response R<sub>i</sub> (solid red curve from 4 A). The interocular suppression factors w<sub>c</sub><sup>b</sup> and w<sub>i</sub><sup>b</sup> are larger with neurons that are more monocular than with neurons that are more binocular. The R<sub>c</sub> and R<sub>i</sub> are divided by the respective interocular suppression factors, producing the normalized contralateral responses (dashed blue curve labeled R<sub>c</sub>/w<sub>c</sub><sup>b</sup>) and ipsilateral responses (dashed red curve labeled R<sub>i</sub>/w<sub>i</sub><sup>b</sup>). These normalized curves are lower than original monocular responses, especially for neurons that are more monocular (ODIs farther from 0), showing interocular suppression.</p><p>Then the normalized monocular curves are summed up in <xref ref-type="fig" rid="fig4">Figure 4C</xref>, which represents binocular summation and produces the final binocular responses (R<sub>b</sub>). Therefore, as a result of combined interocular suppression and binocular summation, the final curve for binocular responses becomes nearly flat within the data range.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The current study compared the responses of large samples of V1 superficial-layer neurons to monocular and binocular stimulations in three macaques. The monocular response functions exhibited drastic changes as a function of the ocular dominance index, but binocular response functions remained largely flat, regardless of neurons’ eye preferences. Modeling efforts indicated that when signals from two eyes are combined, interocular divisive suppression, which is more prominent with neurons preferring one eye, and binocular summation, which is more prominent with binocular neurons, together produce the nearly flat binocular response function within a broad range of ocular dominance indices. These findings imply that at least for neurons in superficial layers of V1, significant ocular dominance may stem from a release of interocular suppression during monocular stimulation, an unusual viewing scenario as our vision is typically binocular, rather than a lack of binocular combination of inputs from upstream monocular neurons.</p><p>We introduced this paper by citing the stable vision with monocular or binocular viewing. Relevant to this issue, in <xref ref-type="fig" rid="fig4">Figure 4A</xref> we observe that the median binocular neuronal responses is only marginally higher than those of monocular responses from each eye (black vs. red and blue arrows), consistent with earlier reports (<xref ref-type="bibr" rid="bib27">Prince et al., 2002</xref>; <xref ref-type="bibr" rid="bib21">Mitchell et al., 2022</xref>). The overall similarity between monocular and binocular responses likely plays a significant role in maintaining stable vision in both viewing conditions. What captivates us is the finding that seemingly very small response changes represent the net effects of profound binocular suppression with monocular neurons and facilitation with binocular neurons. Moreover, the slightly elevated binocular responses hint at possible further modulation by additional mechanisms to sustain stable vision.</p><p>In the study by <xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref>, they found that monocular and binocular neurons exhibit similar responses under monocular stimulation, with only monocular neurons, but not binocular neurons, being significantly suppressed by binocular stimulation. In contrast, our results reveal that monocular neurons show much stronger responses to stimulation in the preferred eye compared to binocular neurons under the same monocular stimulation (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Moreover, while we confirm the presence of interocular suppression in monocular neurons responding to the preferred eye as observed in <xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref>, our results also indicate enhanced responses in binocular neurons to binocular stimulation. The large diversity of binocular responses from neurons with similar eye preferences (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) implies that obtaining accurate statistical estimates with small and potentially biased samples of neurons in electrode recording experiments may be challenging. In addition, it remains unclear whether the discrepancies observed are caused by differences in temporal resolutions of electrode recording and calcium imaging techniques. The results of <xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref> represent changes of neuronal spike activities over a period of approximately 50–200ms after stimulus onset, which may reflect the sustained neuronal responses to the stimulus and possible feedback signals. In contrast, calcium signals are much slower and capture aggregated neuronal responses over a longer period up to 1000ms in the current study, which should theoretically reduce through averaging, rather than exaggerate, the differences between monocular and binocular responses. However, we cannot rule out the possibility that neuronal response changes beyond 200ms may contribute to these discrepancies.</p><p>Binocular combination of monocular signals has been understood to involve both interocular suppression and binocular summation (<xref ref-type="bibr" rid="bib6">DeSliva and Bartley, 1930</xref>; <xref ref-type="bibr" rid="bib5">Cohn and Lasley, 1976</xref>; <xref ref-type="bibr" rid="bib18">Li and Atick, 1994</xref>). Many more recent models have adopted divisive normalization to explain interocular suppression (e.g. <xref ref-type="bibr" rid="bib4">Cogan, 1987</xref>; <xref ref-type="bibr" rid="bib1">Anderson and Movshon, 1989</xref>; <xref ref-type="bibr" rid="bib7">Ding and Sperling, 2006</xref>; <xref ref-type="bibr" rid="bib23">Moradi and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib14">Huang et al., 2010</xref>; <xref ref-type="bibr" rid="bib8">Ding et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Mitchell et al., 2023</xref>). Our modeling work suggests that a similar divisive interocular suppression and binocular summation model can effectively account for changes in neuronal responses under monocular and binocular stimulations, with the distinction that the divisive interocular suppression is additionally controlled by neurons’ ocularity preferences. The critical role of ocular dominance has been largely overlooked in extant binocular vision models to our knowledge, with exceptions that <xref ref-type="bibr" rid="bib1">Anderson and Movshon, 1989</xref> in their model incorporating multiple ocular dominance channels to explain psychophysical adaptation data, and by <xref ref-type="bibr" rid="bib22">Mitchell et al., 2023</xref> who showed that neurons’ ocularity preference influences binocular combination of different contrasts from two eyes. We hope that our two-photon imaging results can be incorporated into future neuronally plausible models of binocular vision.</p><p>On the basis of current findings, future two-photon imaging work shall aim to compare neural responses to monocular and binocular stimulations with uneven effective stimulus contrasts due to physical contrast differences (<xref ref-type="bibr" rid="bib1">Anderson and Movshon, 1989</xref>; <xref ref-type="bibr" rid="bib22">Mitchell et al., 2023</xref>), monocular adaptation (<xref ref-type="bibr" rid="bib1">Anderson and Movshon, 1989</xref>), short-term monocular deprivation (<xref ref-type="bibr" rid="bib20">Lunghi et al., 2011</xref>), and the relevant roles of ocular dominance of individual neurons. These investigations would enhance the understanding of abnormal binocular vision in patients with strabismus and amblyopia. In addition, in our experiments, binocular stimuli were presented with zero disparity, which best affected the responses of neurons with zero-disparity tuning (including tuned excitatory and inhibitory neurons, <xref ref-type="fig" rid="fig2">Figure 2</xref>). A more realistic model of binocular combination also requires the consideration of neurons with other disparity-tuning profiles.</p><sec id="s3-1"><title>Limitations of two-photon calcium imaging</title><p>While two-photon calcium imaging has the advantage of sampling a large number of neurons at cellular resolution with low sampling bias, it also has its known limitations that would position it as a complementary research tool to electrophysiological recording. For example, two-photon imaging can only sample neurons from superficial-layers, while binocular neurons also exist in deeper layers, and even neurons in the input layer are affected by feedback from downstream binocular neurons to exhibit binocular response properties (<xref ref-type="bibr" rid="bib9">Dougherty et al., 2019</xref>). Furthermore, calcium signals are relatively slow and cannot capture the fast dynamics of neuronal responses. Consequently, to gain a more comprehensive understanding of the neuronal mechanisms involved in the binocular integration of monocular responses, combining both two-photon calcium imaging and electrophysiological recordings may offer a more holistic perspective.</p><p>In addition, it is important to consider that calcium signals may exaggerate the nonlinear properties of neurons. Although calcium signals indicated by GCaMP5, our preferred calcium indicator, displays a linear relationship to neuronal spike rates within a range of 10–150 Hz (<xref ref-type="bibr" rid="bib19">Li et al., 2017</xref>), weaker and stronger signals out of this range are more nonlinear, and may appear poorer and stronger, respectively, than electrode-recorded effects. Consequently, the differences in population responses between monocular and binocular stimulations revealed by this study might be less pronounced.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Monkey preparation</title><p>Monkey preparations were conducted following the methodology outlined in a previous study (<xref ref-type="bibr" rid="bib12">Guan et al., 2021</xref>; <xref ref-type="bibr" rid="bib17">Ju et al., 2021</xref>). Three rhesus monkeys (<italic>Macaca mulatta</italic>), aged 4–6 years, underwent two sequential surgeries under general anesthesia and strict sterile conditions. During the initial surgery, a 20 mm diameter craniotomy was performed on the skull over V1. The dura was opened, and multiple tracks of 100–150 nL AAV1.hSynap.GCaMP5G.WPRE.SV40 (AV-1-PV2478, titer 2.37e13 (GC/ml), Penn Vector Core) were pressure-injected at a depth of approximately 350 μm. Then the dura was sutured, the skull cap was re-attached using three titanium lugs and six screws, and the scalp was sutured. Following the surgery, the animal was returned to the cage and treated with injectable antibiotics (Ceftriaxone sodium, Youcare Pharmaceutical Group, China) for 1 week, along with postoperative analgesia. The second surgery took place 45 days later. A T-shaped steel frame was installed for head stabilization, and an optical window was inserted onto the cortical surface. Data collection could commence as early as one week following this procedure. More details about the preparation and surgical procedures can be found in <xref ref-type="bibr" rid="bib19">Li et al., 2017</xref>. The procedures were approved by the Institutional Animal Care and Use Committee, Peking University.</p></sec><sec id="s4-2"><title>Behavioral task</title><p>After a ten-day recovery period following the second surgery, the monkeys were placed in primate chairs with head restraints. They were trained to maintain fixation on a small white spot (0.1°), with eye positions monitored by an ISCAN ETL-200 infrared eye-tracking system (ISCAN Inc) at a sampling rate of 120 Hz for Monkeys A and B, and an Eyelink-1000 (SR Research) at a sampling rate of 1000 Hz for Monkey C. During the experiment, trials in which the eye position deviated 1.5<sup>o</sup> or more from the fixation point before stimulus offset were excluded as ones with saccades and repeated. For the remaining trials, the eye positions were predominantly concentrated around the fixation point, with eye positions within 0.5<sup>o</sup> from the fixation point in over 95% of trials.</p></sec><sec id="s4-3"><title>Visual stimuli</title><p>For Monkeys A and B, visual stimuli were generated using a ViSaGe system (Cambridge Research Systems) and presented on a 21’’ Sony G520 CRT monitor with a refresh rate of 80 Hz, a resolution of 1280 pixel ×960 pixel, and a pixel size of 0.31 mm × 0.31 mm. Due to space constraints, the viewing distance and the monitor position varied depending on the stimulus spatial frequency (30 cm for 0.25, 0.5, and 1 cpd, 60 cm for 2 cpd, and 120 cm for 4 and 8 cpd). For Monkey C, visual stimuli were created using Psychotoolbox 3 (<xref ref-type="bibr" rid="bib25">Pelli and Zhang, 1991</xref>) and presented on a 27’’ Acer XB271HU LCD monitor with a refresh rate of 80 Hz native, a resolution of 2560 pixel ×1,440 pixel native, and a pixel size of 0.23 mm × 0.23 mm. The viewing distance was 50 cm for lower frequencies (0.25–1 cpd) and 100 cm for higher frequencies (2–8 cpd). Both monitors had their screen luminance linearized by an 8-bit look-up table, and the mean luminance was approximately 47 cd/m<sup>2</sup>.</p><p>A drifting square-wave grating with a spatial frequency of 4 cpd, a full contrast, a speed of 3 cycles/sec, a starting phase at 0<sup>o</sup>, and a size of 0.4° in diameter was initially used to determine the location, eccentricity (3.4<sup>o</sup> for Monkey A, 1.7<sup>o</sup> for Monkey B, and 1.1<sup>o</sup> for Monkey C), and size (0.8 - 1<sup>o</sup>) of the population receptive field associated with a recording field of view (FOV). Additionally, it was used to examine ocular dominance columns when presented monocularly to confirm the V1 location. This fast process involved a 4× objective lens mounted on a two-photon microscope and did not provide cell-specific information.</p><p>Neuronal responses were measured using a high-contrast (0.9) Gabor patch, which is a Gaussian-windowed sinusoidal grating, drifting at 2 cycles/sec in opposite directions perpendicular to the Gabor’s orientation. The Gabor grating had a starting phase of 0<sup>o</sup> and varied at 12 orientations from 0° to 165° in 15<sup>o</sup> steps, along with 6 spatial frequencies ranging from 0.25 to 8 cpd in 1-octave steps.</p><p>In addition, three stimulus sizes (with constant stimulus centers) were used at each spatial frequency for two purposes. Firstly, our pilot measurements suggested very strong surround suppression with larger stimuli. Therefore, comparing responses to different stimulus sizes could help approximate the RF size of each neuron that produced maximal response and least surround suppression. Secondly, larger stimuli would have better chances to trigger neurons whose RF centers and the stimulus center were misaligned. It is worth noting that for additional neurons whose RFs had less overlap even with the largest stimuli used, they would have weaker and less orientation-tuned responses because of the Gaussian-blurred stimulus edge. These neurons would most likely be filtered out during our multiple steps of selection of orientation tuned neurons (see below).</p><p>Specifically, the stimulus sizes, represented by the σ of the Gaussian envelope of the Gabor, were 0.64λ and 0.85λ at all spatial frequencies, and was additionally smaller at 0.42λwhen the SFs were 0.25–1 cpd, and larger at 1.06λ when the SFs were 2–8 cpd (λ: wavelength). Gabors at various SFs, if having the same σ in wavelength unit, would have the same number of cycles. Here at the smallest σ (0.42λ), the Gabors still had sufficient number of cycles (frequency bandwidths = 1 octave; <xref ref-type="bibr" rid="bib10">Graham, 1989</xref>), so that the actual stimulus spatial frequencies were precise at nominal values. In terms of visual angle, σ = 1.68<sup>o</sup>, 2.56<sup>o</sup>, and 3.36<sup>o</sup> at 0.25 cpd; 0.84<sup>o</sup>, 1.28<sup>o</sup>, and 1.68<sup>o</sup> at 0.5 cpd; 0.42<sup>o</sup>, 0.64<sup>o</sup>, and 0.85<sup>o</sup> at 1 cpd; 0.34<sup>o</sup>, 0.42<sup>o</sup>, and 0.53<sup>o</sup> at 2 cpd; 0.17<sup>o</sup>, 0.21<sup>o</sup>, and 0.26<sup>o</sup> at 4 cpd, and 0.08<sup>o</sup>, 0.11<sup>o</sup>, and 0.13<sup>o</sup> at 8 cpd, respectively.</p><p>Each stimulus was presented for 1000 ms, followed by an inter-stimulus interval (ISI) of 1500 ms, allowing sufficient time for the calcium signals to return to baseline levels (<xref ref-type="bibr" rid="bib11">Guan et al., 2020</xref>). Each stimulus condition was repeated 12 times, with six repetitions for each opposite drift direction. When presenting a stimulus monocularly to one eye, the other eye was covered with a translucent eye patch to minimize short-term monocular deprivation. For Monkey A, binocular recordings preceded monocular recordings on separate days. During monocular recordings, contralateral and ipsilateral stimulations alternated in blocks of trials, with at least a 10-min break in between, during which the eye patch was taken off. Recording at a specific viewing distance was completed with all trials at relevant SFs pseudo-randomly presented before proceeding to the next viewing distance. For Monkeys B and C, binocular and monocular recordings were mixed and completed in two daily sessions. At a specific viewing distance, all binocular trials at relevant SFs were carried out first, then contralateral and ipsilateral trials were completed in alternating blocks of trials with a at least 10 min eye-patch-off break in between. Again, recordings at a specific viewing distance were completed before proceeding to a different distance.</p><p>Each block of trials typically lasted 20–25 min, but for Monkeys A and B, certain blocks involving three SFs could extend up to 45 min. The strength of fluorescent signals (mean luminance of a small area) was continuously monitored and adjusted as needed to account for any drift in fluorescent signals. We compared the response ratios of the last two trials over the first two trials for each stimulus condition in these extended blocks with ipsilateral and contralateral stimulations. The respective mean ratios were 0.94 and 0.86, suggesting that the recorded neuronal responses remained largely stable over the extended blocks of trials.</p></sec><sec id="s4-4"><title>Two-photon calcium imaging</title><p>Two-photon calcium imaging was performed with a Prairie Ultima IV (In Vivo) two-photon microscope (Prairie Technologies) on Monkeys A and B, or a FENTOSmart two-photon microscope (Femtonics) on Monkey C, and a Ti:sapphire laser (Mai Tai eHP, Spectra Physics). GCaMP5 was chosen as the indicator of calcium signals because the fluorescence activities it expresses are linearly proportional to neuronal spike activities within a wide range of firing rates from 10 to 150 Hz (<xref ref-type="bibr" rid="bib19">Li et al., 2017</xref>). One FOV of 850 x 850 μm<sup>2</sup> was selected from each animal and imaged using a 1000 nm femtosecond laser under a 16× objective lens (0.8 N.A., Nikon) at a resolution of 1.6 μm/pixel. A fast resonant scanning mode (32 frames per second) was chosen to obtain continuous images of neuronal activity (8 frames per second after averaging every 4 frames). Recordings were first performed at a shallower depth, and some neurons with high brightness or unique dendrite patterns were selected as landmarks. In the next daily session, the same FOV at the same depth was first located with the help of the landmarks, and the depth plane was then lowered if recordings were performed at a deeper depth (Monkeys A &amp; B). Because of the time limit, recordings at a specific FOV/depth with monocular and binocular stimulations were completed in 2–3 consecutive daily sessions, but the same neurons could be precisely tracked over multiple recording sessions with the use of landmark cues.</p></sec><sec id="s4-5"><title>Imaging data analysis: initial screening of ROIs</title><p>Data were analyzed with customized MATLAB codes. A normalized cross-correlation based translation algorithm (source code provided in <xref ref-type="supplementary-material" rid="scode1">Source code 1</xref>) was used to reduce motion artifacts (<xref ref-type="bibr" rid="bib19">Li et al., 2017</xref>). Then the fluorescence changes were associated with corresponding visual stimuli through the time sequence information recorded by Neural Signal Processor (Cerebus system, Blackrock Microsystem). By subtracting the mean of the 4 frames before stimuli onset (<italic>F0</italic>) from the average of the 6th-9th frames after stimuli onset (<italic>F</italic>) across 5 or 6 repeated trials for the same stimulus condition (same orientation, spatial frequency, size, and drifting direction), the differential image (<italic>∆F=F</italic> F0) was obtained.</p><p>For a specific FOV at a specific recording depth, the regions of interest (ROIs) or possible cell bodies were decided through sequential analysis of 216 differential images in the order of spatial frequency (6), size (3), and orientation (12) (6x3 x 12=216). The first differential image was filtered with a band-pass Gaussian filter (size = 2–10 pixels), and connected subsets of pixels (&gt;25 pixels, which would exclude smaller vertical neuropils) with average pixel value &gt;3 standard deviations of the mean brightness were selected as ROIs. Then the areas of these ROIs were set to mean brightness in the next differential image before the bandpass filtering and thresholding were performed. This measure gradually reduced the standard deviations of differential images and facilitated detection of neurons with relatively low fluorescence responses. If a new ROI and an existing ROI from the previous differential image overlapped, the new ROI would be on its own if the overlapping area OA &lt;1/4 ROI<sub>new</sub>, discarded if 1/4 ROI<sub>new</sub> &lt;OA &lt; 3/4 ROI<sub>new</sub>, and merged with the existing ROI if OA &gt;3/4 ROI<sub>new</sub>. The merges would help smoothen the contours of the final ROIs. This process went on through all differential images twice to select ROIs. Finally, the roundness for each ROI was calculated as:<disp-formula id="equ4"><mml:math id="m4"><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msqrt><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mo>×</mml:mo><mml:mi>A</mml:mi></mml:msqrt></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf3"><mml:mi>A</mml:mi></mml:math></inline-formula> was the ROI’s area, and <inline-formula><mml:math id="inf4"><mml:mi>P</mml:mi></mml:math></inline-formula> was the perimeter. Only ROIs with roundness larger than 0.9, which would exclude horizontal neuropils, were selected for further analysis.</p></sec><sec id="s4-6"><title>Imaging data analysis: orientation tuning, SF tuning, and ocular dominance</title><p>The ratio of fluorescence change (<italic>∆F/F0</italic>) was calculated as a neuron’s response to a specific stimulus condition. For a specific cell’s response to a specific stimulus condition, the <italic>F0<sub>n</sub></italic> of the n-th trial was the average of 4 frames before stimulus onset, and F<sub>n</sub> was the average of 5th-8th frames after stimulus onset. F0<sub>n</sub> was then averaged across 12 trials to obtain the baseline F0 for all 12 trials (for the purpose of reducing noises in the calculation of responses), and ∆F<sub>n</sub>/F0 = (F<sub>n</sub>-F0)/F0 was taken as the neuron’s response to this stimulus at this trial. The final response was averaged over 11 trials, excluding the 12<sup>th</sup> trial that showed the weakest and often negative response. For a small portion of neurons (e.g.,~3% in Monkeys A,~8% in monkey B, and ~2% in Monkey C) showing direction selectivity as their responses to two opposite drifting directions differed significantly (<italic>P</italic>&lt;0.05, Friedman test), the 6 trials at the preferred direction was considered for calculations of ∆F<sub>n</sub>/F0 as the cell’s responses to a particular stimulus. F0 was still averaged over 12 trials at two opposite directions.</p><p>Several steps were then taken to determine whether a neuron was tuned to orientation and/or spatial frequency, and if so, its ocular dominance index. For each monocular condition, first the orientation, SF, and size (σ) producing the maximal response among all conditions were selected. Then responses to other 11 orientations and 5 SFs were decided at the selected SF and size. Second, to select orientation and/or SF tuned neurons, a non-parametric Friedman test was performed to test whether a neuron’s responses at 12 orientations or 6 SFs were significantly different from each other at least under one monocular stimulation condition. To reduce Type-I errors, the significance level was set at <italic>α</italic>=0.01. Third, for those showing significant orientation differences, the trial-based orientation responses of each neuron were fitted with a Gaussian model with a MATLAB nonlinear least-squares function: lsqnonlin:<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where R(θ) was the response at orientation θ, free parameters a<sub>1</sub>, θ<sub>0</sub>, σ, and b were the amplitude, peak orientation, standard deviation of the Gaussian function (and half width at half height), and minimal response of the neuron, respectively. Only neurons with goodness of fit R<sup>2</sup> &gt;0.5 at least under one stimulation condition were finally selected as orientation-tuned neurons. Fourth, for those showing significant SF difference, the trial-based SF responses of each neuron were further fitted with a Difference-of-Gaussian model.<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where R(sf) was a neuron’s response at spatial frequency sf, free parameters a<sub>1</sub>, σ<sub>1</sub>, a<sub>2</sub>, and σ<sub>2</sub> were amplitudes and standard deviations of two Gaussians, respectively, and b was the minimal response among 6 spatial frequencies. Only those with goodness of fit R<sup>2</sup> &gt;0.5 at least under one monocular stimulation condition were selected as SF tuned neurons.</p><p>The ocular dominance index (ODI) was calculated to characterize each orientation and/or SF tuned neuron’s eye preference: ODI = (R<sub>i</sub> – R<sub>c</sub>)/(R<sub>i</sub> +R<sub>c</sub>), in which R<sub>i</sub> and R<sub>c</sub> were the neuron’s respective peak responses at the best orientation and SF to ipsilateral and contralateral stimulations on the basis of data fitting. Here ODI = –1 and 1 would indicate complete contralateral and ipsilateral eye preferences, respectively, and ODI = 0 would indicate equal preference to both eyes.</p></sec><sec id="s4-7"><title>Model fitting</title><p>Monocular and binocular data in <xref ref-type="fig" rid="fig4">Figure 4</xref> were fitted by <xref ref-type="disp-formula" rid="equ2 equ3">Equations 2 and 3</xref>, respectively. The goodness-of-fit was indicated by a fit quality index q with a range of 0–1, which was the root mean square deviation between the observed responses and the model normalized by the observed response mean (<xref ref-type="bibr" rid="bib3">Busse et al., 2009</xref>):<disp-formula id="equ7"><mml:math id="m7"><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msqrt><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <italic>i</italic> was the i<sub>th</sub> bin, <italic>r</italic> was the median response of a specific bin, and m was the corresponding model prediction.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Investigation, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation</p></fn><fn fn-type="con" id="con3"><p>Data curation</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Funding acquisition, Writing - original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experimental protocols were approved by the Peking University Animal Care and Use Committee (LSC-TangSM-5).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-92839-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="scode1"><label>Source code 1.</label><caption><title>Source code for removing motion artifacts.</title></caption><media xlink:href="elife-92839-code1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p><xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref> and <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref> contain the numerical data used to generate the figures.</p></sec><ack id="ack"><title>Acknowledgements</title><p>This study was supported by a STI2030-Major Projects grant (2022ZD0204600), Natural Science Foundation of China grants (31230030 and 31730109), and funds from Peking-Tsinghua Center for Life Sciences, Peking University. We thank Jian Ding and Dennis Levi at UC Berkeley and Si Wu at Peking University for their comments during the writing of the manuscript.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>PA</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Binocular combination of contrast signals</article-title><source>Vision Research</source><volume>29</volume><fpage>1115</fpage><lpage>1132</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(89)90060-6</pub-id><pub-id pub-id-type="pmid">2617860</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name><name><surname>Blakemore</surname><given-names>C</given-names></name><name><surname>Pettigrew</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>The neural mechanism of binocular depth discrimination</article-title><source>The Journal of Physiology</source><volume>193</volume><fpage>327</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1967.sp008360</pub-id><pub-id pub-id-type="pmid">6065881</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname><given-names>L</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title><source>Neuron</source><volume>64</volume><fpage>931</fpage><lpage>942</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.004</pub-id><pub-id pub-id-type="pmid">20064398</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cogan</surname><given-names>AI</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Human binocular interaction: towards a neural model</article-title><source>Vision Research</source><volume>27</volume><fpage>2125</fpage><lpage>2139</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(87)90127-1</pub-id><pub-id pub-id-type="pmid">3447362</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohn</surname><given-names>TE</given-names></name><name><surname>Lasley</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Binocular vision: two possible central interactions between signals from two eyes</article-title><source>Science</source><volume>192</volume><fpage>561</fpage><lpage>563</lpage><pub-id pub-id-type="doi">10.1126/science.1257791</pub-id><pub-id pub-id-type="pmid">1257791</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeSliva</surname><given-names>HR</given-names></name><name><surname>Bartley</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="1930">1930</year><article-title>Summation and subtraction of brightness in binocular perception</article-title><source>British Journal of Psychology. General Section</source><volume>20</volume><fpage>241</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1111/j.2044-8295.1930.tb00547.x</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A gain-control theory of binocular combination</article-title><source>PNAS</source><volume>103</volume><fpage>1141</fpage><lpage>1146</lpage><pub-id pub-id-type="doi">10.1073/pnas.0509629103</pub-id><pub-id pub-id-type="pmid">16410354</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Klein</surname><given-names>SA</given-names></name><name><surname>Levi</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Binocular combination of phase and contrast explained by a gain-control and gain-enhancement model</article-title><source>Journal of Vision</source><volume>13</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1167/13.2.13</pub-id><pub-id pub-id-type="pmid">23397038</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dougherty</surname><given-names>K</given-names></name><name><surname>Cox</surname><given-names>MA</given-names></name><name><surname>Westerberg</surname><given-names>JA</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Binocular modulation of monocular v1 neurons</article-title><source>Current Biology</source><volume>29</volume><fpage>381</fpage><lpage>391</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.12.004</pub-id><pub-id pub-id-type="pmid">30661798</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Graham</surname><given-names>NVS</given-names></name></person-group><year iso-8601-date="1989">1989</year><source>Visual Pattern Analyzers</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195051544.001.0001</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guan</surname><given-names>S-C</given-names></name><name><surname>Zhang</surname><given-names>S-H</given-names></name><name><surname>Zhang</surname><given-names>Y-C</given-names></name><name><surname>Tang</surname><given-names>S-M</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Plaid detectors in macaque v1 revealed by two-photon calcium imaging</article-title><source>Current Biology</source><volume>30</volume><fpage>934</fpage><lpage>940</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.01.005</pub-id><pub-id pub-id-type="pmid">32084400</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guan</surname><given-names>S-C</given-names></name><name><surname>Ju</surname><given-names>N-S</given-names></name><name><surname>Tao</surname><given-names>L</given-names></name><name><surname>Tang</surname><given-names>S-M</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Functional organization of spatial frequency tuning in macaque V1 revealed with two-photon calcium imaging</article-title><source>Progress in Neurobiology</source><volume>205</volume><elocation-id>102120</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2021.102120</pub-id><pub-id pub-id-type="pmid">34252470</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henriksen</surname><given-names>S</given-names></name><name><surname>Tanabe</surname><given-names>S</given-names></name><name><surname>Cumming</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Disparity processing in primary visual cortex</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>371</volume><elocation-id>20150255</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2015.0255</pub-id><pub-id pub-id-type="pmid">27269598</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>CB</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>ZL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Contrast and phase combination in binocular vision</article-title><source>PLOS ONE</source><volume>5</volume><elocation-id>e15075</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0015075</pub-id><pub-id pub-id-type="pmid">21151558</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex</article-title><source>The Journal of Physiology</source><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id><pub-id pub-id-type="pmid">14449617</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Receptive fields and functional architecture of monkey striate cortex</article-title><source>The Journal of Physiology</source><volume>195</volume><fpage>215</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1968.sp008455</pub-id><pub-id pub-id-type="pmid">4966457</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ju</surname><given-names>N-S</given-names></name><name><surname>Guan</surname><given-names>S-C</given-names></name><name><surname>Tao</surname><given-names>L</given-names></name><name><surname>Tang</surname><given-names>S-M</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Orientation tuning and end-stopping in macaque v1 studied with two-photon calcium imaging</article-title><source>Cerebral Cortex</source><volume>31</volume><fpage>2085</fpage><lpage>2097</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhaa346</pub-id><pub-id pub-id-type="pmid">33279951</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>ZP</given-names></name><name><surname>Atick</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Efficient stereo coding in the multiscale representation*</article-title><source>Network</source><volume>5</volume><fpage>157</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/5/2/003</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>TS</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Long-term two-photon imaging in awake macaque monkey</article-title><source>Neuron</source><volume>93</volume><fpage>1049</fpage><lpage>1057</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.01.027</pub-id><pub-id pub-id-type="pmid">28215557</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunghi</surname><given-names>C</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name><name><surname>Morrone</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Brief periods of monocular deprivation disrupt ocular balance in human adult visual cortex</article-title><source>Current Biology</source><volume>21</volume><fpage>R538</fpage><lpage>R539</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.06.004</pub-id><pub-id pub-id-type="pmid">21783029</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>BA</given-names></name><name><surname>Dougherty</surname><given-names>K</given-names></name><name><surname>Westerberg</surname><given-names>JA</given-names></name><name><surname>Carlson</surname><given-names>BM</given-names></name><name><surname>Daumail</surname><given-names>L</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name><name><surname>Cox</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Stimulating both eyes with matching stimuli enhances V1 responses</article-title><source>iScience</source><volume>25</volume><elocation-id>104182</elocation-id><pub-id pub-id-type="doi">10.1016/j.isci.2022.104182</pub-id><pub-id pub-id-type="pmid">35494250</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>BA</given-names></name><name><surname>Carlson</surname><given-names>BM</given-names></name><name><surname>Westerberg</surname><given-names>JA</given-names></name><name><surname>Cox</surname><given-names>MA</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A role for ocular dominance in binocular integration</article-title><source>Current Biology</source><volume>33</volume><fpage>3884</fpage><lpage>3895</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2023.08.019</pub-id><pub-id pub-id-type="pmid">37657450</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moradi</surname><given-names>F</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Inter-ocular contrast normalization in human visual cortex</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1167/9.3.13</pub-id><pub-id pub-id-type="pmid">19757952</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>AJ</given-names></name><name><surname>Smith</surname><given-names>JET</given-names></name><name><surname>Krug</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural architectures for stereo vision</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>371</volume><elocation-id>20150261</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2015.0261</pub-id><pub-id pub-id-type="pmid">27269604</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>DG</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Accurate control of contrast on microcomputer displays</article-title><source>Vision Research</source><volume>31</volume><fpage>1337</fpage><lpage>1350</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(91)90055-a</pub-id><pub-id pub-id-type="pmid">1891822</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poggio</surname><given-names>GF</given-names></name><name><surname>Fischer</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Binocular interaction and depth sensitivity in striate and prestriate cortex of behaving rhesus monkey</article-title><source>Journal of Neurophysiology</source><volume>40</volume><fpage>1392</fpage><lpage>1405</lpage><pub-id pub-id-type="doi">10.1152/jn.1977.40.6.1392</pub-id><pub-id pub-id-type="pmid">411898</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prince</surname><given-names>SJD</given-names></name><name><surname>Pointon</surname><given-names>AD</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Quantitative analysis of the responses of V1 neurons to horizontal disparity in dynamic random-dot stereograms</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>191</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1152/jn.00465.2000</pub-id><pub-id pub-id-type="pmid">11784742</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Read</surname><given-names>JCA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Binocular vision and stereopsis across the animal kingdom</article-title><source>Annual Review of Vision Science</source><volume>7</volume><fpage>389</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-093019-113212</pub-id><pub-id pub-id-type="pmid">34283925</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shatz</surname><given-names>CJ</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Ocular dominance in layer IV of the cat’s visual cortex and the effects of monocular deprivation</article-title><source>The Journal of Physiology</source><volume>281</volume><fpage>267</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1978.sp012421</pub-id><pub-id pub-id-type="pmid">702379</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welchman</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The human brain in depth: how we see in 3D</article-title><source>Annual Review of Vision Science</source><volume>2</volume><fpage>345</fpage><lpage>376</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-111815-114605</pub-id><pub-id pub-id-type="pmid">28532360</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.92839.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gaier</surname><given-names>Eric D</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Boston Children's Hospital</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>Overall, the reviewers found the significance of the work <bold>valuable</bold> to the field of visual neuroscience, particularly given the large data set and strength of the method used that allowed for spatial analysis of neuronal responses in macaque V1. The evidence was deemed <bold>compelling</bold>, owing in part to the consistency of responses across animals and the fitness of modeling. The authors have addressed the major comments from reviewers and improved the manuscript through relation to prior literature and addressing specific limitations of the method used.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.92839.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Zhang et al., investigated the relationship between monocular and binocular responses of V1 superficial-layer neurons using two-photon calcium imaging. They found a strong relationship in their data: neurons that exhibited a greater preference for one eye or the other (high ocular dominance) were more likely to be suppressed under binocular stimulation, whereas neurons that are more equivalently driven by each other (low ocular dominance) were more likely to be enhanced by binocular stimulation. This result chiefly demonstrates the relationship between ocular dominance and binocular responses in V1, corroborating what has been shown previously using electrophysiological techniques with now much finer spatial resolution. The binocular responses were well-fitted by a model that institutes divisive normalization between the eyes that accounts for both the suppression and enhancement phenomena observed in the subpopulation of binocular neurons. In so doing, the authors reify the importance of incorporating ocular dominance in computational models of binocular combination.</p><p>The conclusions of this paper are well supported by the data. The authors deftly contextualize these important findings in the literature while also acknowledging the limitations of the methodology employed. Future work would do well to combine the spatial power of 2P imaging with the temporal power of electrophysiology to assess ocular dominance-dependent binocular combination across the V1 laminar microcircuit.</p><p>Strengths:</p><p>The two-photon imaging technique used to resolve the activity of individual neurons within intact brain tissue grants a host of advantages. Foremost, two-photon imaging confers considerably high spatial resolution. As a result, the authors were able to sample and analyze the activity from thousands of verified superficial-layer V1 neurons. The animal model used, awake macaques, is also highly relevant for the study of binocular combination. Macaques, like humans, are binocular animals, meaning they have forward-facing eyes that confer overlapping visual fields. Importantly, macaque V1 is organized into cortical columns that process specific visual features from the separate eyes just like in humans. In combination with a powerful imaging technique, this allowed the authors to evaluate the monocular and binocular response profiles of V1 neurons that are situated within neighboring ocular dominance columns, a novel feat. To this aim, the approach was well-executed and should instill confidence in the notion that V1 neurons combine monocular information in a manner that is dependent on the strength of their ocular dominance.</p><p>Weaknesses:</p><p>This study suffers no major weaknesses. The authors address the limitations of the methodology and have calibrated the interpretations accordingly.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.92839.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This study examines the pattern of responses produced by the combination of left-eye and right-eye signals in V1. For this, they used calcium imaging of neurons in V1 of awake, fixating monkeys. They take advantage of calcium imaging, which yields large populations of neurons in each field of view. With their data set, they observe how response magnitude relates to ocular dominance across the entire population. They analyze carefully how the relationship changed as the visual stimulus switched from contra-eye only, ipsi-eye only, and binocular. As expected, the contra-eye dominated neurons responded strongly with a contra-eye only stimulus. The ipsi-eye dominated neurons responded strongly with an ipsi-eye only stimulus. The surprise was responses to a binocular stimulus. The responses were similarly weak across the entire population, regardless of each neuron's ocular dominance. They conclude that this pattern of responses could be explained by interocular divisive normalization, followed by binocular summation.</p><p>Strengths:</p><p>A major strength of this work is that the model-fitting was done on a large population of simultaneously recorded neurons. This approach is an advancement over previous work, which did model-fitting on individual neurons. The fitted model in the manuscript represents the pattern observed across the large population in V1, and washes out any particular property of individual neurons. Given the large neuronal population from which the conclusion was drawn, the authors provide solid evidence supporting their conclusion. They also observed consistency across 5 field of views.</p><p>The experiments were designed and executed appropriately to test their hypothesis. Their data support their conclusion.</p><p>Weaknesses:</p><p>The nonlinear interocular suppression found in this study, could potentially be partially exaggerated by the nonlinear properties of calcium signals. One of the authors of this study has previously reported that the particular GCaMP used in this study has a nice proportional relationship with firing rate of a neuron. So the concern of exaggeration probably does not apply to this particular study. The concern would apply to others who try similar measurements with other versions of GCaMP.</p><p>The implication of their finding is that strong ocular dominance is the result of release from interocular suppression by a monocular stimulus, rather than the lack of binocular combination as many traditional studies have assumed. This could significantly advance our understanding of the binocular combination circuitry of V1. The entire population of neurons could be part of a binocular combination circuitry present in V1.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.92839.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary</p><p>The authors have made simultaneous recordings of the responses of large numbers of neurons from the primary visual cortex of macaque monkeys using optical two-photon imaging of calcium signals from the superficial layers of the cortex. Recordings were made to compare the responses of the cortical neurons under normal binocular viewing of a flat screen with both eyes open and monocular viewing of the same screen with one eye's view blocked by a translucent filter. The screen displayed visual stimuli comprising small contrast patches of Gabor function distributions of luminance, a stimulus that is known to excite cortical neurons.</p><p>Strengths</p><p>This is an important data set, given the large number of neurons recorded. The authors present a simple model to explain binocular combination of neuronal signals from the right and left eyes. The work advances the use of two-photon imaging in the cerebral neocortex. The research design adds valuable information to our understanding of the organization of binocular vision in macaque monkeys, which are the only realistic animal model of human vision for the study of binocular interactions.</p><p>Limitations and Weaknesses</p><p>(1) Given that these recordings are made optically, these results reflect primarily activations of neurons in the superficial layers of the cortex. This limitation arises from the usual constraints (depth of cortex, degree of myelination) on optical imaging in the macaque cortex. This means that the sample of neurons forming this data set is not fully representative of the population of binocular neurons within the visual cortex. This limitation is important in comparing the outcome of these experiments with the results from other studies of binocular combination, which have used single-electrode recording. Electrode recording will result in a sample of neurons that is drawn from many layers of the cortex, rather than just the superficial layers, noting that electrode recordings also carry different risks of sampling bias.</p><p>(2) Single neuron recording of binocular neurons in the primary visual cortex has shown that these neurons often have some spontaneous activity. Assessment of this spontaneous level of firing is important for accurate model fitting [1]. The present imaging approach works exclusively with differential measurements of neuronal signals, so assessment of the level of spontaneous activity is not feasible.</p><p>(3) The arrangements for visual stimulation and comparison of binocular and monocular responses mean that the stereoscopic disparity of the binocular stimuli is always at zero or close to zero. The consequence is that the experimental design does not test the cortical response over a range of different binocular depths.</p><p>The animal's fixation point is in the centre of a single display that is viewed binocularly. The fixation point is, by definition, at zero disparity.. Provided that the animals accurately converged their eyes on the binocular fixation point, then the disparity of the visual stimuli across the whole display will always be at or close to zero. However, we already know from earlier work that neurons in the visual cortex exhibit a range of selectivity for binocular disparity. Some neurons have their peak response at non-zero disparities, representing binocular depths nearer than the fixation depth or beyond it.</p><p>There are also other neurons whose response is maximally suppressed by disparities at the depth of the fixation point (so-called Tuned Inhibitory [TI] neurons). The simple model and analysis presented in the paper for the summation of monocular responses to predict binocular responses will perform adequately for neurons that are tuned to zero disparity, so-called tuned excitatory neurons [TE], but is necessarily compromised when applied to neurons that have other, different tuning profiles for binocular disparity. Specifically, when neurons are stimulated binocularly with a non-preferred disparity, the binocular response may be lower than the monocular response [2, 3]. The same limitation applies to another recent paper [4].</p><p>This more realistic view of binocular responses needs to be considered further to gain a full picture of the operation of the visual cortex in responding to binocular depth</p><p>Citations</p><p>1. Prince, S.J.D., Pointon, A.D., Cumming, B.G., and Parker, A.J., (2002). Quantitative analysis of the responses of V1 neurons to horizontal disparity in dynamic random-dot stereograms. Journal of Neurophysiology, 87: 191-208.</p><p>2. Prince, S.J.D., Cumming, B.G., and Parker, A.J., (2002). Range and mechanism of encoding of horizontal disparity in macaque V1. Journal of Neurophysiology, 87: 209-221.</p><p>3. Poggio, G.F. and Fischer, B., (1977). Binocular interaction and depth sensitivity in striate and prestriate cortex of behaving rhesus monkey. Journal of Neurophysiology, 40: 1392-1405 doi 10.1152/jn.1977.40.6.1392.</p><p>4. B. A. Mitchell, K. Dougherty, J. A. Westerberg, B. M. Carlson, L. Daumail, A. Maier, et al. (2022) Stimulating both eyes with matching stimuli enhances V1 responses.</p><p>iScience 2022 Vol. 25 Issue 5 DOI: 10.1016/j.isci.2022.104182</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.92839.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Sheng-Hui</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Xing-Nan</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Jiang</surname><given-names>Dan-Qing</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Tang</surname><given-names>Shiming</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Yu</surname><given-names>Cong</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>Zhang et al., investigated the relationship between monocular and binocular responses of V1 superficial-layer neurons using two-photon calcium imaging. They found a strong relationship in their data: neurons that exhibited a greater preference for one eye or the other (high ocular dominance) were more likely to be suppressed under binocular stimulation, whereas neurons that are more equivalently driven by each other (low ocular dominance) were more likely to be enhanced by binocular stimulation. This result chiefly demonstrates the relationship between ocular dominance and binocular responses in V1, corroborating what has been shown previously using electrophysiological techniques but now with greater spatial resolution (albeit less temporal resolution). The binocular responses were well-fitted by a model that institutes divisive normalization between the eyes that accounts for both the suppression and enhancement phenomena observed in the subpopulation of binocular neurons. In so doing, the authors reify the importance of incorporating ocular dominance in computational models of binocular combination.</p><p>The conclusions of this paper are mostly well supported by the data, but there are some limitations of the methodology that need to be clarified, and an expansion of how the results relate to previous work would better contextualize these important findings in the literature.</p><p>Strengths:</p><p>The two-photon imaging technique used to resolve the activity of individual neurons within intact brain tissue grants a host of advantages. Foremost, two-photon imaging confers considerably high spatial resolution. As a result, the authors were able to sample and analyze the activity from thousands of verified superficial-layer V1 neurons. The animal model used, awake macaques, is also highly relevant for the study of binocular combination. Macaques, like humans, are binocular animals, meaning they have forward-facing eyes that confer overlapping visual fields. Importantly, macaque V1 is organized into cortical columns that process specific visual features from the separate eyes just like in humans. In combination with a powerful imaging technique, this allowed the authors to evaluate the monocular and binocular response profiles of V1 neurons that are situated within neighboring ocular dominance columns, a novel feat. To this aim, the approach was well-executed and should instill further confidence in the notion that V1 neurons combine monocular information in a manner that is dependent on the strength of their ocular dominance.</p><p>Weaknesses:</p><p>While two-photon imaging provides excellent spatial resolution, its temporal resolution is often lower compared to some other techniques, such as electrophysiology. This limits the ability to study the fast dynamics of neuronal activity, a well-understood trade-off of the method. The issue is more so that the authors draw comparisons to electrophysiological studies without explicit appreciation of the temporal difference between these techniques. In a similar vein, two-photon imaging is limited spatially in terms of cortical depth, preferentially sampling from neurons in layers 2/3. This limitation does not invalidate any of the interpretations but should be considered by readers, especially when making comparisons to previous electrophysiological reports using microelectrode linear arrays that sample from all cortical layers. Indeed, it is likely that a complete picture of early cortical binocular processing will require high spatial resolution (i.e., sampling from neurons in neighboring ocular dominance columns, from pia mater to white matter) at the biophysically relevant timescales (1ms resolution, capturing response dynamics over the full duration of the stimulus presentation, including the transient onset and steady-state periods).</p></disp-quote><p>To address the same concern from all three reviewers, we discussed the technical limitations of two photon calcium imaging at the end of Discussion, including limited imaging depth, low temporal resolution, and nonlinearity. The relevant texts are copied here:</p><p>(Ln 304) “Limitations of the current study</p><p>Although capable of sampling a large number of neurons at cellular resolution and with low sampling bias, two-photon calcium imaging has its known limitations that may better make it a complementary research tool to electrophysiological recordings.</p><p>For example, two-photon imaging can only sample neurons from superficial-layers, while binocular neurons also exist in deeper layers, and even neurons in the input layer are affected by feedback from downstream binocular neurons to exhibit binocular response properties (Dougherty, Cox, Westerberg, &amp; Maier, 2019). Furthermore, calcium signals are relatively slow and cannot reveal the fast dynamics of neuronal responses. Due to these spatial and temporal limitations, a more complete picture of the neuronal mechanisms underlying binocular combination of monocular responses may come from studies using both technologies.</p><p>In addition, calcium signals may exaggerate the nonlinear properties of neurons. Although calcium signals indicated by GCaMP5, our favored choice of calcium indicator, displays a linear relationship to neuronal spike rates within a range of 10-150 Hz (Li, Liu, Jiang, Lee, &amp; Tang, 2017), weak and strong signals out of this range are more nonlinear, and may appear poorer and stronger, respectively, than electrode-recorded effects. Consequently, the differences in population responses between monocular and binocular stimulations revealed by this study might be less pronounced.”</p><disp-quote content-type="editor-comment"><p><bold>(Recommendations For The Authors):</bold></p><p>Overall, my main suggestion for the authors to improve the paper is to revise some of the interpretations of their results in relation to previous research. The purpose of the present study was to illustrate a more complete picture of the binocular combination of monocular responses by taking into consideration the ocular dominance of V1 cells (lines 34-36). A study published earlier this year had an identical purpose (Mitchell et al., Current Biology, 2023) and arrived at a highly similar conclusion (and also applied divisive normalization to fit their data). I would ask that this paper be mentioned in the introduction and discussed.</p></disp-quote><p>The Mitchell et al 2023 paper is added to the Introduction and Discussion:</p><p>(Ln 50) “In addition (to the Dougherty et al 2019 paper from the same group), Mitchell, Carlson, Westerberg, Cox, and Maier (2023) reported that binocular combination of monocular stimuli with different contrasts is also affected by neurons’ eye preference.”</p><p>(Ln 286) “The critical roles of ocular dominance have been largely overlooked by extant binocular vision models to our knowledge, except that Anderson and Movshon (1989) demonstrated that a model consisting of multiple ocular dominance channels can better explain their psychophysical adaptation data, and that Mitchell et al. (2023) revealed that binocular combination of different contrasts presented to different eyes are affected by neurons’ ocularity preference.”</p><disp-quote content-type="editor-comment"><p>Nevertheless, the results of the present study are very valuable. They add substantial spatial resolution and sophisticated relational analysis of monocular and binocular responses that Mitchell et al., 2023 did not include. Therefore, my suggestion is to emphasize the advantages of two-photon imaging in the introduction, focusing on the ability to image neurons in neighboring ocular dominance columns. The rigorous modeling of the relationship between nearby neurons with a range of eye preferences, in tandem with the incredible yield of two-photon imaging, is what sets this paper apart from previous electrophysiological work.</p><p>The finding that binocular responses were dependent on ocular dominance is largely consistent with previous electrophysiological results. However, there should be a paragraph in the discussion section that speaks to the limitations of comparing two-photon imaging data to electrophysiological data. Namely, there are two limitations:</p><p>(1) These two techniques confer different temporal resolutions. It is conceivable that some of the electrophysiology relationships (for example, described by Dougherty et al., 2019) may be dependent on the temporal window over which the data was averaged, typically over 50-100ms around stimulus onset, or 100-250ms comprising the neurons' sustained response to the stimulus. This possible explanation of the difference in obtained results would be especially useful for the discussion paragraph starting at line 232. It would also be helpful to readers for there to be some mention of the advantage of having high temporal resolution (i.e., the benefits of electrophysiology) since (a) recent work has distinguished between sequential stages of binocular combination (Cox et al., 2019) and (b) modern models of V1 neurons emphasize recurrent feedback to explain V1 temporal dynamics (see Heeger et al., 2019; Rubin et al., 2015), which could prove to be relevant for combination of stimuli in the two eyes (Fleet et al., 1997).</p></disp-quote><p>Our discussion regarding the technical limitations of 2-p calcium imaging has been listed earlier. Specific to the Dougherty et 2019 paper, we added the following discussion to address the issue of temporal resolution difference between two technologies.</p><p>(Ln 266) “In addition, it is unclear whether the discrepancies are caused by different temporal resolutions of electrode recording and calcium imaging. The results of Dougherty et al. (2019) represent changes of neuronal spike activities over a period of approximately 50-200 ms after the stimulus onset, which may reflect the sustained neuronal responses to the stimulus and possible feedback signals. Calcium signals are much slower and indicative of the aggregated neuronal responses over a longer period (up to 1000 ms in the current study). They should have smeared, rather than exaggerated, the differences between monocular and binocular responses, although we cannot exclude the possibility that some neuronal response changes beyond 200 ms are responsible for the discrepancies.”</p><disp-quote content-type="editor-comment"><p>(2) The sample of V1 neurons in this study is limited to cells in the most superficial layers of the cortex (layers 2/3). This limitation is, of course, well understood, but it should be mentioned at least in the context of studying the formative mechanisms of binocular combination in V1 (since we know that binocular neurons also exist in layers 5/6, and there is now substantial evidence that even layer 4 neurons are not as &quot;monocular&quot; as we previously thought (Dougherty et al., 2019)).</p></disp-quote><p>See our discussion regarding the technical limitations of 2-p calcium imaging listed earlier.</p><disp-quote content-type="editor-comment"><p>In short, I believe the paper would be improved by (1) adding the above citations in the appropriate places, (2) acknowledging in the introduction that this question has been investigated electrophysiologically but emphasizing the advantages of two-photon imaging, and (3) adding a paragraph to the discussion section that discusses the temporal and spatial limitations when using two-photon imaging to study binocular combination, particularly when comparing the results to electrophysiology.</p><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>This study examines the pattern of responses produced by the combination of left-eye and right-eye signals in V1. For this, they used calcium imaging of neurons in V1 of awake, fixating monkeys. They take advantage of calcium imaging, which yields large populations of neurons in each field of view. With their data set, they observe how response magnitude relates to ocular dominance across the entire population. They analyze carefully how the relationship changed as the visual stimulus switched from contra-eye only, ipsi-eye only, and binocular. As expected, the contra-eye-dominated neurons responded strongly with a contra-eye-only stimulus. The ipsi-eye-dominated neurons responded strongly with an ipsi-eye-only stimulus. The surprise was responses to a binocular stimulus. The responses were similarly weak across the entire population, regardless of each neuron's ocular dominance. They conclude that this pattern of responses could be explained by interocular divisive normalization, followed by binocular summation.</p><p>Strengths:</p><p>A major strength of this work is that the model-fitting was done on a large population of simultaneously recorded neurons. This approach is an advancement over previous work, which did model-fitting on individual neurons. The fitted model in the manuscript represents the pattern observed across the large population in V1, and washes out any particular property of individual neurons. Given the large neuronal population from which the conclusion was drawn, the authors provide solid evidence supporting their conclusion. They also observed consistency across 5 fields of view.</p><p>The experiments were designed and executed appropriately to test their hypothesis. Their data support their conclusion.</p><p>Weaknesses:</p><p>One weakness of their study is that calcium signals can exaggerate the nonlinear properties of neurons. Calcium imaging renders poor responses poorer and strong responses stronger, compared to single-unit recording. In particular, the dramatic change in the population response between monocular stimulation and binocular stimulation could actually be less pronounced when measured with single-unit recording methods. This means their choice of recording method could have accidentally exaggerated the evidence of their finding.</p></disp-quote><p>We discussed the nonlinearity of calcium signals as part of the technical limitations of 2-p imaging calcium. The calcium indicator we use, GCaMP5, has a reasonable range of linear relationship with spike rates. But out of this range, the nonlinearity is indeed a concern.</p><p>(Ln 314) “In addition, calcium signals may exaggerate the nonlinear properties of neurons. Although signals indicated by GCaMP5, our favored choice of calcium indicator, displays a linear relationship to neuronal spike rate within a range of 10-150 Hz (Li et al., 2017), weak and strong signals out of this range are more nonlinear, and may appear poorer and stronger, respectively, than electrode-recorded effects. Consequently, the changes in population responses between monocular and binocular stimulations revealed by this study might be less pronounced.”</p><disp-quote content-type="editor-comment"><p>The implication of their finding is that strong ocular dominance is the result of release from interocular suppression by a monocular stimulus, rather than the lack of binocular combination as many traditional studies have assumed. This could significantly advance our understanding of the binocular combination circuitry of V1. The entire population of neurons could be part of a binocular combination circuitry present in V1.</p></disp-quote><p>This is a very good insight. We added the following sentences to the end of the first paragraph of Discussion:</p><p>(Ln 242) “These findings implicate that at least for neurons in superficial layers of V1, significant ocular dominance may result from a release of interocular suppression during monocular stimulation, an unusual viewing condition as our vision is typically binocular, rather than a lack of binocular combination of inputs from upstream monocular neurons.”</p><disp-quote content-type="editor-comment"><p><bold>(Recommendations For The Authors):</bold></p><p>Line 150: &quot;To model interocular response suppression, responses from each eye in Eq. 2 were further normalized by an interocular suppression factor wib or wcb,&quot; I recommend the authors improve their explanation of how they arrived at Eq. 3 from Eq. 2. As it stands, my impression is that they have one model for the responses to monocular stimulation, and another model for the responses to binocular stimulation. What I think is missing is that both equations are derived from the same model. Monocular stimulation is a situation in which the stimulus in one eye's contrast is zero. Could the authors clarify whether this situation produces an interocular suppression of zero, and how that leads to Eq. 2?</p></disp-quote><p>We rewrote the modeling part to show that Equations 1-3 are sequential steps of development for the same model. We also added a brief paragraph to discuss how Eq. 3 could lead to Eq. 2 under monocular viewing:</p><p>(Ln 166) “Although not shown in Eq. 3, we also assumed that the nonlinear exponent b also depends on the contrast of the stimulus presented to the other eye (i.e., Sc or Si). Consequently, when Sc or Si = 0 under monocular stimulation, Rc or Ri = 0 (Eq. 1), and interocular suppression wib or wcb = 1, so Eq. 3 changes back to Eq. 2. It is only when Sc and Si are equal and close to 1, as in the current study, that interocular suppression and binocular combination would be in the current Eq. 3 format.”</p><disp-quote content-type="editor-comment"><p>Line 225: &quot;However, individually, compared to monocular responses, responses of monocular neurons more preferring the stimulated eye are actually suppressed, and only responses of binocular neurons are increased by binocular stimulation.&quot; This sentence is difficult to follow. I recommend the authors improve clarity by breaking up the sentence into several sentences. If I understand correctly, they summarize the pattern in the data that is indicative of interocular divisive normalization, i.e., their final conclusion.</p></disp-quote><p>This sentence no longer exists in the Discussion.</p><disp-quote content-type="editor-comment"><p>Line 426: &quot;Third, for those showing significant orientation difference, the trial-based orientation responses of each neuron were fitted with a Gaussian model with a MATLAB nonlinear least squares function:&quot; The choice of using a Gaussian function to fit orientation tuning was probably suboptimal. A Gaussian function provides an adequate fit only for neurons whose tuning is very sharp. The responses outside of the peak fall down to the baseline and the two ends meet. Otherwise, the two ends do not meet. An adequate fit would be achieved with a function of a circular variable, which wraps around 180 deg. I recommend using a Von Mises function for fitting orientation tuning.</p></disp-quote><p>We agree with the reviewer that the Von Mises function is more accurate than Gaussian for fitting orientation tuning functions. Indeed we are using it to fit orientation tuning of V4 neurons, many of which have two peaks. For the current V1 data, the differences between Von Mises and Gaussian fittings are very small, as shown in the orientation functional maps from three macaques below. Because we also use the same Gaussian fitting of orientation tuning in several published and current under-review papers, we prefer to keep the Gaussian fitting results in the manuscript.</p><fig id="sa4fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-92839-sa4-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>The authors have made simultaneous recordings of the responses of large numbers of neurons from the primary visual cortex using optical two-photon imaging of calcium signals from the superficial layers of the cortex. Recordings were made to compare the responses of the cortical neurons under normal binocular viewing of a flat screen with both eyes open and monocular viewing of the same screen with one eye's view blocked by a translucent filter. The screen displayed visual stimuli comprising small contrast patches of Gabor function distributions of luminance, a stimulus that is known to excite cortical neurons.</p><p>This is an important data set, given the large numbers of neurons recorded. The authors present a simple model to explain the binocular combination of neuronal signals from the right and left eyes.</p><p>The limitations of the paper as written are as follows. These points can be addressed with some additional analysis and rewriting of sections of the paper. No new experimental data need to be collected.</p><p>(1) The authors should acknowledge the fact that these recordings arise from neurons in the superficial layers of the cortex. This limitation arises from the usual constraints on optical imaging in the macaque cortex. This means that the sample of neurons forming this data set is not fully representative of the population of binocular neurons within the visual cortex. This limitation is important in comparing the outcome of these experiments with the results from other studies of binocular combination, which have used single-electrode recording. Electrode recording will result in a sample of neurons that is drawn from many layers of the cortex, rather than just the superficial layers.</p></disp-quote><p>See our discussion regarding the technical limitations of 2-p calcium imaging listed earlier.</p><disp-quote content-type="editor-comment"><p>(2) Single-neuron recording of binocular neurons in the primary visual cortex has shown that these neurons often have some spontaneous activity. Assessment of this spontaneous level of firing is important for accurate model fitting [1]. The paper here should discuss the level of spontaneous neuronal firing and its potential significance.</p></disp-quote><p>We have noticed previously that at non-optimal spatial frequencies, calcium responses to a moving Gabor grating are close to zero (Guan et al., Prog Neurobiology, 2021, Fig. 1B), but we cannot tell whether this is due to calcium response nonlinearity, or a close-to-zero level of spontaneous neuronal activity. Prince et al (2002) reported low spontaneous responses of V1 neurons with moving grating stimuli (e.g., about 3 spikes/sec in one exemplar neuron, their Fig. 1B), so this appears not a big effect. In our data fitting, we do have an orientation-unspecific component in the Gaussian model, which represents the neuronal response at a non-preferred orientation, but not necessarily the spontaneous activity.</p><disp-quote content-type="editor-comment"><p>(3) The arrangements for visual stimulation and comparison of binocular and monocular responses mean that the stereoscopic disparity of the binocular stimuli is always at zero or close to zero. The animal's fixation point is in the centre of a single display that is viewed binocularly. The fixation point is, by definition, at zero disparity. The other points on the flat display are also at zero disparity or very close to zero because they lie in the same depth plane. There will be some small deviations from exactly zero because the geometry of the viewing arrangements results in the extremities of the display being at a slightly different distance than the centre. Therefore, the visual stimulation used to test the binocular condition is always at zero disparity, with a slight deviation from zero at the edges of the display, and never changes. [There is a detail that can be ignored. The experimenters tested neurons with visual stimulation at different real distances from the eyes, but this is not relevant here. Provided the animals accurately converged their eyes on the provided binocular fixation point, then the disparity of the visual stimuli will always be at or close to zero, regardless of viewing distance in these circumstances.] However, we already know from earlier work that neurons in the visual cortex exhibit a range of selectivity for binocular disparity. Some neurons have their peak response at non-zero disparities, representing binocular depths nearer than the fixation depth or beyond it. The response of other neurons is maximally suppressed by disparities at the depth of the fixation point (so-called Tuned Inhibitory [TI] neurons). The simple model and analysis presented in the paper for the summation of monocular responses to predict binocular responses will perform adequately for neurons that are tuned to zero disparity, so-called tuned excitatory neurons [TE], but is necessarily compromised when applied to neurons that have other, different tuning profiles. Specifically, when neurons are stimulated binocularly with a non-preferred disparity, the binocular response may be lower than the monocular response[2, 3]. This more realistic view of binocular responses needs to be considered by the authors and integrated into their modelling.</p></disp-quote><p>We agree and include the following texts when discussing the future work:</p><p>(Ln 298) “In addition, in our experiments, binocular stimuli were presented with zero disparity, which best triggered the responses of neurons with zero-disparity tuning. A more realistic model of binocular combination also requires the consideration of neurons with other disparity-tuning profiles.”</p><disp-quote content-type="editor-comment"><p>(4) The data in the paper show some features that have been reported before but are not captured by the model. Notably for neurons with extreme values of ocular dominance, the binocular response is typically less than the larger of the two monocular responses. This is apparent in the row of plots in Figure 2D from individual animals and in the pooled data in Figure 2E. Responses of this type are characteristic of tuned inhibitory [TI] neurons[2]. It is not immediately clear why this feature of the data does not appear in the summary and analysis in Figure 3.</p></disp-quote><p>This difference is indeed captured by the model, which can be more easily appreciated in Fig. 4A where monocular and binocular model simulations are plotted in the same panel. In the text, we also wrote: (Ln 195) “It is apparent that binocular responses cannot be explained by the sum of monocular responses, as binocular responses are substantially lower than the summed monocular responses for both monocular and binocular neurons. Nor can binocular responses be explained by the responses to the preferred eye, as binocular responses are also lower than those to the preferred eye (the larger of the two monocular responses) for monocular neurons.”</p><disp-quote content-type="editor-comment"><p>The paper text states that the responses were &quot;first normalized by the median of the binocular responses&quot;. This will certainly get rid of this characteristic of the data, but this step needs better justification, or an amendment to the main analysis is needed.</p></disp-quote><p>The relevant sentence has been rewritten as “Monocular and binocular data of each FOV/depth, as well as the pooled data, were first normalized by the respective median of the binocular responses of all neurons in the same FOV/depth.” This normalization would render the overall binocular responses to be around unity, for the purpose of facilitating comparisons among all FOV/depth, but it would not affect the overall characteristic of the data.</p><disp-quote content-type="editor-comment"><p>In the present form, the model and analysis do not appear to fit the data in Figure 2 as accurately as needed.</p></disp-quote><p>Thanks for pointing out the problem, as data fitting for FOV C_270 and the pooled data were especially inaccurate. The issue has been mostly fixed when each datum was weighted by its standard deviation (please see the updated Fig. 3).</p></body></sub-article></article>