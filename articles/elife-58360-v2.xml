<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">58360</article-id><article-id pub-id-type="doi">10.7554/eLife.58360</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A new no-report paradigm reveals that face cells encode both consciously perceived and suppressed stimuli</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-185462"><name><surname>Hesse</surname><given-names>Janis Karan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0405-8632</contrib-id><email>jhesse@caltech.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-12395"><name><surname>Tsao</surname><given-names>Doris Y</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1083-1919</contrib-id><email>dortsao@caltech.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Division of Biology and Biological Engineering, Computation and Neural Systems</institution><addr-line><named-content content-type="city">Pasadena</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Howard Hughes Medical Institute</institution><addr-line><named-content content-type="city">Pasadena</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Meng</surname><given-names>Ming</given-names></name><role>Reviewing Editor</role><aff><institution>South China Normal University</institution><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Radboud University</institution><country>Netherlands</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>11</day><month>11</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e58360</elocation-id><history><date date-type="received" iso-8601-date="2020-04-28"><day>28</day><month>04</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-11-09"><day>09</day><month>11</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Hesse and Tsao</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Hesse and Tsao</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-58360-v2.pdf"/><abstract><p>A powerful paradigm to identify neural correlates of consciousness is binocular rivalry, wherein a constant visual stimulus evokes a varying conscious percept. It has recently been suggested that activity modulations observed during rivalry may represent the act of report rather than the conscious percept itself. Here, we performed single-unit recordings from face patches in macaque inferotemporal (IT) cortex using a no-report paradigm in which the animal’s conscious percept was inferred from eye movements. We found that large proportions of IT neurons represented the conscious percept even without active report. Furthermore, on single trials we could decode both the conscious percept and the suppressed stimulus. Together, these findings indicate that (1) IT cortex possesses a true neural correlate of consciousness and (2) this correlate consists of a population code wherein single cells multiplex representation of the conscious percept and veridical physical stimulus, rather than a subset of cells perfectly reflecting consciousness.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>consciousness</kwd><kwd>binocular rivalry</kwd><kwd>no-report paradigm</kwd><kwd>inferotemporal cortex</kwd><kwd>face perception</kwd><kwd>face patch</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Tsao</surname><given-names>Doris Y</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Tsao</surname><given-names>Doris Y</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Conscious visual percepts are encoded by face patches in the absence of report, can be decoded from population recordings, and are multiplexed with the veridical physical stimulus.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Having conscious experience is arguably the most important reason why it matters to us whether we are alive or dead. The question which signals in the brain reflect this conscious experience and which reflect obligatory processing of input regardless of conscious experience is a central puzzle of neuroscience. For example, activations in the retina may correlate with the conscious percept of flashing light but are arguably entirely driven by physical input, much of which never evolves into a conscious percept. Another driver of neural activity that can be confounded with signals related to conscious perception is report. Recently, it has been suggested that brain regions may correlate with conscious perception simply because they are driven by the active report of it (<xref ref-type="bibr" rid="bib1">Aru et al., 2012</xref>; <xref ref-type="bibr" rid="bib5">Block, 2019</xref>; <xref ref-type="bibr" rid="bib6">Block, 2020</xref>; <xref ref-type="bibr" rid="bib7">Boly et al., 2017</xref>; <xref ref-type="bibr" rid="bib13">Frässle et al., 2014</xref>; <xref ref-type="bibr" rid="bib22">Koch et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Overgaard and Fazekas, 2016</xref>; <xref ref-type="bibr" rid="bib29">Panagiotaropoulos et al., 2020</xref>; <xref ref-type="bibr" rid="bib32">Safavi et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Tsuchiya et al., 2016</xref>; <xref ref-type="bibr" rid="bib39">Tsuchiya et al., 2015</xref>).</p><p>A paradigm known as binocular rivalry is useful for distinguishing responses related to conscious perception from those driven by obligatory processing of physical input (<xref ref-type="bibr" rid="bib4">Blake et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Tong et al., 2006</xref>): when two incompatible stimuli such as a face and an object are shown to the left and right eyes, respectively, one does not perceive a constant superimposition of the two but rather an alternation between face and object, even though the physical input is fixed (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Since these alternations are internally generated, they cannot be attributed to pure feedforward processing of external input.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>A novel no-report paradigm.</title><p>(<bold>a</bold>) Illustration of binocular rivalry stimuli used in the paradigm. Four example trials are shown. Each trial was presented continuously for 800 ms without blank period between trials. The first and second rows show stimuli in the left and right eyes, respectively. If different stimuli are shown to the left and right eyes, as in this example, one’s percept will spontaneously alternate between the two, as shown in the example perceptual trajectory in the third row. Stimuli in each eye contained a fixation spot at one of four possible positions. (<bold>b</bold>) Example eye traces from a human subject. Red and blue traces show the distance of the eye position from the fixation spot in the right and left eyes, respectively. Thick lines show the average. Traces are aligned to the onset of a trial where the subject reported that the percept switched from face to object (left) or object to face (right). (<bold>c</bold>) The bar plot shows the average proportion of trials where the percept inferred matched the percept reported by button press. White circles show accuracies of individual subjects. We inferred that a subject was perceiving face or object if the subject fixated on the face fixation spot (i.e., fixation spot in the eye of the face stimulus) or object fixation spot (i.e., fixation spot in the eye of the object stimulus), respectively, for at least half of the trial.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig1-v2.tif"/></fig><p>In previous studies, researchers trained monkeys to report their percept during binocular rivalry by releasing a lever. They found that the proportion of cells modulated by the reported percept increases along the visual hierarchy, with 20% of cells showing modulations in V1 (<xref ref-type="bibr" rid="bib25">Leopold and Logothetis, 1996</xref>) compared to 90% of cells showing modulations in inferotemporal (IT) cortex (<xref ref-type="bibr" rid="bib33">Sheinberg and Logothetis, 1997</xref>). Using functional magnetic resonance imaging (fMRI), <xref ref-type="bibr" rid="bib34">Tong et al., 1998</xref> found that the human fusiform face area responds to reported perceptual switches. Using single-unit recording, <xref ref-type="bibr" rid="bib15">Gelbard-Sagiv et al., 2018</xref> found that the activity of neurons in the human medial temporal lobe and frontal cortex is also modulated by the reported percept.</p><p>Although binocular rivalry dissociates the conscious percept from physical input, an important confounding factor remains. In all studies cited above, the monkey or human subject always actively reported their percept by a motor response. Thus it is possible that the observed neuronal activations were due to the act of report itself, including introspection, decision making, and motor action accompanying report, rather than a switch in conscious percept. This concern was emphasized in an fMRI experiment by <xref ref-type="bibr" rid="bib13">Frässle et al., 2014</xref> who compared modulations in the brain with and without active report. Many of the modulations observed in higher-level brain regions such as the frontal lobe disappeared when subjects did not actively report perceptual switches.</p><p>To infer the subject’s percept in the absence of report, Frässle et al. used two no-report paradigms that depended on pupil size and optokinetic nystagmus, respectively. To exploit pupil size, they presented stimuli with different brightness in the two eyes, causing the subject’s pupil size to vary according to the dominant percept’s brightness. To exploit optokinetic nystagmus, they presented gratings moving in opposite directions in the two eyes, causing the subject’s eye position to reflexively follow the direction of the dominant grating. Therefore, the conscious percept could be inferred by reading out pupil size and drift of eye position, respectively.</p><p>These no-report paradigms allow accurate prediction of the subject’s percept but are not free of confounds themselves (<xref ref-type="bibr" rid="bib27">Overgaard and Fazekas, 2016</xref>). First, pupil size is known to correlate with arousal, surprise, attention, and other confounding factors (<xref ref-type="bibr" rid="bib8">Bradley et al., 2008</xref>; <xref ref-type="bibr" rid="bib18">Hoeks and Levelt, 1993</xref>; <xref ref-type="bibr" rid="bib30">Preuschoff et al., 2011</xref>). Second, when optokinetic nystagmus is applied to moving non-grating stimuli such as natural objects that drive IT cortex, there will be confounding physical stimulus differences. For example, the dominant stimulus that is smoothly pursued by the subject’s eyes will tend to be stationary on the subject’s fovea and optimally modulate IT areas with foveal biases, while the non-dominant stimulus will be more eccentric and have increased motion velocity. Moreover, optokinetic nystagmus is still present in monkeys in which the conscious percept is diminished due to anesthesia with low doses of ketamine (<xref ref-type="bibr" rid="bib24">Leopold et al., 2002</xref>).</p><p>Here, we introduce a new no-report paradigm that relies on active tracking of a fixation spot, unlike the reflex-based paradigms mentioned above. In this fixation-based paradigm the subject is required to maintain fixation on a jumping spot, a task that many animals in vision research are already trained to perform. While following the fixation spot, subjects view either unambiguous, monocular stimuli physically switching between a face and an object, or a binocular rivalry stimulus that switches only perceptually. For the binocular rivalry stimulus, a fixation spot is shown to each eye at different positions on the screen. Thus, when perceiving a face in the left eye, the subject will generally perceive only the fixation spot in the left eye and saccade to it, ignoring the fixation spot in the right eye. In this way, the subject’s percept can be inferred from eye movement patterns without active report.</p><p>In a second innovation, we performed electrophysiological recordings using a novel 128-electrode site Neuropixels-like probe that allowed us to measure responses from large numbers of cells simultaneously. This allowed us to address for the first time the extent to which neural activity is modulated by conscious perception in <italic>single trials</italic>. <xref ref-type="bibr" rid="bib33">Sheinberg and Logothetis, 1997</xref> reported that 90% of IT cells are modulated by conscious perception. However, a fact that has been largely overlooked is that the response modulations found in that study during the rivalry condition were clearly smaller than those in the physical condition. It is possible that the decrease arose due to incorrect reporting of the percept by the monkey on some trials, and cells were modulated just as strongly by perceptual as by physical alternations. However, the decrease could also have been due to a more interesting possibility: mixed selectivity of cells for the conscious percept and the suppressed stimulus on single trials in the rivalry condition. In other words, it is possible that single cells encode both the conscious percept and the suppressed stimulus during rivalry. Inter-trial averaging confounds these two possibilities. To distinguish them, it is critical to compare perceptual vs. physical response modulations for single trials.</p><p>To explore correlates of conscious perception, we targeted recordings to macaque face patches ML and AM. The macaque face patch system constitutes an anatomically connected network of regions in IT cortex dedicated to face processing (<xref ref-type="bibr" rid="bib11">Chang and Tsao, 2017</xref>; <xref ref-type="bibr" rid="bib16">Grimaldi et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Hesse and Tsao, 2020</xref>; <xref ref-type="bibr" rid="bib38">Tsao et al., 2006</xref>) and has served as an archetypal system for understanding object recognition in IT in general (<xref ref-type="bibr" rid="bib2">Bao et al., 2020</xref>). To date, most response properties of cells in the face patch network can be explained using a feedforward framework without invoking conscious perception. For example, the functional hierarchy of this network, with increasing view invariance as one moves anterior from ML to AM (<xref ref-type="bibr" rid="bib14">Freiwald and Tsao, 2010</xref>), can be explained by simple feedforward pooling mechanisms (<xref ref-type="bibr" rid="bib23">Leibo et al., 2017</xref>). The representation of facial identity by cells in face patches through projection onto specific preferred axes can also be explained by feedforward mechanisms (<xref ref-type="bibr" rid="bib11">Chang and Tsao, 2017</xref>).</p><p>Here, we explore activity in the face patch network using a binocular rivalry paradigm in which neural activity modulation is difficult to explain by feedforward filtering processes, since the stimulus remains unchanged. The hierarchical and feedback-rich organization of the face patch network (<xref ref-type="bibr" rid="bib14">Freiwald and Tsao, 2010</xref>; <xref ref-type="bibr" rid="bib16">Grimaldi et al., 2016</xref>) makes it a ripe testbed to examine the neural circuits underlying construction of conscious visual experience beyond feedforward filtering of visual input. It has been postulated that the fundamental architecture of the cortex is a predictive loop in which inference guided by internal priors plays a key role in determining what we see (<xref ref-type="bibr" rid="bib31">Rao and Ballard, 1999</xref>). One explanation for binocular rivalry is that it arises as a consequence of such predictive coding, reflecting a high-level prior that two objects cannot occupy the same space (<xref ref-type="bibr" rid="bib19">Hohwy et al., 2008</xref>).</p><p>We recorded from fMRI-identified face patches ML and AM in two monkeys using high channel-count electrodes, while we inferred the animals’ conscious percept through the no-report paradigm described above. We found that large proportions of cells in both face patches (57% in ML and 73% in AM) encoded the conscious percept even without active report. Population activity of perceptually modulated cells was modulated more weakly during rivalry than during physical stimulus transitions in single trials. Nevertheless, we could reliably decode the dynamically changing conscious percept from activity in single trials. Surprisingly, we could also decode suppressed stimuli using activity from the same cells, indicating that single cells multiplex information about the conscious percept and the suppressed stimulus. These findings suggest that the neural correlate of consciousness within IT cortex resides in a population code rather than a subset of cells perfectly reflecting consciousness, and different linear readouts can decode either the consciously perceived or the suppressed stimulus from the same population.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We first confirmed that it is possible to correctly infer a subject’s conscious percept using a fixation-based no-report paradigm through a behavioral experiment in humans. We presented binocular rivalry stimuli consisting of a face (e.g., Obama) in the right eye and a non-face object (e.g., a taco) in the left eye, causing the percept to stochastically alternate between the two (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Each of the stimuli contained a fixation spot that jumped to one of four possible locations every trial. Trials were 2000 ms long and contained no blank period, that is, stimuli were presented continuously. If subjects fixated at the fixation spot presented in the right eye on a given trial, we inferred that they perceived the face and vice versa for the object. To verify that the percept of face or object could be inferred from fixations, we instructed six naïve human subjects to perform the fixation task while simultaneously reporting their conscious percept with button presses. On trials where the percept switched, subjects also switched the fixation spot they were following (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). We were able to infer which image the subjects were consciously perceiving with accuracies ranging from 86% to 98% across subjects (average: 93%, <xref ref-type="fig" rid="fig1">Figure 1c</xref>).</p><p>We next used the same method in monkeys to infer their conscious percept while recording from face patches ML and AM in IT. Importantly, the two monkeys in this study had never been trained to report their percept. They had previously been trained to maintain fixation on a spot (presented binocularly) and learned to perform the new task within 1 or 2 days, respectively (maintaining fixation on a spot for at least 80% of all trials). Since the monkeys were so adept at the task, we set the trial length to 800 ms (compared to 2000 ms in humans); this allowed higher temporal fidelity in determining the animal’s percept. We presented two types of stimuli: in the ‘physical’ condition, unambiguous monocular stimuli were physically switched between face and object. In the ‘perceptual’ (binocular rivalry) condition, the same face and object were continuously presented to the right and left eyes, respectively, so any changes in percept were internally generated. To account for individuals’ eye dominance, we balanced the contrasts of the stimuli in the two eyes so that the monkey followed both fixation spots equally often in the rivalry condition. After balancing, median dominance durations were 7.2 s for faces and 7.2 s for objects across the two monkeys. Similarly, in human subjects, median dominance durations were 8 s for faces and 10 s for objects as estimated from fixation patterns, and 8.1 s for faces and 8.3 s for objects as estimated from reports. We inferred switches during rivalry when monkeys behaviorally switched from following the fixation spot in one eye to following the fixation spot in the other eye (example eye traces, <xref ref-type="fig" rid="fig2">Figure 2a</xref>, top). Spike rasters from an example ML cell showed a stronger response after switches from face to object compared to switches from object to face (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, bottom; rasters aligned to onset of trials in which a switch occurred). <xref ref-type="fig" rid="fig2">Figure 2b</xref> compares average response time courses to physical vs. perceptual switches in two example cells, one from ML and one from AM. Both cells responded more strongly to a physically presented face than object. Importantly, in the binocular rivalry condition the response of both cells was also higher when the monkey perceived a face (as inferred by its eye movement) than when the monkey perceived an object. Since the physical stimulus was constant in this condition, the response reflected the monkey’s conscious percept of a face and not just the physical input.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Example face cells modulated by both physical and perceptual switches.</title><p>(<bold>a</bold>) Top: Example eye traces from a macaque performing the task aligned to a trial where the inferred percept switched from face to object (left) and from object to face (right). Red and blue curves indicate distances from the face and object fixation spots, respectively (as in <xref ref-type="fig" rid="fig1">Figure 1b</xref>). Bottom: Spike raster of an example ML cell recorded in the same session as for the top panel. Responses are aligned to all trials where the inferred percept switched from face to object (left) and from object to face (right). (<bold>b</bold>) Left: Coronal slices from magnetic resonance imaging scan showing recording locations for the two example cells in this figure (top: face patch ML, bottom: face patch AM). Color overlay shows functional magnetic resonance imaging activation to visually presented faces vs. non-face objects. Middle: Peristimulus histograms (PSTHs) show neuronal response time courses aligned to trial onsets where the visual stimulus was physically switched from face to object (blue) or from object to face (red). Right: PSTHs aligned to trial onsets where the inferred percept switched from face to object (blue) or object to face (red). ML cell is same cell as in (a). Shaded areas indicate standard error of the mean across trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig2-v2.tif"/></fig><p>We recorded a total of 348 cells in ML and 210 cells in AM that were selective, i.e., they showed a significant difference between face and object in the physical switch condition (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, two-sided two-sample t-test). Since we recorded from face patches, most cells showed stronger responses to the physically presented face stimulus. Importantly, most cells kept their preference in the binocular rivalry condition (<xref ref-type="fig" rid="fig3">Figure 3</xref>). In face patch ML, 57% (200/348) of cells were significantly modulated by the conscious percept in the binocular rivalry condition and showed preference consistent with the physical switch condition (<inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, two-sided t-test), while 10% (34/348) of cells were significantly but inconsistently modulated. In AM, a face patch that receives input from ML (<xref ref-type="bibr" rid="bib16">Grimaldi et al., 2016</xref>) and is the highest patch in the face patch hierarchy within IT (<xref ref-type="bibr" rid="bib14">Freiwald and Tsao, 2010</xref>), the percentage of significant consistent modulation increased to 73% (153/210), with only 2% (5/210) showing significant inconsistent modulation. For both patches there was a clear correlation between modulation by the physical stimulus and modulation by the percept in binocular rivalry (<inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>83</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, Pearson’s <inline-formula><mml:math id="inf4"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.70</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>558</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> cells). Thus, in a no-report paradigm, cells in IT exhibit modulations by the conscious percept that reflect their response selectivity to physically unambiguous inputs.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Large proportions of face cells show modulation by conscious percept.</title><p>The scatterplot shows modulation indices <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>face</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>object</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>face</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>object</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> measuring the difference in responses (i.e., average spike count <inline-formula><mml:math id="inf7"><mml:mi>R</mml:mi></mml:math></inline-formula>) on trials where the inferred percept was face vs. trials where the inferred percept was object for the physical monocular condition (x-axis) and perceptual binocular rivalry condition (y-axis). Yellow and orange triangles show cells from ML without and with significant difference between perceived face and perceived object response in the binocular rivalry condition, respectively. Blue and green squares show cells from AM without and with significant difference between perceived face and perceived object response in the binocular rivalry condition, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Color and eye-of-origin confound control.</title><p>Left: Scatterplot similar to <xref ref-type="fig" rid="fig3">Figure 3</xref> but modulation indices <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>preferred</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>nonpreferred</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>preferred</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>nonpreferred</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> now show the difference between preferred and non-preferred stimulus. The preferred stimulus is face if the response to face is higher and non-face object if the response to non-face object is higher in the physical condition. Thus, by definition the x-values of all cells are positive. Right: Scatterplot of modulation indices <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>preferred</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>nonpreferred</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>preferred</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mtext>nonpreferred</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for the same preferred and non-preferred object identities of stimuli when the colors and eye-of-origin of the two stimuli were switched. Importantly, the preference of a given stimulus identity was assigned based on responses to stimuli of the original color and eye-of-origin. N = 193 for ML and N = 120 for AM for both plots. Symbols have same conventions as in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig3-figsupp1-v2.tif"/></fig></fig-group><p>After eliminating the report confound, two important potential confounds remain. First, cells could be selective for the eye-of-origin of the fixation point that the animal is following (e.g., a cell could respond selectively to a fixation spot in the fovea of the left eye). Second, since we presented binocular stimuli using red/cyan anaglyph goggles, a confound could arise if cells were selective for the color of the fixation spot that is in the fovea. To control for these two potential confounds, we switched the colors and eye-of-origin of the face and object stimuli, that is, where the face and its corresponding fixation spot was previously presented in red in one eye, it was now presented in cyan in the other eye and vice versa for the object (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). If cells followed color or eye-of-origin, then all the dots in the upper right quadrant in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a</xref> should move to the lower left quadrant in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref>. Instead, the majority of cells followed the object identity rather than color or eye-of-origin for both the physical and perceptual conditions (<inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>42</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for physical condition and <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>19</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for perceptual condition, one-sided t-test, <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>313</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> cells, alternative hypothesis: modulation indices for switched condition are greater than 0). This confirms that cells in IT cortex indeed represent the conscious percept rather than the color or eye-of-origin of the fixation spot.</p><p>The strong modulation by conscious percept in single cells suggests that we should be able to decode the percept on single trials from population activity. To test this, we performed recordings from multiple neurons simultaneously using S-probes with 32 electrode sites and passive Neuropixels-like probes with 128 electrode sites (see Materials and methods for details). <xref ref-type="fig" rid="fig4">Figure 4</xref> shows the recordings from face patch ML in one session using the Neuropixels probe. In this session, we recorded 81 cells simultaneously, of which 63 were face-selective (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). An example population time course snippet of cells recorded simultaneously in the perceptual switch condition showed clearly stronger activity across the recorded population during perception of face compared to object (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). The average population response across cells to perceptual switches is shown in <xref ref-type="fig" rid="fig4">Figure 4c</xref>. We found above chance decoding of the perceptual condition in all 12 sessions (in all but one session, responses were recorded in both ML and AM, and cells were pooled across the two patches). Cross-validated accuracies of linear classifiers across different sessions are shown in <xref ref-type="fig" rid="fig4">Figure 4d</xref> (see Materials and methods). Decoding accuracy was 99% for the best session and 95% on average for the physical condition. For the perceptual condition, decoding accuracy was 88% on the best session and 78% on average.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Multi-channel recordings allow decoding of conscious percept on single trials.</title><p>(<bold>a</bold>) Left: Average responses (baseline-subtracted and normalized) of cells (rows) to 96 stimuli (columns) from six categories, including faces and other objects. Right: Waveforms of cells corresponding to rows on the left. Gray vertical bar on left indicates cells that significantly preferred face over object in the physical condition (p&lt;0.05). (<bold>b</bold>) Top: Example eye trace across 24 trials as in <xref ref-type="fig" rid="fig1">Figure 1b</xref> during binocular rivalry (i.e., only perceptual, no physical switches). The inferred percept across trials according to eye trace is indicated by shading (red = face, blue = non face object). Small black dots on top of eye traces indicate time points where our method detected saccades (see Materials and methods), which are used in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Bottom: Response time course snippet of a population of 81 neurons recorded with a Neuropixels-like probe in ML simultaneously to the eye trace at top. Each row represents one cell; ordering same as in (a). Face-selective cells indicated by gray vertical bar on left. (<bold>c</bold>) Normalized average population response across all significantly face-selective ML cells recorded from one Neuropixels session (same session as in a and b) to perceptual switch from object to face (red) and face to object (blue). Shaded areas indicate standard error mean across cells. (<bold>d</bold>) Cross-validated decoding accuracy of a linear classifier trained to discriminate trials of inferred percept face vs. inferred percept object for the physical switch condition (x-axis) and perceptual switch condition (y-axis). Each plus symbol represents a session of neurons recorded simultaneously with multi-channel electrodes.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig4-v2.tif"/></fig><p>Looking at the population time course, we noticed bursts of activity that appeared to be triggered by saccades, which occurred even when an object was perceived (blue epochs in <xref ref-type="fig" rid="fig4">Figure 4b</xref>; small black dots on top indicate detected saccades). This suggested to us that cells modulated by perception might still carry information about the physical stimulus: the bursts may have been caused by responses to the suppressed face stimulus. To investigate this further, we selected cells that (i) showed both significant physical and perceptual modulation and (ii) consistently preferred the face over the object. We then averaged responses across these cells and computed response time courses triggered by individual saccades, grouped by whether a saccade occurred during a trial inferred to be face or object, respectively (<xref ref-type="fig" rid="fig5">Figure 5</xref>). We observed response modulations for both physical and perceptual conditions starting around 130 ms after saccade onset (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). In the physical condition, a saccade during an object epoch led to response suppression, while a saccade during a face epoch led to response increase. In striking contrast, in the rivalry condition saccades led to response increase in both object and face epochs. As a consequence, during rivalry the response difference to a saccade between face and object, though significant (<inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>6</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>23</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, two-sample t-test, <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>701</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> saccades for object, <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>703</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> saccades for face), was weaker than during the physical condition. Computing histograms of responses averaged across neurons for individual saccades shows that responses in the rivalry condition were less bimodal and spanned a smaller range compared to the physical condition (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). Importantly, this difference in response profiles between physical and perceptual conditions was apparent even when pooling across both face and object trials (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, middle), and <italic>hence cannot be explained by mistakes in inferring the percept from eye movements</italic>. We computed the absolute value of these responses and found the difference in response distributions to be significant (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, right, <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>6</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>35</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, two-sample t-test on absolute value distributions, <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>229</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> saccades for physical condition, <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>1404</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> saccades for perceptual condition).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Saccade-triggered responses are less bimodal during rivalry.</title><p>(<bold>a</bold>) Single-trial responses during saccades averaged across simultaneously recorded ML neurons from the same session as in <xref ref-type="fig" rid="fig4">Figure 4b</xref> that were significantly face-selective for both physical and perceptual conditions. Individual neuron responses were normalized to make the mean object response −1 and the mean face response +1. Rows of each plot correspond to response time courses to individual saccades, aligned to saccade onset, and sorted by average response during 0–400 ms after saccade onset. Top: Physical condition. Bottom: Perceptual condition. Left, middle, and right columns correspond to saccades during object epochs, face epochs, and across both, respectively. The difference between perceptual and physical conditions in the third column shows that this difference cannot be simply attributed to mislabeling of perceptual state by the no-report paradigm. (<bold>b</bold>) Histograms of saccade-aligned responses averaged across a time window of 0–400 ms after saccade onset and across neurons (after normalizing as in (<bold>a</bold>)) that were significantly modulated for both physical and perceptual conditions. Top: Physical condition. Bottom: Perceptual condition. Left: Saccades for face and object plotted separately in red and blue, respectively. Middle: Saccades for either face or object epochs plotted in gray. Right: Absolute values of normalized responses plotted in light gray.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Lack of bimodality is a general trademark of rivalry.</title><p>(<bold>a</bold>) Trial responses in ML are less bimodal during rivalry. Histograms have same conventions as <xref ref-type="fig" rid="fig5">Figure 5b</xref> but instead of averaging neuron responses for individual saccades, responses are averaged across trial duration for individual trials. (<bold>b</bold>) Trial responses in AM are less bimodal during rivalry. Same conventions as in (<bold>a</bold>), but instead of the Neuropixels-like probe in ML, cells were recorded simultaneously from AM using a 32-channel S-probe.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig5-figsupp1-v2.tif"/></fig></fig-group><p>The observation of different response profiles for physical and perceptual conditions was not specific for saccades: histograms were also less bimodal and spanned a smaller range for the rivalry condition when triggering responses on trial onsets rather than saccades in both ML (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>, <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>9</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, two-sample t-test on absolute value distributions, <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>150</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> trials for physical condition, <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>571</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> trials for perceptual condition) and AM (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1b</xref>, <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.0014</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, two-sample t-test on absolute value distributions, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>120</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> trials for physical condition, <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>480</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> trials for perceptual condition). Therefore, it appears that throughout rivalry, for perceptually modulated cells, response differences to face and object are less pronounced than in the physical condition, and this is true in both ML and AM. One tantalizing explanation for this phenomenon is that perceptually modulated cells may be multiplexing information about both the physical stimulus and the perceptual state during single trials, allowing both to be simultaneously represented across the face patch hierarchy.</p><p>Is it possible that the apparent responses to the suppressed face were due to incomplete suppression, leading to piecemeal percepts on some trials? We performed simulations of the worst-case effect of mixture, in which the percept would be exactly half-face and half-object, by taking the responses of the physical condition and averaging responses to face and body on a specific proportion of trials. The simulated distributions only became statistically indistinguishable from the observed binocular rivalry condition if 50–70% of trials were mixed percepts of half-face and half-body. This is markedly inconsistent with reports from every human subject that on most trials they did not perceive any mixture. We of course cannot be absolutely sure that monkeys do not experience mixed percepts significantly more often than humans. Yet, under the reasonable assumption that percepts were similar in the two species, trials with mixed or piecemeal percepts cannot account for the difference in response distributions between physical and perceptual conditions.</p><p>To directly test the hypothesis that cells multiplex information about the perceptually dominant and suppressed stimulus, we performed a new experiment in which we varied the identity of the suppressed stimulus. In this experiment, instead of having only two rivalling stimuli, we used three images A, B, and C to create two different binocular rivalry stimuli, (A,B) and (A,C), presented in separate blocks (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). This allowed us to keep the dominant percept fixed as image A, and compare responses to trial types (<bold>A</bold>,B) and (<bold>A</bold>,C) to test whether neural responses could discriminate the suppressed stimulus (bold font indicates the dominant image, as inferred by eye movements). We trained a linear decoder to distinguish between trial types (<bold>A</bold>,B) and (<bold>A</bold>,C). Remarkably, the decoding accuracy for distinguishing the two trial types was 74% (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). For comparison, the decoding accuracy for distinguishing (A,<bold>B</bold>) vs. (A,<bold>C</bold>) from the same cell population was 88%. Thus, while the conscious percept can be decoded better than the suppressed stimulus, face cells do encode significant information about the latter. Potential mislabeling of trials by the no-report paradigm could not account for this decoding accuracy (see Supplementary text).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Face cells multiplex information about both the perceptually dominant and perceptually suppressed stimulus.</title><p>(<bold>a</bold>) Schematic of experiment design. Two types of binocular rivalry stimuli consisting of image pairs (A,B) and (A,C), respectively, were presented. During one image pair block, 12 trials corresponding to the 12 positions of the two fixation spots were presented in randomized order before the next block corresponding to the other image pair was presented. This was repeated more than 60 times. (<bold>b</bold>) Decoding accuracy for distinguishing (<bold>A</bold>,B) from (<bold>A</bold>,C) was 74% (black vertical line), even though the conscious percept was A for both trial types. As a control, we shuffled labels 100 times and attempted to perform decoding. Gray bars show the distribution of decoding accuracies for these 100 shuffle iterations. (<bold>c</bold>) Scatterplot showing dominant stimulus modulation indices <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>dominant</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mtext> </mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> on the x-axis and suppressed stimulus modulation indices <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>suppressed</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mtext> </mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> on the y-axis. Each triangle represents 1 of 66 physically selective cells recorded in one session from face patch ML with a 64-ch S-probe. (<bold>d</bold>) Schematic of three possible models for how perceptually modulated neurons may encode consciously perceived and suppressed stimuli during binocular rivalry. Left: (I) Neural responses encode the conscious percept in binocular rivalry identically to the corresponding unambiguous physical stimulus; x and y axes represent two dimensions of neural state space. Middle: (II) Responses during binocular rivalry lie in between the two stimuli but are biased toward the dominant stimulus. Right: (IIa) Spikes reflect a weighted sum of consciously perceived and suppressed stimuli and are generated through a Poisson process based on average firing rates. (IIb) Two different types of spikes, defined, for example through a temporal code, encode the consciously perceived and veridical physical stimulus, respectively. The time course in this schematic is from a single perceptual dominance period and divided into different epochs that represent either the conscious or physical stimulus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-fig6-v2.tif"/></fig><p>Do the same cells multiplex information about both the conscious and suppressed stimuli, or are there two distinct subpopulations, one encoding the conscious stimulus and another encoding the suppressed stimulus? To address this question, we compared modulation indices for the dominant stimulus with modulation indices for the suppressed stimulus for each cell. For the former, we fixed the suppressed stimulus while varying the dominant stimulus, that is, we compared responses to trial type (A,<bold>B</bold>) with responses to trial type (A,<bold>C</bold>) to compute the modulation index <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>dominant</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mtext> </mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. For the latter, we fixed the dominant stimulus while varying the suppressed stimulus, that is, we compared responses to trial type (<bold>A</bold>,B) with responses to trial type (<bold>A</bold>,C) to compute the modulation index <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>suppressed</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mtext> </mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). We found a positive correlation between dominant stimulus modulation indices and suppressed stimulus modulation indices (<inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, Pearson’s <inline-formula><mml:math id="inf30"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>66</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> physically selective cells). This suggests that cells strongly modulated by the dominant stimulus tend to be similarly modulated by the suppressed stimulus. Thus there are not two separate populations of cells that encode conscious and unconscious stimuli.</p><p>In summary, our findings indicate that the neural correlate of consciousness in IT does not reside in a subset of cells perfectly reflecting consciousness but rather in a population code. This is supported by the findings that (i) modulation by the conscious percept is weaker than modulation by the physical stimulus (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig5">5</xref>), (ii) both consciously perceived and suppressed stimuli can be decoded from the same population (<xref ref-type="fig" rid="fig6">Figure 6b</xref>), and (iii) modulation indices for consciously perceived and suppressed stimuli are correlated in single cells (<xref ref-type="fig" rid="fig6">Figure 6c</xref>).</p></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we developed a new no-report paradigm for tracking conscious state and used it to investigate the neural correlate of consciousness in face patches within macaque IT cortex. We made two new findings. First, we found that face patches ML and AM are modulated by conscious perception and do not merely encode the physical input. Importantly, monkeys in this study had never been trained to actively report their percept. Instead, we were able to infer their percept from eye movements using a new no-report paradigm. Thus activity modulations attributed to switches in conscious perception in IT cannot be explained simply by active report. Second, we found that cells in face patches are modulated by the identity of both the consciously perceived stimulus and the suppressed stimulus, such that both stimuli can be read out from the same population using different linear decoders. This finding challenges the widely held notion that in IT cortex almost all neurons respond only to the consciously perceived stimulus.</p><p>Previous single-unit recordings in IT cortex using active report to infer the percept found 90% of cells represent the conscious percept (<xref ref-type="bibr" rid="bib33">Sheinberg and Logothetis, 1997</xref>). Here, we found proportions of 57% in ML and 73% in the more anterior patch AM. The quantitative difference may be due to several factors including different recording sites (Sheinberg and Logothetis recorded from both upper and lower banks of the superior temporal sulcus in a less specifically targeted manner), imperfect accuracy of the no-report paradigm, and differences in stimuli and analysis methods. Importantly, our results confirm that the majority of cells in IT cortex do represent conscious perception. Furthermore, this new paradigm makes studies of consciousness in monkeys more accessible, by replacing the need to train the animal to signal its conscious percept (which can be a laborious process) with a simple task that only requires animals to follow a fixation spot.</p><p>Our results show that for cells that are modulated by conscious perception, the modulation is not ‘all-or-none’. Instead, the average response modulation during the perceptual condition was weaker than during the physical condition (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This was also observed in a previous study of rivalry (<xref ref-type="bibr" rid="bib33">Sheinberg and Logothetis, 1997</xref>), but somehow, this fact has been forgotten in popular lore surrounding the neural correlates of consciousness. For example, the Wikipedia entry for ‘neural correlates of consciousness’ states that “in [inferior temporal cortex] almost all neurons responded only to the perceptually dominant stimulus, so that a ‘face’ cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye”. We think the reason this fact - the decreased average modulation of IT cells by switches in conscious percept compared to switches in physical stimulus - has not garnered much attention up to now is that it could, at least up to now, be simply explained by imperfect labeling of the animal’s perceptual state.</p><p>The key question is: <italic>what happens during single trials?</italic> In the rivalry condition, do responses in single trials look like those to either physically presented faces or objects? By recording from a large number of face cells simultaneously using a novel 128-electrode site probe specifically designed for use in primates, we could address this question for the first time. Surprisingly, we found a dramatically different response profile on single trials between the perceptual and physical conditions (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Although in the physical condition responses clustered into two groups, in the rivalry condition responses appeared unimodal, lying in between the two clusters for the physical condition. This suggests that single cells are multiplexing the conscious percept and the veridical physical stimulus during single trials. To directly test this hypothesis, we presented more than one binocular rivalry stimulus, created from pairs of three images, and found that the subconscious stimulus could indeed by decoded from face patch activity. Moreover, the same cells that were strongly modulated by the conscious percept also tended to be strongly modulated by the suppressed stimulus, ruling out the existence of a subpopulation of cells in IT purely reflecting consciousness. These findings strongly suggest that rivalry is not fully resolved before IT. It remains an open question where and how the conscious percept is ultimately isolated from the suppressed stimulus to produce conscious awareness of the former and not the latter.</p><p>In <xref ref-type="fig" rid="fig6">Figure 6d</xref>, we sketch three models for how perceptually modulated cells in IT cortex could encode stimuli during binocular rivalry. In Model I, cells exactly reflect the conscious percept, encoding it the same way they would encode an unambiguous stimulus. In Model II, the response during binocular rivalry is in between the responses to the two unambiguous stimuli, with the contributions of the two stimuli weighted differently depending on which stimulus is dominant and which stimulus is suppressed. Thus, both the consciously perceived stimulus and suppressed stimulus can be decoded using two different decoders. For Model II, one can further distinguish between two different sub-models depending on whether consciously perceived and suppressed stimuli are encoded by different subsets of spikes or not: in Model IIa, spikes are stochastically generated from the average firing rate on a trial, which is determined by a linearly weighted sum of consciously perceived and suppressed stimuli. Alternatively, in Model IIb, there are two different types of spikes that encode the conscious percept or physical stimulus, respectively. The type of a spike may depend on the phase of a high-frequency oscillation at which the spike occurs (the oscillation would need to be faster than alternations in perceptual dominance), or on whether the spike occurs synchronously with spikes from other neurons. Unlike Model IIa, Model IIb harbors an explicit neural correlate of the conscious percept within a subset of spikes. Importantly, our result that the suppressed stimulus can be decoded rules out the cartoon picture of Model I. Our findings are compatible with both Models IIa and IIb, and future experiments may be able to distinguish between the two.</p><p>Compared to previous approaches that attempted to isolate representations of the conscious percept, our new no-report binocular rivalry paradigm has several advantages. For flash suppression, where a stimulus flashed in one eye suppresses the stimulus in the other eye, report is also not required (<xref ref-type="bibr" rid="bib41">Tsuchiya and Koch, 2005</xref>; <xref ref-type="bibr" rid="bib42">Wilke et al., 2003</xref>; <xref ref-type="bibr" rid="bib43">Wolfe, 1984</xref>). However, in that case, the physical input when the target is perceived is not identical to that when it is suppressed, and thus any modulation observed may be driven entirely externally. Indeed, it is known that if a distractor stimulus is presented simultaneously with a preferred stimulus, the response can be reduced compared to when the preferred stimulus is presented alone, due to simple normalization mechanisms (<xref ref-type="bibr" rid="bib3">Bao and Tsao, 2018</xref>). Another paradigm that has been widely used to study the neural correlates of consciousness is backward masking. Here, the stimulus is presented for such a short time before being masked that sometimes it enters consciousness and sometimes not (<xref ref-type="bibr" rid="bib10">Breitmeyer et al., 1984</xref>). So far, backward masking has always relied on report. Also, it is more susceptible to modulations arising from bottom-up withdrawal of attention or low-level (e.g., retinal) noise, whereas in binocular rivalry perceptual switches appear to be internally generated. One potential confound described by Block as the ‘bored monkey problem’ is that the monkey may still be thinking about whether it is perceiving object or face and internally report it even if it is not required to actively report it (<xref ref-type="bibr" rid="bib6">Block, 2020</xref>). It is methodologically very difficult to entirely remove this confound, but the fact that monkeys had to simultaneously perform a very challenging unrelated task of saccading to jumping fixation points should at least alleviate this concern.</p><p>Alternative approaches to the no-report paradigms of <xref ref-type="bibr" rid="bib13">Frässle et al., 2014</xref> have been developed in which the monkey or human subject is unaware of when a perceptual switch is happening and hence cannot report it, either due to anesthesia or due to the difference in stimuli being too subtle to report. <xref ref-type="bibr" rid="bib9">Brascamp et al., 2015</xref> reported that fMRI responses to binocular rivalry switches in fronto-parietal regions disappear when the difference between the percepts is made so subtle that subjects cannot report it; however, it is possible that the difference between the percepts was just too small to be picked up by the fMRI signal. <xref ref-type="bibr" rid="bib45">Zou et al., 2016</xref> created rivalry stimuli from orthogonal gratings where the grating in one eye was flickered fast enough that it was perceived as uniform gray and only produced fMRI activations in early visual cortex. These stimuli evoked rivalry according to behavioral reports whereas physically uniform stimuli do not, indicating that competition occurred in early visual cortex. In another study consistent with competition in early visual cortex, <xref ref-type="bibr" rid="bib44">Xu et al., 2016</xref> performed optical imaging in V1 while monkeys were anesthetized. They found that during binocular rivalry activations clearly alternated in counter-phase between left eye and right eye dominance columns. We note that competition occurring in V1 is not incompatible with our findings, although our findings suggest that rivalry is unlikely to be fully resolved in early areas, given our ability to decode the suppressed stimulus from cells in IT. It should also be noted as a caveat that hemodynamic signals, as measured in the above studies by fMRI or optical imaging, only indirectly reflect neural activity and have previously shown discrepancies with single-unit responses (<xref ref-type="bibr" rid="bib25">Leopold and Logothetis, 1996</xref>; <xref ref-type="bibr" rid="bib36">Tong and Engel, 2001</xref>). Overall, to the best of our knowledge, the current study describes the representation of conscious and subconscious stimuli in IT cells in the most confound-free way to date. Our study complements a study conducted in parallel by <xref ref-type="bibr" rid="bib21">Kapoor et al., 2020</xref> that found modulations by conscious percept in prefrontal cortex using a different no-report paradigm based on optokinetic nystagmus.</p><p>The existence of two directly connected functional modules with a hierarchical relationship (ML and AM) that both encode the conscious percept of a particular type of object opens the possibility for future studies to investigate how changes in conscious percept are coordinated across the brain. Recordings and perturbations in multiple face patches simultaneously using high-channel count recordings may reveal whether switches occur in a feedforward or feedback wave, and thus yield insight into how our interpretation of the world can be rendered consistent across different levels of representation.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>All animal procedures in this study complied with local and National Institute of Health guidelines including the US National Institutes of Health Guide for Care and Use of Laboratory Animals. All experiments were performed with the approval of the Caltech Institutional Animal Care and Use Committee (IACUC). The behavioral experiment with human subjects for the human psychophysics experiment complied with a protocol approved by the Caltech Institutional Review Board (IRB).</p><sec id="s4-1"><title>Targeting</title><p>Two male rhesus macaques were implanted with head posts and trained to fixate on a dot for juice reward. We targeted face patches ML and AM in IT cortex for electrophysiological recordings. ML and AM were identified using fMRI. Monkeys were scanned in a 3T scanner (Siemens), as described previously (<xref ref-type="bibr" rid="bib38">Tsao et al., 2006</xref>). MION contrast agent was injected to increase signal-to-noise ratio. During fMRI, monkeys passively viewed blocks of faces and blocks of other objects to identify face-selective patches in the brain. Recording chambers (Crist) were implanted over ML and AM. Guide tubes were inserted into the brain 4 mm past the dura through custom-printed grids placed inside the chamber, and electrodes were advanced to the target through the guide tube. Both chamber placement and grid design were planned with the software Planner (<xref ref-type="bibr" rid="bib26">Ohayon and Tsao, 2012</xref>). After insertion of tungsten electrodes, correct targeting of the desired location was confirmed with anatomical MRI scans.</p></sec><sec id="s4-2"><title>Electrophysiology</title><p>Recordings were performed using tungsten electrodes (FHC) with 1 MΩ impedance and, after correct targeting was confirmed, with 32-channel S-probes (Plexon) with 75 µm and 100 µm inter-electrode distance, and, in three sessions, with passive Neuropixels-like probe prototypes (IMEC) (<xref ref-type="bibr" rid="bib12">Dutta et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Jun et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Trautmann et al., 2019</xref>). These prototypes were a limited stock of test devices that were developed and used for testing as part of the development of primate Neuropixels probes and are not available for other labs. Unlike the final product, the prototypes had 128 passive electrode sites across 2 mm (arranged in two parallel staggered bands), but used the same electrode materials and shank specifications (45 mm total shank length). In the additional experiment performed to decode the suppressed stimulus (<xref ref-type="fig" rid="fig6">Figure 6</xref>), we recorded with a novel 64-ch. S-probe in face patch ML. All electrodes were advanced to the target using an oil hydraulic Microdrive (Narishige). Neural signals were recorded using an Omniplex system (Plexon). Local field potentials were low-pass filtered at 200 Hz and recorded at 1000 Hz, and units were high-pass filtered at 300 Hz and recorded at 40 kHz. Only well-isolated units were considered for further analysis.</p></sec><sec id="s4-3"><title>Task</title><p>Monkeys were head fixed and viewed an LCD screen (Acer) of 47° size in a dark room. Monkeys viewed stimuli of 5° size wearing red/cyan anaglyph goggles custom made with filters to match the red and green/blue emission spectrum of the screen, respectively, so that inputs to left and right eyes could be controlled independently. Emission spectra were measured using a PR-650 SpectraScan colorimeter (Photo Research). Eye position was monitored using an infrared eye tracking system (ISCAN). The camera recorded one eye through the red/cyan anaglyph filter. We measured the precision of ISCAN eye positions by computing the absolute value of distances between 1 ms adjacent eye data. The median and 99% confidence interval of this jitter was 0.038° and 0.34°, respectively. Note that these confidence intervals should not be contaminated by saccades which occur less frequently than 10 Hz and therefore make up less than 1% of the distribution. In the first phase of the experiment, monkeys passively viewed at least five repeats of 61 screening stimuli in pseudorandom order (250 ms ON time, 100 ms OFF time) with a fixation spot of 0.25° diameter in the center of the screen. Screening stimuli consisted of 20 images of faces and 41 images of non-face objects. During this phase, monkeys received a juice reward for maintaining fixation for at least 3 s. Subsequently, for the main experiment, stimuli contained one or two fixation spots at one of four possible locations (top, bottom, left, and right, 1° from the center) and were presented for 800 ms ON time and 0 ms OFF time. In the case of two fixation spots, stimuli contained one fixation spot per eye and the two spots never appeared at the same location. During this phase, the monkey received a juice reward if the monkey maintained fixation within 0.5° of one of the fixation spots for at least half of the trial duration (i.e., 400 ms, not required to be contiguous). Stimuli during the main experiment included (1) a monocular face/monocular object with one fixation spot and (2) a binocular stimulus composed of a face and a fixation spot in one eye, and an object and a second fixation spot in the other eye. During the binocular rivalry condition, even though the same stimulus was presented continuously, we refer to the 800 ms duration, after which the two fixation spots would change position, as one trial. To improve rivalry and minimize periods of mixture, face and object stimuli were presented at high contrast on backgrounds consisting of gratings that were orthogonal in the two eyes. Moreover, we applied orthogonal orientation filters (with concentration <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>angle</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0.5</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) to the face and object stimuli, respectively, to increase local orientation contrast and further reduce periods of mixture. For human subjects, stimuli were identical except that the trial duration was 2000 ms, since they had not been extensively trained on the task unlike monkeys and hence needed more time to saccade to the jumping fixation spots. During the additional session performed for decoding the suppressed stimulus (<xref ref-type="fig" rid="fig6">Figure 6</xref>), we presented stimuli in a block design. Each block corresponded to an image pair, for example (A,B), where each fixation position was presented in randomized order, that is, eight trials for the physical condition (including four trials of unambiguous A and four trials of unambiguous B), and 12 trials for the perceptual condition, after which another block was presented (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). We repeated this design so that each image-pair block was presented for at least 60 repetitions.</p></sec><sec id="s4-4"><title>Online analysis</title><p>Spikes were isolated and sorted online using the PlexControl software (Plexon). During the screening phase, the average number of spikes during the time window from 100 ms to 300 ms was calculated for each unit and stimulus. For each stimulus, the average response across units was determined after normalizing the response of each unit by subtracting the mean and dividing by the standard deviation for the unit. Subsequently, the face stimulus with the highest average response and the object stimulus with the lowest average response were chosen to generate stimuli for the main experiment.</p></sec><sec id="s4-5"><title>Offline analysis</title><p>For human subjects, the inferred percept based on button-presses on a given trial was determined according to the last report the subject made before the end of the trial. For humans and monkeys, we also determined their inferred percept based on eye movements depending on which fixation spot they fixated on if they fixated on one of the fixation spots for at least half of the trial duration (i.e., 400 ms for monkeys or 1000 ms for humans, not required to be contiguous). We computed L1 norms for the distance between eye position and a given fixation spot (<xref ref-type="fig" rid="fig1">Figures 1b</xref>, <xref ref-type="fig" rid="fig2">2a</xref>, and <xref ref-type="fig" rid="fig4">4b</xref>). We accounted for an average saccade delay of 350 ms, by analyzing the eye data from 350 ms after trial onset until 350 ms after trial end. For <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4">Figure 4d</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, and <xref ref-type="fig" rid="fig6">Figure 6</xref> in order to exclude trials during which the percept switched back to the opposite percept, we also required the following trial to have the same inferred percept as the current trial. Spikes were re-sorted using the software OfflineSorter (Plexon). For the Neuropixels prototypes, since the high density of electrodes allowed the same neuron to appear on multiple channels, we used Kilosort2 to re-sort spikes (<xref ref-type="bibr" rid="bib28">Pachitariu et al., 2016</xref>). A total of 653 and 481 cells were recorded in monkey A and monkey O, respectively. To correct for delays in stimulus presentation, we used a photodiode that detected the onset and offset of the stimuli. The output of the photodiode was fed into the recording system and later used to synchronize the onset of the stimulus and the neurophysiological data during offline analysis. Peristimulus time histograms (PSTHs) were smoothed with a box kernel (100 ms width). For computing modulation indices we used the average spike count across trials as response. Decoding analysis was performed with a support vector machine with a linear kernel (Matlab fitcsvm) trained to discriminate trials where the inferred percept was face or object, respectively. As predictor variables we used the spike count during the 800 ms of each trial for all simultaneously recorded neurons. All decoding accuracies were cross-validated. In more detail, one trial was chosen for testing and the remaining trials for training; this was repeated for all trials to compute decoding accuracies. Criteria for detecting a saccade were as follows: A saccade was detected at time t if the distance between the mean eye position during t−100,…t−2 ms and the mean eye position during t+2,…t+100 ms was greater than 0.5°, and the eye position during t−100,…t−2 ms and t+2,…t+100 ms, respectively, stayed within 0.5° of the respective mean for at least 80% of the duration of each period. We also required consecutive saccades to be at least 100 ms apart from each other. All analyses were performed using Matlab (MathWorks).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by HHMI and the Simons Foundation. We are grateful to members of the Tsao lab for feedback on the manuscript, Varun Wadia for helping us collect the human subject data, Audo Flores for animal support, Daniel Wagenaar and Eric Trautmann for technical assistance, and Barun Dutta, Tim Harris, Tirin Moore, Michael Shadlen, Krishna Shenoy, and HHMI for contributions to development of NHP Neuropixels probes.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The behavioral experiment with human subjects for the human psychophysics experiment complied with a protocol approved by the Caltech Institutional Review Board (IRB 19-0903). Informed consent was obtained from all subjects.</p></fn><fn fn-type="other"><p>Animal experimentation: All animal procedures in this study complied with local and National Institute of Health guidelines including the US National Institutes of Health Guide for Care and Use of Laboratory Animals. All experiments were performed with the approval of the Caltech Institutional Animal Care and Use Committee (IACUC), under protocol #1574.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-58360-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting files.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aru</surname> <given-names>J</given-names></name><name><surname>Bachmann</surname> <given-names>T</given-names></name><name><surname>Singer</surname> <given-names>W</given-names></name><name><surname>Melloni</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distilling the neural correlates of consciousness</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>36</volume><fpage>737</fpage><lpage>746</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2011.12.003</pub-id><pub-id pub-id-type="pmid">22192881</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname> <given-names>P</given-names></name><name><surname>She</surname> <given-names>L</given-names></name><name><surname>McGill</surname> <given-names>M</given-names></name><name><surname>Tsao</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A map of object space in primate inferotemporal cortex</article-title><source>Nature</source><volume>583</volume><fpage>103</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2350-5</pub-id><pub-id pub-id-type="pmid">32494012</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname> <given-names>P</given-names></name><name><surname>Tsao</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Representation of multiple objects in macaque category-selective Areas</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1774</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04126-7</pub-id><pub-id pub-id-type="pmid">29720645</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blake</surname> <given-names>R</given-names></name><name><surname>Brascamp</surname> <given-names>J</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Can binocular rivalry reveal neural correlates of consciousness?</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><elocation-id>20130211</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0211</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Block</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>What is wrong with the No-Report paradigm and how to fix it</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>1003</fpage><lpage>1013</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.10.001</pub-id><pub-id pub-id-type="pmid">31676213</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Block</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Finessing the bored monkey problem</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>167</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.12.012</pub-id><pub-id pub-id-type="pmid">31987718</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boly</surname> <given-names>M</given-names></name><name><surname>Massimini</surname> <given-names>M</given-names></name><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Tononi</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Are the neural correlates of consciousness in the front or in the back of the cerebral cortex? clinical and neuroimaging evidence</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>9603</fpage><lpage>9613</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3218-16.2017</pub-id><pub-id pub-id-type="pmid">28978697</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname> <given-names>MM</given-names></name><name><surname>Miccoli</surname> <given-names>L</given-names></name><name><surname>Escrig</surname> <given-names>MA</given-names></name><name><surname>Lang</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The pupil as a measure of emotional arousal and autonomic activation</article-title><source>Psychophysiology</source><volume>45</volume><fpage>602</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2008.00654.x</pub-id><pub-id pub-id-type="pmid">18282202</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brascamp</surname> <given-names>J</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name><name><surname>Knapen</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Negligible fronto-parietal BOLD activity accompanying unreportable switches in bistable perception</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1672</fpage><lpage>1678</lpage><pub-id pub-id-type="doi">10.1038/nn.4130</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Breitmeyer</surname> <given-names>BG</given-names></name><name><surname>Hoar</surname> <given-names>WS</given-names></name><name><surname>Randall</surname> <given-names>D</given-names></name><name><surname>Conte</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="1984">1984</year><source>Visual Masking: An Integrative Approach</source><publisher-name>Clarendon Press</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname> <given-names>L</given-names></name><name><surname>Tsao</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The code for facial identity in the primate brain</article-title><source>Cell</source><volume>169</volume><fpage>1013</fpage><lpage>1028</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.05.011</pub-id><pub-id pub-id-type="pmid">28575666</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Dutta</surname> <given-names>B</given-names></name><name><surname>Andrei</surname> <given-names>A</given-names></name><name><surname>Harris</surname> <given-names>T</given-names></name><name><surname>Lopez</surname> <given-names>C</given-names></name><name><surname>O’Callahan</surname> <given-names>J</given-names></name><name><surname>Putzeys</surname> <given-names>J</given-names></name><name><surname>Raducanu</surname> <given-names>B</given-names></name><name><surname>Severi</surname> <given-names>S</given-names></name><name><surname>Stavisky</surname> <given-names>S</given-names></name><name><surname>Trautmann</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The neuropixels probe: a CMOS based integrated microsystems platform for neuroscience and brain-computer interfaces. 2019</article-title><conf-name>IEEE International Electron Devices Meeting (IEDM)</conf-name><pub-id pub-id-type="doi">10.1109/IEDM19573.2019.8993611</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frässle</surname> <given-names>S</given-names></name><name><surname>Sommer</surname> <given-names>J</given-names></name><name><surname>Jansen</surname> <given-names>A</given-names></name><name><surname>Naber</surname> <given-names>M</given-names></name><name><surname>Einhauser</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Binocular rivalry: frontal activity relates to introspection and action but not to perception</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>1738</fpage><lpage>1747</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4403-13.2014</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freiwald</surname> <given-names>WA</given-names></name><name><surname>Tsao</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional compartmentalization and viewpoint generalization within the macaque face-processing system</article-title><source>Science</source><volume>330</volume><fpage>845</fpage><lpage>851</lpage><pub-id pub-id-type="doi">10.1126/science.1194908</pub-id><pub-id pub-id-type="pmid">21051642</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelbard-Sagiv</surname> <given-names>H</given-names></name><name><surname>Mudrik</surname> <given-names>L</given-names></name><name><surname>Hill</surname> <given-names>MR</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Fried</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human single neuron activity precedes emergence of conscious perception</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2057</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-03749-0</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grimaldi</surname> <given-names>P</given-names></name><name><surname>Saleem</surname> <given-names>KS</given-names></name><name><surname>Tsao</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Anatomical connections of the functionally defined &quot;Face Patches&quot; in the Macaque Monkey</article-title><source>Neuron</source><volume>90</volume><fpage>1325</fpage><lpage>1342</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.009</pub-id><pub-id pub-id-type="pmid">27263973</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesse</surname> <given-names>JK</given-names></name><name><surname>Tsao</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The macaque face patch system: a turtle’s underbelly for the brain</article-title><source>Nature Reviews Neuroscience</source><volume>147</volume><fpage>695</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-00393-w</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoeks</surname> <given-names>B</given-names></name><name><surname>Levelt</surname> <given-names>WJM</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Pupillary dilation as a measure of attention: a quantitative system analysis</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><volume>25</volume><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.3758/BF03204445</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hohwy</surname> <given-names>J</given-names></name><name><surname>Roepstorff</surname> <given-names>A</given-names></name><name><surname>Friston</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Predictive coding explains binocular rivalry: an epistemological review</article-title><source>Cognition</source><volume>108</volume><fpage>687</fpage><lpage>701</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2008.05.010</pub-id><pub-id pub-id-type="pmid">18649876</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname> <given-names>JJ</given-names></name><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Siegle</surname> <given-names>JH</given-names></name><name><surname>Denman</surname> <given-names>DJ</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Barbarits</surname> <given-names>B</given-names></name><name><surname>Lee</surname> <given-names>AK</given-names></name><name><surname>Anastassiou</surname> <given-names>CA</given-names></name><name><surname>Andrei</surname> <given-names>A</given-names></name><name><surname>Aydın</surname> <given-names>Ç</given-names></name><name><surname>Barbic</surname> <given-names>M</given-names></name><name><surname>Blanche</surname> <given-names>TJ</given-names></name><name><surname>Bonin</surname> <given-names>V</given-names></name><name><surname>Couto</surname> <given-names>J</given-names></name><name><surname>Dutta</surname> <given-names>B</given-names></name><name><surname>Gratiy</surname> <given-names>SL</given-names></name><name><surname>Gutnisky</surname> <given-names>DA</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name><name><surname>Karsh</surname> <given-names>B</given-names></name><name><surname>Ledochowitsch</surname> <given-names>P</given-names></name><name><surname>Lopez</surname> <given-names>CM</given-names></name><name><surname>Mitelut</surname> <given-names>C</given-names></name><name><surname>Musa</surname> <given-names>S</given-names></name><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Putzeys</surname> <given-names>J</given-names></name><name><surname>Rich</surname> <given-names>PD</given-names></name><name><surname>Rossant</surname> <given-names>C</given-names></name><name><surname>Sun</surname> <given-names>WL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Harris</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><volume>551</volume><fpage>232</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/nature24636</pub-id><pub-id pub-id-type="pmid">29120427</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kapoor</surname> <given-names>V</given-names></name><name><surname>Dwarakanath</surname> <given-names>A</given-names></name><name><surname>Safavi</surname> <given-names>S</given-names></name><name><surname>Werner</surname> <given-names>J</given-names></name><name><surname>Besserve</surname> <given-names>M</given-names></name><name><surname>Panagiotaropoulos</surname> <given-names>TI</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Decoding the contents of consciousness from prefrontal ensembles</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.28.921841</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Massimini</surname> <given-names>M</given-names></name><name><surname>Boly</surname> <given-names>M</given-names></name><name><surname>Tononi</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural correlates of consciousness: progress and problems</article-title><source>Nature Reviews Neuroscience</source><volume>17</volume><fpage>307</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.22</pub-id><pub-id pub-id-type="pmid">27094080</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leibo</surname> <given-names>JZ</given-names></name><name><surname>Liao</surname> <given-names>Q</given-names></name><name><surname>Anselmi</surname> <given-names>F</given-names></name><name><surname>Freiwald</surname> <given-names>WA</given-names></name><name><surname>Poggio</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>View-Tolerant face recognition and hebbian learning imply Mirror-Symmetric neural tuning to head orientation</article-title><source>Current Biology</source><volume>27</volume><fpage>62</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.10.015</pub-id><pub-id pub-id-type="pmid">27916522</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leopold</surname> <given-names>DA</given-names></name><name><surname>Plettenberg</surname> <given-names>HK</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Visual processing in the ketamine-anesthetized monkey</article-title><source>Experimental Brain Research</source><volume>143</volume><fpage>359</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1007/s00221-001-0998-0</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leopold</surname> <given-names>DA</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Activity changes in early visual cortex reflect monkeys' percepts during binocular rivalry</article-title><source>Nature</source><volume>379</volume><fpage>549</fpage><lpage>553</lpage><pub-id pub-id-type="doi">10.1038/379549a0</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohayon</surname> <given-names>S</given-names></name><name><surname>Tsao</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>MR-guided stereotactic navigation</article-title><source>Journal of Neuroscience Methods</source><volume>204</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2011.11.031</pub-id><pub-id pub-id-type="pmid">22192950</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Overgaard</surname> <given-names>M</given-names></name><name><surname>Fazekas</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Can No-Report paradigms extract true correlates of consciousness?</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>241</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.01.004</pub-id><pub-id pub-id-type="pmid">26880396</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Kadir</surname> <given-names>SN</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fast and accurate spike sorting of high-channel count probes with KiloSort</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panagiotaropoulos</surname> <given-names>TI</given-names></name><name><surname>Dwarakanath</surname> <given-names>A</given-names></name><name><surname>Kapoor</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Prefrontal Cortex and Consciousness: Beware of the Signals</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>343</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.02.005</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname> <given-names>K</given-names></name><name><surname>'t Hart</surname> <given-names>BM</given-names></name><name><surname>Einhäuser</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil dilation signals surprise: evidence for noradrenaline's Role in Decision Making</article-title><source>Frontiers in Neuroscience</source><volume>5</volume><elocation-id>115</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2011.00115</pub-id><pub-id pub-id-type="pmid">21994487</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname> <given-names>RP</given-names></name><name><surname>Ballard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safavi</surname> <given-names>S</given-names></name><name><surname>Kapoor</surname> <given-names>V</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name><name><surname>Panagiotaropoulos</surname> <given-names>TI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Is the frontal lobe involved in conscious perception?</article-title><source>Frontiers in Psychology</source><volume>5</volume><elocation-id>1063</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.01063</pub-id><pub-id pub-id-type="pmid">25285089</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheinberg</surname> <given-names>DL</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The role of temporal cortical Areas in perceptual organization</article-title><source>PNAS</source><volume>94</volume><fpage>3408</fpage><lpage>3413</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.7.3408</pub-id><pub-id pub-id-type="pmid">9096407</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname> <given-names>F</given-names></name><name><surname>Nakayama</surname> <given-names>K</given-names></name><name><surname>Vaughan</surname> <given-names>JT</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Binocular rivalry and visual awareness in human extrastriate cortex</article-title><source>Neuron</source><volume>21</volume><fpage>753</fpage><lpage>759</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80592-9</pub-id><pub-id pub-id-type="pmid">9808462</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname> <given-names>F</given-names></name><name><surname>Meng</surname> <given-names>M</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural bases of binocular rivalry</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>502</fpage><lpage>511</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.09.003</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname> <given-names>F</given-names></name><name><surname>Engel</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Interocular rivalry revealed in the human cortical blind-spot representation</article-title><source>Nature</source><volume>411</volume><fpage>195</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1038/35075583</pub-id><pub-id pub-id-type="pmid">11346796</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trautmann</surname> <given-names>EM</given-names></name><name><surname>Stavisky</surname> <given-names>SD</given-names></name><name><surname>Lahiri</surname> <given-names>S</given-names></name><name><surname>Ames</surname> <given-names>KC</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>O'Shea</surname> <given-names>DJ</given-names></name><name><surname>Vyas</surname> <given-names>S</given-names></name><name><surname>Sun</surname> <given-names>X</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Accurate estimation of neural population dynamics without spike sorting</article-title><source>Neuron</source><volume>103</volume><fpage>292</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.003</pub-id><pub-id pub-id-type="pmid">31171448</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname> <given-names>DY</given-names></name><name><surname>Freiwald</surname> <given-names>WA</given-names></name><name><surname>Tootell</surname> <given-names>RB</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A cortical region consisting entirely of face-selective cells</article-title><source>Science</source><volume>311</volume><fpage>670</fpage><lpage>674</lpage><pub-id pub-id-type="doi">10.1126/science.1119983</pub-id><pub-id pub-id-type="pmid">16456083</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Wilke</surname> <given-names>M</given-names></name><name><surname>Frässle</surname> <given-names>S</given-names></name><name><surname>Lamme</surname> <given-names>VAF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>No-Report paradigms: extracting the true neural correlates of consciousness</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>757</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.10.002</pub-id><pub-id pub-id-type="pmid">26585549</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Frässle</surname> <given-names>S</given-names></name><name><surname>Wilke</surname> <given-names>M</given-names></name><name><surname>Lamme</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>No-report and report-based paradigms jointly unravel the NCC: response to Overgaard and fazekas</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>242</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.01.006</pub-id><pub-id pub-id-type="pmid">26899261</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Continuous flash suppression reduces negative afterimages</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1096</fpage><lpage>1101</lpage><pub-id pub-id-type="doi">10.1038/nn1500</pub-id><pub-id pub-id-type="pmid">15995700</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilke</surname> <given-names>M</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name><name><surname>Leopold</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Generalized flash suppression of salient visual targets</article-title><source>Neuron</source><volume>39</volume><fpage>1043</fpage><lpage>1052</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2003.08.003</pub-id><pub-id pub-id-type="pmid">12971902</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Reversing ocular dominance and suppression in a single flash</article-title><source>Vision Research</source><volume>24</volume><fpage>471</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(84)90044-0</pub-id><pub-id pub-id-type="pmid">6740966</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Ma</surname> <given-names>H</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rivalry-Like neural activity in primary visual cortex in anesthetized monkeys</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>3231</fpage><lpage>3242</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3660-15.2016</pub-id><pub-id pub-id-type="pmid">26985033</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname> <given-names>J</given-names></name><name><surname>He</surname> <given-names>S</given-names></name><name><surname>Zhang</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Binocular rivalry from invisible patterns</article-title><source>PNAS</source><volume>113</volume><fpage>8408</fpage><lpage>8413</lpage><pub-id pub-id-type="doi">10.1073/pnas.1604816113</pub-id><pub-id pub-id-type="pmid">27354535</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>Supplementary text</title><boxed-text><p>In the Results section we found that the suppressed stimulus, that is, B or C in binocular rivalry trials (<bold>A</bold>,B) vs. (<bold>A</bold>,C), where <bold>A</bold> is the consciously perceived image, could be decoded from neural activity with 74% accuracy. A natural question arising from the decoding accuracy of 74% is whether this could have been due to mislabeling by the no-report paradigm. On some trials, the conscious percept may have been mislabeled as (<bold>A</bold>,B) or (<bold>A</bold>,C) and actually have been (A,<bold>B</bold>) or (A,<bold>C</bold>), respectively. In this case, even if cells only encode the conscious percept and not the suppressed stimulus, the decoding accuracy would be higher than chance, as on those mislabeled trials, the decoder could successfully discriminate based on a difference in conscious percept. To address this concern, below we estimate the worst-case decoding accuracy increase we could expect from mislabelings under the null hypothesis that neurons do not encode the suppressed stimulus. For image pair (A,B), we could decode (<bold>A</bold>,B) vs. (A,<bold>B</bold>), that is, whether A or B was consciously perceived as in <xref ref-type="fig" rid="fig4">Figure 4d</xref>, with 89% accuracy in this session. If we had recorded more neurons, or neurons that were more selective, we would expect a decoding accuracy at least as high. Since there is physically no difference between trial types (<bold>A</bold>,B) and (A,<bold>B</bold>), any information that the decoder was able to acquire must have come from the difference in conscious percept. Thus, we can use 89% as a lower bound for the estimated accuracy of the no-report paradigm in inferring the correct conscious percept in this session. Under the null hypothesis that neurons only encode the conscious percept, the decoding accuracy for distinguishing (<bold>A</bold>,B) from (<bold>A</bold>,C) for 89% of trials should be chance. For the remaining 11% of trials, the conscious percept may have been B or C, respectively. Even if the decoder can decode all of these mislabeled trials with 100% accuracy (which is an overestimate), the decoding accuracy across all trials would be at most <inline-formula><mml:math id="inf33"><mml:mn>89</mml:mn><mml:mi>%</mml:mi><mml:mo>×</mml:mo><mml:mn>50</mml:mn><mml:mi>%</mml:mi><mml:mo>+</mml:mo><mml:mn>11</mml:mn><mml:mi>%</mml:mi><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mi>%</mml:mi><mml:mo>=</mml:mo><mml:mn>55.5</mml:mn><mml:mi>%</mml:mi></mml:math></inline-formula>. So even in the worst-case, the mislabeled trials would not lead to the observed decoding accuracy of 74%. This suggests that face cells do indeed encode the suppressed image.</p></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.58360.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Meng</surname><given-names>Ming</given-names></name><role>Reviewing Editor</role><aff><institution>South China Normal University</institution><country>China</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Duchaine</surname><given-names>Brad</given-names> </name><role>Reviewer</role><aff><institution>Dartmouth College</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Binocular rivalry is a prominent type of bistable perception (illusion), in which observer's conscious perception automatically switches while stimuli remain unchanged. The present study combines cutting-edge neurophysiological recordings and a novel no-report paradigm to revisit whether macaque inferotemporal (IT) cortex correlates with the animal's conscious percept. The results are provocative, suggesting that a) cells in the IT cortex are modulated by conscious percept; b) single cells may multiplex representation of illusory percept and physical stimulus.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Representation of conscious percept without report in the macaque face patch network&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Floris de Lange as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Brad Duchaine (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require a modest amount of additional new data, as they do with your paper, we are asking that the manuscript be revised to either limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Our expectation is that the authors will eventually carry out the additional experiments and report on how they affect the relevant conclusions either in a preprint on bioRxiv or medRxiv, or if appropriate, as a Research Advance in <italic>eLife</italic>, either of which would be linked to the original paper.</p><p>Summary:</p><p>The study by Hesse and Tsao on &quot;Representation of conscious percept without report in the macaque face patch network&quot; presents confirmatory results reported first in seminal studies by Sheinberg and Logothetis from the 90's showing that neurons in infero-temporal (IT) cortex represent the conscious percept in a binocular rivalry paradigm rather than the physical stimulus. This earlier work has inspired neuroscientists for generations, and the present study is a refreshing update in presenting a novel paradigm to study conscious perception without the necessity of active report.</p><p>The authors recorded a large set of neurons with a neuropixel prototype and 32 channel probes in parts of the macaque face patch system, specifically patches ML and AM. They devised a novel task during which perceptual switches between a face and an objects were denoted with specific fixation point locations, so that the percept could be tracked without the need to track manual responses. Thereby, any contributions of the motor system to rivalry could be ruled out. This 'no report' paradigm was first established in humans, and then applied to monkeys trained to fixate for periods of time. The rivalry conditions were compared to physical alternations. The authors show compellingly that a large proportion of ML neurons, and the majority of AM neurons follow the percept during rivalry. The perceptual state could also be decoded from population activity.</p><p>The main novelty of this study is the innovation of a new paradigm that can be used to study conscious perception in individuals who are simply trained on fixation. The results (both behavioral and recordings) are compelling. While the study confirms that IT neurons can reflect the percept of an individual, it does not show where that percept is generated, that is whether it reflects feedback signals from PFC, or other neural structures (see Kapoor study), or locally generated, stochastic alternations.</p><p>Revisions for this paper:</p><p>1) The population result is nice given the novel neuropixels recordings, but perhaps not surprising given that the perceptual state could be determined from the majority of single units? Were you able to decode the percept also from the 32 channel probes? Perhaps discuss in greater detail what the population analysis adds.</p><p>2) Rivalry switches often occur slowly, often on the order of seconds. It would be helpful to include more details regarding the behavior (e.g. length of fixation, duration of stable percepts, frequency of switches). Was the paradigm presented in a trial structure? How long were these trials? Was this different for humans and monkeys? Your time scale for the human studies denotes several seconds, the monkey timescales are typically a few hundred milliseconds, which is very short. As you know, it often takes time to even become aware of a switch. More detail on these issues will be helpful given that the no report task is the major advance of the study.</p><p>3) The authors mention that Frassle et al., 2014, used a no-report paradigm, but I'm curious why the authors didn't discuss other rivalry studies that have used no-report paradigm such as Brascamp et al., 2015, Zou et al., 2016, and Xu et al., 2016. These papers used quite different approaches than the current study, but they seem to establish that the neural modulations that accompany rivalry can occur in the absence of a report.</p><p>4) What does it really mean when the cells carry information about both perceived and unperceived stimulus (as shown in Figures 4B and 5B)? If face patch neurons behave in a way of multiplexing information as the authors suggested, then what role might they take in the neural circuits underlying the conscious percept? It has been reported that the responses of high-level visual neurons to suppressive stimuli were almost eliminated (Sheinberg and Logothetis, 1997). Could the authors explain their differences and elaborate why information multiplexing in IT neurons happen only when perceptual reports are not demanded?</p><p>5) While I think the novel no-report design very smart, I wonder how accurate it is. The inferred percepts might be distorted by many factors, such as piecemeal rivalry. Such paradigm imperfection might weaken the average response modulation in rivalry condition, as you might oversimplify the percept, which in fact is not complete face or object. If so, does the less pronounced modulation during rivalry than in physical condition truly reflect neural representation, or a side effect from mislabeling?</p><p>Revisions expected in follow-up work:</p><p>How was the ISCAN system integrated with the goggles? What was the quality of eye movement measurements? Did you examine microsaccades that also can contribute to switches?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.58360.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>[…] The main novelty of this study is the innovation of a new paradigm that can be used to study conscious perception in individuals who are simply trained on fixation. The results (both behavioral and recordings) are compelling. While the study confirms that IT neurons can reflect the percept of an individual, it does not show where that percept is generated, that is whether it reflects feedback signals from PFC, or other neural structures (see Kapoor study), or locally generated, stochastic alternations.</p></disp-quote><p>We would like to thank the reviewers for both the compliments and constructive criticism on the manuscript. We have revised the paper incorporating all the feedback and believe that the manuscript is significantly stronger due to this process.</p><p>In addition to the valuable revisions suggested by the reviewers, we are happy to announce that we have also performed a new experiment. Even though the reviewers did not require additional experiments, we believe that this addition adds scientific value to the article by directly addressing the outstanding question whether face patches indeed encode the unperceived stimulus, for which we until now only had suggestive evidence:</p><p>Decoding the suppressed stimulus</p><p>The finding that modulations in the perceptual condition are weaker and responses are distributed less bimodally on a single-trial basis suggested that cells may be multiplexing information about not only the consciously perceived stimulus but also the suppressed, subconscious stimulus. However, since in all previously recorded sessions binocular rivalry stimuli consisted of only two rivalling images, this could not be shown directly. In a new experiment, we therefore used three images, A, B, and C, and presented two different binocular rivalry stimuli made of image pairs (A,B) and (A,C), respectively (Figure 6A). This allowed us to compare trials where A was consciously perceived but the suppressed stimulus was either B or C, i.e., the animal’s conscious perception was the same in both types of trials, and only the suppressed stimulus varied. We asked whether we can decode the suppressed stimulus, i.e., distinguish between trial types (A,B) and (A,C) based on neural responses, where the image name in bold indicates the consciously perceived image, as inferred by eye movements. We performed this experiment while recording from face patch ML with a 64 channel S-probe. The decoding accuracy for distinguishing the two trial types with different suppressed images was 74% (Figure 6B). This indicates that face cells do encode the subconscious stimulus. Do the same cells multiplex information about both the conscious and subconscious stimulus or are there two distinct subpopulations, with one population encoding the conscious stimulus and another encoding the subconscious stimulus? To address this question, we compared modulation indices for the dominant stimulus with modulation indices for the suppressed stimulus for each cell. For the former, we fixed the suppressed stimulus while varying the dominant stimulus, i.e., 𝑀𝐼<sub>𝑑𝑜𝑚𝑖𝑛𝑎𝑛𝑡</sub> = (𝑅<sub>A<bold>B</bold> </sub>− 𝑅<sub>A𝐂</sub>)/(𝑅<sub>A𝐁</sub> + 𝑅<sub>A𝐂</sub> ), and for the latter we fixed the dominant stimulus while varying the suppressed stimulus, i.e., 𝑀𝐼<sub>𝑠𝑢𝑝𝑝𝑟𝑒𝑠𝑠𝑒𝑑</sub> = (𝑅<sub>𝐀B</sub> −𝑅<sub>𝐀C</sub>)/(𝑅<sub>𝐀B</sub> + 𝑅<sub>𝐀C</sub> ). We found a positive correlation between dominant stimulus modulation indices and suppressed stimulus modulation indices (𝑝 = 1.4 × 10<sup>−6</sup>, Pearson’s 𝑟 = 0.55, 𝑛 = 66 physically selective cells, Figure 6C). This suggests that cells that are strongly modulated by the dominant stimulus tend to be similarly modulated by the suppressed stimulus. Thus, we did not find evidence for separate populations of cells that encode conscious and unconscious stimulus, respectively.</p><p>A natural question arising from the decoding accuracy of 74% is whether this could be due to mislabeling by the no-report paradigm. On some trials, the conscious percept may have been mislabeled as (<bold>A</bold>,B) or (<bold>A</bold>,C) and actually have been (A,<bold>B</bold>) or (A,<bold>C</bold>), respectively. In this case, even if cells only encode the conscious percept and not the suppressed stimulus, the decoding accuracy may have been higher than chance because on those mislabeled trials, the decoder successfully discriminated based on a difference in conscious percept. The following calculation addresses this concern: We will estimate the worst-case decoding accuracy increase we could expect from these mislabelings under the null hypothesis that neurons do not encode the suppressed stimulus. Within image pair (A,B), we could decode (<bold>A</bold>,B) vs. (A,<bold>B</bold>), i.e., whether A or B was consciously perceived as in Figure 4D, with 89% accuracy in this session. If we had recorded more neurons, or neurons that were more selective, we would expect a decoding accuracy at least as high. Given the nature of the no-report binocular rivalry paradigm there is physically no difference between trial types (<bold>A</bold>,B) and (A,<bold>B</bold>), and hence any information that the decoder was able to acquire must have come from the difference in conscious percept. Thus, we can use 89% as a lower bound for the estimated accuracy of the no-report paradigm of inferring the correct conscious percept in this session. Under the null hypothesis that neurons only encode the conscious percept, the decoding accuracy for distinguishing (<bold>A</bold>,B) from (<bold>A</bold>,C) for 89% of trials should be chance (since for these trials, the conscious percept is correctly decoded as A). For the remaining 12% of trials, the conscious percept may have been B or C, respectively. Even if the decoder can decode all of these mislabeled trials with 100% accuracy (which is an overestimate), the decoding accuracy across all trials would be at most 89% × 50% + 11% × 100% = 55.5%. So even in the worst-case, the mislabeled trials would not lead to the observed decoding accuracy of 74%. This suggests that face cells do indeed encode the suppressed image.</p><p>We have incorporated the new experiment and associated analyses into the revised manuscript. We believe this additional evidence significantly strengthens the paper, and raise it from a mostly confirmatory study to one that challenges the currently dominant concept of how rivalrous stimuli are represented in IT cortex (Figure 6D, Model I versus Model II).</p><disp-quote content-type="editor-comment"><p>Revisions for this paper:</p><p>1) The population result is nice given the novel neuropixels recordings, but perhaps not surprising given that the perceptual state could be determined from the majority of single units? Were you able to decode the percept also from the 32 channel probes? Perhaps discuss in greater detail what the population analysis adds.</p></disp-quote><p>We agree that the perceptual modulation of single units predicts that perceptual state can be decoded. The decoding analysis is a proof of concept that perceptual content can be decoded on a single-trial basis with accuracies much higher than chance (95% for physical and 78% for perceptual on average across sessions). This is something we could not achieve with single electrodes: When performing the decoding with single neurons, decoding accuracies were merely 61% ± 12% for physical and 55% ± 6% for perceptual (mean accuracy ± standard deviation across neurons). While the use of Neuropixels prototypes represents an innovation in terms of number of simultaneously recorded channels, it was not necessary to use Neuropixels to decode the percept above chance. Indeed, of the 12 data points in Figure 4D, only three sessions included Neuropixels data. On the 9 other sessions, we recorded with two 32-ch. S-probes in ML and AM and still obtained decoding accuracies much higher than chance. We make this clearer in the text now:</p><p>“Recordings were performed using tungsten electrodes (FHC) with 1 MΩ impedance and, after correct targeting was confirmed, with 32-channel S-probes (Plexon) with 75 µm and 100 µm inter-electrode distance, and, in three sessions, with passive Neuropixels-like probe prototypes (IMEC) (Dutta et al., 2019; Jun et al., 2017; Trautmann et al., 2019).”</p><p>What the population analysis really adds in our opinion is that we can ask how conscious percepts are encoded during binocular rivalry on single trials. Previous</p><p>electrophysiological studies averaged across trials (e.g., Sheinberg and Logothetis, 1997) and found weaker modulation on average for binocular rivalry as compared to physical switches. However, it is unclear whether this weaker modulation strength was the case across all trials or whether it arose from mislabeling of percept on some trials. Therefore, a common perception is that in IT most cells reflect conscious perception exactly (see, e.g., reviewer comment #4 below). Our single-trial analysis of large numbers of simultaneously recorded cells shows that the distribution of single-trial responses during binocular rivalry is less bimodal and spans a smaller range, indicating that cells are truly more weakly modulated during binocular rivalry. This raised the interesting possibility that cells may multiplex information about the veridical physical stimulus and the conscious percept, which we were able to confirm by decoding the suppressed stimulus from a population of simultaneously recorded neurons. We emphasize this fact in the Introduction:</p><p>“In a second innovation, we performed electrophysiological recordings using a novel 128-electrode site Neuropixels-like probe that allowed us to measure responses from large numbers of cells simultaneously. […] Inter-trial averaging confounds these two possibilities; to distinguish them, it is critical to compare perceptual versus physical response modulations for single trials.”</p><disp-quote content-type="editor-comment"><p>2) Rivalry switches often occur slowly, often on the order of seconds. It would be helpful to include more details regarding the behavior (e.g. length of fixation, duration of stable percepts, frequency of switches). Was the paradigm presented in a trial structure? How long were these trials? Was this different for humans and monkeys? Your time scale for the human studies denotes several seconds, the monkey timescales are typically a few hundred milliseconds, which is very short. As you know, it often takes time to even become aware of a switch. More detail on these issues will be helpful given that the no report task is the major advance of the study.</p></disp-quote><p>Thank you for this helpful comment. We have now clarified and supplemented the pertaining information in the Materials and methods section. The binocular rivalry stimuli were presented continuously, but fixation spot positions changed at regular intervals and we defined a trial structure based on that. For monkey experiments, the duration of each trial duration was 800 ms (i.e., fixation spots jumped to a new position every 800 ms). For the human experiment, we set the trial duration to 2000 ms, since the study participants had not been extensively trained on the task unlike monkeys and hence needed more time to saccade to the jumping fixation spots. We have now clarified these details in the text:</p><p>“Subsequently, for the main experiment, stimuli contained one or two fixation spots at one of four possible locations (top, bottom, left, and right, 1 degree from the center) and were presented for 800 ms ON time and 0 ms OFF time. […] During the binocular rivalry condition, even though the same stimulus was presented continuously, we refer to the 800 ms duration, after which the two fixation spots would change position, as one trial.”</p><p>“For human subjects, stimuli were identical except that the trial duration was 2000 ms, since they had not been extensively trained on the task unlike monkeys and hence needed more time to saccade to the jumping fixation spots.”</p><p>The trial duration determines the temporal resolution with which we were able to infer switches in percept. However, the trial duration was significantly lower than the average switching time of the percept: In monkeys, median dominance duration was 7.2 seconds for faces and 7.2 seconds for objects. In humans, median dominance duration was 8 seconds for faces and 10 seconds for objects as estimated from fixation patterns, and 8.1 seconds for faces and 8.3 seconds for objects as estimated from reports. We now include the dominance durations in the Results section of the manuscript:</p><p>“To account for individuals’ eye dominance, we balanced the contrasts of the stimuli in the two eyes so that the monkey followed both fixation spots equally often in the rivalry condition. […] Similarly, in human subjects median dominance durations were 8 seconds for faces and 10 seconds for objects as estimated from fixation patterns, and 8.1 seconds for faces and 8.3 seconds for objects as estimated from reports.”</p><disp-quote content-type="editor-comment"><p>3) The authors mention that Frassle et al., 2014, used a no-report paradigm, but I'm curious why the authors didn't discuss other rivalry studies that have used no-report paradigm such as Brascamp et al., 2015, Zou et al., 2016, and Xu et al., 2016. These papers used quite different approaches than the current study, but they seem to establish that the neural modulations that accompany rivalry can occur in the absence of a report.</p></disp-quote><p>We thank the reviewers for directing our attention to these interesting alternative approaches to no-report paradigms and have added them to the Discussion:</p><p>“Alternative approaches to the no-report paradigms of Frässle et al., 2014, have been developed in which the monkey or human subject is unaware of when a perceptual switch is happening and hence cannot report it, either due to anesthesia or due to the difference in stimuli being too subtle to report. […] Thus, to the best of our knowledge, the current study reveals representation of the conscious percept in IT cells in the most confound-free way to date.”</p><disp-quote content-type="editor-comment"><p>4) What does it really mean when the cells carry information about both perceived and unperceived stimulus (as shown in Figures 4B and 5B)? If face patch neurons behave in a way of multiplexing information as the authors suggested, then what role might they take in the neural circuits underlying the conscious percept? It has been reported that the responses of high-level visual neurons to suppressive stimuli were almost eliminated (Sheinberg and Logothetis, 1997). Could the authors explain their differences and elaborate why information multiplexing in IT neurons happen only when perceptual reports are not demanded?</p></disp-quote><p>It would be hard to imagine how a circuit mechanism within IT could generate switches of conscious percept if IT cells did not encode any information about the suppressed stimulus, since the neural state would be indistinguishable from that to an unambiguous stimulus. The additional experiment described above confirms that cells do indeed multiplex information about the perceived and unperceived stimulus, as both the perceived stimulus and the unperceived stimulus can be decoded from the population, using different decoders. Figure 6C suggests that there are not two distinct populations for encoding perceived and unperceived stimulus, respectively, but the same neuron may have mixed selectivity for perceived and unperceived stimulus. This leaves open the possibility that IT or downstream areas are involved in switches of conscious percept. We mention this in the Discussion:</p><p>“To directly test this hypothesis, we presented more than one binocular rivalry stimulus, created from pairs of three images, and found that the subconscious stimulus could indeed by decoded from face patch activity. […] It remains an open question where and how the conscious percept is ultimately isolated from the suppressed stimulus to produce conscious awareness of the former and not the latter.”.</p><p>It is a common misconception, which we also had at the outset of this project, that high level visual neurons in IT reflect conscious percept exactly as physical stimuli. Figure 5 of the original paper by Sheinberg and Logothetis, 1997, on neural correlates of binocular rivalry, shows that cells were significantly more weakly modulated during rivalry. Notably, when the non-preferred stimulus was perceived in rivalry, responses were not eliminated. The original study used single electrodes and averaged across trials, and hence, it could not be determined whether the weaker modulation stemmed from mislabeling on a subset of trials. Importantly, we do not think that the multiplexing happens only if reports are demanded. Instead, the weaker modulation appears to be a hallmark of rivalry whether it is reported or not.</p><disp-quote content-type="editor-comment"><p>5) While I think the novel no-report design very smart, I wonder how accurate it is. The inferred percepts might be distorted by many factors, such as piecemeal rivalry. Such paradigm imperfection might weaken the average response modulation in rivalry condition, as you might oversimplify the percept, which in fact is not complete face or object. If so, does the less pronounced modulation during rivalry than in physical condition truly reflect neural representation, or a side effect from mislabeling?</p></disp-quote><p>The effect of mislabeled and mixture trials is a valid concern. We therefore optimized the stimulus to enhance competition between the stimuli and decrease periods of mixture using a variety of methods including: (1) having the stimulus as small as possible while allowing accurate tracking of fixation patterns (5 degree total), (2) increasing contrast of both eyes’ object images, (3) adding fixation marks to help with fusion, (4) adding orthogonal gratings in the background of the objects to increase local orientation contrast, and (5) applying orientation filters to the object images that were orthogonal in left and right eyes to further increase local orientation contrast. We asked human subjects to report whether and how frequently they perceived mixture during the experiment and all subjects reported that they could see only one of the objects most of the time. See the Materials and methods section:</p><p>“During the binocular rivalry condition, even though the same stimulus was presented continuously, we refer to the 800 ms duration, after which the two fixation spots would change position, as one trial. […] Moreover, we applied orthogonal orientation filters (with concentration 𝜎<sub>𝑎𝑛𝑔𝑙𝑒</sub> = 0.5°) to the face and object stimuli, respectively, to increase local orientation contrast and further reduce periods of mixture.”</p><p>We think that trials with mixture or mislabeled percept did contribute to the weaker modulation averaged across trials assuming that proportions of mislabeling and mixture were similar. However, we think that these factors cannot explain the radically different response single-trial response profiles between rivalrous and unambiguous conditions; the former were much less bimodal than the latter and spanned a smaller range, despite the binocular rivalry condition having been presented in many more trials. We performed simulations of the effect of mixture on the data shown in Figure 5. We assumed different proportions of mixture from 0%-100% and simulated the worst-case effect of mixture (i.e. exactly half-face, half-object) on responses in the physical condition, by averaging the responses to pairs of face and object trials. We used the same statistical test as described in the paper and found that only if we added 50%-70% mixture to the physical trial responses, did they become statistically indistinguishable from binocular rivalry responses, whereas each human subject reported not seeing any mixture on most trials. Note that this analysis is independent of correct labeling of conscious percepts. We now describe this simulation in the Results section:</p><p>“Importantly, this difference in response profiles between physical and perceptual conditions was apparent even when pooling across both face and object trials (Figure 5B, middle), and hence cannot be explained by mistakes in inferring the percept from eye movements. […] Yet, under the reasonable assumption that they were similar, trials with mixed or piecemeal percepts cannot account for the difference in response distributions between physical and perceptual conditions.”</p><disp-quote content-type="editor-comment"><p>Revisions expected in follow-up work:</p><p>How was the ISCAN system integrated with the goggles? What was the quality of eye movement measurements? Did you examine microsaccades that also can contribute to switches?</p></disp-quote><p>The ISCAN camera recorded the position of one eye through the anaglyph filter. The presence of the filter only slightly impaired the quality of eye movement measurements. We have added this information to the Materials and methods section:</p><p>“Eye position was monitored using an eye tracking system (ISCAN). The camera recorded one eye through the red/cyan anaglyph filter.”</p><p>We measured the precision of ISCAN eye positions by computing the absolute value of distances between 1 ms adjacent eye data. The median and 99% confidence interval, respectively, were 0.038 degrees and 0.34 degrees. Note that saccades should not contaminate the confidence interval estimate of this jitter, since saccades happen less frequently than every 10 ms. For comparison, the distance between fixation spots was 1.4 or 2 degrees, much larger than the jitter magnitude.</p><fig id="sa2fig1"><label>Author response image 1.</label><caption><title>Quality of eye movement measurements.</title><p>Histogram shows counts of Euclidean distances between eye positions of adjacent milliseconds in the range from 0 to 1 degree visual angle across all recorded sessions. Median and 99% confidence interval (CI) is shown in orange and yellow, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58360-resp-fig1-v2.tif"/></fig><p>We now mention this in the Materials and methods:</p><p>“We measured the precision of ISCAN eye positions by computing the absolute value of distances between 1 ms adjacent eye data. […] Note that these confidence intervals should not be contaminated by saccades which occur less frequently than 10 Hz and therefore make up less than 1% of the distribution.”</p><p>Given the measurement noise above, we were able to detect saccades over distances of 0.5 degrees or larger, which under some definitions can still be considered microsaccades. It has been reported that perceptual switches happen more frequently around microsaccades (Sabrin and Kertesz, 1980; van Dam and van Ee, 2006). However, in our no-report paradigm we infer the conscious percept based on which fixation spot a subject is saccading to at a given trial, and therefore we can infer percepts with at most the sample rate of saccades. Hence, we cannot determine whether the percept switched more during microsaccades than during static fixation. In terms of neural modulation, we did find that saccades evoked response increases during binocular rivalry, and the response increase was slightly higher when we inferred that the preferred stimulus was perceived compared to the non-preferred, see Figure 5 and Results section:</p><p>“We observed response modulations for both physical and perceptual conditions starting around 130 ms after saccade onset (Figure 5A). […] As a consequence, during rivalry the response difference to a saccade between face and object, though significant (𝑝 = 6 × 10<sup>−23</sup>, two-sample t-test, 𝑁 = 701 saccades for object, 𝑁 = 703 saccades for face), was weaker than during the physical condition.”</p><p><bold>References:</bold></p><p>Sabrin, H. W., and Kertesz, A. E. (1980). Microsaccadic eye movements and binocular rivalry. Perception and psychophysics, 28(2), 150-154.</p><p>van Dam, L. C., and van Ee, R. (2006). Retinal image shifts, but not eye movements per se, cause alternations in awareness during binocular rivalry. Journal of vision, 6(11), 3-3.</p></body></sub-article></article>