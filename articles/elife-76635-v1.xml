<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">76635</article-id><article-id pub-id-type="doi">10.7554/eLife.76635</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Putting perception into action with inverse optimal control for continuous psychophysics</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-265201"><name><surname>Straub</surname><given-names>Dominik</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5263-2622</contrib-id><email>dominik.straub@tu-darmstadt.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-232280"><name><surname>Rothkopf</surname><given-names>Constantin A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5636-0801</contrib-id><email>rothkopf@psychologie.tu-darmstadt.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047wbd030</institution-id><institution>Centre for Cognitive Science, Technical University of Darmstadt</institution></institution-wrap><addr-line><named-content content-type="city">Darmstadt</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047wbd030</institution-id><institution>Institute of Psychology, Technical University of Darmstadt</institution></institution-wrap><addr-line><named-content content-type="city">Darmstadt</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Frankfurt Institute for Advanced Studies, Goethe University Frankfurt</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Western University</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>29</day><month>09</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e76635</elocation-id><history><date date-type="received" iso-8601-date="2021-12-23"><day>23</day><month>12</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-08-08"><day>08</day><month>08</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-12-23"><day>23</day><month>12</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.12.23.473976"/></event></pub-history><permissions><copyright-statement>© 2022, Straub and Rothkopf</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Straub and Rothkopf</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-76635-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-76635-figures-v1.pdf"/><abstract><p>Psychophysical methods are a cornerstone of psychology, cognitive science, and neuroscience where they have been used to quantify behavior and its neural correlates for a vast range of mental phenomena. Their power derives from the combination of controlled experiments and rigorous analysis through signal detection theory. Unfortunately, they require many tedious trials and preferably highly trained participants. A recently developed approach, continuous psychophysics, promises to transform the field by abandoning the rigid trial structure involving binary responses and replacing it with continuous behavioral adjustments to dynamic stimuli. However, what has precluded wide adoption of this approach is that current analysis methods do not account for the additional variability introduced by the motor component of the task and therefore recover perceptual thresholds that are larger compared to equivalent traditional psychophysical experiments. Here, we introduce a computational analysis framework for continuous psychophysics based on Bayesian inverse optimal control. We show via simulations and previously published data that this not only recovers the perceptual thresholds but additionally estimates subjects’ action variability, internal behavioral costs, and subjective beliefs about the experimental stimulus dynamics. Taken together, we provide further evidence for the importance of including acting uncertainties, subjective beliefs, and, crucially, the intrinsic costs of behavior, even in experiments seemingly only investigating perception.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>Humans often perceive the world around them subjectively. Factors like light brightness, the speed of a moving object, or an individual's interpretation of facial expressions may influence perception. Understanding how humans perceive the world can provide valuable insights into neuroscience, psychology, and even people’s spending habits, making human perception studies important. However, these so-called psychophysical studies often consist of thousands of simple yes or no questions, which are tedious for adult volunteers, and nearly impossible for children.</p><p>A new approach called ‘continuous psychophysics’ makes perception studies shorter, easier, and more fun for participants. Instead of answering yes or no questions (like in classical psychophysics experiments), the participants follow an object on a screen with their fingers or eyes. One question about this new approach is whether it accounts for differences that affect how well participants follow the object. For example, some people may have jittery hands, while others may be unmotivated to complete the task.</p><p>To overcome this issue, Straub and Rothkopf have developed a mathematical model that can correct for differences between participants in the variability of their actions, their internal costs of actions, and their subjective beliefs about how the target moves. Accounting for these factors in a model can lead to more reliable study results. Straub and Rothkopf used data from three previous continuous psychophysics studies to construct a mathematical model that could best predict the experimental results. To test their model, they then used it on data from a continuous psychophysics study conducted alongside a classical psychophysics study. The model was able to correct the results of the continuous psychophysics study so they were more consistent with the results of the classical study.</p><p>This new technique may enable wider use of continuous psychophysics to study a range of human behavior. It will allow larger, more complex studies that would not have been possible with conventional approaches, as well as enable research on perception in infants and children. Brain scientists may also use this technique to understand how brain activity relates to perception.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>continuous psychophysics</kwd><kwd>optimal control</kwd><kwd>inverse reinforcement learning</kwd><kwd>rational analysis</kwd><kwd>perception and action</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Hessian Ministry of Higher Education, Science, Research and Art</institution></institution-wrap></funding-source><award-id>The Adaptive Mind</award-id><principal-award-recipient><name><surname>Rothkopf</surname><given-names>Constantin A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A new method for analyzing continuous psychophysics experiments estimates not only perceptual uncertainty from tracking tasks but also action variability, intrinsic costs, and subjective internal models.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Psychophysical methods such as forced-choice tasks are widely used in psychology, cognitive science, neuroscience, and behavioral economics because they provide precise and reliable quantitative measurements of the relationship between external stimuli and internal sensations (<xref ref-type="bibr" rid="bib21">Gescheider, 1997</xref>; <xref ref-type="bibr" rid="bib63">Wichmann and Jäkel, 2018</xref>). The tasks employed by traditional psychophysics are typically characterized by a succession of hundreds of trials in which stimuli are presented briefly and the subject responds with a binary decision, for example, whether target stimuli at different contrast levels were perceived to be present or absent.</p><p>The analysis of such experimental data using signal detection theory (SDT; <xref ref-type="bibr" rid="bib24">Green and Swets, 1966</xref>) employs a model that assumes that a sensory signal generates an internal representation corrupted by Gaussian variability. A putative comparison of this stochastic signal with an internal criterion leads to a binary decision. These assumptions render human response rates amenable to analysis based on Bayesian decision theory, by probabilistically inverting the model of the decision-generating process. This provides psychologically interpretable measures of perceptual uncertainty and of the decision criterion, for example, for contrast detection. Thus, the power of classical psychophysics derives from the combination of controlled experimental paradigms with computational analysis encapsulated in SDT.</p><p>Psychophysical experiments and their analysis with SDT have revealed invaluable knowledge about perceptual and cognitive abilities and their neuronal underpinnings, and found widespread application to tasks as diverse as eyewitness identification and medical diagnosis (for recent reviews, see, e.g., <xref ref-type="bibr" rid="bib39">Lynn and Barrett, 2014</xref>; <xref ref-type="bibr" rid="bib64">Wixted, 2020</xref>). One central drawback, however, is that collecting data in such tasks is often tedious, as famously noted already by <xref ref-type="bibr" rid="bib31">James, 1890</xref>. This leads to participants’ engagement levels being low, particularly in untrained subjects, resulting in measurements contaminated by additional variability (<xref ref-type="bibr" rid="bib40">Manning et al., 2018</xref>). A common solution is to rely on few but highly trained observers to achieve consistent measurements (<xref ref-type="bibr" rid="bib24">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib30">Jäkel and Wichmann, 2006</xref>).</p><p>Recent work has suggested overcoming this shortcoming by abandoning the rigid structure imposed by independent trials and instead eliciting continuous behavioral adjustments to dynamic stimuli (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Huk et al., 2018</xref>). In their first study using continuous psychophysics, <xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>, used a tracking task, in which subjects moved a computer mouse to track targets of different contrasts moving according to a random walk governed by linear dynamics with additive Gaussian noise. This experimental protocol not only requires orders of magnitude less time compared to traditional psychophysical methods, but participants report it to be more natural, making it more suitable for untrained subjects and potentially children and infants. Similar approaches have recently been used to measure contrast sensitivity (<xref ref-type="bibr" rid="bib42">Mooney et al., 2018</xref>), eye movements toward optic flow (<xref ref-type="bibr" rid="bib9">Chow et al., 2021</xref>), or retinal sensitivity (<xref ref-type="bibr" rid="bib25">Grillini et al., 2021</xref>).</p><p>To obtain measures of perceptual uncertainty from the tracking data, <xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>, proposed analyzing these data with the Kalman filter (KF; <xref ref-type="bibr" rid="bib34">Kalman, 1960</xref>), the Bayes-optimal estimator for sequential observations with Gaussian uncertainty. The KF, however, models the perceptual side of the tracking task only, that is, how an ideal observer (<xref ref-type="bibr" rid="bib19">Geisler, 1989</xref>) sequentially computes an estimate of the target’s position. Unfortunately, although the perceptual thresholds estimated with the KF from the tracking task were highly correlated with the perceptual uncertainties obtained with an equivalent classical forced-choice task employing stimuli with the same contrast, <xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>, reported that these were systematically larger by a large margin.</p><p>This is not surprising since every perceptual laboratory task involves some motor control component at least for generating a response, albeit to different degrees. While a detection task may require pressing a button, a reproduction task involves a motor control component, and a tracking task involves continuous visuomotor control, as mentioned by <xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>. In addition to the problem of estimating the current position of the target, a tracking task encompasses the motor control problem of moving the finger, computer mouse, or gaze toward the target. This introduces additional sources of variability and bias. First, repeated movements toward a target exhibit variability (<xref ref-type="bibr" rid="bib15">Faisal et al., 2008</xref>), which arises because of neural variability during execution of movements (<xref ref-type="bibr" rid="bib32">Jones et al., 2002</xref>) or their preparation (<xref ref-type="bibr" rid="bib10">Churchland et al., 2006</xref>). Second, a subject might trade off the instructed behavioral goal of the tracking experiment with subjective costs, such as biomechanical energy expenditure (<xref ref-type="bibr" rid="bib13">di Prampero, 1981</xref>) or mental effort (<xref ref-type="bibr" rid="bib52">Shenhav et al., 2017</xref>). Third, subjects might have mistaken assumptions about the statistics of the task (<xref ref-type="bibr" rid="bib45">Petzschner and Glasauer, 2011</xref>; <xref ref-type="bibr" rid="bib5">Beck et al., 2012</xref>), which can lead to different behavior from a model that perfectly knows the task structure, that is, ideal observers. A model that only considers the perceptual side of the task will, therefore, tend to overestimate perceptual uncertainty because these additional factors get lumped into perceptual model parameters, as we will show in simulations.</p><p>Here, we account for these factors by applying ideas from optimal control under uncertainty (see, e.g., <xref ref-type="bibr" rid="bib65">Wolpert and Ghahramani, 2000</xref>; <xref ref-type="bibr" rid="bib56">Todorov and Jordan, 2002</xref>; <xref ref-type="bibr" rid="bib51">Shadmehr and Mussa-Ivaldi, 2012</xref>, for reviews in the context of sensorimotor neuroscience) to the computational analysis of continuous psychophysics. Partially observable Markov decision processes (POMDPs; <xref ref-type="bibr" rid="bib3">Åström, 1965</xref>; <xref ref-type="bibr" rid="bib33">Kaelbling et al., 1998</xref>) offer a general framework for modeling sequential perception, and actions under sensory uncertainty, action variability, and explicitly include behavioral costs (<xref ref-type="bibr" rid="bib28">Hoppe and Rothkopf, 2019</xref>). They can be seen as a generalization of Bayesian decision theory, on which classical analysis of psychophysics including SDT is based, to sequential tasks. Specifically, we employ the well-studied linear quadratic Gaussian framework (LQG; <xref ref-type="bibr" rid="bib2">Anderson and Moore, 2007</xref>), which accommodates continuous states and actions under linear dynamics and Gaussian variability. While the KF, being the Bayes-optimal estimator for a linear-Gaussian system, can be shown to minimize the squared error between the latent target and its estimate, the optimal control framework can flexibly incorporate different kinds of costs such as the intrinsic costs of actions. Thus, it can accommodate task goals beyond estimation as well as physiological and cognitive costs of performing actions.</p><p>Modeling the particular task as it is implemented by the researcher allows deriving a normative model of behavior such as ideal observers in perceptual science (<xref ref-type="bibr" rid="bib24">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib19">Geisler, 1989</xref>) or optimal feedback control models in motor control (<xref ref-type="bibr" rid="bib65">Wolpert and Ghahramani, 2000</xref>; <xref ref-type="bibr" rid="bib56">Todorov and Jordan, 2002</xref>). This classic task analysis at the computational level (<xref ref-type="bibr" rid="bib41">Marr, 1982</xref>) can now be used to produce predictions of behavior, which can be compared to the actual empirically observed behavior. However, the fundamental assumption in such a setting is that the subject is carrying out the instructed task and that subject’s internal model of the task is identical to the underlying generative model of the task employed by the researcher. Here, instead, we allow for the possibility that the subject is not acting on the basis of the model the researcher has implemented in the experiment. Instead, we allow for the possibility that subjects’ cost function does not only capture the instructed task goals but also the experienced subjective cost such as physiological and cognitive costs of performing actions. Such an approach is particularly useful in a more naturalistic task setting, where subjective costs and benefits of behavior are difficult to come by a priori. Similarly, we allow subjects’ subjective internal model of stimulus dynamics to differ from the true model employed by the researcher. In the spirit of rational analysis (<xref ref-type="bibr" rid="bib53">Simon, 1955</xref>; <xref ref-type="bibr" rid="bib1">Anderson, 1991</xref>; <xref ref-type="bibr" rid="bib20">Gershman et al., 2015</xref>), we subsequently invert this model of human behavior by developing a method for performing Bayesian inference of parameters describing the subject. Importantly, inversion of the model allows all parameters to be inferred from behavioral data and does not presuppose their value, so that, for example, if subjects’ actions were not influenced by subjective internal behavioral costs, the internal cost parameter would be estimated to be zero. This approach therefore reconciles normative and descriptive approaches to sensorimotor behavior as it answers the question which subjective internal model, beliefs, and costs best explain observed behavior.</p><p>We show through simulations with synthetic data that models not accounting for behavioral cost and action variability overestimate perceptual uncertainty when applied to data that includes these factors. We apply our method to data from three previously published experiments, infer perceptual uncertainty, and obtain overwhelming evidence through Bayesian model comparison with the widely applicable information criterion (WAIC; <xref ref-type="bibr" rid="bib61">Watanabe and Opper, 2010</xref>) that this model explains the data better than models only considering perceptual contributions to behavioral data. Additionally, the method provides inferences of subjects’ action variability, subjective behavioral costs, and subjective beliefs about stimulus dynamics. Taken together, the methodology presented here improves current analyses and should be the preferred analysis technique for continuous psychophysics paradigms.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Computational models of psychophysical tasks</title><p>In a classical psychophysics task (e.g., position discrimination; <xref ref-type="fig" rid="fig1">Figure 1A and B</xref>), the stimuli <italic>x</italic><sub><italic>t</italic></sub> presented to the observer are usually independent and identically distributed between trials. This allows for straightforward application of Bayesian decision theory: in any trial, the observer receives a stochastic measurement <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, forms a belief <inline-formula><mml:math id="inf2"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and makes a single decision minimizing a cost function <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mtext>argmin</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. In SDT, for example, observations are commonly assumed to be Gaussian distributed and the cost function <italic>J</italic> assigns a value to correct and wrong decisions. These assumptions make it straightforward to compute the observer’s decision probabilities <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> given parameters <italic>θ</italic> (e.g., sensitivity and criterion in SDT) and invert the model to infer those parameters from behavior, yielding a posterior distribution <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig1">Figure 1C</xref>). Similarly, a psychometric curve can be interpreted as the decision probabilities of a Bayesian observer with a particular choice of measurement distribution, which determines the shape of the curve. The assumption of independence between trials is critical in the application of these modeling techniques.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Conceptual frameworks for classical and continuous psychophysics.</title><p>(<bold>A</bold>) In a classical psychophysics task, the subject receives stimuli <italic>x</italic><sub><italic>t</italic></sub> on independent trials, generates sensory observations <italic>y</italic><sub><italic>t</italic></sub>, forms beliefs about the stimulus <inline-formula><mml:math id="inf6"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, and (<bold>B</bold>) makes a single decision <italic>u</italic><sub><italic>t</italic></sub> (e.g., whether the target stimulus was present or absent). (<bold>C</bold>) The researcher has a model of how the agent makes decisions and measures the subject’s sensitivity and decision criterion by inverting this model. For example, one can estimate the agent’s visual uncertainty by computing the width of a psychometric function. (<bold>D</bold>) In a continuous psychophysics task, a continuous stream of stimuli is presented. The subject has an internal model of the dynamics of the task, which they use to form a belief about the state of the world and then perform continuously actions (<bold>E</bold>) based on their belief and subjective costs. (<bold>F</bold>) The researcher observes the subject’s behavior and inverts this internal model, fo example, using Bayesian inference applied to optimal control under uncertainty.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig1-v1.tif"/></fig><p>Continuous psychophysics abandons the independence of stimuli between individual trials. Instead, stimuli are presented in a continuous succession. For example, in a position-tracking task, the stimulus moves from frame to frame and the observer’s goal is to track the stimulus with their mouse cursor (<xref ref-type="fig" rid="fig1">Figure 1D and E</xref>). In a computational model of a continuous task, the stimulus dynamics are characterized by a state transition probability <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and can potentially be influenced by the agent’s actions <inline-formula><mml:math id="inf8"><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. As in the trial-based task, the agent receives a stochastic measurement <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and has the goal to perform a sequence of actions <inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mtext>argmin</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, minimizing the cost function. Formally, this problem of acting under uncertainty is a POMDP and is computationally intractable in the general case (<xref ref-type="bibr" rid="bib3">Åström, 1965</xref>; <xref ref-type="bibr" rid="bib33">Kaelbling et al., 1998</xref>).</p><p>In target-tracking tasks used in previous continuous psychophysics studies (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>; <xref ref-type="bibr" rid="bib29">Huk et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>), in which the target is on a random walk, the dynamics of the stimulus are linear and the subjects’ goal is to track the target. Tracking can be reasonably modeled with a quadratic cost function penalizing the separation between the target and the position of the tracking device. The variability in the dynamics and the uncertainty in the observation model can be modeled with Gaussian distributions. The resulting LQG control problem is a well-studied special case of the general POMDP setting, which can be solved exactly by determining an optimal estimator and an optimal controller (<xref ref-type="bibr" rid="bib14">Edison, 1971</xref>; <xref ref-type="bibr" rid="bib2">Anderson and Moore, 2007</xref>). It is defined by a discrete-time linear dynamical system with Gaussian noise,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>a linear observation model with Gaussian noise,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>and a quadratic cost function,<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>Q</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>R</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <italic>Q</italic> defines the costs for the state (e.g., squared distance between the target and a mouse or hand) and <italic>R</italic> defines the cost of actions (biomechanical, cognitive, etc.).</p><p>For the LQG control problem, the <italic>separation principle</italic> between estimation and control holds (<xref ref-type="bibr" rid="bib11">Davis and Vinter, 1985</xref>). This means that the optimal solutions for the estimator (KF) and controller (LQR) can be computed independently from one another. The KF (<xref ref-type="bibr" rid="bib34">Kalman, 1960</xref>) is used to form a belief <inline-formula><mml:math id="inf11"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> about the current state based on the previous estimate and the current observation:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>This belief is then used to compute the optimal action <inline-formula><mml:math id="inf12"><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> based on the linear quadratic regulator (LQR, <xref ref-type="bibr" rid="bib35">Kalman, 1964</xref>): <inline-formula><mml:math id="inf13"><mml:mrow><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. For the derivations of <inline-formula><mml:math id="inf14"><mml:mi>K</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf15"><mml:mi>L</mml:mi></mml:math></inline-formula>, see section ‘LQG control derivations’.</p><p>We consider four models, each of which is a generalization of the previous one. Importantly, this means that the most general model contains the remaining three as special cases. We introduce the models in the following paragraphs and describe their respective free parameters. For a complete specification of how these parameters need to be set to model a tracking task and how this gives rise to the matrices defining the linear dynamical systems for each model, see <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>.</p><p>First, the ideal observer model in the tracking task is the KF as it is the optimal Bayesian sequential estimator of the latent, unobserved state of the system (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The state represents the current position of the target and there is no explicit representation of the agent’s response or action. The computational goal of the KF is to perform sequential inference about the position of the target given sensory measurements and an internal model of the target’s dynamics. As a proxy for a behavioral response, one can therefore use the best estimate <inline-formula><mml:math id="inf16"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> that corresponds to the target’s position. Because the ideal observer assumption implies that the task dynamics, that is, the standard deviation of the random walk are perfectly known to the subject, the KF has only one free parameter, the perceptual uncertainty <italic>σ</italic>. This parameter describes the uncertainty in the sensory observation of target’s true position.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Computational models for continuous psychophysics.</title><p>(<bold>A</bold>) In the Kalman filter (KF) model, the subject makes an observation <inline-formula><mml:math id="inf17"><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> with Gaussian variability at each time step. They combine their prediction <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with their observation to compute an optimal estimate <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>B</bold>) In the optimal control models, this estimate is then used to compute an optimal action <inline-formula><mml:math id="inf20"><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> using the linear quadratic regulator (LQR). The optimal action can be based on the task goal only or (<bold>C</bold>) bounded by internal costs, which, for example, penalize large movements. (<bold>D</bold>) Finally, the subject may act rationally using optimal estimation and control, but may use a subjective internal model of stimulus dynamics that differs from the true generative model of the task. These four different models are illustrated with an example stimulus and tracking trajectory (left subplots) and corresponding cross-correlograms (CCG, right subplots; see <xref ref-type="bibr" rid="bib43">Mulligan et al., 2013</xref> and ‘Cross-correlograms’).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Pareto efficiency plot.</title><p>The Pareto efficiency plot visualizes the trade-off between two costs contributing to the cost function. The cost function is composed of two terms: state costs <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and action costs <inline-formula><mml:math id="inf22"><mml:msup><mml:mi mathvariant="bold">uu</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:math></inline-formula>, whose importance is balanced by the control cost parameter <italic>c</italic>. In a simulation, we computed these two terms separately for different values of <italic>c</italic> (see color bar) and plot them against each other. We did this for two levels each of action variability (<inline-formula><mml:math id="inf23"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>) and perceptual uncertainty (<italic>σ</italic>). First, there is a trade-off between tracking the target (state costs) and expending control effort (action costs): the better you track the target, the more action costs you have to tolerate. Second, the tracking performance depends on the values of the other two parameters: For a specific level of action variability <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> and perceptual uncertainty <italic>σ</italic>, there is a minimum level of state costs incurred, which cannot be alleviated by decreasing action costs via <italic>c</italic>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Second, the optimal actor model maintains a representation of its own response, that is, the position of the mouse cursor in addition to the target’s position: the state space is now two-dimensional. This allows us, in addition to the sensory uncertainty about the target, to model sensory uncertainty about the position of the cursor <inline-formula><mml:math id="inf25"><mml:msub><mml:mi>σ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). It is now possible to explicitly model a behavioral goal different from optimal sensory inference, as in the case of the KF model. The behavioral goal is encapsulated in the cost function and for the optimal actor the cost function is fully determined by the task goal intended by the researcher, that is, the tracking of the target. Therefore, the cost function does not contain any free parameters in the optimal actor model. Different from the KF model that only carries out estimation, the optimal actor model generates a sequences of actions with their associated action variability <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>. The optimal behavior of the model is now to move the cursor as closely as possible toward the estimated position of the target.</p><p>Third, the bounded actor model is based on the optimal actor model by also using a state representation involving the target and its own response as well as uncertain sensory observations of both these state variables. We use the term &quot;bounded actor&quot; as it is customary in parts of the cognitive science literature, where, according to Herbert Simon's definition (<xref ref-type="bibr" rid="bib53">Simon, 1955</xref>), bounded rationality, which is related to the concept of resource-rationality, takes the limitations on cognitive capacity into a account. It is also a control model so that sequential actions are generated. The difference lies in the cost function, which now can additionally accommodate internal behavioral costs <italic>c</italic> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) that may penalize, for example, large actions and thus result in a larger lag between the response and the target. The control cost parameter <italic>c</italic> therefore can implement a trade-off between tracking the target and expending effort (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>Finally, the subjective actor is a version of the bounded actor but now bases its decisions on an internal model of the stimulus dynamics that may differ from the true generative model employed by the experimenter. The causes for differences in the internal model may be sensory, perceptual, cognitive, or stemming from constraints on planning. For example, in an experimental design with a target moving according to a random walk on position (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>) with a true standard deviation <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>σ</mml:mi><mml:mtext>rw</mml:mtext></mml:msub></mml:math></inline-formula>, the subject could instead assume that the target follows a random walk on position with standard deviation <inline-formula><mml:math id="inf28"><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> and an additional random walk on the velocity with standard deviation <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:math></inline-formula>. These subjective assumptions about the target dynamics can, for example, lead the subjective actor to overshoot the target, for which they then have to correct (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). For the subjective actor, the state space is three-dimensional because it contains the target’s velocity in addition to the target and response positions (see Appendix 2). One could also formulate a version of any of the other models to include subjective beliefs. However, the subjective actor model is a generalization that includes all of these possible models. Accordingly, if the subjective beliefs played an important role but the costs or variability did not, we would infer the relevant parameters to have a value close to zero.</p></sec><sec id="s2-2"><title>Bayesian inverse optimal control</title><p>The normative models described in the previous section treat the problem from the subject’s point of view. That is, they describe how optimal actors with different internal models and different goals as encapsulated by the cost function should behave in a continuous psychophysics task. The above normative models may give rise to different sequences of actions, which are the optimal solutions given the respective models with their associated parameters and computational goals. From the subject’s perspective, the true state of the experiment <inline-formula><mml:math id="inf30"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> is only indirectly observed via the uncertain sensory observation <inline-formula><mml:math id="inf31"><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig1">Figure 1D</xref>). From the point of view of a researcher, the true state of the experiment is observed because it is under control of the experiment, for example, using a computer that presents the target and mouse position. The computational goal for the researcher is to estimate parameters <italic>θ</italic> that describe the perceptual, cognitive, and motor processes of the subject for each model, given observed trajectories <inline-formula><mml:math id="inf32"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). In the case of continuous psychophysics, these parameters include the perceptual uncertainty about the target <italic>σ</italic> and about one’s own cursor position <inline-formula><mml:math id="inf33"><mml:msub><mml:mi>σ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></inline-formula>, the control cost <italic>c</italic>, and the action variability <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, as well as parameters that describe how the subject’s internal model differs from the true generative model of the experiment employed by the researcher. These properties are not directly observed and can only be inferred from the subject’s behavior. Importantly, in the framework presented here, we subsequently need to carry out model comparison across the considered models potentially describing the subject as we do not assume to know the model describing the subject’s internal beliefs, costs, and model a priori.</p><p>To compute the posterior distribution according to Bayes’ theorem <inline-formula><mml:math id="inf35"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mpadded><mml:mo lspace="2.5pt" rspace="4.2pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, we need the likelihood <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which we can derive using the probabilistic graphical model from the researcher’s point of view (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). The graph’s structure is based on that describing the subject’s point of view. However, because different variables are observed, the decoupling of the perceptual and control processes no longer holds and we need to marginalize out the latent internal observations of the subject: <inline-formula><mml:math id="inf37"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The section ‘Likelihood function’ describes how to do this efficiently. We compute posterior distributions using probabilistic programming and Bayesian inference (see section ‘Bayesian inference’). In the following, we show empirically through simulations involving synthetic data that the models’ parameters can indeed be recovered with Bayesian inverse optimal control.</p></sec><sec id="s2-3"><title>Simulation results</title><p>To establish that the inference algorithm can recover the model parameters from ground truth data, we generated 200 sets of parameters from uniform distributions resulting in realistic tracking data (see Appendix 3, ‘Parameter recovery’ for details). For each set of parameters, we simulated datasets consisting of 10, 25, and 50 trials (corresponding to 2, 5, and 10 min) from the subjective actor model. <xref ref-type="fig" rid="fig3">Figure 3A</xref> shows one example posterior distribution. Average posterior means and credible intervals relative to the true value of the parameter are shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. With only 2 min of tracking, the 95% posterior credible intervals of the perceptual uncertainty <italic>σ</italic> are [0.8, 1.3] relative to the true value on average. This means that the tracking data of an experiment lasting 2 min is sufficient to obtain posterior distributions over model parameters for which 95% of probability is within a range of 20% underestimation and 30% overestimation of the true values. As a comparison, we consider the simulations for estimating the width of a psychometric function in classical psychophysical tasks conducted by <xref ref-type="bibr" rid="bib50">Schütt et al., 2015</xref>. With 800 forced-choice trials (corresponding to roughly 20 min), the 95% posterior credible intervals are within [0.6, 1.6] relative to the true value on average. This suggests a temporal efficiency gain for continuous psychophysics of at least a factor of 10. These simulation results are in accordance with the empirical results of <xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>, who had shown that the tracking task yields stable but biased estimates of perceptual uncertainty in under 2 min of data collection.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Inference on simulated data.</title><p>(<bold>A</bold>) Pairwise joint posterior distributions (0.5, 0.9, and 0.99 highest density intervals) inferred from simulated data from the subjective actor with parameters representative of real tracking data (<inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf39"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>6.0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>3.0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf43"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>). The pink dots mark the true value used to simulate the data, while the black dots mark the posterior mode. (<bold>B</bold>) Average posterior means and average 95% credible intervals relative to the true value for different numbers of trials (200 repetitions each). (<bold>C</bold>) Model recovery analysis. Inferring perceptual uncertainty (<inline-formula><mml:math id="inf44"><mml:mrow><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>/</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:math></inline-formula>, posterior mean relative to the true value) with each of the four models from data simulated from the bounded actor model and subjective actor model, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Model comparison for simulations.</title><p>Model comparison using widely applicable information criterion (WAIC) between different models fit to data simulated from the bounded actor or subjective actor model. Error bars indicate 95% CIs across 20 simulated datasets.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig3-figsupp1-v1.tif"/></fig></fig-group><p>Behavior in a task with an interplay of perception and action such as a tracking task contains additional sources of variability and bias beyond sensory influences: repeated actions with the same goal are variable and the cost of actions may influence behavior. We model these factors as action variability <inline-formula><mml:math id="inf45"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> and control cost <italic>c</italic>, respectively, in the bounded actor model. A model without these factors needs to attribute all the experimentally measured behavioral biases and variability to perceptual factors, even when they are potentially caused by additional cognitive and motor processes. We substantiate this theoretical argument via simulations. We simulated 20 datasets with different values for <italic>c</italic> and <inline-formula><mml:math id="inf46"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> sampled from uniform ranges from the bounded actor model and the subjective actor model. Then, we fit each of the four different models presented in <xref ref-type="fig" rid="fig2">Figure 2</xref> to the tracking data and computed posterior mean perceptual uncertainties. The results are shown in <xref ref-type="fig" rid="fig3">Figure 3C</xref>. The posterior means of <italic>σ</italic> from the bounded actor and subjective actor scatter around the true value, with the model used to simulate the data being the most accurate for estimating <italic>σ</italic>. The other two models (KF and optimal actor), which do not contain intrinsic behavioral costs, both overestimate <italic>σ</italic>. This overestimation is worse when the model does also not account for action variability (KF). Furthermore, Bayesian model comparison confirms that the model used to simulate the data is also the model with the highest predictive accuracy in all cases (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></sec><sec id="s2-4"><title>Continuous psychophysics</title><p>We now show that the ability of the optimal control models to account for control costs and action variability results in more accurate estimates of perceptual uncertainty in a target-tracking task that are in closer agreement to the values obtained through an equivalent two-interval forced-choice (2IFC) task. We reanalyze data from three subjects in two previously published experiments (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>, Appendix 4, ‘Continuous psychophysics’ for details): a position discrimination and a position-tracking task. Both experiments employed the same visual stimuli: Gaussian blobs with six different widths within white noise backgrounds were used to manipulate the stimulus contrast (see <xref ref-type="fig" rid="fig4">Figure 4A</xref>). In the 2IFC discrimination task, the psychophysical measurements of perceptual uncertainty increased with decreasing contrast (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, green lines). In the tracking experiment, the same visual stimuli moved on a Gaussian random walk with a fixed standard deviation and subjects tracked the target with a small red mouse cursor.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Continuous psychophysics.</title><p>(<bold>A</bold>) Perceptual uncertainty (<italic>σ</italic>) parameter estimates (posterior means) for the two-interval forced-choice (2IFC) task and the tracking task (Kalman filter [KF] and linear quadratic Gaussian [LQG] models) in the six blob width conditions (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>). The shaded area represents 95% posterior credible intervals. (<bold>B</bold>) Posterior distributions for action cost (<inline-formula><mml:math id="inf47"><mml:mi>c</mml:mi></mml:math></inline-formula>) and action variability (<inline-formula><mml:math id="inf48"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>). (<bold>C</bold>) Posterior distributions for subjective stimulus dynamics parameters (position: <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>, velocity: <inline-formula><mml:math id="inf50"><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:math></inline-formula>). The true values of the target’s random walk are marked by a green point. (<bold>D</bold>) Cross-correlograms (CCGs) of the empirical data and both models for all three subjects. (<bold>E</bold>) Model comparison. The difference in widely applicable information criterion (WAIC) w.r.t. the best model is shown with error bars representing WAIC standard error. Models without control cost (KF and optimal) fare worst, while the subjective model has the highest predictive accuracy.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig4-v1.tif"/></fig><p>We fit all four models presented in <xref ref-type="fig" rid="fig2">Figure 2</xref> to the data of the tracking experiment. To a first approximation, it is reasonable to assume that action variability, perceptual uncertainty about the mouse position, and control costs are independent of the target blob width, so that these parameters are shared across the different contrast conditions. The perceptual uncertainty <italic>σ</italic> should be different across contrasts, so we inferred individual parameters <italic>σ</italic> per condition. We assume ideal temporal integration over individual frames, including for the reanalysis of the KF model (see Appendix 4). We focus on the KF and the subjective actor in the following.</p><p>The posterior means of estimated perceptual uncertainty in both models were highly correlated with the classical psychophysical measurements (<italic>r</italic> &gt; 0.88 for both models and all subjects). However, the parameters from the subjective actor model are smaller in magnitude than KF’s in all three subjects and all but one blob width condition (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). The reason for this is that the KF attributes all variability to perceptual uncertainty, while the other models explicitly include cognitive and motor influences (see section ‘Simulation results’). The average factor between the posterior mean perceptual uncertainty in the continuous task and the 2IFC task in the five higher contrast conditions is 1.20 for the subjective actor, while it is 1.73 for the KF. Only in the lowest contrast condition, it increases to 2.20 and 2.93, respectively. Thus, accounting for action variability and control effort in our model leads to estimates of perceptual uncertainty closer to those obtained with the classical 2IFC psychophysics task. Note that a deviation between the two psychophysical tasks should not be surprising based on previous research comparing the thresholds obtained with different traditional paradigms, as we further discuss below.</p><p>Importantly, in addition to the perceptual uncertainty parameter, we also obtain posterior distributions over the other model parameters (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). The three subjects differ in how variable their actions are (<inline-formula><mml:math id="inf51"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>) and how much they subjectively penalize control effort (<italic>c</italic>). Additionally, the subjective actor model infers subjects’ implicit assumptions about how the target blob moved. The model estimates that two of the three subjects assume a velocity component <inline-formula><mml:math id="inf52"><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:math></inline-formula> to the target’s dynamics, although the target’s true motion according to the experimenter’s generative model does not contain such a motion component, while in the third participant this estimated velocity component is close to zero. Similarly, the model also infers the subjectively perceived randomness of the random walk, that is, the standard deviation <inline-formula><mml:math id="inf53"><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), for each subject, which can be smaller or larger than the true standard deviation used in generating the stimulus.</p><p>As an important test, previous research has proposed comparing the autocorrelation structure of the tracking data with that of the model’s prediction (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Huk et al., 2018</xref>). We simulated data from both the KF and the subjective actor (20 trials, using the posterior mean parameter estimates) and compared it to the empirical data. To this end, we computed cross-correlograms (CCGs, i.e., the cross-correlation between the velocities of the target and the response, see section ‘Cross-correlograms’), for each trial of the real data and simulated data from both models (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Indeed, the subjective actor captures more of the autocorrelation structure of the tracking data, quantified by the correlation between the CCGs of the model and those of the data, which was 0.61 for the KF and 0.86 for the subjective actor.</p><p>To quantitatively compare the models, we employ Bayesian model comparison using the WAIC (<xref ref-type="bibr" rid="bib61">Watanabe and Opper, 2010</xref>, see section ‘Model comparison’). WAIC is computed from posterior samples and estimates the out-of-sample predictive accuracy of a model, thereby taking into account that models with more parameters are more expressive. Overwhelming evidence for the subjective actor model is provided by Akaike weights larger than 0.98 in all three subjects, with the weight for the KF model being equal to 0 within floating point precision. This means that the behavioral data was overwhelmingly more likely under the subjective actor than the KF model, even after taking the wider expressivity of the model into account. Such strong evidence in favor of one of the models is the consequence of the large number of data samples obtained in continuous psychophysics paradigms.</p></sec><sec id="s2-5"><title>Application to other datasets</title><p>We furthermore applied all four models to data from an additional experiment in which subjects tracked a target with their finger using a motion tracking device. Experiment 2 in the study by <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref> involved five conditions with different standard deviations for the target’s random walk. These five conditions were presented in separate blocks (see Appendix 4, ‘Motion tracking’). Comparisons of CCGs for one subject are shown in <xref ref-type="fig" rid="fig5">Figure 5A</xref> (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for all subjects). Qualitatively, the subjective actor captures the cross-correlation structure of the data better than the other models. To quantitatively evaluate the model fits, we again used WAIC (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). In two of the three subjects, the subjective actor performs best, while in one subject the bounded actor with accurate stimulus model accounts better for the data. We also performed a cross-validation analysis by fitting the models to four of the conditions and evaluating it in the remaining condition. Our reasoning was that the quality of different models in capturing participants’ behavior can be quantified by measuring the likelihood of parameters across conditions, that is, by cross-validation, and in the consistency of estimated parameters, that is, their respective variance. The cross-validation analysis provides additional support for the subjective model since it gives more consistent estimates of perceptual uncertainty and has higher log likelihood than the other models (<xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>). Again, we can also inspect and interpret the other model parameters such as control costs, action variability, and subjective belief about target dynamics (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). Similarly, when applied to another experiment, in which one human participant, two monkeys, and a marmoset tracked optic flow fields with their gaze (<xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>), model selection favored the subjective actor (<xref ref-type="fig" rid="app5fig2">Appendix 5—figure 2</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Model comparison on motion-tracking data.</title><p>(<bold>A</bold>) Average cross-correlograms (CCGs) for S1 from <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref> and three models in different target random walk conditions. For the other two subjects, see <xref ref-type="fig" rid="fig3">Figure 3</xref>. (<bold>B</bold>) Difference in widely applicable information criterion (WAIC) w.r.t. best model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Cross-correlograms (CCGs) for all subjects.</title><p>(<bold>A</bold>) CCGs as in <xref ref-type="fig" rid="fig5">Figure 5</xref> for all three subjects separately based on the data in experiment 2 from <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Posterior distributions of model parameters of the subjective model in experiment 2 (<xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>).</title><p>(<bold>A</bold>) Posterior distributions for action cost (<italic>c</italic>) and action variability (<inline-formula><mml:math id="inf54"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>). (<bold>B</bold>) Posterior distributions for subjective stimulus dynamics parameters (position: <inline-formula><mml:math id="inf55"><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>, velocity: <inline-formula><mml:math id="inf56"><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:math></inline-formula>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-fig5-figsupp2-v1.tif"/></fig></fig-group></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We introduce an analysis method for continuous psychophysics experiments (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>; <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>; <xref ref-type="bibr" rid="bib29">Huk et al., 2018</xref>) that allows estimating subjects’ perceptual uncertainty, the quantity of interest in the analysis of traditional psychophysics experiments with SDT. We validated the method on synthetic data and demonstrated its feasibility for actions involving human and nonhuman primate participants’ tracking with a computer mouse (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>), tracking by pointing a finger (<xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>), and tracking using gaze (<xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>).</p><p>Importantly, we applied our method to experimental data from a manual tracking task, which were collected together with equivalent stimuli in a 2IFC paradigm for the purpose of empirical validation (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>). The perceptual uncertainties inferred using inverse optimal control were in better agreement with the 2IFC measurements than those inferred using the previously proposed KF. In the lowest contrast conditions, all models we considered show a large and systematic deviation in the estimated perceptual uncertainty compared to the equivalent 2IFC task. Note that when considering synthetic data we did not see such a discrepancy. Thus, the observed bias points toward additional mechanisms such as a computational cost or computational uncertainty that are not captured by the current models at very low contrast. One reason for this could be that the assumption of constant behavioral costs across different contrast conditions might not hold at very low contrasts because subjects might simply give up tracking the target although they can still perceive its location. Another possible explanation is that the visual system is known to integrate visual signals over longer times at lower contrasts (<xref ref-type="bibr" rid="bib12">Dean and Tolhurst, 1986</xref>; <xref ref-type="bibr" rid="bib4">Bair and Movshon, 2004</xref>), which could affect not only sensitivity in a nonlinear fashion but could also lead to nonlinear control actions extending across a longer time horizon. Further research will be required to isolate the specific reasons. The analysis methods presented in this study are well suited to investigate these questions systematically because they allow modeling these assumptions explicitly and quantifying parameters describing subjects’ behavior.</p><p>Because subjects’ behavior is conceptualized as optimal control under uncertainty (<xref ref-type="bibr" rid="bib3">Åström, 1965</xref>; <xref ref-type="bibr" rid="bib33">Kaelbling et al., 1998</xref>; <xref ref-type="bibr" rid="bib2">Anderson and Moore, 2007</xref>; <xref ref-type="bibr" rid="bib28">Hoppe and Rothkopf, 2019</xref>), the optimal actor model additionally contains action variability and a cost function encapsulating the behavioral goal of tracking the target. The present analysis method probabilistically inverts this model similarly to approaches in inverse reinforcement learning (<xref ref-type="bibr" rid="bib44">Ng and Russell, 2000</xref>; <xref ref-type="bibr" rid="bib67">Ziebart et al., 2008</xref>; <xref ref-type="bibr" rid="bib47">Rothkopf and Dimitrakakis, 2011</xref>) and inverse optimal control (<xref ref-type="bibr" rid="bib8">Chen and Ziebart, 2015</xref>; <xref ref-type="bibr" rid="bib26">Herman et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">Schmitt et al., 2017</xref>). The inferred action variability can be attributed to motor variability (<xref ref-type="bibr" rid="bib15">Faisal et al., 2008</xref>) but also to other cognitive sources, including decision variability (<xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2007</xref>). We extended this model to a bounded actor model in the spirit of rational analysis (<xref ref-type="bibr" rid="bib53">Simon, 1955</xref>; <xref ref-type="bibr" rid="bib1">Anderson, 1991</xref>; <xref ref-type="bibr" rid="bib20">Gershman et al., 2015</xref>) by including subjective costs for carrying out tracking actions. These behavioral costs correspond to intrinsic, subjective effort costs, which may include biomechanical costs (<xref ref-type="bibr" rid="bib13">di Prampero, 1981</xref>), as well as cognitive effort (<xref ref-type="bibr" rid="bib52">Shenhav et al., 2017</xref>), trading off with the subject’s behavioral goal of tracking the target.</p><p>The model was furthermore extended to allow for the possibility that subjects may act upon beliefs about the dynamics of the target stimuli that differ from the true dynamics employed by the experimenter. Such a situation may arise due to perceptual biases in the observation of the target’s dynamics. Model selection using WAIC (<xref ref-type="bibr" rid="bib61">Watanabe and Opper, 2010</xref>) favored this bounded actor with subjective beliefs about stimulus dynamics in all four experiments involving human and monkey subjects with a single exception, in which the bounded actor model better accounted for the behavioral data. Thus, we found overwhelming evidence that subjects’ behavior in the continuous psychophysics paradigm was better explained by a model that includes action variability and internal costs for actions increasing with the magnitude of the response.</p><p>One possible criticism of continuous psychophysics is that it introduces additional unmeasured factors such as action variability, intrinsic costs, and subjective internal models. While classical psychophysical paradigms take great care to minimize the influence of these factors by careful experimental design, they can nevertheless still be present, for example, as serial dependencies (<xref ref-type="bibr" rid="bib23">Green, 1964</xref>; <xref ref-type="bibr" rid="bib16">Fischer and Whitney, 2014</xref>; <xref ref-type="bibr" rid="bib18">Fründ et al., 2014</xref>). Similarly, estimates of perceptual uncertainty often differ between classical psychophysical tasks when compared directly. For example, <xref ref-type="bibr" rid="bib66">Yeshurun et al., 2008</xref>, reviewed previous psychophysical studies and conducted experiments to empirically test the theoretical predictions of SDT between Yes-No and 2IFC tasks. They found a broad range of deviations between the empirically measured perceptual uncertainty and the theoretical value predicted by SDT. Similarly, there are differences between 2AFC tasks, in which two stimuli are separated spatially, and their equivalent 2IFC tasks, in which the stimuli are separated in time (<xref ref-type="bibr" rid="bib30">Jäkel and Wichmann, 2006</xref>). While the former task engages spatial attention, the latter engages memory. These factors are typically also not accounted for in SDT-based models. Thus, substantial empirical evidence suggests that factors often not modeled by SDT, such as attention, memory, intrinsic costs, beliefs of the subject differing from the true task statistics, and learning, nevertheless very often influence the behavior in psychophysical experiments. This applies to classical trial-based tasks as well as continuous tasks. Crucially, the framework we employ here allows modeling and inferring some of these additional cognitive factors responsible for some of the observed deviations.</p><p>On a conceptual level, the results of this study underscore the fact that psychophysical methods, together with their analysis methods, always imply a generative model of behavior (<xref ref-type="bibr" rid="bib24">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib55">Swets, 1986</xref>; <xref ref-type="bibr" rid="bib64">Wixted, 2020</xref>). Nevertheless, different models can be used in the analysis, that is, models that may or may not be aligned with the actual generative model of the experiment as designed by the researcher or with the internal model that the subject is implicitly using. For example, while classical SDT assumes independence between trials and an experiment may be designed in that way, the subject may assume temporal dependencies between trials. The analysis framework we use here accounts for both these possibilities. A participant may engage in an experiment with unknown subjective costs and false beliefs, as specified in the subjective actor model. Similarly, this analysis framework also allows for the researcher to consider multiple alternative models of behavior and quantify both the uncertainty over individual models’ parameters as well as uncertainty over models through Bayesian model comparison.</p><p>The limitations of the current method are mainly due to the limitations of the LQG framework. For instance, the assumption that perceptual uncertainty is constant across the whole range of the stimulus domain is adequate for position stimuli, but would not be correct for stimuli that behave according to Weber’s law (<xref ref-type="bibr" rid="bib62">Weber, 1834</xref>). This could be addressed using an extension of the LQG to signal-dependent uncertainty (<xref ref-type="bibr" rid="bib57">Todorov, 2005</xref>) to which our inverse optimal control method can be adapted, as we have recently shown (<xref ref-type="bibr" rid="bib49">Schultheis et al., 2021</xref>). Similarly, the assumption of linear dynamics can be overcome using generalizations of the LQG framework (<xref ref-type="bibr" rid="bib58">Todorov and Li, 2005</xref>) or policies parameterized with neural networks (<xref ref-type="bibr" rid="bib38">Kwon et al., 2020</xref>). Finally, assuming independent noise across time steps at the experimental sampling rate of (60 Hz) is certainly a simplifying assumption. Nevertheless, the assumption of independent noise across time steps is very common both in models of perceptual inference as well as in models of motor control, and there is to our knowledge no computationally straightforward way around it in the LQG framework.</p><p>Taken together, the current analysis framework opens up the prospect of a wider adoption of continuous psychophysics paradigms in psychology, cognitive science, and neuroscience as it alleviates the necessity of hundreds of repetitive trials with binary forced-choice responses in expert observers, recovering perceptual uncertainties closer to classical paradigms than previous analysis methods. Additionally, it extracts meaningful psychological quantities capturing behavioral variability, effort costs, and subjective perceptual beliefs and provides further evidence for the importance of modeling the behavioral goal and subjective costs in experiments seemingly only investigating perception as perception and action are inseparably intertwined.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>LQG control derivations</title><p>For the LQG control problem as defined in section ‘Computational models of psychophysical tasks,’ the <italic>separation principle</italic> between estimation and control holds (<xref ref-type="bibr" rid="bib11">Davis and Vinter, 1985</xref>). This means that the optimal solutions for the estimator <inline-formula><mml:math id="inf57"><mml:mi>K</mml:mi></mml:math></inline-formula> and controller <inline-formula><mml:math id="inf58"><mml:mi>L</mml:mi></mml:math></inline-formula> can be computed independent from one another. Note that this does not mean that actions are independent of perception because <inline-formula><mml:math id="inf59"><mml:msub><mml:mi mathvariant="bold">u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> depends on <inline-formula><mml:math id="inf60"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>.</p><p>The optimal estimator is the KF (<xref ref-type="bibr" rid="bib34">Kalman, 1960</xref>)<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where the Kalman gain <inline-formula><mml:math id="inf61"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is computed using a discrete-time Riccati equation<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>C</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>initialized with <inline-formula><mml:math id="inf62"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf63"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that our analyses were insensitive to the initialization because state uncertainty and Kalman gains converged after a few time steps, while trials were about 1000 time steps long, which led to a negligible influence of the initial conditions. The optimal controller<disp-formula id="equ7"> <label>(7)</label><mml:math id="m7"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>is the LQR <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and is also computed with a discrete-time Riccati equation<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>initialized with <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:math></inline-formula>. In principle, all matrices of the dynamical system and thus also <inline-formula><mml:math id="inf66"><mml:mi>K</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf67"><mml:mi>L</mml:mi></mml:math></inline-formula> could be time-dependent, but since this is not the case in the models considered in this work, we leave the time indices out for notational simplicity. Due to this time invariance of the dynamical system, the gain matrices <inline-formula><mml:math id="inf68"><mml:msub><mml:mi>K</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf69"><mml:msub><mml:mi>L</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> typically converge after a few time steps. This allows us to use the converged versions, which we call <inline-formula><mml:math id="inf70"><mml:mi>K</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf71"><mml:mi>L</mml:mi></mml:math></inline-formula> in our inference method.</p></sec><sec id="s4-2"><title>Cross-correlograms</title><p>As a summary statistic of the tracking data, we use CCGs as defined by <xref ref-type="bibr" rid="bib43">Mulligan et al., 2013</xref>. The CCG at time lag <inline-formula><mml:math id="inf72"><mml:mi>τ</mml:mi></mml:math></inline-formula> is the correlation between the velocities of the target <inline-formula><mml:math id="inf73"><mml:msubsup><mml:mi>v</mml:mi><mml:mi>t</mml:mi><mml:mtext>(target)</mml:mtext></mml:msubsup></mml:math></inline-formula> at time <inline-formula><mml:math id="inf74"><mml:mi>t</mml:mi></mml:math></inline-formula> and the velocity of the response <inline-formula><mml:math id="inf75"><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mtext>(response)</mml:mtext></mml:msubsup></mml:math></inline-formula> at time <inline-formula><mml:math id="inf76"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>cov</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mtext>(response)</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mtext>(response)</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf77"><mml:mrow><mml:mtext>cov</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the covariance and standard deviation across all time steps and trials. The velocities are estimated from position data via finite differences.</p></sec><sec id="s4-3"><title>Likelihood function</title><p>Due to the conditional independence assumption implied by the graphical model from the researcher’s point of view (<xref ref-type="fig" rid="fig1">Figure 1F</xref>), the next state <inline-formula><mml:math id="inf79"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> depends on the whole history of the subject’s noisy observations <inline-formula><mml:math id="inf80"><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and internal estimates <inline-formula><mml:math id="inf81"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Since, for the researcher, the subject’s observations <inline-formula><mml:math id="inf82"><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> are latent variables, the Markov property between the <inline-formula><mml:math id="inf83"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> no longer holds and each <inline-formula><mml:math id="inf84"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> depends on all previous <inline-formula><mml:math id="inf85"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf86"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. We can, however, find a more manageable representation of the dynamical system by describing how the <inline-formula><mml:math id="inf87"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf88"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> evolve jointly (<xref ref-type="bibr" rid="bib59">van den Berg et al., 2011</xref>). This allows us to write down a joint dynamical system of <inline-formula><mml:math id="inf89"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, which only depends on the previous time step:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>G</mml:mi><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>For the derivation of this joint dynamical system and the definitions of <italic>F</italic> and <italic>G</italic>, see Appendix 1, ‘Derivation.’ The derivation is extended to account for differences between the true generative model and the agent’s subjective internal model in Appendix 1, ‘Extension to subjective internal models’.</p><p>This allows us to recursively compute the likelihood function in the following way. If we know the distribution <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, we can compute the joint distribution <inline-formula><mml:math id="inf92"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using the dynamical system from (10). Since this distribution is a multivariate Gaussian, we can condition on <inline-formula><mml:math id="inf93"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and marginalize out the <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to arrive at <inline-formula><mml:math id="inf96"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For details, see Appendix 1. The computation of the likelihood function involves looping over a possibly large number of time steps. To make computing gradients w.r.t. the parameters computationally tractable, we use the Python automatic differentiation library <monospace>jax</monospace> (<xref ref-type="bibr" rid="bib17">Frostig et al., 2018</xref>). Our implementation is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/RothkopfLab/lqg">https://github.com/RothkopfLab/lqg</ext-link>; <xref ref-type="bibr" rid="bib54">Straub, 2022</xref>.</p></sec><sec id="s4-4"><title>Bayesian inference</title><p>Equipped with the likelihood function derived above, we can use Bayes’ theorem to compute the posterior distribution for the parameters of interest:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>θ</mml:mi></mml:mpadded><mml:mo lspace="2.5pt" rspace="4.2pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Since most parameters (except the internal costs <italic>c</italic>) are interpretable in degrees of visual angle, prior distributions <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be chosen in a reasonable range depending on the experimental setup. We used half-Cauchy priors with the scale parameter <italic>γ</italic> set to 50 for <italic>σ</italic>, 25 for <inline-formula><mml:math id="inf98"><mml:msub><mml:mi>σ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></inline-formula>, 0.5 for <inline-formula><mml:math id="inf99"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, and 1 for <italic>c</italic>. We verified that the prior distributions lead to reasonable tracking data using prior predictive checks with the CCGs of the tracking data.</p><p>Samples from the posterior were drawn using NUTS (<xref ref-type="bibr" rid="bib27">Hoffman and Gelman, 2014</xref>) as implemented in the probabilistic programming package <monospace>numpyro</monospace> (<xref ref-type="bibr" rid="bib46">Phan et al., 2019</xref>).</p></sec><sec id="s4-5"><title>Model comparison</title><p>We compare models using the WAIC (<xref ref-type="bibr" rid="bib61">Watanabe and Opper, 2010</xref>), which approximates the expected log pointwise predictive density. Importantly, unlike AIC it does not make parametric assumptions about the form of the posterior distribution. It can be computed using samples from the posterior distribution (see <xref ref-type="bibr" rid="bib60">Vehtari et al., 2017</xref>, for a detailed explanation):<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mtable align="\displaystyle" columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mtext>WAIC</mml:mtext><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>S</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf100"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>S</mml:mi></mml:msubsup></mml:math></inline-formula> is the variance over samples from the posterior. Since WAIC requires individual data points <inline-formula><mml:math id="inf101"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> to be independent given the parameters <italic>θ</italic>, we define the terms <inline-formula><mml:math id="inf102"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as the likelihood of a trial <inline-formula><mml:math id="inf103"><mml:mi>i</mml:mi></mml:math></inline-formula> given posterior sample <inline-formula><mml:math id="inf104"><mml:mi>s</mml:mi></mml:math></inline-formula>, which is computed as explained in section ‘Likelihood function.’ We use the implementation from the Python package <monospace>arviz</monospace> (<xref ref-type="bibr" rid="bib37">Kumar et al., 2019</xref>).</p><p>When comparing multiple models, the WAIC values can be turned into Akaike weights summing to 1<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>j</mml:mi></mml:msub></mml:mstyle><mml:mi>exp</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf105"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the difference between the current model’s and the best model’s WAIC. The Akaike weights can be interpreted as the relative likelihood of each model.</p><p>Note that the assumption of independent noise across time steps might lead to WAIC values that are larger than those obtained under a more realistic noise model involving correlations across time. However, this should not necessarily affect the ranking between models in a systematic way, that is, favoring individual models disproportionately more than others.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-76635-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no new data have been generated for this manuscript. Modelling code is uploaded at <ext-link ext-link-type="uri" xlink:href="https://github.com/RothkopfLab/lqg">https://github.com/RothkopfLab/lqg</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:e812337f02689e3af0cf2b2ef33434f1743a5a65;origin=https://github.com/RothkopfLab/lqg;visit=swh:1:snp:0d1eb0f07c918c59f927ea44b86a4e21b52a55fe;anchor=swh:1:rev:58ab4c621081d6eb9eccefd0f3f3c91032ddca38">swh:1:rev:58ab4c621081d6eb9eccefd0f3f3c91032ddca38</ext-link>).</p><p>The following previously published datasets were used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Cormack</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><data-title>Data from: Continuous psychophysics: Target-tracking to measure visual sensitivity</data-title><source>github.com</source><pub-id pub-id-type="accession" xlink:href="https://github.com/kbonnen/BonnenEtAl2015_KalmanFilterCode">BonnenEtAl2015_KalmanFilterCode</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Knöll </surname></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Opticflow tracking data</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/h5rxv/">h5rxv</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Kathryn Bonnen and Lawrence Cormack for sharing their behavioral data and for discussion of continuous psychophysics. Calculations for this research were conducted on the Lichtenberg high-performance computer of the TU Darmstadt. This research was supported by 'The Adaptive Mind,' funded by the Excellence Program of the Hessian Ministry of Higher Education, Science, Research and Art.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Is human cognition adaptive?</article-title><source>Behavioral and Brain Sciences</source><volume>14</volume><fpage>471</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1017/S0140525X00070801</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>BD</given-names></name><name><surname>Moore</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Optimal Control: Linear Quadratic Methods</source><publisher-name>Courier Corporation</publisher-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Åström</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Optimal control of markov processes with incomplete state information</article-title><source>Journal of Mathematical Analysis and Applications</source><volume>10</volume><fpage>174</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/0022-247X(65)90154-X</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bair</surname><given-names>W</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Adaptive temporal integration of motion in direction-selective neurons in macaque visual cortex</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>7305</fpage><lpage>7323</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0554-04.2004</pub-id><pub-id pub-id-type="pmid">15317857</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Not noisy, just wrong: the role of suboptimal inference in behavioral variability</article-title><source>Neuron</source><volume>74</volume><fpage>30</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.016</pub-id><pub-id pub-id-type="pmid">22500627</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnen</surname><given-names>K</given-names></name><name><surname>Burge</surname><given-names>J</given-names></name><name><surname>Yates</surname><given-names>J</given-names></name><name><surname>Pillow</surname><given-names>J</given-names></name><name><surname>Cormack</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Continuous psychophysics: target-tracking to measure visual sensitivity</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.1167/15.3.14</pub-id><pub-id pub-id-type="pmid">25795437</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnen</surname><given-names>K</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Cormack</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic mechanisms of visually guided 3d motion tracking</article-title><source>Journal of Neurophysiology</source><volume>118</volume><fpage>1515</fpage><lpage>1531</lpage><pub-id pub-id-type="doi">10.1152/jn.00831.2016</pub-id><pub-id pub-id-type="pmid">28637820</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Ziebart</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Predictive inverse optimal control for linear-quadratic-gaussian systems</article-title><conf-name>Eighteenth International Conference on Artificial Intelligence and Statistics. PMLR</conf-name><fpage>165</fpage><lpage>173</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chow</surname><given-names>HM</given-names></name><name><surname>Knöll</surname><given-names>J</given-names></name><name><surname>Madsen</surname><given-names>M</given-names></name><name><surname>Spering</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Look where you go: characterizing eye movements toward optic flow</article-title><source>Journal of Vision</source><volume>21</volume><elocation-id>19</elocation-id><pub-id pub-id-type="doi">10.1167/jov.21.3.19</pub-id><pub-id pub-id-type="pmid">33735378</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Afshar</surname><given-names>A</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A central source of movement variability</article-title><source>Neuron</source><volume>52</volume><fpage>1085</fpage><lpage>1096</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.10.034</pub-id><pub-id pub-id-type="pmid">17178410</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>MHA</given-names></name><name><surname>Vinter</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="1985">1985</year><source>Stochastic Modelling and Control</source><publisher-loc>London</publisher-loc><publisher-name>Chapman and Hall</publisher-name><pub-id pub-id-type="doi">10.1007/978-94-009-4828-0</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dean</surname><given-names>AF</given-names></name><name><surname>Tolhurst</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Factors influencing the temporal phase of response to bar and grating stimuli for simple cells in the cat striate cortex</article-title><source>Experimental Brain Research</source><volume>62</volume><fpage>143</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1007/BF00237410</pub-id><pub-id pub-id-type="pmid">3956629</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>di Prampero</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Energetics of muscular exercise</article-title><source>Reviews of Physiology, Biochemistry and Pharmacology</source><volume>89</volume><fpage>143</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1007/BFb0035266</pub-id><pub-id pub-id-type="pmid">7015457</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edison</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>On the optimal control of stochastic linear systems</article-title><source>IEEE Transactions on Automatic Control</source><volume>16</volume><fpage>776</fpage><lpage>785</lpage><pub-id pub-id-type="doi">10.1109/TAC.1971.1099840</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname><given-names>AA</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Noise in the nervous system</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>292</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nrn2258</pub-id><pub-id pub-id-type="pmid">18319728</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>J</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Serial dependence in visual perception</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>738</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1038/nn.3689</pub-id><pub-id pub-id-type="pmid">24686785</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Frostig</surname><given-names>R</given-names></name><name><surname>Johnson</surname><given-names>MJ</given-names></name><name><surname>Leary</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Compiling machine learning programs via high-level tracing</article-title><conf-name>Systems for Machine Learning</conf-name><fpage>23</fpage><lpage>24</lpage></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fründ</surname><given-names>I</given-names></name><name><surname>Wichmann</surname><given-names>FA</given-names></name><name><surname>Macke</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Quantifying the effect of intertrial dependence on perceptual decisions</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1167/14.7.9</pub-id><pub-id pub-id-type="pmid">24944238</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>WS</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Sequential ideal-observer analysis of visual discriminations</article-title><source>Psychological Review</source><volume>96</volume><fpage>267</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.96.2.267</pub-id><pub-id pub-id-type="pmid">2652171</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Horvitz</surname><given-names>EJ</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Computational rationality: A converging paradigm for intelligence in brains, minds, and machines</article-title><source>Science</source><volume>349</volume><fpage>273</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1126/science.aac6076</pub-id><pub-id pub-id-type="pmid">26185246</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gescheider</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="1997">1997</year><source>Psychophysics: The Fundamentals</source><publisher-name>Psychology Press</publisher-name></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Consistency of auditory detection judgments</article-title><source>Psychological Review</source><volume>71</volume><fpage>392</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1037/h0044520</pub-id><pub-id pub-id-type="pmid">14208857</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grillini</surname><given-names>A</given-names></name><name><surname>Hernández-García</surname><given-names>A</given-names></name><name><surname>Renken</surname><given-names>RJ</given-names></name><name><surname>Demaria</surname><given-names>G</given-names></name><name><surname>Cornelissen</surname><given-names>FW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Computational methods for continuous eye-tracking perimetry based on spatio-temporal integration and a deep recurrent neural network</article-title><source>Frontiers in Neuroscience</source><volume>15</volume><elocation-id>e540</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2021.650540</pub-id><pub-id pub-id-type="pmid">33994927</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Herman</surname><given-names>M</given-names></name><name><surname>Gindele</surname><given-names>T</given-names></name><name><surname>Wagner</surname><given-names>J</given-names></name><name><surname>Schmitt</surname><given-names>F</given-names></name><name><surname>Burgard</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Inverse reinforcement learning with simultaneous estimation of rewards and dynamics</article-title><conf-name>In Artificial Intelligence and Statistics</conf-name><fpage>102</fpage><lpage>110</lpage></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffman</surname><given-names>MD</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo</article-title><source>Journal of Machine Learning Research: JMLR</source><volume>15</volume><fpage>1593</fpage><lpage>1623</lpage><pub-id pub-id-type="doi">10.5555/2627435.2638586</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoppe</surname><given-names>D</given-names></name><name><surname>Rothkopf</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Multi-step planning of eye movements in visual search</article-title><source>Scientific Reports</source><volume>9</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41598-018-37536-0</pub-id><pub-id pub-id-type="pmid">30644423</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huk</surname><given-names>A</given-names></name><name><surname>Bonnen</surname><given-names>K</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Beyond trial-based paradigms: continuous behavior, ongoing neural activity, and natural stimuli</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>7551</fpage><lpage>7558</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1920-17.2018</pub-id><pub-id pub-id-type="pmid">30037835</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jäkel</surname><given-names>F</given-names></name><name><surname>Wichmann</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spatial four-alternative forced-choice method is the preferred psychophysical method for naïve observers</article-title><source>Journal of Vision</source><volume>6</volume><fpage>1307</fpage><lpage>1322</lpage><pub-id pub-id-type="doi">10.1167/6.11.13</pub-id><pub-id pub-id-type="pmid">17209737</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1890">1890</year><source>The Principles of Psychology</source><publisher-name>Henry Holt and Company</publisher-name><pub-id pub-id-type="doi">10.1037/10538-000</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>KE</given-names></name><name><surname>Hamilton</surname><given-names>AF</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Sources of signal-dependent noise during isometric force production</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>1533</fpage><lpage>1544</lpage><pub-id pub-id-type="doi">10.1152/jn.2002.88.3.1533</pub-id><pub-id pub-id-type="pmid">12205173</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaelbling</surname><given-names>LP</given-names></name><name><surname>Littman</surname><given-names>ML</given-names></name><name><surname>Cassandra</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Planning and acting in partially observable stochastic domains</article-title><source>Artificial Intelligence</source><volume>101</volume><fpage>99</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/S0004-3702(98)00023-X</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalman</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>A new approach to linear filtering and prediction problems</article-title><source>Journal of Basic Engineering</source><volume>82</volume><fpage>35</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1115/1.3662552</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalman</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>When is a linear control system optimal?</article-title><source>Journal of Basic Engineering</source><volume>86</volume><fpage>51</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1115/1.3653115</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knöll</surname><given-names>J</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Lawful tracking of visual motion in humans, macaques, and marmosets in a naturalistic, continuous, and untrained behavioral context</article-title><source>PNAS</source><volume>115</volume><fpage>E10486</fpage><lpage>E10494</lpage><pub-id pub-id-type="doi">10.1073/pnas.1807192115</pub-id><pub-id pub-id-type="pmid">30322919</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>R</given-names></name><name><surname>Carroll</surname><given-names>C</given-names></name><name><surname>Hartikainen</surname><given-names>A</given-names></name><name><surname>Martin</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>ArviZ a unified library for exploratory analysis of bayesian models in python</article-title><source>Journal of Open Source Software</source><volume>4</volume><elocation-id>1143</elocation-id><pub-id pub-id-type="doi">10.21105/joss.01143</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwon</surname><given-names>M</given-names></name><name><surname>Daptardar</surname><given-names>S</given-names></name><name><surname>Schrater</surname><given-names>P</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Inverse rational control with partially observable continuous nonlinear dynamics</article-title><source>Neural Information Processing Systems</source><volume>33</volume><fpage>7898</fpage><lpage>7909</lpage><pub-id pub-id-type="doi">10.48550/arXiv.2009.12576</pub-id><pub-id pub-id-type="pmid">34712038</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lynn</surname><given-names>SK</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>“Utilizing” signal detection theory</article-title><source>Psychological Science</source><volume>25</volume><fpage>1663</fpage><lpage>1673</lpage><pub-id pub-id-type="doi">10.1177/0956797614541991</pub-id><pub-id pub-id-type="pmid">25097061</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manning</surname><given-names>C</given-names></name><name><surname>Jones</surname><given-names>PR</given-names></name><name><surname>Dekker</surname><given-names>TM</given-names></name><name><surname>Pellicano</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Psychophysics with children: investigating the effects of attentional lapses on threshold estimates</article-title><source>Attention, Perception &amp; Psychophysics</source><volume>80</volume><fpage>1311</fpage><lpage>1324</lpage><pub-id pub-id-type="doi">10.3758/s13414-018-1510-2</pub-id><pub-id pub-id-type="pmid">29582387</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1982">1982</year><source>Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</source><publisher-name>W. H. Freeman</publisher-name></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mooney</surname><given-names>SWJ</given-names></name><name><surname>Hill</surname><given-names>NJ</given-names></name><name><surname>Tuzun</surname><given-names>MS</given-names></name><name><surname>Alam</surname><given-names>NM</given-names></name><name><surname>Carmel</surname><given-names>JB</given-names></name><name><surname>Prusky</surname><given-names>GT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Curveball: a tool for rapid measurement of contrast sensitivity based on smooth eye movements</article-title><source>Journal of Vision</source><volume>18</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/18.12.7</pub-id><pub-id pub-id-type="pmid">30452585</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mulligan</surname><given-names>JB</given-names></name><name><surname>Rogowitz</surname><given-names>BE</given-names></name><name><surname>Pappas</surname><given-names>TN</given-names></name><name><surname>Stevenson</surname><given-names>SB</given-names></name><name><surname>Cormack</surname><given-names>LK</given-names></name><name><surname>de Ridder</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reflexive and voluntary control of smooth eye movements</article-title><conf-name>IS&amp;T/SPIE Electronic Imaging</conf-name><conf-loc>Burlingame, California, USA</conf-loc><pub-id pub-id-type="doi">10.1117/12.2010333</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>AY</given-names></name><name><surname>Russell</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><chapter-title>Algorithms for inverse reinforcement learning</chapter-title><source>In Proc. 17th International Conf. on Machine Learning</source><publisher-name>Morgan Kaufmann</publisher-name><fpage>663</fpage><lpage>670</lpage></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petzschner</surname><given-names>FH</given-names></name><name><surname>Glasauer</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Iterative bayesian estimation as an explanation for range and regression effects: a study on human path integration</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>17220</fpage><lpage>17229</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2028-11.2011</pub-id><pub-id pub-id-type="pmid">22114288</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Phan</surname><given-names>D</given-names></name><name><surname>Pradhan</surname><given-names>N</given-names></name><name><surname>Jankowiak</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Composable Effects for Flexible and Accelerated Probabilistic Programming in Numpyro</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1912.11554</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rothkopf</surname><given-names>CA</given-names></name><name><surname>Dimitrakakis</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Preference elicitation and inverse reinforcement learning</article-title><conf-name>In Joint European conference on machine learning and knowledge discovery in databases</conf-name><conf-loc>Grenoble, France</conf-loc></element-citation></ref><ref id="bib48"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Schmitt</surname><given-names>F</given-names></name><name><surname>Bieg</surname><given-names>HJ</given-names></name><name><surname>Herman</surname><given-names>M</given-names></name><name><surname>Rothkopf</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>I see what you see: inferring sensor and policy models of human real-world motor behavior</article-title><conf-name>Proceedings of the AAAI Conference on Artificial Intelligence</conf-name><fpage>3797</fpage><lpage>3803</lpage><pub-id pub-id-type="doi">10.1609/aaai.v31i1.11049</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Schultheis</surname><given-names>M</given-names></name><name><surname>Straub</surname><given-names>D</given-names></name><name><surname>Rothkopf</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2110.11130</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schütt</surname><given-names>H</given-names></name><name><surname>Harmeling</surname><given-names>S</given-names></name><name><surname>Macke</surname><given-names>J</given-names></name><name><surname>Wichmann</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Psignifit 4: pain-free bayesian inference for psychometric functions</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>474</elocation-id><pub-id pub-id-type="doi">10.1167/15.12.474</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>R</given-names></name><name><surname>Mussa-Ivaldi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Biological Learning and Control: How the Brain Builds Representations, Predicts Events, and Makes Decisions</source><publisher-name>Mit Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/9780262016964.001.0001</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Musslick</surname><given-names>S</given-names></name><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Kool</surname><given-names>W</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Toward a rational and mechanistic account of mental effort</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>99</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031526</pub-id><pub-id pub-id-type="pmid">28375769</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>A behavioral model of rational choice</article-title><source>The Quarterly Journal of Economics</source><volume>69</volume><elocation-id>99</elocation-id><pub-id pub-id-type="doi">10.2307/1884852</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Straub</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>RothkopfLab/lqg</data-title><version designator="swh:1:rev:58ab4c621081d6eb9eccefd0f3f3c91032ddca38">swh:1:rev:58ab4c621081d6eb9eccefd0f3f3c91032ddca38</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://github.com/RothkopfLab/lqg">https://github.com/RothkopfLab/lqg</ext-link></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Indices of discrimination or diagnostic accuracy: their rocs and implied models</article-title><source>Psychological Bulletin</source><volume>99</volume><fpage>100</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.99.1.100</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Optimal feedback control as a theory of motor coordination</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>1226</fpage><lpage>1235</lpage><pub-id pub-id-type="doi">10.1038/nn963</pub-id><pub-id pub-id-type="pmid">12404008</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Stochastic optimal control and estimation methods adapted to the noise characteristics of the sensorimotor system</article-title><source>Neural Computation</source><volume>17</volume><fpage>1084</fpage><lpage>1108</lpage><pub-id pub-id-type="doi">10.1162/0899766053491887</pub-id><pub-id pub-id-type="pmid">15829101</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name><name><surname>Li</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A generalized iterative lqg method for locally-optimal feedback control of constrained nonlinear stochastic systems</article-title><conf-name>In Proceedings of the 2005, American Control Conference</conf-name></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Berg</surname><given-names>J</given-names></name><name><surname>Abbeel</surname><given-names>P</given-names></name><name><surname>Goldberg</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>LQG-mp: optimized path planning for robots with motion uncertainty and imperfect state information</article-title><source>The International Journal of Robotics Research</source><volume>30</volume><fpage>895</fpage><lpage>913</lpage><pub-id pub-id-type="doi">10.1177/0278364911406562</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Gabry</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Practical bayesian model evaluation using leave-one-out cross-validation and waic</article-title><source>Statistics and Computing</source><volume>27</volume><fpage>1413</fpage><lpage>1432</lpage><pub-id pub-id-type="doi">10.1007/s11222-016-9696-4</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>S</given-names></name><name><surname>Opper</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Asymptotic equivalence of bayes cross validation and widely applicable information criterion in singular learning theory</article-title><source>Journal of Machine Learning Research</source><volume>11</volume><elocation-id>12</elocation-id></element-citation></ref><ref id="bib62"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Weber</surname><given-names>EH</given-names></name></person-group><year iso-8601-date="1834">1834</year><source>De Pulsu, Resorptione, Auditu et Tactu: Annotationes Anatomicae et Physiologicae</source><publisher-name>CF Koehler</publisher-name></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wichmann</surname><given-names>FA</given-names></name><name><surname>Jäkel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Methods in psychophysics</article-title><source>Experimental Psychology and Cognitive Neuroscience</source><volume>5</volume><fpage>1</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1002/9781119170174</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wixted</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The forgotten history of signal detection theory</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>46</volume><fpage>201</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1037/xlm0000732</pub-id><pub-id pub-id-type="pmid">31246058</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Computational principles of movement neuroscience</article-title><source>Nature Neuroscience</source><volume>3 Suppl</volume><fpage>1212</fpage><lpage>1217</lpage><pub-id pub-id-type="doi">10.1038/81497</pub-id><pub-id pub-id-type="pmid">11127840</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name><name><surname>Maloney</surname><given-names>LT</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bias and sensitivity in two-interval forced choice procedures: tests of the difference model</article-title><source>Vision Research</source><volume>48</volume><fpage>1837</fpage><lpage>1851</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.05.008</pub-id><pub-id pub-id-type="pmid">18585750</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ziebart</surname><given-names>BD</given-names></name><name><surname>Maas</surname><given-names>A</given-names></name><name><surname>Bagnell</surname><given-names>JA</given-names></name><name><surname>Dey</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Maximum entropy inverse reinforcement learning</article-title><conf-name>In Proceedings of the 23rd national conference on Artificial intelligence</conf-name><fpage>1433</fpage><lpage>1438</lpage></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Inverse LQG likelihood</title><sec sec-type="appendix" id="s8-1"><title>Derivation</title><p>We define <inline-formula><mml:math id="inf106"><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:math></inline-formula> to be the vector containing any parameters of interest, which influence the LQG system defined above. This could be parameters of the matrices of the dynamical system (<inline-formula><mml:math id="inf107"><mml:mi>A</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf108"><mml:mi>B</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf109"><mml:mi>V</mml:mi></mml:math></inline-formula>), the observation model (<inline-formula><mml:math id="inf110"><mml:mi>C</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf111"><mml:mi>W</mml:mi></mml:math></inline-formula>), or the cost function (<inline-formula><mml:math id="inf112"><mml:mi>Q</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf113"><mml:mi>R</mml:mi></mml:math></inline-formula>). For notational simplicity, we do not explicitly indicate this dependence of the matrices on the parameters. We are interested in the posterior probability<disp-formula id="equ14"><label>(S1)</label><mml:math id="m14"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>θ</mml:mi></mml:mpadded><mml:mo lspace="2.5pt" rspace="4.2pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>We start by writing the likelihood using repeated applications of the chain rule:<disp-formula id="equ15"><label>(S2)</label><mml:math id="m15"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The current state <inline-formula><mml:math id="inf114"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> depends on the whole history of previous states <inline-formula><mml:math id="inf115"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> since the internal observations <inline-formula><mml:math id="inf116"><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and estimates <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are unobserved from the researcher’s perspective (see <xref ref-type="fig" rid="fig1">Figure 1F</xref>). The linear Gaussian assumption, however, allows us to marginalize over these variables efficiently. To do this, we start by expressing the current state <inline-formula><mml:math id="inf118"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and estimate <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> such that they only depend on the previous time step. This idea is based on LQG-MP (<xref ref-type="bibr" rid="bib59">van den Berg et al., 2011</xref>), a method for planning in LQG problems, which computes the distribution of states and estimates without any observations. We start by inserting the LQR control law (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>) into the state update (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>):<disp-formula id="equ16"><label>(S3)</label><mml:math id="m16"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Then, we rewrite the KF update equation (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>)<disp-formula id="equ17"><label>(S4)</label><mml:math id="m17"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ18"><label>(S5)</label><mml:math id="m18"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ19"><label>(S6)</label><mml:math id="m19"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ20"><label>(S7)</label><mml:math id="m20"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ21"><label>(S8)</label><mml:math id="m21"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>K</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>C</mml:mi><mml:mi>V</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>W</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Here, we have again inserted the LQR control law (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>), then the observation model (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>), then the state transition model (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>), and finally rearranged the terms. Putting these together, we can write<disp-formula id="equ22"><label>(S9)</label><mml:math id="m22"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>A</mml:mi></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi></mml:mtd><mml:mtd><mml:mi>A</mml:mi><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>K</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>V</mml:mi></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:mi>C</mml:mi><mml:mi>V</mml:mi></mml:mtd><mml:mtd><mml:mi>K</mml:mi><mml:mi>W</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ23"><label>(S10)</label><mml:math id="m23"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>This allows us to recursively compute the likelihood function (<xref ref-type="disp-formula" rid="equ15">Equation S2</xref>) in the following way. If we know the distribution <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, we can compute the joint distribution <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using the dynamical system from <xref ref-type="disp-formula" rid="equ1">Equation S10</xref> and the formulas for linear transformations of Gaussian distributions, giving us the mean and covariance matrix<disp-formula id="equ24"><label>(S11)</label><mml:math id="m24"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Since this distribution is a multivariate Gaussian, we can marginalize out <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to obtain <inline-formula><mml:math id="inf123"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and then condition on <inline-formula><mml:math id="inf124"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> to arrive at <inline-formula><mml:math id="inf125"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We do this by partitioning the mean and covariance matrix as<disp-formula id="equ25"><label>(S12)</label><mml:math id="m25"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>μ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>μ</mml:mi><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>To marginalize out <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we simply drop those rows and columns that correspond to <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, yielding<disp-formula id="equ26"><label>(S13)</label><mml:math id="m26"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>F</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>To condition on <inline-formula><mml:math id="inf128"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, we proceed by applying the equations for conditioning in a multivariate Gaussian distribution to obtain<disp-formula id="equ27"><label>(S14)</label><mml:math id="m27"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>with<disp-formula id="equ28"><label>(S15)</label><mml:math id="m28"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>and<disp-formula id="equ29"><label>(S16)</label><mml:math id="m29"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>To obtain the contribution to the likelihood at the current time step <inline-formula><mml:math id="inf129"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we take <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and marginalize over <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Again, since everything is Gaussian, we can achieve this by simply dropping those rows of the mean and rows and columns of the covariance matrix that correspond to <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. This concludes our iterative algorithm for computing the likelihood factors. Without loss of generality (since we can subtract the initial time step from the observed trajectories to let them start at zero), we initialize <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf134"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf135"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec sec-type="appendix" id="s8-2"><title>Extension to subjective internal models</title><p>If we allow the subjective internal model to differ from the true generative model of the experiment, we need to adapt the model equations accordingly. We denote matrices of the true generative model with superscript <italic>g</italic> and matrices representing the subjective internal model with superscript <inline-formula><mml:math id="inf136"><mml:mi>s</mml:mi></mml:math></inline-formula>. The state update model<disp-formula id="equ30"><label>(S17)</label><mml:math id="m30"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>V</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ31"><label>(S18)</label><mml:math id="m31"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>V</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>and the observation model<disp-formula id="equ32"><label>(S19)</label><mml:math id="m32"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>C</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>g</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>remain the same and contain only the matrices of the generative model. The KF update equation, being internal to the subject, is now influenced by several subjective components<disp-formula id="equ33"><label>(S20)</label><mml:math id="m33"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ34"><label>(S21)</label><mml:math id="m34"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ35"><label>(S22)</label><mml:math id="m35"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ36"><label>(S23)</label><mml:math id="m36"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ37"><label>(S24)</label><mml:math id="m37"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>K</mml:mi><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The joint dynamical system of <inline-formula><mml:math id="inf137"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf138"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> is then<disp-formula id="equ38"><label>(S25)</label><mml:math id="m38"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>K</mml:mi><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mi>K</mml:mi><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ39"><label>(S26)</label><mml:math id="m39"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Then, we proceed by conditioning on the observed states and marginalizing out the subject’s internal estimates at each time step as described in the previous subsection.</p></sec></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Models of the tracking task</title><p>As explained in section ‘Computational models of psychophysical tasks,’ we consider a succession of increasingly more complex models, which can be seen as generalizations of the previous ones. In this section, we provide a verbal description of each of the models. <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref> contains full definitions of all the matrices needed to define the models.</p><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Model overview.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Model</th><th align="left" valign="bottom">State space</th><th align="left" valign="bottom">Dynamical systemmatrices</th><th align="left" valign="bottom">Cost function</th><th align="left" valign="bottom">Free parameters</th></tr></thead><tbody><tr><td align="left" valign="bottom">Ideal observer</td><td align="left" valign="middle"><inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">w</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mi>σ</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle">-</td><td align="left" valign="middle"> σ</td></tr><tr><td align="left" valign="bottom">Optimal actor</td><td align="left" valign="middle"><inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>(response)</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>rw</mml:mtext></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>σ</mml:mi></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"> <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Bounded actor</td><td align="left" valign="middle"><inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as above<break/><inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as above</td><td align="left" valign="middle"><inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as above<break/><inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as above</td><td align="left" valign="middle"><inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as above,<break/><inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as above</td><td align="left" valign="middle"> <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom" rowspan="2">Subjective actor</td><td align="left" valign="middle" rowspan="2"><inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>target</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>response</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle" rowspan="2"><inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle" rowspan="2"><inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle" rowspan="2"><inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><sec sec-type="appendix" id="s9-1"><title>Ideal observer (KF)</title><p>For the KF model, the state is simply the position of the target, <inline-formula><mml:math id="inf160"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>target</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The subject’s cursor position is taken as the internal estimate of the state <inline-formula><mml:math id="inf161"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>. The likelihood of the observed data <inline-formula><mml:math id="inf162"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be computed as above (Appendix 1), but since the model does not explicitly include actions and instead treats the internal estimate as the subject’s cursor position, we need to condition on <inline-formula><mml:math id="inf163"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf164"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at every time step.</p></sec><sec sec-type="appendix" id="s9-2"><title>Optimal and bounded actor</title><p>The models based on LQG control explicitly include the subject’s cursor position as a part of the state. In the simplest case, the state is two-dimensional and contains the position of the target stimulus and the subject’s position of the response: <inline-formula><mml:math id="inf165"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="5pt"><mml:mtr><mml:mtd columnalign="center"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>target</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd columnalign="center"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>response</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. The continuous psychophysics experiments considered here used target stimuli moving according to a simple Gaussian random walk.</p><p>Accordingly, the model may assume that the target only moves because of the random walk with standard deviation <inline-formula><mml:math id="inf166"><mml:msub><mml:mi>σ</mml:mi><mml:mtext>rw</mml:mtext></mml:msub></mml:math></inline-formula> and that the response is influenced by the agent’s control input and by action variability <inline-formula><mml:math id="inf167"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>. The agent observes the target and response position separately, with independent observation noise in both dimensions (<inline-formula><mml:math id="inf168"><mml:mi>σ</mml:mi></mml:math></inline-formula> for the target and <inline-formula><mml:math id="inf169"><mml:msub><mml:mi>σ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></inline-formula> for the response). The behavioral cost of actions is penalized by the parameter <inline-formula><mml:math id="inf170"><mml:mi>c</mml:mi></mml:math></inline-formula>. For the optimal actor without internal costs, we set <inline-formula><mml:math id="inf171"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, while for the bounded actor <inline-formula><mml:math id="inf172"><mml:mi>c</mml:mi></mml:math></inline-formula> is a free parameter.</p></sec><sec sec-type="appendix" id="s9-3"><title>Subjective actor</title><p>The target’s position in the tracking task by <xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref> is on a random walk,</p><p><inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>rw</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula>(S27)</p><p>The subjective actor may assume that the target dynamics differ from this true random walk in that there is still a random walk on the target’s position, but the standard deviation can be different from the true standard deviation. In addition, the subjective actor may assume that in addition to the target position’s random walk, the target’s velocity can change over time according to its own random walk,</p><p><inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>(target)</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula>(S28)<disp-formula id="equ40"><label>(S29)</label><mml:math id="m40"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Thus, for the subjective actor, the actual matrices of the generative model remain identical to the basic model, but the agent assumes a different dynamical system, in which the target has an additional dimension representing its velocity <inline-formula><mml:math id="inf175"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="5pt"><mml:mtr><mml:mtd columnalign="center"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>target</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd columnalign="center"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>response</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. The agent still receives an observation of the positions only, with independent observation noise on both dimensions. The parameters <inline-formula><mml:math id="inf176"><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf177"><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:math></inline-formula> represent the subject’s belief about the standard deviation of the target’s position and velocity. The matrices of the subjective part of the model are changed to represent the subjective dynamics described here verbally (see <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>).</p></sec></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Simulations</title><sec sec-type="appendix" id="s10-1"><title>Parameter recovery</title><p>To evaluate the inference method, 200 sets of parameters for the subjective actor model were sampled from the following uniform distributions:<disp-formula id="equ41"><mml:math id="m41"><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="right"><mml:mi>c</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0.05</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mi>σ</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0.05</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>σ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>For each set of parameters, we simulated datasets with the following number of trials: 10, 25, and 50 trials. Each trial was 720 time steps long. For each dataset, four Markov chains with 7500 samples each were drawn from the posterior distribution, after 2500 warm-up steps.</p></sec><sec sec-type="appendix" id="s10-2"><title>Model recovery</title><p>To investigate how different models behave when fit to tracking data generated from one of the other models, we performed a model recovery analysis. To this end, 20 different values for the parameters <inline-formula><mml:math id="inf178"><mml:mi>c</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf179"><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> were sampled from uniform distributions defined above. The values of the other model parameter were fixed at <inline-formula><mml:math id="inf180"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf181"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf182"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf183"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>. For each set of parameters, we simulated datasets of 50 trials with 500 time steps per trial from the bounded actor model and the subjective model. Then, we estimated fits for each of the four different models presented in <xref ref-type="fig" rid="fig2">Figure 2</xref> to the tracking data. We ran four chains with 5000 samples each after 2000 warm-up steps.</p></sec></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>Experiments</title><p>We reanalyze data from three previous publications (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>). In this section, we describe our data analysis procedures for these datasets. For detailed information about the experiments, we refer to the original publications.</p></sec><sec sec-type="appendix" id="s12"><title>Continuous psychophysics</title><p>First, we reanalyze data from three subjects in two previously published experiments (<xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>): a position discrimination and a position tracking task. The stimuli were ‘Gaussian blobs,’ two-dimensional Gaussian functions on Gaussian pixel noise, which changed from frame to frame. The visibility of the stimuli was manipulated via the standard deviation of the Gaussian blobs, with larger standard deviations leading to lower luminance increments and thus to a weaker signal. The standard deviations were 11, 13, 17, 21, 25, and 29 arcmin.</p><p>In the discrimination experiment, position discrimination thresholds for each blob width were measured in a two-interval forced-choice (2IFC) task. We fit cumulative Gaussian psychometric functions with lapse rates in a Beta-Binomial model to the discrimination performance using <monospace>psignifit</monospace> (<xref ref-type="bibr" rid="bib50">Schütt et al., 2015</xref>). We use the posterior mean of the standard deviation of the Gaussian psychometric function as our estimate of the perceptual uncertainty in the 2IFC task.</p><p>In the tracking experiment, the same visual stimuli moved on a random walk with a standard deviation of one pixel (1.32 arcmin of visual angle) per frame at a frame rate of 60 Hz. Subjects were instructed to track the target with a small red mouse cursor. Each subject completed 20 trials for each blob width, with each trial lasting 1200 time steps (20 s). As in <xref ref-type="bibr" rid="bib6">Bonnen et al., 2015</xref>, the response time series were shifted by <inline-formula><mml:math id="inf184"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:math></inline-formula> time steps w.r.t. the target time series to account for a constant time lag. Instead, one could explicitly account for the time lag in the observation function of the model by extending the state space to include the <inline-formula><mml:math id="inf185"><mml:mi>τ</mml:mi></mml:math></inline-formula> previous time steps, but we found no appreciable differences in the model fits. We obtain posterior mean perceptual uncertainty estimates using the methods described in sections ‘Likelihood function’ and ‘Bayesian inference’. Since there are two stimulus presentations in a 2IFC task and we are interested in perceptual uncertainty for a single stimulus presentation, we divided the estimates of the perceptual uncertainty by √2 to obtain single-interval sensory uncertainties. This corresponds to the assumption that the subject judges the difference between the stimuli observed in the two intervals. Although this assumption is debated and empirical deviations in both directions were observed (<xref ref-type="bibr" rid="bib66">Yeshurun et al., 2008</xref>), as discussed in the main text, this assumption is a natural starting point when converting between 2IFC and single-interval perceptual uncertainties. Because the stimuli in the 2IFC task were shown for 15 frames and the computational models of the tracking task operate on single frames, we apply a second correction factor to the perceptual uncertainty estimates. Assuming optimal integration of the Gaussian uncertainty across frames, the 2IFC sensory uncertainty estimates were multiplied by a constant factor of √15.</p></sec><sec sec-type="appendix" id="s13"><title>Motion tracking</title><p>We reanalyzed the data from experiment 2 of <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>, in which subjects tracked a circular target on a gray background with their cursor. Instead of the computer mouse, the cursor was controlled used a Leap Motion hand tracking device (Leap Motion, San Francisco, USA). There were five different standard deviations for the target’s random walk. Each subject completed 20 trials per standard deviation in randomly interleaved blocks of 10 trials. As above, the response time series were shifted by 12 time steps w.r.t. the target time series.</p></sec><sec sec-type="appendix" id="s14"><title>Gaze tracking</title><p>We reanalyzed the data from an experiment on gaze tracking (<xref ref-type="bibr" rid="bib36">Knöll et al., 2018</xref>), in which two macaques (M1 and M2), one human participant (H), and a marmoset (C) tracked the center of an optical flow field displayed on a screen, while their eye movements were recorded. In this experiment, the temporal shift applied to the response time series was 10 time steps, which was determined from the CCGs.</p></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s15"><title>Cross-validation</title><p>For the experiment from <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>, in addition to the model fits on the data from all conditions, we performed a cross-validation evaluation for the tracking experiment with different random walk conditions. In experiment 2 from the study by <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>, there were five different standard deviation conditions for the target’s random walk, which were presented in blocks (see Appendix 4, ‘Motion tracking’). Specifically, we fit all models to the data in a leave-one-condition-out cross-validation scheme, that is, we fit the model on data from four conditions and evaluate it on the remaining condition, and repeated this procedure for each condition. As a metric for evaluation, we compute the log predictive posterior density relative to the best performing model (<inline-formula><mml:math id="inf186"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>). It was higher for the subjective model than for the other models in all but one condition of one participant (<xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1A</xref>). To check which model yields the most reliable estimates of perceptual uncertainty, we look at the posterior mean estimates of <inline-formula><mml:math id="inf187"><mml:mi>σ</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1B</xref>). The subjective model’s estimates are most consistent across cross-validation conditions, with an average standard deviation of 0.25 arcmin, compared to 0.60 for the basic LQG and 0.52 for the KF. This suggests that the model recovers the subjects’ perceptual uncertainty more reliably than the alternative models.</p></sec><sec sec-type="appendix" id="s16"><title>Application to eye-tracking data</title><p>We reanalyze data from the experiment described in Appendix 4, ‘Gaze tracking.’ Since the generative model of the target’s random walk was slightly different compared to the other experiments, the model was adapted accordingly.</p><p>The target dynamics has a velocity component that depends on the current position, such that the target tends toward the center of the screen. The matrices of the dynamical system and cost function are<disp-formula id="equ42"><label>(S30)</label><mml:math id="m42"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mi>λ</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">,</mml:mo><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">,</mml:mo><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">,</mml:mo><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">,</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ43"><label>(S31)</label><mml:math id="m43"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">,</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="center"><mml:mi>c</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Thus, the agent’s estimate is also three-dimensional, that is, the agent estimates a velocity from their observations of the position.</p><p>As for the other experiments, we fit all four models to the data and computed WAIC as a model comparison metric (<xref ref-type="fig" rid="app5fig2">Appendix 5—figure 2</xref>). Again, the behavioral data is better accounted for by the LQG models compared to the KF model. As in the other analyses of experimental data, the bounded actor models with internal costs better account for the data than the optimal actor model.</p><fig id="app5fig1" position="float"><label>Appendix 5—figure 1.</label><caption><title>Cross-validation of estimated parameters.</title><p>(<bold>A</bold>) Difference in log-posterior relative to the best model per left-out condition from the experiment by <xref ref-type="bibr" rid="bib7">Bonnen et al., 2017</xref>. Each model was fitted on the remaining four conditions as described in Appendix 5. In all but one condition of one participant, the model with a subjective component accounts best for the data. Error bars indicate 95% CIs across the 5 cross-validation runs. (<bold>B</bold>) Perceptual uncertainty (posterior mean) estimates across cross-validation conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-app5-fig1-v1.tif"/></fig><fig id="app5fig2" position="float"><label>Appendix 5—figure 2.</label><caption><title>Model comparison on eye-tracking data.</title><p>Widely applicable information criterion (WAIC) on our four models for the eye-tracking data, fit separately to the X and Y dimension.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76635-app5-fig2-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76635.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Western University</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.12.23.473976" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.23.473976"/></front-stub><body><p>This important article presents a Bayesian model framework for estimating individual perceptual uncertainty from continuous tracking data – a powerful and exciting alternative to traditional binary-choice psychophysical experiments. The model takes into account motor variability, action cost, and possible misestimation of the generative dynamics. The analyses provide compelling evidence for the framework. The article is clearly written and provides a didactic resource for students wishing to implement similar models on continuous action data.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76635.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Western University</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Western University</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.23.473976">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.12.23.473976v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Putting perception into action: Inverse optimal control for continuous psychophysics&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Jörn Diedrichsen as Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Joshua Gold as the Senior Editor.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission. Overall, all reviewers thought that the paper has the potential to become a very valuable contribution to the field. The revisions focus mainly on the clarity of the submission. The extensive original reviews are attached below and should be responded to in detail.</p><p>Essential revisions:</p><p>1) The assumption of independence of motor noise across observations (reviewer #1, comment #1) is likely problematic in terms of obtaining valid WAIC values – and this problem should be addressed.</p><p>2) The technical exposition in the introduction is sometimes confusing and the clarity of the explanations should be improved. The specific comments provide a detailed list of constructive suggestions here.</p><p>3) The discussion of the previous literature is not always as balanced and would be ideal (see reviewer #2)</p><p>4) For a tools and resource paper, I would hold that the associated code and documentation should be visible to the reviewers at the point of submission, so the quality of the online resource can be reviewed together with the paper. So I would ask you to provide a working link with the revision of the paper.</p><p><italic>Reviewer #1: All comments in public review.</italic></p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>Specific Remarks:</p><p>– There are passages that read like poorly grounded indictments of well-established literature. Supplementary Section A, which functions as support for claims in the main text and the figure 3 caption, references a study by Yeshurun et al., (2008). The authors of the present paper write that Yeshurun et al., 'investigated the validity of the theoretical result (Green and Swets, 1966), that the forced-choice sensitivity d'FC differs from the sensitivity obtained through an equivalent Yes-No task d'YN by a factor of √2, i.e. d'FC = √2d'YN. Apart from running a serious of experiments targeted at evaluating the validity of this theoretical result, the authors reported the actual values of this factor based on extensive literature review involving numerous studies investigating perceptual sensitivities across sensory modalities. Indeed, the literature review collected a broad range of deviations from the theoretical value.'</p><p>The authors then go on to specifically reference two of the papers cited by Yeshurun (2008). One of these papers (Jesteadt and Bilger, 1974) reported that d-prime estimated with a forced-choice task was better by a factor of 2.1 than performance in an equivalent yes-no task. The other (Markowitz and Swets, 1967) reported d-prime estimated with a forced-choice task was better by only 1.15. These two studies deviated from the predicted 1.4 improvement by factors of 1.5x and 0.8x, respectively.</p><p>The logic of the passage is problematic, and the passage seems only tenuously connected to the aims of the paper. In my view, I think the supplementary passage and the connected threads in the main text are harmful to the paper's messaging and should be removed. Here is why: The theoretical result relating sensitivity in forced-choice and yes-no tasks as reported by Green and Swets (1966) is easy to derive in a few lines and is most certainly valid, presuming that certain assumptions hold. The authors can of course fairly question whether these assumptions hold in certain experiments (as did Yeshurun et al., 2008), but experiments do not, and could not, evaluate the 'validity of this theoretical result'. The theoretical result stands on its own. The authors' writing seems to conflate a lack of empirical variability (e.g. due to measurement error, assumptions not holding) with a lack of theoretical validity. I thought, initially, that this could perhaps be explained away by inattentive writing.</p><p>But the authors' then use the range of deviations aforementioned deviations-the 1.5x deviation reported by Jesteadt and Bliger was on auditory frequency and intensity discrimination; the 0.8x deviation reported by Markowitz and Swets, was on sound detection-to suggest that the observed 1.36x deviations between tracking- and forced-choice-based estimates (from Model 4 fits) are within an established range of deviations in the literature. The relevance of these numbers to the present work is dubious at best. Consider, for example, if some other pair of studies on gustatory sodium discrimination or detection had reported deviations ranging from 0.25x to 8x the theoretically predicted values. Would that somehow be relevant to the interpretation of the current work? I am not sure why the authors thought this a valuable addition to the paper. They seem to be using these studies to suggest that because other studies have deviated from predictions (whatever the causes) that discrepancies in the present study should be thought of as small. It all feels forced. After writing out these notes, I was concerned that perhaps I had been making too much of it. But the next issue has a similar flavor.</p><p>– The manuscript appears both to misleadingly describe findings in Bonnen et al., (2015), and to self-contradict its own assertions regarding those findings. The authors several times write that Bonnen et al.,'s tracking-based estimates of position uncertainty (i.e. position discrimination thresholds) are an order of magnitude (i.e. ~10x) higher than corresponding forced-choice-based estimates. The authors contrast this discrepancy with their own results, saying that they 'infer values that differ by a factor of 1.36 on average'. It is true that the raw estimates of Bonnen et al., reported tracking-based estimates that were ~10x larger. But that was before Bonnen et al., took several obvious factors into account (e.g. the benefit of integrating across 15 frames of each stimulus presentation, the predicted improvement in sensitivity in 'two-look' forced choice tasks). After taking these factors into account (as it is appropriate to do), the ~10x difference between the tracking- and forced-choice-based was reduced to a ~2x difference. In the supplement, the authors acknowledge that Bonnen et al., took these factors into account, but their writing in the abstract, introduction, and discussion (references to order of magnitude differences) reads as if they are unaware. I am unclear about the reasons for this discrepancy, but it should be corrected.</p><p>Further, on page 5, left column the authors report that estimates of perceptual uncertainty of target position from the Kalman Filter model differ from the forced-choice-based estimates by approximately 2x. They write: 'The average factor between the posterior mean perceptual uncertainty in the continuous task and the 2IFC task in the 5 higher contrast conditions is 1.20 for the LQG model, while it is 1.73 for the KF. Only in the lowest contrast condition, it increases to 2.20 and 2.93 arcmin, respectively.'. This difference is in line with the conclusions of Bonnen et al., and does not square with the assertion that tracking-based estimates were off by an order of magnitude (~10x). Given that the current Kalman filter analysis essentially replicates the analysis performed by Bonnen et al., these two assertions (10x differences vs 2x differences) cannot both be correct. Again, in keeping with the first point above, all this seems like a forced attempt to convince the reader that observed deviations are small between the tracking- vs. forced-choice-based estimates of perceptual uncertainty about target position. But it seems unnecessary. Model 4 does a more accurate job of estimating perceptual uncertainty about target position than simpler models (and seems to provide a closer match to forced-choice-based estimates). Let those results stand on their own.</p><p>– For a computational paper, in which the primary contribution is to develop methods for data analysis and parameter estimation, there should be substantially more discussion of which parameters have their values trade off of one another. For example, the authors have taken the trouble visualize a posterior distribution over the parameters (Figure 3A). They should help the reader develop an intuition for why the posterior has the structure that it does. All models other than the Kalman filter model include perceptual uncertainty about target position (\σ), perceptual uncertainty about cursor position (\σ_p), and motor variability. All of these quantities affect the reliability with which discrepancies between target and cursor position can be evaluated, and should have similar effects on performance. The figure shows that these parameters trade-off with each other (strong negative correlations in the posterior distributions over the model parameters). The authors should include some discussion of these trade-offs, helping to provide the reader intuition for why these parameters trade-off in the way that they do. Similarly for the positive correlation between motor variability (\σ_m) and perceptual uncertainty about cursor position.</p><p>– Regarding their analysis of simulated data, the authors report that attempts to infer the value of the target position uncertainty (\σ) from Model 4 were accurate (Figure 3C). It would be helpful for the authors to describe in more detail the parameters of the simulation. Specifically, in would be useful to explain and provide intuition for how, if the observer had a mistaken belief regarding the drift dynamics, it is possible to accurately infer the value of perceptual uncertainty about target position. A naïve reader might presume that, because there is an infinite number of pairs of position uncertainty (\σ) and presumed drift variance (\σ_s) that determine the Kalman gain, that \σ could not in fact be accurately estimated if \σ_s does not equal the true drift parameter (\σ_rw). Please explain for the reader how this works.</p><p>Tone</p><p>The current paper describes shortcomings of the Bonnen et al., (2015) data analyses. Many of these shortcomings were explicitly acknowledged by Bonnen et al., It would help the tone and tenor of the manuscript if, when the current authors describe the acknowledged shortcomings, the current authors cite Bonnen et al., (2015).</p><p>Examples include:</p><p>– &quot;A model, which only considers the perceptual side of the task, will therefore tend to overestimate perceptual uncertainty because these additional factors get lumped into perceptual model parameters, as we will show in simulations.&quot;</p><p>– &quot;A model without these factors needs to attribute all the experimentally measured behavioral biases and variability to perceptual factors, even when they are potentially caused by additional cognitive and motor processes.&quot;</p><p>The current paper makes a nice contribution in demonstrating these points quantitatively. But, in places (and in keeping with the flavor of remarks above), the writing seems concerned that readers might not recognize the paper's unique contribution. I think the paper's contribution is clear. And I think that their paper will read better, and leave a better impression, if it looks for ways to portray previous work in a more generous light.</p><p>Specific Comments</p><p>– Experimentor/Participant distinction</p><p>The experimenter has access to the true target position and the true cursor position is available. The experimental participant him/herself has access only to the estimates of target and cursor positions. The article should more explicitly discuss this issue in the main text. Figure 2 and the Supplemental derivations allude to it, but it should be discussed more prominently.</p><p>– Explanation of matrix values.</p><p>The authors should explain why the B=[0 dt]' parameter takes on the particular values that it does. Is the implication that the control action is best understood as a 'rate of change' so that result matrix-multiplying the control action with B is a position? Please explain. The value of the non-zero element of B trades off perfectly with the square root (?or similar?) of the movement cost parameter 'c'. So it would be valuable for the authors to explain why they chose to set B to have the value it does.</p><p>Telegraphic mathematical development.</p><p>In the supplement, the mathematics associated with transitioning between Supplemental Equations S16-S18 needs to be expanded. Conditioning the nD Gaussian on x_t and marginalizing out x_hat_t are two separate steps, but the manner in which the passage is written encourages the reader to presume that they are a single step. Too much analytical work is foisted on the reader if he/she wants to carefully follow the derivation along. The derivation is correct (I worked it out myself), but it should be laid out more explicitly. Further, the final expression for the likelihood of the state (x_{t+1}) on time step t+1 should be provided. This likelihood is straightforwardly obtained by marginalizing out the estimate (x^{hat}_{t+1}) of the (2-vector) state, but it would be nice for the reader if the final expression was actually made explicit for the reader.</p><p>Subjective model of state dynamics</p><p>The authors should make explicit in equation form the fallacious state dynamics that are assumed by the subjective observer. The authors describe it in words, but equations will prevent any uncertainty that the description may produce. Something like:</p><p>position walk: p_{t+1} = p_t + eps; where eps ~ N(0, σ_{rw})</p><p>velocity walk: v_{t+1} = v_t + eta; where eta ~ N(0, σ_v )</p><p>x_{t+1} = p_{t+1} + sum( v_{ 0:(t+1) } ) where the sum goes from 0 to t+1</p><p>Subjective model of estimate of velocity</p><p>Also, it is not made completely clear how the subjective observer's fallacious estimate of velocity is computed, how it resides in the model, whether the state is expressed as a 2-vector [ x_t x_p ] or a 3-vector [ x_t x_p v_t ], and whether the estimate of the state is expressed as a two-vector [ xhat_t xhat_p ] or a 3-vector [ xhat_t xhat_p vhat_t ]. An expanded discussion of these issues should be included. The expressions are correct but as they stand, but the mathematical development and discussion of these points are a bit too telegraphic.</p><p>Typo in the supplementary equation.</p><p>I believe that there is a typo in equation S2 of the supplement where the Ricatti equation is laid out. The term with the inverse currently reads ( C*P*C' )^-1 whereas this term in standard expressions for the Ricatti equation should be ( C*P*C' + W*W' )^-1. This term follows the same form as the inverse term in the expression for the Kalman gain (see the line above) which reflects the total covariance ( prior + observation covariances ).</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>The paper is already in a very polished state. I have only a few comments about clarity and completeness.</p><p>– I found myself getting confused while reading the paper about what parameters were actually involved in each model (e.g. pg 3: &quot;the KF model has only one parameter: perceptual uncertainty σ&quot;. My recommendation to the authors is to move equations 1-4 out of the Methods section and into the main text. Personally I would consider this part of the results (ie. &quot;what are the models we're using&quot;?) and so I would rather see this presented pedagogically within the main paper. Keep implementation details or other technical issues in the Methods, but present the models themselves in the Results section. Just a recommendation, but that's my 2 cents!</p><p>– This leads to a related note on clarity: it's not entirely clear to me which parameters are being fit in each model. Presumably you're not fitting the C matrix in equation 2? What about B in equation 1? Come to think of it, I'm not sure where the cursor fits in, allowing for uncertainty in cursor position). (Does that become part of the state vector x_t? Please unpack this more clearly so that we can understand what these equations correspond to for each of the models discussed in the paper!</p><p>– &quot;Our implementation will be made available on github&quot; -- I want to note that this should be a requirement for acceptance! (i.e., the code should be posted before the paper is accepted).</p><p>– The name &quot;bounded actor&quot; seems like a poor one, since there aren't any bounds on the actor. (There are just costs). Figure 2 C refers to it as &quot;bounded actor with behavioral costs&quot; -- personally I would keep the &quot;with behavioral costs&quot; and drop the &quot;bounded&quot;.</p><p>– One other point that would be worth making: you could also formulate a &quot;with subjective belief&quot; version of any of the simpler models. Even in the simple KF model, you could allow for mismatch between the true dynamics and the subject's belief about the dynamics. I think it's probably ok to leave the model comparisons as is, since obviously it becomes a bit messy if we have to include &quot;optimal&quot; and &quot;subjective&quot; versions of each of the models, but you should at least mention somewhere in the paper that this can be used to improve the accuracy (in terms of matching observer behavior) for any of the models.</p><p>– Can you say anything about the discrete time assumptions of the model? i.e., how would you expect the model parameters (or the accuracy of the fit) to change if you switched to 120 Hz frame rate or 20 Hz frame rate?</p><p>– Finally, a small note on grammar/usage: the paper frequently uses &quot;… , which…&quot; in cases where &quot;that&quot; (with no comma). e.g., in the abstract: &quot;recover perceptual thresholds, which are one order of magnitude larger compared to equivalent traditional psychophysical experiments&quot;. This makes it sound like you're providing a definition of threshold, rather than describing a property of the recovered thresholds. More correct would be: &quot;We recover perceptual thresholds that are one order of magnitude larger than …&quot;. I found this issue repeatedly in the text. You could basically look for nearly every occurrence of &quot;, which&quot; and replace by &quot;that&quot;.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76635.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The assumption of independence of motor noise across observations (reviewer #1, comment #1) is likely problematic in terms of obtaining valid WAIC values – and this problem should be addressed.</p><p>2) The technical exposition in the introduction is sometimes confusing and the clarity of the explanations should be improved. The specific comments provide a detailed list of constructive suggestions here.</p><p>3) The discussion of the previous literature is not always as balanced and would be ideal (see reviewer #2)</p><p>4) For a tools and resource paper, I would hold that the associated code and documentation should be visible to the reviewers at the point of submission, so the quality of the online resource can be reviewed together with the paper. So I would ask you to provide a working link with the revision of the paper.</p></disp-quote><p>Yes, thank you for summarizing the main points by the reviewers. We address all of these points in the responses to individual reviewers in the following. The link to the code associated with our manuscript is https://github.com/RothkopfLab/lqg and has been added in the manuscript.</p><disp-quote content-type="editor-comment"><p>Reviewer #1: All comments in public review.</p></disp-quote><p>Responses provided in response to public review.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>Specific Remarks:</p><p>– There are passages that read like poorly grounded indictments of well-established literature. Supplementary Section A, which functions as support for claims in the main text and the figure 3 caption, references a study by Yeshurun et al., (2008). The authors of the present paper write that Yeshurun et al., 'investigated the validity of the theoretical result (Green and Swets, 1966), that the forced-choice sensitivity d'FC differs from the sensitivity obtained through an equivalent Yes-No task d'YN by a factor of √2, i.e. d'FC = √2d'YN. Apart from running a serious of experiments targeted at evaluating the validity of this theoretical result, the authors reported the actual values of this factor based on extensive literature review involving numerous studies investigating perceptual sensitivities across sensory modalities. Indeed, the literature review collected a broad range of deviations from the theoretical value.'</p><p>The authors then go on to specifically reference two of the papers cited by Yeshurun (2008). One of these papers (Jesteadt and Bilger, 1974) reported that d-prime estimated with a forced-choice task was better by a factor of 2.1 than performance in an equivalent yes-no task. The other (Markowitz and Swets, 1967) reported d-prime estimated with a forced-choice task was better by only 1.15. These two studies deviated from the predicted 1.4 improvement by factors of 1.5x and 0.8x, respectively.</p><p>The logic of the passage is problematic, and the passage seems only tenuously connected to the aims of the paper. In my view, I think the supplementary passage and the connected threads in the main text are harmful to the paper's messaging and should be removed. Here is why: The theoretical result relating sensitivity in forced-choice and yes-no tasks as reported by Green and Swets (1966) is easy to derive in a few lines and is most certainly valid, presuming that certain assumptions hold. The authors can of course fairly question whether these assumptions hold in certain experiments (as did Yeshurun et al., 2008), but experiments do not, and could not, evaluate the 'validity of this theoretical result'. The theoretical result stands on its own. The authors' writing seems to conflate a lack of empirical variability (e.g. due to measurement error, assumptions not holding) with a lack of theoretical validity. I thought, initially, that this could perhaps be explained away by inattentive writing.</p><p>But the authors' then use the range of deviations aforementioned deviations-the 1.5x deviation reported by Jesteadt and Bliger was on auditory frequency and intensity discrimination; the 0.8x deviation reported by Markowitz and Swets, was on sound detection-to suggest that the observed 1.36x deviations between tracking- and forced-choice-based estimates (from Model 4 fits) are within an established range of deviations in the literature. The relevance of these numbers to the present work is dubious at best. Consider, for example, if some other pair of studies on gustatory sodium discrimination or detection had reported deviations ranging from 0.25x to 8x the theoretically predicted values. Would that somehow be relevant to the interpretation of the current work? I am not sure why the authors thought this a valuable addition to the paper. They seem to be using these studies to suggest that because other studies have deviated from predictions (whatever the causes) that discrepancies in the present study should be thought of as small. It all feels forced. After writing out these notes, I was concerned that perhaps I had been making too much of it. But the next issue has a similar flavor.</p></disp-quote><p>We were not as careful in our wording as we should have been. Of course, experiments finding empirical differences in perceptual uncertainties between psychophysical tasks deviating from the differences predicted by SDT cannot invalidate the theoretical result of a sqrt(2) factor between 2-AFC and Y-N experiments based on signal detection theory. We fully agree on that. We have therefore replaced phrases like “investigated the validity of the theoretical result” with more adequate wording such as “empirically tested the theoretical result”.</p><p>The point we were trying to make by citing Yeshurun et al., (2008) is that, irrespective of the sensory modality, it is very common to find discrepancies between the predictions of SDT across different psychophysical tasks and the empirical data across different psychophysical tasks. How large are these discrepancies? We turned to Yeshurun et al., (2008) to provide a quantitative value for these discrepancies.</p><p>This is not an “indictment” of “well-established literature” but a scientific fact. The first sentence of our abstract should leave no doubt that no “indictments” are involved here. If there are other studies showing that empirical data in different psychophysical tasks agree with the theoretical predictions, we will be happy to cite them.</p><p>Why are we trying to make this point?</p><p>Because it is not at all straightforward how to interpret these discrepancies, scientifically. One common criticism towards continuous psychophysics tracking experiments that we have encountered repeatedly is that they introduce additional uncontrolled factors and therefore yield biased estimates of sensory uncertainty. Classic psychophysics paradigms such as 2-AFC and Y-N experiments together with SDT, on the other hand, are said to provide unbiased and consistent estimates of sensory uncertainty. But, Yeshurun et al., (2008) have carefully reviewed the literature and carried out experiments to establish that, empirically, there are significant discrepancies across numerous classical tasks. Jäkel and Wichmann (2006) also report systematic discrepancies between the empirical results and the results expected by SDT across experiments. Numerous studies also have reported pervasive systematic sequential effects across classic psychophysical experiments, a fact that has attracted a lot of interest recently. Thus, in our view, there is enough empirical evidence to support the view that the analysis of behavioral data obtained through classical psychophysical experiments with SDT is useful, but that there are almost always factors in the experiments that are not perfectly captured by models based on SDT, such as attention, memory, intrinsic costs, beliefs on the side of the subject differing from the true task statistics employed by the researcher, learning, and potentially more.</p><p>This applies to trial-based tasks as well as continuous tasks. In our models, we have included some of these additional factors for the tracking task, and shown that this helps decrease the discrepancy between the sensory uncertainty inferred from the tracking task and the 2-AFC task. Therefore, it is important to us to highlight that the remaining discrepancy is not a particularity of continuous psychophysics as a new experimental paradigm, but typical when comparing different psychophysical tasks.</p><p>We agree that the concrete values in different sensory modalities derived from the studies by Jestead and Bilger (1974) and Markowitz and Swets (1967) may not be as relevant to the visual position discrimination and tracking tasks conducted by Bonnen et al., (2015). We have therefore removed references to these concrete values from the Results section (Figure 4A, where we now plot posterior CIs instead), the Discussion section, and the supplementary material. In the discussion, we instead cite Yeshurun et al., (2008) simply as evidence for the discrepancies between empirical measurements and the predictions by SDT across tasks.</p><p>As requested by the reviewer, we have removed the passage in the supplementary material and revised the discussion of this point in the Discussion section in the following way:</p><p>“One possible criticism of continuous psychophysics is that it introduces additional unmeasured factors such as action variability, intrinsic costs, and subjective internal models. While classical psychophysical paradigms take great care to minimize the influence of these factors by careful experimental design, they can nevertheless still be present, e.g. as serial dependencies (Green, 1964; Fischer and Whitney, 2014; Fründ et al., 2014). Similarly, estimates of perceptual uncertainty often differ between classical psychophysical tasks when compared directly. For example, Yeshurun et al., (2008) reviewed previous psychophysical studies and conducted experiments to empirically test the theoretical predictions of SDT between Yes-No and 2IFC tasks. They found a broad range of deviations between the empirically measured perceptual uncertainty and the theoretical value predicted by SDT. Similarly, there are differences between 2AFC tasks, in which two stimuli are separated spatially, and their equivalent 2IFC tasks, in which the stimuli are separated in time (Jäkel and Wichmann, 2006). While the former task engages spatial attention, the latter engages memory. These factors are typically also not accounted for in SDT-based models. Thus, substantial empirical evidence suggests that factors often not modeled by SDT, such as attention, memory, intrinsic costs, beliefs of the subject differing from the true task statistics, and learning nevertheless very often influence the behavior in psychophysical experiments.”</p><disp-quote content-type="editor-comment"><p>– The manuscript appears both to misleadingly describe findings in Bonnen et al., (2015), and to self-contradict its own assertions regarding those findings. The authors several times write that Bonnen et al.,'s tracking-based estimates of position uncertainty (i.e. position discrimination thresholds) are an order of magnitude (i.e. ~10x) higher than corresponding forced-choice-based estimates. The authors contrast this discrepancy with their own results, saying that they 'infer values that differ by a factor of 1.36 on average'. It is true that the raw estimates of Bonnen et al., reported tracking-based estimates that were ~10x larger. But that was before Bonnen et al., took several obvious factors into account (e.g. the benefit of integrating across 15 frames of each stimulus presentation, the predicted improvement in sensitivity in 'two-look' forced choice tasks). After taking these factors into account (as it is appropriate to do), the ~10x difference between the tracking- and forced-choice-based was reduced to a ~2x difference. In the supplement, the authors acknowledge that Bonnen et al., took these factors into account, but their writing in the abstract, introduction, and discussion (references to order of magnitude differences) reads as if they are unaware. I am unclear about the reasons for this discrepancy, but it should be corrected.</p><p>Further, on page 5, left column the authors report that estimates of perceptual uncertainty of target position from the Kalman Filter model differ from the forced-choice-based estimates by approximately 2x. They write: ‘The average factor between the posterior mean perceptual uncertainty in the continuous task and the 2IFC task in the 5 higher contrast conditions is 1.20 for the LQG model, while it is 1.73 for the KF. Only in the lowest contrast condition, it increases to 2.20 and 2.93 arcmin, respectively.’. This difference is in line with the conclusions of Bonnen et al., and does not square with the assertion that tracking-based estimates were off by an order of magnitude (~10x). Given that the current Kalman filter analysis essentially replicates the analysis performed by Bonnen et al., these two assertions (10x differences vs 2x differences) cannot both be correct. Again, in keeping with the first point above, all this seems like a forced attempt to convince the reader that observed deviations are small between the tracking- vs. forced-choice-based estimates of perceptual uncertainty about target position. But it seems unnecessary. Model 4 does a more accurate job of estimating perceptual uncertainty about target position than simpler models (and seems to provide a closer match to forced-choice-based estimates). Let those results stand on their own.</p></disp-quote><p>Again, thank you for pointing out that this could potentially be misunderstood by a reader. But, we would like the reviewer to be as generous with us as with the authors of the Bonnen et al., study. We were referring to the fact that in the Bonnen et al., (2015) paper in Figure 10 the factor between forced choice and tracking is approximately one order of magnitude. It is worth pointing out that Bonnen et al., (2015) discuss that this factor can be reduced by accounting for temporal integration.</p><p>We understand that the way we have referred to these values could potentially be read in a misleading way. We agree that our results can stand on their own simply due to the fact that the estimates are closer to forced-choice based estimates. Therefore, in the revised manuscript all references to &quot;an order of magnitude&quot; are removed and instead we simply state the values as they result from our reanalysis of the data from Bonnen et al., (2015).</p><p>We have now written in the abstract,</p><p>“However, what has precluded wide adoption of this approach is that current analysis methods do not account for the additional variability introduced by the motor component of the task and therefore recover perceptual thresholds, which are larger compared to equivalent traditional psychophysical experiments.”</p><p>and rewritten the parts that mention “orders of magnitude” in the introduction and discussion as well.</p><disp-quote content-type="editor-comment"><p>– For a computational paper, in which the primary contribution is to develop methods for data analysis and parameter estimation, there should be substantially more discussion of which parameters have their values trade off of one another. For example, the authors have taken the trouble visualize a posterior distribution over the parameters (Figure 3A). They should help the reader develop an intuition for why the posterior has the structure that it does. All models other than the Kalman filter model include perceptual uncertainty about target position (\σ), perceptual uncertainty about cursor position (\σ_p), and motor variability. All of these quantities affect the reliability with which discrepancies between target and cursor position can be evaluated, and should have similar effects on performance. The figure shows that these parameters trade-off with each other (strong negative correlations in the posterior distributions over the model parameters). The authors should include some discussion of these trade-offs, helping to provide the reader intuition for why these parameters trade-off in the way that they do. Similarly for the positive correlation between motor variability (\σ_m) and perceptual uncertainty about cursor position.</p></disp-quote><p>Sorry, but we first need to clarify a conceptual point about Bayesian inference. While there are some correlations in the two-dimensional marginals of the posterior distributions, these cannot be interpreted as perfect linear trade-offs. Instead, there are non-linear relationships between multiple variables in the posterior distributions and one should always be cautious when interpreting posterior distributions using only two-dimensional marginals. The mode of the full non-Gaussian joint posterior is also not in general equal to the mode of the marginal distributions.</p><p>For example, there is a positive correlation between motor variability (parameter σ_m) and behavioral costs (parameter c) in the two-dimensional marginal posterior distribution shown in Figure 3A. The posterior distribution infers that these parameters lie in a certain range: e.g., most of the posterior mass for σ_m is between 0.48 and 0.52. Within that range, there is some remaining uncertainty about which exact values the parameters take. However, this does not mean that one can arbitrarily increase perceptual uncertainty while linearly increasing the cost, because this relationship is non-linear and breaks down outside of the region with high posterior density. Similarly, the Figure2—figure supplement1 “Pareto efficiency plot” is a clear example that tradeoffs can interact highly nonlinearly. We also want to emphasize that the ability to infer a full joint posterior distribution (with correlations between variables) is a desirable property of Bayesian statistics instead of a shortcoming. With a maximum-likelihood approach, we would obtain a single best-fitting value per parameter without any insight into its associated uncertainty.</p><p>We agree that, intuitively, it may seem like “these quantities affect the reliability with which discrepancies between target and cursor position can be evaluated, and should have similar effects on performance”. But, importantly, our model-based analysis shows that their influence is not the same. This can be seen in our parameter recovery analysis, which shows that our inference method can recover the true values of these parameters used to simulate the trajectories quite well (Figure 3B). Note that our inference method considers full trajectories in the space of states, sensory measurements, actions and associated noises. Thus, the inference is based not on summary statistics such as position errors or cross-correlations, but takes into account how the different parameters interact at each time step.</p><p>All these points together emphasize the importance of including extensive simulations to check for parameter recovery (‘Simulations results’) and proper model comparison on experimental data (‘Model comparison’).</p><p>As for a more in depth discussion of the influence of the parameters, we have decided to substantially expand the final paragraph of the section “Computational models of psychophysical tasks”. This includes a qualitative discussion of the effects of most of the parameters when introducing the different models and will hopefully aid in developing better intuitions about the behavior of the overall model and the inferred properties. Here are some example sentences:</p><p>“[…] the KF has only one free parameter, the perceptual uncertainty \σ. This parameter describes the uncertainty in the sensory observation of target's true position.”</p><p>“The difference lies in the cost function, which now can additionally accommodate internal behavioral costs c (Figure 2 C) that may penalize e.g. large actions and thus result in a larger lag between the response and the target. The control cost parameter c therefore can implement a trade-off between tracking the target and expending effort (see Figure 2—figure supplement1).“</p><p>“[…], the subject could instead assume that the target follows a random walk on position with standard deviation \σ_s and an additional random walk on the velocity with standard deviation σ_v. These subjective assumptions about the target dynamics can, for example, lead the subjective actor to overshoot the target, for which they then have to correct.”</p><disp-quote content-type="editor-comment"><p>– Regarding their analysis of simulated data, the authors report that attempts to infer the value of the target position uncertainty (\σ) from Model 4 were accurate (Figure 3C). It would be helpful for the authors to describe in more detail the parameters of the simulation. Specifically, in would be useful to explain and provide intuition for how, if the observer had a mistaken belief regarding the drift dynamics, it is possible to accurately infer the value of perceptual uncertainty about target position. A naïve reader might presume that, because there is an infinite number of pairs of position uncertainty (\σ) and presumed drift variance (\σ_s) that determine the Kalman gain, that \σ could not in fact be accurately estimated if \σ_s does not equal the true drift parameter (\σ_rw). Please explain for the reader how this works.</p></disp-quote><p>Sorry, but this again refers back to the issue of properties of Bayesian inference of parameters in the present models. This is why validation of inference on synthetic data and proper model comparison are fundamentally important.</p><p>For what it is worth, our intuition for why we can disentangle the subjective random walk drift from the perceptual uncertainty goes as follows: As you note correctly, both parameters influence the Kalman gain. However, the state estimate (x^hat_t) is not only a function of the Kalman gain, but also of the concrete sensory observations (y_t) that the subject receives (see equation 5). These sensory observations depend on the perceptual uncertainty, but not on the subjective random walk drift.</p><p>Another way to get an intuition is to see that the prediction of the next position may be rendered uncertain in equivalent ways by the two factors but with new incoming sensory observations, there is less variability in the estimates when the perceptual uncertainty is low. This leads to a difference in behavior that the statistical model picks up.</p><p>Additionally, to show that both the perceptual uncertainty and the subjective standard deviation of the random walk can be inferred, we ran the same simulations as for Figure 3A and B (which were previously for the bounded actor) for the subjective actor. The results show that all of its parameters can be inferred accurately. The updated versions of Figure 3A and B now show all six parameters of the subjective actor model.</p><disp-quote content-type="editor-comment"><p>Tone</p><p>The current paper describes shortcomings of the Bonnen et al., (2015) data analyses. Many of these shortcomings were explicitly acknowledged by Bonnen et al., It would help the tone and tenor of the manuscript if, when the current authors describe the acknowledged shortcomings, the current authors cite Bonnen et al., (2015).</p><p>Examples include:</p><p>– &quot;A model, which only considers the perceptual side of the task, will therefore tend to overestimate perceptual uncertainty because these additional factors get lumped into perceptual model parameters, as we will show in simulations.&quot;</p><p>– &quot;A model without these factors needs to attribute all the experimentally measured behavioral biases and variability to perceptual factors, even when they are potentially caused by additional cognitive and motor processes.&quot;</p><p>The current paper makes a nice contribution in demonstrating these points quantitatively. But, in places (and in keeping with the flavor of remarks above), the writing seems concerned that readers might not recognize the paper's unique contribution. I think the paper's contribution is clear. And I think that their paper will read better, and leave a better impression, if it looks for ways to portray previous work in a more generous light.</p></disp-quote><p>We are sorry that we have written some passages in a way that the reviewer feels potentially could be understood as a misrepresentation of Bonnen et al., (2015). This was not our intent. The other reviewers did not comment on this. In the passages cited above, we do not refer to the data analysis by Bonnen et al., (2015), specifically. For example, the statement that “a model, which only considers the perceptual side of the task, will tend to overestimate perceptual uncertainty” seems fairly neutral to us. We are making a general statement that a model without a motor component has to attribute all the variability and biases in the tracking data to perception. This is simply a fact that is clearly shown in our simulations in Figure 3C.</p><p>However, there is still a difference between mentioning factors such as actions and motor variability and explicitly accounting for these factors in a quantitative computational model, whose implementation is provided to the research community.</p><p>Nevertheless, to acknowledge the comments of the reviewer, we have revised a paragraph in the introduction and now explicitly mention that Bonnen et al., (2015) acknowledge that motor processes play a role in the tracking task. If there are any other specific passages that paint the contributions of Bonnen et al., (2015) in an unfavorable light, we are more than happy to consider changing them.</p><p>The revised paragraph reads:</p><p>“The KF models the perceptual side of the tracking task only, i.e. how an ideal observer sequentially computes an estimate of the target’s position. Tracking, however, is not merely a perceptual task but involves motor processes as well: In addition to the problem of estimating the current position of the target, a tracking task encompasses the motor control problem of moving the finger, computer mouse, or gaze towards the target. This introduces additional sources of variability and bias. First, repeated movements towards a target exhibit variability (Faisal et al., 2008), which arises because of neural variability during execution of movements (Jones et al., 2002) or their preparation (Churchland et al., 2006). Second, a subject might trade off the instructed behavioral goal of the tracking experiment</p><p>With subjective costs, such as biomechanical energy expenditure (Di Prampero,1981) or mental effort (Shenhav et al., 2017). Third, subjects might have mistaken assumptions about the statistics of the task (Petzschner and Glasauer, 2011, Beck et al., 2012), which can lead to different behavior from a model which perfectly knows the task structure, i.e. ideal observers. Bonnen et al., (2015) acknowledge that motor processes play a role, but their computational model, the KF, does not account for these processes. A model that only considers the perceptual side of the task will, therefore, tend to overestimate perceptual uncertainty because these additional factors get lumped into perceptual model parameters, as we will show in simulations.”</p><disp-quote content-type="editor-comment"><p>Specific Comments</p><p>– Experimentor/Participant distinction</p><p>The experimenter has access to the true target position and the true cursor position is available. The experimental participant him/herself has access only to the estimates of target and cursor positions. The article should more explicitly discuss this issue in the main text. Figure 2 and the Supplemental derivations allude to it, but it should be discussed more prominently.</p></disp-quote><p>We discuss this more prominently in the revised manuscript first in the introduction:</p><p>“By modeling the particular task as it is implemented by the researcher allows deriving a normative model of behavior such as ideal observers in perceptual science (Green and Swets,1966; Geisler, 1989) or optimal feedback control models in motor control (Wolpert and Ghahramani, 2000; Todorov and Jordan, 2002). This classic task analysis at the computational level (Marr, 1982) can now be used to produce predictions of behavior, which can be compared to the actual empirically observed behavior. However, the fundamental assumption in such a setting is that the subject is carrying out the instructed task and that subject's internal model of the task is identical to the underlying generative model of the task employed by the researcher. Here, instead, we allow for the possibility that the subject is not acting on the basis of the model the researcher has implemented. Instead, we allow for the possibility that subjects' cost function does not only capture the instructed task goals but also the experienced subjective cost such as physiological and cognitive costs of performing actions. Such an approach is particularly useful in more naturalistic task setting, where subjective costs and benefits of behavior are difficult to come by a priori.</p><p>Similarly, we allow subjects' subjective internal model of stimulus dynamics to differ from the true model employed by the researcher in the specific experimental task.</p><p>In the spirit of rational analysis (Simon, 1955; Anderson, 1991; Gershman et al., 2015) we subsequently invert this model of human behavior, by developing a method for performing Bayesian inference of parameters describing the subject. Importantly, inversion of the model allows all parameters to be inferred from behavioral data and does not presuppose their value, so that, e.g., if subjects' actions were not influenced by subjective internal behavioral costs, the internal cost parameter would be estimated to be zero. This approach therefore reconciles normative and descriptive approaches to sensorimotor behavior.”</p><p>and explain the graphical models in Figure 1 in more detail. Specifically, we have expanded the beginning of the section “Bayesian inverse optimal control” in the following way to better explain the distinction between the researcher’s and the subject’s perspective:</p><p>“The normative models described in the previous section treat the problem from the subject's point of view. That is, they describe how optimal actors with different internal models and goals should behave in a continuous psychophysics task. From the subject's perspective, the true state of the experiment x_t is only indirectly observed via the uncertain sensory information y_t (see Figure 1D). From the point of view of a researcher, the true state of the experiment is observed because they control the experiment, e.g. using a computer that presents the target and mouse position. The goal is to estimate parameters \theta that describe the perceptual, cognitive, and motor processes of the subject for each model, given observed trajectories x_{1:T} (Figure 1F).“</p><p>and the Discussion section also includes</p><p>“On a conceptual level, the results of this study underscore the fact that psychophysical methods together with their analysis methods always imply a generative model of behavior (Green and Swets, 1966; Swets, 1986; Wixted, 2020).</p><p>Nevertheless, different models can be used in the analysis i.e. models that may or may not be aligned with the actual generative model of the experiment as designed by the researcher or with the internal model that the subject is implicitly using. For example, while classical SDT assumes independence between trials and an experiment may be designed in that way, the subject may assume temporal dependencies between trials.</p><p>The analysis framework we use here accounts for both these possibilities. A participant may engage in an experiment with unknown subjective costs and false beliefs, as specified in the subjective actor model. Similarly, this analysis framework also allows for the researcher to consider multiple alternative models of behavior and to quantify both the uncertainty over individual models' parameters as well as uncertainty over models through Bayesian model comparison.”</p><disp-quote content-type="editor-comment"><p>– Explanation of matrix values.</p><p>The authors should explain why the B=[0 dt]' parameter takes on the particular values that it does. Is the implication that the control action is best understood as a 'rate of change' so that result matrix-multiplying the control action with B is a position? Please explain. The value of the non-zero element of B trades off perfectly with the square root (?or similar?) of the movement cost parameter 'c'. So it would be valuable for the authors to explain why they chose to set B to have the value it does.</p></disp-quote><p>The non-zero element of B is the gain applied to the action to yield the change in position. As you explain correctly, the choice of the non-zero element of B trades off with the action cost parameter c. If we had set it to a different value, we would simply have a different scaling of the action cost parameter. This is why B is not a free parameter of the model but set to a fixed value. Setting this value to the duration of a time step is customary in modeling of dynamical systems including in motor control, because it allows interpreting the magnitude of the action in physical terms, i.e. as a velocity.</p><disp-quote content-type="editor-comment"><p>Telegraphic mathematical development.</p><p>In the supplement, the mathematics associated with transitioning between Supplemental Equations S16-S18 needs to be expanded. Conditioning the nD Gaussian on x_t and marginalizing out x_hat_t are two separate steps, but the manner in which the passage is written encourages the reader to presume that they are a single step. Too much analytical work is foisted on the reader if he/she wants to carefully follow the derivation along. The derivation is correct (I worked it out myself), but it should be laid out more explicitly. Further, the final expression for the likelihood of the state (x_{t+1}) on time step t+1 should be provided. This likelihood is straightforwardly obtained by marginalizing out the estimate (x^{hat}_{t+1}) of the (2-vector) state, but it would be nice for the reader if the final expression was actually made explicit for the reader.</p></disp-quote><p>Thanks for verifying our derivations! We have inserted some details between Equations S16 and S18 (which is now Equation S20) to hopefully make the derivations easier to follow. Specifically, we have treated the marginalization and conditioning as separate operations. We have also clarified how x^{hat}_{t+1} can be marginalized out from p(x_{t+1}, x^{hat}_{t+1} | x_{1:t}).</p><disp-quote content-type="editor-comment"><p>Subjective model of state dynamics</p><p>The authors should make explicit in equation form the fallacious state dynamics that are assumed by the subjective observer. The authors describe it in words, but equations will prevent any uncertainty that the description may produce. Something like:</p><p>position walk: p_{t+1} = p_t + eps; where eps ~ N(0, σ_{rw})</p><p>velocity walk: v_{t+1} = v_t + eta; where eta ~ N(0, σ_v )</p><p>x_{t+1} = p_{t+1} + sum( v_{ 0:(t+1) } ) where the sum goes from 0 to t+1</p></disp-quote><p>Thank you for this suggestion. We have added the univariate descriptions of the subjective position and velocity random walks to the supplementary text to clarify the subjective dynamics. We have also extended Appendix 2 Table 1 to clarify the dynamics of all models.</p><disp-quote content-type="editor-comment"><p>Subjective model of estimate of velocity</p><p>Also, it is not made completely clear how the subjective observer's fallacious estimate of velocity is computed, how it resides in the model, whether the state is expressed as a 2-vector [ x_t x_p ] or a 3-vector [ x_t x_p v_t ], and whether the estimate of the state is expressed as a two-vector [ xhat_t xhat_p ] or a 3-vector [ xhat_t xhat_p vhat_t ]. An expanded discussion of these issues should be included. The expressions are correct but as they stand, but the mathematical development and discussion of these points are a bit too telegraphic.</p></disp-quote><p>Sorry, the definition of the state space for our models could indeed have been clearer. We have extended Appendix 2 Table 1 to include definitions of the state vectors and added a statement in the main text pointing these differences out.</p><disp-quote content-type="editor-comment"><p>Typo in the supplementary equation.</p><p>I believe that there is a typo in equation S2 of the supplement where the Ricatti equation is laid out. The term with the inverse currently reads ( C*P*C' )^-1 whereas this term in standard expressions for the Ricatti equation should be ( C*P*C' + W*W' )^-1. This term follows the same form as the inverse term in the expression for the Kalman gain (see the line above) which reflects the total covariance ( prior + observation covariances ).</p></disp-quote><p>Thanks for catching this error, we fixed it. The error was only in the equation and does not affect the implementation.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>The paper is already in a very polished state. I have only a few comments about clarity and completeness.</p><p>– I found myself getting confused while reading the paper about what parameters were actually involved in each model (e.g. pg 3: &quot;the KF model has only one parameter: perceptual uncertainty σ&quot;. My recommendation to the authors is to move equations 1-4 out of the Methods section and into the main text. Personally I would consider this part of the results (ie. &quot;what are the models we're using&quot;?) and so I would rather see this presented pedagogically within the main paper. Keep implementation details or other technical issues in the Methods, but present the models themselves in the Results section. Just a recommendation, but that's my 2 cents!</p></disp-quote><p>This is a good idea! We have moved these equations into the main text. We have also expanded the verbal description of the models in the section “Computational models of psychophysical tasks” and included a reference to Appendix 2 Table 1, which clarifies what parameters are included in which model. In addition, we have changed some of the model descriptions in the section “Computational models of psychophysical tasks” to hopefully improve the comprehensibility of this section.</p><disp-quote content-type="editor-comment"><p>– This leads to a related note on clarity: it's not entirely clear to me which parameters are being fit in each model. Presumably you're not fitting the C matrix in equation 2? What about B in equation 1? Come to think of it, I'm not sure where the cursor fits in, allowing for uncertainty in cursor position). (Does that become part of the state vector x_t? Please unpack this more clearly so that we can understand what these equations correspond to for each of the models discussed in the paper!</p></disp-quote><p>We hope that our changes in the section “Computational models of psychophysical tasks” as mentioned in our response to the previous comment clarify this!</p><disp-quote content-type="editor-comment"><p>– &quot;Our implementation will be made available on github&quot; -- I want to note that this should be a requirement for acceptance! (i.e., the code should be posted before the paper is accepted).</p></disp-quote><p>Of course. The implementation is available at https://github.com/RothkopfLab/lqg and we have added the link in the manuscript.</p><disp-quote content-type="editor-comment"><p>– The name &quot;bounded actor&quot; seems like a poor one, since there aren't any bounds on the actor. (There are just costs). Figure 2 C refers to it as &quot;bounded actor with behavioral costs&quot; -- personally I would keep the &quot;with behavioral costs&quot; and drop the &quot;bounded&quot;.</p></disp-quote><p>We agree that, formally, there are no bounds as this term is used within the optimization literature. Instead, we use this term as it is customary in parts of the cognitive science literature, where, according to Herbert Simon’s definition, bounded rationality takes the limitations on cognitive capacity into account. In our model, the costs capture both biomechanical costs in the motor system and cognitive costs.</p><disp-quote content-type="editor-comment"><p>– One other point that would be worth making: you could also formulate a &quot;with subjective belief&quot; version of any of the simpler models. Even in the simple KF model, you could allow for mismatch between the true dynamics and the subject's belief about the dynamics. I think it's probably ok to leave the model comparisons as is, since obviously it becomes a bit messy if we have to include &quot;optimal&quot; and &quot;subjective&quot; versions of each of the models, but you should at least mention somewhere in the paper that this can be used to improve the accuracy (in terms of matching observer behavior) for any of the models.</p></disp-quote><p>Yes, we fully agree that we could compare any possible combination of models with or without subjective beliefs, action variability, and behavioral costs. We decided against this for two reasons.</p><p>First, the introduction of behavioral costs leads to the largest difference in the model comparison (Figure 4E), while the subjective beliefs make a smaller difference. Thus, it would be unlikely that a KF with subjective beliefs would fare better than the other models.</p><p>Second, and more importantly, the subjective actor is a generalization of the other models, so if action variability and costs did not play a large role but subjective beliefs were important, our method would infer posterior distributions over the action variability and cost parameters that are essentially zero but the posterior distributions over the subjective beliefs would be very different from the true dynamics, i.e. we would essentially recover a KF with subjective beliefs. This is not what we find, though (Figure 4B and C).</p><p>Following your suggestion, we point the following out in the section introducing the subjective actor:</p><p>“One could also formulate a version of any of the other models to include subjective beliefs. However, the subjective actor model is a generalization that includes all of these possible models. Accordingly, if the subjective beliefs played an important role but the costs or variability did not, we would infer the relevant parameters to have a value close to zero.”</p><disp-quote content-type="editor-comment"><p>– Can you say anything about the discrete time assumptions of the model? i.e., how would you expect the model parameters (or the accuracy of the fit) to change if you switched to 120 Hz frame rate or 20 Hz frame rate?</p></disp-quote><p>For the analyses in the present paper, we have chosen the sampling rate to match the frame rate at which the experiment was conducted. If one were to change the frame rate, the statistics of the target’s random walk would no longer be captured by the model in a straightforward way. For example, if we fit the model at a frame rate of 120Hz to data that was collected at 60Hz, the assumption of linear dynamics with independent Gaussian noise would no longer hold, because there would only be noise at every second time step.</p><p>Theoretically, if one were to run a tracking experiment at a different frame rate, we would certainly expect a higher uncertainty in the parameter estimates at lower frame rates because there would be less data. At higher frame rates, on the other hand, one could run into problems with the assumption of independent noise across time steps, as discussed in our response to Reviewer #1.</p><disp-quote content-type="editor-comment"><p>– Finally, a small note on grammar/usage: the paper frequently uses &quot;… , which…&quot; in cases where &quot;that&quot; (with no comma). e.g., in the abstract: &quot;recover perceptual thresholds, which are one order of magnitude larger compared to equivalent traditional psychophysical experiments&quot;. This makes it sound like you're providing a definition of threshold, rather than describing a property of the recovered thresholds. More correct would be: &quot;We recover perceptual thresholds that are one order of magnitude larger than …&quot;. I found this issue repeatedly in the text. You could basically look for nearly every occurrence of &quot;, which&quot; and replace by &quot;that&quot;.</p></disp-quote><p>Thanks for pointing this out. We have changed several of our &quot;which&quot; constructions to &quot;that&quot;.</p></body></sub-article></article>