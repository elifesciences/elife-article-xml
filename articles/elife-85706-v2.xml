<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">85706</article-id><article-id pub-id-type="doi">10.7554/eLife.85706</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Dynamics and maintenance of categorical responses in primary auditory cortex during task engagement</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-260709"><name><surname>Chillale</surname><given-names>Rupesh K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0858-9660</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-83129"><name><surname>Shamma</surname><given-names>Shihab</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-38981"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7473-1223</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-258831"><name><surname>Boubenec</surname><given-names>Yves</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0106-6947</contrib-id><email>boubenec@ens.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Laboratoire des Systèmes Perceptifs, Département d’Études Cognitives, École Normale Supérieure, PSL University,</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Laboratoire de Neurosciences Cognitives Computationnelle (INSERM U960), Département d’Études Cognitives, École Normale Supérieure</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047s2c258</institution-id><institution>Institute for System Research, Department of Electrical and Computer Engineering, University of Maryland, College Park</institution></institution-wrap><addr-line><named-content content-type="city">College Park, Maryland</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>16</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e85706</elocation-id><history><date date-type="received" iso-8601-date="2022-12-20"><day>20</day><month>12</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-11-12"><day>12</day><month>11</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-12-20"><day>20</day><month>12</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.12.19.521141"/></event></pub-history><permissions><copyright-statement>© 2023, Chillale et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Chillale et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-85706-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-85706-figures-v2.pdf"/><abstract><p>Grouping sets of sounds into relevant categories is an important cognitive ability that enables the association of stimuli with appropriate goal-directed behavioral responses. In perceptual tasks, the primary auditory cortex (A1) assumes a prominent role by concurrently encoding both sound sensory features and task-related variables. Here, we sought to explore the role of A1 in the initiation of sound categorization, shedding light on its involvement in this cognitive process. We trained ferrets to discriminate click trains of different rates in a Go/No-Go delayed categorization task and recorded neural activity during both active behavior and passive exposure to the same sounds. Purely categorical response components were extracted and analyzed separately from sensory responses to reveal their contributions to the overall population response throughout the trials. We found that categorical activity emerged during sound presentation in the population average and was present in both active behavioral and passive states. However, upon task engagement, categorical responses to the No-Go category became suppressed in the population code, leading to an asymmetrical representation of the Go stimuli relative to the No-Go sounds and pre-stimulus baseline. The population code underwent an abrupt change at stimulus offset, with sustained responses after the Go sounds during the delay period. Notably, the categorical responses observed during the stimulus period exhibited a significant correlation with those extracted from the delay epoch, suggesting an early involvement of A1 in stimulus categorization.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>auditory cortex</kwd><kwd>categorization</kwd><kwd>population code</kwd><kwd>ferret</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-17-EURE-0017</award-id><principal-award-recipient><name><surname>Chillale</surname><given-names>Rupesh K</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-10-IDEX-0001-02</award-id><principal-award-recipient><name><surname>Chillale</surname><given-names>Rupesh K</given-names></name><name><surname>Shamma</surname><given-names>Shihab</given-names></name><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-JCJC-DynaMiC</award-id><principal-award-recipient><name><surname>Boubenec</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>H2020 European Research Council</institution></institution-wrap></funding-source><award-id>ERC 787836-NEUME</award-id><principal-award-recipient><name><surname>Shamma</surname><given-names>Shihab</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-19-CE37-0016</award-id><principal-award-recipient><name><surname>Shamma</surname><given-names>Shihab</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Primary auditory cortex shows population-level correlates of sound categorization, with categorical patterns emerging during sound presentation and task engagement leading to asymmetrical representation of stimuli, indicating an early involvement in stimulus categorization.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Grouping individual stimuli into abstract, context-dependent categories and maintaining them in memory are fundamental cognitive abilities for appropriate behavioral responses and decisions. Neural correlates of such categorical perception have been found widely across cortical areas and modalities, from sensory cortices to the frontal regions (<xref ref-type="bibr" rid="bib38">Swaminathan and Freedman, 2012</xref>; <xref ref-type="bibr" rid="bib14">Folstein et al., 2013</xref>; <xref ref-type="bibr" rid="bib42">Yin et al., 2020</xref>; <xref ref-type="bibr" rid="bib32">Reinert et al., 2021</xref>). The emerging picture thus far has been that categorization is a hierarchical process implemented through a series of computations and gradual transformations across multiple cortical areas, beginning with relatively basic stimulus representations in the primary sensory areas, and ultimately concluding with categorical responses in the frontal regions (<xref ref-type="bibr" rid="bib42">Yin et al., 2020</xref>; <xref ref-type="bibr" rid="bib1">Atiani et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Tajima et al., 2017</xref>). In the auditory modality, this framework suggests that the primary auditory cortex (A1) would mainly represent stimulus acoustic features and only exhibit weak correlates of the associated behavioral categories (<xref ref-type="bibr" rid="bib21">Jaramillo et al., 2014</xref>; <xref ref-type="bibr" rid="bib37">Selezneva et al., 2017</xref>; <xref ref-type="bibr" rid="bib7">Christison-Lagay and Cohen, 2018</xref>).</p><p>Recent studies have however challenged this conception from multiple viewpoints. To begin with, the encoding of sounds in the primary auditory cortex (A1) is relatively plastic and is rapidly enhanced by task engagement (<xref ref-type="bibr" rid="bib42">Yin et al., 2020</xref>; <xref ref-type="bibr" rid="bib16">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib17">Fritz et al., 2007</xref>; <xref ref-type="bibr" rid="bib40">Xin et al., 2019</xref>). Furthermore, A1 has already been shown to extract some of the behavioral meaning of target sounds for task-relevant downstream readout (<xref ref-type="bibr" rid="bib33">Rodgers and DeWeese, 2014</xref>; <xref ref-type="bibr" rid="bib2">Bagur et al., 2018</xref>; <xref ref-type="bibr" rid="bib3">Barbosa et al., 2022</xref>). Nevertheless, the stimuli and experimental designs used in most of these experiments did not allow for disentangling category-specific neural dimensions from sensory-related activity. It thus remains uncertain how A1 population responses represent stimulus category during sound presentation in addition to strictly sensory-evoked responses, and how the representations of the task-relevant categories could be dynamically maintained after the stimulus is played. This study explores the critical questions of how and when categorical encoding emerges in primary auditory cortex, and the extent to which these categorical representations become behaviorally shaped upon task engagement.</p><p>To this end, we trained ferrets to classify click trains into Go and No-Go categories of either low or high rates during an appetitive Go/No-Go task. After training, we recorded in A1 while ferrets passively listened to or actively discriminated between the two stimulus categories. Using population-level analyses, we contrasted the representation of stimulus features (click-rates) and behavioral categories (Go/No-Go) during and after stimulus presentation. First, we discovered a signature of category which emerged early during stimulus presentation in the population average. Second, upon task engagement, the population-level representations of the No-Go category became suppressed, leading to an asymmetrical representation of the Go stimuli relative to the No-Go sounds and pre-stimulus baseline. Third, at stimulus offset, the population code changed abruptly and a large fraction of neurons maintained sustained responses after Go sounds throughout the delay epoch. The responses to Go sounds built up during the delay in anticipation of the subsequent behavioral response. Lastly, incorrect behavioral choices could be traced back to degraded sensory encoding during the stimulus period, resulting in a degraded categorical representation.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A1 neurons sustain activity after Go sounds during task engagement</title><p>Two ferrets were trained on a Go/No-Go delayed categorization task under appetitive reinforcement. Water-deprived ferrets had to classify click trains into two categories: target (Go) and non-target (No-Go) depending on the rates of click trains. Six rates were used, from 4 to 24 Hz in 4 Hz steps, and with a category boundary fixed at 14 Hz. To ensure the dissociation between categories and stimulus rates, one animal was trained with low rates as the Go sounds, while the second animal classified high rates as the Go sounds. Click trains were presented for 1.1 s and were followed by a 1-s-long delay in which the animals had to refrain from licking (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Licks during the subsequent 1-s-long response window were rewarded with water in Go trials and punished with a timeout in No-Go trials. Any licks before this response window (early licks) resulted in an aborted trial and were punished with a timeout; these were called ‘early trials’.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Sustained A1 activity during a delayed categorization task.</title><p>(<bold>a</bold>) Delayed categorization task. A trial starts with a 0.5 s of pre-stimulus silence followed by 1.1-s-duration click train stimulus. The animal must wait for a 1-s delay period before the 1-s-long response window (R.W.). Correct trials were rewarded with water while error trials and early trials (lick during delay period including sound period) were punished by a timeout. (<bold>b</bold>) Proportion of licks in response window for one of the animals (ferret P) with low rates as No-Go and higher rates as Go stimuli. Only non-early trials are considered. Shaded regions are SEM. (<bold>c</bold>) Temporal profile of first lick rate. Shaded regions are SEM. (<bold>d</bold>) Average PSTHs of all neurons from ferret P corresponding to passive (blue curve) and active (red curve) states for each of the click trains (only correct behavioral trials were used, i.e., correct rejections for No-Go and hits for Go sounds). Note that the response during the delay period is enhanced for Go stimuli (16, 20, 24 Hz). (<bold>e</bold>) Contrast (Go – No-Go firing rate) computed for neurons of both animals (n = 816 units) in passive (right) and active (left) states (z-scored with pre-stimulus baseline activity). Neurons were ranked by delay firing rate for Go active trials. (<bold>f</bold>) Modulation index (see ‘Methods’) with respect to spontaneous activity during delay (1.1–2.1 s) period for active and passive states (<italic>t</italic>-test *p&lt;0.05; n = 816 units from both ferrets).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Behavioral performance and sustained responses for all animals.</title><p>(<bold>a</bold>) Psychometric curves. (<bold>b</bold>) Average percentage of trials in recording sessions. (<bold>d</bold>) Sustained activity for ferret P. (<bold>c, d, f</bold>) Same as (<bold>a, b</bold>) and (<bold>e</bold>) for ferret T.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Modulation index for delay activity in (<bold>a</bold>) ferret P and (<bold>b</bold>) ferret T (*** p&lt;0.001, * p&lt;0.05).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Difference in average firing rate between Go and No-Go correct trials computed for neurons of both animals (n = 816 units) in active (left) and passive (right) states (z-scored with pre-stimulus baseline activity).</title><p>Neurons were ranked by delay firing rate for Go trials during passive listening.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig1-figsupp3-v2.tif"/></fig></fig-group><p>Ferrets categorized the click trains (ferret P: d' = 1.2 ± 0.5, n = 35 sessions; ferret T: d' = 1.1 ± 0.2, n = 39 sessions; <xref ref-type="fig" rid="fig1">Figure 1b</xref>) with a bias to lick for the No-Go rates close to the category boundary (12 Hz for the animal shown in <xref ref-type="fig" rid="fig1">Figure 1b</xref>). This was found in both ferrets (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a and b</xref>) regardless of the mapping between stimulus rates and category, suggesting that their decision criterion was relatively liberal and impulsive. First lick probability was higher in Go than in No-Go trials throughout the entire trial duration (<xref ref-type="fig" rid="fig1">Figure 1c</xref>), confirming the categorical response profile. We also observed a build-up of lick probability during the delay, with early responses being quite common in Go trials. Early trials and error trials (misses and false alarms) were discarded in the analysis unless otherwise specified.</p><p>We chronically recorded neural activity from a total of 816 units in A1 (ferret P: 575; ferret T: 241), while the two animals alternately listened passively to the stimuli or actively engaged in categorizing them. <xref ref-type="fig" rid="fig1">Figure 1d</xref> depicts the average click responses across all cells, showing a significant increase in firing rate relative to baseline activity in all conditions. Firing rates also steadily ramped up during the delay period in Go trials compared to No-Go’s (<xref ref-type="fig" rid="fig1">Figure 1d and e</xref>; both animals in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c and d</xref>). Importantly here we considered only hit trials in which the animals were not licking the spout until the response window. Neurons with significant changes in firing rate during the delay period did not show any modulation of activity during the passive state (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). Ranking neurons by delay activity during the passive condition did not reveal a similar pattern neither in passive or active states (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>), reflecting a pattern of response specific to the task-engaged delay period. Additionally, we found that the firing rates of these neurons increased during the delay (<xref ref-type="fig" rid="fig1">Figure 1f</xref>, paired <italic>t</italic>-test active p=0.01, passive p=0.15, n = 816 units; both animals in <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>; ferret P: active p=0.04, passive p=0.83, n = 575 units; ferret T: active p&lt;0.001, passive p=0.35, n = 241 units). Nevertheless, we noticed some heterogeneity in the delay activity, with a proportion of neurons showing large suppression during this period (top neurons in <xref ref-type="fig" rid="fig1">Figure 1e</xref>).</p></sec><sec id="s2-2"><title>A1 population activity encodes behavioral categories during stimulus in both active and passive states</title><p>Because A1 activity was heterogeneously modulated during the post-Go sound delay (<xref ref-type="fig" rid="fig1">Figure 1f</xref>), we relied on population decoding to examine the categorical representation. To do so, we trained linear decoders to discriminate Go and No-Go trials based on single-trial population activity (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). During task engagement, population responses steadily discriminated between Go and No-Go categories along the entire course of the trial (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, both animals in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Decoding accuracy diminished at stimulus offset, but subsequently increased during the delay period, ultimately peaking in the behavioral response window (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). By contrast, accuracy in the passive context decreased throughout the delay period. As a control, we performed recordings in an untrained (naive) animal using the same set of stimuli (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2a</xref>). The accuracy of passive context decoder was also similar to what is observed in the naive animal (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>). Note that decoding was performed at the single-session level (11.3 ± 4.9 neurons per session for ferret P; ± SD; n = 35 sessions and 5.2 ± 3.2 neurons per session for ferret T; n = 39 sessions), explaining the modest but above chance-level performance of the decoder.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Emergence of categorical information from primary auditory cortex during stimulus presentation.</title><p>(<bold>a</bold>) Go vs No-Go classification performance in active (red curve) and passive (blue curve) conditions (n = 35 sessions from ferret P). Gray curve indicates the performance by shuffling labels for the task-engaged condition. Error bars show 1 SD. The dashed lines separate stimulus, delay, and response window (R.W.) periods. (<bold>b</bold>) Cross-correlation matrix between decoders trained at different time points for task-engaged (left) and passive (right) data. Nonsignificant correlations are shown in gray. Significance was assessed by permutation test (200 permutations). Black frame shows the significant cross-correlation during the stimulus period. White frames show absence of correlation between decoders trained during the stimulus and the delay period. Similarly, pink frames correspond to correlation of stimulus and response window decoders. (<bold>c</bold>) Example neuron showing sensory encoding during sound period, firing rate plotted as a function of click rates (blue curve, error bars show 1 SD over trials). Prediction from the regression model are overlaid (dashed line) (CPD<sub>sensory,stimulus</sub> = 0.07 ± 0.02/CPD<sub>category,stimulus</sub> = 0.02 ± 0.01). Time course of coefficient of partial determination (CPD) is shown below. (<bold>d, e</bold>) Same as (<bold>c</bold>) for example neurons mostly tuned to categories during the stimulus (<bold>d</bold>, CPD<sub>sensory,stimulus</sub> = 0.02 ± 0.01/CPD<sub>category,stimulus</sub> = 0.05 ± 0.01) or delay (<bold>e</bold>, CPD<sub>sensory,delay</sub> = 0.00 ± 0.01/CPD<sub>category,delay</sub> = 0.02 ± 0.01) periods. (<bold>f</bold>) CPD computed by fitting linear regression models in active state (n = 395 neurons from ferret P). Shaded region represents 1 SEM over all the neurons. (<bold>g</bold>) Same as (<bold>f</bold>) for passive state. (<bold>h</bold>) CPD computed during the stimulus, delay, and response window time epochs. Significance is tested against pre-stimulus period value (two-tailed <italic>t</italic>-test ***p&lt;0.001, n = 395 neurons from ferret P). (<bold>i</bold>) Same as (<bold>h</bold>) for passive state. CPD computed from a naive animal is added in the stimulus period for comparison.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>(<bold>a,c</bold>) Decoding accuracies for passive (blue) and active (red) states for ferret P (n=35 sessions). (<bold>b,d</bold>) Decoding accuracies for passive (blue) and active (red) for ferret T (n=39 sessions).</title><p>Window periods used for computing accuracies in (<bold>c, d</bold>) are stimulus period (0-1.0 s), Delay period (1.4-2.1 s) and Response window (2.1-3.1 s).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Decoding accuracy in naive animals.</title><p>(<bold>a</bold>) Population-averaged PSTHs for passive listening and (deep blue) and in naive animals (light blue). (<bold>b</bold>) Decoding performance for naive animals. Gray curve indicates the performance by shuffling labels in task engagement. Error bars are 1 SD over 200 cross-validations. Neuron number is balanced while computing the decoders for trained and naive animal (n = 71 units).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Correlation of passive and task-engaged decoders for ferrets P and T.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Projection of each click rates onto linear decoders.</title><p>(<bold>a, c, e</bold>) Projection of trial-averaged activity of each of the category stimuli onto the passive decoders trained at different time epochs (i.e., stimulus, delay, and response window). The gray shaded region indicates the time at which the decoder was trained. Right panels show the distance matrix between successive stimulus pairs. (<bold>b, d, f</bold>) Same as (<bold>a, c, e</bold>) for active behavior.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig2-figsupp4-v2.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>Regression model supplemented with licks and reward.</title><p>(<bold>a, b</bold>) Coefficient of partial determination (CPD) obtained using other task variables for ferret P (<bold>a</bold>) and ferret T (<bold>b</bold>). (<bold>c, d</bold>) Correlation between regressors with two and four regressor values. Plotted here is the Pearson correlation between category weights when linear regression is performed with two (sensory and category) and four (sensory, category, lick, and decision) regressors for ferret P (<bold>c</bold>) and ferret T (<bold>d</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig2-figsupp5-v2.tif"/></fig></fig-group><p>We then looked further into how population code evolves during the trial. For this, we compared decoders trained at different time bins throughout the trial. We found that for both passive and task-engaged sessions, the direction of the decoding axis was mainly preserved during the stimulus epoch (black outline in <xref ref-type="fig" rid="fig2">Figure 2b</xref>), and the corresponding decoders trained on passive and task-engaged data were correlated (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Furthermore, these decoders were uncorrelated with the decoding axis during the <italic>delay</italic> period of the task-engaged condition (white outline in <xref ref-type="fig" rid="fig2">Figure 2b</xref>), indicating a behavior-dependent change of the population code at the sound offset. This delay activity pattern further persisted during the <italic>response window</italic>, as shown by the correlation between delay and response window decoding axes (pink outline in <xref ref-type="fig" rid="fig2">Figure 2b</xref>). This suggests a time-independent categorical representation in A1 population activity throughout the delay and response window epochs.</p><p>While categorical encoding is evident during task engagement <italic>after</italic> the stimulus end<italic>,</italic> it remains unclear whether it was biased toward stimulus-related or category-related responses <italic>during</italic> the stimulus. Indeed, both stimulus-related (click train rate) and category-related responses are captured by the decoders (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4a and b</xref>). To disentangle sensory and categorical contributions, we computed a population-level linear regression of the neuronal firing rates at each time bin in each session (see ‘Methods’ for details). Single-neuron activity showed linear relationship with click rates (example in <xref ref-type="fig" rid="fig2">Figure 2c</xref>) or robust categorical encoding during and after the stimulus (<xref ref-type="fig" rid="fig2">Figure 2d and e</xref>). To model this type of responses, we used two regressors: (i) stimulus rates as a <italic>sensory</italic> regressor and (ii) the binary category (Go or No-Go) as a <italic>category</italic> regressor. We also fitted two additional models in which the labels of one of the regressors were shuffled (<xref ref-type="bibr" rid="bib26">Musall et al., 2019</xref>), which allowed us to compute the relative contributions using a <italic>coefficient of partial determination</italic> (CPD) from each regressor as the decrement in variance due to shuffling one of the regressors (<xref ref-type="bibr" rid="bib13">Fisher et al., 2019</xref>)⁠. During task engagement, we found that the CPD of the category regressor increased during the stimulus period and persisted throughout the delay period, before increasing at the response window (<xref ref-type="fig" rid="fig2">Figure 2f and h</xref>; paired <italic>t</italic>-test on category regressor, delay vs response window; ferret P: n = 395 neurons, p&lt;0.001; ferret T: n = 203 neurons, p&lt;0.01). Interestingly, both task-engaged and passive category CPD were larger than chance during stimulus presentations (<xref ref-type="fig" rid="fig2">Figure 2f–i</xref>), an effect absent in the naive animal (<xref ref-type="fig" rid="fig2">Figure 2i</xref>), which indicates training-dependent encoding of categories. Because the variance captured by the category regressor during the delay could be related to other factors than pure behavioral categories, such as reward delivery or licking, we fitted another model including lick and reward regressors (see ‘Methods’). We found similar category axes in the passive and active conditions when accounting for licks and rewards (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). We consider further the possible link of this delay activity pattern with reward expectation or motor preparation (see ‘Discussion’). For practical reasons, we will refer to the delay activity as category-related in the following sections.</p></sec><sec id="s2-3"><title>Population-level categorical responses show suppression of No-Go representations upon task engagement</title><p>We then examined how the category information during the delay emerged from the mixed representation of stimulus and category we found during stimulus presentation. Regression axes define encoding axes along which population activity carries information about stimulus click rate or category. We thus projected population activity onto the category neural axis to track the categorical representation in the population at each moment in time. This procedure sums the neuronal responses weighted by the coefficients extracted from the earlier regression analysis and reduces A1 population dynamics to one information-bearing dimension encoding category through time, independently from sensory information. We did so in both the stimulus and the delay periods for the passive and task-engaged conditions in order to compare the patterns of categorical encoding across conditions. Projections on the category neural axis (called thereafter categorical responses) revealed a stable encoding of categories during sound presentation, regardless of the stimulus identity (<xref ref-type="fig" rid="fig3">Figure 3a and b</xref>), indicating that these categorical responses were not contaminated by sensory activity.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Emergence of categorical representation through suppression of No-Go sounds.</title><p>(<bold>a–d</bold>) Projection of trial-averaged activities of individual click rates onto category axis trained at different time epochs (n = 35 sessions from ferret P). The shaded regions show training time and the error bars are ±2 SEM over sessions. (<bold>a, c</bold>) are active and (<bold>b, d</bold>) are passive states. See <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> for graded sensory responses to the different stimuli. (<bold>e</bold>) Categorical responses for passive and active states (n = 35 sessions from ferret P; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1d</xref> for ferret T). (<bold>f</bold>) Time course of No-Go suppression in categorical responses (difference between the absolute value of passive and active No-Go categorical responses highlighted in <bold>e</bold>). Black bar represents the significant period (p&lt;0.05, <italic>t</italic>-test n = 35 sessions).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>No-Go suppression in all animals.</title><p>(<bold>a, b</bold>) Category index for ferrets P and T. (<bold>c, d</bold>) Projection of trial-averaged activities of passive and active states onto the category axis for ferrets P (<bold>c</bold>) and T (<bold>d</bold>). (<bold>e, f</bold>) No-Go suppression index (***p&lt;0.001, *p&lt;0.01, *p&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Projection of trial-averaged activity onto sensory regressor weights.</title><p>(<bold>a, b</bold>) Projection of trial-averaged activity onto sensory regressor weights trained at stimulus time epoch. (<bold>a</bold>) Active and (<bold>b</bold>) passive states. (<bold>c</bold>) Sensory index as quantified by projection distance between successive click rates onto the sensory regressor weights (***p&lt;0.001 using permutation test for individual boxes).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Projection onto category neural axis extracted from the task-engaged condition for passive and active states.</title><p>Note that Go and No-Go sounds are symmetrically laid out around baseline projections.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig3-figsupp3-v2.tif"/></fig></fig-group><p>Categorization can be defined as the maximization of neural differences between categories and a minimization of the differences within a category. Therefore, we investigated stimulus discriminability along the category neural axis. We designed a category index (see ‘Methods’) which compared the neural distance between stimuli at the category boundary (12 and 16 Hz) against pairs of stimuli within categories. We found that categories were effectively present in both passive and task-engaged states during stimulus presentation with equal magnitude (<xref ref-type="fig" rid="fig3">Figure 3a and b</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a and b</xref>). In contrast, significant categories were found only in the task-engaged state during the delay period (<xref ref-type="fig" rid="fig3">Figure 3c and d</xref>).</p><p>To further determine if task engagement induced a targeted change along the categorical neural dimension, we examined the temporal profiles of the Go and No-Go categorical responses. Here, we found that there was a clear shift of population coding between the two behavioral conditions: No-Go categorical responses aligned with the pre-stimulus spontaneous activity during task engagement (<xref ref-type="fig" rid="fig3">Figure 3a</xref>), inducing an asymmetry between No-Go and Go categorical responses (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, both animals in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c and d</xref>), a characteristic that is not observed in the passive projections (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). A No-Go suppression index measuring the relative displacement of the No-Go responses closer to the projections of spontaneous activity (<xref ref-type="fig" rid="fig3">Figure 3f</xref>) showed that the suppression was confined to the stimulus period (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1e and f</xref>, bottom row; ferret P: p&lt;10<sup>–6</sup>, n = 35 sessions; ferret T: p&lt;10<sup>–4</sup>, n = 39 sessions), and absent in the delay period (ferret P: p=0.70; ferret T: p=0.46). Crucially, projections of the passive population responses onto the active category neural axis <italic>did not</italic> show the suppression of No-Go sounds, confirming that this shift originated from a change in the structure of the population responses during task engagement, and not due to the weights of the regressor themselves (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). In summary, these findings demonstrate a task-induced asymmetry in categorical representations which specifically targets the relevant neural dimension.</p></sec><sec id="s2-4"><title>Single-trial categorical representations correlate between sound and delay periods</title><p>The categorical signal in the stimulus period exhibits short latencies (<xref ref-type="fig" rid="fig3">Figure 3a</xref>) consistent with a feedforward mechanism of early categorization taking place in A1. We wondered whether this early categorical information may influence later categorical information captured in the delay period. However, the categorical axes in the early stimulus and delay periods were not correlated (white frames in <xref ref-type="fig" rid="fig4">Figure 4a</xref>). So how could the categorical information present in these two distinct intervals be still linked? To find out, we tested directly whether the categorical responses during the stimulus period correlated with those during the delay. Specifically, we examined the <italic>single-trial</italic> fluctuations of categorical responses in each period and discovered that the two categorical responses were correlated (one session in <xref ref-type="fig" rid="fig4">Figure 4b</xref>, all sessions in the inset; p&lt;0.001, permutation test, n = 74 sessions). Note that the stimulus and delay categorical responses were computed from uncorrelated projection axes (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) that were originally derived from distinct non-overlapping epochs, and hence the single-trial fluctuations in categorical responses need not have been correlated in any way.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Post-stimulus anticipatory activity correlates with categorical representation during the sound.</title><p>(<bold>a</bold>) Temporal evolution of the category axis (n = 35 sessions from ferret P). (<bold>b</bold>) Scatter plot for categorical response during stimulus and delay period for one session. Inset: correlation of single-trial categorical responses between the sound and delay periods (n = 74 sessions from both ferrets). (<bold>c</bold>) Categorical responses for hit, early trials with licks in the early (early licks) and late (late licks) phases of the delay period. (<bold>d</bold>) Lick-aligned categorical responses. Projections were not different between hit and early trials at lick time (see outcome decoding in <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). The black bar represents the significant period (p&lt;0.05, <italic>t</italic>-test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Scatter plot of the category weights regressed during stimulus and delay periods (n = 395 neurons from ferret P and n = 203 neurons from ferret T).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Projection of trial-averaged activity of hit, early–early, and late–early trials onto the category neural axis computed during the stimulus period.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Delay activity in hit and early trials is identical.</title><p>(<bold>a</bold>) Lick-aligned population decoding of hit vs early trials. The accuracy is about chance level 500 ms before the lick. (<bold>b</bold>) Comparison of accuracy within 0–500 ms and 500–1000 ms before lick with that of random shuffling, significance is computed using a permutation test (***p&lt;0.001).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig4-figsupp3-v2.tif"/></fig></fig-group></sec><sec id="s2-5"><title>Post-sound anticipatory activity builds up towards behavioral response</title><p>Another interesting relationship is that between the categorical responses and the licks. We have observed that population activity on hit trials ramped up throughout the delay period (<xref ref-type="fig" rid="fig3">Figures <xref ref-type="fig" rid="fig3">3</xref>,<xref ref-type="fig" rid="fig4">4</xref>3c and 4c</xref>, categorical responses during the delay). By aligning single-trial projections onto lick timings during the response window, we found that the categorical activity built up during the delay period and culminated when the animal licked (<xref ref-type="fig" rid="fig4">Figure 4d</xref>, categorical responses centered on licks), indicating that delay activity was anticipating behavioral responses. We further tested whether the temporal dynamics of the categorical responses correlated with the timing of the animal’s behavioral response. To do so, we took advantage of early Go trials when the animals licked <italic>before</italic> the response window (see lick histogram in <xref ref-type="fig" rid="fig1">Figure 1c</xref>), so that we accessed to Go trials in which first licks occurred earlier than what we had in hit trials. We then sorted all the collected trials into three groups: early trials with licks early in the delay period (first half), early trials with licks late in the delay (second half), and hits. We found significantly faster response build-up rates in early trials than in hit trials (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). Early trials with early licks in the delay exhibited the steepest response build-ups (<xref ref-type="fig" rid="fig4">Figure 4c</xref>), a pattern that was not observed in the categorical responses during the stimulus period (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). We then aligned all trials to their respective reaction times and found that categorical responses of early and hit trials culminated at the licking time (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). This alignment was done on lick times, that is, independently of neural activity, indicating a build-up of population-level dynamics anticipating behavioral response.</p></sec><sec id="s2-6"><title>Sensory information is degraded during error trials, leading to poor categorization</title><p>Finally, we searched for the neural correlates of incorrect perceptual decisions. In particular, we wanted to pinpoint which encoding stages were degraded during incorrect categorizations. We envisioned three different hypotheses causing the error trials: (a) sensory information was intact in error trials, but conversion to the correct category during the stimulus was incorrect; or that (b) sensory-to-category processing during the stimulus period is correct, but the anticipatory activity is impaired during the delay; or that (c) sensory information was in fact degraded early on during the stimulus, leading to a loss of categorical information.</p><p>We first sought to test whether the error trials correlated with an inversion of the neural responses between the Go and No-Go categories, as would be predicted by hypothesis (a). To do so, we used Go/No-Go classifiers trained with correct trials (as in <xref ref-type="fig" rid="fig2">Figure 2a</xref>) and reported the classifiers’ performance in predicting the expected (and not actual) behavioral categories. If false alarms were fully behaving like hits, and misses like correct rejections, we should observe below-chance decoding accuracy. That was not the case, but instead we found a decrease in decoding accuracy during the sound period and a decoding performance at chance level during the delay (<xref ref-type="fig" rid="fig5">Figure 5a and b</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for separate projections of false alarm and miss trials; decoding accuracy during delay for incorrect trials: p=0.99, permutation test). As a control, we noted that decoding accuracy dipped below chance during the response window confirming that motor information was confined to this late time period (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). This indicates that incorrect decisions could be traced back to the stimulus period, excluding hypothesis (b) in which only the delay activity was incorrect during error trials.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Sensory and categorical responses during error trials.</title><p>(<bold>a</bold>) Encoding of behavioral choices: here we trained the active classifier on correct behavioral choices (hit and correct rejection) and used the decoding weights to compute the accuracy using incorrect behavioral choices (false alarm and miss) as shown in the purple curve (n = 35 sessions from ferret P). Gray curve indicated the performance by shuffling labels in task engagement. Error bars show 1 SD. (<bold>b</bold>) Accuracy of the active decoder for correct and error trials during sound and delay period (n = 35 sessions from ferret P). (<bold>c</bold>) Category index and sensory index computed from the projections of trial-averaged correct and error trials onto category axis trained during sound period (see ‘Methods’). (<bold>d</bold>) Category index for delay period (see <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for both animals).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Projection of trial-averaged activity of error trials (average number of error trials in ferret P: 55.1 ± 14.9 and in ferret T: 66.2 ± 13.2) in both Go and No-Go categories onto the classifiers trained on correct trials during stimulus presentation (<bold>a</bold>), delay (<bold>b</bold>), and response window (<bold>c</bold>).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Sensory and Category index per animal.</title><p>(<bold>a, c</bold>) Sensory and category Index during active correct and error trials for ferret P. (<bold>b, d</bold>) Same as (<bold>a, c</bold>) for ferret T (***p&lt;0.001, **p&lt;0.05, *p&lt;0.1).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-fig5-figsupp2-v2.tif"/></fig></fig-group><p>We then further tested the hypothesis (c) of a degradation of sensory information during the stimulus period. In line with this interpretation, we found that sensory responses were lower in incorrect compared to correct trials (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2a and b</xref>; stimulus period-sensory index: ferret P: p&lt;10<sup>–5</sup>, n = 35 sessions; ferret T: p&lt;10<sup>–3</sup>, n = 39 sessions; stimulus period-category index: ferret P: p=0.01, n = 35 sessions; ferret T: p=0.35, n = 39 sessions; paired <italic>t</italic>-test across sessions, individual boxes were tested with permutation test). Categorical responses were further degraded during the delay period (delay-category index [<xref ref-type="fig" rid="fig5">Figure 5d</xref> and <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2b and c</xref>] for both animals; paired <italic>t</italic>-test across sessions; ferret P: p&lt;10<sup>–4</sup>, n = 35 sessions; ferret T: p&lt;10<sup>–5</sup>, n = 39 sessions). Altogether, this suggests that errors likely originated from an improper encoding of the stimulus that subsequently led to an incorrect categorization and behavioral response.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Categorical perception of real-world signals is a key cognitive function in all sensory modalities, one that is thought to be implemented at higher cortical levels (<xref ref-type="bibr" rid="bib38">Swaminathan and Freedman, 2012</xref>; <xref ref-type="bibr" rid="bib14">Folstein et al., 2013</xref>; <xref ref-type="bibr" rid="bib42">Yin et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Freedman and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib34">Roy et al., 2010</xref>; <xref ref-type="bibr" rid="bib5">Bizley and Cohen, 2013</xref>). In this work, we examined if and how population responses in <italic>primary</italic> auditory cortex could contribute to and reflect the categorical encoding of sounds during passive listening or engagement in a Go/No-Go categorization task. The study resulted in four main findings. First, we isolated an encoding of behavioral categories in the population-average during stimulus presentation in both task-engaged and passive listening. This was not observed in a naive animal (<xref ref-type="fig" rid="fig2">Figure 2i</xref>). We interpret this observation as an effect of long-term memory (<xref ref-type="bibr" rid="bib11">Elgueda et al., 2019</xref>). Second, we found that population-level categorical responses to No-Go sounds were suppressed during task engagement during the stimulus period (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Third, the population-level categorical representation changed at stimulus offset but still correlated at the single-trial level with categorical responses observed during the stimulus period (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>). Fourth, incorrect behavioral choices were traced back to degraded categorical encoding during the stimulus period, resulting in a degraded categorical representation during the subsequent <italic>delay</italic> period (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Altogether, these results suggest that behavior-dependent categorical information emerged during the stimulus period, influenced population dynamics beyond the stimulus period itself, and persisted throughout the delay period until the behavioral response.</p><sec id="s3-1"><title>Neuronal selectivity to behavioral categories during task engagement</title><p>Previous findings have found categorical responses in A1 with a marked increase of response contrast at category boundaries (<xref ref-type="bibr" rid="bib42">Yin et al., 2020</xref>; <xref ref-type="bibr" rid="bib40">Xin et al., 2019</xref>)<sup>⁠</sup>. Here, we focused on revealing the temporal dynamics and evolution of categorical encoding both in the population average and in the population code. Regression analyses allowed us to disentangle the binary categorical representation from the more graded representation of the sensory properties (i.e., click train rates) (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Similar to a previous study in the mouse (<xref ref-type="bibr" rid="bib40">Xin et al., 2019</xref>⁠), we found that the encoding of stimulus sensory properties within behavioral categories was stable across behavioral states. In <xref ref-type="bibr" rid="bib40">Xin et al., 2019</xref>⁠, the authors found that categorical representations in A1 matched behavioral decision as early as at stimulus offset, and was maintained during several seconds. Such choice-related activity has been demonstrated to be the result of feedforward and feedback flow between primary sensory cortices and downstream regions (<xref ref-type="bibr" rid="bib9">Dehaene and Changeux, 2011</xref>; <xref ref-type="bibr" rid="bib41">Yang et al., 2016</xref>⁠). Our observations are consistent with this view as we found that perceptual choice influenced the category decoded during the response window (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). Nevertheless, we used longer stimulus followed by a long delay in our study, which allowed us to decouple the early categorical information building up during stimulus presentation from the late choice report of the animal. In addition, categorical information declined during stimulus and delay periods, suggesting that incorrect trials were due to a lack of proper categorical information early on during the stimulus itself.</p></sec><sec id="s3-2"><title>Population-level suppression of No-Go categorical responses</title><p>Our analyses showed that, even though categorical encoding was present in passive and active states in trained animals, task engagement induced a suppression of No-Go responses during the stimulus. This was not due to a lack of sound-evoked responses to No-Go sounds, as shown by the average population peristimulus time histogram (PSTH) (<xref ref-type="fig" rid="fig1">Figure 1d</xref>) and its sensory responses (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Instead, this asymmetry in the categorical representation stems from a task-induced population-level enhancement of Go and suppression of No-Go categorical responses, consistent with our previous findings (<xref ref-type="bibr" rid="bib2">Bagur et al., 2018</xref>) in these Go/No-Go paradigms. To elaborate, No-Go sounds instruct the animal to maintain the same behavioral output (lick inhibition) as in periods of silence when spontaneous activity is measured. We therefore proposed that the alignment of the No-Go population responses with the spontaneous activity reflects the identical behavioral meaning of these two epochs. Here, we found a similar mechanism (suppression of No-Go responses) which was confined to the categorical responses extracted through linear regression. This suggests an interesting mechanism in which population dynamics could multiplex behavior-independent sensory representations and task-modulated categorical encoding. Intriguingly, this is reminiscent of population dynamics found in prefrontal cortex (PFC) (<xref ref-type="bibr" rid="bib24">Mante et al., 2013</xref>), where sensory information and decision formation were represented along different neural dimensions.</p><p>In line with a role of A1 in the category build-up, we found that categorical information was degraded in error trials, which is consistent with an early mapping of individual stimulus into generic categories at the level of primary sensory areas. We thus propose that A1 has an initial contribution in the feedfoward formation of behavior-dependent categories. During behavior, higher areas would access an explicit representation of the behaviorally relevant categories by reading out the asymmetrical population-level encoding of Go and No-Go sounds in A1 (<xref ref-type="bibr" rid="bib2">Bagur et al., 2018</xref>). These areas would then utilize the A1 categorical representation to amplify and strengthen the ongoing category, possibly passing or gating it to motor-related regions depending on the behavioral state (<xref ref-type="bibr" rid="bib1">Atiani et al., 2014</xref>).</p></sec><sec id="s3-3"><title>Possible roles for sustained activity after Go sounds</title><p>Categorical responses changed at stimulus offset to maintain a Go-specific prolonged activity during the delay period, consistent with other studies showing choice-related activity in A1 (<xref ref-type="bibr" rid="bib6">Bizley et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Niwa et al., 2012b</xref>; <xref ref-type="bibr" rid="bib27">Niwa et al., 2012a</xref>; <xref ref-type="bibr" rid="bib19">Guo et al., 2019</xref>⁠). We do not interpret this activity as efferent copies directly sent from motor regions (<xref ref-type="bibr" rid="bib36">Schneider et al., 2018</xref>), as one would expect such motor-related activity to have shorter latencies (~100–300 ms; <xref ref-type="bibr" rid="bib2">Bagur et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Orlandi et al., 2023</xref>⁠). Here, sound category was decodable throughout the entire delay period (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), which does not match with short-latency efference copies. We have also found that the delay activity is not closely locked in time to licks since false alarm trials, in which the animals licked during the response window, were not decoded as hit trials during the delay period (<xref ref-type="fig" rid="fig5">Figure 5b</xref>).</p><p>Other studies investigating the role of A1 in auditory Go/No-Go tasks with a delay did not analyze neuronal responses after Go sounds (<xref ref-type="bibr" rid="bib43">Yu et al., 2021</xref>; <xref ref-type="bibr" rid="bib20">Huang et al., 2016</xref>), which may explain why this sustained activity has not been previously reported. Interestingly, delay activity in sensory cortices is thought not to be causally involved in the behavioral response of trained animals (causal inactivations in V1 [<xref ref-type="bibr" rid="bib18">Goard et al., 2016</xref><sup>⁠</sup>] and A1 [<xref ref-type="bibr" rid="bib43">Yu et al., 2021</xref><sup>⁠</sup>]). We note that this sustained activity after Go sounds can be caused by at least three different factors.</p><p>First, delay activity in A1 could be the result of a feedback signal from higher-order decision-related areas signaling the chosen category and maintaining it in memory by engaging A1 in a network of parietal and frontal areas (<xref ref-type="bibr" rid="bib18">Goard et al., 2016</xref>)<sup>⁠</sup>. In this framework, previous works in the somatosensory system have shown that choice-related information flows bidirectionally between primary and secondary somatosensory cortices, with choice-related information emerging in primary sensory cortex, then fed to downstream areas that further feedback enriched choice-related information to the primary field (<xref ref-type="bibr" rid="bib23">Kwon et al., 2016</xref>⁠). Consistent with this hypothesis, we have demonstrated that trial-to-trial fluctuations of categorical responses during the <italic>sound</italic> period correlate with the amplitude of the <italic>delay</italic> categorical signal (<xref ref-type="fig" rid="fig4">Figure 4b</xref>), possibly suggesting that category-related information during the stimulus and delay periods is part of this communication loop.</p><p>A second interpretation is that delay activity is the result of motor preparation that would unfold over several hundreds of milliseconds (<xref ref-type="bibr" rid="bib26">Musall et al., 2019</xref>⁠). The pattern of activity observed during early trials is consistent with this view, with faster build-up when the animals licked earlier. However, a similar pattern was not observed on false alarm trials, contrary to what would be predicted for this interpretation.</p><p>A last possibility is that delay activity signals reward expectation (<xref ref-type="bibr" rid="bib8">Chubykin et al., 2013</xref>⁠), a type of response which increases through learning (<xref ref-type="bibr" rid="bib26">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib30">Poort et al., 2015</xref>⁠). This delay activity would then reflect post-learning residual top-down feedback, or alternatively may be the signature of an eligibility trace, that is, a persistent activity necessary for bridging the gap between the sound and the response window (<xref ref-type="bibr" rid="bib31">Raybuck and Lattal, 2014</xref><sup>⁠</sup>). Overall, disentangling these different interpretations will require further experiments.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Animals</title><p>Adult female ferrets (<italic>Mustela putorius furo</italic>) obtained from Marshall BioResource were used for this study. The animals were 1–3 years of age, weighing 500–800 g, and were housed in pairs or trios with a normal day–night light cycle and free access to water during weekends. Ferrets were on a water-controlled protocol in which their water intake is restricted during the weekdays. Water was delivered during behavioral sessions as a reward. To maintain a stable weight, we provided ad libitum water for 1–2 hr post behavior. The animals’ weights were daily monitored and maintained at 80% of pre-experiment weight.</p></sec><sec id="s4-2"><title>Behavioral task and training</title><p>Two adult female ferrets (<italic>M. putorius furo</italic>) were trained on an appetitive Go/No-Go delayed categorization task and one additional ferret was used for naive recording. The animals were head-fixed in a custom-made tube during training and recording sessions, and the stimuli were presented from a calibrated earphone (Sennheiser IE800, HDVA 600 amplifier). Ferrets had to classify click trains into two categories: target (Go) and non-target (No-Go) depending on the rates of click trains. Six rates were used, from 4 to 24 Hz in 4 Hz steps, and with a category boundary fixed at 14 Hz. To ensure the dissociation between categories and stimulus rates, one animal was trained with low rates as the Go sounds, while the second animal classified high rates as the Go sounds. Clicks were monopolar, rectangular pulses of 1 ms duration with amplitude set at 70 dB sound pressure level. A trial started with a pre-stimulus silence of 0.5 s followed by a click train (Go or No-Go) of 1.1 s (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The animals were trained to wait for a response window that started after a delay of 1 s following stimulus offset. A hit (lick on the response window for Go stimuli) was rewarded with 0.2 ml of water. An LED attached to the water spout emphasized the delay period in which the animal had to restrain from licking. Early trials (lick during stimulus and delay period) and false alarms (lick on the response window of a No-Go sound) were punished with a timeout of 10 s. In each session, Go and No-Go stimuli were presented in a pseudo-random manner. In the absence of delay, ferrets learned to associate the categories in 1 wk, and we then slowly increased the delay between stimulus offset and response window. It took several weeks for the ferrets to be trained on the full task structure. Initially we trained with extreme categorical stimuli (4 and 24 Hz) that were easy to learn, and after reaching a consistent performance (d’ &gt; 1), we progressively introduced other stimuli.</p></sec><sec id="s4-3"><title>Surgery</title><p>To head restrain during training and obtain stable neurophysiological recordings, we implanted the ferrets with a stainless steel headpost. The day prior to the surgery ferrets were injected with antibiotics (Baytril, 12.5 mg/kg subcutaneous) to minimize infections arising from the surgery. On the day of surgery, ferrets were deprived of water and food 90 min prior to the surgery. After sedation (medetomidine, 0.08 mg/kg, subcutaneous), anesthesia was induced with ketamine (5 mg/kg, intramuscular). Animals were kept under deep anesthesia (1–2% isoflurane) throughout the surgery and vitals (ECG, pulse, oxygenation, and rectal temperature) were continuously monitored. We also medicated the animals with atropine sulfate (0.2 mg/kg) to stabilize salvation and control arrhythmia arising from anesthesia. Using a complete sterile procedure, the animal skull was surgically exposed by an incision to the skin along the media crest down to the neck. The temporal muscles were carefully removed from the medial crest to the beginning of the zygomatic arch and the lateral wing at the lateral end of the nuchal crest. Using a stereotaxic apparatus, the headpost was mounted on the skull using methyl methacrylate-based dental adhesive resin cement. Stainless steel screws were anchored along the areas surrounding the auditory cortex, leaving a cavity for easy access to the auditory cortex. The typical horseshoe shape of the auditory cortex was marked with nail polish. Finally, the surrounding areas were filled with poly-methyl methacrylate-based bone cement to stabilize the implant. Antibiotics (Baytril, 12.5 mg/kg, subcutaneous) and analgesic (meloxicam, 0.05 mg/kg, oral) were administered to the animal following the surgery.</p><p>We allowed a 2-week postoperative care for the animals to recover from the surgery. Antibiotics were continued for 7 d and anti-inflammatory and analgesics were administered for 4 d. Animals were habituated to a head-restrained custom-made horizontal plastic tube a few days prior to training session. Experiments were approved by the French Ministry of Agriculture (protocol authorization: 21022) and strictly comply with the European directives on the protection of animals used for scientific purposes (2010/63/EU).</p></sec><sec id="s4-4"><title>Neurophysiological recordings</title><p>In a separate surgery, we chronically implanted 32-channel metal electrodes arrays (MEA; Pt-Ir, MicroProbes, 8 × 4, electrode of impedance 2.5 MΩ with 0.4 μm distance between the electrodes) over the prior marked auditory cortex. We custom-designed the chronic implant with MEA inserted in a drive-shuttle system having a flexible control of the array vertical movement. The base of the drive was sealed with a stretchable silicon membrane sheet to stop flowing any residues into the drive. Before the implantation, the electrodes were moved down such that the apex popped out of the silicon membrane. Under surgical anesthesia (isoflurane 1 %), we removed the cement above the location marked during the surgery. We then performed a 4 mm × 4 mm craniotomy. This craniotomy allowed us to identify the core regions of the auditory cortex (middle ectosylvian gyrus) by visual inspection of the tip of the ectosylvian gyrus. We carefully removed the transparent dura to ensure that the array penetrated the brain without additional strain. The drive-shuttle system was placed on the brain surface using a stereotaxic apparatus and the entire system was fixed to the skull using bone cement. To minimize vibrations that could be caused by shocks on the drive, the chronic implant was enclosed in a custom-made tube cemented to the implant. Immediately after the surgery we slowly lowered the electrodes and observed physiological activity, allowing us to verify the electrodes moved inside the brain.</p><p>Each recording session consisted of passive and active sessions. Recordings were performed head-fixed in a soundproof chamber. In the passive sessions, the water spout was removed. Continuous electrophysiological recordings were digitized (31,250 Hz), amplified (15,000×), and band-passed between 300 Hz and 7000 Hz using a digital acquisition system (Blackrock Cereplex). Band-passed signals were monitored online and units (including multi- and single-) were identified by spikes crossing a threshold of 3 SD of baseline noise. The data acquisition was done using an open-source suite MANTA v. 1.0 (<xref ref-type="bibr" rid="bib12">Englitz et al., 2013</xref>). We used a custom-made open-source software Behavioral Auditory PHYsiology (BAPHY) written in MATLAB for sound delivery, recording, behavioral monitor and online analysis.</p><p>To identify units, we presented band-pass noise (0.2 s duration, 1 octave bandwidth) and pure tone stimuli to the animal using earphones (Sennheiser IE 800). Primary auditory cortical responses were identified by analyzing tuning properties to 100 ms tone pips of random frequencies spanning 4 octaves and temporally orthogonal ripple combinations (STRF) (<xref ref-type="bibr" rid="bib10">Depireux et al., 2001</xref>). A1 responses show sharp tuning to random tones and single-peak, short-latency STRFs (<xref ref-type="bibr" rid="bib1">Atiani et al., 2014</xref>; <xref ref-type="bibr" rid="bib16">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib11">Elgueda et al., 2019</xref>)<sup>⁠</sup>. Finally assessing the STRFs, we continued with the experimental protocols to record the neuronal responses.</p></sec><sec id="s4-5"><title>Unit identification and spike sorting</title><p>We performed offline spike sorting on thresholded signals using PCA-based customized spike sorting routines written in MATLAB. Single- and multi-unit responses were identified by spiking shape and manually adjusting the PCA clusters (<xref ref-type="bibr" rid="bib16">Fritz et al., 2003</xref>)⁠. A total of 575 (ferret P) and 241 (ferret T) multi-units were identified and used for further analysis (<xref ref-type="table" rid="table1">Table 1</xref>). Spike sorting was done on concatenated passive and active sessions. We obtained 11.3 ± 4.9 neurons per session (± SD; n = 35 sessions) for ferret P and 5.2 ± 3.2 neurons per session (± SD; n = 39 sessions) for ferret T.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Number of recorded units.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Ferret</th><th align="left" valign="top">Recorded Units</th><th align="left" valign="top">Units used for population analysis</th><th align="left" valign="top">Sessions</th></tr></thead><tbody><tr><td align="left" valign="top">Ferret P</td><td align="char" char="." valign="top">575</td><td align="char" char="." valign="top">395</td><td align="char" char="." valign="top">35</td></tr><tr><td align="left" valign="top">Ferret T</td><td align="char" char="." valign="top">241</td><td align="char" char="." valign="top">203</td><td align="char" char="." valign="top">39</td></tr></tbody></table></table-wrap></sec><sec id="s4-6"><title>Data analysis</title><sec id="s4-6-1"><title>Preprocessing</title><p>Offline data analysis was performed using custom-written scripts in MATLAB (R2016a). All units were preprocessed to identify stable units that were kept under recording for both the active and passive sessions. We used a firing rate-based threshold to find stable units with non-zero firing rate for &gt;80% of the trials, and the difference between time-averaged maximum and minimum firing rates is less than tenfold across trials. We only analyzed units with &gt;2 spikes/s firing rate. This procedure yielded 395 units in ferret P and 203 units in ferret T. Spike counts were constructed for 100 ms non-overlapping time bins and thus used for further analysis. All population analyses were done at the single-session level, and therefore individual sessions were used as samples in statistical tests. This also allowed us to use all trials in each session, despite the difference in the number of correct trials across sessions due to variable behavior.</p></sec><sec id="s4-6-2"><title>Neurons with sustained activity during the delay period</title><p>To identify neurons with sustained activity during the delay, we z-scored spike counts from the baseline period (500 ms pre-stimulus) and then applied a threshold of 1.5 to the z-scored firing rate averaged over the delay period.</p></sec><sec id="s4-6-3"><title>Modulation index</title><p>For each unit, the modulation index of activity for quantifying modulation of delay activity was computed using<disp-formula id="equ1"><mml:math id="m1"><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <italic>Delay</italic> is the firing rate during the delay and <italic>Spont</italic> is the spontaneous activity over the pre-stimulus period.</p></sec><sec id="s4-6-4"><title>Population decoding</title><p>In each recording session, we constructed time-based binary linear discriminant classifiers (<xref ref-type="bibr" rid="bib2">Bagur et al., 2018</xref>; <xref ref-type="bibr" rid="bib4">Bishop, 2006</xref>; <xref ref-type="bibr" rid="bib25">Meyers et al., 2008</xref>⁠) to decode stimulus categories (Go vs No-Go) with 100 ms binning. In brief, for each recording sessions, population vectors were constructed at each time bin and trained with equal number of random Go and No-Go trials (<inline-formula><mml:math id="inf1"><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>-</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>). Then the population decoding vector is given by<disp-formula id="equ2"><mml:math id="m2"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>-</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf2"><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>-</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are trial-averaged population vectors for Go and No-Go categories, respectively. The threshold is defined by<disp-formula id="equ3"><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>-</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>For each test trial population vector <inline-formula><mml:math id="inf3"><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, the linear discriminant function is given by<disp-formula id="equ4"><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>The test trial <inline-formula><mml:math id="inf4"><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is assigned to the Go category if <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> and to the No-Go category otherwise. The assigned category is compared to the ground truth and the proportion correct defines the accuracy of the classifier. Cross-validation was performed 200 times by randomly choosing train (70% of data) and test trials (30% of data).</p><p>Random classifier performance was obtained with 200 label shuffling permutations (the lower bound for the p-value being 1/200 = 0.005) and the comparison was statistically evaluated through permutation tests, comparing the actual performance with the chance-level distribution. Unless mentioned otherwise, all analyses were done using only correct trials (correct rejection No-Go trials and hit Go trials). Temporal evolution of the decoder was computed as the correlation between decoding weight vectors at one time bin against others, and time points below-chance correlation values are shown in gray in <xref ref-type="fig" rid="fig2">Figure 2b</xref>. We also projected the trial-averaged activity of test trials onto the unit decoders trained at sound and delay period as shown in <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>.</p></sec><sec id="s4-6-5"><title>Linear regression</title><p>A linear decoder trained on classifying categories inherently mixed sensory and category information to decode categories. To disentangle the contributions from sensory features and categories in the population code, we opted for linear regression models to capture the unique contribution of each feature.</p><p>At each time bin, the design matrix for linear regression consists of sensory (click rates 4, 8, 12, 16, 20, and 24 Hz) and category (–1 for No-Go and +1 Go) regressors as follows:<disp-formula id="equ5"><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:mi>C</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1,2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> are the regressor weights, <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> a constant, and <italic>Sensory</italic> and <italic>Category</italic> are the regressor values.</p><p>The model was fitted for each neuron on correct trials (hit Go trials and correct rejections No-Go trials). We used ridge regression to minimize overfitting and diminish the impact of correlated variables. The ridge parameter is calculated using a cross-validated marginal maximum likelihood method (<xref ref-type="bibr" rid="bib22">Karabatsos, 2018</xref>⁠). To fit the model, we used the ridgeMML function from <ext-link ext-link-type="uri" xlink:href="http://churchlandlab.labsites.cshl.edu">http://churchlandlab.labsites.cshl.edu</ext-link> (<xref ref-type="bibr" rid="bib26">Musall et al., 2019</xref>⁠).</p><p>In order to make sure that the sensory and category regressor weights were not contaminated by other task variables, we included lick and reward variables in a separate model fitted on correct and incorrect trials. At each time bin, the lick regressor consisted of either 1 or 0 corresponding to the presence or absence of licks. During the hit trials, the reward regressor was set to 1 the time bins in response window when the animal licked and was 0 otherwise. We found that the category and sensory axes were similar in the two-regressor and the four-regressor models (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>).</p></sec><sec id="s4-6-6"><title>Coefficient of partial determination</title><p>To capture the contribution of each feature into neuronal activity, we computed a CPD as the fraction of variance lost by shuffling one of the features with respect to the full original model (<xref ref-type="bibr" rid="bib13">Fisher et al., 2019</xref>)⁠. Doing so, CPD captured the unique contribution of that feature (<xref ref-type="bibr" rid="bib26">Musall et al., 2019</xref>)⁠. We thus fitted reduced linear models with one of the variables being shuffled in the design matrix in order to destroy the contribution arising from that particular task variable. We used fivefold cross-validation to compute the mean square error (MSE) for the full and reduced models. CPD was defined as<disp-formula id="equ6"><mml:math id="m6"><mml:mi>C</mml:mi><mml:mi>P</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is obtained by cross-validating the following reduced models with fivefold cross-validation:</p><list list-type="bullet"><list-item><p>For estimating the unique contribution of sensory regressor:<disp-formula id="equ7"><mml:math id="m7"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:mi>C</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:math></disp-formula></p></list-item><list-item><p>For estimating the unique contribution of category regressor:<disp-formula id="equ8"><mml:math id="m8"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:msub><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p></list-item></list><p>Time windows for computing average CPD in each period were 0–1.1 s for the stimulus period, 1.1–2.1 s for the delay period, and 2.1–3.1 s for the response window period.</p></sec><sec id="s4-6-7"><title>Projections of population activity onto sensory and category neural axes</title><p>We assessed the time evolution of population activity along sensory- and category-related neural axes defined by the linear regression (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This was done by projecting baseline-corrected population activity specific to the feature of interest onto category or sensory regressor weights. Therefore, any deviation from zero represents the deviation of population activity along the regression axis away from the projection of baseline activity.</p><p>Regression weights for the active sensory and category neural axes were correlated during the stimulus period (ρ = 0.37, p&lt;10<sup>–2</sup>, n = 35 sessions in ferret P; ρ = 0.17, p=0.04, n = 38 sessions in ferret T; Pearson correlation). We made sure to separate the contribution of each variable before projecting on the regression weights. For restricting the projections of activity along each axis (say feature X, which could be category), we first subtracted the response predicted by the model for the other regressor (say feature Y, in this case sensory: <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:math></inline-formula>) from the single-trial population activity. We then projected the residual population activity onto the regression weights of feature X. Projections are therefore computed as follows:<disp-formula id="equ9"><mml:math id="m9"><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mi>*</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:mi>C</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>where 1/2 corresponds to weights for sensory and category regressors.</p><p>Before projecting, the test trial activity at each time bin was baseline-corrected, so that projections of baseline activity lie at zero. We could then project population activity corresponding to individual click rates (<xref ref-type="fig" rid="fig3">Figure 3a–d</xref>) or averaging across click trains of the same category (<xref ref-type="fig" rid="fig3">Figures 3e<xref ref-type="fig" rid="fig3">3</xref>,<xref ref-type="fig" rid="fig4">4</xref> and 4</xref>). Time windows for computing average projection axis in each period were 0.2–0.9 s for the stimulus period and 1.3–2.1 s for the delay period.</p></sec><sec id="s4-6-8"><title>Categorization and sensory indices</title><p>We quantified the amount of category information present in the projections using a category index (CI). CI is an index comparing the distance between categorical responses of stimulus pairs within and between categories:<disp-formula id="equ10"><mml:math id="m10"><mml:mi>C</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf10"><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> was averaged over all possible successive pairs belonging to the same category (4–8 Hz, 8–12 Hz, 16–20 Hz, and 20–24 Hz) while <inline-formula><mml:math id="inf11"><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> was measured at the category boundary (12–16 Hz).</p><p>Similarly, a sensory index (SI) measured the distance between the projections of successive click rates within the same category (4–8 Hz, 8–12 Hz, 16–20 Hz, and 20–24 Hz) onto the sensory regressor weights:<disp-formula id="equ11"><mml:math id="m11"><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf12"><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the projection distance between successive click rates within the category.</p></sec></sec><sec id="s4-7"><title>Statistics and data availability</title><p>We performed both population decoding and linear regression analysis session-wise with simultaneously recorded neurons. All statistics across passive and active states were done with paired <italic>t</italic>-tests. Correlations were linearly assessed (Pearson correlation). Unless specified otherwise, error bars showed ± 1 SEM over sessions. The codes for reproducing the analysis are available on the following repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/rupeshjnu/A1-Category">https://github.com/rupeshjnu/A1-Category</ext-link>, (copy archived at <xref ref-type="bibr" rid="bib35">Rupesh, 2023</xref>). The electrophysiological data is publicly available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/8371084">https://zenodo.org/records/8371084</ext-link>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con2"><p>Validation, Investigation, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Validation, Investigation, Methodology, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Experiments were approved by the French Ministry of Agriculture (protocol authorization: 21022) and strictly comply with the European directives on the protection of animals used for scientific purposes (2010/63/EU).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-85706-mdarchecklist1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data is available on Zenodo, <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.8371083">https://doi.org/10.5281/zenodo.8371083</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Chillale</surname><given-names>RK</given-names></name><name><surname>Boubenec</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Dynamics and maintenance of categorical responses in primary auditory cortex during task engagement</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.8371083</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Joao Barbosa and Célian Bimbard for deep reading and fruitful comments. This work was supported by ANR-17-EURE-0017 and ANR-10-IDEX-0001-02, ERC 787836-NEUME and ANR-19-CE37-0016 to SAS, and ANR-JCJC-DynaMiC to YB.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atiani</surname><given-names>S</given-names></name><name><surname>David</surname><given-names>SV</given-names></name><name><surname>Elgueda</surname><given-names>D</given-names></name><name><surname>Locastro</surname><given-names>M</given-names></name><name><surname>Radtke-Schuller</surname><given-names>S</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name><name><surname>Fritz</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emergent selectivity for task-relevant stimuli in higher-order auditory cortex</article-title><source>Neuron</source><volume>82</volume><fpage>486</fpage><lpage>499</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.02.029</pub-id><pub-id pub-id-type="pmid">24742467</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagur</surname><given-names>S</given-names></name><name><surname>Averseng</surname><given-names>M</given-names></name><name><surname>Elgueda</surname><given-names>D</given-names></name><name><surname>David</surname><given-names>S</given-names></name><name><surname>Fritz</surname><given-names>J</given-names></name><name><surname>Yin</surname><given-names>P</given-names></name><name><surname>Shamma</surname><given-names>S</given-names></name><name><surname>Boubenec</surname><given-names>Y</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Go/No-Go task engagement enhances population representation of target stimuli in primary auditory cortex</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2529</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04839-9</pub-id><pub-id pub-id-type="pmid">29955046</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Barbosa</surname><given-names>J</given-names></name><name><surname>Proville</surname><given-names>R</given-names></name><name><surname>Rodgers</surname><given-names>CC</given-names></name><name><surname>DeWeese</surname><given-names>MR</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name><name><surname>Boubenec</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Flexible selection of task-relevant features through population gating</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.07.21.500962</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><chapter-title>Pattern recognition</chapter-title><source>Pattern Recognition and Machine Learning</source><publisher-loc>New York, United states</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Cohen</surname><given-names>YE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The what, where and how of auditory-object perception</article-title><source>Nature Reviews. Neuroscience</source><volume>14</volume><fpage>693</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1038/nrn3565</pub-id><pub-id pub-id-type="pmid">24052177</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Walker</surname><given-names>KMM</given-names></name><name><surname>Nodal</surname><given-names>FR</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Schnupp</surname><given-names>JWH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Auditory cortex represents both pitch judgments and the corresponding acoustic cues</article-title><source>Current Biology</source><volume>23</volume><fpage>620</fpage><lpage>625</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.03.003</pub-id><pub-id pub-id-type="pmid">23523247</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christison-Lagay</surname><given-names>KL</given-names></name><name><surname>Cohen</surname><given-names>YE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The contribution of primary auditory cortex to auditory categorization in behaving monkeys</article-title><source>Frontiers in Neuroscience</source><volume>12</volume><elocation-id>601</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2018.00601</pub-id><pub-id pub-id-type="pmid">30210282</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chubykin</surname><given-names>AA</given-names></name><name><surname>Roach</surname><given-names>EB</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name><name><surname>Shuler</surname><given-names>MGH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A cholinergic mechanism for reward timing within primary visual cortex</article-title><source>Neuron</source><volume>77</volume><fpage>723</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.039</pub-id><pub-id pub-id-type="pmid">23439124</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Experimental and theoretical approaches to conscious processing</article-title><source>Neuron</source><volume>70</volume><fpage>200</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.03.018</pub-id><pub-id pub-id-type="pmid">21521609</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Depireux</surname><given-names>DA</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name><name><surname>Klein</surname><given-names>DJ</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>85</volume><fpage>1220</fpage><lpage>1234</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.85.3.1220</pub-id><pub-id pub-id-type="pmid">11247991</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elgueda</surname><given-names>D</given-names></name><name><surname>Duque</surname><given-names>D</given-names></name><name><surname>Radtke-Schuller</surname><given-names>S</given-names></name><name><surname>Yin</surname><given-names>P</given-names></name><name><surname>David</surname><given-names>SV</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name><name><surname>Fritz</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>State-dependent encoding of sound and behavioral meaning in a tertiary region of the ferret auditory cortex</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>447</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0317-8</pub-id><pub-id pub-id-type="pmid">30692690</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Englitz</surname><given-names>B</given-names></name><name><surname>David</surname><given-names>SV</given-names></name><name><surname>Sorenson</surname><given-names>MD</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MANTA--an open-source, high density electrophysiology recording suite for MATLAB</article-title><source>Frontiers in Neural Circuits</source><volume>7</volume><elocation-id>69</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2013.00069</pub-id><pub-id pub-id-type="pmid">23653593</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>A</given-names></name><name><surname>Rudin</surname><given-names>C</given-names></name><name><surname>Dominici</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>All models are wrong, but many are useful: Learning a variable’s importance by studying an entire class of prediction models simultaneously</article-title><source>Journal of Machine Learning Research</source><volume>20</volume><fpage>1</fpage><lpage>81</lpage><pub-id pub-id-type="pmid">34335110</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Folstein</surname><given-names>JR</given-names></name><name><surname>Palmeri</surname><given-names>TJ</given-names></name><name><surname>Gauthier</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Category learning increases discriminability of relevant object dimensions in visual cortex</article-title><source>Cerebral Cortex</source><volume>23</volume><fpage>814</fpage><lpage>823</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs067</pub-id><pub-id pub-id-type="pmid">22490547</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Experience-dependent representation of visual categories in parietal cortex</article-title><source>Nature</source><volume>443</volume><fpage>85</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/nature05078</pub-id><pub-id pub-id-type="pmid">16936716</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname><given-names>JB</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name><name><surname>Klein</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1216</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1038/nn1141</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname><given-names>JB</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Adaptive changes in cortical receptive fields induced by attention to complex sounds</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>2337</fpage><lpage>2346</lpage><pub-id pub-id-type="doi">10.1152/jn.00552.2007</pub-id><pub-id pub-id-type="pmid">17699691</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goard</surname><given-names>MJ</given-names></name><name><surname>Pho</surname><given-names>GN</given-names></name><name><surname>Woodson</surname><given-names>J</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinct roles of visual, parietal, and frontal motor cortices in memory-guided sensorimotor decisions</article-title><source>eLife</source><volume>5</volume><elocation-id>13764</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13764</pub-id><pub-id pub-id-type="pmid">27490481</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>L</given-names></name><name><surname>Weems</surname><given-names>JT</given-names></name><name><surname>Walker</surname><given-names>WI</given-names></name><name><surname>Levichev</surname><given-names>A</given-names></name><name><surname>Jaramillo</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Choice-selective neurons in the auditory cortex and in its striatal target encode reward expectation</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>3687</fpage><lpage>3697</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2585-18.2019</pub-id><pub-id pub-id-type="pmid">30837264</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Matysiak</surname><given-names>A</given-names></name><name><surname>Heil</surname><given-names>P</given-names></name><name><surname>König</surname><given-names>R</given-names></name><name><surname>Brosch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Persistent neural activity in auditory cortex is related to auditory working memory in humans and nonhuman primates</article-title><source>eLife</source><volume>5</volume><elocation-id>15441</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.15441</pub-id><pub-id pub-id-type="pmid">27438411</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaramillo</surname><given-names>S</given-names></name><name><surname>Borges</surname><given-names>K</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Auditory thalamus and auditory cortex are equally modulated by context during flexible categorization of sounds</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>5291</fpage><lpage>5301</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4888-13.2014</pub-id><pub-id pub-id-type="pmid">24719107</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karabatsos</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Marginal maximum likelihood estimation methods for the tuning parameters of ridge, power ridge, and generalized ridge regression</article-title><source>Communications in Statistics - Simulation and Computation</source><volume>47</volume><fpage>1632</fpage><lpage>1651</lpage><pub-id pub-id-type="doi">10.1080/03610918.2017.1321119</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwon</surname><given-names>SE</given-names></name><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Minamisawa</surname><given-names>G</given-names></name><name><surname>O’Connor</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sensory and decision-related activity propagate in a cortical feedback loop during touch perception</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1243</fpage><lpage>1249</lpage><pub-id pub-id-type="doi">10.1038/nn.4356</pub-id><pub-id pub-id-type="pmid">27437910</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyers</surname><given-names>EM</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dynamic population coding of category information in inferior temporal and prefrontal cortex</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>1407</fpage><lpage>1419</lpage><pub-id pub-id-type="doi">10.1152/jn.90248.2008</pub-id><pub-id pub-id-type="pmid">18562555</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niwa</surname><given-names>M</given-names></name><name><surname>Johnson</surname><given-names>JS</given-names></name><name><surname>O’Connor</surname><given-names>KN</given-names></name><name><surname>Sutter</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Active engagement improves primary auditory cortical neurons’ ability to discriminate temporal modulation</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>9323</fpage><lpage>9334</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5832-11.2012</pub-id><pub-id pub-id-type="pmid">22764239</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niwa</surname><given-names>M</given-names></name><name><surname>Johnson</surname><given-names>JS</given-names></name><name><surname>O’Connor</surname><given-names>KN</given-names></name><name><surname>Sutter</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Activity related to perceptual judgment and action in primary auditory cortex</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3193</fpage><lpage>3210</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0767-11.2012</pub-id><pub-id pub-id-type="pmid">22378891</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orlandi</surname><given-names>JG</given-names></name><name><surname>Abdolrahmani</surname><given-names>M</given-names></name><name><surname>Aoki</surname><given-names>R</given-names></name><name><surname>Lyamzin</surname><given-names>DR</given-names></name><name><surname>Benucci</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Distributed context-dependent choice information in mouse posterior cortex</article-title><source>Nature Communications</source><volume>14</volume><elocation-id>192</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-35824-6</pub-id><pub-id pub-id-type="pmid">36635318</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>Khan</surname><given-names>AG</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Nemri</surname><given-names>A</given-names></name><name><surname>Orsolic</surname><given-names>I</given-names></name><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning enhances sensory and multiple non-sensory representations in primary visual cortex</article-title><source>Neuron</source><volume>86</volume><fpage>1478</fpage><lpage>1490</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.037</pub-id><pub-id pub-id-type="pmid">26051421</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raybuck</surname><given-names>JD</given-names></name><name><surname>Lattal</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Bridging the interval: theory and neurobiology of trace conditioning</article-title><source>Behavioural Processes</source><volume>101</volume><fpage>103</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2013.08.016</pub-id><pub-id pub-id-type="pmid">24036411</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinert</surname><given-names>S</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Goltstein</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mouse prefrontal cortex represents learned rules for categorization</article-title><source>Nature</source><volume>593</volume><fpage>411</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03452-z</pub-id><pub-id pub-id-type="pmid">33883745</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodgers</surname><given-names>CC</given-names></name><name><surname>DeWeese</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural correlates of task switching in prefrontal cortex and primary auditory cortex in a novel stimulus selection task for rodents</article-title><source>Neuron</source><volume>82</volume><fpage>1157</fpage><lpage>1170</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.031</pub-id><pub-id pub-id-type="pmid">24908492</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>JE</given-names></name><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Prefrontal cortex activity during flexible categorization</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>8519</fpage><lpage>8528</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4837-09.2010</pub-id><pub-id pub-id-type="pmid">20573899</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Rupesh</surname><given-names>KC</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>A1-category</data-title><version designator="swh:1:rev:aaf03946fae24eac277d6d74d498edf83a70786a">swh:1:rev:aaf03946fae24eac277d6d74d498edf83a70786a</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:6a8b25828ea7d086da7b9411d950d911f72b4f3c;origin=https://github.com/rupeshjnu/A1-Category;visit=swh:1:snp:ec46ef14f9c68529c00e0f8be64b90826428a515;anchor=swh:1:rev:aaf03946fae24eac277d6d74d498edf83a70786a">https://archive.softwareheritage.org/swh:1:dir:6a8b25828ea7d086da7b9411d950d911f72b4f3c;origin=https://github.com/rupeshjnu/A1-Category;visit=swh:1:snp:ec46ef14f9c68529c00e0f8be64b90826428a515;anchor=swh:1:rev:aaf03946fae24eac277d6d74d498edf83a70786a</ext-link></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>DM</given-names></name><name><surname>Sundararajan</surname><given-names>J</given-names></name><name><surname>Mooney</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A cortical filter that learns to suppress the acoustic consequences of movement</article-title><source>Nature</source><volume>561</volume><fpage>391</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0520-5</pub-id><pub-id pub-id-type="pmid">30209396</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Selezneva</surname><given-names>E</given-names></name><name><surname>Oshurkova</surname><given-names>E</given-names></name><name><surname>Scheich</surname><given-names>H</given-names></name><name><surname>Brosch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Category-specific neuronal activity in left and right auditory cortex and in medial geniculate body of monkeys</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0186556</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0186556</pub-id><pub-id pub-id-type="pmid">29073162</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swaminathan</surname><given-names>SK</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Preferential encoding of visual categories in parietal cortex compared with prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>315</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1038/nn.3016</pub-id><pub-id pub-id-type="pmid">22246435</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tajima</surname><given-names>S</given-names></name><name><surname>Koida</surname><given-names>K</given-names></name><name><surname>Tajima</surname><given-names>CI</given-names></name><name><surname>Suzuki</surname><given-names>H</given-names></name><name><surname>Aihara</surname><given-names>K</given-names></name><name><surname>Komatsu</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Task-dependent recurrent dynamics in visual cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>26868</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.26868</pub-id><pub-id pub-id-type="pmid">28737487</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xin</surname><given-names>Y</given-names></name><name><surname>Zhong</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>T</given-names></name><name><surname>Pan</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>N-L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sensory-to-category transformation via dynamic reorganization of ensemble structures in mouse auditory cortex</article-title><source>Neuron</source><volume>103</volume><fpage>909</fpage><lpage>921</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.06.004</pub-id><pub-id pub-id-type="pmid">31296412</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Kwon</surname><given-names>SE</given-names></name><name><surname>Severson</surname><given-names>KS</given-names></name><name><surname>O’Connor</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Origins of choice-related activity in mouse somatosensory cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>127</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1038/nn.4183</pub-id><pub-id pub-id-type="pmid">26642088</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>P</given-names></name><name><surname>Strait</surname><given-names>DL</given-names></name><name><surname>Radtke-Schuller</surname><given-names>S</given-names></name><name><surname>Fritz</surname><given-names>JB</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dynamics and hierarchical encoding of non-compact acoustic categories in auditory and frontal cortex</article-title><source>Current Biology</source><volume>30</volume><fpage>1649</fpage><lpage>1663</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.02.047</pub-id><pub-id pub-id-type="pmid">32220317</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>L</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Shi</surname><given-names>C</given-names></name><name><surname>Zhou</surname><given-names>L</given-names></name><name><surname>Tian</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The causal role of auditory cortex in auditory working memory</article-title><source>eLife</source><volume>10</volume><elocation-id>64457</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.64457</pub-id><pub-id pub-id-type="pmid">33913809</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85706.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>King</surname><given-names>Andrew J</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>This study provides an important contribution to our understanding of the neural basis for the categorical perception of sounds. Although the number of animals included is small, solid evidence is presented to show how categorical information emerges in the ferret primary auditory cortex following sound presentation and persists until a behavioral response is made. The work will be of interest to neuroscientists interested in the neural representation of task–related variables in sensory cortex during decision–making tasks.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85706.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Dynamics and maintenance of categorical responses in primary auditory cortex during task engagement&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Andrew King as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. More information on how the linear regression analysis used to separate auditory and category–related activity was carried out is needed. This analysis should also be expanded by including other task–relevant parameters (licking, reward, uninstructed movement) in order to provide stronger evidence that the changes in A1 activity represent a categorical response rather than a premotor response or signals related to reward expectation. Related to this point, the reviewers were concerned that the effects reported are very small.</p><p>2. More details of the population decoding are needed and there are many places where important methodological and other information is missing (see individual reviewer comments).</p><p>3. The naïve animal included in the study was not thought to be an ideal control. Evidence that A1 neurons encode learned categories would be stronger if the comparison could be made with ferrets that have been pre–trained on the task structure. i.e. are performing the task, licking, receiving rewards, etc, but have not learned the stimulus categories. If possible, please provide this more appropriate control.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>In this study, Chillale et al. investigate auditory cortex population dynamics during sound categorization. The authors train ferrets in a delay go/nogo task and record neuronal activity with multielectrode arrays. The main finding is that learned categories are encoded in A1 population activity, both in a task–engaged and a passive setting. The task–engaged category representation persists during the delay, but its activity pattern is uncorrelated with that during stimulus presentation. Further analyses show that the 'nogo' category sound representation is suppressed during task engagement and that sensory encoding during stimulus presentation is degraded when the ferret makes a mistake. The authors conclude that the A1 category representation is an early contributor to auditory categorization.</p><p>Overall, the study uses an elegant task design and provides important insights into the encoding of learned categories early in sensory processing. The task, having a delay period between stimulus presentation and response window, allows the authors to address how the neuronal representation evolves in absence of the stimulus and before the onset of motor behavior. The finding that neural activity during stimulus presentation and delay periods encodes learned categories, but is uncorrelated, is particularly intriguing, as it suggests complex circuit dynamics beyond sensory processing in A1. In addition, the use of stimuli varying in click rates rather than, the more common, sound frequency makes the results less sensitive to sampling biases (i.e. through tonotopy). In general, the focus of this study on characterizing population dynamics rather than describing single–neuron responses provides an interesting contrast to previous studies on sound categorization.</p><p>I have two suggestions for how the conclusions could be strengthened and presented in a better interpretable way. The first suggestion concerns the approach to disentangle stimulus from the category–related activity and its description in the manuscript, and the second is regarding the question of whether the category representation is indeed a learned sensory representation, or could reflect other task–related aspects. I will detail both below.</p><p>1. The authors use a linear regression model to disambiguate stimulus–specific and category–specific population activity. They then use the learned regressor weights to project population activity onto a category coding dimension. However, from the manuscript, it cannot be inferred whether this model can isolate sensory– and category–related activity. The methods state that the sensory regressor assumes a linear relationship between neural activation and click rate. I am not convinced that this is always the case in the auditory cortex. In addition, since there is a stable mapping between click rate and category identity, the two regressors are not independent, which can lead to unreliable estimation of regression weights and lower statistical power (multicollinearity). This problem potentially extends to the method for calculating the projection of activity using the model weights, the projection axes could be not independent or orthogonal. Therefore, it is hard to determine if the category encoding projection is unique to category encoding. The model also lacks other behavioral parameters, like licking, reward, and uninstructed movement parameters, that therefore go unaccounted for.</p><p>In order to address these concerns, the authors should amend the regression model with the other task–relevant parameters, and describe in more detail how it was constructed and fit (e.g. showing a design matrix and/or schematic or toy model illustrating how projections were made), report on its performance (e.g. Rsquared) and show that their choice of regression parameters, and method of calculating projections, leads to separable dimensions/projection axes. In addition, the authors can explore whether single neuron click rate tuning (in naive animals) indeed does not give rise to any 'categorical response'.</p><p>2. The authors compare their findings in trained animals to passive recordings in one naive animal. This comparison is used to argue for a learned component of the category representation. However, this finding is (to some degree) confounded with other learned task–related behaviors/associations that covary with the learned categories.</p><p>The conclusions of this study would be vastly strengthened if a comparison was done with &quot;naive&quot; animals that have been pre–trained on the task structure. i.e. are performing the task, licking, receiving rewards, etc, but have not learned the stimulus categories (yet). I would find it very useful to know whether the 'categorical response' is absent in behaving animals that did not learn the category association. This approach would also allow the authors to more directly address the specificity of the 'nogo' suppression with learned behavioral inhibition and to compare the influence of motor planning on the category representation during the delay period.</p><p>In addition to the two main suggestions, I have some more detailed comments on how the authors could improve their manuscript.</p><p>1. Clarity and precision of method descriptions. Several key methods are hard to follow, I listed some questions in the bullet points below:</p><p>As mentioned above, the model description is unclear, what is t, time, or trial?</p><p>When describing trial–averaged data, what was averaged, frames in a trial, or trial repetitions?</p><p>What linear decoder was used?</p><p>Was the whole task done head–fixed?</p><p>The section on surgical procedures is imprecise, were multiple craniotomies performed? It says the craniotomies were made into cement. How did the craniotomies allow for the visual identification of A1 regions?</p><p>2. Clarity and precision of figure legends and statistics descriptions. Often it is not clear from text or legends if a plot shows data from one or both animals (e.g. Figure 2b, but also others), what information the error bars display (e.g. Figure 1b,c Figure 2c), to which time–bin decoders are trained/regressors are fit (e.g. Figure 4a), and what certain figure elements, like black bars, represent (e.g. Figure 3f, 4d). Some statistical tests are only reported in text and not in the respective figure and legends, some vice versa (eg. Figure 2e). Some labels are switched (Figure 2b).</p><p>3. In the analysis of error trials, it seems both misses and false alarms are combined. However if the hypothesis is that in nogo trials the category representation, and hence behavioral action, is suppressed, shouldn't there be an interesting difference between misses and false alarms? This should be explored to strengthen the interpretation of the results.</p><p>4. The discussion and clarity of the interpretations of results could be improved, specifically regarding the following questions:</p><p>Is the interpretation of the uncorrelated stim and delay period decoders (Figure 2b) that different neurons are responsible for the encoding? Are there alternative interpretations?</p><p>Can overall changes in population activity (more firing, attention,..) explain the trial–to–trial correlation of stimulus period and delay period activity (Figure 4b)?</p><p>It would be very interesting to discuss in more detail how this study's findings relate to the observations on a single neuron level (Xin et al., 2019).</p><p>The direction of argumentation is unclear when it comes to the question of whether the feedback–related activity can explain the results. The authors could also consider work in the somatosensory system (e.g. Yang et al., Nat Neuro, 2016).</p><p>If underlying rotational dynamics are suspected, would those not lead to a gradual shift in correlation rather than an abrupt switch?</p><p>5. The authors state in the first paragraph of the discussion that encoding of behavioral categories was not observed in the naive animal. Does this refer to Figure S4? I do not see any data supporting this claim.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The authors trained two ferrets to discriminate high and low–rate click trains with target and non–target categories each comprised of three distinct rates with one animal trained to treat fast rates as targets and the second to treat slow rates as targets. In each case animals are rewarded for licking targets and required to refrain from licking non–target trials. Additional complexity is imposed by ferrets being required to withhold their response until a delay period (indicated with an LED) ends. Requiring that animals wait for this extra delay period offers the potential to parse out sensory, categorical, and motor aspects of the neural response.</p><p>Neural recordings are made in passive and active configurations for every neuron. The authors use population decoding to explore the emergence of categorical responses through the trial duration with their key finding being that categorical information exists during the stimulus, the delay period, and the response period, whereas sensory information is predominantly encoded in the stimulus period. During passive listening stimulus and (some) category information exists in the stimulus, but not the later epochs.</p><p>Broadly speaking this study confirms similar findings relating to the time course over which single neuron choice probabilities emerge in A1 (which are closely related to categorical perception in animals with good task performance, as they quantify the ability to decode the class of response across multiple stimulus values) from e.g. the Sutter lab, the Bizley lab, the Jaramillo lab.</p><p>I was left a little uncertain as to how large the conceptual advance was here, and a little unsatisfied that I don't know anything about the neural responses within the population (or even how the population response is being modelled, see comments below). For example, is the category sensitivity a consequence of a few category–tuned neurons, or is it an emergent property only visible in the population? How does the category selectivity compare to single neurons decoded over analogous time windows? What is the added value of combining information across small groups of neurons? I also don't follow the argument for why their data support that delay activity might be feedback activity (although I agree this is a perfectly plausible theoretical argument).</p><p>I have some concerns about to what extent the 'categorical' response really represents an abstraction of the stimulus class, as opposed to a premotor response or feedback from an area generating such signals. In this regard the observation that activity during error trials for all but the latest epochs of the trial is noisy / chance level rather than below chance is reassuring; however, the 'error' trials here include two categories of behaviour – both misses (where there was no motor response) and false alarms (where the motor response was early). This analysis would be more convincing if each class of response was separated out.</p><p>I would also like more information on the population decoding approaches. The authors apply a regression model which is an elegant solution to try and tease apart the confounded sensory and category information. However, the coefficient of partial determination (i.e. the variance explained by one or another factor) is tiny – on average ~ 1% of the overall variance. This begs the question of how good the linear models are in the first place, and what proportion of the explainable variance 1% accounts for (maybe it's a large fraction but without more information about model fit we can't assess this). In fact, the sensory information also shows a u–shaped function, being high during the stimulus, low in the delay then nearly as high as the stimulus period in the response window. This doesn't seem to fit with the narrative put forwards in the manuscript. There aren't sufficient details (or code) in the methods to work out what is actually modelled – what is the neural response at time t and how does it relate to the population of units (i.e. is it the average spike rate across the population or a vector of unit spike rates or a matrix of spike rates over time… ?). Without this information, it makes it very hard to understand what is being projected back onto the regression coefficients.</p><p>For the linear decoder more details (or as a minimum a reference) are needed – is it a Foffani and Moxon style Euclidean distance decoder, an SVN, or … ? I presume 2A is the result of the linear decoder? It would be nice to see something a little closer to the raw data here instead of just mean {plus minus}SD. 2B is also the linear decoder. Generally speaking, there are insufficient details in the methods for the population decoding to really understand what was run, and even less so to replicate their study. More details need to be provided here (and ideally the code released alongside the paper).</p><p>I would have liked the information about the population size to be in the Results section rather than only buried deep in the methods; the populations themselves are really quite small (mean 5 / 11 neurons in the two animals) which is useful in interpreting the modest performance of the decoder (which is clearly above chance but not that much so). Also how confident are they that all units are in A1 as the array sounds like it's quite large (potentially larger than A1) to me?</p><p>There are many places in the manuscript where it's not obvious whether the data is from one animal or both (one assumes one animal, as the figures list only a single contingency for high/low rates). The data for both animals are very clearly laid out in the supplemental material but not always well described in the main manuscript.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>This work investigated the activity of neurons from the primary auditory cortex (A1) of ferrets performing a click–rate categorization go/no–go task or passively listening to these sounds. The authors found that the population of recorded A1 neurons shows a different firing pattern for go vs. no–go stimuli, not only during the stimulus presentation but also during a delay period before the licking response. Prediction of the go vs. no–go categories via neural decoding analysis revealed that these categories were decodable during both the stimulus and delay periods, but the population code was different between these two periods.</p><p>The authors provide clear evidence of differences in neural activity patterns for correct trials with go vs no–go stimuli. However, it is not completely clear that these observations reflect auditory categorization as the authors suggest. Most of the data presented seems consistent with alternative interpretations such as a representation of expected reward or pre–motor signals in the auditory cortex. For example: (1) the differences in neural activity between go and no–go stimuli are not present during the passive presentation (Figure 1f) when animals are presumably not licking or expecting reward; (2) the dynamics of neural activity changes consistently with movement when comparing (invalid) early licks, (invalid) late licks and (valid) hit trials (Figure 4c); and (3) the population code that enables decoding of go vs no–go stimuli changes between the stimulus presentation period and the delay period, which suggests a change in what is being represented during these periods (which could be mostly stimulus identity in the first period and motor–preparation signals in the second period). As such, the claim that neural activity reflects the categorization of the stimuli rather than the representation of other variables does not seem fully supported.</p><p>The authors try to address some of these concerns in the discussion by suggesting that motor–related activity is expected to have a short latency (~100 ms). However, from their experiments, it seems difficult to rule out that signals related to motor preparation or reward expectation (at possibly multiple latencies) are the main drivers of the observed effects.</p><p>If we define perceptual categorization as a maximization of perceptual differences between categories and a minimization of the differences within a category, investigating the neural representation of auditory categories may require a more nuanced comparison of how well one can decode stimuli within vs. across categories from neural activity.</p><p>– The manuscript would benefit from a discussion of alternative explanations related to reward expectation.</p><p>– The differences in neural activity seem compelling, but the author may want to de–emphasize the idea that these changes are associated with a neural representation of auditory categories.</p><p>– Figure 1e: because the structure can appear from random data when sorted, a supplementary figure showing neurons sorted by the delay during passive would illustrate that effects shown in this figure are not just the result of sorting for the active condition.</p><p>– It would be useful to clarify whether the &quot;increase&quot; associated with Figure 1f (during the delay period) is with respect to the spontaneous or sound–evoked activity.</p><p>– Clarify what &quot;R.W&quot; means. I don't think that is a standard acronym.</p><p>– Figure 1f: specify what period(s) of activity the modulation index refers to.</p><p>– The authors need to clarify whether the animals are head–fixed or freely moving during training and recordings. While they mentioned &quot;To obtain stable neurophysiological recordings we implanted the ferrets with a stainless steel headpost&quot;, it's not clear when the headpost was used since the electrodes were chronically implanted.</p><p>– Authors should also specify how sounds were delivered (Figure 1 seems to indicate the ferrets had headphones).</p><p>– Authors should be clearer about the passive stimulation sessions. Are the animals licking? are there other differences compared to the active sessions (e.g., inter–trial interval)?</p><p>– The first mention of &quot;the naive animal&quot; comes out of nowhere. The authors should introduce that there is a naive animal used for control experiments.</p><p>– Figure 2 caption: I don't know what &quot;resp.&quot; means.</p><p>– Figure 4C: y–label should say &quot;categorical&quot;.</p><p>– Figure 5a: the caption says &quot;cyan&quot; but it looks purple to me.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85706.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. More information on how the linear regression analysis used to separate auditory and category–related activity was carried out is needed. This analysis should also be expanded by including other task–relevant parameters (licking, reward, uninstructed movement) in order to provide stronger evidence that the changes in A1 activity represent a categorical response rather than a premotor response or signals related to reward expectation. Related to this point, the reviewers were concerned that the effects reported are very small.</p></disp-quote><p>We thank the reviewers for their detailed suggestions that have helped us improve the manuscript. Briefly, we have made several main edits to the manuscript and provided the clarifications as requested by the reviewers. For instance, we have amended our linear regression model to include more task variables (licking and reward), and have added a supplementary figure describing this analysis (new Figure 2—figure supplement 5). The procedure for linear regression using more task variables, its design matrix and the regularization used were added with more information to the methods section. The percentage of variance explained is small and the same has been observed in other studies involving similar procedures, for example, Musal et al., 2019. We provide some modeling results to discuss this latter point (see Figure “CPD for category regressor as a function of noise strength” in response to Reviewer 2).</p><disp-quote content-type="editor-comment"><p>2. More details of the population decoding are needed and there are many places where important methodological and other information is missing (see individual reviewer comments).</p></disp-quote><p>We added an extensive description of the population decoding and other technical points to the manuscript. We have greatly revised and improved the method sections to contain all details required by the reviewers.</p><disp-quote content-type="editor-comment"><p>3. The naïve animal included in the study was not thought to be an ideal control. Evidence that A1 neurons encode learned categories would be stronger if the comparison could be made with ferrets that have been pre–trained on the task structure. i.e. are performing the task, licking, receiving rewards, etc, but have not learned the stimulus categories. If possible, please provide this more appropriate control.</p></disp-quote><p>We agree with this comment. However, our study’s main focus was to disentangle the task variables, especially sensory and categorical, and to investigate their population-level coding to understand their link with categorization. We introduced a long delay period after the stimulus to study how categories emerge and are maintained in a goal-directed behavior. Studying the evolution of categorical responses in A1 through learning is definitely one of our future goals. Consequently, adding a naive animal that was pre-trained on the task structure is beyond the scope of this study.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>In this study, Chillale et al. investigate auditory cortex population dynamics during sound categorization. The authors train ferrets in a delay go/nogo task and record neuronal activity with multielectrode arrays. The main finding is that learned categories are encoded in A1 population activity, both in a task–engaged and a passive setting. The task–engaged category representation persists during the delay, but its activity pattern is uncorrelated with that during stimulus presentation. Further analyses show that the 'nogo' category sound representation is suppressed during task engagement and that sensory encoding during stimulus presentation is degraded when the ferret makes a mistake. The authors conclude that the A1 category representation is an early contributor to auditory categorization.</p><p>Overall, the study uses an elegant task design and provides important insights into the encoding of learned categories early in sensory processing. The task, having a delay period between stimulus presentation and response window, allows the authors to address how the neuronal representation evolves in absence of the stimulus and before the onset of motor behavior. The finding that neural activity during stimulus presentation and delay periods encodes learned categories, but is uncorrelated, is particularly intriguing, as it suggests complex circuit dynamics beyond sensory processing in A1. In addition, the use of stimuli varying in click rates rather than, the more common, sound frequency makes the results less sensitive to sampling biases (i.e. through tonotopy). In general, the focus of this study on characterizing population dynamics rather than describing single–neuron responses provides an interesting contrast to previous studies on sound categorization.</p></disp-quote><p>We thank the reviewer for the overall positive feedback and we address the specific comments below.</p><disp-quote content-type="editor-comment"><p>I have two suggestions for how the conclusions could be strengthened and presented in a better interpretable way. The first suggestion concerns the approach to disentangle stimulus from the category–related activity and its description in the manuscript, and the second is regarding the question of whether the category representation is indeed a learned sensory representation, or could reflect other task–related aspects. I will detail both below.</p><p>1. The authors use a linear regression model to disambiguate stimulus–specific and category–specific population activity. They then use the learned regressor weights to project population activity onto a category coding dimension. However, from the manuscript, it cannot be inferred whether this model can isolate sensory– and category–related activity. The methods state that the sensory regressor assumes a linear relationship between neural activation and click rate. I am not convinced that this is always the case in the auditory cortex. In addition, since there is a stable mapping between click rate and category identity, the two regressors are not independent, which can lead to unreliable estimation of regression weights and lower statistical power (multicollinearity). This problem potentially extends to the method for calculating the projection of activity using the model weights, the projection axes could be not independent or orthogonal. Therefore, it is hard to determine if the category encoding projection is unique to category encoding. The model also lacks other behavioral parameters, like licking, reward, and uninstructed movement parameters, that therefore go unaccounted for.</p><p>In order to address these concerns, the authors should amend the regression model with the other task–relevant parameters, and describe in more detail how it was constructed and fit (e.g. showing a design matrix and/or schematic or toy model illustrating how projections were made), report on its performance (e.g. Rsquared) and show that their choice of regression parameters, and method of calculating projections, leads to separable dimensions/projection axes. In addition, the authors can explore whether single neuron click rate tuning (in naive animals) indeed does not give rise to any 'categorical response'.</p></disp-quote><p>These are all fair points. We address below the reviewer’s suggestions one by one. First, we provide more details on how the regression is designed to deal with multicollinearity. Furthermore, we assess effects of co-linearity using a toy model. We then verify that including more task variables (licking and reward) in the regression model does not significantly change the sensory and category axes. Lastly, we show in the naive animal that the choice of the sensory axis is relevant for describing a purely sensory response, and that the category regressor is, as expected, irrelevant for fitting the naive response.</p><p>Multicollinearity:</p><p>The design matrix for linear regression consists of sensory (click rates 4, 8, 12, 16, 20, 24 Hz) and category (-1 for No-Go and +1 Go) regressors. Inherently to our experimental paradigm, sensory and category regressors are correlated (ρ=0.88 n=35 sessions in Ferret P; ρ=0.84, n=38 sessions in Ferret T; Pearson correlation). We performed regularization during the regression procedure to reduce the impact of correlated variables (Karabotos et al., 2017). Furthermore, we made sure to discard the contribution of other regressors when we projected onto a regression axis.</p><p>Ridge regression<bold>.</bold> We used ridge regression to minimize the overfitting of the model and diminish the impact of correlated variables. The ridge parameters are calculated using the marginal maximum likelihood method from Karabotos et al., 2017. The efficacy of this method is tested using a model of a hypothetical neuron tuned to both sensory and category features. We simulated its neural response to the actual stimuli presented during a recording session and generated spiking activity as follows:</p><p><inline-formula><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mtext>Sensory</mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mtext>Category</mml:mtext><mml:mo>=</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>∗</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> where <italic>r<sub>i</sub></italic> (<italic>t</italic> )=0 for <italic>t</italic>&lt;0 and <italic>t</italic>&gt;1.1, <italic>β</italic><sub>1</sub>(<italic>t</italic> )=0 and <italic>β</italic><sub>1</sub>(<italic>t</italic> )=1 otherwise and <italic>β</italic><sub>2</sub>(<italic>t</italic> )=0 for <italic>t</italic>&lt;0 and <italic>β</italic><sub>2</sub>(<italic>t</italic> )=1 otherwise. (0,1) is the gaussian noise and is the noise strength. For a noiseless ɳ <italic><bold>ε</bold></italic> neuron, = 0. By design, this simulated neural response has both sensory and category <italic><bold>ε</bold></italic> contributions in the time period t=0 to t=1.1 during the stimulus, and only category for t &gt;1.1 (panels a and b <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>). We then applied our linear regression model to compute the CPD. As shown in panels c and d in (<xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>) , the regression captured both sensory and category contributions during the stimulus period, as well as only a category contribution during the delay period. This shows that our model was able to disentangle both sensory and category contributions in the neuronal activity.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>Testing the ability of the regression procedure to disentangle sensory and category contributions with modeled neurons.</title><p>A model generated spike counts from both sensory and category regressors during the sound period and from the category regressor during the delay period (see text). The number of trials, number of neurons and sessions were the same as in one example session of Ferret P ( = 0.5). <italic><bold>ε</bold></italic> (<bold>a</bold>) Scatter plot of a model neuron, organized by click rates. (<bold>b</bold>) Average response of all neurons in the model as a function of click rate. (<bold>c</bold>) CPD for the sensory and category regressors. (<bold>d</bold>) Category regressor weights recovered from the model. (<bold>e</bold>) Sensory regressor weights recovered from the model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-sa2-fig1-v2.tif"/></fig><p>Projection on sensory and category axes. We found that the sensory and category neural axes were correlated during the stimulus period of the task (ρ=0.37, p&lt;10<sup>-2</sup>, n=35 sessions in Ferret P; ρ=0.17, p=0.04, n=38 sessions in Ferret T; Pearson correlation). We made sure to separate the contribution of each variable before projecting onto the regression weights. To restrict the projections of activity along each axis (say feature X, that could be category), we first subtracted the response predicted by the model for the other regressor (say feature Y, in this case sensory: <italic>β</italic><sub>1</sub>(<italic>t</italic> )∗ <italic>Sensory</italic>) from the single-trial population activity. We then projected the residual population activity onto the regression weights of feature X. This is now explicitly described in the Methods:</p><p>“We assessed the time-evolution of population activity along sensory- and category-related neural axes defined by the linear regression (Figure 3). This was done by projecting baseline corrected population activity specific to the feature of interest onto category or sensory regressor weights. Therefore, any deviation from zero represents the deviation of population activity along the regression axis away from the projection of baseline activity.</p><p>Regression weights for the active sensory and category neural axes were correlated during the stimulus period (ρ=0.37, p&lt;10<sup>-2</sup>, n=35 sessions in Ferret P; ρ=0.17, p=0.04, n=38 sessions in Ferret T; Pearson correlation). We made sure to separate the contribution of each variable before projecting on the regression weights. For restricting the projections of activity along each axis (say feature X, that could be category), we first subtracted the response predicted by the model for the other regressor (say feature Y, in this case sensory:) from the single-trial population activity. We then projected the residual population activity onto the regression weights of feature X. Projections are therefore computed as follows:</p><p><inline-formula><mml:math id="sa2m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mtext>Proj</mml:mtext><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>te</mml:mtext><mml:mtext>st</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mtext>Category</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>,</p><p>Linear regression with more task variables:</p><p>To make sure that the sensory and category axes captured by the regression were not contaminated by other task variables, we supplemented the design matrix with lick and reward variables (only during the active state) and fitted this expanded regression model. At each time bin, the lick regressor consisted of either 1 or 0 corresponding to presence or absence of licks. Reward regressor also consisted of either 0 (no reward) and 1 (reward, Hit trials) in the response window. Figure 2—figure supplement 5 shows the CPD corresponding to each task variable in both animals.</p><p>It is clear that including more task variables preserves the results described in Figure 3, i.e. that A1 population activity encodes categories during the sound and delay periods upon task engagement. We then verified that the regression weights obtained with the original model of the paper, and with this updated model, were consistent. Indeed, we found high correlation values between the category weights in both models, for both animals and both the sound and delay periods (see <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>).</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>Correlation between regressors with two and four regressor values Distributions of correlation values between category weights independantly obtained from each of the two regression models (with either two [sensory and category] or four [sensory, category, lick and decision] regressors) (n=35 sessions in Ferret P; n=38 sessions in Ferret T).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-sa2-fig2-v2.tif"/></fig><p>Single neuron tuning for naive and trained animals:</p><p>We have examined the single-unit tuning curves in the naive animal. The left panel shows a example neuron and the middle panel is the average tuning response of all neurons, demonstrating a linear relationship between firing rate and stimulus click rate. Overall, neural responses do not show any categorical responses. This is confirmed by the non-significant Coefficient of Partial Determination for the category regressor in the naive animal (Figure 2i).</p><p>To offer more details about the regression, we now show different example neurons exhibiting robust sensory (Figure 2c) and category tuning (Figure 2d) during the stimulus period, or category tuning during the delay period (Figure 2e). Blue solid curves are the neural responses and the magenta (sensory) and dark green (category) are the fits using only sensory and category weights while the dashed line is the linear fit using both regressors.</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><caption><title>(<bold>a</bold>) Example neuron raster plot with trials sorted by click rates. (<bold>b</bold>) Average tuning curve over all neurons (shaded area shows 1 SEM; n=71 neurons).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-sa2-fig3-v2.tif"/></fig><p>This is now in the Results section:</p><p>“Single-neuron activity showed linear relationship with click rates (example in Figure 2c) or robust categorical encoding during and after the stimulus (Figure 2d,e).“</p><disp-quote content-type="editor-comment"><p>2. The authors compare their findings in trained animals to passive recordings in one naive animal. This comparison is used to argue for a learned component of the category representation. However, this finding is (to some degree) confounded with other learned task–related behaviors/associations that covary with the learned categories.</p><p>The conclusions of this study would be vastly strengthened if a comparison was done with &quot;naive&quot; animals that have been pre–trained on the task structure. i.e. are performing the task, licking, receiving rewards, etc, but have not learned the stimulus categories (yet). I would find it very useful to know whether the 'categorical response' is absent in behaving animals that did not learn the category association. This approach would also allow the authors to more directly address the specificity of the 'nogo' suppression with learned behavioral inhibition and to compare the influence of motor planning on the category representation during the delay period.</p></disp-quote><p>This is a fascinating remark. The proposed paradigm would allow one to investigate how the link between stimulus and reward possibly reshapes the reward-elicited activity in auditory cortex. However, our study’s main focus was to focus on the stimulus to category transduction.</p><p>Therefore, adding a naive animal that was pre-trained on the task structure is beyond the scope of this study. Nevertheless, studying the evolution of category responses in A1 through learning is definitely a key future goal.</p><disp-quote content-type="editor-comment"><p>In addition to the two main suggestions, I have some more detailed comments on how the authors could improve their manuscript.</p><p>1. Clarity and precision of method descriptions. Several key methods are hard to follow, I listed some questions in the bullet points below:</p><p>As mentioned above, the model description is unclear, what is t, time, or trial?</p></disp-quote><p>We apologize for this. We have added a full description of the linear regression we performed and how we calculated the projections:</p><p>“A linear decoder trained on classifying categories inherently mixed sensory and category information to decode categories. To disentangle the contributions from sensory features and categories in the population code, we opted for linear regression models to capture the unique contribution of each feature.</p><p>At each time bin, the design matrix for linear regression consists of sensory (click rates 4, 8, 12, 16, 20, 24 Hz) and category (-1 for No-Go and +1 for Go) regressors, as follows:</p><p>r<sub>i</sub> (t )=β<sub>0</sub>(t )+β<sub>1</sub>(t )∗Sensory+β<sub>2</sub>(t )∗Category</p><p>where β<sub>1,2</sub> (t ) are the regressor weights, β<sub>0</sub> (t) a constant, Sensory and Category are the regressor values.</p><p>The model was fitted for each neuron on correct trials (hit Go trials and correct rejections No-Go trials). We used ridge regression to minimize overfitting and diminish the impact of correlated variables. The ridge parameter is calculated using a cross-validated marginal maximum likelihood method<sup>42</sup>. To fit the model, we used the ridgeMML function from http://churchlandlab.labsites.cshl.edu<sup>16</sup>.</p><p>In order to make sure that the sensory and category regressors weights were not contaminated by other task variables, we included lick and reward variables in a separate model fitted on correct and incorrect trials. At each time bin, the lick regressor consisted of either 1 or 0 corresponding to presence or absence of licks. During the hit trials, the reward regressor was set to 1 the time bins in response window when the animal licked and was 0 otherwise. We found that the category and sensory axes were similar in the 2-regressor and the 4-regressor models (Figure 2—figure supplement 5).”</p><disp-quote content-type="editor-comment"><p>When describing trial–averaged data, what was averaged, frames in a trial, or trial repetitions?</p></disp-quote><p>We computed the average over <italic>trial repetitions</italic>. This is now clearly stated:<inline-formula><mml:math id="sa2m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></p><disp-quote content-type="editor-comment"><p>are trial-averaged population vectors for Go and No-Go categories respectively.”</p><p>What linear decoder was used?</p></disp-quote><p>We used linear discriminant classifiers as prescribed in Bagur et al., 2018. Binary linear classifiers were trained to discriminate between Go and No-Go categories (Supplementary Figure 3 in Bagur et al., 2018). We now expanded and clarified the section about decoding in the methods:</p><p>“In each recording session, we constructed time-based binary linear discriminant classifiers<sup>14,40,41</sup> to decode stimulus categories (Go vs No-Go) with 100 ms binning. In brief, for each recording sessions, population vectors were constructed at each time bin and trained with equal number of random Go and No-Go trials (<inline-formula><mml:math id="sa2m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>). Then the population decoding vector is given by<disp-formula id="sa2equ1"><mml:math id="sa2m5"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p><p>Where <inline-formula><mml:math id="sa2m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are trial-averaged population vectors for Go and No-Go categories respectively. The threshold is defined by<disp-formula id="sa2equ2"><mml:math id="sa2m7"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>For each test trial population vector V <sup>test</sup><sub>t</sub> , the linear discriminant function is given by</p><p><inline-formula><mml:math id="sa2m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p>The test trial <inline-formula><mml:math id="sa2m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is assigned to the Go category if Y <sub>t</sub> ≥0 and to the No-Go category otherwise. The assigned category is compared to the ground truth and the proportion correct defines the accuracy of the classifier. Cross-validation was performed 200 times by randomly choosing train (70% of data) and test trials (30% of data).</p><p>Random classifier performance was obtained with 200 label shuffling permutations (the lower bound for the p-value being 1/200 = 0.005) and the comparison was statistically evaluated through permutation tests, comparing the actual performance with the chance-level distribution. Unless mentioned otherwise, all analysis were done using only correct trials (correct rejection No-Go trials and hit Go trials). Temporal evolution of the decoder was computed as the correlation between decoding weight vectors at one time bin against others and time points below chance correlation values were shown as grey in Figure 2b. We also projected the trial averaged activity of test trials onto the unit decoders trained at sound and delay period as shown in Figure 2—figure supplement 4.”</p><disp-quote content-type="editor-comment"><p>Was the whole task done head–fixed?</p></disp-quote><p>Yes, the animals were head-fixed in both training and recording sessions. This is now stated in the Methods:</p><p>“Each recording session consisted of passive and active sessions. Recordings were performed head-fixed in a soundproof chamber. In the passive sessions the water spout was removed.”</p><disp-quote content-type="editor-comment"><p>The section on surgical procedures is imprecise, were multiple craniotomies performed? It says the craniotomies were made into cement. How did the craniotomies allow for the visual identification of A1 regions?</p></disp-quote><p>We have detailed the surgical procedure in the methods:</p><p>“In a separate surgery, we chronically implanted 32-channel metal electrodes arrays (MEA; PtIr, MicroProbes, 8 x 4, electrode of impedance 2.5 MΩ with 0.4 μm distance between the electrodes) over the prior marked auditory cortex. We custom-designed the chronic implant with MEA inserted in a drive-shuttle system having a flexible control of the array vertical movement. The base of the drive is sealed with a stretchable silicon membrane sheet to stop flowing any residues into the drive. Before the implantation, the electrodes are moved down such that the apex popped out of the silicon membrane. Under surgical anesthesia (isoflurane 1 %), we removed the cement above the location marked during the surgery. We then performed a 4 mm x 4 mm craniotomy. This craniotomy allowed us to identify the core regions of the auditory cortex (middle ectosylvian gyrus) by visual inspection of the tip of the ectosylvian gyrus. We carefully removed the transparent dura to ensure that the array penetrated the brain without additional strain. The drive-shuttle system was placed on the brain surface using a stereotaxic apparatus and the entire system was fixed to the skull using bone cement. To minimize vibrations that could be caused by shocks on the drive, the chronic implant was enclosed in a custom-made tube cemented to the implant. Immediately after the surgery we slowly lowered the electrodes and observed physiological activity, allowing us to verify the electrodes moved inside the brain.”</p><disp-quote content-type="editor-comment"><p>2. Clarity and precision of figure legends and statistics descriptions. Often it is not clear from text or legends if a plot shows data from one or both animals (e.g. Figure 2b, but also others), what information the error bars display (e.g. Figure 1b,c Figure 2c), to which time–bin decoders are trained/regressors are fit (e.g. Figure 4a), and what certain figure elements, like black bars, represent (e.g. Figure 3f, 4d). Some statistical tests are only reported in text and not in the respective figure and legends, some vice versa (eg. Figure 2e). Some labels are switched (Figure 2b).</p></disp-quote><p>Most of the results in main figures are shown for one animal such as Figure 1a-d, Figure 2, Figure 3, Figure 4a, 4c,d and Figure 5a,b. The consistency of these results in the second animal is shown in corresponding supplementary figures. We now systematically mention the number of neurons/sessions from either one or two ferrets in each figure caption. We also mention the significance bars in Figure 3f and 4d. Legends in Figure 2b have been corrected.</p><disp-quote content-type="editor-comment"><p>3. In the analysis of error trials, it seems both misses and false alarms are combined. However if the hypothesis is that in nogo trials the category representation, and hence behavioral action, is suppressed, shouldn't there be an interesting difference between misses and false alarms? This should be explored to strengthen the interpretation of the results.</p></disp-quote><p>The reviewer is correct in that more insight can be obtained by looking into the miss and false alarm trials separately. As shown in Figure 5—figure supplement 1, both types of error trials on the delay decoder overlap (panel B), consistent with decoding at chance level (Figure 5a). A trend of reversed trajectories on the response window decoders was observed (FA above misses in the right panel), in line with decoding below chance level in this period (Figure 5a).</p><disp-quote content-type="editor-comment"><p>4. The discussion and clarity of the interpretations of results could be improved, specifically regarding the following questions:</p></disp-quote><p>The discussion has been greatly expanded; we review these changes below.</p><disp-quote content-type="editor-comment"><p>Is the interpretation of the uncorrelated stim and delay period decoders (Figure 2b) that different neurons are responsible for the encoding? Are there alternative interpretations?</p></disp-quote><p>The stimulus and delay decoders are not correlated (Figure 2b), which is consistent with the fact that the category regression weights during stimulus and delay periods (Figure 4a) are not correlated either. We plotted the regression weights for category found during the stimulus period against the delay period. We now included this figure in the manuscript (Figure 4figure supplement 1) to unpack the correlation plot in Figure 4a.</p><disp-quote content-type="editor-comment"><p>Can overall changes in population activity (more firing, attention,..) explain the trial–to–trial correlation of stimulus period and delay period activity (Figure 4b)?</p></disp-quote><p>As a proxy for attention-driven changes in population activity, we compared the structure of population activity changes induced task engagement with the category neural axis extracted from the stimulus period. We found no correlation between these two axes (Author reaponse image 4), indicating that overall changes of population activity driven by attentional or arousal changes are not aligned with the category neural axis.</p><fig id="sa2fig4" position="float"><label>Author response image 4.</label><caption><title>Distribution of correlations between the category regressor weights during the active stimulus period and the weights of state (passive/active) decoders (p =0. 125 t-test, Ferret P, n= 35 sessions).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-sa2-fig4-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>It would be very interesting to discuss in more detail how this study's findings relate to the observations on a single neuron level (Xin et al., 2019).</p><p>The direction of argumentation is unclear when it comes to the question of whether the feedback–related activity can explain the results. The authors could also consider work in the somatosensory system (e.g. Yang et al., Nat Neuro, 2016).</p></disp-quote><p>Thanks for suggesting these lines of discussion; we now elaborate on this point:</p><p>“Similar to a previous study in the mouse<sup>12</sup>, we found that the encoding of stimulus sensory properties within behavioral categories was stable across behavioral states. In Xin et al<sup>12</sup>, the authors found that categorical representations in A1 matched behavioral decision as early as at stimulus offset, and was maintained during several seconds. Such choice-related activity have been demonstrated to be the result of feedforward and feedback flow between primary sensory cortices and downstream regions<sup>22,23</sup>. Our observations are consistent with this view, as we found that perceptual choice influenced the category decoded during the response window (Figure 5a).”</p><disp-quote content-type="editor-comment"><p>If underlying rotational dynamics are suspected, would those not lead to a gradual shift in correlation rather than an abrupt switch?</p></disp-quote><p>Considering the changes in the discussion suggested by the reviewers, the reference to rotational dynamics did not fit anymore in this section. We therefore removed it.</p><disp-quote content-type="editor-comment"><p>5. The authors state in the first paragraph of the discussion that encoding of behavioral categories was not observed in the naive animal. Does this refer to Figure S4? I do not see any data supporting this claim.</p></disp-quote><p>Thanks for pointing this out. We referred to Figure 2i, in which the category CPD is for naive and is insignificant compared to that of the trained animals during the stimulus period. It is now corrected:</p><p>“First, we isolated an encoding of behavioral categories in the population-average during stimulus presentation in both task-engaged and passive listening. This was not observed in a naive animal (Figure 2i).”</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>The authors trained two ferrets to discriminate high and low–rate click trains with target and non–target categories each comprised of three distinct rates with one animal trained to treat fast rates as targets and the second to treat slow rates as targets. In each case animals are rewarded for licking targets and required to refrain from licking non–target trials. Additional complexity is imposed by ferrets being required to withhold their response until a delay period (indicated with an LED) ends. Requiring that animals wait for this extra delay period offers the potential to parse out sensory, categorical, and motor aspects of the neural response.</p><p>Neural recordings are made in passive and active configurations for every neuron. The authors use population decoding to explore the emergence of categorical responses through the trial duration with their key finding being that categorical information exists during the stimulus, the delay period, and the response period, whereas sensory information is predominantly encoded in the stimulus period. During passive listening stimulus and (some) category information exists in the stimulus, but not the later epochs.</p><p>Broadly speaking this study confirms similar findings relating to the time course over which single neuron choice probabilities emerge in A1 (which are closely related to categorical perception in animals with good task performance, as they quantify the ability to decode the class of response across multiple stimulus values) from e.g. the Sutter lab, the Bizley lab, the Jaramillo lab.</p></disp-quote><p>The reviewer is right that our findings are related to the work of these labs. We took care of adding more references to their studies.</p><disp-quote content-type="editor-comment"><p>I was left a little uncertain as to how large the conceptual advance was here, and a little unsatisfied that I don't know anything about the neural responses within the population (or even how the population response is being modelled, see comments below). For example, is the category sensitivity a consequence of a few category–tuned neurons, or is it an emergent property only visible in the population? How does the category selectivity compare to single neurons decoded over analogous time windows? What is the added value of combining information across small groups of neurons? I also don't follow the argument for why their data support that delay activity might be feedback activity (although I agree this is a perfectly plausible theoretical argument).</p></disp-quote><p>We list here the conceptual advances we think we provide with respect to previous studies:</p><list list-type="bullet"><list-item><p>categorical activity emerged upon stimulus presentation in <italic>trained</italic> animals in the population average, <italic>both</italic> in the passive and active states</p></list-item><list-item><p>at the offset of Go sounds, sustained activity built up until lick time (over more than a second), and the encoding format of the categorical information was different between the stimulus and the delay periods</p></list-item><list-item><p>at the population-level, the representation of the No-Go sounds during the stimulus epoch became suppressed upon task engagement</p></list-item><list-item><p>error trials showed no reliable encoding of stimulus sensory features, suggesting that error came from a deficient encoding of the stimulus</p></list-item></list><p>We believe that the revisions made on the manuscript after the reviewers’ suggestions highlight these points much better. In particular, we clarified in the abstract, in the introduction and in the first paragraph of the discussion that the signature of category is found in the population evarge (CPD measure in Figure 2), whereas suppression of the No-Go sounds was found at the population level (when projecting on regressor weights; Figure 3).</p><p>Tuning to behavioral categories. The emergence of category-related activity during stimulus presentation was a property found in the population average. Neurons with significant CPD showed a wide range of values (see <xref ref-type="fig" rid="sa2fig5">Author response image 5</xref>), indicating that this tuning was not driven by a few outliers.</p><fig id="sa2fig5" position="float"><label>Author response image 5.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-sa2-fig5-v2.tif"/></fig><p>The category selectivity was found in the population average (Figure 1—figure supplement 1c,f), and we show in Figure 2c-e the tuning curve of several example neurons, alongside with the fit to the linear regression. These neurons exhibit robust sensory (panel B) and category tuning (panel D) during the stimulus period, or category tuning during the delay period (panel E). Blue solid curves are the neural responses and the magenta (sensory) and dark green (category) are the fits using only sensory and category weights while the dashed line is the linear fit using both regressors. We also included example neurons in the manuscript (Figure 2) to exemplify the results.We now compare the category selectivity of single neurons in the stimulus and delay periods in Figure 4—figure supplement 1. Category regression weights of these two periods are overall uncorrelated, in accordance with the correlation plot in Figure 4a. We note that the weigths do not form distinct clusters.</p><p>Suppression of the population-level categorical responses. The suppression of the No-Go sound along the category axis is a collective property found at the population-level (Figure 3). Upon task engagement, the No-Go responses are more aligned with the baseline activity, leading to asymmetrical representation of the both Go and No-Go stimuli along the baseline active. We performed population-level analysis (linear decoding and projection on regression axes) at the sessions level (i.e., sessions were treated as samples) for two main reasons. First, we believe that finding effects that are consistent across <italic>independent</italic> sessions is an important observation that consolidates our results. Second, it allowed us to characterize how trial-to-trial fluctuations in the categorical signals correlated between the stimulus and delay epochs (Figure 4), which would not be possible with a of the neurons from all sessions.</p><p>As for the interpretations of the delay activity, we are now presenting different alternatives, including a feedback origin, but also reward anticipation.</p><p>“We note that this sustained activity after Go sounds can be caused by at least three different factors.</p><p>First, delay activity in A1 could be the result of a feedback signal from higher-order decision related areas signaling the chosen category and maintaining it in memory by engaging A1 in a network of parietal and frontal areas<sup>33</sup>. In this framework, previous works in the somatosensory system have shown that choice-related information flows bidirectionally between primary and secondary somatosensory cortices, with choice-related information emerging in primary sensory cortex, then fed to downstream areas that further feedback enriched choice-related information to the primary field<sup>34</sup>. Consistent with this hypothesis, we have demonstrated that trial-to-trial fluctuations of categorical responses during the sound period correlate with the amplitude of the delay categorical signal (Figure 4b), possibly suggesting that category-related information during the stimulus and delay periods are part of this communication loop.</p><p>A second interpretation is that delay activity is the result of motor preparation that would unfold over several hundreds of milliseconds<sup>16</sup>. The pattern of activity observed during early trials is consistent with this view, with faster build-up when the animals licked earlier. However, a similar pattern was not observed on false alarm trials, contrary to what would be predicted for this interpretation.</p><p>A last possibility is that delay activity signals reward expectation<sup>35</sup>, a type of response which increases through learning<sup>16,36</sup>. This delay activity would then reflect post-learning residual topdown feedback, or alternatively may be the signature of an eligibility trace, i.e. a persistent activity necessary for bridging the gap between the sound and the response window<sup>37</sup>. Overall, disentangling these different interpretations will require further experiments.”</p><disp-quote content-type="editor-comment"><p>I have some concerns about to what extent the 'categorical' response really represents an abstraction of the stimulus class, as opposed to a premotor response or feedback from an area generating such signals. In this regard the observation that activity during error trials for all but the latest epochs of the trial is noisy / chance level rather than below chance is reassuring; however, the 'error' trials here include two categories of behaviour – both misses (where there was no motor response) and false alarms (where the motor response was early). This analysis would be more convincing if each class of response was separated out.</p></disp-quote><p>The reviewer is correct in that more insight can be obtained by looking into the miss and false alarm trials separately. As shown in Figure 5—figure supplement 1, both types of error trials on the delay decoder overlap (panel B), consistent with decoding at chance level (Figure 5a). A trend of reversed trajectories on the response window decoders was observed (FA above misses in the right panel), in line with decoding below chance level in this period (Figure 5a).</p><p>This figure is now referenced in the results:</p><p>“…we found a decrease in decoding accuracy during the sound period, and a decoding performance at chance level during the delay (Figure 5a,b and Figure 5—figure supplement 1 for separate projections of false alarm and miss trials; decoding accuracy during delay for incorrect trials: p=0.99, permutation test).”</p><disp-quote content-type="editor-comment"><p>I would also like more information on the population decoding approaches. The authors apply a regression model which is an elegant solution to try and tease apart the confounded sensory and category information. However, the coefficient of partial determination (i.e. the variance explained by one or another factor) is tiny – on average ~ 1% of the overall variance. This begs the question of how good the linear models are in the first place, and what proportion of the explainable variance 1% accounts for (maybe it's a large fraction but without more information about model fit we can't assess this). In fact, the sensory information also shows a u–shaped function, being high during the stimulus, low in the delay then nearly as high as the stimulus period in the response window. This doesn't seem to fit with the narrative put forwards in the manuscript. There aren't sufficient details (or code) in the methods to work out what is actually modelled – what is the neural response at time t and how does it relate to the population of units (i.e. is it the average spike rate across the population or a vector of unit spike rates or a matrix of spike rates over time… ?). Without this information, it makes it very hard to understand what is being projected back onto the regression coefficients.</p></disp-quote><p>Our linear regression model was inspired by the methodology described in Musall et al., 2019. Even in the simple tasks described in this cited publicaiton, the task variables contributed less than 10% of the variance for single variable models that by definition overestimates the explained variance (for instance, Figures 4c and 7c of Musall et al., 2019). We assessed the theoretically-expected CPD value as a function of noise in the data using a hypothetical neuron tuned to both sensory and category features. We simulated its neural response to the actual stimuli presented during a recording session. We generated spiking activity as:</p><p>r<sub>i</sub> <italic>(</italic>t <italic>)=</italic>β<italic><sub>0</sub>(</italic>t <italic>)+</italic>β<italic><sub>1</sub>(</italic>t <italic>)</italic>∗Sensory<italic>+</italic>β<italic><sub>1</sub>(</italic>t <italic>)</italic>∗Category<italic>+<bold>ε</bold></italic>∗ɳ <italic>( 0,1)</italic>,</p><p>where <italic>r<sub>i</sub></italic> (<italic>t</italic> )=0 for <italic>t</italic>&lt;0 and <italic>t</italic>&gt;1.1, <italic>β</italic><sub>1</sub>(<italic>t</italic> )=0 and <italic>β</italic><sub>1</sub>(<italic>t</italic> )=1 otherwise and <italic>β</italic><sub>2</sub>(<italic>t</italic> )=0 for <italic>t</italic>&lt;0 and <italic>β</italic><sub>2</sub>(<italic>t</italic> )=1 otherwise. (0,1) is the gaussian noise scaled by the noise strength. For a noiseless neuron, <italic><bold>ε</bold></italic> = 0. By design, this simulated neural response has both sensory and category <italic><bold>ε</bold></italic> contributions during the time-period t=0 to t=1.1 during the stimulus period, and only category during t &gt;1.1 (panels a and b <xref ref-type="fig" rid="sa2fig6">Author response image 6</xref>). Then we applied our linear regression model to compute the CPD (see top sections of the response to reviewers for more details) as function of <italic><bold>ε</bold></italic> (see <xref ref-type="fig" rid="sa2fig6">Author response image 6</xref>).</p><p>We took an example session and used the toy model to generate spike counts from the same number of neurons and trials as in the actual session. We then fitted the regression model on data generated from different noise levels <italic><bold>ε</bold></italic>. For the actual data, we made the assumption that the noise strength can be assessed as the standard deviation σ of stimulus-evoked response. We found σ<sub>ferret P</sub> = 0.94 and σ<sub>ferret P</sub> = 1.41, which corresponds to CPD ~ 0.1 for the simulated neuron, consistent with the values found in the data.</p><fig id="sa2fig6" position="float"><label>Author response image 6.</label><caption><title>Coefficient of partial determination (CPD) for category regressor as a function of noise strength.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-sa2-fig6-v2.tif"/></fig><p>The sensory information during the response window is difficult to sort out since licking activity is taking place during this time period. The hypothesis put forward in the manuscript mostly concerns the stimulus and delay periods, so we did not emphasize this result. Nevertheless, we expanded our linear regression model to test for an influence of licks onto population activity. We supplemented the design matrix with lick and reward variables (only during the active state) and fitted this expanded regression model. At each time bin, the lick regressor consisted of either 1 or 0 corresponding to presence or absence of licks. Reward regressor also consisted of either 0 (no reward) and 1 (reward, Hit trials) in the response window. The figure below shows the CPD corresponding to each task variable in both animals. We found that the sensory regressor explained no more neural activity during the response window, suggesting that lickrelated activity is captured by the sensory regressor.</p><p>We now expanded and clarified the section about regression in the methods:</p><p>“A linear decoder trained on classifying categories inherently mixed sensory and category information to decode categories. To disentangle the contributions from sensory features and categories in the population code, we opted for linear regression models to capture the unique contribution of each feature.</p><p>At each time bin, the design matrix for linear regression consists of sensory (click rates 4, 8, 12, 16, 20, 24 Hz) and category (-1 for No-Go and +1 Go) regressors, as follows:</p><disp-quote content-type="editor-comment"><p>r<sub>i</sub> (t )=β<sub>0</sub>(t )+β<sub>1</sub>(t )∗Sensory+β<sub>2</sub>(t )∗Category</p></disp-quote><p>where <italic>β<sub>1,2</sub> (t )</italic> are the regressor weights, β<sub>0</sub> (t) a constant, Sensory and Category are the regressor values.</p><p>The model was fitted for each neuron on correct trials (hit Go trials and correct rejections No-Go trials). We used ridge regression to minimize overfitting and diminish the impact of correlated variables. The ridge parameter is calculated using a cross-validated marginal maximum likelihood method<sup>42</sup>. To fit the model, we used the ridgeMML function from http://churchlandlab.labsites.cshl.edu <ext-link ext-link-type="uri" xlink:href="http://churchlandlab.labsites.cshl.edu16/">16</ext-link> .</p><p>In order to make sure that the sensory and category regressors weights were not contaminated by other task variables, we included lick and reward variables in a separate model fitted on correct and incorrect trials. At each time bin, the lick regressor consisted of either 1 or 0 corresponding to presence or absence of licks. During the hit trials, the reward regressor was set to 1 the time bins in response window when the animal licked and was 0 otherwise. We found that the category and sensory axes were similar in the 2-regressor and the 4-regressor models (Figure 2—figure supplement 5).”</p><disp-quote content-type="editor-comment"><p>For the linear decoder more details (or as a minimum a reference) are needed – is it a Foffani and Moxon style Euclidean distance decoder, an SVN, or … ? I presume 2A is the result of the linear decoder? It would be nice to see something a little closer to the raw data here instead of just mean {plus minus}SD. 2B is also the linear decoder. Generally speaking, there are insufficient details in the methods for the population decoding to really understand what was run, and even less so to replicate their study. More details need to be provided here (and ideally the code released alongside the paper).</p></disp-quote><p>We used binary linear classifiers, as prescribed in Bagur et al., 2018. A discriminant axis w and a decision threshold B are defined from a training set, and projections of the test set on the w axis are compared to the threshold B for predicting their labels (see <xref ref-type="fig" rid="sa2fig7">Author response image 7</xref>).</p><fig id="sa2fig7" position="float"><label>Author response image 7.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85706-sa2-fig7-v2.tif"/></fig><p>We now expanded the population decoding in the methods section to describe more details on the classifiers are evaluation, accuracy computation and their temporal evolution:“In each recording session, we constructed time-based binary linear discriminant classifiers<sup>14,40,41</sup> to decode stimulus categories (Go vs No-Go) with 100 ms binning. In brief, for each recording sessions, population vectors were constructed at each time bin and trained with equal number of random Go and No-Go trials (<inline-formula><mml:math id="sa2m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>). Then the population decoding vector is given by <inline-formula><mml:math id="sa2m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>Where <inline-formula><mml:math id="sa2m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are trial-averaged population vectors for Go and No-Go categories respectively. The threshold is defined by <inline-formula><mml:math id="sa2m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula> For each test trial population vector V <sup>test</sup><sub>t</sub> , the linear discriminant function is given by <inline-formula><mml:math id="sa2m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>Go</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>The test trial <inline-formula><mml:math id="sa2m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is assigned to the Go category if Y <sub>t</sub> ≥0 and to the No-Go category otherwise. The assigned category is compared to the ground truth and the proportion correct defines the accuracy of the classifier. Cross-validation was performed 200 times by randomly choosing train (70% of data) and test trials (30% of data).</p><p>Random classifier performance was obtained with 200 label shuffling permutations (the lower bound for the p-value being 1/200 = 0.005) and the comparison was statistically evaluated through permutation tests, comparing the actual performance with the chance-level distribution. Unless mentioned otherwise, all analysis were done using only correct trials (correct rejection No-Go trials and hit Go trials). Temporal evolution of the decoder was computed as the correlation between decoding weight vectors at one time bin against others and time points below chance correlation values were shown as grey in Figure 2b. We also projected the trial averaged activity of test trials onto the unit decoders trained at sound and delay period as shown in Figure 2—figure supplement 4.”</p><p>The code is now available in the following repository: https://github.com/rupeshjnu/A1-Category</p><disp-quote content-type="editor-comment"><p>I would have liked the information about the population size to be in the Results section rather than only buried deep in the methods; the populations themselves are really quite small (mean 5 / 11 neurons in the two animals) which is useful in interpreting the modest performance of the decoder (which is clearly above chance but not that much so). Also how confident are they that all units are in A1 as the array sounds like it's quite large (potentially larger than A1) to me?</p></disp-quote><p>We agree that it is best to make the information readily available to the reader in the Results section. We added the following comment regarding the single-session decoding in the Results:</p><p>“Note that decoding was performed at the single-session level (11.3±4.9 neurons per session for ferret P; ±std; n = 35 sessions and 5.2±3.2 neurons per session for ferret T; n = 39 sessions), explaining the modest but above chance-level performance of the decoder.“</p><p>The array size is relatively large (2.8 x 1.2 mm, with 8x4 electrodes and 0.4 μm distance between the electrodes) but perfectly fits within ferret A1 which is about 4-5 mm-long and 3-4 mm-wide (Bizley et al., 2005. <italic>Cerebral Cortex</italic>; Elgueda et al., 2019. <italic>Nature Neuro</italic>). We now detail the procedure for making sure we were in A1 in the methods:</p><p>“Using a stereotaxic apparatus, the headpost was mounted on the skull using methyl methacrylate based dental adhesive resin cement. Stainless steel screws were anchored along the areas surrounding the auditory cortex leaving a cavity for easy access to the auditory cortex. The typical horseshoe shape of the auditory cortex was marked with nail polish. Finally the surrounding areas are filled with poly-methyl methacrylate (PMMA) based bone cement to stabilize the implant. […] Under surgical anesthesia (isoflurane 1 %), we removed the cement above the location marked during the surgery. We then performed a 4 mm x 4 mm craniotomy. This craniotomy allowed us to identify the core regions of the auditory cortex (middle ectosylvian gyrus) by visual inspection of the tip of the ectosylvian gyrus. We carefully removed the transparent dura to ensure that the array penetrated the brain without additional strain. […] Primary auditory cortical responses were identified by analyzing tuning properties to 100 ms tone pips of random frequencies spanning 4 octaves and temporally orthogonal ripple combinations (STRF)<sup>39</sup>. A1 responses show sharp tuning to random tones and single peak, short latency STRFs<sup>5,10,21</sup>.“</p><disp-quote content-type="editor-comment"><p>There are many places in the manuscript where it's not obvious whether the data is from one animal or both (one assumes one animal, as the figures list only a single contingency for high/low rates). The data for both animals are very clearly laid out in the supplemental material but not always well described in the main manuscript.</p></disp-quote><p>Most of the results in the main figures are derived from one animal such as Figure 1a-1d, Figure 2, Figure 3, Figure 4a,c,d and Figure 5a-5b. The validity of these results in the second animal is shown in corresponding supplementary figures. We now mention neuron and session numbers from either one or two ferrets in each figure caption.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>This work investigated the activity of neurons from the primary auditory cortex (A1) of ferrets performing a click–rate categorization go/no–go task or passively listening to these sounds. The authors found that the population of recorded A1 neurons shows a different firing pattern for go vs. no–go stimuli, not only during the stimulus presentation but also during a delay period before the licking response. Prediction of the go vs. no–go categories via neural decoding analysis revealed that these categories were decodable during both the stimulus and delay periods, but the population code was different between these two periods.</p><p>The authors provide clear evidence of differences in neural activity patterns for correct trials with go vs no–go stimuli. However, it is not completely clear that these observations reflect auditory categorization as the authors suggest. Most of the data presented seems consistent with alternative interpretations such as a representation of expected reward or pre–motor signals in the auditory cortex. For example: (1) the differences in neural activity between go and no–go stimuli are not present during the passive presentation (Figure 1f) when animals are presumably not licking or expecting reward; (2) the dynamics of neural activity changes consistently with movement when comparing (invalid) early licks, (invalid) late licks and (valid) hit trials (Figure 4c); and (3) the population code that enables decoding of go vs no–go stimuli changes between the stimulus presentation period and the delay period, which suggests a change in what is being represented during these periods (which could be mostly stimulus identity in the first period and motor–preparation signals in the second period). As such, the claim that neural activity reflects the categorization of the stimuli rather than the representation of other variables does not seem fully supported.</p><p>The authors try to address some of these concerns in the discussion by suggesting that motor–related activity is expected to have a short latency (~100 ms). However, from their experiments, it seems difficult to rule out that signals related to motor preparation or reward expectation (at possibly multiple latencies) are the main drivers of the observed effects.</p></disp-quote><p>We thank the reviewer for the comments and observations on our results. We are totally open to all these interpretations for two main reasons. First, we have observed categorical tuning in the population average, both during passive and task-engaged states. Then, the emergence of early categorical signals and the task-induced suppression of the No-Go sounds at the population-level are independent of the licking activity. Second, we believe that the sustained delay activity whose dynamics scales with the licking action is interesting irrespective of its origin. But we fully agree with the reviewer that the sustained activity we observed could be explained by other different factors. For this reason, we toned down the description of this activity in the abstract and introduction:</p><p>“The population code underwent an abrupt change at stimulus offset, with sustained responses after the Go sounds during the delay period.” And</p><p>“Third, at stimulus offset, the population code changed abruptly and a large fraction of neurons maintained sustained responses after Go sounds throughout the delay epoch.”</p><p>We also take care to mention this point in the results:</p><p>“We consider further the possible link of this delay activity pattern with reward expectation or motor preparation (see Discussion). For practical reasons, we will refer to the delay activity as category-related in the following sections.“</p><p>In addition, we now discuss several alternative interpretations of this activity in the Discussion: categorical activity tied to choice, reward expectation and motor preparation:</p><p>“We note that this sustained activity after Go sounds can be caused by at least three different factors.</p><p>First, delay activity in A1 could be the result of a feedback signal from higher-order decisionrelated areas signaling the chosen category and maintaining it in memory by engaging A1 in a network of parietal and frontal areas<sup>33</sup>. In this framework, previous works in the somatosensory system have shown that choice-related information flows bidirectionally between primary and secondary somatosensory cortices, with choice-related information emerging in primary sensory cortex, then fed to downstream areas that further feedback enriched choice-related information to the primary field<sup>34</sup>. Consistent with this hypothesis, we have demonstrated that trial-to-trial fluctuations of categorical responses during the sound period correlate with the amplitude of the delay categorical signal (Figure 4b), possibly suggesting that category-related information during the stimulus and delay periods are part of this communication loop.</p><p>A second interpretation is that delay activity is the result of motor preparation that would unfold over several hundreds of milliseconds<sup>16</sup>. The pattern of activity observed during early trials is consistent with this view, with faster build-up when the animals licked earlier. However, a similar pattern was not observed on false alarm trials, contrary to what would be predicted for this interpretation.</p><p>A last possibility is that delay activity signals reward expectation<sup>35</sup>, a type of response which increases through learning<sup>16,36</sup>. This delay activity would then reflect post-learning residual topdown feedback, or alternatively may be the signature of an eligibility trace, i.e. a persistent activity necessary for bridging the gap between the sound and the response window<sup>37</sup>. Overall, disentangling these different interpretations will require further experiments.”</p><disp-quote content-type="editor-comment"><p>If we define perceptual categorization as a maximization of perceptual differences between categories and a minimization of the differences within a category, investigating the neural representation of auditory categories may require a more nuanced comparison of how well one can decode stimuli within vs. across categories from neural activity.</p></disp-quote><p>We agree with the reviewer that we did not sufficiently stress this point in the original version, although we used a category index (CI) as a direct measure of the difference in discriminability for pairs of stimuli that were within or across categories. This index compares the distances between projections of stimuli onto the categorical neural axis (Figure 3figure supplement 1a,b). We changed the text to highlight how the CI relates to grouping and separability between stimulus pairs:</p><p>“Categorization can be defined as the maximization of neural differences between categories and a minimization of the differences within a category. Therefore we investigated stimulus discriminability along the category neural axis. We designed a category index (see Methods) which compared the neural distance between stimuli at the category boundary (12 and 16 Hz) against pairs of stimuli within categories. We found that categories were effectively present in both passive and task-engaged states during stimulus presentation with equal magnitude (Figure 3a,b and Figure 3—figure supplement 1a,b). In contrast, significant categories were found only in the task-engaged state during the delay period (Figure 3c,d).“</p><p>Additionally, we believe that we did address this question from two different perspectives in the manuscript. First, we showed the neural distances between pairs of stimuli projected on the category decoder (Figure 2—figure supplement 4). The grouping of stimuli within the same category can be seen during the stimulus period, and even more during the delay (Figure 2figure supplement 4d) and the response window (Figure 2—figure supplement 4f).</p><disp-quote content-type="editor-comment"><p>– The manuscript would benefit from a discussion of alternative explanations related to reward expectation.</p></disp-quote><p>Thank you for the suggestion; we review these alternative explanations in the discussion now (see comment 2 pages above).</p><disp-quote content-type="editor-comment"><p>– The differences in neural activity seem compelling, but the author may want to de–emphasize the idea that these changes are associated with a neural representation of auditory categories.</p></disp-quote><p>Similarly, we toned down this point throughout the manuscript. For instance, in the abstract:</p><p>“Third, at stimulus offset, the population code changed abruptly and a large fraction of neurons maintained sustained responses after Go sounds throughout the delay epoch.”</p><p>or in the discussion:</p><p>“Categorical responses changed at stimulus offset to maintain a Go-specific prolonged activity during the delay period, consistent with other studies showing choice-related activity in A1<sup>25–28</sup>. We do not interpret this activity as efferent copies directly sent from motor regions<sup>29</sup>, as one would expect such motor-related activity to have shorter latencies (~100-300 ms<sup>14,30</sup>). Here, sound category was decodable throughout the entire delay period (Figure 2a), which does not match with short-latency efference copies. We have also found that the delay activity is not closely locked in time to licks since false alarm trials, in which the animals licked during the response window, were not decoded as hit trials during the delay period (Figure 5b).</p><p>Other studies investigating the role of A1 in auditory Go/No-Go tasks with a delay did not analyze neuronal responses after Go sounds<sup>31,32</sup>, which may explain why this sustained activity has not been previously reported. Interestingly, delay activity in sensory cortices is thought not to be causally involved in the behavioral response of trained animals (causal inactivations in V1<sup>33</sup> and A1<sup>31</sup>). We note that this sustained activity after Go sounds can be caused by at least three different factors.”</p><disp-quote content-type="editor-comment"><p>– Figure 1e: because the structure can appear from random data when sorted, a supplementary figure showing neurons sorted by the delay during passive would illustrate that effects shown in this figure are not just the result of sorting for the active condition.</p></disp-quote><p>The increase in delay period activity during the active context is not due to sorting. We added a new supplementary figure (Figure 1—figure supplement 3) by sorting using passive state which shows the sorting done from the passive data has no effect on the claim mentioned in Figure 1d:</p><p>“Ranking neurons by delay activity during the passive condition did not reveal a similar pattern neither in passive or active states (Figure 1—figure supplement 3), reflecting a pattern of response specific to the task-engaged delay period.”</p><disp-quote content-type="editor-comment"><p>– It would be useful to clarify whether the &quot;increase&quot; associated with Figure 1f (during the delay period) is with respect to the spontaneous or sound–evoked activity.</p></disp-quote><p>Figure 1f modulation index is with respect to the spontaneous activity. This is now mentioned in the caption and in the figure.</p><disp-quote content-type="editor-comment"><p>– Clarify what &quot;R.W&quot; means. I don't think that is a standard acronym.</p></disp-quote><p>The R.W. in all figures corresponds to the response window. We now mention it in the figure captions.</p><disp-quote content-type="editor-comment"><p>– Figure 1f: specify what period(s) of activity the modulation index refers to.</p></disp-quote><p>The time-period used to calculate the modulation index in Figure 1f is mentioned in the caption.</p><disp-quote content-type="editor-comment"><p>– The authors need to clarify whether the animals are head–fixed or freely moving during training and recordings. While they mentioned &quot;To obtain stable neurophysiological recordings we implanted the ferrets with a stainless steel headpost&quot;, it's not clear when the headpost was used since the electrodes were chronically implanted.</p></disp-quote><p>The ferrets were head-fixed during the training and recording sessions. We now mention it in the methods:</p><p>“Each recording session consisted of passive and active sessions. Recordings were performed head-fixed in a soundproof chamber. In the passive sessions the water spout was removed.“</p><disp-quote content-type="editor-comment"><p>– Authors should also specify how sounds were delivered (Figure 1 seems to indicate the ferrets had headphones).</p></disp-quote><p>Thank you for the observation. We have clarified the details of the sound presentation in the methods section:</p><p>“The animals were head fixed in a custom-made tube during training and recording sessions and the stimuli were presented from a calibrated earphone (Sennheiser IE800, HDVA 600 amplifier). Ferrets had to classify click trains into two categories: target (Go) and non-target (NoGo) depending on the rates of click trains. Six rates were used, from 4 to 24 Hz in 4 Hz steps, and with a category boundary fixed at 14 Hz. To ensure the dissociation between categories and stimulus rates, one animal was trained with low rates as the Go sounds, while the second animal classified high rates as the Go sounds.“</p><disp-quote content-type="editor-comment"><p>– Authors should be clearer about the passive stimulation sessions. Are the animals licking? are there other differences compared to the active sessions (e.g., inter–trial interval)?</p></disp-quote><p>The passive sessions were identical to active sessions in terms of stimulus presentation and duration, with the only difference being the water spout was absent. There was no change of inter-trial interval. As far as the licking is considered, the animal did not show any licking behavior since the passive sessions were always first to record and the animal readily recognized the absence of water spout. After the passive session, we brought the waterspout back in place and provided some water drops before starting the active session recording, so that animals recognized the presence of the spout.</p><disp-quote content-type="editor-comment"><p>– The first mention of &quot;the naive animal&quot; comes out of nowhere. The authors should introduce that there is a naive animal used for control experiments.</p></disp-quote><p>Thank you for the observation. We now added a sentence to introduce the naive animal in the result section:</p><p>“As a control, we performed recordings in an untrained (naive) animal using the same set of stimuli (Figure 2—figure supplement 2a). The accuracy of passive context decoder was also similar to what is observed in the naive animal (Figure 2—figure supplement 2b).”</p><disp-quote content-type="editor-comment"><p>– Figure 2 caption: I don't know what &quot;resp.&quot; means.</p></disp-quote><p>The caption is now corrected.</p><disp-quote content-type="editor-comment"><p>– Figure 4C: y–label should say &quot;categorical&quot;.</p></disp-quote><p>We have corrected this typo.</p><disp-quote content-type="editor-comment"><p>– Figure 5a: the caption says &quot;cyan&quot; but it looks purple to me.</p></disp-quote><p>We have corrected the caption to purple.</p></body></sub-article></article>