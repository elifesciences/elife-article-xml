<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">79950</article-id><article-id pub-id-type="doi">10.7554/eLife.79950</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>Scale-free behavioral dynamics directly linked with scale-free cortical dynamics</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-280345"><name><surname>Jones</surname><given-names>Sabrina A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-280346"><name><surname>Barfield</surname><given-names>Jacob H</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-280347"><name><surname>Norman</surname><given-names>V Kindler</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-230491"><name><surname>Shew</surname><given-names>Woodrow L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0679-1766</contrib-id><email>shew@uark.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05jbt9m15</institution-id><institution>Department of Physics, University of Arkansas at Fayetteville</institution></institution-wrap><addr-line><named-content content-type="city">Fayetteville</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Berman</surname><given-names>Gordon J</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03czfpz43</institution-id><institution>Emory University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>27</day><month>01</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e79950</elocation-id><history><date date-type="received" iso-8601-date="2022-05-03"><day>03</day><month>05</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-01-06"><day>06</day><month>01</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-05-13"><day>13</day><month>05</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.05.12.443799"/></event></pub-history><permissions><copyright-statement>© 2023, Jones et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Jones et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-79950-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-79950-figures-v2.pdf"/><abstract><p>Naturally occurring body movements and collective neural activity both exhibit complex dynamics, often with scale-free, fractal spatiotemporal structure. Scale-free dynamics of both brain and behavior are important because each is associated with functional benefits to the organism. Despite their similarities, scale-free brain activity and scale-free behavior have been studied separately, without a unified explanation. Here, we show that scale-free dynamics of mouse behavior and neurons in the visual cortex are strongly related. Surprisingly, the scale-free neural activity is limited to specific subsets of neurons, and these scale-free subsets exhibit stochastic winner-take-all competition with other neural subsets. This observation is inconsistent with prevailing theories of scale-free dynamics in neural systems, which stem from the criticality hypothesis. We develop a computational model which incorporates known cell-type-specific circuit structure, explaining our findings with a new type of critical dynamics. Our results establish neural underpinnings of scale-free behavior and clear behavioral relevance of scale-free neural activity.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>As we go about our days, how often do we fidget, compared to how frequently we make larger movements, like walking down the hall? And how rare is a trek across town compared to that same walk down the hall? Animals tend to follow a mathematical law that relates the size of our movements to how often we do them.</p><p>This law posits that small-to-medium movements and large-to-huge movements are related in the same way, that is, the law is ‘scale-free’, it holds the same for different scales of movement. Surprisingly, measurements of brain activity also follow this scale-free law: the level of activation of a group of neurons relates to how often they are activated in the same way for different levels of activation.</p><p>Although body movements and brain activity behave in a mathematically similar way, these two facts had not previously been linked. Jones et al. studied body movements and brain activity in mice, and found that scale-free body movements were linked to scale-free brain activity, but only in certain subsets of neurons. This observation had been hidden because other subsets of neurons compete with scale-free neurons. When the scale-free neurons turn on, the competing groups turn off. When averaged together, these fluctuations cancel out.</p><p>The findings of Jones et al. provide a new understanding of how brain and body dynamics are orchestrated in healthy organisms. In particular, their results suggest that the complex, multi-scale nature of behavior and body movements may emerge from brain activity operating at a critical tipping point between order and disorder, at the edge of chaos.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>scale-free</kwd><kwd>cerebral cortex</kwd><kwd>behavior</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>NIHR15NS116742</award-id><principal-award-recipient><name><surname>Shew</surname><given-names>Woodrow L</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100008982</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>NSF1912352</award-id><principal-award-recipient><name><surname>Shew</surname><given-names>Woodrow L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Complex, multi-scale natural behaviors may arise from subpopulations of neurons in cerebral cortex operating near the tipping point of a phase transition, that is, near criticality.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>From fidgeting to expeditions, natural body movements manifest over a very broad range of spatiotemporal scales. The complexity of such movements is often organized with fractal structure, scale-free fluctuations spanning multiple spatiotemporal orders of magnitude (<xref ref-type="bibr" rid="bib2">Anteneodo and Chialvo, 2009</xref>; <xref ref-type="bibr" rid="bib40">Proekt et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Sims et al., 2008</xref>; <xref ref-type="bibr" rid="bib60">Viswanathan et al., 1999</xref>). Such behavioral complexity may be beneficial for foraging (<xref ref-type="bibr" rid="bib18">Garg and Kello, 2021</xref>; <xref ref-type="bibr" rid="bib51">Sims et al., 2008</xref>; <xref ref-type="bibr" rid="bib60">Viswanathan et al., 1999</xref>; <xref ref-type="bibr" rid="bib64">Wosniack et al., 2017</xref>), visual search (<xref ref-type="bibr" rid="bib60">Viswanathan et al., 1999</xref>), decision-making based on priority (<xref ref-type="bibr" rid="bib3">Barabási, 2005</xref>; <xref ref-type="bibr" rid="bib54">Sorribes et al., 2011</xref>), flexible switching of behavior (<xref ref-type="bibr" rid="bib1">Abe, 2020</xref>), and perhaps more. Similarly, fluctuations of ongoing neural activity in the cerebral cortex can exhibit fractal, scale-free fluctuations like the spatiotemporal cascades sometimes referred to as ‘neuronal avalanches’ (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>; <xref ref-type="bibr" rid="bib5">Bellay et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Ma et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Priesemann et al., 2014</xref>; <xref ref-type="bibr" rid="bib44">Scott et al., 2014</xref>; <xref ref-type="bibr" rid="bib48">Shew et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Shriki et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Tagliazucchi et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Yu et al., 2017</xref>) and long-range temporal correlations (<xref ref-type="bibr" rid="bib22">Hardstone et al., 2012</xref>; <xref ref-type="bibr" rid="bib26">Kello et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Palva et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Smit et al., 2013</xref>). Considering these observations of behavior and brain activity together, a simple, yet unanswered question arises. Are scale-free dynamics in cerebral cortex related to scale-free body movements? Or are these statistical similarities merely superficial, without any direct link?</p><p>Two previous studies in humans have shown that temporally scale-free ongoing brain dynamics are related to some subtle aspects of behavior – fluctuations in success at rhythmic finger tapping (<xref ref-type="bibr" rid="bib52">Smit et al., 2013</xref>) and sensory detection tasks (<xref ref-type="bibr" rid="bib35">Palva et al., 2013</xref>). But, here, we are concerned with less subtle, larger-scale body movements and invasive measurements of brain activity with single neuron resolution.</p><p>According to prevailing theories of scale-free ongoing neural activity, these dynamics are often interpreted as ‘background’ activity, not directly linked to behavior. This view arises in part because computational models of scale-free neural activity generate this type of dynamics autonomously, due to internal interactions, without explicit modeling of a body that behaves (<xref ref-type="bibr" rid="bib11">Dalla Porta and Copelli, 2019</xref>; <xref ref-type="bibr" rid="bib12">di Santo et al., 2018</xref>; <xref ref-type="bibr" rid="bib20">Girardi-Schappo et al., 2020</xref>; <xref ref-type="bibr" rid="bib31">Li and Shew, 2020</xref>; <xref ref-type="bibr" rid="bib62">Wilting et al., 2018</xref>). Similarly, in experiments, scale-free neural activity has typically been observed in animals that are at rest, not engaged by any particular motor task or sensory input, or under anesthesia (<xref ref-type="bibr" rid="bib13">Fontenele et al., 2019</xref>; <xref ref-type="bibr" rid="bib19">Gautam et al., 2015</xref>; <xref ref-type="bibr" rid="bib21">Gireesh and Plenz, 2008</xref>), or in vitro (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>; <xref ref-type="bibr" rid="bib6">Bellay et al., 2020</xref>; <xref ref-type="bibr" rid="bib46">Shew et al., 2009</xref>; <xref ref-type="bibr" rid="bib58">Tetzlaff et al., 2010</xref>) where there is no behavior to be observed. Based on these previous experimental observations and modeling efforts, one might naturally conclude that scale-free neural activity is internally generated, emerging spontaneously, without any link to behavior.</p><p>However, recent experiments in awake mice have revealed that behaviors typically ignored by experimenters, such as whisking, eye and face movement, fidgeting, walking, and running, are strongly related to ongoing neural activity in the cortex (<xref ref-type="bibr" rid="bib7">Clancy et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Salkoff et al., 2020</xref>; <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>). These studies did not address our question here about scale-free-ness of neural activity and behavior, but they suggest that if ongoing activity is scale-free, then it may be strongly related to behavior. More specifically, these studies point out the possibility that previous observations of scale-free neural activity in awake animals didn’t notice a link to behavior because those studies did not measure ongoing, spontaneous movements of the face, whiskers, and body. If this is the case, it would dramatically revise the typical interpretation of scale-free ongoing activity and provide direct evidence that scale-free behavior and scale-free brain activity are inseparably related. However, in the work by <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>, the measured behaviors could explain only 10–30% of the total variance in neural activity fluctuations. Thus, the question remains: is this behaviorally-related 10–30% of neural activity scale-free? Here, our aim was to answer this question.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Here, we analyzed simultaneous recordings of more than 10,000 pyramidal neurons during 1–2 hr in visual cortex of awake mice ( seven mice, nine recordings, recording duration 1.52 ± 0.51 hr), performed and first reported by <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>. The neurons were distributed throughout a volume (300–400 μm in-depth, 0.9 × 0.935 mm in the area) and sampled at 3 Hz. In addition to the neural activity, several aspects of behavior and body movements were also recorded (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Here, we focused on four aspects of behavior. First, we studied run speed, which was assessed using an optical sensor and a floating spherical treadmill. Second, we examined pupil diameter, which was obtained from a camera targeting the faces of the mice. Pupil diameter dynamics are associated with changes in arousal and other aspects of body movement and sensory input (<xref ref-type="bibr" rid="bib42">Reimer et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Reimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib59">Vinck et al., 2015</xref>). Third, we studied changes in direction of gaze by tracking the speed of the center of the pupil as the mice looked around. Finally, we used previously developed methods to study whisker motion (<xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>), which was also obtained from the face camera.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Simultaneous recording of behavior and neural activity.</title><p>(<bold>A</bold>) Multiplane calcium imaging measured ~10,000 neurons in shallow layers of mouse visual cortex, while a camera measured facial motion and a treadmill measured run speed. (<bold>B</bold>) Example activity time series from 15 neurons (out of 11,005 total in this recording). Notice some neurons were strongly correlated with behavior (bottom five), while others were anticorrelated (top five), and others were nearly uncorrelated (middle five). (<bold>C</bold>) The four aspects of behavior - run speed, pupil diameter, speed of changes in gaze direction, and whisker motion - tended to covary on long time scales, but differ in fast fluctuations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig1-v2.tif"/></fig><sec id="s2-1"><title>Scale-free behavior</title><p>The behavior tended to occur in bursts; rest periods were punctuated with well-defined bouts of body movement (<xref ref-type="fig" rid="fig1">Figure 1C</xref> and <xref ref-type="fig" rid="fig2">Figure 2A</xref>). All four of the behavioral variables we studied tended to start and stop together, approximately, but differed in their detailed, fast fluctuations (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We first sought to determine whether the behaviors exhibited scale-free dynamics. To this end, we first defined each bout of elevated body activity, hereafter called a behavioral ‘event,’ based on a threshold (the median of the entire time series). Each behavioral event began when the behavioral time series, run speed for example (<xref ref-type="fig" rid="fig2">Figure 2A</xref>), exceeded the threshold and ended when it returned below the threshold. The ‘size’ of each behavioral event was defined as the area between the threshold and the variable during the event (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). This definition of events and their sizes is motivated by previous studies of scale-free neural activity (<xref ref-type="bibr" rid="bib19">Gautam et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Larremore et al., 2014</xref>; <xref ref-type="bibr" rid="bib31">Li and Shew, 2020</xref>; <xref ref-type="bibr" rid="bib38">Poil et al., 2012</xref>), typically referred to as neuronal avalanches. In the case of run speed, the event size corresponds to an effective distance traveled during the event. If the animal behavior is scale-free, one expects the distribution Pr(s) of behavioral event sizes (s) to have a power-law form, Pr(s)~s<sup>-τ</sup>. We found that these distributions often were in the form of a power-law over a wide range of event sizes (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). For example, the run speed event size distribution for mouse 1 was scale-free for nearly four orders of magnitude of event sizes (power-law range, r=3.9 decades). To rigorously assess the range over which the data is power-law distributed, we used a maximum likelihood fitting algorithm that accounts for the number of events observed and the possibility of a cutoff at the head and tail of the distribution (Methods). Our approach builds on that used in previous studies (<xref ref-type="bibr" rid="bib48">Shew et al., 2015</xref>). We report the power-law range r in decades, i.e., the number of orders of magnitude. If no range meets our fit criteria for statistical significance, we report r=0.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Spontaneous behavior is often scale-free.</title><p>(<bold>A</bold>) Behavioral events (run speed, in this example) are defined by excursions above the median; event size is the area (shaded patch) between the curve and the median. (<bold>B</bold>) Four examples of behavioral event size distributions with large power-law range <italic>r</italic>&gt;3 dB. Black points indicate the part of the distribution that is fit well by a power law. Blue points fall outside the power-law range. Gray patch indicates the expected variability (10th to 90th percentile) of the best-fit power law. (<bold>C</bold>) Summary of power-law range for all mice and all behaviors. Gaze dynamics were least likely to have a large power-law range. All mice had at least one behavior with a very large (&gt;3 decades) power law range. Changes in power-law fitting parameters (goodness-of-fit criteria and outlier criteria) did not change our general conclusions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Interpreting probability density functions (PDF) with logarithmic bins.</title><p>The best practice for presenting a distribution of a power-law distributed quantity is to use logarithmic bin sizes. However, probability density can be difficult to interpret with logarithmic bins because it represents the count of events in a bin divided by the bin size. Since the bin size can be &lt;&lt;1, the probability density can be high even though the sample counts are low. To make this clear, we show both event counts (bottom row) and PDFs (top row) for three data sets. The left column is from the total population in mouse 1 (same as <xref ref-type="fig" rid="fig3">Figure 3B</xref>). The middle column was obtained by drawing sizes from the positive side of a gaussian distribution with the same SD as the data set in the left column (The mean was zero and values less than zero were excluded). Note the similarity of the middle and left columns; both have a poor sampling of small event sizes which manifests as noisy fluctuations in the small size range of the PDF. From this, it appears that the total population is more similar to a truncated gaussian than to a power-law. The right column is a synthetic data set with half the samples drawn from a power-law and half drawn from a uniform distribution on the interval [0, 0.01]. Note the similarity with certain behavioral event size distributions in <xref ref-type="fig" rid="fig2">Figure 2</xref>. This suggests that there is a mix of low-amplitude noise and power-law distributed behavioral fluctuations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Outlier exclusion effects on power-law fitting algorithm.</title><p>In the experimental data, we occasionally found that the distributions of neural or behavioral events had ‘outliers’ – samples that fell far from the distribution, often with a large gap between the outlier point and the nearest neighbor sample. To remove subjective choices from our analysis pipeline we developed a systematic automated algorithm for excluding outliers. Although this outlier exclusion is not subjective, it is still important to understand how it may impact the ability of our power-law fitting algorithm. Here, we benchmarked our outlier exclusion and fitting pipeline on synthetic samples drawn from known power-law distributions. We tested a family of truncated power-law distributions. In all cases, we set the minimum and maximum sample sizes to be 0.01 and 100, respectively. We tested a range of power-law exponents z=0.8 to z=2, where P(s) ~ s<sup>-z</sup> (like those observed in our experimental results) and sample sizes from N=100 to N=10,000. Finally, we tested outlier cutoff thresholds 0.01, 0.03, 0.06, and 0.1. (<bold>A</bold>) Our fitting algorithm successfully identified the correct exponent, independent of the outlier threshold (N was fixed at 5000 for all panel A results). (<bold>B</bold>) Best fit exponents were very slightly underestimated when the sample size was very small, less than about 200. Our typical sample size in the experiments was larger than this. (<bold>C</bold>) Since excluding outliers inevitably reduces the range of the data, power-law range was more sensitive to outlier threshold, but only for exponents above about 1.7. We note that the neural subsets that were strongly correlated with behavior had much lower exponents (closer to one), for which there is no substantial sensitivity to outlier threshold. Dashed line shows the upper bound on power-law range for N=5000. (<bold>D</bold>) Power-law range was also underestimated when sample sizes were small. Again, we emphasize for the outlier thresholds we used in our main results (0.03 and 0.06) and the typical sample sizes from the experiments (&gt;400), the best-fit power-law range was not very sensitive to the outlier threshold.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig2-figsupp2-v2.tif"/></fig></fig-group><p>Although not all behaviors were scale-free over such a large range for all recordings, we found that most of the mice exhibited scale-free behaviors, particularly for running and pupil fluctuations (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). In addition to the power-law range for larger behavioral events, some behaviors exhibited a range of small-scale behavioral events with a flat distribution consistent with low amplitude noise in the measurement methods (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). These conclusions were robust to changes in the two most important parameters for the power-law fitting algorithm: the goodness-of-fit criterion and the outlier exclusion threshold (more on outlier exclusion in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p></sec><sec id="s2-2"><title>Scale-free neural activity</title><p>Next, we turned to the neural activity to test whether it was scale-free like the behavior. First, we averaged over all neurons to obtain a single population activity time series. Then, we treated the neural data in a similar way to the behavioral data. We defined neural events with a median threshold and defined event size as the area between the threshold and the data during the event (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). This definition of events and event sizes is well-established in previous studies of scale-free neural activity (<xref ref-type="bibr" rid="bib19">Gautam et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Larremore et al., 2014</xref>; <xref ref-type="bibr" rid="bib31">Li and Shew, 2020</xref>; <xref ref-type="bibr" rid="bib38">Poil et al., 2012</xref>). (For more discussion of why this definition was chosen over other established alternatives, see Methods). The resulting distributions of neural event sizes were not scale-free; they were poorly fit by a power-law distribution (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Considering all 9 recordings, we found that r=1.5 ± 0.9 decades (mean ± SD). Such a short power-law range should be interpreted as evidence against any power-law at all, because nearly any function can be fit on a short range of data (more on why a large power-law range is important below).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Certain subsets of neurons exhibit scale-free dynamics, but total population does not.</title><p>(<bold>A</bold>) Activity of the total neural population (black) and two subsets of neurons (blue, red) are shown. Each excursion above the median is one neural event (blue shaded area for subset A). Examples in panels A, B, and C are from mouse 1. (<bold>B</bold>) For the total population, the distribution of neural event sizes is not well fit by a power law (small range rtot = 1.2 decades). Histogram of event sizes (green, same bins used for blue, black distributions) shows that head of the distribution is noisy because very few events had very small sizes. (<bold>C</bold>) Certain subsets of neurons exhibited very large power-law range (rA = 3.9 decades), while other subsets did not (rB = 1.8 decades). These two example distributions are offset vertically to aid comparison of shape. (<bold>D</bold>) Distribution of power-law range r for 1000 subsets from mouse 1 (blue). Power law range r reached 4.5 decades for some subsets but did not exceed 2.6 decades for time-shifted controls (gray) in this mouse. (<bold>E</bold>) Summary of all mice, showing the number of subsets (out of 1000) with power-law range <italic>r</italic>&gt;3.5 decades, compared to time-shifted controls. Results were qualitatively unchanged for different group size or goodness-of-fit criteria.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Neural event size distributions are robust to some loss of spikes due to analysis of Ca imaging signals.</title><p>Previous studies have shown that the deconvolution used to obtain an estimate of spike rate from raw GCAMP6s Ca signals can result in missing some spikes (<xref ref-type="bibr" rid="bib24">Huang et al., 2021</xref>). Here, we asked if such missing spikes might distort or bias the event size statistics we report in the main text (<xref ref-type="fig" rid="fig3">Figures 3</xref>, <xref ref-type="fig" rid="fig5">5</xref> and <xref ref-type="fig" rid="fig7">7</xref>). To address this question, we began with time-resolved spike data from 294 single units measured with a Neuropixel probe (the data set was first published by Stringer et al and is labeled Probe 5 from the mouse called Robbins in their online data repository). We first performed a forward-modeling process to create a signal like the GCAMP6s Ca signals we study in our main results. This involved four steps: (1) convolution with a Ca-transient (step increase, exponential decay with 2 s time constant), (2) downsampling to 3 Hz sample rate, (3) non-negative deconvolution with the OASIS algorithm described in <xref ref-type="bibr" rid="bib16">Friedrich et al., 2017</xref> and used by <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>, and (4) z-scoring each neuron’s deconvolved activity time series. We compared the resulting estimate of spike count activity to the ground truth spike count in 330ms time bins. We note that we did not add any noise into these signals, so the results should be considered a best-case scenario. Real experimental measurement tools will, of course, have some noise, which will result in some additional erroneous spikes. (<bold>A–F</bold>) Two examples of the forward modeling and comparison to ground truth are shown, one example for a high firing rate neuron (panels A-C), another example for a bursty low rate neuron (panels D-F). The dashed line circle in panel F highlights an example where the deconvolution (purple) misses some of the original spikes. (<bold>G</bold>) Neural event size distribution for the deconvolved 3 Hz data. (<bold>H</bold>) Neural event size distribution for the ground truth original data, also binned at 3 Hz time resolution. Note that although z-scoring changes the sizes of events, the exponent and range of power-law scaling was nearly unchanged. Thus, we conclude that the spikes missed by deconvolution do not dramatically impact neural event statistics we studied here.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Reconciling fast and slow time scales of electrophysiology and Ca imaging.</title><p>Previous studies of scale-free event size distributions have mostly been based on time-resolved electrophysiological data. To better understand how the slow Ca imaging signals we studied here may relate to fast ephys data, we analyzed an example electrophysiological recording of spike times with sub-millisecond time resolution in an awake mouse (data is from a Neuropixel recording in <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>). (<bold>A</bold>) First, we examined the data at high time resolution using spike counts in 5ms time bins. Raster shows 50 out of a total of 294 recorded neurons. The first 25 have the largest loadings of the first principal component (PC1). The last 25 have the lowest loadings of PC1. (<bold>B</bold>) Next, we created a Ca-like signal by convolving the spike times with a Ca-like-transient with a 0.8 s time constant. Then,this signal was downsampled to a 3 Hz sample rate. Then it was deconvolved using the same OASIS nonnegative deconvolution algorithm as was used for the Ca imaging data in our main results. Finally, the signal was z-scored. Raster order is same as panel A, but PC1 was recomputed for the 330 ms resolution data. (<bold>C</bold>) As is apparent in panel A, the 5ms resolution data exhibited very weak anticorrelations. This was also apparent in the nearly entirely positive loadings of PC1 (red). In contrast, the 330ms resolution data had stronger anticorrelations (about 1/4 of neurons had negative loading in PC1). (<bold>D</bold>) When considering the entire population of 294 neurons, the 5ms data exhibited a power-law avalanche size distribution with an exponent near –2, consistent with some previous reports of spike avalanches in awake mice (e.g. <xref ref-type="bibr" rid="bib32">Ma et al., 2019</xref>; <xref ref-type="bibr" rid="bib13">Fontenele et al., 2019</xref>). (<bold>E</bold>) When considering the 50 neurons with the largest positive loadings to PC1, the 330 ms resolution data also exhibited power law scaling over a range of 2.3 decades. (<bold>F</bold>) When the entire population was considered, the 330 ms resolution data exhibited a poorer power law with a relatively short range (1.5 decades) due to cancelation between anticorrelated neurons as discussed in <xref ref-type="fig" rid="fig7">Figure 7</xref> of the main manuscript.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig3-figsupp2-v2.tif"/></fig></fig-group><p>One note of warning: at first glance, the distribution in <xref ref-type="fig" rid="fig3">Figure 3B</xref> may appear to have a decent power-law fit for the small event sizes. This is a misleading artifact resulting from using logarithmic bins and very few samples to estimate probability density. The inset in <xref ref-type="fig" rid="fig3">Figure 3B</xref> shows the number of events rather than probability density. See also <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for more clarification of this point. We emphasize that our power-law fitting algorithm does not use any bins and accounts for sample size, thus avoiding such misleading artifacts.</p><p>The lack of scale-free dynamics for the neural population was surprising considering two facts together: first, the behavior exhibited scale-free dynamics (<xref ref-type="fig" rid="fig2">Figure 2</xref>), and second, many neurons are strongly correlated with behavior (<xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>). One possible explanation for this puzzling observation is that summing the entire population together obscures the scale-free dynamics of certain subsets of neurons. Next, we set out to test this possibility. Since we did not know, a priori, which neurons might be in these subsets, we adopted a brute-force, shotgun search. First, we picked a ‘seed’ neuron at random from the entire population. Then we identified the 50 neurons that were most correlated with the seed neuron (we also tried 200 neurons without major impacts on the following results, <xref ref-type="fig" rid="fig3">Figure 3E</xref>). We averaged the activity of these 50 neurons to obtain a single time series and proceeded to define events and examine their size distribution. Two examples of time series obtained from subsets of neurons in this way are shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. We repeated this process for 1000 different seed neurons. We found that some subsets of neurons were indeed scale-free, with power-law scaling over more than four orders of magnitude, while other subsets were not scale-free (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). With so many neurons to choose from and a shotgun approach like this, it is important to avoid chance-level false positive conclusions. As a conservative control for this possibility, we repeated the analysis, but with surrogate data, generated by applying a random time shift to each neuron’s activity time series relative to other neurons. This time-shifted control data, thus, has identical statistics to the original data at the single neuron level, but correlations among neurons occur only by chance. For time-shifted controls, we found that large power-law ranges (greater than 3.5 decades) were rare and not found at all in the majority of recordings (<xref ref-type="fig" rid="fig3">Figure 3D and E</xref>). This conclusion was robust for different choices of group size and goodness-of-fit criteria used for the power-law fitting (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p><p>Two concerns with the data analyzed here are that it was sampled at a slow time scale (3 Hz frame rate) and that the deconvolution methods used to obtain the data here from the raw GCAMP6s Ca imaging signals are likely to miss some of the underlying spike activity (<xref ref-type="bibr" rid="bib24">Huang et al., 2021</xref>). Since our analysis of neural events hinges on summing up activity across neurons, could it be that the missed activity creates systematic biases in our observed event size statistics? To address this question, we analyzed some time-resolved spike data (Neuropixel recording from <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref>). Starting from the spike data, we created a slow signal, similar to that we analyzed here by convolving with a Ca-transient, down sampling, deconvolving, and z-scoring (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s2">2</xref>). We compared neural event size distributions to ‘ground truth’ based on the original spike data (with no loss of spikes) and found that the neural event size distributions were very similar, with the same exponent and the same power-law range (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Thus, we conclude that our reported neural event size distributions are reliable.</p></sec><sec id="s2-3"><title>Linking scale-free brain activity and behavior</title><p>Having established that certain subsets of neurons have scale-free dynamics and that behavior has scale-free dynamics, we next sought to assess how the neural and behavioral dynamics are related. We first computed the correlation coefficient between each behavior time series and each neural subset time series. The correlation was very weak between the total neural population time series and behavior (red x’s in <xref ref-type="fig" rid="fig4">Figure 4</xref>). For the 50-neuron subsets, we found a very wide range of behavioral correlation values, from 0.9 to –0.75 (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Interestingly, the subsets with the greatest correlation with behavior also tended to have the largest ranges of power-law scaling. Moreover, the neural subsets with the smallest power-law range were most often near zero correlation with behavior. These results strongly suggest that the scale-free subsets of neurons are directly related to scale-free behavior. It is also interesting to note that many of the subsets that were strongly anticorrelated with behavior also had a large power-law range (the U-shaped relationships in <xref ref-type="fig" rid="fig4">Figure 4</xref>). These findings were very robust in 6 out of 9 recordings (mouse 1–4 c, <xref ref-type="fig" rid="fig4">Figure 4</xref>), but less prominent for some behaviors in the remaining three recordings (mouse 5–7). We note that these three ‘outlier’ animals also had tendencies to run much more than usual (mouse 6 and 7 ran 50 times more than the next most active animal) or much less than usual (mouse 5 ran 10 times less than the next least active animal) as shown in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. This observation suggests that our main findings hold best in vigilance states that are moderate, not too hyperactive, or hypoactive.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Scale-free neural subsets correlate with behavior, but non-scale-free subsets do not.</title><p>(<bold>A</bold>) Each point represents the power-law range r and behavioral correlation of one neural subset from mouse 1. Subsets with large r tend to be most correlated with behavior. Thick line is a moving average of points; thin lines delineate quartiles. The red x represents the total population. (<bold>B</bold>) Same as panel A for the other eight recordings. Tick mark on horizontal axis marks zero correlation. Points have partially transparent markers, thus darker areas reveal higher density of points.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Outlier recordings.</title><p>Our primary result, shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>, was that subset of neurons with large power-law ranges tended to be most strongly correlated to behavior. However, this observation was less pronounced in mouse 5, mouse 6, and mouse 7 recordings (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Here, we show that one possible factor that might contribute to the ‘outlier’ tendency for these three recordings is that mice 6 and 7 were much more active. They ran about 50 times more than the next most active animal (mouse 2). Mouse 5 was unusual in that it was the least active animal, moving 10 times less than the next least active animal (mouse 3). It is plausible that these abnormally high or low levels of activity would cause deviations from the main results in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig4-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Power-law range, exponents, and scaling relations</title><p>Previous studies of scale-free neural activity have typically not reported power-law range. Readers may wonder why we focused our analyses here on the power-law range. So far, our results offer two answers to this question. First, and most importantly, only neural subsets with large power-law ranges were strongly correlated with behavior (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Second, any claim of power-law scaling is stronger if that scaling extends over a greater range. Previous studies often rely on a ‘rule of thumb’ that one or two decades of scaling is not bad. For the data analyzed here, we found that a power-law range of 1–2 decades is insignificant compared to chance for event size distributions (<xref ref-type="fig" rid="fig3">Figure 3</xref>).</p><p>One reason previous studies of scale-free brain activity have not reported power-law range stems from their motivating hypothesis that scale-free activity results from the neural circuits operating in a special dynamical regime near the tipping point of a phase transition, i.e., near criticality. Rather than power-law range, these studies focused on scaling relationships between the power-law exponents of the event size and duration distributions as predicted by the theory of critical phenomena. Based on our results, we contend that these previous studies might be strengthened by also accounting for power-law range. Conversely, previous studies also raise a natural question about whether the data we analyzed here supports predictions from the theory of criticality. Our next goal is to answer this question.</p><p>According to prevailing theories of criticality in neural systems, both the sizes and durations of events should be power-law distributed. Moreover, the theory of crackling noise, which explains a broad class of stick-slip critical phenomena (<xref ref-type="bibr" rid="bib45">Sethna et al., 2001</xref>), predicts that the size power-law exponent τ and the duration power-law exponent α should be related to how size scales with duration. More specifically, S(T)~T<sup>β</sup> where β<sub>crackling</sub> = (α - 1)/(τ –1). Many previous observations of scale-free neural activity support this prediction with values of β<sub>crackling</sub> ≈ 1.1–1.3 (<xref ref-type="bibr" rid="bib13">Fontenele et al., 2019</xref>; <xref ref-type="bibr" rid="bib14">Fosque et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Friedman et al., 2012</xref>; <xref ref-type="bibr" rid="bib32">Ma et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Shew et al., 2015</xref>). To test this theory, we first found the best-fit power-law and its exponent τ for the size distribution (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Then, we fit a power-law to the event duration distributions for the same set of events that were in the range of power-law scaling for event sizes (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), thus obtaining α. And finally, we computed a best-fit β by doing a linear fit to log(S) versus log(T) as shown in <xref ref-type="fig" rid="fig5">Figure 5C</xref>. We found that τ, α, and β varied dramatically across different neural subsets (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). However, if we examined only the behaviorally-correlated subsets, i.e., those with a large power-law range (<italic>r</italic>&gt;3.5), we found that the power-law exponents were relatively consistent: <italic>τ</italic>=1.0 ± 0.1, <italic>α</italic>=1.2 ± 0.2, and fit <italic>β</italic>=2.2 ± 0.2 (mean ± SD, <xref ref-type="fig" rid="fig5">Figure 5E</xref>). Thus, we conclude that power-law scaling exists for both sizes and durations of neural events and that size scales with duration according to another power-law. The existence of these scaling laws is consistent with criticality, but we found that our measured values of β were not consistent with crackling noise theory predictions; best fit β was not close to (α - 1)/(τ –1). This was typically because τ was near one, resulting in small, sometimes negative values of τ–1 in the denominator of the predicted β formula. Moreover, our observations of β were greater than two, which is not close to previously reported values from experiments – around 1.1–1.3. This suggests that if the scale-free neural activity we observe has its origins in criticality, it may be a type of criticality that is different than previous observations. Indeed, this discrepancy with the existing theory is part of the motivation for the new model we present below. Additional scaling laws from the experiments are compared to the model results below.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Consistent scaling relations for behaviorally-correlated neural subsets.</title><p>(<bold>A</bold>) Example neural event size distribution with exponent <italic>τ</italic>=0.96 of the best fit power law (slope on log-log plot). (<bold>B</bold>) Distribution of event durations with exponent <italic>α</italic>=1.18 of the best fit power law (same events as in panel A). (<bold>C</bold>) Event sizes scale with event duration to the power <italic>β</italic>=2.3. Note that the best fit β is not well predicted by crackling noise theory (gold dashed line). (<bold>D</bold>) Each point represents one neural subset (color – power law range) from mouse 1. The neural subsets with strongest correlation to behavior (and largest power-law range) exhibited consistent scaling exponents: <italic>τ</italic>=0.98 ± 0.11, <italic>α</italic>=1.18 ± 0.19, and fit <italic>β</italic>=2.18 ± 0.17. Neural subsets with weaker behavioral correlation (smaller power-law range) had widely varying best fit exponents. Contour lines surround points with power-law range &gt;3.5 decades. (<bold>E</bold>) Summary of all neural subsets with power-law range &gt;3.5 decades from all experiments. Each semi-transparent gray patch corresponds to one contour like the example shown in panel D. The behavioral correlation was chosen to represent the behavior with the greatest correlation for each neural subset.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig5-v2.tif"/></fig><p>Finally, we examined the exponents for distributions of behavioral events. Considering the behaviors with a large power-law range (<italic>r</italic>&gt;3), we found <italic>τ</italic>=1.2 ± 0.2, <italic>α</italic>=1.4 ± 0.3, and fit <italic>β</italic>=1.8 ± 0.4. These exponents were related to the exponents and power-law ranges for neural event distributions, but only if we considered the neural subsets with large power-law range (<italic>r</italic>&gt;3.5 decades) and strong correlation to behavior (<italic>R</italic>&gt;0.6). We found that τ, α, r, and β were significantly correlated for neural and behavioral events (Pearson correlation R<sub>τ</sub>=0.5, p&lt;10<sup>–17</sup>; R<sub>α</sub>=0.2, p&lt;0.002; R<sub>r</sub> = 0.4, p&lt;10<sup>–66</sup>; R<sub>β</sub>=0.3, p&lt;10<sup>–4</sup>). For these comparisons, we paired each neural subset with the type of behavior that was most correlated to that subset.</p></sec><sec id="s2-5"><title>Correlations of individual behavioral and neural events</title><p>The calculation of correlations between neural subsets and behavior, like those in <xref ref-type="fig" rid="fig4">Figure 4</xref>, represents the entire recording duration, leaving open several questions. Are the high correlations in <xref ref-type="fig" rid="fig4">Figure 4</xref> simply due to coarse, on-off dynamics of the neural and behavioral activity, or are there strong correlations at the more detailed level of the faster fluctuations during a single behavioral event? To answer these questions, we computed event-specific correlations – computed between the behavior time series and the neural subset time series during each behavioral event, for each neural subset (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). For instance, for 1000 neural subsets and 1000 behavioral events (which are typical numbers for this data), we would calculate 1 million correlation values. Each correlation is based on the relatively short time series between the start and stop of the corresponding behavioral event. These event-specific correlations were often quite high (&gt;0.9). However, the chance-level occurrence of such high correlations can also be high for such short time series. We account for such chance-level correlations by repeating the calculations for time-shifted control data (Methods), which defines the event-specific, subset-specific chance-level occurrence rate.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Individual neural events correlate with specific behavioral events.</title><p>(<bold>A</bold>) Time series from 7 example neural subsets and the four behaviors. Each behavioral event with significant correlation to a neural event is indicated with a pair of colored line segments, one on the behavioral time series, one on the neural time series. (<bold>B</bold>) Behavioral events with greater size were strongly correlated with more neural events (i.e. more neural subsets). (<bold>C</bold>) Neural subsets with greater power-law range were significantly correlated with a larger number of behavioral events. For panels B and C, each plot summarizes one recording, with one gray point per behavioral event. Black line is a moving average of the points. Background color indicates type of behavior: orange – running; blue – pupil; green – whisking; purple – gaze. (<bold>D</bold>) The white bar indicates the fraction of behaviorally-active time with strong correlation to a significant number of neural groups. <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplements 1</xref>–<xref ref-type="fig" rid="fig6s2">2</xref> show similar results for all recordings and behaviors.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>These plots present the same results as <xref ref-type="fig" rid="fig6">Figure 6B</xref>, but for all mice and all behaviors.</title><p>The left column represents pupil diameter changes, the second column represents gaze dynamics, the third column represents whisking, the right column represents running. The number on the right side of each plot represents the fraction shown in <xref ref-type="fig" rid="fig6">Figure 6D</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>These plots present the same results as <xref ref-type="fig" rid="fig6">Figure 6C</xref>, but for all mice and all behaviors.</title><p>The left column represents pupil diameter changes, the second column represents gaze dynamics,the third column represents whisking, the right column represents running.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig6-figsupp2-v2.tif"/></fig></fig-group><p>First, we asked how many neural subsets were strongly correlated with each behavioral event and whether this count depended on behavioral event size. We found that many behavioral events had a significant number of such strongly correlated subsets and that the larger behavioral events tended to have a larger number of strongly correlated subsets (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Next, we asked how many behavioral events were strongly correlated with each neural subset and whether this count depended on the power-law range of the neural subset. We found that many subsets were strongly correlated with a significant number of behavioral events and that the subsets with greater power-law range tended to be correlated with more behavioral events (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). The example results in <xref ref-type="fig" rid="fig6">Figure 6</xref> are shown for all mice and all types of behaviors in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplements 1</xref>–<xref ref-type="fig" rid="fig6s2">2</xref>. Finally, we considered the time during which the mouse was active and asked what fraction of that time had a significant number of strongly correlated neural subsets. This fraction of time was often as high as 0.5 (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). Thus, we conclude that the detailed, fast fluctuations of behavior are significantly and strongly correlated with scale-free neural activity.</p></sec><sec id="s2-6"><title>Anticorrelated neural subsets</title><p>How is it possible for the total population to not exhibit scale-free fluctuations, while certain subsets are scale-free? A clue to this mystery is apparent upon close inspection of the results in <xref ref-type="fig" rid="fig4">Figure 4</xref>. Some neural subsets are strongly correlated with behavior, while other subsets are strongly anticorrelated, similar to previous reports from the motor cortex (<xref ref-type="bibr" rid="bib67">Zagha et al., 2015</xref>) and prefrontal cortex (<xref ref-type="bibr" rid="bib17">Garcia-Junco-Clemente et al., 2017</xref>). Since the scale-free subsets are often strongly correlated with behavior, it stands to reason that some neural subsets are strongly anti-correlated with the scale-free subsets. We show in <xref ref-type="fig" rid="fig7">Figure 7</xref> that this fact explains why the total population does not exhibit scale-free dynamics. When two anticorrelated subsets are averaged together, they cancel out, resulting in relatively small fluctuations at the level of the total population (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). The broad range of correlations and anticorrelations in each recording are more apparent using ‘correlation spectra’ (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). For each previously defined seed neuron, we ranked all the other neurons according to their correlation with the seed neuron. These correlation spectra often reveal large numbers of strongly anticorrelated neurons. To directly show how cancelation of anticorrelated subsets abolishes scale-free dynamics, we re-computed the power-law range, but this time defined each subset to include the 25 most correlated and the 25 most anti-correlated neurons, relative to each seed neuron. The power-law range for these canceling subsets was greatly reduced compared to the original correlated subsets for all recordings (<xref ref-type="fig" rid="fig7">Figure 7C–E</xref>).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Cancelation of anticorrelated neural subsets hide scale-free neural activity.</title><p>(<bold>A</bold>) Activity of a subset of 100 neurons (top, purple) with large power-law range, another subset of 100 neurons (bottom, orange) that are anticorrelated with first subset, and the total population (yellow). (<bold>B</bold>) Example correlation spectrum, showing the pairwise correlation coefficients between one seed neuron and all other neurons, ranked in descending order. Gray - control spectrum based on randomly time-shifted neurons. (<bold>C</bold>) Example neural event size distribution for a subset based on the top 100 most correlated neurons. (<bold>D</bold>) Example event size distribution for a subset based on the top 50 most correlated neurons and 50 most anticorrelated neurons. Note that the power-law range is greatly reduced compared to panel C. (<bold>E</bold>) The power-law range for the 50 most correlated (left) is much greater than that of the 50 most extreme (right) neurons. Shown are results for the 20 subsets with the greatest power law range for each mouse. Gray lines represent time-shifted controls, which exhibit smaller power-law range and smaller drop in range due to anticorrelated neurons. In panels A, C, D, and E, the cartoon correlation spectra indicate which neurons were included (white) in subsets and which were not (black).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig7-v2.tif"/></fig></sec><sec id="s2-7"><title>Stochastic winner-take-all competition and criticality</title><p>What mechanisms might be responsible for scale-free dynamics among a certain subset of neurons that are obscured due to cancelation with anticorrelated subsets of neurons? Theoretical models for studying scale-free dynamics in neural networks have often employed randomly connected (Erdos-Renyi), networks of excitatory and inhibitory neurons, tuned to operate at criticality (<xref ref-type="bibr" rid="bib19">Gautam et al., 2015</xref>; <xref ref-type="bibr" rid="bib31">Li and Shew, 2020</xref>; <xref ref-type="bibr" rid="bib65">Yang et al., 2012</xref>). However, such models do not manifest qualitatively different slow fluctuations in different subsets of neurons. More specifically, large groups of anticorrelated neurons do not occur in previous models. How can traditional models be changed to account for our observations? Here, we propose that a non-random network structure is needed. Indeed, experiments have shown that connectivity among cortical neurons is far from random (<xref ref-type="bibr" rid="bib10">Cossell et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Jiang et al., 2015</xref>; <xref ref-type="bibr" rid="bib53">Song et al., 2005</xref>); this non-random structure is particularly pronounced among different types of inhibitory neurons (<xref ref-type="bibr" rid="bib25">Jiang et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Pfeffer et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Pi et al., 2013</xref>; <xref ref-type="bibr" rid="bib61">Wall et al., 2016</xref>). To our knowledge, this cell-type-specific connectivity has been ignored in previous models of scale-free neural activity.</p><p>Which aspects of this network structure might explain our findings? We initially sought clues from well-known circuit motifs that generate the anticorrelated activity underlying many types of animal locomotion (<xref ref-type="bibr" rid="bib27">Kiehn, 2016</xref>). A common motif in these circuits, sometimes termed ‘crossing inhibition’ or ‘winner-take-all,’ entails two excitatory circuit nodes, say e+ and e−, whose activity is anticorrelated because they interact via at least one inhibitory node; e+ excites the inhibitory node, which suppresses e-, and vice versa, e- excites the inhibitory node which suppresses e+ (<xref ref-type="fig" rid="fig8">Figure 8A–D</xref>). Such circuit motifs certainly are common in the cortex, but they are mixed and interconnected with numerous other motifs. Even Erdos-Renyi networks contain many motifs of this type. Is it plausible that ‘winner-take-all’ motifs are responsible for our findings?</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Winner-take-all network structure explains scale-free anticorrelated subsets.</title><p>(<bold>A</bold>) Connectivity diagram (top) and matrix (bottom) illustrate interactions among four populations. Solid, dashed lines indicate dense (50%), sparse (5%) connectivity, respectively. Two excitatory groups (e+ and e−) inhibit each other via dense crossing inhibition. (<bold>B</bold>) Eigenvalue spectrum of connectivity matrix has two outlying real eigenvalues, the largest equal to 1. (<bold>C</bold>) Timeseries and raster reveal strong anti-correlations between e+ and e− populations which cancel out; total population has small fluctuations. (<bold>D</bold>) Neural event distributions for e+ and e− exhibit large power-law range, while the total population does not. (<bold>E</bold>) Parameter space for model. Model agrees with experiments near dashed line for a wide range of input rates, most with largest eigenvalue is near 1. (<bold>F</bold>) Dense crossing excitation from e+ to e− abolishes winner-take-all dynamics. (<bold>G</bold>) Crossing inhibition motif is important for matching our experimental observations. Realistic topologies, including known connectivity among PV+, VIP, and SOM inhibitory neurons (right), contain this crossing inhibition motif and match our observations, but simpler networks can match as well. (<bold>H</bold>) Considering 8,73,000 different network configurations, only 31 match our experimental observations. All matching configurations had one of these two motifs. Dashed lines indicate unnecessary connections. <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref> shows all matching configurations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig8-v2.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>We tried 8,73,000 different network configurations.</title><p>Here, we show the 31 configurations that successfully reproduced our primary experimental results. The color scheme and meaning of solid and dashed lines are the same as in <xref ref-type="fig" rid="fig8">Figure 8</xref>. The numbers above each circuit diagram report the correlation coefficient between e+ and e− (top left), the correlation coefficient between i+ and i− (top right), power-law range for the total population (bottom left), power-law range for e+ (bottom middle), and power-law range for e− (bottom right).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig8-figsupp1-v2.tif"/></fig><fig id="fig8s2" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 2.</label><caption><title>Model with asynchronous population.</title><p>Building upon the model presented in <xref ref-type="fig" rid="fig8">Figure 8A–F</xref>, we added a population of 1000 more neurons (e* and i*) that has uniform connectivity density to the original model population (e+, i+, e−, i−). Also, the value of each non-zero connection weight was drawn from a uniform distribution [0,0.01] or [–0.01,0] for excitatory and inhibitory connections, respectively. This non-uniform connection strength shows that the uniform connections in <xref ref-type="fig" rid="fig8">Figure 8A–F</xref> are not important for the model dynamics. The new group (e*) exhibits asynchronous firing because it gets approximately equal input from both the e+ and e− groups. Thus the large power-law fluctuations of each e+ and e− cancel out resulting in a relatively steady level of input to e* and, thus, no power-law fluctuations in e*. (<bold>A</bold>) Schematic of connectivity among groups. (<bold>B</bold>) Color visualization of the entire 2000 × 2000 connectivity matrix for all neurons. Different colors indicate density of connectivity (also marked as percentages) and whether connections are excitatory (yellow) or inhibitory (blue). (<bold>C</bold>) Example spike raster from the model with rows ordered in the same way as the rows of the connectivity matrix in panel B. (<bold>D</bold>) Population average activity time series for e+ and e− have large amplitude anticorrelated fluctuations just like the original model in <xref ref-type="fig" rid="fig8">Figure 8A–F</xref>. The activity of e* (black) has small fluctuations like the total population (gold). (<bold>E–G</bold>) The fluctuations of e+ and e− have power-law distributed event sizes and durations as well as size versus duration scaling. The total population and e* are not power-law distributed. These distributions were generated from 1,00,000-time steps of the simulation (much longer than the example time series in panels C and D).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig8-figsupp2-v2.tif"/></fig><fig id="fig8s3" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 3.</label><caption><title>Single-neuron variance and pairwise covariance are larger for neural subsets with large power-law range.</title><p>(left) Each point represents one subset of neurons from the experiments. For each subset, the activity variance was computed for each neuron and then averaged over neurons. Subsets with large single-neuron variance tended to have large power-law range. (right) Each point represents the average pairwise covariance of all neurons within a subset. Subsets with large covariance tended to have large power-law range. White line is the median of points, gray band delineates quartiles. Color of points indicates recording (mouse 1 – red, mouse 2 – dark blue, mouse 3 – gold, mouse 4 a – purple, mouse 4b – green, mouse 4 c – cyan, mouse 5 – dark red, mouse 6 – blue, mouse 7 – orange).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig8-figsupp3-v2.tif"/></fig></fig-group><p>As shown in <xref ref-type="fig" rid="fig8">Figure 8A</xref>, we tested this possibility using a computational model of 1000 binary neurons divided into two excitatory groups (e+ and e− with 400 neurons each) and two groups of inhibitory neurons (i+ and i− with 100 neurons each). We considered two inhibitory groups, instead of just one, to account for previous reports of anticorrelations between VIP and SOM inhibitory neurons in addition to anticorrelations between groups of excitatory neurons (<xref ref-type="bibr" rid="bib17">Garcia-Junco-Clemente et al., 2017</xref>). The excitatory groups were densely connected within each group (50% connectivity) and sparsely connected across groups (5%), consistent with experimental observations (<xref ref-type="bibr" rid="bib10">Cossell et al., 2015</xref>; <xref ref-type="bibr" rid="bib53">Song et al., 2005</xref>). We also included dense crossing inhibition according to known connectivity among some inhibitory cell types (<xref ref-type="bibr" rid="bib25">Jiang et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Pfeffer et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Pi et al., 2013</xref>; <xref ref-type="bibr" rid="bib61">Wall et al., 2016</xref>). Excitatory and inhibitory synaptic weights were of the same absolute magnitude, but opposite in sign, and the connectivity matrix was normalized such that its largest eigenvalue was one (<xref ref-type="fig" rid="fig8">Figure 8B</xref>), following previous studies of scale-free dynamics and criticality (<xref ref-type="bibr" rid="bib19">Gautam et al., 2015</xref>; <xref ref-type="bibr" rid="bib29">Larremore et al., 2011</xref>; <xref ref-type="bibr" rid="bib31">Li and Shew, 2020</xref>). Each neuron fired probabilistically, in proportion to the sum of its inputs (Methods).</p><p>We found that the e+ and e− neural subsets in this model produced large, slow, scale-free fluctuations (<xref ref-type="fig" rid="fig8">Figure 8C</xref>) like those observed in the scale-free subsets of neurons from our experimental observations (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). The dynamics of e+ were strongly anticorrelated with those of e−, and i+ was anti-correlated with i− (<xref ref-type="fig" rid="fig8">Figure 8C</xref>), resulting in cancelation and a lack of scale-free dynamics when the entire population was considered together (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). All neurons in the model were driven by unstructured random input; there was no statistical difference between the input to different subsets. Thus, the anticorrelated switching behavior in our model emerges stochastically. These results were robust to a wide range of different input rates (<xref ref-type="fig" rid="fig8">Figure 8E</xref>), provided that the largest eigenvalue of the connectivity matrix was near 1. If the largest eigenvalue was increased beyond one, the dynamics stopped switching between e+ and e−, instead getting locked into either e+ active and e− inactive or vice versa (this occurred to the right of the red dashed lines in <xref ref-type="fig" rid="fig8">Figure 8E and F</xref>). Thus, the stochastic switching between e+ and e− activity is a type of critical dynamics occurring at a boundary (red dashed line) in the model parameter space. Such critical winner-take-all dynamics never actually ‘choose a winner,’ instead switching randomly between the two ‘equally deserving winners.’ Scale-free anticorrelated fluctuations were also abolished when the density of connections between e+ and e− was increased beyond about 10% (<xref ref-type="fig" rid="fig8">Figure 8F</xref>). Above this density of connectivity between e+ and e−, the network effectively behaves like a single network, like previous models of criticality and scale-free dynamics.</p><p>In addition to testing dependence on the largest eigenvalue, the input rate, and the density of e+-to-e− connectivity, we did a systematic exploration of different network structures. We sought to understand if the network structure considered in <xref ref-type="fig" rid="fig8">Figure 8A–F</xref> is the only structure that reproduces our experimental observations, or if some other network structures could also work. <xref ref-type="fig" rid="fig8">Figure 8G</xref> summarizes the results of testing several other network structures. We found that crossing inhibition mediated by a single inhibitory population could suffice. The disinhibitory motif highlighted by other recent studies (<xref ref-type="bibr" rid="bib17">Garcia-Junco-Clemente et al., 2017</xref>) is, thus, not necessary to reproduce our observations. Importantly, we showed that our observations can also occur in a more realistic network including a third population of inhibitory neurons with connectivity like that of PV neurons, according to known connectivity (<xref ref-type="bibr" rid="bib25">Jiang et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Pfeffer et al., 2013</xref>). We employed a brute force search considering 873,000 different combinations of dense, sparse, or zero connectivity for the 16 connections among the four network nodes in <xref ref-type="fig" rid="fig8">Figure 8A</xref> (more detail in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). We found only 31 configurations that matched the four criteria in <xref ref-type="fig" rid="fig8">Figure 8G</xref>. All matching configurations included one of two dense crossing inhibition motifs as well as segregated excitatory groups e+ and e− (<xref ref-type="fig" rid="fig8">Figure 8H</xref> and <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). In fact, these two motifs were sufficient for predicting which configurations match our experimental results with 80% accuracy (Methods).</p><p>Finally, we considered the exponents and scaling relationships for the event size and duration distributions from the (example shown in <xref ref-type="fig" rid="fig9">Figure 9A, B and C</xref>). We considered the parts of model parameter space with non-zero power-law range for e+ (<xref ref-type="fig" rid="fig9">Figure 9D</xref> inset). We compared to experimental results from all neural subsets and all recordings (<xref ref-type="fig" rid="fig9">Figure 9E</xref>). For smaller power-law ranges, τ and α were more scattered and inconsistent. For the model, we found <italic>τ</italic>=1.3 ± 0.12, <italic>α</italic>=1.4 ± 0.15, and <italic>β</italic>=1.4 ± 0.04, for power-law range above three decades. For both the experiment and the model, the best-fit β was typically not well predicted by crackling noise theory; a confirmation of crackling noise theory would have the points falling on the unity line in the right panels of <xref ref-type="fig" rid="fig9">Figure 9D and E</xref>.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Consistent scaling laws for large power-law range in model and experiment.</title><p>(<bold>A</bold>) Model example neural event size distribution with exponent <italic>τ</italic>=1.28 of the best fit power law. (<bold>B</bold>) Distribution of event durations from model with exponent <italic>α</italic>=1.5. (<bold>C</bold>) Event sizes scale with event duration to the power <italic>β</italic>=1.4. Note that the best-fit β is not well predicted by crackling noise theory (gold dashed line). (<bold>D</bold>) For the model, best fit scaling exponents τ, α, and β are consistent for large power-law range, but not for low power law range. Each gray point represents one run of the model. Different points come from different parameters (input and Λ) with non-zero power-law range. Inset in middle shows how many points came from each parameter combination (yellow = 4, dark blue = 0). Black points in right panels represent model parameters with power-law range above three decades. (<bold>E</bold>) Same as panel D, but experimental data are shown. Each point represents one neural subset. Color represents mouse. Experiment and model follow similar trends, but experiments tended to have smaller τ and larger β than the model, for large r. Crackling noise predictions of β are poor for both experiment and model. Dark colored points in right panels represent neural subsets with power-law range above 3.5 decades.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79950-fig9-v2.tif"/></fig><p>While our model offers a simple explanation of anticorrelated scale-free dynamics, its simplicity comes with limitations. Perhaps the most obvious limitation of our model is that it does not include neurons with weak correlations to both e+ and e− (those neurons in the middle of the correlation spectrum shown in <xref ref-type="fig" rid="fig7">Figure 7B</xref>). In <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>, we show that our model can be modified in a simple way to include asynchronous neurons. Another limitation is that we assumed that all non-zero synaptic connections were equal in weight. We loosen this assumption allowing for variable weights in <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>, without changing the basic features of anticorrelated scale-free fluctuations. Future work might improve our model further by accounting for neurons with intermediate correlations, i.e., less sharp boundaries of the e+ and e− groups.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have shown that ongoing, untrained locomotion, whisking, and pupil diameter changes in mice often exhibit scale-free dynamics. This scale-free behavior is directly related to concurrent scale-free cortical neural activity among certain subsets of neurons, with a strong one-to-one correspondence between many behavioral and neural events. Moreover, the subsets of neurons with the greatest range of scale-free-ness (i.e. the greatest power-law range) were the most correlated with behavior.</p><p>Why might a large power-law range among neurons be important for behavior? The behavioral variables we analyzed are likely to involve both local interactions among neighboring neurons and long-range coordination across many brain regions. For example, volitional movements like running and whisking presumably require coordinated interactions within and among motor, sensory, and other brain regions associated with decisions to move. One way to manifest such multiscale coordination from local to brain-wide circuits is to have neural events with sizes that occur with diverse scales, i.e., neural events with large power-law range.</p><p>Previous studies suggest additional functional implications of this close relationship between scale-free behavior and brain activity. First, scale-free neural activity has been associated with multiple functional benefits for sensory information processing and memory (<xref ref-type="bibr" rid="bib9">Clawson et al., 2017</xref>; <xref ref-type="bibr" rid="bib19">Gautam et al., 2015</xref>; <xref ref-type="bibr" rid="bib47">Shew and Plenz, 2013</xref>; <xref ref-type="bibr" rid="bib50">Shriki and Yellin, 2016</xref>; <xref ref-type="bibr" rid="bib56">Suárez et al., 2021</xref>), while scale-free behavior has been associated with benefits for foraging, search, and decision making (<xref ref-type="bibr" rid="bib1">Abe, 2020</xref>; <xref ref-type="bibr" rid="bib3">Barabási, 2005</xref>; <xref ref-type="bibr" rid="bib18">Garg and Kello, 2021</xref>; <xref ref-type="bibr" rid="bib51">Sims et al., 2008</xref>; <xref ref-type="bibr" rid="bib54">Sorribes et al., 2011</xref>; <xref ref-type="bibr" rid="bib60">Viswanathan et al., 1999</xref>; <xref ref-type="bibr" rid="bib64">Wosniack et al., 2017</xref>). Our results suggest that these two lists of functional benefits, previously considered separately, may in fact be a single unified list that occurs together. This long list of benefits may explain why several types of neural plasticity have been shown to maintain scale-free neural activity (<xref ref-type="bibr" rid="bib23">Hoseini et al., 2017</xref>; <xref ref-type="bibr" rid="bib32">Ma et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Shew et al., 2015</xref>).</p><p>What mechanisms are responsible for scale-free neural activity? The prevailing view is the criticality hypothesis (see for example <xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>; <xref ref-type="bibr" rid="bib33">Muñoz, 2018</xref>; <xref ref-type="bibr" rid="bib47">Shew and Plenz, 2013</xref>; <xref ref-type="bibr" rid="bib63">Wilting and Priesemann, 2019</xref>). In this view, scale-free dynamics occur because the system operates near criticality, i.e., near the tipping point between two distinct dynamical regimes - one synchronous, the other asynchronous. However, previously studied models of criticality fail to explain several crucial components of our observations. First, we observed that scale-free activity is limited to subsets of neurons, which were strongly anticorrelated with other subsets of neurons. This apparent stochastic winner-take-all competition between subsets results in the cancelation of fluctuations at the level of the total population, thus obscuring the scale-free dynamics of the subsets. Previous models also do not agree with the power-law scaling relationships we found – especially our measurements of β in the relation S(T)~T<sup>β</sup>. Our results suggest that a new type of criticality may be required to explain these observations. One possibility suggested by our model is that the scale-free dynamics we observe occur at the boundary between winner-less switching and single-winner locked-in dynamics (the red dashed line in <xref ref-type="fig" rid="fig8">Figure 8E and F</xref>). Additional theoretical efforts are necessary to more fully explore how the traditional criticality hypothesis relates to the competitive criticality suggested by our model.</p><p>At first glance, our results appear to not only contradict existing theory of criticality in neural systems, but also prior experimental observations based on different measurement methods. Most prominently, many previous studies have observed scale-free neural activity based on fast electrophysiological measurements using the total measured population, without accounting for anticorrelated subsets of neurons. Can fast ephys dynamics be reconciled with the slow calcium imaging signals we analyzed here? A detailed reconciliation of these different timescales of measurement will require more extensive investigation, but we provide a partial answer here (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s2">2</xref>). We analyzed an electrophysiological recording of spike times from 294 single units, also reported in the <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref> paper. We found that when the activity is analyzed at a fast time scale (5 ms resolution), scale-free activity is clear using the full population and anticorrelations were very weak. The exponent of the power law was near –2, consistent with some previous reports based on time-resolved spike recordings in awake animals (<xref ref-type="bibr" rid="bib13">Fontenele et al., 2019</xref>; <xref ref-type="bibr" rid="bib32">Ma et al., 2019</xref>). In contrast, when the activity was analyzed at a slow time scale (330 ms resolution) like the calcium imaging data, strong anticorrelations emerged and scale-free dynamics were much more apparent (i.e. power law range was greater) when analyzed in subsets of neurons. This result (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) suggests that our findings are not inconsistent with prior studies of scale-free activity based on time-resolved electrophysiological data and calls for a more thorough study of how correlation structure and scale-free dynamics differ and relate across spatiotemporal scales. At the coarse time resolution of the calcium imaging data, we note that the neural subsets with large power-law range tended to be composed of neurons with high activity variance and high pairwise covariance (<xref ref-type="fig" rid="fig8s3">Figure 8—figure supplement 3</xref>). We note that a similar point about the emergence of anticorrelations at slow timescales was made in the original <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref> paper.</p><p>What causes the scale-free fluctuations in behavior we observed from experiments? From the point of view of our model and the criticality hypothesis more generally, scale-free-ness originates in the dynamics of neural circuits. Indeed, the model generates scale-free fluctuations without any interactions with an ‘outside world.’ These internally generated scale-free neural dynamics then, might manifest as scale-free behavior. However, recalling that the experimental measurements reported here were from primary visual cortex, one might ask whether the scale-free fluctuations we observed in V1 are driven by scale-free fluctuations in visual input. In our view, this is unlikely given several facts. First, the gaze motion often had the least convincing scale-free-ness in our results (i.e. smallest power-law range, <xref ref-type="fig" rid="fig2">Figure 2C</xref>) and gaze motion would be the most obvious reason for changes in visual input (there were no dynamic visual stimuli on a viewed screen for these recordings). Second, the Stringer et al., paper (2019), from which our data originated, showed that spatially distributed electrophysiological recordings from multiple brain regions (not just sensory) were correlated to behavior in a similar way. This suggests that our results here may be a brain-wide phenomenon, not just a V1 phenomenon.</p><p>Setting aside speculations, our results firmly establish that complex fluctuations and events that make up scale-free neural activity are not ‘background noise’ nor ‘internal’ cognitive processes as is often supposed. Our findings call for a revision of these traditional views; scale-free neural activity directly causes (or perhaps is caused by) scale-free behavior and body motion.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Software,algorithm</td><td align="left" valign="bottom">Matlab</td><td align="left" valign="bottom">Mathworks</td><td align="left" valign="bottom">R2018a</td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Animals and data acquisition</title><p>The data analyzed here were first published in <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref> and are publicly available at doi:<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25378/janelia.6163622.v4">10.25378/janelia.6163622.v4</ext-link>.</p><p>All animal protocols and data acquisition methods are described in the original publication. All experimental procedures were conducted according to the UK Animals Scientific Procedures Act (1986). Experiments were performed at University College London under personal and project licenses released by the Home Office following appropriate ethics review. In brief, multiplane calcium imaging during periods with no visual stimulation was performed in seven adult mice (P35 to P125) bred to express GCaMP6s in excitatory neurons. Our labeling of the different recordings corresponds to the original authors’ labeling system of the data as follows:</p><list list-type="simple"><list-item><p>mouse 1 - spont_M150824_MP019_2016-04-05,</p></list-item><list-item><p>mouse 2 - spont_M160825_MP027_2016-12-12,</p></list-item><list-item><p>mouse 3 - spont_M160907_MP028_2016-09-26,</p></list-item><list-item><p>mouse 4 a - spont_M161025_MP030_2016-11-20,</p></list-item><list-item><p>mouse 4b - spont_M161025_MP030_2017-06-16,</p></list-item><list-item><p>mouse 4 c - spont_M161025_MP030_2017-06-23,</p></list-item><list-item><p>mouse 5 - spont_M170714_MP032_2017-08-04,</p></list-item><list-item><p>mouse 6 - spont_M170717_MP033_2017-08-18,</p></list-item><list-item><p>mouse 7 - spont_M170717_MP034_2017-08-25.</p></list-item></list></sec><sec id="s4-2"><title>Neural data pre-processing</title><p>Beginning from the deconvolved fluorescence traces (variable called Fsp in the original data set), first, the data were z-scored. That is, for each neuron, we subtracted its time-averaged activity and divided by its standard deviation. Second, we applied a low-pass filter (cutoff frequency 0.2 Hz, 2nd order butterworth filter, using Matlab filtfilt function).</p></sec><sec id="s4-3"><title>Definition of neural events</title><p>From previous studies of scale-free neural activity, there are three established strategies for defining neural events. The original approach was to first bin time (with time bin durations usually defined by the average inter-spike-interval, or average interval between LFP peaks) and define an event or avalanche as a sequence of time bins with at least one spike or LFP peak, preceded and terminated by an empty time bin (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>). This approach has been very useful when the data come from a relatively small number of neurons or electrodes but runs into difficulty with very large numbers of single neurons. The simple reason for this difficulty is that for very large numbers of neurons, there is simply no empty time bins (down to the time resolution of measurements), resulting in a single event that never ends. A second approach that better accounts for the possibility of more than one event occurring at the same time came from analyzing fMRI brain activity (<xref ref-type="bibr" rid="bib57">Tagliazucchi et al., 2012</xref>). This approach assumes that an event must evolve in a spatially contiguous way as it spreads through the brain. This approach, while good for spatially coarse measurements like fMRI, does not make sense for a small local circuit with a single neuron resolution like that analyzed here. The third approach is the one we adopted here, described in our Results section, which is the only good option, to our knowledge, for single neuron resolution and very large numbers of neurons.</p></sec><sec id="s4-4"><title>Power-law fitting and range</title><p>To assess the scale-freeness of behavioral events and neural population events, we developed an algorithm for finding the range of event sizes that are well fit by a power law. The algorithm is based on a maximum likelihood fitting procedure as established in previous work (e.g. <xref ref-type="bibr" rid="bib8">Clauset et al., 2009</xref>; <xref ref-type="bibr" rid="bib28">Langlois et al., 2014</xref>; <xref ref-type="bibr" rid="bib48">Shew et al., 2015</xref>). We fit the measured event size distribution with a truncated power-law with minimum event size s<sub>min</sub> and maximum event size s<sub>max</sub>, excluding data that fell outside these bounds during the fit process. Similar to previous studies, our algorithm has two fitting parameters - s<sub>min</sub> and the power-law exponent. s<sub>max</sub> was not a fitting parameter; it was chosen to be the largest observed event size (for subsets with power-law range &gt;3, the mean ± SD for s<sub>max</sub> was 59 ± 26 s for event durations and 102 ± 48 for event sizes). We tested exponents between 0.7 and 2 in steps of 0.02. We tested s<sub>min</sub> values between the smallest observed event size and the largest observed event size, increasing in 10 logarithmically spaced increments per decade. Thus, the power-law range reported in the manuscript has a resolution of 0.1 decades. Importantly, our fitting algorithm is entirely independent of any choice of binning that might be used to visualize the event size distribution.</p><p>For our purposes of measuring power law range, previously reported algorithms required improvements to account for (exclude) confounding outlier event sizes. These ‘outliers’ were rare events that caused noise in the extremes of the distribution tail or head and, in some cases, caused spuriously large power-law range estimates. Accounting for these outliers provides a more conservative estimate of power-law range. We defined outliers by first ranking all event sizes from smallest to largest. Next, we computed differences in sizes (in decades) for consecutive sizes in this ranked list. Outliers have a large difference in size compared to the following size (or preceding size). We define outliers as events with a size difference greater than 3% of the total range in decades. We also tried 6% as an outlier threshold and found that our results were not very sensitive to this choice (<xref ref-type="fig" rid="fig2">Figure 2C</xref>).</p><p>The fitting algorithm executed the following steps. First, outliers were excluded. Second, events with size less than s<sub>min</sub> were excluded. Third, the maximum likelihood power-law exponent was calculated. Fourth, we assessed the goodness-of-fit. We repeated these four steps for all the possible s<sub>min</sub> values, in the end, identifying the largest range (smallest s<sub>min</sub>) that passed our goodness-of-fit criterion.</p><p>The goodness-of-fit criterion we adopted here was also new, to our knowledge, and better suited to our goals of assessing power-law range, compared to previous methods. The steps for quantifying goodness-of-fit were as follows. First, we created a cumulative distribution function (CDF) of the real data. Second, we created 500 surrogate data sets drawn from the best-fit truncated power-law. Third, we created 500 CDFs, one for each of the surrogate data sets. Fourth, we resampled all 501 CDFs with 10 logarithmically spaced points per decade, linearly interpolated. Fifth, we calculated the fraction F of points in the resampled CDF of the real data that fell within the bounds of the 500 resampled surrogate CDFs. F is our goodness-of-fit measure. <italic>F</italic>=1 means that the entire range of the real data falls within the expected variation for a perfect power-law, given the number of samples in the data. We explored various goodness-of-fit criteria between <italic>F</italic>=0.75 and <italic>F</italic>=0.9 for the behavioral data (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) and the neural data (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). This is a rather conservative goodness-of-fit test, much more conservative than the more typically used Kolmogorov-Smirnov statistic for example.</p><p>The 500 surrogate data sets were also used for the purpose of creating the gray-shaded regions in each plotted distribution of avalanche sizes and durations (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, <xref ref-type="fig" rid="fig5">Figure 5A and B</xref>, <xref ref-type="fig" rid="fig9">Figure 9A and B</xref>). First, each surrogate data set was used to create a probability density function (PDF) with the same bins as the real data. Each of these PDFs was slightly different due to statistical noise (i.e. finite sample size). The gray-shaded region represents the range between which 90% of the surrogated PDFs fell. Thus, the gray region indicates how much variability one should expect for a perfect power law with the best fit exponent and the same range and sample size as the real data. We also use the upper and lower bounds of the gray region to estimate error bars for our exponents (as reported in <xref ref-type="fig" rid="fig2">Figure 2C</xref>, <xref ref-type="fig" rid="fig5">Figure 5A and B</xref>, <xref ref-type="fig" rid="fig9">Figure 9A and B</xref>) We calculate τ<sub>up</sub> from the slope of the upper boundary of the gray region and τ<sub>lo</sub> from the slope of the lower boundary of the gray region. Then we report τ = τ<sub>MLE</sub> ± τ<sub>VAR</sub>, where τ<sub>MLE</sub> is the maximum likelihood exponent and τ<sub>VAR</sub> = (τ<sub>up</sub> - τ<sub>lo</sub>)/2. Considering the event size exponents for all neural subsets with power-law range greater than 3, we found that τ<sub>VAR</sub>=0.07 ± 0.05 (mean, SD); corresponding event duration exponents had τ<sub>VAR</sub>=0.11 ± 0.07. For all behavioral event size distributions, τ<sub>VAR</sub>=0.19 ± 0.17.</p><p>In <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, we report the results of a benchmarking analysis in which we ran our power-law fitting algorithm on synthetic data sets drawn from known power-law distributions. We found that the exponents and power-law ranges found by our fitting algorithm are robust for a reasonable range of outlier exclusion thresholds (including 3% and 6%), different exponents, and sample sizes.</p></sec><sec id="s4-5"><title>Statistical significance of correlations</title><p><xref ref-type="fig" rid="fig6">Figure 6</xref> is based on computing correlation coefficients of short time series of behavior and neural activity. The number of such correlation coefficients computed for each behavioral event was 1000 because there were 1000 neural subsets. In the manuscript, we concluded that a significant number of these correlations were strong. This conclusion was arrived at by comparing to time-shifted control neural data (same as described for the time-shifted controls in the manuscript for <xref ref-type="fig" rid="fig3">Figure 3</xref>). The time shifts were randomly chosen from the interval 0 s up to the entire duration of the recording. A cyclic permutation was performed such that a time shift of + N samples would move the ith sample to become the (i+N)<sup>th</sup> and the last N samples become the first N. For each behavioral event, we obtained 1000 time-shifted control correlation coefficients. We then counted how many of the real correlation coefficients were greater than 999 of the time-shifted control correlation coefficients. By chance, we should expect this count to be one. We concluded that there was a significant number of strong correlations if this count was greater than four. A similar reasoning was used to conclude that there were a significant number of strongly correlated behavioral events for each neural subset.</p></sec><sec id="s4-6"><title>Computational model</title><p>The model consisted of N=1000 binary neurons; the state of the ith neuron at time t is <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> (quiescent) or <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> (firing). The population was divided into four groups called e+, e−, i+, and i−, as diagramed in <xref ref-type="fig" rid="fig8">Figure 8A</xref>. The e+ and e− groups include 400 excitatory neurons each; i+ and i− include 100 inhibitory neurons each. The dynamics of the neurons are updated synchronously according to<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where the activation probability is<disp-formula id="equ2"><mml:math id="m2"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>η</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf3"><mml:mi>η</mml:mi></mml:math></inline-formula> is a constant representing input from outside the model network and/or a tendency to fire spontaneously without input. We characterized how changes in <inline-formula><mml:math id="inf4"><mml:mi>η</mml:mi></mml:math></inline-formula> affect model dynamics in <xref ref-type="fig" rid="fig8">Figure 8E</xref> (vertical axis, labeled ‘external drive’). The connection from neuron j to neuron i is given by <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , one element of the connection matrix depicted in <xref ref-type="fig" rid="fig8">Figure 8A</xref>. Certain pairs of groups were sparsely connected, while other pairs of groups were densely connected, or not connected at all. 50% of connections (randomly chosen) were zero for two densely connected groups. 95% of connections (randomly chosen) were zero for a sparsely connected pair of groups. All non-zero excitatory connections were set to the same constant <italic>c</italic>; all non-zero inhibitory connections were set to <italic>-c</italic>. The value of <italic>c</italic> was set by first normalizing the entire connection matrix by its largest eigenvalue and then multiplying by another constant <inline-formula><mml:math id="inf6"><mml:mi>Λ</mml:mi></mml:math></inline-formula> to obtain the desired largest eigenvalue. We studied how the model dynamics depend on <inline-formula><mml:math id="inf7"><mml:mi>Λ</mml:mi></mml:math></inline-formula> in <xref ref-type="fig" rid="fig8">Figure 8F</xref> and <xref ref-type="fig" rid="fig8">Figure 8G</xref> (horizontal axis). For the shotgun search of many different circuit configurations, we set <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. We also studied how the density of connectivity between e+ and e− impacted model dynamics in <xref ref-type="fig" rid="fig8">Figure 8F</xref> (vertical axis, called ‘crossing excitation’).</p><p>All model data analysis was done on the population activity and averaged over neurons for each group.</p><p>We did a shotgun search for model configurations that result in dynamics consistent with our experimental results. To do this, we first generated a list of all possible configurations of the 16 pairwise group connections. We considered three possible densities for each of these connections: disconnected (0%), sparse (5%), or dense (50%). Thus, the list of all possible connection configurations includes 3<sup>16</sup> (more than 43 million) possibilities. Clearly testing all these possibilities would take a long time, so we pared down the list with the following constraints, which exclude several very unrealistic possibilities:</p><list list-type="order"><list-item><p>Both e+ and e− groups must have non-zero within-group connectivity.</p></list-item><list-item><p>No disconnected components were allowed. Every group had to be reachable by at least one connection.</p></list-item><list-item><p>There must be at least one excitatory to inhibitory connection.</p></list-item><list-item><p>There must be at least one inhibitory to excitatory connection.</p></list-item></list><p>After applying these constraints, the list of possible configurations still included 18,576,000 possible circuits. We tested 8,73,000 of these possibilities, chosen at random. We considered a circuit to be consistent with experimental results if it met the following conditions:</p><list list-type="order"><list-item><p>Correlation coefficient of e+ and e− must be less than –0.5</p></list-item><list-item><p>Correlation coefficient of i+ and i− must be less than –0.5</p></list-item><list-item><p>Power law range of e+ or e− must be greater than 3.5 decades</p></list-item><list-item><p>Power law range of the total population must be less than 2 decades</p></list-item></list><p>We found that only 31 circuit configurations met these conditions. These matching networks are illustrated in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>. As noted in the main text, all matching configurations featured two structural motifs. First, they included dense self-connections within e+ and within e−, but weak or non-existent connections between e+ and e−. Second, all matching configurations included one of two dense crossing inhibition configurations (<xref ref-type="fig" rid="fig8">Figure 8H</xref>). Moreover, we found that these two conditions were sufficient to predict which networks would match the experimental results with 80% accuracy if we loosened the criteria for matching experiments slightly. These looser criteria were:</p><list list-type="order"><list-item><p>Correlation coefficient of e+ and e− must be less than –0.5</p></list-item><list-item><p>Correlation coefficient of i+ and i− must be less than –0.2</p></list-item><list-item><p>Power law range of e+ or e− must be at least 1.4 times that of the total population</p></list-item></list></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Formal analysis, Investigation</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experimental procedures were conducted according to the UK Animals Scientific Procedures Act (1986). Experiments were performed at University College London under personal and project licenses released by the Home Office following appropriate ethics review.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-79950-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data analyzed here were first published in <xref ref-type="bibr" rid="bib55">Stringer et al., 2019</xref> and are publicly available on figshare at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25378/janelia.6163622.v6">https://doi.org/10.25378/janelia.6163622.v6</ext-link>. Analysis code is publicly available on figshare at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2021.05.12.443799">https://doi.org/10.1101/2021.05.12.443799</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Shrew</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Code for computational model, power law fitting, power law range [Shew Lab]</data-title><source>figshare</source><pub-id pub-id-type="doi">10.6084/m9.figshare.21954389.v1</pub-id></element-citation></p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>C</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Recordings of ten thousand neurons in visual cortex during spontaneous behaviors</data-title><source>Figshare</source><pub-id pub-id-type="doi">10.25378/janelia.6163622.v6</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abe</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Functional advantages of Lévy walks emerging near a critical point</article-title><source>PNAS</source><volume>117</volume><fpage>24336</fpage><lpage>24344</lpage><pub-id pub-id-type="doi">10.1073/pnas.2001548117</pub-id><pub-id pub-id-type="pmid">32929032</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anteneodo</surname><given-names>C</given-names></name><name><surname>Chialvo</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Unraveling the fluctuations of animal motor activity</article-title><source>Chaos</source><volume>19</volume><elocation-id>033123</elocation-id><pub-id pub-id-type="doi">10.1063/1.3211189</pub-id><pub-id pub-id-type="pmid">19792003</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barabási</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The origin of bursts and heavy tails in human dynamics</article-title><source>Nature</source><volume>435</volume><fpage>207</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1038/nature03459</pub-id><pub-id pub-id-type="pmid">15889093</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beggs</surname><given-names>JM</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neuronal avalanches in neocortical circuits</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>11167</fpage><lpage>11177</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-35-11167.2003</pub-id><pub-id pub-id-type="pmid">14657176</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellay</surname><given-names>T</given-names></name><name><surname>Klaus</surname><given-names>A</given-names></name><name><surname>Seshadri</surname><given-names>S</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Irregular spiking of pyramidal neurons organizes as scale-invariant neuronal avalanches in the awake state</article-title><source>eLife</source><volume>4</volume><elocation-id>e07224</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.07224</pub-id><pub-id pub-id-type="pmid">26151674</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellay</surname><given-names>T</given-names></name><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Yu</surname><given-names>S</given-names></name><name><surname>Falco-Walter</surname><given-names>JJ</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Selective participation of single cortical neurons in neuronal avalanches</article-title><source>Frontiers in Neural Circuits</source><volume>14</volume><elocation-id>620052</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2020.620052</pub-id><pub-id pub-id-type="pmid">33551757</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clancy</surname><given-names>KB</given-names></name><name><surname>Orsolic</surname><given-names>I</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Locomotion-dependent remapping of distributed cortical networks</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>778</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0357-8</pub-id><pub-id pub-id-type="pmid">30858604</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clauset</surname><given-names>A</given-names></name><name><surname>Shalizi</surname><given-names>CR</given-names></name><name><surname>Newman</surname><given-names>MEJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Power-Law distributions in empirical data</article-title><source>SIAM Review</source><volume>51</volume><fpage>661</fpage><lpage>703</lpage><pub-id pub-id-type="doi">10.1137/070710111</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clawson</surname><given-names>WP</given-names></name><name><surname>Wright</surname><given-names>NC</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name><name><surname>Shew</surname><given-names>WL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Adaptation towards scale-free dynamics improves cortical stimulus discrimination at the cost of reduced detection</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005574</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005574</pub-id><pub-id pub-id-type="pmid">28557985</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cossell</surname><given-names>L</given-names></name><name><surname>Iacaruso</surname><given-names>MF</given-names></name><name><surname>Muir</surname><given-names>DR</given-names></name><name><surname>Houlton</surname><given-names>R</given-names></name><name><surname>Sader</surname><given-names>EN</given-names></name><name><surname>Ko</surname><given-names>H</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional organization of excitatory synaptic strength in primary visual cortex</article-title><source>Nature</source><volume>518</volume><fpage>399</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1038/nature14182</pub-id><pub-id pub-id-type="pmid">25652823</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalla Porta</surname><given-names>L</given-names></name><name><surname>Copelli</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Modeling neuronal avalanches and long-range temporal correlations at the emergence of collective oscillations: continuously varying exponents mimic M/EEG results</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006924</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006924</pub-id><pub-id pub-id-type="pmid">30951525</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>di Santo</surname><given-names>S</given-names></name><name><surname>Villegas</surname><given-names>P</given-names></name><name><surname>Burioni</surname><given-names>R</given-names></name><name><surname>Muñoz</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Landau-ginzburg theory of cortex dynamics: scale-free avalanches emerge at the edge of synchronization</article-title><source>PNAS</source><volume>115</volume><fpage>E1356</fpage><lpage>E1365</lpage><pub-id pub-id-type="doi">10.1073/pnas.1712989115</pub-id><pub-id pub-id-type="pmid">29378970</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fontenele</surname><given-names>AJ</given-names></name><name><surname>de Vasconcelos</surname><given-names>NAP</given-names></name><name><surname>Feliciano</surname><given-names>T</given-names></name><name><surname>Aguiar</surname><given-names>LAA</given-names></name><name><surname>Soares-Cunha</surname><given-names>C</given-names></name><name><surname>Coimbra</surname><given-names>B</given-names></name><name><surname>Dalla Porta</surname><given-names>L</given-names></name><name><surname>Ribeiro</surname><given-names>S</given-names></name><name><surname>Rodrigues</surname><given-names>AJ</given-names></name><name><surname>Sousa</surname><given-names>N</given-names></name><name><surname>Carelli</surname><given-names>PV</given-names></name><name><surname>Copelli</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Criticality between cortical states</article-title><source>Physical Review Letters</source><volume>122</volume><elocation-id>208101</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.122.208101</pub-id><pub-id pub-id-type="pmid">31172737</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fosque</surname><given-names>LJ</given-names></name><name><surname>Williams-García</surname><given-names>RV</given-names></name><name><surname>Beggs</surname><given-names>JM</given-names></name><name><surname>Ortiz</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Evidence for quasicritical brain dynamics</article-title><source>Physical Review Letters</source><volume>126</volume><elocation-id>98101</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.126.098101</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>N</given-names></name><name><surname>Ito</surname><given-names>S</given-names></name><name><surname>Brinkman</surname><given-names>BAW</given-names></name><name><surname>Shimono</surname><given-names>M</given-names></name><name><surname>DeVille</surname><given-names>REL</given-names></name><name><surname>Dahmen</surname><given-names>KA</given-names></name><name><surname>Beggs</surname><given-names>JM</given-names></name><name><surname>Butler</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Universal critical dynamics in high resolution neuronal avalanche data</article-title><source>Physical Review Letters</source><volume>108</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.108.208102</pub-id><pub-id pub-id-type="pmid">23003192</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>P</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fast online deconvolution of calcium imaging data</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005423</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005423</pub-id><pub-id pub-id-type="pmid">28291787</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia-Junco-Clemente</surname><given-names>P</given-names></name><name><surname>Ikrar</surname><given-names>T</given-names></name><name><surname>Tring</surname><given-names>E</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name><name><surname>Trachtenberg</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An inhibitory pull-push circuit in frontal cortex</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>389</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1038/nn.4483</pub-id><pub-id pub-id-type="pmid">28114295</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garg</surname><given-names>K</given-names></name><name><surname>Kello</surname><given-names>CT</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Efficient Lévy walks in virtual human foraging</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>5242</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-84542-w</pub-id><pub-id pub-id-type="pmid">33664346</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gautam</surname><given-names>SH</given-names></name><name><surname>Hoang</surname><given-names>TT</given-names></name><name><surname>McClanahan</surname><given-names>K</given-names></name><name><surname>Grady</surname><given-names>SK</given-names></name><name><surname>Shew</surname><given-names>WL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Maximizing sensory dynamic range by tuning the cortical state to criticality</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004576</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004576</pub-id><pub-id pub-id-type="pmid">26623645</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Girardi-Schappo</surname><given-names>M</given-names></name><name><surname>Brochini</surname><given-names>L</given-names></name><name><surname>Costa</surname><given-names>AA</given-names></name><name><surname>Carvalho</surname><given-names>TTA</given-names></name><name><surname>Kinouchi</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Synaptic balance due to homeostatically self-organized quasicritical dynamics</article-title><source>Physical Review Research</source><volume>2</volume><elocation-id>12042</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevResearch.2.012042</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gireesh</surname><given-names>ED</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neuronal avalanches organize as nested theta- and beta/gamma-oscillations during development of cortical layer 2/3</article-title><source>PNAS</source><volume>105</volume><fpage>7576</fpage><lpage>7581</lpage><pub-id pub-id-type="doi">10.1073/pnas.0800537105</pub-id><pub-id pub-id-type="pmid">18499802</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardstone</surname><given-names>R</given-names></name><name><surname>Poil</surname><given-names>S-S</given-names></name><name><surname>Schiavone</surname><given-names>G</given-names></name><name><surname>Jansen</surname><given-names>R</given-names></name><name><surname>Nikulin</surname><given-names>VV</given-names></name><name><surname>Mansvelder</surname><given-names>HD</given-names></name><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Detrended fluctuation analysis: a scale-free view on neuronal oscillations</article-title><source>Frontiers in Physiology</source><volume>3</volume><elocation-id>450</elocation-id><pub-id pub-id-type="doi">10.3389/fphys.2012.00450</pub-id><pub-id pub-id-type="pmid">23226132</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoseini</surname><given-names>MS</given-names></name><name><surname>Pobst</surname><given-names>J</given-names></name><name><surname>Wright</surname><given-names>NC</given-names></name><name><surname>Clawson</surname><given-names>W</given-names></name><name><surname>Shew</surname><given-names>W</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Induced cortical oscillations in turtle cortex are coherent at the mesoscale of population activity, but not at the microscale of the membrane potential of neurons</article-title><source>Journal of Neurophysiology</source><volume>118</volume><fpage>2579</fpage><lpage>2591</lpage><pub-id pub-id-type="doi">10.1152/jn.00375.2017</pub-id><pub-id pub-id-type="pmid">28794194</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>L</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Lecoq</surname><given-names>J</given-names></name><name><surname>Murphy</surname><given-names>GJ</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>de Vries</surname><given-names>SE</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Buice</surname><given-names>MA</given-names></name><name><surname>Waters</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Relationship between simultaneously recorded spiking activity and fluorescence signal in gcamp6 transgenic mice</article-title><source>eLife</source><volume>10</volume><elocation-id>e51675</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51675</pub-id><pub-id pub-id-type="pmid">33683198</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Shen</surname><given-names>S</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Sinz</surname><given-names>F</given-names></name><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Patel</surname><given-names>S</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Principles of connectivity among morphologically defined cell types in adult neocortex</article-title><source>Science</source><volume>350</volume><elocation-id>aac9462</elocation-id><pub-id pub-id-type="doi">10.1126/science.aac9462</pub-id><pub-id pub-id-type="pmid">26612957</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kello</surname><given-names>CT</given-names></name><name><surname>Brown</surname><given-names>GDA</given-names></name><name><surname>Ferrer-I-Cancho</surname><given-names>R</given-names></name><name><surname>Holden</surname><given-names>JG</given-names></name><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name><name><surname>Rhodes</surname><given-names>T</given-names></name><name><surname>Van Orden</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Scaling laws in cognitive sciences</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>223</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.02.005</pub-id><pub-id pub-id-type="pmid">20363176</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiehn</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decoding the organization of spinal circuits that control locomotion</article-title><source>Nature Reviews. Neuroscience</source><volume>17</volume><fpage>224</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.9</pub-id><pub-id pub-id-type="pmid">26935168</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langlois</surname><given-names>D</given-names></name><name><surname>Cousineau</surname><given-names>D</given-names></name><name><surname>Thivierge</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Maximum likelihood estimators for truncated and censored power-law distributions show how neuronal avalanches may be misevaluated</article-title><source>Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</source><volume>89</volume><elocation-id>012709</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.89.012709</pub-id><pub-id pub-id-type="pmid">24580259</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larremore</surname><given-names>DB</given-names></name><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Restrepo</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Predicting criticality and dynamic range in complex networks: effects of topology</article-title><source>Physical Review Letters</source><volume>106</volume><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.106.058101</pub-id><pub-id pub-id-type="pmid">21405438</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larremore</surname><given-names>DB</given-names></name><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Ott</surname><given-names>E</given-names></name><name><surname>Sorrentino</surname><given-names>F</given-names></name><name><surname>Restrepo</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Inhibition causes ceaseless dynamics in networks of excitable nodes</article-title><source>Physical Review Letters</source><volume>112</volume><elocation-id>138103</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.112.138103</pub-id><pub-id pub-id-type="pmid">24745460</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Shew</surname><given-names>WL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Tuning network dynamics from criticality to an asynchronous state</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008268</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008268</pub-id><pub-id pub-id-type="pmid">32986705</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>Z</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name><name><surname>Hengen</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical circuit dynamics are homeostatically tuned to criticality in vivo</article-title><source>Neuron</source><volume>104</volume><fpage>655</fpage><lpage>664</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.08.031</pub-id><pub-id pub-id-type="pmid">31601510</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muñoz</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Colloquium: criticality and dynamical scaling in living systems</article-title><source>Reviews of Modern Physics</source><volume>90</volume><elocation-id>31001</elocation-id><pub-id pub-id-type="doi">10.1093/ejcts/ezx068</pub-id><pub-id pub-id-type="pmid">28380633</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palva</surname><given-names>JM</given-names></name><name><surname>Zhigalov</surname><given-names>A</given-names></name><name><surname>Hirvonen</surname><given-names>J</given-names></name><name><surname>Korhonen</surname><given-names>O</given-names></name><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name><name><surname>Palva</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neuronal long-range temporal correlations and avalanche dynamics are correlated with behavioral scaling laws</article-title><source>PNAS</source><volume>110</volume><fpage>3585</fpage><lpage>3590</lpage><pub-id pub-id-type="doi">10.1073/pnas.1216855110</pub-id><pub-id pub-id-type="pmid">23401536</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeffer</surname><given-names>CK</given-names></name><name><surname>Xue</surname><given-names>M</given-names></name><name><surname>He</surname><given-names>M</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inhibition of inhibition in visual cortex: the logic of connections between molecularly distinct interneurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1068</fpage><lpage>1076</lpage><pub-id pub-id-type="doi">10.1038/nn.3446</pub-id><pub-id pub-id-type="pmid">23817549</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pi</surname><given-names>HJ</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Kvitsiani</surname><given-names>D</given-names></name><name><surname>Sanders</surname><given-names>JI</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical interneurons that specialize in disinhibitory control</article-title><source>Nature</source><volume>503</volume><fpage>521</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1038/nature12676</pub-id><pub-id pub-id-type="pmid">24097352</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poil</surname><given-names>SS</given-names></name><name><surname>Hardstone</surname><given-names>R</given-names></name><name><surname>Mansvelder</surname><given-names>HD</given-names></name><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Critical-state dynamics of avalanches and oscillations jointly emerge from balanced excitation/inhibition in neuronal networks</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>9817</fpage><lpage>9823</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5990-11.2012</pub-id><pub-id pub-id-type="pmid">22815496</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priesemann</surname><given-names>V</given-names></name><name><surname>Wibral</surname><given-names>M</given-names></name><name><surname>Valderrama</surname><given-names>M</given-names></name><name><surname>Pröpper</surname><given-names>R</given-names></name><name><surname>Le Van Quyen</surname><given-names>M</given-names></name><name><surname>Geisel</surname><given-names>T</given-names></name><name><surname>Triesch</surname><given-names>J</given-names></name><name><surname>Nikolić</surname><given-names>D</given-names></name><name><surname>Munk</surname><given-names>MHJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spike avalanches in vivo suggest a driven, slightly subcritical brain state</article-title><source>Frontiers in Systems Neuroscience</source><volume>8</volume><elocation-id>108</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2014.00108</pub-id><pub-id pub-id-type="pmid">25009473</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Proekt</surname><given-names>A</given-names></name><name><surname>Banavar</surname><given-names>JR</given-names></name><name><surname>Maritan</surname><given-names>A</given-names></name><name><surname>Pfaff</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Scale invariance in the dynamics of spontaneous behavior</article-title><source>PNAS</source><volume>109</volume><fpage>10564</fpage><lpage>10569</lpage><pub-id pub-id-type="doi">10.1073/pnas.1206894109</pub-id><pub-id pub-id-type="pmid">22679281</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Yatsenko</surname><given-names>D</given-names></name><name><surname>Denfield</surname><given-names>GH</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil fluctuations track fast switching of cortical states during quiet wakefulness</article-title><source>Neuron</source><volume>84</volume><fpage>355</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.033</pub-id><pub-id pub-id-type="pmid">25374359</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Rodenkirch</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13289</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id><pub-id pub-id-type="pmid">27824036</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salkoff</surname><given-names>DB</given-names></name><name><surname>Zagha</surname><given-names>E</given-names></name><name><surname>McCarthy</surname><given-names>E</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Movement and performance explain widespread cortical activity in a visual detection task</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>421</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz206</pub-id><pub-id pub-id-type="pmid">31711133</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>JW</given-names></name><name><surname>Sherrill</surname><given-names>L</given-names></name><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Zhao</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Tuning to odor solubility and sorption pattern in olfactory epithelial responses</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>2025</fpage><lpage>2036</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3736-13.2014</pub-id><pub-id pub-id-type="pmid">24501345</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sethna</surname><given-names>JP</given-names></name><name><surname>Dahmen</surname><given-names>KA</given-names></name><name><surname>Myers</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Crackling noise</article-title><source>Nature</source><volume>410</volume><fpage>242</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1038/35065675</pub-id><pub-id pub-id-type="pmid">11258379</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Petermann</surname><given-names>T</given-names></name><name><surname>Roy</surname><given-names>R</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neuronal avalanches imply maximum dynamic range in cortical networks at criticality</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>15595</fpage><lpage>15600</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3864-09.2009</pub-id><pub-id pub-id-type="pmid">20007483</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The functional benefits of criticality in the cortex</article-title><source>The Neuroscientist</source><volume>19</volume><fpage>88</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1177/1073858412445487</pub-id><pub-id pub-id-type="pmid">22627091</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Clawson</surname><given-names>WP</given-names></name><name><surname>Pobst</surname><given-names>J</given-names></name><name><surname>Karimipanah</surname><given-names>Y</given-names></name><name><surname>Wright</surname><given-names>NC</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Adaptation to sensory input tunes visual cortex to criticality</article-title><source>Nature Physics</source><volume>11</volume><fpage>659</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1038/nphys3370</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shriki</surname><given-names>O</given-names></name><name><surname>Alstott</surname><given-names>J</given-names></name><name><surname>Carver</surname><given-names>F</given-names></name><name><surname>Holroyd</surname><given-names>T</given-names></name><name><surname>Henson</surname><given-names>RNA</given-names></name><name><surname>Smith</surname><given-names>ML</given-names></name><name><surname>Coppola</surname><given-names>R</given-names></name><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neuronal avalanches in the resting MEG of the human brain</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>7079</fpage><lpage>7090</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4286-12.2013</pub-id><pub-id pub-id-type="pmid">23595765</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shriki</surname><given-names>O</given-names></name><name><surname>Yellin</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Optimal information representation and criticality in an adaptive sensory recurrent neuronal network</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004698</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004698</pub-id><pub-id pub-id-type="pmid">26882372</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sims</surname><given-names>DW</given-names></name><name><surname>Southall</surname><given-names>EJ</given-names></name><name><surname>Humphries</surname><given-names>NE</given-names></name><name><surname>Hays</surname><given-names>GC</given-names></name><name><surname>Bradshaw</surname><given-names>CJA</given-names></name><name><surname>Pitchford</surname><given-names>JW</given-names></name><name><surname>James</surname><given-names>A</given-names></name><name><surname>Ahmed</surname><given-names>MZ</given-names></name><name><surname>Brierley</surname><given-names>AS</given-names></name><name><surname>Hindell</surname><given-names>MA</given-names></name><name><surname>Morritt</surname><given-names>D</given-names></name><name><surname>Musyl</surname><given-names>MK</given-names></name><name><surname>Righton</surname><given-names>D</given-names></name><name><surname>Shepard</surname><given-names>ELC</given-names></name><name><surname>Wearmouth</surname><given-names>VJ</given-names></name><name><surname>Wilson</surname><given-names>RP</given-names></name><name><surname>Witt</surname><given-names>MJ</given-names></name><name><surname>Metcalfe</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Scaling laws of marine predator search behaviour</article-title><source>Nature</source><volume>451</volume><fpage>1098</fpage><lpage>1102</lpage><pub-id pub-id-type="doi">10.1038/nature06518</pub-id><pub-id pub-id-type="pmid">18305542</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smit</surname><given-names>DJA</given-names></name><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name><name><surname>de Geus</surname><given-names>EJC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-range temporal correlations in resting-state α oscillations predict human timing-error dynamics</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>11212</fpage><lpage>11220</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2816-12.2013</pub-id><pub-id pub-id-type="pmid">23825424</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Sjöström</surname><given-names>PJ</given-names></name><name><surname>Reigl</surname><given-names>M</given-names></name><name><surname>Nelson</surname><given-names>S</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title><source>PLOS Biology</source><volume>3</volume><elocation-id>e68</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0030068</pub-id><pub-id pub-id-type="pmid">15737062</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorribes</surname><given-names>A</given-names></name><name><surname>Armendariz</surname><given-names>BG</given-names></name><name><surname>Lopez-Pigozzi</surname><given-names>D</given-names></name><name><surname>Murga</surname><given-names>C</given-names></name><name><surname>de Polavieja</surname><given-names>GG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The origin of behavioral bursts in decision-making circuitry</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1002075</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002075</pub-id><pub-id pub-id-type="pmid">21731478</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>255</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suárez</surname><given-names>LE</given-names></name><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Lajoie</surname><given-names>G</given-names></name><name><surname>Misic</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning function from structure in neuromorphic networks</article-title><source>Nature Machine Intelligence</source><volume>3</volume><fpage>771</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1038/s42256-021-00376-1</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tagliazucchi</surname><given-names>E</given-names></name><name><surname>Balenzuela</surname><given-names>P</given-names></name><name><surname>Fraiman</surname><given-names>D</given-names></name><name><surname>Chialvo</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Criticality in large-scale brain FMRI dynamics unveiled by a novel point process analysis</article-title><source>Frontiers in Physiology</source><volume>3</volume><elocation-id>15</elocation-id><pub-id pub-id-type="doi">10.3389/fphys.2012.00015</pub-id><pub-id pub-id-type="pmid">22347863</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tetzlaff</surname><given-names>C</given-names></name><name><surname>Okujeni</surname><given-names>S</given-names></name><name><surname>Egert</surname><given-names>U</given-names></name><name><surname>Wörgötter</surname><given-names>F</given-names></name><name><surname>Butz</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Self-organized criticality in developing neuronal networks</article-title><source>PLOS Computational Biology</source><volume>6</volume><elocation-id>e1001013</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1001013</pub-id><pub-id pub-id-type="pmid">21152008</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id><pub-id pub-id-type="pmid">25892300</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viswanathan</surname><given-names>GM</given-names></name><name><surname>Buldyrev</surname><given-names>SV</given-names></name><name><surname>Havlin</surname><given-names>S</given-names></name><name><surname>da Luz</surname><given-names>MG</given-names></name><name><surname>Raposo</surname><given-names>EP</given-names></name><name><surname>Stanley</surname><given-names>HE</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Optimizing the success of random searches</article-title><source>Nature</source><volume>401</volume><fpage>911</fpage><lpage>914</lpage><pub-id pub-id-type="doi">10.1038/44831</pub-id><pub-id pub-id-type="pmid">10553906</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wall</surname><given-names>NR</given-names></name><name><surname>De La Parra</surname><given-names>M</given-names></name><name><surname>Sorokin</surname><given-names>JM</given-names></name><name><surname>Taniguchi</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Brain-Wide maps of synaptic input to cortical interneurons</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>4000</fpage><lpage>4009</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3967-15.2016</pub-id><pub-id pub-id-type="pmid">27053207</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilting</surname><given-names>J</given-names></name><name><surname>Dehning</surname><given-names>J</given-names></name><name><surname>Pinheiro Neto</surname><given-names>J</given-names></name><name><surname>Rudelt</surname><given-names>L</given-names></name><name><surname>Wibral</surname><given-names>M</given-names></name><name><surname>Zierenberg</surname><given-names>J</given-names></name><name><surname>Priesemann</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Operating in a reverberating regime enables rapid tuning of network states to task requirements</article-title><source>Frontiers in Systems Neuroscience</source><volume>12</volume><elocation-id>55</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2018.00055</pub-id><pub-id pub-id-type="pmid">30459567</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilting</surname><given-names>J</given-names></name><name><surname>Priesemann</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>25 years of criticality in neuroscience-established results, open controversies, novel concepts</article-title><source>Current Opinion in Neurobiology</source><volume>58</volume><fpage>105</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.08.002</pub-id><pub-id pub-id-type="pmid">31546053</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wosniack</surname><given-names>ME</given-names></name><name><surname>Santos</surname><given-names>MC</given-names></name><name><surname>Raposo</surname><given-names>EP</given-names></name><name><surname>Viswanathan</surname><given-names>GM</given-names></name><name><surname>da Luz</surname><given-names>MGE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The evolutionary origins of Lévy walk foraging</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005774</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005774</pub-id><pub-id pub-id-type="pmid">28972973</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Roy</surname><given-names>R</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Maximal variability of phase synchrony in cortical networks with neuronal avalanches</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>1061</fpage><lpage>1072</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2771-11.2012</pub-id><pub-id pub-id-type="pmid">22262904</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>S</given-names></name><name><surname>Ribeiro</surname><given-names>TL</given-names></name><name><surname>Meisel</surname><given-names>C</given-names></name><name><surname>Chou</surname><given-names>S</given-names></name><name><surname>Mitz</surname><given-names>A</given-names></name><name><surname>Saunders</surname><given-names>R</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Maintained avalanche dynamics during task-induced changes of neuronal activity in nonhuman primates</article-title><source>eLife</source><volume>6</volume><elocation-id>e27119</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27119</pub-id><pub-id pub-id-type="pmid">29115213</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zagha</surname><given-names>E</given-names></name><name><surname>Ge</surname><given-names>X</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Competing neural ensembles in motor cortex gate goal-directed motor output</article-title><source>Neuron</source><volume>88</volume><fpage>565</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.044</pub-id><pub-id pub-id-type="pmid">26593093</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79950.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Berman</surname><given-names>Gordon J</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03czfpz43</institution-id><institution>Emory University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.05.12.443799" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.05.12.443799"/></front-stub><body><p>This paper is an important study that is of interest to neuroscientists studying the organization of neural activity and behavior. The authors present compelling evidence to link the apparently scale-free distributions of behavioral metrics with scale-free distributions of neural activity. They then explore computationally mechanistic models that could account for these observations. The simulations of mechanistic models are provocative and suggest interesting network-connectivity hypotheses to test in future experiments.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79950.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Berman</surname><given-names>Gordon J</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03czfpz43</institution-id><institution>Emory University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Hengen</surname><given-names>Keith B</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01yc7t268</institution-id><institution>Washington University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.05.12.443799">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.05.12.443799v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Scale-free behavioral dynamics directly linked with scale-free cortical dynamics&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Ronald Calabrese as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Keith B Hengen (Reviewer #1).</p><p>The reviewers have discussed their reviews with one another, and although there were some concerns, there was general enthusiasm for the approach and for the ideas presented in the work. Accordingly, the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. The reviewers would like to see a detailed and thoughtful reflection on the role that 3 Hz Ca imaging might play in the conclusions that the authors derive. While the dataset in question offers many neurons, this approach is, from other perspectives, impoverished – calcium intrinsically misses spikes, a 3 Hz sampling rate is two orders of magnitude slower than an action potential, and the recordings are relatively short for amassing substantial observations of low probability (large) avalanches. The potential concern is that some of this disconnect may reflect optophysiological constraints. One argument against this is that a truly scale free system should be observable at any temporal or spatial scale and still give rise to the same sets of power laws. This quickly falls apart when applied to biological systems which are neither infinite in time nor space. As a result, the severe mismatch between the spatial resolution (single cell) and the temporal resolution (3 Hz) of the dataset, combined with filtering intrinsic to calcium imaging, raises the possibility that the conclusions are influenced by the methods.</p><p>2. Another reservation expressed by the referees has to do with the generality of the conclusions drawn from the mechanistic model. One of the connectivity motifs identified appears to be i+ to e- and i- to e+, where potentially i+/i- are SOM and VIP (or really any specific inhibitory type) cells. The specific connections to subsets of excitatory cells appear to be important (based on the solid lines in Figure 8). This seems surprising: is there any experimental support for excitatory cells to preferentially receive inhibition from either SOM or VIP, but not both? More broadly, there was concern that the neat diagrams drawn here are misleading. The sample raster, showing what appears to be the full simulation, certainly captures the correlated/anti-correlated pattern of the 100 cells most correlated with a seed cell and 100 cells most anti-correlated with it, but it does not contain the 11,000 cells in between with zero to moderate levels of correlation. We probably expect that the full covariance matrix has similar structure from any seed (see Meshulam et al. 2019, PRL, for an analysis of scaling of coarse-grained activity covariance), and this suggests multiple cross-over inhibition constraints, which seem like they could be hard to satisfy. The motifs identified in Figure 8 likely exist, but I am left with many questions of what we learned about connectivity rules that would account for the full distribution of correlations. Would starting with an Erdos-Renyi network with slight over-representation of these motifs be sufficient? How important is the homogeneous connection weights from each pool assumption – would allowing connection weights with some dispersion change the results?</p><p>3. Putting 2) another way, it's unclear why the averaging is required in the first place. This operation projects the entire population down in an incredibly lossy way and removes much of the complexity of the population activity. Second, the authors state that it is highly curious that subsets of the population exhibit power laws while the entire population does not. While the discussion and hypothesizing about different e-i interactions is interesting, it is possible that there's a discussion to be had on a much more basic level of whether there are topology independent explanations, such as basic distributions of correlations between neurons that can explain the subnetwork averaging. Specifically, if the correlation to any given neuron falls off, e.g., with an exponential falloff (i.e., a Gaussian Process type covariance between neurons), it seems that similar effects should hold. This type of effect can be easily tested by generating null distributions existing code bases. This is an important point since local (broadly defined) correlations of neurons implying the observed subnetwork behavior means that many mechanisms that have local correlations but don't cluster in any meaningful way could also be responsible for the local averaging effect.</p><p>4. In general, the discussion of &quot;two networks&quot; seems like it relies on the correlation plot of Figure~7B. The decay away from the peak correlation is sharp, but there does not seem to be significant clustering in the anti-correlation population, instead a very slow decay away from zero. The authors do not show evidence of clustering in the neurons, nor any biophysical reason why e and i neurons are present in the imaging data. The alternative explanation (as mentioned in (b)) is that the there is a more continuous set of correlations among the neurons with the same result. In fact one of the reviewers tested this themself using code to generate some data with the desired statistics, and the distribution of events seems to also describe this same observation. Obviously, the full test would need to use the same event identification code, and so it is quite important that the authors consider the much more generic explanation for the sub-network averaging effect. We recommend assessing the possibility that broader explanations, e.g., in the form of the distributions of correlations accounts for the observed phenomenon. Even with 10K neurons, there are many other forces at play influencing the observed network and while it is nice that e-i networks are one explanation, much less constraining explanations that are still biophysically feasible should be discussed and compared against. I have provided one possible approach (see PDF for code and example figure: https://submit.elifesciences.org/<italic>eLife</italic>_files/2022/05/19/00107349/00/107349_0_attach_6_474_convrt.pdf).</p><p>5. Another important aspect here is how single neurons behave. It was not clear if single neurons were stated to exhibit a power law. If they do, then that would help in that there are different limiting behaviors to the averaging that pass through the observed stated numbers. If not, then there is an additional oddity that one must average neurons at all to obtain a power law. We recommend the authors show the full curve so that the readers get a more detailed sense of how averaging effects the power-law interpretation of the data.</p><p>6. There is something that seems off about the range of \β values inferred with the ranges of \tau and $\α$. With \tau in [0.9,1.1], then the denominator 1-\tau is in [-0.1, 0.1], which the authors state means that \β (found to be in [2,2.4]) is not near \β_{crackling} = (\α-1)/(1-\tau). It seems as this is the opposite, as the possible values of the \β_{crackling} is huge due to the denominator, and so \β is in the range of possible \β_{crackling} almost vacuously. Was this statement just poorly worded?</p><p>7. It is not clear if there is more to what the authors are trying to say with the specifics of the scale free fits for behavior. Apparently, these results are used to motivate the neural studies, but aside from that, the details of those ranges don't seem to come up again. Given that the primary connection between neuronal and behavioral activity seems to be Figure 4. The distribution of points in these plots seem to be very lopsided, in that some plots have large ranges of few-to-no data points. It would be very helpful to get a sense of the distribution of points that are a bit hard to see given the overlapping points and super-imposed lines. We recommend that the authors add distribution information to the plots in Figure 4B to give a sense of how points are spread through the [correlation with behavior]-by-[power law range] space. Potential plots might be a co-located histogram, or perhaps an uncertainty estimate as a function of correlation based on the number of points and variance. This would help show significance of the curves in a way that accounts for the uneven spread of datapoints.</p><p>8. Neural activity correlated with some behavior variables can sometimes be the most active subset of neurons. This could potentially skew the maximum sizes of events and give behaviorally correlated subsets an unfair advantage in terms of the scale-free range. In a similar vain to 8), what are the typical dynamic ranges for subsets correlated and uncorrelated with behavior? We recommend showing a number of these to see if those dynamic ranges are impacting the possible ranges in the [correlation with behavior]-by-[power law range] plots. Perhaps something like curve in each plot showing the minimum maximum value of the power law range per correlation range. In general, the reviewers struggled with the interpretation of Figure 4b in the sense that there seems to be such variability between mice. How much do the authors feel that this is a difference in neural populations imaged, vs changes in imaging conditions (illumination, window clarity, optical alignment) or differences in mouse activity levels?</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>This paper feels highly polished and thorough in its presentation. I truly enjoyed reading it and believe it will be of value to the community.</p><p>A nuanced question: mouse #5 and mouse #6 consistently seems to break the rules implied by the rest of the dataset. The behavioral descriptors look normal in figure 2, but neural structure is notably different from the rest of the group in 3E, 4B, 6C, 7E, and S4 (that one is behavior). Is there anything meaningfully different about these recordings (n cells, mean event rate, anatomical location etc)?</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>Comments, questions, and technical issues for the authors.</p><p>1. The values of tau (size exponent) from neural avalanches are surprisingly low. For instance, in the Ma et al. (Hengen) 2019 Neuron paper, tau ranged from 1.5 to 1.9, sometimes more than 2, but never less than 1. I am wondering how the imaging preprocessing affects the estimate of tau. For instance, if you started with simulated spiking activity that has avalanches with size pdf that go as a power law with exponent tau, and then use a forward model to generate &quot;calcium imaging,&quot; and then apply deconvolution, z-scoring, and low-pass filtering, and then measure the avalanches again: what is the new tau?</p><p>2. This may be an ignorant question (apologies). The power law range is quantified in decibels (dB) throughout the paper; do you actually mean decades?</p><p>3. Related to the set-up of the model, was there a reason that there are no adaptation mechanisms in this network model, as there often are in mechanistic models for avalanche criticality (including past work by the authors of this paper, e.g. Shew's 2015 Nature Physics paper)? Also, there appears to have been an error with the reference manager, as this reference shows up twice in the reference list.</p><p>4. It would be helpful the authors could elaborate on predictions that their results make for future studies. Maybe this is rather technical, but can you tell us when you expect to find a power-law distribution as a function of how much of the population is sampled and for how long? What if you were analyzing Neuropixels data, where you lose the extensive spatial sampling (and the restriction to pyramidal cells only) but you gain 3 orders of magnitude in temporal resolution?</p><p>5. On page 8, you ask &quot;are all behavioral events equally correlated to their concurrent neural events, or are certain neural events from certain subsets of neurons more strongly related to behavioral events?&quot; I don't understand the question. What does it mean for all behavioral events to be equally correlated to concurrent neural events? Aren't &quot;concurrent neural events&quot; in specific subsets of neurons?</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>1. Limits of calcium imaging: My recommendation is to assess mathematically the potential impact of missing data on the range and power-law slope estimates, which are the primary values used throughout the paper.</p><p>2. Correlations and power-laws in subsets.</p><p>2a-c. My recommendation is to assess the possibility that broader explanations, e.g., in the form of the distributions of correlations accounts for the observed phenomenon. Even with 10K neurons, there are many other forces at play influencing the observed network and while it is nice that e-i networks are one explanation, much less constraining explanations that are still biophysically feasible should be discussed and compared against. I have provided one possible approach (see PDF for code and example figure: https://submit.elifesciences.org/<italic>eLife</italic>_files/2022/05/19/00107349/00/107349_0_attach_6_474_convrt.pdf) that I hope will be useful to the authors.</p><p>2d. I recommend the authors show the full curve so that the readers get a more detailed sense of how averaging effects the power-law interpretation of the data.</p><p>3. Please check that this calculation and interpretation is correct.</p><p>4. Connection between brain and behavior:</p><p>4b. I recommend that the authors add distribution information to the plots in Figure~4B to give a sense of how points are spread through the [correlation with behavior]-by-[power law range] space. Potential plots might be a co-located histogram, or perhaps an uncertainty estimate as a function of correlation based on the number of points and variance. This would help show significance of the curves in a way that accounts for the uneven spread of datapoints.</p><p>4c. In a similar vein, what are the typical dynamic ranges for subsets correlated and uncorrelated with behavior? I recommend showing a number of these to see if those dynamic ranges are impacting the possible ranges in the [correlation with behavior]-by-[power law range] plots. Perhaps something like curve in each plot showing the minimum maximum value of the power law range per correlation range.</p><p>4d. In general I'm struggling with the interpretation of Figure~4b in the sense that there seems to be such variability between mice. How much do the authors feel that this is a difference in neural populations imaged, vs changes in imaging conditions (illumination, window clarity, optical alignment) or differences in mouse activity levels?</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Scale-free behavioral dynamics directly linked with scale-free cortical dynamics&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Timothy Behrens (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved, and the reviewers concurred that an eventual acceptance is likely, but there are some remaining issues that need to be addressed. Specifically, the reviewers think that it's important that you address the points raised by Reviewer #3 (see below) regarding the &quot;Mechanisms vs. Statistics&quot; questions.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>The authors have responded effectively to previous reviews both in the updated writing (discussion and intro) as well as the models and results.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>Overall the authors addressed my concerns adequately. The paper has important results and makes a valuable contribution.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>I appreciate your time and effort to respond to my review points. I believe the majority of my points have been addressed. The main weakness I still see is the lack of discussion about the broader mechanisms beyond the basic structures described that could account for the observations (see below).</p><p>Mechanisms vs. Statistics</p><p>I would like to clarify my reason for bringing up this &quot;statistical&quot; viewpoint that I believe may have been lost in translation. The paper as it stands makes the following logical steps (in terms of the mechanistic model) 1) The data exhibits power law scaling under certain binning of neurons (effect E) and 2) One way to account for this effect E is to consider certain e-i models. This is reasonable, but the overall search for possible mechanisms seems to be a combination of intuition and trial and error. Different architectures were tried and either &quot;passed&quot; or &quot;failed&quot;.</p><p>The purpose of bringing up the statistical properties needed was to hopefully raise a conversation around what core properties are needed to replicate this effect. As activity statistics and connectivity are intimately related in mechanistic models, such a characterization would point to how broad or narrow the family of mechanisms that are possible is: i.e. how significant is it that the given sampling of models in the papers points to certain configurations. The closest I can see is the discussion point here that I think fails to completely address this point:</p><p>&quot;One possibility suggested by our model is that the scale-free dynamics we observe occur at the boundary between winner-less switching and single-winner locked-in dynamics (the red dashed line in Figures8E and F). Additional theoretical efforts are necessary to more fully explore how the traditional criticality hypothesis relates to the competitive criticality suggested by our model.&quot;</p><p>On the author's distinction between mechanisms and statistics, I do not believe the two are independent paths to choose between. Mechanisms have statistical signatures (so-called &quot;statistical model&quot;) and data statistics inform which mechanisms are possible given data. At the end of the day, these are mathematical models that need to connect core concepts to data. My point for this particular paper, which I will try to say more clearly and succinctly now is that there are many possible mechanisms that could explain observed effect E. I was hoping in my prior review to spark a slightly longer discussion on what overall properties would such a family of mechanisms share. I fail to see how identifying core statistics that would pare down the possible mechanisms is at odds with looking for a mechanism that explains an effect.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79950.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. The reviewers would like to see a detailed and thoughtful reflection on the role that 3 Hz Ca imaging might play in the conclusions that the authors derive. While the dataset in question offers many neurons, this approach is, from other perspectives, impoverished – calcium intrinsically misses spikes, a 3 Hz sampling rate is two orders of magnitude slower than an action potential, and the recordings are relatively short for amassing substantial observations of low probability (large) avalanches. The potential concern is that some of this disconnect may reflect optophysiological constraints. One argument against this is that a truly scale free system should be observable at any temporal or spatial scale and still give rise to the same sets of power laws. This quickly falls apart when applied to biological systems which are neither infinite in time nor space. As a result, the severe mismatch between the spatial resolution (single cell) and the temporal resolution (3 Hz) of the dataset, combined with filtering intrinsic to calcium imaging, raises the possibility that the conclusions are influenced by the methods.</p></disp-quote><p>We quite agree with the reviewer that reconciling different scales of measurement is an important and interesting question. One clue comes from Stringer et al’s original paper (2019 Science). They analyzed time-resolved spike data (from Neuropixel recordings) alongside the Ca imaging data we analyzed here. They showed that if the ephys spike data was analyzed with coarse time resolution (300 ms time bins, analogous to the Ca imaging data), then the anticorrelated activity became apparent (50/50 positive/negative loadings of PC1). When analyzed at faster time scales, anticorrelations were not apparent (mostly positive loadings of PC1). This interesting point was shown in their Supplementary Fig 12.</p><p>This finding suggests that our findings about anticorrelated neural groups may be relevant only at coarse time scales. Moreover, this point suggests that avalanche statistics may differ when analyzed at very different time scales, because the cancelation of anticorrelated groups may not be an important factor at faster timescales.</p><p>In our revised manuscript, we explored this point further by analyzing spike data from Stringer et al 2019. We focused on the spikes recorded from one local population (one Neuropixel probe). We first took the spike times of ~300 neurons and convolved them with a fast rise/slow fall, like typical Ca transient. Then we downsampled to 3 Hz sample rate. Next, we deconvolved using the same methods as those used by Stringer et al (OASIS nonnegative deconvolution). And finally, we z-scored the resulting activity, as we did with the Ca imaging data. With this Ca-like signal in hand, we analyzed avalanches in four ways and compared the results. The four ways were: (1) the original time-resolved spikes (5 ms resolution), (2) the original spikes binned at 330 ms time res, (3) the full population of slow Ca-like signal, and (4) a correlated subset of neurons from the slow Ca-like signal. Based on the results of this new analysis (now in Figs S3 and S4), we found several interesting points that help reconcile potential differences between fast ephys and slow Ca signals:</p><p>1. In agreement with Sup Fig 12 from Stringer et al, anticorrelations are minimal in the fast, time-resolved spike data, but can be dominant in the slow, Ca-like signal.</p><p>2. Avalanche size distributions of spikes at fast timescales can exhibit a nice power law, consistent with previous results with exponents near -2 (e.g. Ma et al Neuron 2019, Fontenele et al PRL 2019). But, the same data at slow time scales exhibited poor power-laws when the entire population was considered together.</p><p>3. The slow time scale data could exhibit a better power law if subsets of neurons were considered, just like our main findings based on Ca imaging. This point was the same using coarse time-binned spike data and the slow Ca-like signals, which gives us some confidence that deconvolution does not miss too many spikes.</p><p>In our opinion, a more thorough understanding of how scale-free dynamics differs across timescales will require a whole other paper, but we think these new results in our Figs S3 and S4 provide some reassurance that our results can be reconciled with previous work on scale free neural activity at faster timescales.</p><disp-quote content-type="editor-comment"><p>2. Another reservation expressed by the referees has to do with the generality of the conclusions drawn from the mechanistic model. One of the connectivity motifs identified appears to be i+ to e- and i- to e+, where potentially i+/i- are SOM and VIP (or really any specific inhibitory type) cells. The specific connections to subsets of excitatory cells appear to be important (based on the solid lines in Figure 8). This seems surprising: is there any experimental support for excitatory cells to preferentially receive inhibition from either SOM or VIP, but not both?</p></disp-quote><p>There is indeed direct experimental support for the competitive relationship between SOM, VIP, and functionally distinct groups of excitatory neurons. This was shown in the paper by Josh Trachtenberg’s group: Garcia-Junco-Clemente et al 2017. An inhibitory pull-push circuit in frontal cortex. Nat Neurosci 20:389–392. However, we emphasize that we also showed (lower left motif in Fig 8G) that a simpler model with only one inhibitory group is sufficient to explain the anticorrelations and scale-free dynamics we observe. We opted to highlight the model with two inhibitory groups since it can also account for the Garcia-Junco-Clemente et al results.</p><p>In the section where we describe the model, we state, “We considered two inhibitory groups, instead of just one, to account for previous reports of anticorrelations between VIP and SOM inhibitory neurons in addition to anticorrelations between groups of excitatory neurons (Garcia-Junco-Clemente et al., 2017).”</p><disp-quote content-type="editor-comment"><p>More broadly, there was concern that the neat diagrams drawn here are misleading. The sample raster, showing what appears to be the full simulation, certainly captures the correlated/anti-correlated pattern of the 100 cells most correlated with a seed cell and 100 cells most anti-correlated with it, but it does not contain the 11,000 cells in between with zero to moderate levels of correlation.</p></disp-quote><p>We agree that our original model has several limitations and that one of the most obvious features lacking in our model is asynchronous neurons (The limitations are now discussed more openly in the last paragraph of the model subsection). In the data from the Garcia-Junco-Clemente et al paper above there are many asynchronous neurons as well. To ameliorate this limitation, we have now created a modified model that now accounts for asynchronous neurons together with the competing anticorrelated neurons (now shown and described in Fig 8 – figure supplement 2). We put this modified model in supplementary material and kept the simpler, original model in the main findings of our work, because the original model provides a simpler account of the features of the data we focused on in our work – i.e. anticorrelated scale-free fluctuations. The addition of the asynchronous population does not substantially change the behavior of the two anticorrelated groups in the original model.</p><disp-quote content-type="editor-comment"><p>We probably expect that the full covariance matrix has similar structure from any seed (see Meshulam et al. 2019, PRL, for an analysis of scaling of coarse-grained activity covariance), and this suggests multiple cross-over inhibition constraints, which seem like they could be hard to satisfy.</p></disp-quote><p>We agree that it remains an outstanding challenge to create a model that reproduces the full complexity of the covariance matrix. We feel that this challenge is beyond the scope of this paper, which is already arguably squeezing quite a lot into one manuscript (one reviewer already suggested removing figures!).</p><p>We added a paragraph at the end of the subsection about the model to emphasize this limitation of the model as well as other limitations. This new paragraph says:</p><p>While our model offers a simple explanation of anticorrelated scale-free dynamics, its simplicity comes with limitations. Perhaps the most obvious limitation of our model is that it does not include neurons with weak correlations to both e+ and e- (those neurons in the middle of the correlation spectra shown in Fig 7B). In Fig 8 - figure supplement 2, we show that our model can be modified in a simple way to include asynchronous neurons. Another limitation is that we assumed that all non-zero synaptic connections were equal in weight. We loosen this assumption allowing for variable weights in Fig 8 - figure supplement 2, without changing the basic features of anticorrelated scale-free fluctuations. Future work might improve our model further by accounting for neurons with intermediate correlations.</p><disp-quote content-type="editor-comment"><p>The motifs identified in Figure 8 likely exist, but I am left with many questions of what we learned about connectivity rules that would account for the full distribution of correlations. Would starting with an Erdos-Renyi network with slight over-representation of these motifs be sufficient? How important is the homogeneous connection weights from each pool assumption – would allowing connection weights with some dispersion change the results?</p></disp-quote><p>First, we emphasize that our specific goal with our model was to identify a possible mechanism for the anticorrelated scale-free fluctuations that played the key role in our analyses. We agree that this is not a complete account of all correlations, but this was not the goal of our work. Nonetheless, our new modified model in Fig 8 - figure supplement 2 now accounts for additional neurons with weak correlations. However, we think that future theoretical/modeling work will be required to better account for the intermediate correlations that are also present in the experimental data.</p><p>We confirmed that an Erdo-Renyi network of E and I neurons can produce scale-free dynamics, but cannot produce substantial anticorrelated dynamics (Fig 8G, top right motif). Additionally, the parameter space study we performed with our model in Fig 8 showed that if the interactions between the two excitatory groups exceed a certain tipping point density, then the model behavior switches to behavior expected from an Erdos-Renyi network (Fig 8F). Finally, we have now confirmed that some non-uniformity of synaptic weights does not change the main results (Fig 8 - figure supplement 2). In the model presented in Fig 8 - figure supplement 2, the value of each non-zero connection weight was drawn from a uniform distribution [0,0.01] or [-0.01,0] for excitatory and inhibitory connections, respectively. All of these facts are described in the model subsection of the paper results.</p><disp-quote content-type="editor-comment"><p>3. Putting 2) another way, it's unclear why the averaging is required in the first place. This operation projects the entire population down in an incredibly lossy way and removes much of the complexity of the population activity.</p></disp-quote><p>Our population averaging approach is motivated by theoretical predictions and previous work. According to established theoretical accounts of scale-free population events (i.e. non-equilibrium critical phenomena in neural systems) such population-summed event sizes should have power law statistics if the system is near a critical point. This approach has been used in many previous studies of scale-free neural activity (e.g. all of those cited in the introduction in relation to scale-free neuronal avalanches). One of the main results of our study is that the existing theories and models of critical dynamics in neural systems fail to account for small subsets of neurons with scale-free activity amid a larger population that does not conform to these statistics. We could not make this conclusion if we did not test the predictions of those existing theories and models.</p><disp-quote content-type="editor-comment"><p>Second, the authors state that it is highly curious that subsets of the population exhibit power laws while the entire population does not. While the discussion and hypothesizing about different e-i interactions is interesting, it is possible that there's a discussion to be had on a much more basic level of whether there are topology independent explanations, such as basic distributions of correlations between neurons that can explain the subnetwork averaging. Specifically, if the correlation to any given neuron falls off, e.g., with an exponential falloff (i.e., a Gaussian Process type covariance between neurons), it seems that similar effects should hold. This type of effect can be easily tested by generating null distributions existing code bases. This is an important point since local (broadly defined) correlations of neurons implying the observed subnetwork behavior means that many mechanisms that have local correlations but don't cluster in any meaningful way could also be responsible for the local averaging effect.</p></disp-quote><p>We appreciate the reviewer’s effort, trying out some code to generate a statistical model. We agree that we could create such a *statistical model* that describes the observed distribution of pairwise correlations among neurons. For instance, it would be trivial to directly measure the covariance matrix, mean activities, and autocorrelations of the experimental data, which would, of course, provide a very good statistical description of the data. It would also be simple to generate more approximate statistical descriptions of the data, using multivariate gaussians, similar to the code suggested by the reviewer. However, we emphasize, this would not meet the goal of our modeling effort, which is mechanistic, not statistical. The aim of our model was to identify a possible biophysical mechanism from which emerge certain observed statistical features of the data. We feel that a statistical model is not a suitable strategy to meet this aim. Nonetheless, we agree with the reviewer that clusters with sharp boundaries (like the distinction between e+ an e- in our model) are not necessary to reproduce the cancelation of anticorrelated neurons. In other words, we agree that sharp boundaries of the e+ and e- groups of our model are not crucial ingredients to match our observations.</p><disp-quote content-type="editor-comment"><p>4. In general, the discussion of &quot;two networks&quot; seems like it relies on the correlation plot of Figure~7B. The decay away from the peak correlation is sharp, but there does not seem to be significant clustering in the anti-correlation population, instead a very slow decay away from zero. The authors do not show evidence of clustering in the neurons, nor any biophysical reason why e and i neurons are present in the imaging data.</p></disp-quote><p>First a small reminder: As stated in the paper, the data here is only showing activity of excitatory neurons. Inhibitory neurons are certainly present in V1, but they are not recorded in this data set. Thus we interpret our e+ and e- groups as two subsets of anticorrelated excitatory neurons, like those we observed in the experimental data. We agree that our simplified model treats the anticorrelated subsets as if they are clustered, but this clustering is certainly not required for any of the data analyses of experimental data. We expect that our model could be improved to allow for a less sharp boundary between e+ and e- groups, but we leave that for future work, because it is not essential to most of the results in the paper. This limitation of the model is now stated clearly in the last paragraph of the model subsection.</p><disp-quote content-type="editor-comment"><p>The alternative explanation (as mentioned in (b)) is that the there is a more continuous set of correlations among the neurons with the same result. In fact one of the reviewers tested this themself using code to generate some data with the desired statistics, and the distribution of events seems to also describe this same observation. Obviously, the full test would need to use the same event identification code, and so it is quite important that the authors consider the much more generic explanation for the sub-network averaging effect. We recommend assessing the possibility that broader explanations, e.g., in the form of the distributions of correlations accounts for the observed phenomenon. Even with 10K neurons, there are many other forces at play influencing the observed network and while it is nice that e-i networks are one explanation, much less constraining explanations that are still biophysically feasible should be discussed and compared against. I have provided one possible approach (see PDF for code and example figure: https://submit.elifesciences.org/eLife_files/2022/05/19/00107349/00/107349_0_attach_6_474_convrt.pdf).</p></disp-quote><p>As discussed above, we respectfully disagree that a statistical model is an acceptable replacement for a mechanistic model, since we are seeking to understand possible biophysical mechanisms. A statistical model is agnostic about mechanisms. We have nothing against statistical models, but in this case, they would not serve our goals.</p><p>To emphasize our point about the inadequacy of a statistical model for our goals, consider the following argument. Imagine we directly computed the mean activities, covariance matrix, and autocorrelations of all 10000 neurons from the real data. Then, we would have in hand an excellent statistical model of the data. We could then create a surrogate data set by drawing random numbers from a multivariate gaussian with same statistical description (e.g. using code like that offered by reviewer 3). This would, by construction, result in the same numbers of correlated and anticorrelated surrogate neurons. But what would this tell us about the biophysical mechanisms that might underlie these observations? Nothing, in our opinion.</p><disp-quote content-type="editor-comment"><p>5. Another important aspect here is how single neurons behave. It was not clear if single neurons were stated to exhibit a power law. If they do, then that would help in that there are different limiting behaviors to the averaging that pass through the observed stated numbers. If not, then there is an additional oddity that one must average neurons at all to obtain a power law. We recommend the authors show the full curve so that the readers get a more detailed sense of how averaging effects the power-law interpretation of the data.</p></disp-quote><p>We understand that our approach may seem odd from the point of view of central-limit-theorem-type argument. However, as mentioned above (reply R3b) and in our paper, there is a well-established history of theory and corresponding experimental tests for power-law distributed population events in neural systems near criticality. The prediction from theory is that the population summed activity will have power-law distributed events or fluctuations. That is the prediction that motivates our approach. In these theories, it is certainly not necessary that individual neurons have power-law fluctuations on their own. In most previous theories, it is necessary to consider the collective activity of many neurons before the power-law statistics become apparent, because each individual neurons contributes only a small part to the emergent, collective fluctuations. This phenomenon does not require that each individual neuron have power-law fluctuations.</p><p>At the risk of being pedantic, we feel obliged to point out that one cannot understand the peculiar scale-free statistics that occur at criticality by considering the behavior of individual elements of the system; hence the notion that critical phenomena are “emergent”. This important fact is not trivial and is, for example, why there was a Nobel prize awarded in physics for developing theoretical understanding of critical phenomena.</p><disp-quote content-type="editor-comment"><p>6. There is something that seems off about the range of \β values inferred with the ranges of \tau and $\α$. With \tau in [0.9,1.1], then the denominator 1-\tau is in [-0.1, 0.1], which the authors state means that \β (found to be in [2,2.4]) is not near \β_{crackling} = (\α-1)/(1-\tau). It seems as this is the opposite, as the possible values of the \β_{crackling} is huge due to the denominator, and so \β is in the range of possible \β_{crackling} almost vacuously. Was this statement just poorly worded?</p></disp-quote><p>The point here is that theory of crackling noise predicts that the fit value of beta should be equal to (1-alpha)/(1-tau). In other words, a confirmation of the theory would have all the points on the unity line in the rightmost panels of Fig9D and 9E, not scattered by more than an order of magnitude around the unity line. (We now state this explicitly in the text where Fig 9 is discussed.) Broad scatter around the unity line means the theory prediction did not hold. This is well established in previous studies of scale-free brain dynamics and crackling noise theory (see for example Ma et al Neuron 2019, Shew et al Nature Physics 2015, Friedman et al PRL 2012). A clearer single example of the failure of the theory to predict beta is shown in Fig 5A,B, and C.</p><disp-quote content-type="editor-comment"><p>7) It is not clear if there is more to what the authors are trying to say with the specifics of the scale free fits for behavior. Apparently, these results are used to motivate the neural studies, but aside from that, the details of those ranges don't seem to come up again.</p></disp-quote><p>The reviewer is correct, the primary point in Fig 2 is that scale-free behavioral statistics often exist. Beyond this point about existence, reporting of the specific exponents and ranges is just standard practice for this kind of analysis; a natural question to ask after claiming that we find scale behavior is “what are the exponents and ranges”. We would be remiss not to report those numbers.</p><disp-quote content-type="editor-comment"><p>Given that the primary connection between neuronal and behavioral activity seems to be Figure 4. The distribution of points in these plots seem to be very lopsided, in that some plots have large ranges of few-to-no data points.</p></disp-quote><p>We agree that this whitespace in the figure panels is a somewhat awkward, but we chose to keep the horizontal axis the same for all panels of Fig 4B, because this shows that not all behaviors, and not all animals had the same range of behavioral correlations. We felt that hiding this was a bit misleading, so we kept the white space.</p><disp-quote content-type="editor-comment"><p>It would be very helpful to get a sense of the distribution of points that are a bit hard to see given the overlapping points and super-imposed lines. We recommend that the authors add distribution information to the plots in Figure 4B to give a sense of how points are spread through the [correlation with behavior]-by-[power law range] space. Potential plots might be a co-located histogram, or perhaps an uncertainty estimate as a function of correlation based on the number of points and variance. This would help show significance of the curves in a way that accounts for the uneven spread of datapoints.</p></disp-quote><p>We also agree that characterizing uncertainty in power law range as a function of correlation and providing distribution information are good ideas. If we have not misunderstood the reviewer’s suggestion, we think we have already done such characterization. The three lines in each panel of Fig 4B meet the goal of characterizing variability as a function of correlation. The middle line is median, the top and bottom lines span the quartile range, which is a good way to characterize variability around the median for non-normally distributed variability. We also provide information on how points are distributed by plotting the points with partially transparent markers. In this way, higher density of overlapping points creates darker regions in the clouds of points. We feel that this approach avoids hiding outlier points and accounts for distributions of overlapping points. Adding more information (actual distributions, e.g.) to these plots would be largely redundant and make them too cluttered. We added the following sentence to Fig 4 caption: “Points have partially transparent markers, thus darker areas reveal higher density of points.”</p><disp-quote content-type="editor-comment"><p>8. Neural activity correlated with some behavior variables can sometimes be the most active subset of neurons. This could potentially skew the maximum sizes of events and give behaviorally correlated subsets an unfair advantage in terms of the scale-free range. In a similar vain to 8), what are the typical dynamic ranges for subsets correlated and uncorrelated with behavior? We recommend showing a number of these to see if those dynamic ranges are impacting the possible ranges in the [correlation with behavior]-by-[power law range] plots. Perhaps something like curve in each plot showing the minimum maximum value of the power law range per correlation range.</p><p>In general, the reviewers struggled with the interpretation of Figure 4b in the sense that there seems to be such variability between mice. How much do the authors feel that this is a difference in neural populations imaged, vs changes in imaging conditions (illumination, window clarity, optical alignment) or differences in mouse activity levels?</p></disp-quote><p>Here we follow a standard convention for Ca imaging data (e.g. original Stringer 2019 Science paper). Each neuron’s activity was z-scored before defining groups and events. This means that the “dynamic ranges” (ranges of activity amplitudes) of each single neuron were similar. This should “normalize” the maximum possible event size in a fair way. We note, however, that the primary reason this z-scoring is done is that the measurement signal-to-noise ratio can vary across neurons due to variable expression of fluorescent indicator molecules across neurons.</p><p>As mentioned in above, the scatter of points in Fig 4 panels already directly shows the min-to-max span of power law range for each correlation.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>This paper feels highly polished and thorough in its presentation. I truly enjoyed reading it and believe it will be of value to the community.</p></disp-quote><p>We truly appreciate the positive feedback. Thanks</p><disp-quote content-type="editor-comment"><p>A nuanced question: mouse #5 and mouse #6 consistently seems to break the rules implied by the rest of the dataset. The behavioral descriptors look normal in figure 2, but neural structure is notably different from the rest of the group in 3E, 4B, 6C, 7E, and S4 (that one is behavior). Is there anything meaningfully different about these recordings (n cells, mean event rate, anatomical location etc)?</p></disp-quote><p>We agree that 3 of the 9 recordings (mice 5-7) are somewhat “outlying” relative to the results from the other 6 recordings. We took a closer look at those recordings and found that at least one possible reason is that the animals were much more active than usual (mice 6 and 7 were 50 times more active the next most active mouse, in terms of median run speed) or much less activity than usual (mouse 5 was 10 time less active than the next least active mouse). We have pointed this out in the main text near the description of Figure 4 and showed it directly in Figure 4 —figure supplement 1.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):Comments, questions, and technical issues for the authors.</p><p>1. The values of tau (size exponent) from neural avalanches are surprisingly low. For instance, in the Ma et al. (Hengen) 2019 Neuron paper, tau ranged from 1.5 to 1.9, sometimes more than 2, but never less than 1. I am wondering how the imaging preprocessing affects the estimate of tau. For instance, if you started with simulated spiking activity that has avalanches with size pdf that go as a power law with exponent tau, and then use a forward model to generate &quot;calcium imaging,&quot; and then apply deconvolution, z-scoring, and low-pass filtering, and then measure the avalanches again: what is the new tau?</p></disp-quote><p>We appreciate the suggestion to do some forward modeling of Ca-like signals from spikes. This is the approach we have now taken for FiguresS3 and S4.</p><disp-quote content-type="editor-comment"><p>2. This may be an ignorant question (apologies). The power law range is quantified in decibels (dB) throughout the paper; do you actually mean decades?</p></disp-quote><p>The typical definition of dB is the ratio of two log quantities and then multiplied by a factor of 10 or 20 (depending on the context). In our usage, we did the ratio of two log quantities, but we never multiplied by 10 or 20. To avoid confusion, we have replaced “dB” with “decades” throughout the paper.</p><disp-quote content-type="editor-comment"><p>3. Related to the set-up of the model, was there a reason that there are no adaptation mechanisms in this network model, as there often are in mechanistic models for avalanche criticality (including past work by the authors of this paper, e.g. Shew's 2015 Nature Physics paper)? Also, there appears to have been an error with the reference manager, as this reference shows up twice in the reference list.</p></disp-quote><p>There was no reason for the omission of adaptation mechanisms other than to increase simplicity. We aimed to make the model as simple as possible and still explain the features of the data we were most concerned with (i.e. scale-free-ness and anticorrelations).</p><p>Thanks for catching the double reference. We fixed that now.</p><disp-quote content-type="editor-comment"><p>4. It would be helpful the authors could elaborate on predictions that their results make for future studies. Maybe this is rather technical, but can you tell us when you expect to find a power-law distribution as a function of how much of the population is sampled and for how long? What if you were analyzing Neuropixels data, where you lose the extensive spatial sampling (and the restriction to pyramidal cells only) but you gain 3 orders of magnitude in temporal resolution?</p></disp-quote><p>Please see above and Figure 3 —figure supplements 1-2.</p><disp-quote content-type="editor-comment"><p>5. On page 8, you ask &quot;are all behavioral events equally correlated to their concurrent neural events, or are certain neural events from certain subsets of neurons more strongly related to behavioral events?&quot; I don't understand the question. What does it mean for all behavioral events to be equally correlated to concurrent neural events? Aren't &quot;concurrent neural events&quot; in specific subsets of neurons?</p></disp-quote><p>We agree that the wording of this sentence was confusing, so we deleted it. We think the goals of the analysis in Figure 6 are clearer with this deletion.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>1. Limits of calcium imaging: My recommendation is to assess mathematically the potential impact of missing data on the range and power-law slope estimates, which are the primary values used throughout the paper.</p></disp-quote><p>We appreciate the concern here and agree that event size statistics could in principle be biased in some systematic way due to missed spikes due to deconvolution of Ca signals. To directly test this possibility, we performed a new analysis of spike data recorded with high time resolution electrophysiology. We began with forward-modeling process to create a low-time-resolution, Ca-like signal, using the same deconvolution algorithm (OASIS) that was used to generate the data we analyzed in our work here. In agreement with the reviewer’s concern, we found that spikes were sometimes missed, but the loss was not extreme and did not impact the neural event size statistics in a significant way compared to the ground truth we obtained directly from the original spike data (with no loss of spikes). This new work is now described in a new paragraph at the end of the subsection of results related to Fig 3 and in a new Fig 3 - figure supplement 1. The new paragraph says…</p><p>“Two concerns with the data analyzed here are that it was sampled at a slow time scale (3 Hz frame rate) and that the deconvolution methods used to obtain the data here from the raw GCAMP6s Ca imaging signals are likely to miss some activity (Huang et al., 2021). Since our analysis of neural events hinges on summing up activity across neurons, could it be that the missed activity creates systematic biases in our observed event size statistics? To address this question, we analyzed some time-resolved spike data (Neuropixel recording from Stringer et al 2019). Starting from the spike data, we created a slow signal, similar to that we analyzed here by convolving with a Ca-transient, down sampling, deconvolving, and z-scoring (Fig 3 - figure supplement 1). We compared neural event size distributions to “ground truth” based on the original spike data (with no loss of spikes) and found that the neural event size distributions were very similar, with the same exponent and same power-law range (Fig 3 - figure supplement 1). Thus, we conclude that our reported neural event size distributions are reliable.”</p><p>However, although loss of spikes did not impact the event size distributions much, the time-scale of measurement did matter. As discussed above and shown in Fig 3 - figure supplement 2, changing from 5 ms time resolution to 330 ms time resolution does change the exponent and the range of the power law. However, in the test data set we worked with, the existence of a power law was robust across time scales.</p><disp-quote content-type="editor-comment"><p>2. Correlations and power-laws in subsets.</p><p>2a-c. My recommendation is to assess the possibility that broader explanations, e.g., in the form of the distributions of correlations accounts for the observed phenomenon. Even with 10K neurons, there are many other forces at play influencing the observed network and while it is nice that e-i networks are one explanation, much less constraining explanations that are still biophysically feasible should be discussed and compared against. I have provided one possible approach (see PDF for code and example figure: https://submit.elifesciences.org/eLife_files/2022/05/19/00107349/00/107349_0_attach_6_474_convrt.pdf) that I hope will be useful to the authors.</p></disp-quote><p>discussed above, we respectfully disagree that a statistical model is an acceptable replacement for a mechanistic model, since we are seeking to understand possible biophysical mechanisms. A statistical model is agnostic about mechanisms. We have nothing against statistical models, but in this case, they would not serve our goals.</p><p>To emphasize our point about the inadequacy of a statistical model for our goals, consider the following argument. Imagine we directly computed the mean activities, covariance matrix, and autocorrelations of all 10000 neurons from the real data. Then, we would have in hand an excellent statistical model of the data. We could then create a surrogate data set by drawing random numbers from a multivariate gaussian with same statistical description (e.g. using code like that offered by reviewer 3). This would, by construction, result in the same numbers of correlated and anticorrelated surrogate neurons. But what would this tell us about the biophysical mechanisms that might underlie these observations? Nothing, in our opinion.</p><disp-quote content-type="editor-comment"><p>2d. I recommend the authors show the full curve so that the readers get a more detailed sense of how averaging effects the power-law interpretation of the data.</p></disp-quote><p>It is not clear to us what is meant by the “full curve”.</p><disp-quote content-type="editor-comment"><p>3. Please check that this calculation and interpretation is correct.</p></disp-quote><p>The point here is that theory of crackling noise predicts that the fit value of beta should be equal to (1-alpha)/(1-tau). In other words, a confirmation of the theory would have all the points on the unity line in the rightmost panels of Fig9D and 9E, not scattered by more than an order of magnitude around the unity line. (We now state this explicitly in the text where Fig 9 is discussed.) Broad scatter around the unity line means the theory prediction did not hold. This is well established in previous studies of scale-free brain dynamics and crackling noise theory (see for example Ma et al Neuron 2019, Shew et al Nature Physics 2015, Friedman et al PRL 2012). A clearer single example of the failure of the theory to predict beta is shown in Fig 5A,B, and C.</p><disp-quote content-type="editor-comment"><p>4. Connection between brain and behavior:</p><p>4b. I recommend that the authors add distribution information to the plots in Figure~4B to give a sense of how points are spread through the [correlation with behavior]-by-[power law range] space. Potential plots might be a co-located histogram, or perhaps an uncertainty estimate as a function of correlation based on the number of points and variance. This would help show significance of the curves in a way that accounts for the uneven spread of datapoints.</p></disp-quote><p>We also agree that characterizing uncertainty in power law range as a function of correlation and providing distribution information are good ideas. If we have not misunderstood the reviewer’s suggestion, we think we have already done such characterization. The three lines in each panel of Figure 4B meet the goal of characterizing variability as a function of correlation. The middle line is median, the top and bottom lines span the quartile range, which is a good way to characterize variability around the median for non-normally distributed variability. We also provide information on how points are distributed by plotting the points with partially transparent markers. In this way, higher density of overlapping points creates darker regions in the clouds of points. We feel that this approach avoids hiding outlier points and accounts for distributions of overlapping points. Adding more information (actual distributions, e.g.) to these plots would be largely redundant and make them too cluttered. We added the following sentence to Figure 4 caption:</p><p>“Points have partially transparent markers, thus darker areas reveal higher density of points.”</p><disp-quote content-type="editor-comment"><p>4c. In a similar vein, what are the typical dynamic ranges for subsets correlated and uncorrelated with behavior? I recommend showing a number of these to see if those dynamic ranges are impacting the possible ranges in the [correlation with behavior]-by-[power law range] plots. Perhaps something like curve in each plot showing the minimum maximum value of the power law range per correlation range.</p></disp-quote><p>Here we follow a standard convention for Ca imaging data (e.g. original Stringer 2019 Science paper). Each neuron’s activity was z-scored before defining groups and events. This means that the “dynamic ranges” (ranges of activity amplitudes) of each single neuron were similar. This should “normalize” the maximum possible event size in a fair way. We note, however, that the primary reason this z-scoring is done is that the measurement signal-to-noise ratio can vary across neurons due to variable expression of fluorescent indicator molecules across neurons.</p><p>As mentioned in R3j, the scatter of points in Figure 4 panels already directly shows the min-to-max span of power law range for each correlation.</p><disp-quote content-type="editor-comment"><p>4d. In general I'm struggling with the interpretation of Figure~4b in the sense that there seems to be such variability between mice. How much do the authors feel that this is a difference in neural populations imaged, vs changes in imaging conditions (illumination, window clarity, optical alignment) or differences in mouse activity levels?</p></disp-quote><p>We agree that 3 of the 9 recordings (mice 5-7) are somewhat “outlying” relative to the results from the other 6 recordings. We took a closer look at those recordings and found that at least one possible reason is that the animals were much more active than usual (mice 6 and 7 were 50 times more active the next most active mouse, in terms of median run speed) or much less activity than usual (mouse 5 was 10 time less active than the next least active mouse). We have pointed this out in the main text near the description of Fig 4 and showed it directly in Fig 4 – figure supplement 1.</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>I appreciate your time and effort to respond to my review points. I believe the majority of my points have been addressed. The main weakness I still see is the lack of discussion about the broader mechanisms beyond the basic structures described that could account for the observations (see below).</p><p>Mechanisms vs. Statistics</p><p>I would like to clarify my reason for bringing up this &quot;statistical&quot; viewpoint that I believe may have been lost in translation. The paper as it stands makes the following logical steps (in terms of the mechanistic model) (1) The data exhibits power law scaling under certain binning of neurons (effect E) and (2) One way to account for this effect E is to consider certain e-i models. This is reasonable, but the overall search for possible mechanisms seems to be a combination of intuition and trial and error. Different architectures were tried and either &quot;passed&quot; or &quot;failed&quot;.</p><p>The purpose of bringing up the statistical properties needed was to hopefully raise a conversation around what core properties are needed to replicate this effect. As activity statistics and connectivity are intimately related in mechanistic models, such a characterization would point to how broad or narrow the family of mechanisms that are possible is: i.e. how significant is it that the given sampling of models in the papers points to certain configurations. The closest I can see is the discussion point here that I think fails to completely address this point:</p><p>&quot;One possibility suggested by our model is that the scale-free dynamics we observe occur at the boundary between winner-less switching and single-winner locked-in dynamics (the red dashed line in Figures8E and F). Additional theoretical efforts are necessary to more fully explore how the traditional criticality hypothesis relates to the competitive criticality suggested by our model.&quot;</p><p>On the author's distinction between mechanisms and statistics, I do not believe the two are independent paths to choose between. Mechanisms have statistical signatures (so-called &quot;statistical model&quot;) and data statistics inform which mechanisms are possible given data. At the end of the day, these are mathematical models that need to connect core concepts to data. My point for this particular paper, which I will try to say more clearly and succinctly now is that there are many possible mechanisms that could explain observed effect E. I was hoping in my prior review to spark a slightly longer discussion on what overall properties would such a family of mechanisms share. I fail to see how identifying core statistics that would pare down the possible mechanisms is at odds with looking for a mechanism that explains an effect.</p></disp-quote><p>We appreciate the clarifications and agree that mechanisms and statistics are intimately related. Indeed, in this context, much of our main results (event size and duration distributions, correlation spectra, etc.) can be viewed as statistical properties. Admittedly, these are rather “high level” statistics. To expand on this, we have now quantified some more basic statistics. We have now added a supplementary figure with single neuron variance and pairwise covariance values, comparing between neural subsets that exhibited good power laws and those that did not (Figure 8 —figure supplement 3). We show in this new figure that neural subsets with large power-law range tended to be composed of neurons with relatively high variance and high pairwise covariance. Perhaps these statistical properties will be shared by the family of mechanistic models suggested by the reviewer. However, in our view, it is beyond the scope of our manuscript to fully identify the necessary and sufficient statistical properties a model must generate to agree with our main results.</p></body></sub-article></article>