<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">82128</article-id><article-id pub-id-type="doi">10.7554/eLife.82128</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Genetics and Genomics</subject></subj-group></article-categories><title-group><article-title>Generating colorblind-friendly scatter plots for single-cell data</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-288322"><name><surname>Guha</surname><given-names>Tejas</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-93121"><name><surname>Fertig</surname><given-names>Elana J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3204-342X</contrib-id><email>ejfertig@jhmi.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-287252"><name><surname>Deshpande</surname><given-names>Atul</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5144-6924</contrib-id><email>adeshpande@jhu.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf3"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047s2c258</institution-id><institution>Department of Electrical and Computer Engineering, A. James Clark School of Engineering, The University of Maryland</institution></institution-wrap><addr-line><named-content content-type="city">College Park</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Department of Oncology, Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Convergence Institute, Johns Hopkins University</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Bloomberg-Kimmel Immunotherapy Institute, Johns Hopkins University School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Department of Applied Mathematics and Statistics, Johns Hopkins University</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Department of Biomedical Engineering, Johns Hopkins University School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Choi</surname><given-names>Jungmin</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047dqcg40</institution-id><institution>Korea University College of Medicine</institution></institution-wrap><country>Republic of Korea</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Zaidi</surname><given-names>Mone</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04a9tmd77</institution-id><institution>Icahn School of Medicine at Mount Sinai</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>16</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e82128</elocation-id><history><date date-type="received" iso-8601-date="2022-07-24"><day>24</day><month>07</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-12-15"><day>15</day><month>12</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-10-07"><day>07</day><month>10</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.10.07.463279"/></event></pub-history><permissions><copyright-statement>Â© 2022, Guha et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Guha et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-82128-v2.pdf"/><abstract><p>Reduced-dimension or spatial in situ scatter plots are widely employed in bioinformatics papers analyzing single-cell data to present phenomena or cell-conditions of interest in cell groups. When displaying these cell groups, color is frequently the only graphical cue used to differentiate them. However, as the complexity of the information presented in these visualizations increases, the usefulness of color as the only visual cue declines, especially for the sizable readership with color-vision deficiencies (CVDs). In this paper, we present scatterHatch, an R package that creates easily interpretable scatter plots by redundant coding of cell groups using colors as well as patterns. We give examples to demonstrate how the scatterHatch plots are more accessible than simple scatter plots when simulated for various types of CVDs.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>visualization</kwd><kwd>accessibility</kwd><kwd>software tool</kwd><kwd>single-cell</kwd><kwd>spatial data</kwd><kwd>UMAP</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000054</institution-id><institution>National Cancer Institute</institution></institution-wrap></funding-source><award-id>U01CA253403</award-id><principal-award-recipient><name><surname>Fertig</surname><given-names>Elana J</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000054</institution-id><institution>National Cancer Institute</institution></institution-wrap></funding-source><award-id>U01CA212007</award-id><principal-award-recipient><name><surname>Fertig</surname><given-names>Elana J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000054</institution-id><institution>National Cancer Institute</institution></institution-wrap></funding-source><award-id>P01CA247886</award-id><principal-award-recipient><name><surname>Fertig</surname><given-names>Elana J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>scatterHatch helps users generate colorblind-friendly scatter plot visualizations by using a combination of patterns and high-contrast colors to represent distinct point groups.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Data visualization is a key component in the presentation of single-cell analyses with multiple cell groups representing factors such as cell types, states, and so forth. Color is commonly used as the only visual cue in low-dimensional scatter plots (e.g., tSNE, UMAP, etc.) or in situ spatial plots of single-cell data. We either use colormaps to represent values on a continuum or distinct colors to identify different cell groups. However, with the increasing complexity of the information being represented in these scatter plots, the ability of the readers to distinguish between the colors decreases, diminishing the interpretability of the visualizations. This problem is exacerbated for the approximately 8% of male and 0.5% of female readers who have some type of color-vision deficiency (CVD) (<ext-link ext-link-type="uri" xlink:href="https://paperpile.com/c/hUfhnS/aNbk">Wong, 2011</ext-link>). Over the course of the last decade, we have seen a number of papers (<xref ref-type="bibr" rid="bib18">Wong, 2011</xref>; <xref ref-type="bibr" rid="bib10">Katsnelson, 2021</xref>; <xref ref-type="bibr" rid="bib5">Crameri et al., 2020</xref>; <xref ref-type="bibr" rid="bib17">Wong, 2010</xref>) providing guidelines for the effective use of colors to create accessible visualizations. More recently, software packages have also been developed that either simulate different CVDs (<xref ref-type="bibr" rid="bib13">Ou, 2021</xref>), or use colorblind-friendly color palettes (<xref ref-type="bibr" rid="bib2">Bunis et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Steenwyk and Rokas, 2021</xref>). However, the rules for choosing accessible color palettes may change depending on the type of CVD. For example, protanopes lack the photoreceptors of red light, whereas deuteranopes lack green photoreceptors (<xref ref-type="bibr" rid="bib6">Deeb, 2005</xref>). We can overcome this problem by using strategies and software solutions that reduce the dependence of visualizations on colors by âredundant codingâ (<xref ref-type="bibr" rid="bib18">Wong, 2011</xref>; <xref ref-type="bibr" rid="bib4">Color Universal Design, 2008</xref>; <xref ref-type="bibr" rid="bib12">Oliveira, 2013</xref>) using other visual cues such as line types, point shapes, and hatched patterns over areas.</p><p>Single-cell or spatial omics data visualizations often contain scatter plots with a mixture of varying point distributions. Although simpler strategies for redundant coding already exist, they are only suitable for specific types of scatter plots. For example, we can combine colors with point shapes (<ext-link ext-link-type="uri" xlink:href="https://paperpile.com/c/hUfhnS/2Jym">Color Universal Design, 2008</ext-link>) in sparse scatter plots, but the point shapes are not apparent when the points are densely clustered together. On the other hand, distinct hatched patterns (<ext-link ext-link-type="uri" xlink:href="https://paperpile.com/c/hUfhnS/gs5P+aNbk">Wong, 2011; Oliveira, 2013</ext-link>; <xref ref-type="bibr" rid="bib8">Fc and Davis, 2022</xref>) overlaid over dense regions of the scatterplot can be used as a visual cue, but this strategy is not well suited for sparsely distributed points. However, hatched patterns can be easily added to violin plots or alluvial plots using R packages such as ggpattern to improve their accessibility.</p><p>We present <italic>scatterHatch</italic>, an R package for generating easily interpretable scatter plots by redundant coding of point groups using patterns and colors. scatterHatch avoids the drawbacks of the simpler strategies discussed before and easily handles point visualizations that contain mixtures of sparse and dense point distributions. Furthermore, we generate example reduced-dimension and spatial scatterHatch plots. Using the same CVD-friendly color palettes, we simulate the perception and accessibility of our scatterHatch plots against standard scatter plots for various types of CVDs.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>scatterHatch adds patterns to scatter plots with mixtures of dense and sparse regions</title><p>In this paper, we present scatterHatch, a R/Bioconductor package to generate colorblind-friendly point visualizations commonly used in single-cell and spatial bioinformatics data analyses. scatterHatch greatly enhances the accessibility of low-dimensional scatter plots and in situ spatial plots of single-cell and spatial omics by using a combination of colors and patterns. A scatterHatch plot effectively represents mixtures of varying point distributions by using simple patterns which are easily plotted over dense clusters as well as sparsely distributed points.</p><p><xref ref-type="fig" rid="fig1">Figure 1</xref> shows the scatterHatch workflow. The minimum required input to scatterHatch is a data frame containing the x, y coordinates and the condition or factor to be visually represented. The output of scatterHatch is a ggplot2 object representing a scatter plot with colors and patterns assigned for each factor. Each point pertaining to a factor is classified as either belonging to a dense cluster or as an individual sparse point. scatterHatch plots coarse patterns over the dense point clusters and individually plots a matching pattern over each sparse point. Users have the option to bypass the in-built sparse point detector by providing a list of sparse points as input to scatterHatch. scatterHatch has six default patternsâhorizontal, vertical, right diagonal, left diagonal, checkers and crisscrossâin addition to supporting a âblankâ pattern or color-only mode. The choice of patterns is intentionally limited to those achievable by simple line segments which are suitable for both individual points or large regions of dense point clusters. The default color palette uses 40 high-contrast CVD-friendly colors imported from the <italic>dittoSeq</italic> package (<xref ref-type="bibr" rid="bib2">Bunis et al., 2020</xref>). To advanced users, scatterHatch extends the ability to customize patterns by specifying the type (e.g., solid, dashed, dotted, etc.), color, and thickness of the lines used in the patterns. Furthermore, users can also generate new patterns composed of one or more lines by providing a list of corresponding line angles and aesthetics as input.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>scatterHatch generates accessible scatter plots by redundant coding of point groups using colors and patterns.</title><p>For every point group, scatterHatch separates sparsely distributed points from the dense clusters. scatterHatch plots coarse patterns over the dense clusters and individually plots patterns over the sparse points. Created using <ext-link ext-link-type="uri" xlink:href="https://biorender.com/">Biorender.com</ext-link>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82128-fig1-v2.tif"/></fig></sec><sec id="s2-2"><title>Improving the accessibility of scatter plots for all types of color vision deficiencies</title><p>Here, we demonstrate the accessibility of a reduced-dimension UMAP scatter plot of single-cell data generated using scatterHatch from the perspective of different CVDs. Specifically, 10,000 cells were selected at random from single-cell data collected from a resection specimen (<xref ref-type="bibr" rid="bib11">Lin et al., 2018</xref>) of Pancreatic Ductal Carcinoma (PDAC) and adjacent normal tissues. The reduced-dimension coordinates are calculated using the UMAP algorithm (<xref ref-type="bibr" rid="bib1">Becht et al., 2018</xref>) and the cells are classified into four groups using K-means clustering of the UMAP coordinates. A scatterHatch plot was generated where a color and pattern were assigned to each cell group. Subsequently, we used the cvdPlot function from the R package colorblindness to simulate common CVDs such as deuteranomaly (red-green colorblindness), protanomaly (blue-yellow colorblindness), and monochromacy (complete color blindness or grayscale vision).</p><p><xref ref-type="fig" rid="fig2">Figure 2</xref> compares the accessibility of the UMAP scatter plot when compared to a scatterHatch plot as perceived by individuals with normal vision (<xref ref-type="fig" rid="fig2">Figure 2A</xref>), deuteranomaly (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), protanomaly (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), and monochromacy (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), respectively. Each simulated visualization also includes an inset with a zoomed-in view of a region with sparse points from the distinct cell groups. As shown in the figure, the addition of the patterns makes it much easier to distinguish between factors for all types of CVD. In the zoomed-out view, we can readily distinguish between large dense clusters associated with each cell group. Similarly, the zoomed-in view demonstrates how plotting the patterns individually over sparse points enables us to distinguish them from adjacent points from other cell groups.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>scatterHatch plots are more accessible compared to scatter plots to individuals with CVD.</title><p>Simulated perception of a UMAP scatter plot compared with a scatterHatch plot by individuals with (<bold>A</bold>) normal color vision, (<bold>B</bold>) deuteranomaly, (<bold>C</bold>) protanomaly, and (<bold>D</bold>) monochromacy, with the insets showing a magnified sparse region showing patterns assigned to individual cells. Despite the change in color perception, readers have access to secondary visual information in the form of patterns to help interpret the data. CVD, color-vision deficiency.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82128-fig2-v2.tif"/></fig></sec><sec id="s2-3"><title>Increasing the accessibility of scatter plots with large number of cell groups</title><p>The benefits of enhanced accessibility are not just limited to individuals with CVD. Different backgrounds can cause the same color to be perceived differently, or for two different colors to be perceived as the same (<ext-link ext-link-type="uri" xlink:href="https://paperpile.com/c/hUfhnS/3usQ">Wong, 2010</ext-link>). When publishing a plot with few colors, the authors can appropriately assign distinct colors to individual cell groups to avoid confusing color perceptions. As the number of colors in a scatter plot increases, however, the ability to choose distinct colors as well as to control the relative distribution of these colors in the plot is severely hampered, leading to a higher probability of color misperception. Redundant coding with patterns facilitated the interpretation of such plots for all readers.</p><p><xref ref-type="fig" rid="fig3">Figure 3A</xref> shows a spatial scatter plot of the cells from the PDAC resection specimen (<xref ref-type="bibr" rid="bib11">Lin et al., 2018</xref>) color-coded by the frame number in the microscopy image (82 groups), with a corresponding scatterHatch plot having redundant coding using both color and pattern. For each type of plot, the groups are colored using 82 distinct colors from the âMuted Nineâ colorblind-friendly color palette from the <italic>ggpubfigs</italic> (<ext-link ext-link-type="uri" xlink:href="https://paperpile.com/c/hUfhnS/DJrt">Steenwyk and Rokas, 2021</ext-link>) package. Using a similar approach to that used in <xref ref-type="fig" rid="fig2">Figure 2</xref>, we simulate the perceptibility of this figure for different CVDs. We see that the addition of patterns facilitates the interpretation of the visualizations.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>scatterHatch plots are more accessible than scatter plots for all readers when number of cell groups is high.</title><p>Perception of a spatial plot of the PDAC data set with 82-cell groups compared with a corresponding scatterHatch plot as simulated for (<bold>A</bold>) normal color vision, (<bold>B</bold>) deuteranomaly, (<bold>C</bold>) protanomaly, and (<bold>D</bold>) monochromacy. As the number of colors in the scatter plot increases, its interpretability reduces even for normal color vision. The redundant coding used in scatterHatch plots results in increased accessibility. PDAC, Pancreatic Ductal Carcinoma.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82128-fig3-v2.tif"/></fig></sec><sec id="s2-4"><title>User-programmable aesthetics and patterns further increase the addressable dimensionality of scatterHatch</title><p>Combining the 40 colors and the 7 patterns provided in the default settings, scatterHatch is already capable of visualizing 280 patterns. Users can input custom color palettes with higher number of colors. In addition, advanced users can customize patterns by choosing line types, line colors, and line widths to achieve a broader pattern library. Finally, scatterHatch also facilitates the introduction of new patterns composed of one or more lines by providing a list of line angles and custom aesthetics. For example, in <xref ref-type="fig" rid="fig4">Figure 4</xref>, the different cell groups are represented using patterns with custom line types (PDAC cell group), custom line colors (Other and Pancreas cell groups), and completely new patterns (Small Intestine cell group). <xref ref-type="table" rid="table1">Table 1</xref> shows the parameters that can be used to either customize the aesthetics of a pattern or to create new patterns.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Parameters to enable users to customize pattern aesthetics or to create new patterns.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="bottom">Name</th><th align="center" valign="bottom">Description</th><th align="center" valign="bottom">Options</th></tr></thead><tbody><tr><td align="center" valign="bottom">pattern</td><td align="center" valign="bottom">Specifies the pattern type</td><td align="center" valign="bottom">Default options are âhorizontalâ, âverticalâ, âpositiveDiagonalâ, ânegativeDiagonalâ, âcrossâ, âcheckersâ, âblankâ<break/>E.g.: pattern=âcheckersâ</td></tr><tr><td align="center" valign="bottom">angle</td><td align="center" valign="bottom">Allows users to specify line angles to be included in the pattern (enables users to create new patterns)</td><td align="center" valign="bottom">Numeric array with values from 0 to 180.<break/>E.g.: angle=c(45, 90, 135)</td></tr><tr><td align="center" valign="bottom">lineWidth</td><td align="center" valign="bottom">Width of the lines in a pattern</td><td align="center" valign="bottom">Numeric - default value based on point size<break/>E.g.: lineWidth=0.1</td></tr><tr><td align="center" valign="bottom">lineColor</td><td align="center" valign="bottom">Color of the lines in a pattern</td><td align="center" valign="bottom">Character string specifying a color<break/>E.g.: lineColor=âwhiteâ</td></tr><tr><td align="center" valign="bottom">lineType</td><td align="center" valign="bottom">Type of the lines in a pattern</td><td align="center" valign="bottom">Character string to specify the line type from the ggplot2 package.<break/>E.g.: lineType=âdottedâ</td></tr><tr><td align="center" valign="bottom">LineAlpha</td><td align="center" valign="bottom">Transparency of the lines in a pattern</td><td align="center" valign="bottom">Numeric value from 0 to 1. Default is 1.<break/>Ex: lineAlpha=0.1</td></tr></tbody></table></table-wrap><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>scatterHatch enables users to customize patterns.</title><p>Spatial scatterHatch plot of the PDAC data set showing four tissue regions using customized patterns with a custom line type (PDAC), custom line colors (Other and Pancreas), and a completely new pattern (Small Intestine).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82128-fig4-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We present <italic>scatterHatch,</italic> a R/Bioconductor package for generating colorblind-friendly scatter plots of embeddings for single-cell and spatial datasets. scatterHatch enables users to generate <italic>scatterHatch</italic> plotsâscatter plots with both a color and a pattern as visual cues. These plots are aesthetically pleasing as well as highly accessible to a broad readership including those with color vision deficiencies. scatterHatch plots are compatible with point distributions that are sparse, dense, as well as mixtures of both. We demonstrate how scatterHatch plots have better accessibility than simple scatter plots in low dimensional embeddings (e.g., PCA, UMAP, and TSNE) as well as spatial plots of cells in the tissue with up to 82-cell groups. As the number of cell groups increases, the benefits of scatterHatch plots extend even to readers with normal vision. In future work, we will make enhancements to the algorithms and plotting functions to improve the aesthetics and accessibility of scatterHatch plots with overlapping cell groups. Additionally, the software will be extended to be compatible with single-cell and spatial data formats from commonly used bioinformatics packages such as Seurat (<xref ref-type="bibr" rid="bib3">Butler et al., 2018</xref>) and scanpy (<xref ref-type="bibr" rid="bib16">Wolf et al., 2018</xref>).</p><p>Despite the consensus on the need for bioinformatics visualizations that are accessible across the spectrum of color perception, the progress has been slow in terms of actually affecting this change in our publications. While well intentioned, recommendations for incorporating additional steps to ensure accessible visualizations are not sufficient by themselves. For example, simulating multiple CVDs and subjectively selecting the best possible color palette for their visualizations may not come naturally to a vast majority of researchers who have normal color vision. In fact, such strategies are themselves not practical for individuals with one type of CVD who wish to ensure accessibility for other types of CVD. Software packages, such as ggpattern, dittoSeq, and scatterHatch, remove this subjectivity to a large extent by using colorblind-friendly color palettes as default, and enabling the use of visualization strategies that reduce the dependence on color. Future work could include the development of a software suite that combines the functionalities of these packages into a comprehensive software solution for creating CVD-friendly visualizations. Meanwhile, there is also a need for standards and guidelines for creating accessible visualizations, which requires support at multiple levelsâfrom funding agencies, journals, and developers of large-scale analysis software and visualization tools (<xref ref-type="bibr" rid="bib14">Speir et al., 2021</xref>). The submission review process for R or Python packages should require that the default color palettes used by the software visualizations are colorblind friendly according to well-established accessibility standards. In addition, we should develop processes for periodically incorporating the best practices for accessibility introduced in new software packages into the graphical design language standards expected from newer packages. Finally, the strategies developed by scatterHatch and other recent software only address color-vision deficiencies and not other visual impairments such as double vision or complete blindness. In such cases, we need to incorporate accessibility features such as screen reader-friendly alternate texts (<xref ref-type="bibr" rid="bib9">Jung et al., 2022</xref>) which describe the graphical elements of the visualizations.</p><sec id="s3-1"><title>Code availability</title><p><italic><underline>scatterHatch</underline></italic> is available on Bioconductor at <ext-link ext-link-type="uri" xlink:href="https://bioconductor.org/packages/release/bioc/html/scatterHatch.html">https://bioconductor.org/packages/release/bioc/html/scatterHatch.html</ext-link>.</p><p>The development version is available on Github at <ext-link ext-link-type="uri" xlink:href="https://github.com/FertigLab/scatterHatch">https://github.com/FertigLab/scatterHatch</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:499543a39e36217af88e23f3a71c5a93c0a36d48;origin=https://github.com/FertigLab/scatterHatch;visit=swh:1:snp:86780af430d237a14898d90418ac2ae00a07eb16;anchor=swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e">swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e</ext-link>; <xref ref-type="bibr" rid="bib7">Deshpande, 2022</xref>).</p><p>The scripts used to generate the figures in the manuscript are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FertigLab/scatterHatch-paper">https://github.com/FertigLab/scatterHatch-paper</ext-link>; <xref ref-type="bibr" rid="bib7">Deshpande, 2022</xref>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s4"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, eLife</p></fn><fn fn-type="COI-statement" id="conf3"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Validation, Investigation, Visualization, Methodology, Writing â original draft, Writing â review and editing</p></fn><fn fn-type="con" id="con2"><p>Resources, Supervision, Funding acquisition, Writing â original draft, Writing â review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Supervision, Validation, Visualization, Methodology, Writing â original draft, Writing â review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s5"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-82128-mdarchecklist1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>'scatterHatch user guide'.</title></caption><media xlink:href="elife-82128-supp1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s6"><title>Data availability</title><p>The current manuscript is a computational study, so no new data have been generated for this manuscript. The scripts used for generating the figures in this manuscript are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FertigLab/scatterHatch-paper">https://github.com/FertigLab/scatterHatch-paper</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:499543a39e36217af88e23f3a71c5a93c0a36d48;origin=https://github.com/FertigLab/scatterHatch;visit=swh:1:snp:86780af430d237a14898d90418ac2ae00a07eb16;anchor=swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e">swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e</ext-link>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Institutes of Health Grants U01CA253403, U01CA212007, and P01CA247886.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becht</surname><given-names>E</given-names></name><name><surname>McInnes</surname><given-names>L</given-names></name><name><surname>Healy</surname><given-names>J</given-names></name><name><surname>Dutertre</surname><given-names>CA</given-names></name><name><surname>Kwok</surname><given-names>IWH</given-names></name><name><surname>Ng</surname><given-names>LG</given-names></name><name><surname>Ginhoux</surname><given-names>F</given-names></name><name><surname>Newell</surname><given-names>EW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dimensionality reduction for visualizing single-cell data using UMAP</article-title><source>Nature Biotechnology</source><volume>1</volume><elocation-id>e314</elocation-id><pub-id pub-id-type="doi">10.1038/nbt.4314</pub-id><pub-id pub-id-type="pmid">30531897</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bunis</surname><given-names>DG</given-names></name><name><surname>Andrews</surname><given-names>J</given-names></name><name><surname>Fragiadakis</surname><given-names>GK</given-names></name><name><surname>Burt</surname><given-names>TD</given-names></name><name><surname>Sirota</surname><given-names>MDS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>DittoSeq: universal user-friendly single-cell and bulk RNA sequencing visualization toolkit</article-title><source>Bioinformatics</source><volume>36</volume><fpage>5535</fpage><lpage>5536</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa1011</pub-id><pub-id pub-id-type="pmid">33313640</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname><given-names>A</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Smibert</surname><given-names>P</given-names></name><name><surname>Papalexi</surname><given-names>E</given-names></name><name><surname>Satija</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Integrating single-cell transcriptomic data across different conditions, technologies, and species</article-title><source>Nature Biotechnology</source><volume>36</volume><fpage>411</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1038/nbt.4096</pub-id><pub-id pub-id-type="pmid">29608179</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="web"><person-group person-group-type="author"><collab>Color Universal Design</collab></person-group><year iso-8601-date="2008">2008</year><article-title>Colorblind Barrier Free</article-title><ext-link ext-link-type="uri" xlink:href="https://jfly.uni-koeln.de/color/">https://jfly.uni-koeln.de/color/</ext-link><date-in-citation iso-8601-date="2008-09-24">September 24, 2008</date-in-citation></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crameri</surname><given-names>F</given-names></name><name><surname>Shephard</surname><given-names>GE</given-names></name><name><surname>Heron</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The misuse of colour in science communication</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>5444</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-19160-7</pub-id><pub-id pub-id-type="pmid">33116149</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deeb</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The molecular basis of variation in human color vision</article-title><source>Clinical Genetics</source><volume>67</volume><fpage>369</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1111/j.1399-0004.2004.00343.x</pub-id><pub-id pub-id-type="pmid">15811001</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Deshpande</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>ScatterHatch</data-title><version designator="swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e">swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:499543a39e36217af88e23f3a71c5a93c0a36d48;origin=https://github.com/FertigLab/scatterHatch;visit=swh:1:snp:86780af430d237a14898d90418ac2ae00a07eb16;anchor=swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e">https://archive.softwareheritage.org/swh:1:dir:499543a39e36217af88e23f3a71c5a93c0a36d48;origin=https://github.com/FertigLab/scatterHatch;visit=swh:1:snp:86780af430d237a14898d90418ac2ae00a07eb16;anchor=swh:1:rev:ae8a6b69722adb123fbcde40d12e2b2317deec2e</ext-link></element-citation></ref><ref id="bib8"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Fc</surname><given-names>M</given-names></name><name><surname>Davis</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Ggpattern: âggplot2â pattern geoms</data-title><version designator="1.0.1">1.0.1</version><source>Ggplot2</source><ext-link ext-link-type="uri" xlink:href="https://github.com/coolbutuseless/ggpattern">https://github.com/coolbutuseless/ggpattern</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>C</given-names></name><name><surname>Mehta</surname><given-names>S</given-names></name><name><surname>Kulkarni</surname><given-names>A</given-names></name><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Kim</surname><given-names>YS</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Communicating visualizations without visuals: investigation of visualization alternative text for people with visual impairments</article-title><source>IEEE Transactions on Visualization and Computer Graphics</source><volume>28</volume><fpage>1095</fpage><lpage>1105</lpage><pub-id pub-id-type="doi">10.1109/TVCG.2021.3114846</pub-id><pub-id pub-id-type="pmid">34591768</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katsnelson</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Colour me better: fixing figures for colour blindness</article-title><source>Nature</source><volume>598</volume><fpage>224</fpage><lpage>225</lpage><pub-id pub-id-type="doi">10.1038/d41586-021-02696-z</pub-id><pub-id pub-id-type="pmid">34608306</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>J-R</given-names></name><name><surname>Izar</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Yapp</surname><given-names>C</given-names></name><name><surname>Mei</surname><given-names>S</given-names></name><name><surname>Shah</surname><given-names>PM</given-names></name><name><surname>Santagata</surname><given-names>S</given-names></name><name><surname>Sorger</surname><given-names>PK</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Highly multiplexed immunofluorescence imaging of human tissues and tumors using t-cycif and conventional optical microscopes</article-title><source>eLife</source><volume>7</volume><elocation-id>e31657</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.31657</pub-id><pub-id pub-id-type="pmid">29993362</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliveira</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Towards more accessible visualizations for color-vision-deficient individuals</article-title><source>Computing in Science &amp; Engineering</source><volume>15</volume><fpage>80</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2013.113</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Ou</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>colorBlindness Guide</article-title><ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/colorBlindness/vignettes/colorBlindness.html">https://cran.r-project.org/web/packages/colorBlindness/vignettes/colorBlindness.html</ext-link><date-in-citation iso-8601-date="2021-04-16">April 16, 2021</date-in-citation></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Speir</surname><given-names>ML</given-names></name><name><surname>Bhaduri</surname><given-names>A</given-names></name><name><surname>Markov</surname><given-names>NS</given-names></name><name><surname>Moreno</surname><given-names>P</given-names></name><name><surname>Nowakowski</surname><given-names>TJ</given-names></name><name><surname>Papatheodorou</surname><given-names>I</given-names></name><name><surname>Pollen</surname><given-names>AA</given-names></name><name><surname>Raney</surname><given-names>BJ</given-names></name><name><surname>Seninge</surname><given-names>L</given-names></name><name><surname>Kent</surname><given-names>WJ</given-names></name><name><surname>Haeussler</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>UCSC cell browser: visualize your single-cell data</article-title><source>Bioinformatics</source><volume>37</volume><fpage>4578</fpage><lpage>4580</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btab503</pub-id><pub-id pub-id-type="pmid">34244710</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steenwyk</surname><given-names>JL</given-names></name><name><surname>Rokas</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Ggpubfigs: colorblind-friendly color palettes and ggplot2 graphic system extensions for publication-quality scientific figures</article-title><source>Microbiology Resource Announcements</source><volume>10</volume><elocation-id>e0087121</elocation-id><pub-id pub-id-type="doi">10.1128/MRA.00871-21</pub-id><pub-id pub-id-type="pmid">34734767</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>FA</given-names></name><name><surname>Angerer</surname><given-names>P</given-names></name><name><surname>Theis</surname><given-names>FJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>SCANPY: large-scale single-cell gene expression data analysis</article-title><source>Genome Biology</source><volume>19</volume><elocation-id>15</elocation-id><pub-id pub-id-type="doi">10.1186/s13059-017-1382-0</pub-id><pub-id pub-id-type="pmid">29409532</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Points of view: color coding</article-title><source>Nature Methods</source><volume>7</volume><elocation-id>573</elocation-id><pub-id pub-id-type="doi">10.1038/nmeth0810-573</pub-id><pub-id pub-id-type="pmid">20704014</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Color blindness</article-title><source>Nature Methods</source><volume>8</volume><elocation-id>441</elocation-id><pub-id pub-id-type="doi">10.1038/nmeth.1618</pub-id><pub-id pub-id-type="pmid">21774112</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.82128.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Choi</surname><given-names>Jungmin</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047dqcg40</institution-id><institution>Korea University College of Medicine</institution></institution-wrap><country>Republic of Korea</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.10.07.463279" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.10.07.463279"/></front-stub><body><p>This manuscript demonstrates a beneficial R package that provides a valuable pattern and overlay framework for producing colorblind-friendly scatter plots for the field. This work will be an extraordinary resource to the single-cell genomics community and of broad interest to many biomedical scientists, especially to viewers with color-vision deficiency. This attempt should become a new standard in the scientific community that strives to achieve greater inclusiveness.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.82128.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Choi</surname><given-names>Jungmin</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047dqcg40</institution-id><institution>Korea University College of Medicine</institution></institution-wrap><country>Republic of Korea</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Bunis</surname><given-names>Daniel G</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/043mz5j54</institution-id><institution>University of California, San Francisco</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.10.07.463279">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.10.07.463279v2">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;scatterHatch: an R/Bioconductor package for generating colorblind-friendly scatter plots for single-cell data&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Mone Zaidi as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Daniel G Bunis (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) In Figure 1, it is a little hard to see the yellow-colored points in the sparse points demonstration. Perhaps the colors could be cycled, or one of the other regions could be used, in order for a darker color to be used for this demonstration.</p><p>2) The manuscript appears well written and where there are shortcomings would be in helping inexperienced r users navigate the add-on package. I would recommend a supplementary guide that helps novice users install and use the package--this would help strive for greater inclusiveness of individuals with varying levels of skill in r.</p><p>3) The pattern-overlay framework could be expanded and applied to other plots such as alluvial plots, violin plots, etc in addition to dim plots.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>scatterHatch seems a well-constructed R package, and the manuscript is well-written. I believe this manuscript will be a very valuable addition to the field, especially because scatterHatch's system provides aid to viewers with monochromatic vision, an aid that even other common CVD-aware visualization tools fail to provide.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.82128.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) In Figure 1, it is a little hard to see the yellow-colored points in the sparse points demonstration. Perhaps the colors could be cycled, or one of the other regions could be used, in order for a darker color to be used for this demonstration.</p></disp-quote><p>We have revised the illustration in Figure 1 to show a different cell group with darker colors for the demonstration of the scatterHatch workflow.</p><disp-quote content-type="editor-comment"><p>2) The manuscript appears well written and where there are shortcomings would be in helping inexperienced r users navigate the add-on package. I would recommend a supplementary guide that helps novice users install and use the package--this would help strive for greater inclusiveness of individuals with varying levels of skill in r.</p></disp-quote><p>We agree that a user guide will be really helpful! We are including a supplementary guide based on the scatterHatch package vignette in the revised submission.</p><disp-quote content-type="editor-comment"><p>3) The pattern-overlay framework could be expanded and applied to other plots such as alluvial plots, violin plots, etc in addition to dim plots.</p></disp-quote><p>Such pattern overlays can be obtained using existing packages like the ggpattern package available on github. However, we agree with the reviewerâs suggestion that future work could include creating a multi-purpose colorblind friendly visualization software, which include CVD-friendly strategies such as scatterHatch, ggpattern, etc.</p></body></sub-article></article>