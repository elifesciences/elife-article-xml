<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">59907</article-id><article-id pub-id-type="doi">10.7554/eLife.59907</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Human complex exploration strategies are enriched by noradrenaline-modulated heuristics</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-192367"><name><surname>Dubois</surname><given-names>Magda</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5396-1855</contrib-id><email>magda.dubois.18@ucl.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-192368"><name><surname>Habicht</surname><given-names>Johanna</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-192369"><name><surname>Michely</surname><given-names>Jochen</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-192370"><name><surname>Moran</surname><given-names>Rani</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7641-2402</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-19714"><name><surname>Dolan</surname><given-names>Ray J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9356-761X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-120970"><name><surname>Hauser</surname><given-names>Tobias U</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7997-8137</contrib-id><email>t.hauser@ucl.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Max Planck UCL Centre for Computational Psychiatry and Ageing Research</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution>Wellcome Trust Centre for Neuroimaging, University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution>Department of Psychiatry and Psychotherapy, Charité – Universitätsmedizin Berlin</institution><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kahnt</surname><given-names>Thorsten</given-names></name><role>Reviewing Editor</role><aff><institution>Northwestern University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Senior Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>04</day><month>01</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e59907</elocation-id><history><date date-type="received" iso-8601-date="2020-06-12"><day>12</day><month>06</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-01-03"><day>03</day><month>01</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Dubois et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Dubois et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-59907-v2.pdf"/><abstract><p>An exploration-exploitation trade-off, the arbitration between sampling a lesser-known against a known rich option, is thought to be solved using computationally demanding exploration algorithms. Given known limitations in human cognitive resources, we hypothesised the presence of additional cheaper strategies. We examined for such heuristics in choice behaviour where we show this involves a value-free random exploration, that ignores all prior knowledge, and a novelty exploration that targets novel options alone. In a double-blind, placebo-controlled drug study, assessing contributions of dopamine (400 mg amisulpride) and noradrenaline (40 mg propranolol), we show that value-free random exploration is attenuated under the influence of propranolol, but not under amisulpride. Our findings demonstrate that humans deploy distinct computationally cheap exploration strategies and that value-free random exploration is under noradrenergic control.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>exploration-exploitation</kwd><kwd>dopamine</kwd><kwd>noradrenaline</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004189</institution-id><institution>Max-Planck-Gesellschaft</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dubois</surname><given-names>Magda</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>Sir Henry Dale Fellowship 211155/Z/18/Z</award-id><principal-award-recipient><name><surname>Hauser</surname><given-names>Tobias U</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003986</institution-id><institution>Jacobs Foundation</institution></institution-wrap></funding-source><award-id>2017-1261-04</award-id><principal-award-recipient><name><surname>Hauser</surname><given-names>Tobias U</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>Investigator Award 098362/Z/12/Z</award-id><principal-award-recipient><name><surname>Dolan</surname><given-names>Ray J</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100009187</institution-id><institution>Medical Research Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Hauser</surname><given-names>Tobias U</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000874</institution-id><institution>Brain and Behavior Research Foundation</institution></institution-wrap></funding-source><award-id>27023</award-id><principal-award-recipient><name><surname>Hauser</surname><given-names>Tobias U</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>946055</award-id><principal-award-recipient><name><surname>Hauser</surname><given-names>Tobias U</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>Centre Award 203147/Z/16/Z</award-id><principal-award-recipient><name><surname>Dolan</surname><given-names>Ray J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Humans supplement complex, resource-demanding strategies with simple heuristics for solving the exploration-exploitation dilemma, and noradrenaline functioning controls their utilisation.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Chocolate, Toblerone, spinach, or hibiscus ice-cream? Do you go for the flavour you like the most (chocolate), or another one? In such an exploration-exploitation dilemma, you need to decide whether to go for the option with the highest known subjective value (exploitation) or opt instead for less known or valued options (exploration) so as to not miss out on possibly even higher rewards. In the latter case, you can opt to either choose an option that you have previously enjoyed (Toblerone), an option you are curious about because you do not know what to expect (hibiscus), or even an option that you have disliked in the past (spinach). Depending on your exploration strategy, you may end up with a highly disappointing ice cream encounter, or a life-changing gustatory epiphany.</p><p>A common approach to the study of complex decision making, for example an exploration-exploitation trade-off, is to take computational algorithms developed in the field of artificial intelligence and test whether key signatures of these are evident in human behaviour. This approach has revealed humans use strategies that reflect an implementation of computationally demanding exploration algorithms (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>; <xref ref-type="bibr" rid="bib71">Schulz and Gershman, 2019</xref>). One such strategy, directed exploration, involves awarding an ‘information bonus’ to choice options, a bonus that scales with uncertainty. This is captured in algorithms such as the Upper Confidence Bound (UCB) (<xref ref-type="bibr" rid="bib3">Auer, 2003</xref>; <xref ref-type="bibr" rid="bib11">Carpentier et al., 2011</xref>) and leads to an exploration of choice options the agent knowns little about (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>; <xref ref-type="bibr" rid="bib72">Schwartenbeck et al., 2019</xref>) (e.g. the hibiscus ice-cream). An alternative strategy, sometimes termed ‘random’ exploration, is to induce stochasticity after value computations in the decision process. This can be realised using a fixed parameter as a source of stochasticity, such as a softmax temperature parameter (<xref ref-type="bibr" rid="bib20">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>), which can be combined with the UCB algorithm (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>). Alternatively, one can use a dynamic source of stochasticity, such as in Thompson sampling (<xref ref-type="bibr" rid="bib84">Thompson, 1933</xref>), where stochasticity adapts to an uncertainty about choice options. This exploration is essentially a more sophisticated, uncertainty-driven, version of a softmax. By accounting for stochasticity when comparing choice options’ expected values, in effect choosing based on both uncertainty and value, these exploration strategies increase the likelihood of choosing ‘good’ options that are only slightly less valuable than the best (e.g. the Toblerone ice-cream if you are a chocolate lover).</p><p>The above processes are computationally demanding, especially when facing real-life multiple-alternative decision problems (<xref ref-type="bibr" rid="bib20">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib15">Cohen et al., 2007</xref>; <xref ref-type="bibr" rid="bib14">Cogliati Dezza et al., 2019</xref>). Human cognitive resources are constrained by capacity limitations (<xref ref-type="bibr" rid="bib61">Papadopetraki et al., 2019</xref>), metabolic consumption (<xref ref-type="bibr" rid="bib102">Zénon et al., 2019</xref>), but also because of resource allocation to parallel tasks (e.g.<xref ref-type="bibr" rid="bib89">Wahn and König, 2017</xref>; <xref ref-type="bibr" rid="bib58">Marois and Ivanoff, 2005</xref>). This directly relates to an agents’ motivation to perform a given task (<xref ref-type="bibr" rid="bib61">Papadopetraki et al., 2019</xref>; <xref ref-type="bibr" rid="bib6">Botvinick and Braver, 2015</xref>; <xref ref-type="bibr" rid="bib29">Froböse et al., 2020</xref>), as increasing an information demand in one process automatically reduces its availability for others (<xref ref-type="bibr" rid="bib102">Zénon et al., 2019</xref>). In real-world highly dynamic environments, this arbitration is critical as humans need to maintain resources for alternative opportunities (i.e. flexibility; <xref ref-type="bibr" rid="bib61">Papadopetraki et al., 2019</xref>; <xref ref-type="bibr" rid="bib54">Kool et al., 2010</xref>; <xref ref-type="bibr" rid="bib16">Cools, 2015</xref>). This accords with previous studies showing humans are demand-avoidant (<xref ref-type="bibr" rid="bib54">Kool et al., 2010</xref>; <xref ref-type="bibr" rid="bib30">Froböse and Cools, 2018</xref>) and suggests that exploration computations tend to be minimised. Here, we examine the explanatory power of two additional computationally less costly forms of exploration, namely value-free random exploration and novelty exploration.</p><p>Computationally, the least resource demanding way to explore is to ignore all prior information and to choose entirely randomly, de facto assigning the same probability to all options. Such ‘value-free’ random exploration, as opposed to the two previously considered ‘value-based’ random explorations (for simulations comparing their effects <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>) that add stochasticity during choice value computation, forgoes any costly computation (i.e. value mean and uncertainty), known as an <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-greedy algorithmic strategy in reinforcement learning (<xref ref-type="bibr" rid="bib82">Sutton and Barto, 1998</xref>). Computational efficiency, however, comes at the cost of sub-optimality due to occasional selection of options of low expected value (e.g. the repulsive spinach ice cream).</p><p>Despite its sub-optimality, value-free random exploration has neurobiological plausibility. Of relevance in this context is a view that exploration strategies depend on dissociable neural mechanisms (<xref ref-type="bibr" rid="bib101">Zajkowski et al., 2017</xref>). Influences from noradrenaline and dopamine are plausible candidates in this regard based on prior evidence (<xref ref-type="bibr" rid="bib15">Cohen et al., 2007</xref>; <xref ref-type="bibr" rid="bib37">Hauser et al., 2016</xref>). Amongst other roles (such as memory [<xref ref-type="bibr" rid="bib69">Sara et al., 1994</xref>], or energisation of behaviour [<xref ref-type="bibr" rid="bib88">Varazzani et al., 2015</xref>; <xref ref-type="bibr" rid="bib75">Silvetti et al., 2018</xref>]), the neuromodulator noradrenaline has been ascribed a function of indexing uncertainty (<xref ref-type="bibr" rid="bib74">Silvetti et al., 2013</xref>; <xref ref-type="bibr" rid="bib100">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib59">Nassar et al., 2012</xref>) or as acting as a ‘reset button’ that interrupts ongoing information processing (<xref ref-type="bibr" rid="bib19">David Johnson, 2003</xref>; <xref ref-type="bibr" rid="bib7">Bouret and Sara, 2005</xref>; <xref ref-type="bibr" rid="bib21">Dayan and Yu, 2006</xref>). Prior experimental work in rats shows boosting noradrenaline leads to more value-free-random-like random behaviour (<xref ref-type="bibr" rid="bib83">Tervo et al., 2014</xref>), while pharmacological manipulations in monkeys indicates reducing noradrenergic activity increases choice consistency (<xref ref-type="bibr" rid="bib45">Jahn et al., 2018</xref>).</p><p>In human pharmacological studies, interpreting the specific function of noradrenaline on exploration strategies is problematic as many drugs, such as atomoxetine (e.g. <xref ref-type="bibr" rid="bib91">Warren et al., 2017</xref>), impact multiple neurotransmitter systems. Here, to avoid this issue, we chose the highly specific <inline-formula><mml:math id="inf2"><mml:mi mathvariant="normal">β</mml:mi></mml:math></inline-formula>-adrenoceptor antagonist propranolol, which has only minimal impact on other neurotransmitter systems (<xref ref-type="bibr" rid="bib28">Fraundorfer et al., 1994</xref>; <xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>). Using this neuromodulator, we examine whether signatures of value-free random exploration are impacted by administration of propranolol.</p><p>An alternative computationally efficient exploration heuristic to random exploration is to simply choose an option not encountered previously, which we term novelty exploration. Humans often show novelty seeking (<xref ref-type="bibr" rid="bib9">Bunzeck et al., 2012</xref>; <xref ref-type="bibr" rid="bib98">Wittmann et al., 2008</xref>; <xref ref-type="bibr" rid="bib32">Gershman and Niv, 2015</xref>; <xref ref-type="bibr" rid="bib81">Stojić et al., 2020</xref>), and this strategy can be used in exploration as implemented by a low-cost version of the UCB algorithm. Here, a novelty bonus (<xref ref-type="bibr" rid="bib56">Krebs et al., 2009</xref>) is added if a choice option has not been seen previously (i.e. it does not have to rely on precise uncertainty estimates). The neuromodulator dopamine is implicated not only in exploration in general (<xref ref-type="bibr" rid="bib27">Frank et al., 2009</xref>), but also in signalling such types of novelty bonuses, where evidence indicates a role in processing and exploring novel and salient states (<xref ref-type="bibr" rid="bib98">Wittmann et al., 2008</xref>; <xref ref-type="bibr" rid="bib8">Bromberg-Martin et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Costa et al., 2014</xref>; <xref ref-type="bibr" rid="bib24">Düzel et al., 2010</xref>; <xref ref-type="bibr" rid="bib43">Iigaya et al., 2019</xref>). Although pharmacological dopaminergic studies in humans have demonstrated effects on exploration as a whole (<xref ref-type="bibr" rid="bib53">Kayser et al., 2015</xref>), they have not identified specific exploration strategies. Here, we used the highly specific D2/D3 antagonist amisulpride, to disentangle the specific role of dopamine and noradrenaline on different exploration strategies.</p><p>Thus, in the current study, we examine the contributions of value-free random exploration and novelty exploration in human choice behaviour. We developed a novel exploration task combined with computational modeling to probe the contributions of noradrenaline and dopamine. Under double-blind, placebo-controlled, conditions, we assessed the impact of two antagonists with high affinity and specificity for either dopamine (amisulpride) or noradrenaline (propranolol), respectively. Our results provide evidence that both exploration heuristics supplement computationally more demanding exploration strategies, and that value-free random exploration is particularly sensitive to noradrenergic modulation, with no effect of amisulpride.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Probing the contributions of heuristic exploration strategies</title><p>We developed a novel multi-round three-armed bandit task (<xref ref-type="fig" rid="fig1">Figure 1</xref>; bandits depicted as trees), enabling us to assess the contributions of value-free random exploration and novelty exploration in addition to Thompson sampling and UCB (combined with a softmax). In particular, we exploited the fact that both heuristic strategies make specific predictions about choice patterns. The novelty exploration assigns a ‘novelty bonus’ only to bandits for which subjects have no prior information, but not to other bandits. This can be seen as a low-resolution version of UCB, which assigns a bonus to all choice options proportionally to how informative they are, in effect a graded bonus which scales to each bandit's uncertainty. Thus, to capture this heuristic, we manipulated the amount of prior information with bandits carrying only little information (i.e. 1 vs 3 initial samples) or no information (0 initial samples). A high novelty exploration predicts a higher frequency of selecting the novel option (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). This is in contrast to high exploration using other strategies which does not predict such a strong effect on the novel option (<xref ref-type="fig" rid="fig1s5">Figure 1—figure supplement 5</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Study design.</title><p>In the Maggie’s farm task, subjects had to choose from three bandits (depicted as trees) to maximise an outcome (sum of reward). The rewards (apple size) of each bandit followed a normal distribution with a fixed sampling variance. (<bold>a</bold>) At the beginning of each trial, subjects were provided with some initial samples on the wooden crate at the bottom of the screen and had to select which bandit they wanted to sample from next. (<bold>b</bold>) Depending the condition, they could either perform one draw (short horizon) or six draws (long horizon). The empty spaces on the wooden crate (and the sun's position) indicated how many draws they had left. The first draw in both conditions was the main focus of the analysis. (<bold>c</bold>) In each trial, three bandits were displayed, selected from four possible bandits, with different generative processes that varied in terms of their sample mean and number of initial samples (i.e. samples shown at the beginning of a trial). The ‘certain-standard bandit’ and the ‘standard bandit’ had comparable means but different levels of uncertainty about their expected mean: they provided three and one initial sample, respectively; the ‘low-value bandit’ had a low mean and displayed one initial sample; the ‘novel bandit’ did not show any initial sample and its mean was comparable with that of the standard bandits. (<bold>d</bold>) Prior to the task, subjects were administered different drugs: 400 mg amisulpride that blocks dopaminergic D2/D3 receptors, 40 mg propranolol to block noradrenergic β-receptors, and inert substances for the placebo group. Different administration times were chosen to comply with the different drug pharmacokinetics (placebo matching the other groups’ administration schedule). (<bold>e</bold>) Simulating value-free random behaviour with a low vs high model parameter (<inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) in this task shows that in a high regime, agents choose the low-value bandit more often (left panel; mean ± 1 SD) and are less consistent in their choices when facing identical choice options (right panel). (<bold>f</bold>) Novelty exploration exclusively promotes choosing choice options for which subjects have no prior information, captured by the ‘novel bandit’ in our task. For details about simulations cf. Materials and methods. For details about the task display <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. For simulations of different exploration strategies and their impact of different bandits <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>–<xref ref-type="fig" rid="fig1s5">5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Visualisation of the nine different sizes that the apples could take.</title><p>The associated rewards went from 2 (small apple on the left) to 10 (big apple on the right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Comparison of value-based (softmax) and value-free (<inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-greedy) random exploration.</title><p>(<bold>a</bold>) Changing the softmax inverse temperature affects the slope of the sigmoid while changing the <inline-formula><mml:math id="inf5"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter (<bold>b</bold>) affects the compression of the sigmoid. Conceptually, in a softmax exploration mode, as each bandit's expected value is taken into account, (<bold>c</bold>) the second best bandit (medium-value bandit) is favoured over one with a lower value (low-value bandit) when injecting noise. In contrast, in an <inline-formula><mml:math id="inf6"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy exploration mode, (<bold>d</bold>) bandits are explored equally often irrespective of their expected value. Both simulations were performed on trials without novel bandit. When simulating on all trials, we observe that this also has a consequence for choice consistency. (<bold>e</bold>) Choices are more consistent in a low (versus high) softmax exploration mode (i.e. high and low values of <inline-formula><mml:math id="inf7"><mml:mi>β</mml:mi></mml:math></inline-formula>, respectively), and similarly (f) choices are more consistent in a low (versus high) <inline-formula><mml:math id="inf8"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy exploration mode (i.e. low and high values of <inline-formula><mml:math id="inf9"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>, respectively). When comparing the overall consistency of the two random exploration strategies, consistency is higher in the value-based mode, reflecting a higher probability of (consistently) exploring the second best option, compared to an equal probability of exploring any non-optimal option (inconsistently) in the value-free mode.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Simulation illustrations of high and low exploration on the frequency of picking the low-value bandit using different exploration strategies (<bold>a</bold>) a high (versus low) value-free random exploration increases the selection of the low-value bandit, whereas neither (<bold>b</bold>) a high (versus low) novelty exploration, (<bold>c</bold>) a high (versus low) Thompson-sampling exploration nor (<bold>d</bold>) a high (versus low) UCB exploration affected this frequency.</title><p>To illustrate the long (versus short) horizon condition, we accommodated the fact that not only key values but also other exploration strategies were enhanced by increasing multiple exploration strategies, as found in our experimental data (<xref ref-type="table" rid="app2table7">Appendix 2—table 7</xref> for parameter values). Please note that the difference between low and high exploration is critical here, rather than a comparison of the absolute height of the bars between strategies (which is influences in the models by multiple different exploration strategies). For simulations fitting participants’ data, please see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1</xref> and <xref ref-type="fig" rid="fig5s3">3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig1-figsupp3-v2.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 4.</label><caption><title>Simulation illustrations of high and low exploration choice consistency using different exploration strategies shows that (<bold>a</bold>) a high (versus low) value-free random exploration decreases the proportion of same choices, whereas neither (<bold>b</bold>) a high (versus low) novelty exploration, (<bold>c</bold>) a high (versus low) Thompson-sampling exploration nor (<bold>d</bold>) a high (versus low) UCB exploration affected this measure.</title><p>To illustrate the long (versus short) horizon condition, accommodated the fact that not only the key value but also other exploration strategies were enhanced by increasing multiple exploration strategies, as found in our experimental data (<xref ref-type="table" rid="app2table7">Appendix 2—table 7</xref> for parameter values). Please note that the difference between low and high exploration is critical here, rather than a comparison of the absolute height of the bars between strategies (which is influences in the models by multiple different exploration strategies). For simulations fitting participants’ data, please see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1</xref> and <xref ref-type="fig" rid="fig5s3">3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig1-figsupp4-v2.tif"/></fig><fig id="fig1s5" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 5.</label><caption><title>Simulation illustrations of high and low exploration on the frequency of picking the novel bandit using different exploration strategies shows that (<bold>a</bold>) a high (versus low) value-free random exploration has little effect on the selection of the novel bandit, whereas (<bold>b</bold>) a high (versus low) novelty exploration increases this frequency.</title><p>(<bold>c</bold>) A high (versus low) Thompson-sampling exploration had little effect and (<bold>d</bold>) a high (versus low) UCB exploration affected this frequency but to a lower extend than novelty exploration. To illustrate the long (versus short) horizon condition, we accommodated the fact that not only the key value but also other exploration strategies were enhanced by increasing multiple exploration strategies, as found in our experimental data (<xref ref-type="table" rid="app2table7">Appendix 2—table 7</xref> for parameter values). Please note that the difference between low and high exploration is critical here, rather than a comparison of the absolute height of the bars between strategies (which is influences in the models by multiple different exploration strategies). For simulations fitting participants’ data, please see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1</xref> and <xref ref-type="fig" rid="fig5s3">3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig1-figsupp5-v2.tif"/></fig></fig-group><p>Value-free random exploration, captured here by <inline-formula><mml:math id="inf10"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy, predicts that all prior information is discarded entirely and that there is equal probability attached to all choice options. This strategy is distinct from other exploration strategies as it is likely to choose bandits known to be substantially worse than the other bandits. Thus, a high value-free random exploration predicts a higher frequency of selecting the low-value option (<xref ref-type="fig" rid="fig1">Figure 1e</xref>), whereas high exploration using other strategies does not predict such effect (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). A second prediction is that choice consistency, across repeated trials, is directly affected by value-free random exploration, in particular by comparison to other more deterministic exploration strategies (e.g. directed exploration) that are value-guided and thus will consistently select the most informative and valuable options. Given that value-free random exploration splits its choice probability equally (i.e. 33.3% of choosing any bandit out of the three displayed), an increase in such exploration predicts a lower likelihood of choosing the same bandit again, even under identical choice options (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). This contrasts to other strategies that make consistent exploration predictions (e.g. UCB would consistently explore the choice option that carries a high information bonus; <xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>).</p><p>We generated bandits from four different generative processes (<xref ref-type="fig" rid="fig1">Figure 1c</xref>) with distinct sample means (but a fixed sampling variance) and number of initial samples (i.e. samples shown at the beginning of a trial for this specific bandit). Subjects were exposed to these bandits before making their first draw. The ‘certain-standard bandit’ and the (less certain) ‘standard bandit’ were bandits with comparable means but varying levels of uncertainty, providing either three or one initial samples (depicted as apples; similar to the horizon task [<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>]). The ‘low-value bandit’ was a bandit with one initial sample from a substantially lower generative mean, thus appealing to a value-free random exploration strategy alone. The last bandit, with a mean comparable with that of the standard bandits, was a ‘novel bandit’ for which no initial sample was shown, primarily appealing to a novelty exploration strategy (cf. Materials and methods for a full description of bandit generative processes). To assess choice consistency, all trials were repeated once. In the pilot experiments (data not shown), we noted some exploration strategies tended to overshadow other strategies. To effectively assess all exploration strategies, we opted to present only three of the four different bandit types on each trial, as different bandit triples allow different explorations to manifest. Lastly, to assess whether subjects’ behaviour captured exploration, we manipulated the degree to which subjects could interact with the same bandits. Similar to previous studies (<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>), subjects could perform either one draw, encouraging exploitation (short horizon condition), or six draws, encouraging more substantial explorative behaviour (long horizon condition) (<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>; <xref ref-type="bibr" rid="bib91">Warren et al., 2017</xref>).</p></sec><sec id="s2-2"><title>Testing the role of catecholamines noradrenaline and dopamine</title><p>In a double-blind, placebo-controlled, between-subjects study design, we assigned subjects (N=60) randomly to one of three experimental groups: amisulpride, propranolol, or placebo. The first group received 40 mg of the <inline-formula><mml:math id="inf11"><mml:mi>β</mml:mi></mml:math></inline-formula>-adrenoceptor antagonist propranolol to alter noradrenaline function, while the second group was administered 400 mg of the D2/D3 antagonist amisulpride that alters dopamine function. Because of different pharmacokinetic properties, these drugs were administered at different times (<xref ref-type="fig" rid="fig1">Figure 1d</xref>) and compared to a placebo group that received a placebo at both drug times to match the corresponding antagonist's time. One subject (amisulpride group) was excluded from the analysis due to a lack of engagement with the task. Reported findings were corrected for IQ and mood, as drug groups differed marginally in those measures (<xref ref-type="table" rid="app2table7">Appendix 2—table 7</xref>), by adding WASI (<xref ref-type="bibr" rid="bib96">Wechsler, 2013</xref>) and PANAS (<xref ref-type="bibr" rid="bib94">Watson et al., 1988a</xref>) negative scores as covariates in each ANOVA. Similar results were obtained in an analysis that corrected for physiological effects as from the analysis without covariates (cf. Appendix 1).</p></sec><sec id="s2-3"><title>Increased exploration when information can subsequently be exploited</title><p>Our task embodied two decision-horizon conditions, a short and a long. To assess whether subjects explored more in a long horizon condition, in which additional information can inform later choices, we examined which bandit subjects chose in their first draw (in accordance with the horizon task [<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>]), irrespective of their drug group. A marker of exploration here is evident if subjects chose bandits with lower expected values, computed as the mean value of their initial samples shown (trials where the novel bandit was chosen were excluded). As expected, subjects chose bandits with a lower expected value in the long compared to the short horizon (repeated-measures ANOVA for the expected value: F(1, 56) = 19.457, p&lt;0.001, <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.258; <xref ref-type="fig" rid="fig2">Figure 2a</xref>). To confirm that this was a consequence of increased exploration, we analysed the proportion of how often the high-value option was chosen (i.e. the bandit with the highest expected reward based on its initial samples) and we found that subjects (especially those with higher IQ) sampled from it more in the short compared to the long horizon, (WASI-by-horizon interaction: F(1, 54) = 13.304, p = 0.001, <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.198; horizon main effect: F(1, 54) = 3.909, p = 0.053, <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.068; <xref ref-type="fig" rid="fig3">Figure 3a</xref>), confirming a reduction in exploitation when this information could be subsequently used. Interestingly, this frequency seemed to be marginally higher in the amisulpride group, suggesting an overall higher tendency to exploitation following dopamine blockade (cf. Appendix 1). This horizon-specific behaviour resulted in a lower reward on the first sample in the long compared to the short horizon (F(1, 56) = 23.922, p&lt;0.001, <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.299; <xref ref-type="fig" rid="fig2">Figure 2c</xref>). When we tested whether subjects were more likely to choose options they knew less about (computed as the mean number of initial samples shown), we found that subjects chose less known (i.e. more informative) bandits more often in the long horizon compared to the short horizon (F(1, 56) = 58.78, p&lt;0.001, <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.512; <xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Benefits of exploration.</title><p>To investigate the effect of information on performance we collapsed subjects over all three treatment groups. (<bold>a</bold>) The expected value (average of its initial samples) of the first chosen bandit as a function of horizon. Subjects chose bandits with a lower expected value (i.e. they explored more) in the long horizon compared to the short horizon. (<bold>b</bold>) The mean number of samples for the first chosen bandit as a function of horizon. Subjects chose less known (i.e. more informative) bandits more in the long compared to the short horizon. (<bold>c</bold>) The first draw in the long horizon led to a lower reward than the first draw in the short horizon, indicating that subjects sacrificed larger initial outcomes for the benefit of more information. This additional information helped making better decisions in the long run, leading to a higher earning over all draws in the long horizon. For values and statistics <xref ref-type="table" rid="app2table3">Appendix 2—table 3</xref>. For response times and details about all long horizons’ samples <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. *** = p&lt;0.001. Data are shown as mean ± 1 SEM and each dot/line represent a subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Further analysis of long horizon draws.</title><p>(<bold>a</bold>) The first draw in the long horizon led to a lower reward than the short horizon, indicating more exploration, while the subsequent draws led to a higher reward indicating that this additional information helped making better decisions in the long run. (<bold>b</bold>) The first draws’ response time was the highest and then decreased for each draw. Long horizon trials in which subjects started with (<bold>c</bold>) an exploitation draw (choose the bandit with the highest expected value) led to little increase in reward (y-axis: difference between obtained reward and highest reward of initial samples; linear regression slope coefficient: mean = 0.118, sd = 0.038), whereas trials in which they started with (<bold>d</bold>) an exploration draw led to an large increase in reward (linear regression slope coefficient: mean = 0.028, sd = 0.041). This larger increase in reward when starting by exploring (slope is higher: t(58) = -12.161, p&lt;0.001, d = −1.583) indicates that the information that was gained through exploration led to higher long-term outcomes. Data are shown as mean ± 1 SEM and each dot represent one subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig2-figsupp1-v2.tif"/></fig></fig-group><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Behavioural horizon and drug effects.</title><p>Choice patterns in the first draw for each horizon and drug group (propranolol, placebo and amisulpride). (<bold>a</bold>) Subjects sampled from the high-value bandit (i.e. bandit with the highest average reward of initial samples) more in the short horizon compared to the long horizon indicating reduced exploitation. (<bold>b</bold>) Subjects sampled from the low-value bandit more in the long horizon compared to the short horizon indicating value-free random exploration, but subjects in the propranolol group sampled less from it overall, and (<bold>c</bold>) were more consistent in their choices overall, indicating that noradrenaline blockade reduces value-free random exploration. (<bold>d</bold>) Subjects sampled from the novel bandit more in the long horizon compared to the short horizon indicating novelty exploration. Please note that some horizon effects were modulated by subjects’ intellectual abilities when additionally controlling for them (<xref ref-type="table" rid="app2table4">Appendix 2—table 4</xref>). Horizontal bars represent rm-ANOVA (thick) and pairwise comparisons (thin). <bold>†</bold> = p&lt;0.07, * = p&lt;0.05, ** = p&lt;0.01. Data are shown as mean ± 1 SEM and each line represent one subject. For values and statistics <xref ref-type="table" rid="app2table4">Appendix 2—table 4</xref>. For response times and frequencies specific to the displayed bandits <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s2">2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Response time (RT) analysis per bandit.</title><p>There was no difference in RT depending which bandit was chosen. For details and statistics cf. Appendix 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Proportion of draws per bandit combination (x-axis).</title><p>(<bold>a</bold>) The high-value bandit was picked more when there was no novel bandit, and less when the high-value bandit was less certain. (<bold>b</bold>) The novel bandit was picked the most when the high-value bandit was less certain, then when the high-value bandit was more certain, and it was picked the least when both certain and certain standard bandits were present. (<bold>c</bold>) The low-value bandit was picked less when the high-value bandit was more certain. For statistics see Appendix 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig3-figsupp2-v2.tif"/></fig></fig-group><p>Next, to evaluate whether subjects used the additional information beneficially in the long horizon condition, we compared the average reward (across six draws) obtained in the long compared to short horizon (one draw). We found that the average reward was higher in the long horizon (F(1, 56) = 103.759, p&lt;0.001, <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.649; <xref ref-type="fig" rid="fig2">Figure 2c</xref>), indicating that subjects tended to choose less optimal bandits at first but subsequently learnt to appropriately exploit the harvested information to guide choices of better bandits in the long run. Additionally, when looking specifically at the long horizon condition, we found that subjects earned more when their first draw was explorative versus exploitative (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1c–d</xref>; cf. Appendix 2 for details).</p></sec><sec id="s2-4"><title>Subjects demonstrate value-free random behaviour</title><p>Value-free random exploration (analogue to <inline-formula><mml:math id="inf18"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy) predicts that <inline-formula><mml:math id="inf19"><mml:mi>ϵ</mml:mi> <mml:mi/><mml:mi>%</mml:mi></mml:math></inline-formula> of the time each option will have an equal probability of being chosen. In such a regime (compared to more complex strategies that would favour options with a higher expected value with a similar uncertainty), the probability of choosing bandits with a low expected value (here the low-value bandit; <xref ref-type="fig" rid="fig1">Figure 1e</xref>) will be higher (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). We investigated whether the frequency of picking the low-value bandit was increased in the long horizon condition across all subjects (i.e. when exploration is useful), and we found a significant main effect of horizon (F(1, 54) = 4.069, p = 0.049, <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.07; <xref ref-type="fig" rid="fig3">Figure 3b</xref>). This demonstrates that value-free random exploration is utilised more when exploration is beneficial.</p></sec><sec id="s2-5"><title>Value-free random behaviour is modulated by noradrenaline function</title><p>When we tested whether value-free random exploration was sensitive to neuromodulatory influences, we found a difference in how often drug groups sampled from the low-value option (drug main effect: F(2, 54) = 7.003, p = 0.002, <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.206; drug-by-horizon interaction: F(2, 54) = 2.154, p = 0.126, <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.074; <xref ref-type="fig" rid="fig3">Figure 3b</xref>). This was driven by the propranolol group choosing the low-value option significantly less often than the other two groups (placebo vs propranolol: t(40) = 2.923, p = 0.005, d = 0.654; amisulpride vs propranolol: t(38) = 2.171, p = 0.034, d = 0.496) with no difference between amisulpride and placebo: (t(38) = -0.587, p = 0.559, d = 0.133). These findings demonstrate that a key feature of value-free random exploration, the frequency of choosing low-value bandits, is sensitive to influences from noradrenaline.</p><p>To further examine drug effects on value-free random exploration, we assessed a second prediction, namely choice consistency. Because value-free random exploration ignores all prior information and chooses randomly, it should result in a decreased choice consistency when presented identical choice options (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplements 2</xref> and <xref ref-type="fig" rid="fig1s4">4</xref>, compared to more complex strategies which are always biased towards the rewarding or the information providing bandit for example). To this end, each trial was duplicated in our task, allowing us to compute the consistency as the percentage of time subjects sampled from an identical bandit when facing the exact same choice options. In line with the above analysis, we found a difference in consistency by which drug groups sampled from different option (drug main effect: F(2, 54) = 7.154, p = 0.002, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.209; horizon main effect: F(1, 54) = 1.333, p = 0.253, <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.024; drug-by-horizon interaction: F(2, 54) = 3.352, p = 0.042, <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.11; <xref ref-type="fig" rid="fig3">Figure 3c</xref>), driven by the fact that the propranolol group chose significantly more consistently than the other two groups (pairwise comparisons: placebo vs propranolol: t(40) = -3.525, p = 0.001, d = 0.788; amisulpride vs placebo: t(38) = 1.107, p = 0.272, d = 0.251; amisulpride vs propranolol: t(38) = -2.267, p = 0.026, d = 0.514). Please see Appendix 1 for further discussion and analysis of the drug-by-horizon interaction. Taken together, these results indicate that value-free random exploration depends critically on noradrenaline functioning, such that an attenuation of noradrenaline leads to a reduction in value-free random exploration.</p></sec><sec id="s2-6"><title>Novelty exploration is unaffected by catecholaminergic drugs</title><p>Next, we examined whether subjects show evidence for novelty exploration by choosing the novel bandit for which there was no prior information (i.e. no initial samples), as predicted by model simulations (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). We found a significant main effect of horizon (F(1, 54) = 5.593, p = 0.022, <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.094; WASI-by-horizon interaction: F(1, 54) = 13.897, p&lt;0.001, <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.205; <xref ref-type="fig" rid="fig3">Figure 3d</xref>) indicating that subjects explored the novel bandit significantly more often in the long horizon condition, and this was particularly strong for subjects with a higher IQ. We next assessed whether novelty exploration was sensitive to our drug manipulation, but found no drug effects on the novel bandit (F(2, 54) = 1.498, p = 0.233, <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.053; drug-by-horizon interaction: F(2, 54) = 0.542, p = 0.584, <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.02; <xref ref-type="fig" rid="fig3">Figure 3d</xref>). Thus, there was no evidence that an attenuation of dopamine or noradrenaline function impacts novelty exploration in this task.</p></sec><sec id="s2-7"><title>Subjects combine computationally demanding strategies and exploration heuristics</title><p>To examine the contributions of different exploration strategies to choice behaviour, we fitted a set of computational models to subjects’ behaviour, building on models developed in previous studies (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>). In particular, we compared models incorporating UCB, Thompson sampling, an <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-greedy algorithm and the novelty bonus (cf. Materials and methods). Essentially, each model makes different exploration predictions. In the Thompson model, Thompson sampling (<xref ref-type="bibr" rid="bib84">Thompson, 1933</xref>; <xref ref-type="bibr" rid="bib1">Agrawal and Goyal, 2012</xref>) leads to an uncertainty-driven value-based random exploration, where both expected value and uncertainty contribute to choice. In this model higher uncertainty leads to more exploration such that instead of selecting a bandit with the highest mean, bandits are chosen relative to how often a random sample would yield the highest outcome, thus accounting for uncertainty (<xref ref-type="bibr" rid="bib71">Schulz and Gershman, 2019</xref>). The UCB model (<xref ref-type="bibr" rid="bib3">Auer, 2003</xref>; <xref ref-type="bibr" rid="bib11">Carpentier et al., 2011</xref>), capturing directed exploration, predicts that each bandit is chosen according to a mixture of expected value and an additional expected information gain (<xref ref-type="bibr" rid="bib71">Schulz and Gershman, 2019</xref>). This is realised by adding a bonus to the expected value of each option, proportional to how informative it would be to select this option (i.e. the higher the uncertainty in the option's value, the higher the information gain). This computation is then passed through a softmax decision model, capturing value-based random exploration. Novelty exploration is a simplified version of the information bonus in the UCB algorithm, which only applies to entirely novel options. It defines the intrinsic value of selecting a bandit about which nothing is known, and thus saves demanding computations of uncertainty for each bandit. Last, the value-free random <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-greedy algorithm selects any bandit <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> % of the time, irrespective of the prior information of this bandit. For additional models cf. Appendix 1.</p><p>We used cross-validation for model selection (<xref ref-type="fig" rid="fig4">Figure 4a</xref>) by comparing the likelihood of held-out data across different models, an approach that adequately arbitrates between model accuracy and complexity. The winning model encompasses uncertainty-driven value-based random exploration (Thompson sampling) with value-free random exploration (<inline-formula><mml:math id="inf33"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter) and novelty exploration (novelty bonus parameter <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). The winning model predicted held-out data with a 55.25% accuracy (SD=8.36%; chance level = 33.33%). Similarly to previous studies (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>), the hybrid model combining UCB and Thompson sampling explained the data better than each of those processes alone, but this was no longer the case when accounting for novelty and value-free random exploration (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). The winning model further revealed that all parameter estimates could be accurately recovered (<xref ref-type="fig" rid="fig4">Figure 4b</xref>; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). Interestingly, although the second and third place models made different prediction about the complex exploration strategy, using a directed exploration with value-based random exploration (UCB) or a combination of complex strategies (hybrid) respectively, they share the characteristic of benefitting from value-free random and novelty exploration. This highlights that subjects used a mixture of computationally demanding and heuristic exploration strategies.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Subjects use a mixture of exploration strategies.</title><p>(<bold>a</bold>) A 10-fold cross-validation of the likelihood of held-out data was used for model selection (chance level = 33.3%; for model selection at the individual level <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The Thompson model with both the <inline-formula><mml:math id="inf35"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter and the novelty bonus <inline-formula><mml:math id="inf36"><mml:mi>η</mml:mi></mml:math></inline-formula> best predicted held-out data (<bold>b</bold>) Model simulation with 4<sup>7</sup> simulations predicted good recoverability of model parameters (for correlations between behaviour and model parameters <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>); <inline-formula><mml:math id="inf37"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is the prior variance and <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is the prior mean (for parameter recovery correlation plots <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). 1 stands for short horizon- and 2 for long horizon-specific parameters. For values and parameter details <xref ref-type="table" rid="app2table5">Appendix 2—table 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Model comparison: further evaluations.</title><p>(<bold>a</bold>) The winning model at the group level (the Thompson model with both <inline-formula><mml:math id="inf39"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:mi>η</mml:mi></mml:math></inline-formula>) was also the one that accounted best for the largest number of subjects. (<bold>b</bold>) The Thompson+<inline-formula><mml:math id="inf41"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>+<inline-formula><mml:math id="inf42"><mml:mi>η</mml:mi></mml:math></inline-formula> model and the UCB+<inline-formula><mml:math id="inf43"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>+<inline-formula><mml:math id="inf44"><mml:mi>η</mml:mi></mml:math></inline-formula> are equally first in subject count when comparing all models, the Thompson+<inline-formula><mml:math id="inf45"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>+<inline-formula><mml:math id="inf46"><mml:mi>η</mml:mi></mml:math></inline-formula> model is therefore still the winning model as it has the highest average likelihood of held-out data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Correlations between model parameters and behaviour.</title><p>The behavioural indicators of (<bold>a</bold>) value-free random exploration (left panel: draws from the low-value bandit; right panel: consistency) correlated with the <inline-formula><mml:math id="inf47"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter values, and of (<bold>b</bold>) novelty exploration (draws from the novel bandit) correlated with the novelty bonus <inline-formula><mml:math id="inf48"> <mml:mi/><mml:mi>η</mml:mi></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Parameter recovery analysis details.</title><p>For each of the seven parameters of the winning model, we took four values, equally spread within the parameter range. We simulated behaviour using every combination (<inline-formula><mml:math id="inf49"><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo> <mml:mi/><mml:mn>16384</mml:mn></mml:math></inline-formula>), fitted the model and analysed how well the generative parameters (original values) correlated with the recovered ones (fitted parameters). Pearson correlation coefficient = r. Each dot represents one simulation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig4-figsupp3-v2.tif"/></fig></fig-group></sec><sec id="s2-8"><title>Noradrenaline controls value-free random exploration</title><p>To more formally compare the impact of catecholaminergic drugs on different exploration strategies, we assessed the free parameters of the winning model between drug groups (<xref ref-type="fig" rid="fig5">Figure 5</xref>, cf. Appendix 2 Table 6 for exact values). First, we examined the <inline-formula><mml:math id="inf50"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter that captures the contribution of value-free random exploration to choice behaviour. We assessed how this value-free random exploration differed between drug groups. A significant drug main effect (drug main effect: F(2, 54) = 6.722, p = 0.002, <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.199; drug-by-horizon interaction: F(2, 54) = 1.305, p = 0.28, <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.046; <xref ref-type="fig" rid="fig5">Figure 5a</xref>) demonstrates that the drug groups differ in how strongly they deploy this exploration strategy. Post-hoc analysis revealed that subjects with reduced noradrenaline functioning had the lowest values of <inline-formula><mml:math id="inf53"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> (pairwise comparisons: placebo vs propranolol: t(40) = 3.177, p = 0.002, d = 0.71; amisulpride vs propranolol: t(38) = 2.723, p = 0.009, d = 0 .626) with no significant difference between amisulpride and placebo: (t(38) = 0.251, p = 0.802, d = 0.057). Critically, the effect on <inline-formula><mml:math id="inf54"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> was also significant when the complex exploration strategy was a directed exploration with value-based random exploration (second place model) and, marginally significant, when it was a combination of the above (third place model; cf. Appendix 1).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Drug effects on model parameters.</title><p>The winning model’s parameters were fitted to each subject’s first draw (for model simulations <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). (<bold>a</bold>) Subjects had higher values of <inline-formula><mml:math id="inf55"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> (value-free random exploration) in the long compared to the short horizon. Notably, subjects in the propranolol group had lower values of <inline-formula><mml:math id="inf56"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> overall, indicating that attenuation of noradrenaline functioning reduces value-free random exploration. Subjects from all groups (<bold>b</bold>) assigned a similar value to novelty, captured by the novelty bonus <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, which was higher (more novelty exploration) in the long compared to the short horizon. (<bold>c</bold>) The groups had similar beliefs <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> about a bandit's mean before seeing any initial samples and (<bold>d</bold>) were similarly uncertain <inline-formula><mml:math id="inf59"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> about it (for gender effects <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). Please note that some horizon effects were modulated by subjects’ intellectual abilities when additionally controlling for them (<xref ref-type="table" rid="app2table6">Appendix 2—table 6</xref>). ** = p&lt;0.01. Data are shown as mean ± 1 SEM and each dot/line represent one subject. For parameter values and statistics <xref ref-type="table" rid="app2table6">Appendix 2—table 6</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Simulated behaviour for Thompson+<inline-formula><mml:math id="inf60"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>+<inline-formula><mml:math id="inf61"><mml:mi>η</mml:mi></mml:math></inline-formula> model.</title><p>We used each subjects’ fitted parameters to simulate behaviour (<inline-formula><mml:math id="inf62"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=4000). Data are shown as mean ± 1 SEM and each dot/line represent one agent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Gender effect on prior variance parameter.</title><p>Mean values (across horizon conditions) of <inline-formula><mml:math id="inf63"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub> <mml:mi/></mml:math></inline-formula> were larger for female subjects, whereas in the amisulpride group, they were larger for male subjects. Data are shown as mean ± 1 SEM and each dot represent one subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Simulated behaviour for UCB+<inline-formula><mml:math id="inf64"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>+<inline-formula><mml:math id="inf65"><mml:mi>η</mml:mi></mml:math></inline-formula> model.</title><p>We used each subjects’ fitted parameters to simulate behaviour (<inline-formula><mml:math id="inf66"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=4000). Data are shown as mean ± 1 SEM and each dot/line represent one agent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-fig5-figsupp3-v2.tif"/></fig></fig-group><p>The <inline-formula><mml:math id="inf67"><mml:mi>ϵ</mml:mi></mml:math></inline-formula><italic>-</italic>greedy parameter was also closely linked to the above behavioural metrics (correlation between the <inline-formula><mml:math id="inf68"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter and: draws from the low-value bandit: <inline-formula><mml:math id="inf69"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 0.828, p&lt;0.001; choice consistency: <inline-formula><mml:math id="inf70"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = -0.596, p&lt;0.001; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>), and showed a similar horizon effect (horizon main effect: F(1, 54) = 1.968, p = 0.166, <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.035; WASI-by-horizon interaction: F(1, 54) = 6.08, p = 0.017, <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.101; <xref ref-type="fig" rid="fig5">Figure 5a</xref>). Our findings thus accord with the model-free analyses and demonstrate that noradrenaline blockade reduces value-free random exploration.</p></sec><sec id="s2-9"><title>No drug effects on other parameters</title><p>The novelty bonus <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> captures the intrinsic reward of selecting a novel option. In line with the model-free behavioural findings, there was no difference between drug groups in terms of this effect (F(2, 54) = 0.249, p = 0.78, <inline-formula><mml:math id="inf74"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.009; drug-by-horizon interaction: F(2, 54) = 0.03, p = 0.971, <inline-formula><mml:math id="inf75"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.001). There was also a close alignment between model-based and model-agnostic analyses (correlation between the novelty bonus <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and draws from the novel bandit: <inline-formula><mml:math id="inf77"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 0.683, p&lt;0.001; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>), and we found a similarly increased novelty bonus effect in the long horizon in subjects with a higher IQ (WASI-by-horizon interaction: F(1, 54) = 8.416, p = 0.005, <inline-formula><mml:math id="inf78"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.135; horizon main effect: F(1, 54) = 1.839, p = 0.181, <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.033; <xref ref-type="fig" rid="fig5">Figure 5b</xref>).</p><p>When analysing the additional model parameters, we found that subjects had similar prior beliefs about bandits, given by the initial estimate of a bandit’s mean (prior mean <inline-formula><mml:math id="inf80"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>: F(2, 54) = 0.118, p = 0.889, <inline-formula><mml:math id="inf81"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.004; <xref ref-type="fig" rid="fig5">Figure 5c</xref>) and their uncertainty about it (prior variance <inline-formula><mml:math id="inf82"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>: horizon main effect: F(1, 54) = 0.129, p = 0.721, <inline-formula><mml:math id="inf83"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.002; drug main effect: F(2, 54) = 0.06, p = 0.942, <inline-formula><mml:math id="inf84"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.002; drug-by-horizon interaction: F(2, 54) = 2.162, p = 0.125, <inline-formula><mml:math id="inf85"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.074; WASI-by-horizon interaction: F(1, 54) = 0.022, p = 0.882, <inline-formula><mml:math id="inf86"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> &lt; 0.001; <xref ref-type="fig" rid="fig5">Figure 5d</xref>). Interestingly, our dopamine manipulation seemed to affect this uncertainty in a gender-specific manner, with female subjects having larger values of <inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> compared to males in the placebo group, and with the opposite being true in the amisulpride group (cf. Appendix 1). Taken together, these findings show that value-free random exploration was most sensitive to our drug manipulations.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Solving the exploration-exploitation problem is non-trivial, and one suggestion is that humans solve it using computationally demanding exploration strategies (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>; <xref ref-type="bibr" rid="bib71">Schulz and Gershman, 2019</xref>), taking account of the uncertainty (variance) as well as the expected reward (mean) of each choice. Although tracking the distribution of summary statistics (e.g. mean and variance) is less resource costly than keeping track of full distributions (<xref ref-type="bibr" rid="bib18">D'Acremont and Bossaerts, 2008</xref>), it nevertheless carries considerable costs when one has to keep track of multiple options, as in exploration. Indeed, in a three-bandit task such as that considered here, this results in a necessity to compute six key-statistics, drastically limiting computational resources when selecting among choice options (<xref ref-type="bibr" rid="bib14">Cogliati Dezza et al., 2019</xref>). Real-life decisions often comprise an unlimited range of options, which results in a tracking of a multitude of key-statistics, potentially mandating a deployment of alternative more efficient strategies. Here, we demonstrate that two additional, less resource-hungry heuristics are at play during human decision-making, value-free random exploration and novelty exploration.</p><p>By assigning intrinsic value (novelty bonus [<xref ref-type="bibr" rid="bib56">Krebs et al., 2009</xref>]) to an option not encountered before (<xref ref-type="bibr" rid="bib26">Foley et al., 2014</xref>), a novelty bonus can be seen as an efficient simplification of demanding algorithms, such as UCB (<xref ref-type="bibr" rid="bib3">Auer, 2003</xref>; <xref ref-type="bibr" rid="bib11">Carpentier et al., 2011</xref>). It is interesting to note that our winning model did not include UCB, but instead novelty exploration. This indicates humans might use such a novelty shortcut to explore unseen, or rarely visited, states to conserve computational costs when such a strategy is possible. A second exploration heuristic that also requires minimal computational resources, value-free random exploration, also plays a role in our task. Even though less optimal, its simplicity and neural plausibility renders it a viable strategy. Indeed, we observe an increase in performance in each model after adding <inline-formula><mml:math id="inf88"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>, supporting the notion that this strategy is a relevant additional human exploration heuristic. Interestingly, the benefit of <inline-formula><mml:math id="inf89"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> is somewhat smaller in a simple UCB model (without novelty bonus), which probably arises because value-based random exploration partially captures some of the increased noisiness. We show through converging behavioural and modelling measures that both value-free random and novelty exploration were deployed in a goal-directed manner, coupled with increased levels of exploration when this was strategically useful. Importantly, these heuristics were observed in all best models (first, second and third position) even though each incorporated different exploration strategies. This suggests that the complex models make similar predictions in our task. This is also observed in our simulations, and demonstrates that value-free random exploration is at play even when accounting for other value-based forms of random exploration (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>; <xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>), whether fixed or uncertainty-driven.</p><p>Exploration was captured in a similar manner to previous studies (<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>), by comparing in the same setting (i.e. same prior information) the first choice in a long decision horizon, where reward can be increased in the long term through information gain, and in a short decision horizon where information cannot subsequently be put to use. This means that by changing the opportunity to benefit from the information gained for the first sample, the long horizon invites extended exploration (<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>), what we find also in our study. This experimental manipulation is a well-established means for altering exploration and has been used extensively in previous studies (<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>; <xref ref-type="bibr" rid="bib101">Zajkowski et al., 2017</xref>; <xref ref-type="bibr" rid="bib91">Warren et al., 2017</xref>; <xref ref-type="bibr" rid="bib99">Wu et al., 2018</xref>). Nevertheless, there remains a possibility that a longer horizon may also affect the psychological nature of the task. In our task, reward outcomes were presented immediately after every draw, rendering it unlikely that perception of reward delays (i.e. delay discounting) is impacted. Moreover, a monetary bonus was given only at the end of the task, and thus did not impact the horizon manipulation. We also consider our manipulation was unlikely to change effort in each horizon, because the reward (i.e. size of the apple) remains the same at every draw, resulting in an equivalent reward-effort ratio (<xref ref-type="bibr" rid="bib76">Skvortsova et al., 2014</xref>; <xref ref-type="bibr" rid="bib38">Hauser et al., 2017a</xref>; <xref ref-type="bibr" rid="bib90">Walton and Bouret, 2019</xref>; <xref ref-type="bibr" rid="bib67">Salamone et al., 2016</xref>). However, this issue can be addressed in further studies, for example, by equating the amount of button presses across both conditions.</p><p>Value-free random exploration might reflect other influences, such as attentional lapses or impulsive motor responses. We consider these as unlikely to a significant factor at play here. Indeed, there are two key features that would signify such effects. Firstly, these influences would be independent of task condition. Secondly, they would be expected to lead to shorter, or more variable, response latencies. In our data, we observe an increase in value-free exploration in the long horizon condition in both behavioural measures and model parameters, speaking against an explanation based upon simple mistakes. Moreover, we did not observe a difference in response latency for choices that were related to value-free random exploration (cf. Appendix 1), further arguing against mistakes. Lastly, the sensitivity of value-free random exploration to propranolol supports this being a separate process, and previous studies using the same drug did not find an effect on task mistakes (e.g. on accuracy [<xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Jahn et al., 2018</xref>; <xref ref-type="bibr" rid="bib67">Salamone et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>; ; <xref ref-type="bibr" rid="bib77">Sokol-Hessner et al., 2015</xref>]). However, future studies could explore these exploration strategies in more detail including by reference to subjects’ own self-reports.</p><p>It is still unclear how exploration strategies are implemented neurobiologically. Noradrenaline inputs, arising from the locus coeruleus (LC; <xref ref-type="bibr" rid="bib63">Rajkowski et al., 1994</xref>) are thought to modulate exploration (<xref ref-type="bibr" rid="bib71">Schulz and Gershman, 2019</xref>; <xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib73">Servan-Schreiber et al., 1990</xref>), although empirical data on its precise mechanisms and means of action remains limited. In this study, we found that noradrenaline impacted value-free random exploration, in contrast to novelty exploration and complex exploration. This might suggest that noradrenaline influences ongoing valuation or choice processes that discards prior information. Importantly, this effect was observed whether the complex exploration was an uncertainty-driven value-based random exploration (winning model), a directed exploration with value-based random exploration (second place model) or a combination of the above (third place model; cf. Appendix 1). This is consistent with findings in rodents where enhanced anterior cingulate noradrenaline release leads to more random behaviour (<xref ref-type="bibr" rid="bib83">Tervo et al., 2014</xref>). It is also consistent with pharmacological findings in monkeys that show enhanced choice consistency after reducing LC noradrenaline firing rates (<xref ref-type="bibr" rid="bib45">Jahn et al., 2018</xref>). It would be interesting for future studies to determine, in more detail, whether value-free random exploration is corrupting a value computation itself, or whether it exclusively biases the choice process.</p><p>We note that pupil diameter has been used as an indirect marker of noradrenaline activity (<xref ref-type="bibr" rid="bib48">Joshi et al., 2016</xref>), although the link between the two it not always straightforward (<xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>). Because the effect of pharmacologically induced changes of noradrenaline levels on pupil size remains poorly understood (<xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib49">Joshi and Gold, 2020</xref>), including the fact that previous studies found no effect of propranolol on pupil diameter (<xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Koudas et al., 2009</xref>), we opted against using pupillometry in this study. However, our current findings align with previous human studies that show an association between this indirect marker and exploration, but that study did not dissociate between the different potential exploration strategies that subjects could deploy (<xref ref-type="bibr" rid="bib47">Jepma and Nieuwenhuis, 2011</xref>). Future studies might usefully include indirect measures of noradrenaline activity, for example pupillometry, to examine a potential link between natural variations in noradrenaline levels and a propensity towards value-free random exploration.</p><p>The LC has two known modes of synaptic signalling (<xref ref-type="bibr" rid="bib63">Rajkowski et al., 1994</xref>), tonic and phasic, thought to have complementary roles (<xref ref-type="bibr" rid="bib21">Dayan and Yu, 2006</xref>). Phasic noradrenaline is thought to act as a reset button (<xref ref-type="bibr" rid="bib21">Dayan and Yu, 2006</xref>), rendering an agent agnostic to all previously accumulated information, a de facto signature of value-free random exploration. Tonic noradrenaline has been associated, although not consistently (<xref ref-type="bibr" rid="bib46">Jepma et al., 2010</xref>), with increased exploration (<xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib87">Usher et al., 1999</xref>), decision noise in rats (<xref ref-type="bibr" rid="bib52">Kane et al., 2017</xref>) and more specifically with random as opposed to directed exploration strategies (<xref ref-type="bibr" rid="bib91">Warren et al., 2017</xref>). This later study unexpectedly found that boosting noradrenaline decreased (rather than increased) random exploration, which the authors speculated was due to an interplay with phasic signalling. Importantly, the drug used in that study also affects dopamine function making it difficult to assign a precise interpretation to the finding. A consideration of this study influenced our decision to opt for drugs with high specificity for either dopamine or noradrenaline (<xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>), enabling us to reveal highly specific effects on value-free random exploration. Although the contributions of tonic and phasic noradrenaline signalling cannot be disentangled in our study, our findings align with theoretical accounts and non-primate animal findings, indicating that phasic noradrenaline promotes value-free random exploration.</p><p>Aside from this ‘reset signal’ role, noradrenaline has been assigned other roles, including a role in memory function (<xref ref-type="bibr" rid="bib69">Sara et al., 1994</xref>; <xref ref-type="bibr" rid="bib66">Rossetti and Carboni, 2005</xref>; <xref ref-type="bibr" rid="bib33">Gibbs et al., 2010</xref>). To minimise a possible memory-related impact, we designed the task such that all necessary information was visible on the screen at all times. This means subjects did not have to memorise values for a given trial, rendering the task less susceptible to forgetting or other memory effects. Another role for noradrenaline relates to volatility and uncertainty estimation (<xref ref-type="bibr" rid="bib74">Silvetti et al., 2013</xref>; <xref ref-type="bibr" rid="bib100">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib59">Nassar et al., 2012</xref>), as well as the energisation of behaviour (<xref ref-type="bibr" rid="bib88">Varazzani et al., 2015</xref>; <xref ref-type="bibr" rid="bib75">Silvetti et al., 2018</xref>). Non-human primate studies demonstrate a higher LC activation for high effort choices, suggesting that noradrenaline release facilitates energy mobilisation (<xref ref-type="bibr" rid="bib88">Varazzani et al., 2015</xref>). Theoretical models also suggest that the LC is involved in the control of effort exertion. Thus, it is thought to contribute to trading off between effortful actions leading to large rewards and ‘effortless’ actions leading to small rewards by modulating ‘raw’ reward values as a function of the required effort (<xref ref-type="bibr" rid="bib75">Silvetti et al., 2018</xref>). Our task can be interpreted as encapsulating such a trade-off: complex exploration strategies are effortful but optimal in terms of reward gain, while value-free random exploration requires little effort while occasionally leading to low reward. Applying this model, a noradrenaline boost could optimise cognitive effort allocation for high reward gain (<xref ref-type="bibr" rid="bib75">Silvetti et al., 2018</xref>), thereby facilitating complex exploration strategies compared to value-free random exploration. In such a framework, blocking noradrenaline release should decrease usage of complex exploration strategies, leading to an increase of value-free random exploration which is the opposite of what we observed in our data. Another interpretation of an effort-facilitation model of noradrenaline is that a boost would help overcoming cost, that is the lack of immediate reward when selecting the low-value bandit, essentially providing a significant increase to the value of information gain. In line with our results, a decrease would interrupt this boost in valuation, removing an incentive to choose the low-value option. However, this theory is currently limited by the absence of empirical evidence for noradrenaline boosting valuation.</p><p>Noradrenaline blockade by propranolol has been shown previously to enhance metacognition (<xref ref-type="bibr" rid="bib39">Hauser et al., 2017b</xref>), decrease information gathering (<xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>), and attenuate arousal-induced boosts in incidental memory (<xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>). All these findings, including a decrease in value-free random exploration found here, suggests propranolol may influence how neural noise affects information processing. In particular, the results indicate that under propranolol behaviour is less stochastic and less influenced by ‘task-irrelevant’ distractions. This aligns with theoretical ideas, as well as recent optogenetic evidence (<xref ref-type="bibr" rid="bib83">Tervo et al., 2014</xref>), that proposes noradrenaline infuses noise in a temporally targeted way (<xref ref-type="bibr" rid="bib21">Dayan and Yu, 2006</xref>). It also accords with studies implicating noradrenaline in attention shifts (for a review <xref ref-type="bibr" rid="bib86">Trofimova and Robbins, 2016</xref>). Other gain-modulation theories of noradrenaline/catecholamine function have proposed an effect on stochasticity (<xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib73">Servan-Schreiber et al., 1990</xref>), although a hypothesised direction of effect is different (i.e. noradrenaline decreases stochasticity). Several aspects of noradrenaline functioning may explain the contradictory accounts of its link with stochasticity. For example, they might be capturing different aspects of an assumed U-shaped noradrenaline functioning curve, and/or distinct activity modes of noradrenaline (i.e. tonic and phasic firing) (<xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>). Further studies can shed light on how different modes of activity affect value-free random exploration. This idea can be extended also to tasks where propranolol has been shown to attenuate a discrimination between different levels of loss (with no effect on the value-based exploration parameter, referred to in these studies as consistency) (<xref ref-type="bibr" rid="bib65">Rogers et al., 2004</xref>) and a reduction in loss aversion (<xref ref-type="bibr" rid="bib77">Sokol-Hessner et al., 2015</xref>). This hints at additional roles for noradrenaline on prior information and task-distractibility during exploration in loss-frame environments. Future studies investigating exploration in loss contexts might provide important additional information on these questions.</p><p>It is important to mention here that β-adrenergic receptors, the primary target of propranolol, have been shown (unlike <inline-formula><mml:math id="inf90"><mml:mi>α</mml:mi></mml:math></inline-formula>-adrenergic receptors) to increase synaptic inhibition within rat cortex (<xref ref-type="bibr" rid="bib92">Waterhouse et al., 1982</xref>), specifically through inhibitory GABA-mediated transmission (<xref ref-type="bibr" rid="bib93">Waterhouse et al., 1984</xref>). Additionally β-adrenergic receptors are more concentrated in the intermediate layers in the prefrontal area (<xref ref-type="bibr" rid="bib34">Goldman-Rakic et al., 1990</xref>), within which inhibition is favoured (<xref ref-type="bibr" rid="bib44">Isaacson and Scanziani, 2011</xref>). Thus, inhibitory mechanisms might account for noradrenaline-related task-distractibility and randomness, or the role of β-adrenergic receptors in executive function impairments (<xref ref-type="bibr" rid="bib68">Salgado et al., 2016</xref>). This raises the question of whether blocking β-adrenergic receptors might lead to an accumulation of synaptic noradrenaline, and therefore act via α-adrenergic receptors. To the best of our knowledge, evidence for such an effect is limited. A second question is whether the observed effects are a pure consequence of propranolol’s impact on the brain, or whether they reflect peripheral effects of propranolol. When we examined peripheral markers (i.e. heart rate) and behaviour we found no evidence for an effect on any of our findings, rendering such influences unlikely. However, future studies using drugs that exclusively targets peripheral, but not central, noradrenaline receptors (e.g. <xref ref-type="bibr" rid="bib22">De Martino et al., 2008</xref>) are needed to answer this question conclusively.</p><p>Dopamine has been ascribed multiple functions besides reward learning (<xref ref-type="bibr" rid="bib70">Schultz et al., 1997</xref>), such as novelty seeking (<xref ref-type="bibr" rid="bib24">Düzel et al., 2010</xref>; <xref ref-type="bibr" rid="bib98">Wittmann et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Costa et al., 2014</xref>) or exploration in general (<xref ref-type="bibr" rid="bib27">Frank et al., 2009</xref>). In fact, studies have demonstrated that there are different types of dopaminergic neurons in the ventral tegmental area, and that some contribute to non-reward signals, such as saliency and novelty (<xref ref-type="bibr" rid="bib8">Bromberg-Martin et al., 2010</xref>). This suggests a role in novelty exploration. Moreover, dopamine has been suggested as important in an exploration-exploitation arbitration (<xref ref-type="bibr" rid="bib101">Zajkowski et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Kayser et al., 2015</xref>; <xref ref-type="bibr" rid="bib12">Chakroun et al., 2019</xref>), although its precise role remains unclear, given reported effects on random exploration (<xref ref-type="bibr" rid="bib13">Cinotti et al., 2019</xref>), on directed exploration (<xref ref-type="bibr" rid="bib17">Costa et al., 2014</xref>; <xref ref-type="bibr" rid="bib27">Frank et al., 2009</xref>), or no effects at all (<xref ref-type="bibr" rid="bib57">Krugel et al., 2009</xref>). A recent study found no effect following dopamine blockade using haloperidol (<xref ref-type="bibr" rid="bib12">Chakroun et al., 2019</xref>), which interestingly also affects noradrenaline function (e.g. <xref ref-type="bibr" rid="bib25">Fang and Yu, 1995</xref>; <xref ref-type="bibr" rid="bib85">Toru and Takashima, 1985</xref>). Our results did not demonstrate any main effect of dopamine manipulation on exploration strategies, even though blocking dopamine was associated with a trend level increase in exploitation (cf. Appendix 1). We believe it unlikely this reflects an ineffective drug dose as previous studies have found neurocognitive effects with the same dose (<xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Kahnt et al., 2015</xref>; <xref ref-type="bibr" rid="bib51">Kahnt and Tobler, 2017</xref>).</p><p>One possible reason for an absence of significant findings is that our dopaminergic blockade targets D2/D3 receptors rather than D1 receptors, a limitation due a lack of available specific D1 receptor blockers for use in humans. An expectation of greater D1 involvement arises out of theoretical models (<xref ref-type="bibr" rid="bib42">Humphries et al., 2012</xref>) and a prefrontal hypothesis of exploration (<xref ref-type="bibr" rid="bib27">Frank et al., 2009</xref>). Interestingly, we observed a weak gender-specific differential drug effect on subjects’ uncertainty about an expected reward, with women being more uncertain than men in the placebo setting, but more certain in the dopamine blockade setting (cf. Appendix 1). This might be meaningful as other studies using the same drug have also found behavioural gender-specific drug effects (<xref ref-type="bibr" rid="bib78">Soutschek et al., 2017</xref>). Upcoming, novel drugs (<xref ref-type="bibr" rid="bib79">Soutschek et al., 2020</xref>) might be able help unravel a D1 contribution to different forms of exploration. Additionally, future studies could use approved D2/D3 agonists (e.g. ropinirole) in a similar design to probe further whether enhancing dopamine leads to a general increase in exploration.</p><p>In conclusion, humans supplement computationally expensive exploration strategies with less resource demanding exploration heuristics, and as shown here the latter include value-free random and novelty exploration. Our finding that noradrenaline specifically influences value-free random exploration demonstrates that distinct exploration strategies may be under specific neuromodulator influence. Our current findings may also be relevant to enabling a richer understanding of disorders of exploration, such as attention-deficit/hyperactivity disorder (<xref ref-type="bibr" rid="bib37">Hauser et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Hauser et al., 2014</xref>) including how aberrant catecholamine function might contribute to its core behavioural impairments.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects</title><p>Sixty healthy volunteers aged 18–35 (mean = 23.22, SD = 3.615) participated in a double-blind, placebo-controlled, between-subjects study. The sample size was determined using power calculations taking effect sizes from our prior studies that used the same drug manipulations (<xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib39">Hauser et al., 2017b</xref>). Each subject was randomly allocated to one of three drug groups, controlling for an equal gender balance across all groups (cf. Appendix 1). Candidate subjects with a history of neurological or psychiatric disorders, current health issues, regular medications (except contraceptives), or prior allergic reactions to drugs were excluded from the study. Subjects had (self-reported) normal or corrected-to-normal vision. The groups consisted of 20 subjects each matched (<xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>) for gender and age. To evaluate peripheral drug effects, heart rate, systolic and diastolic blood pressure were collected at three different time-points: ‘at arrival’, ‘pre-task’ and ‘post-task’, cf. Appendix 1 for details. At 50 min after administrating the second drug, subjects were filled in the PANAS questionnaires (<xref ref-type="bibr" rid="bib94">Watson et al., 1988a</xref>) and completed the WASI Matrix Reasoning subtest (<xref ref-type="bibr" rid="bib96">Wechsler, 2013</xref>). Groups differed in mood (PANAS negative affect, cf. Appendix 1 for details) and marginally in intellectual abilities (WASI), and so we control for these potential confounders in our analyses (cf. Appendix 1 for uncorrected results). Subjects were reimbursed for their participation on an hourly basis and received a bonus according to their performance (proportional to the sum of all the collected apples’ sizes). One subject from the amisulpride group was excluded due to not engaging in the task and performing at chance level. The study was approved by the UCL research ethics committee and all subjects provided written informed consent.</p></sec><sec id="s4-2"><title>Pharmacological manipulation</title><p>To reduce noradrenaline functioning, we administered 40 mg of the non-selective β-adrenoceptor antagonist propranolol 60 min before the task (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). To reduce dopamine functioning, we administered 400 mg of the selective D2/D3 antagonist amisulpride 90 min before the task. Because of different pharmacokinetic properties, drugs were administered at different times. Each drug group received the drug on its corresponding time point and a placebo at the other time point. The placebo group received placebo at both time points, in line with our previous studies (<xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib39">Hauser et al., 2017b</xref>).</p></sec><sec id="s4-3"><title>Experimental paradigm</title><p>To quantify different exploration strategies, we developed a multi-armed bandit task implemented using Cogent (<ext-link ext-link-type="uri" xlink:href="http://www.vislab.ucl.ac.uk/cogent.php">http://www.vislab.ucl.ac.uk/cogent.php</ext-link>) for MATLAB (R2018a). Subjects had to choose between bandits (i.e. trees) that produced samples (i.e. apples) with varying reward (i.e. size) in two different horizon conditions (<xref ref-type="fig" rid="fig1">Figure 1a–b</xref>). Bandits were displayed during the entire duration of a trial and there was no time limit for sampling from (choosing) the bandits. The sizes of apples they collected were summed and converted to an amount of juice (feedback), which was displayed during 2000 ms at the end of each trial. Subjects were instructed to endeavour to make the most juice and that they would receive a cash bonus proportional to their performance. Overall subjects received £10/hr and a mean bonus of £1.12 (std: £0.06).</p><p>Similar to the horizon task (<xref ref-type="bibr" rid="bib97">Wilson et al., 2014</xref>), to induce different extents of exploration, we manipulated the horizon (i.e. number of apples to be picked: one in the short horizon, six in the long horizon) between trials. This horizon-manipulation, which has been extensively used to modulate exploratory behaviour (<xref ref-type="bibr" rid="bib101">Zajkowski et al., 2017</xref>; <xref ref-type="bibr" rid="bib91">Warren et al., 2017</xref>; <xref ref-type="bibr" rid="bib99">Wu et al., 2018</xref>; <xref ref-type="bibr" rid="bib35">Guo and Yu, 2018</xref>), promotes exploration in the long horizon condition as there are more opportunities to gather reward.</p><p>Within a single trial, each bandit had a different mean reward µ (i.e. apple size) and associated uncertainty as captured by the number of initial samples (i.e. number of apples shown at the beginning of the trial). Each bandit (i.e. tree) <inline-formula><mml:math id="inf91"><mml:mi>i</mml:mi></mml:math></inline-formula> was from one of four generative processes (<xref ref-type="fig" rid="fig1">Figure 1c</xref>) characterised by different means <inline-formula><mml:math id="inf92"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and number of initial samples. The rewards (apple sizes) for each bandit were sampled from a normal distribution with mean <inline-formula><mml:math id="inf93"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, specific to the bandit, and with a fixed variance, <inline-formula><mml:math id="inf94"><mml:msup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.8. The rewards were those sampled values rounded to the closest integer. Each distribution was truncated to [2, 10], meaning that rewards with values above or below this interval were excluded, resulting in a total of 9 possible rewards (i.e. 9 different apple sizes; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for a representation). The ‘certain standard bandit’ provided three initial samples and on every trial its mean <inline-formula><mml:math id="inf95"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was sampled from a normal distribution: <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub> <mml:mi/><mml:mo>~</mml:mo> <mml:mi/><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>5.5</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>1.4</mml:mn></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></inline-formula> The ‘standard bandit’ provided one initial sample and to make sure that its mean <inline-formula><mml:math id="inf97"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was comparable to <inline-formula><mml:math id="inf98"> <mml:mi/><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the trials were split equally between the four following: <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. The ‘novel bandit’ provided no initial samples and its mean <inline-formula><mml:math id="inf100"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was comparable to both <inline-formula><mml:math id="inf101"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf102"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> by splitting the trials equally between the eight following:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mspace linebreak="newline"/><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The ‘low bandit’ provided one initial sample which was smaller than all the other bandits’ means on that trial: <inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo></mml:math></inline-formula> We ensured that the initial sample from the low-value bandit was the smallest by resampling from each bandit in the trials were that was not the case. To make sure that our task captures heuristic exploration strategies, we simulated behaviour (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Additionally, in each trial, to avoid that some exploration strategies overshadow other ones, only three of the four different groups were available to choose from. Based on the mean of the initial samples, we identified the high-value option (i.e. the bandit with the highest expected reward) in trials where both the certain-standard and the standard bandit were present.</p><p>There were 25 trials of each of the four three-bandit combination making it a total of 100 different trials. They were then duplicated to measure choice consistency, defined as the frequency of making the same choice on identical trials (in contrast to a previous propranolol study where consistency was defined in terms of a value-based exploration parameter [<xref ref-type="bibr" rid="bib77">Sokol-Hessner et al., 2015</xref>]). Each subject played these 200 trials both in a short and in a long horizon settings, resulting in a total of 400 trials. The trials were randomly assigned to one of four blocks and subjects were given a short break at the end of each of them. To prevent learning, the bandits’ positions (left, middle or right) as well as their colour (eight sets of three different colours) where shuffled between trials. To ensure subjects distinguished different apple sizes and understood that apples from the same tree were always of similar size (generated following a normal distribution), they needed to undergo training prior to the main experiment. In training, based on three displayed apples of similar size, they were tasked to guess between two options, namely which apple was most likely to come from the same tree and then received feedback about their choice.</p></sec><sec id="s4-4"><title>Statistical analyses</title><p>All statistical analyses were performed using the R Statistical Software (<xref ref-type="bibr" rid="bib62">R Development Core Team, 2011</xref>). For computing ANOVA tests and pairwise comparisons the ‘rstatix’ package was used, and for computing effect sizes the ‘lsr’ package (<xref ref-type="bibr" rid="bib60">Navarro, 2015</xref>) was used. To ensure consistent performance across all subjects, we excluded one outlier subject (belonging to the amisulpride group) from our analysis due to not engaging in the task and performing at chance level (defined as randomly sampling from one out of three bandits, that is 33%). Each bandit's selection frequency for a horizon condition was computed over all 200 trials and not only over the trials where this specific bandit was present (i.e. 3/4 of 200 = 150 trials). In all the analysis comparing horizon conditions, except when looking at score values (<xref ref-type="fig" rid="fig2">Figure 2c</xref>), only the first draw of the long horizon was used. We compared behavioural measures and model parameters using (paired-samples) t-tests and repeated-measures (rm-) ANOVAs with a between-subject factor of drug group (propranolol group, amisulpride group, placebo group) and a within-subject factor horizon (long, short). Information seeking, expected values and scores were analysed using rm-ANOVAs with a within-subject factor horizon. Measures that were horizon-independent (e.g. prior mean), were analysed using one-way ANOVAs with a between-subject factor drug group. As drug groups differed in negative affect (<xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>), which, through its relationship to anxiety (<xref ref-type="bibr" rid="bib95">Watson et al., 1988b</xref>) is thought to affect cognition (<xref ref-type="bibr" rid="bib5">Bishop and Gagne, 2018</xref>) and potentially exploration (<xref ref-type="bibr" rid="bib23">de Visser et al., 2010</xref>). We corrected for negative affect (PANAS) and IQ (WASI) in each analysis by adding those two measures as covariates in each ANOVA mentioned above (cf. Appendix 1 for analysis without covariates and analysis with physiological effect as an additional covariates). We report effect sizes using partial eta squared (<inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) for ANOVAs and Cohen’s d (d) for t-tests (<xref ref-type="bibr" rid="bib64">Richardson, 2011</xref>).</p></sec><sec id="s4-5"><title>Computational modelling</title><p>We adapted a set of Bayesian generative models from previous studies (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>), where each model assumed that different characteristics account for subjects’ behaviour. The binary indicators <inline-formula><mml:math id="inf105"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> indicate which components (value-free random and novelty exploration respectively) were included in the different models. The value of each bandit is represented as a distribution <inline-formula><mml:math id="inf106"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> with <inline-formula><mml:math id="inf107"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:math></inline-formula>, the sampling variance fixed to its generative value. Subjects have prior beliefs about bandits’ values which we assume to be Gaussian with mean <inline-formula><mml:math id="inf108"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and uncertainty <inline-formula><mml:math id="inf109"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. The subject's initial estimate of a bandit’s mean (<inline-formula><mml:math id="inf110"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>; prior mean) and its uncertainty about it (<inline-formula><mml:math id="inf111"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>; prior variance) are free parameters.</p><p>These beliefs are updated according to Bayes rule (detailed below) for each initial sample (note that there are no updates for the novel bandit).</p></sec><sec id="s4-6"><title>Mean and variance update rules</title><p>At each time point <inline-formula><mml:math id="inf112"> <mml:mi/><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> in which a sample <inline-formula><mml:math id="inf113"><mml:mi>m</mml:mi></mml:math></inline-formula>, of one of the bandits is presented, the expected mean <inline-formula><mml:math id="inf114"><mml:mi>Q</mml:mi></mml:math></inline-formula> and precision <inline-formula><mml:math id="inf115"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mi/></mml:math></inline-formula> of the corresponding bandit <inline-formula><mml:math id="inf116"><mml:mi>i</mml:mi></mml:math></inline-formula> are updated as follows:<disp-formula id="equ2"><mml:math id="m2"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>*</mml:mi> <mml:mi/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>*</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:msubsup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo> <mml:mi/><mml:msubsup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></disp-formula>where <inline-formula><mml:math id="inf117"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mi/></mml:math></inline-formula> is the sampling precision, with the sampling variance <inline-formula><mml:math id="inf118"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:math></inline-formula> fixed. Those update rules are equivalent to using a Kalman filter (<xref ref-type="bibr" rid="bib4">Bishop, 2006</xref>) in stationary bandits.</p><p>We examined three base models: the UCB model, the Thompson model,and the hybrid model. The UCB model encompasses the UCB algorithm (captures directed exploration) and a softmax choice function (captures a value-based random exploration). The Thompson model reflects Thompson sampling (captures an uncertainty-driven value-based random exploration). The hybrid model captures the contribution of the UCB model and the Thompson model, essentially a mixture of the above. We computed three extensions of each model by either adding value-free random exploration <inline-formula><mml:math id="inf119"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>1,0</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula>, novelty exploration <inline-formula><mml:math id="inf120"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> or both heuristics <inline-formula><mml:math id="inf121"> <mml:mi/><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1,1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>, leading to a total of 12 models (see the labels on the x-axis in <xref ref-type="fig" rid="fig4">Figure 4a</xref>; <inline-formula><mml:math id="inf122"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>0,0</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> is the model with no extension). For additional models cf. Appendix 1. A coefficient <inline-formula><mml:math id="inf123"><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=1 indicates that an <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-greedy component was added to the decision rule, ensuring that once in a while (every <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> % of the time), another option than the predicted one is selected. A coefficient <inline-formula><mml:math id="inf126"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=1 indicates that the novelty bonus <inline-formula><mml:math id="inf127"><mml:mi>η</mml:mi></mml:math></inline-formula> is added to the computation of the value of novel bandits and the Kronecker delta δ in front of this bonus ensures that it is only applied to the novel bandit. The models and their free parameters (summarised in <xref ref-type="table" rid="app2table5">Appendix 2—table 5</xref>) are described in detail below.</p></sec><sec id="s4-7"><title>Choice rules</title><sec id="s4-7-1"><title>UCB model</title><p>In this model, an information bonus <inline-formula><mml:math id="inf128"><mml:mi>γ</mml:mi></mml:math></inline-formula> is added to the expected reward of each option, scaling with the option’s uncertainty (UCB). The value of each band it <inline-formula><mml:math id="inf129"><mml:mi>i</mml:mi></mml:math></inline-formula> at timepoint <italic>t</italic> is:<disp-formula id="equ4"><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub></mml:math></disp-formula></p><p>The probability of choosing bandit <inline-formula><mml:math id="inf130"><mml:mi>i</mml:mi></mml:math></inline-formula> was given by passing this into the softmax decision function:<disp-formula id="equ5"><mml:math id="m5"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mi>*</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula><mml:math id="inf131"> <mml:mi/><mml:mi>β</mml:mi></mml:math></inline-formula> is the inverse temperature of the softmax (lower values producing more value-based random exploration), and the coefficient <inline-formula><mml:math id="inf132"><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> adds the value-free random exploration component.</p></sec><sec id="s4-7-2"><title>Thompson model</title><p>In this model, based on Thompson sampling, the overall uncertainty can be seen as a more refined version of a decision temperature (<xref ref-type="bibr" rid="bib31">Gershman, 2018</xref>). The value of each band it <inline-formula><mml:math id="inf133"><mml:mi>i</mml:mi></mml:math></inline-formula> is as before:<disp-formula id="equ6"><mml:math id="m6"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub></mml:math></disp-formula></p><p>A sample <inline-formula><mml:math id="inf134"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo> <mml:mi/><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></inline-formula> is taken from each bandit. The probability of choosing a bandit <inline-formula><mml:math id="inf135"><mml:mi>i</mml:mi></mml:math></inline-formula> depends on the probability that all pairwise differences between the sample from bandit <inline-formula><mml:math id="inf136"><mml:mi>i</mml:mi></mml:math></inline-formula> and the other bandits <inline-formula><mml:math id="inf137"><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:math></inline-formula> were greater or equal to 0 (see the probability of maximum utility choice rule [<xref ref-type="bibr" rid="bib80">Speekenbrink and Konstantinidis, 2015</xref>]). In our task, because three bandits were present, two pairwise differences scores (contained in the two-dimensional vector u) were computed for each bandit. The probability of choosing bandit <inline-formula><mml:math id="inf138"> <mml:mi/><mml:mi>i</mml:mi></mml:math></inline-formula> is:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>j</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo>;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mi>ϵ</mml:mi><mml:mn>3</mml:mn></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ8"><mml:math id="m8"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>ɸ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced> <mml:mi/><mml:mi>d</mml:mi><mml:mi>u</mml:mi> <mml:mi/></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mi>*</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula><mml:math id="inf139"><mml:mi>ɸ</mml:mi></mml:math></inline-formula> is the multivariate Normal density function with mean vector.</p><p><inline-formula><mml:math id="inf140"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced> <mml:mi/></mml:math></inline-formula> and covariance matrix<disp-formula id="equ9"><mml:math id="m9"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mi/></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:msubsup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup> <mml:mi/></mml:math></disp-formula></p><p>Where the matrix <inline-formula><mml:math id="inf141"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> computes the pairwise differences between bandit <inline-formula><mml:math id="inf142"><mml:mi>i</mml:mi></mml:math></inline-formula> and the other bandits. For example, for band it <inline-formula><mml:math id="inf143"> <mml:mi/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>:<disp-formula id="equ10"><mml:math id="m10"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula></p></sec><sec id="s4-7-3"><title>Hybrid model</title><p>This model allows a combination of the UCB model and the Thompson model. The probability of choosing bandit <inline-formula><mml:math id="inf144"> <mml:mi/><mml:mi>i</mml:mi></mml:math></inline-formula> is:<disp-formula id="equ11"><mml:math id="m11"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>w</mml:mi><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mi>C</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>*</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>ϵ</mml:mi> <mml:mi/></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac> <mml:mi/></mml:math></disp-formula>where <inline-formula><mml:math id="inf145"><mml:mi>w</mml:mi> <mml:mi/></mml:math></inline-formula> specifies the contribution of each of the two models. <inline-formula><mml:math id="inf146"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mi>C</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf147"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are calculated for <inline-formula><mml:math id="inf148"><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=0. If <inline-formula><mml:math id="inf149"><mml:mi>w</mml:mi></mml:math></inline-formula>=1, only the UCB model is used while if <inline-formula><mml:math id="inf150"><mml:mi>w</mml:mi></mml:math></inline-formula>=0 only the Thompson model is used. In between values indicate a mixture of the two models.</p><p>All the parameters besides <inline-formula><mml:math id="inf151"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf152"><mml:mi>w</mml:mi></mml:math></inline-formula> were free to vary as a function of the horizon (<xref ref-type="table" rid="app2table5">Appendix 2—table 5</xref>) as they capture different exploration forms: directed exploration (information bonus <inline-formula><mml:math id="inf153"><mml:mi>γ</mml:mi></mml:math></inline-formula>; UCB model), novelty exploration (novelty bonus <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), value-based random exploration (inverse temperature <inline-formula><mml:math id="inf155"><mml:mi>β</mml:mi></mml:math></inline-formula>; UCB model), uncertainty-directed exploration (prior variance <inline-formula><mml:math id="inf156"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>; Thompson model), and value-free random exploration (<inline-formula><mml:math id="inf157"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter). The prior mean <inline-formula><mml:math id="inf158"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> was fitted to both horizons together as we do not expect the belief of how good a bandit is to depend on the horizon. The same was done for <inline-formula><mml:math id="inf159"><mml:mi>w</mml:mi></mml:math></inline-formula> as assume the arbitration between the UCB model and the Thompson model does not depend on horizon.</p></sec></sec><sec id="s4-8"><title>Parameter estimation</title><p>To fit the parameter values, we used the maximum a posteriori probability (MAP) estimate. The optimisation function used was fmincon in MATLAB. The parameters could vary within the following bounds:<inline-formula><mml:math id="inf160"><mml:msub><mml:mrow> <mml:mi/><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>6</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>10</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo> <mml:mi/><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>0.5</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo> <mml:mi/><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>5</mml:mn><mml:mo>]</mml:mo></mml:math></inline-formula>. The prior distribution used for the prior mean parameter <inline-formula><mml:math id="inf161"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> was the normal distribution: <inline-formula><mml:math id="inf162"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub> <mml:mi/><mml:mo>~</mml:mo> <mml:mi/><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> that approximates the generative distributions. For the <inline-formula><mml:math id="inf163"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter, the novelty bonus <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and the prior variance parameter <inline-formula><mml:math id="inf165"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, a uniform distribution (of range equal to the specific parameters’ bounds) was used, which is equivalent to performing MLE. A summary of the parameter values per group and per horizon can be found in <xref ref-type="table" rid="app2table6">Appendix 2—table 6</xref>.</p></sec><sec id="s4-9"><title>Model comparison</title><p>We performed a K-fold cross-validation with <inline-formula><mml:math id="inf166"> <mml:mi/><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula>. We partitioned the data of each subject (<inline-formula><mml:math id="inf167"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:math></inline-formula> 400; 200 in each horizon) into K folds (i.e. subsamples). For model fitting in our model selection, we used maximum likelihood estimation (MLE), where we maximised the likelihood for each subject individually (fmincon was ran with eight randomly chosen starting point to overcome potential local minima). We fitted the model using K-1 folds and validated the model on the remaining fold. We repeated this process K times, so that each of the K fold is used as a validation set once, and averaged the likelihood over held out trials. We did this for each model and each subject and averaged across subjects. The model with the highest likelihood of held-out data (the winning model) was the Thompson sampling with <inline-formula><mml:math id="inf168"> <mml:mi/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1,1</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula>. It was also the model which accounted best for the largest number of subjects (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p></sec><sec id="s4-10"><title>Parameter recovery</title><p>To make sure that the parameters are interpretable, we performed a parameter recovery analysis. For each parameter, we took four values, equally spread, within a reasonable parameter range (<inline-formula><mml:math id="inf169"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>2.5</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>6</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo> <mml:mi/><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>0.5</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo> <mml:mi/><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mn>5</mml:mn><mml:mo>]</mml:mo></mml:math></inline-formula>). All parameters but <inline-formula><mml:math id="inf170"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> were free to vary as a function of the horizon. We simulated behaviour with one artificial agent for each 4<sup>7</sup> combinations using a new trial for each. The model was fitted using MAP estimation (cf. Parameter estimation) and analysed how well the generative parameters (generating parameters in <xref ref-type="fig" rid="fig5">Figure 5</xref>) correlated with the recovered ones (fitted parameters in <xref ref-type="fig" rid="fig5">Figure 5</xref>) using Pearson correlation (summarised in <xref ref-type="fig" rid="fig5">Figure 5c</xref>). In addition to the correlation we examined the spread (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>) of the recovered parameters. Overall the parameters were well recoverable.</p></sec><sec id="s4-11"><title>Model validation</title><p>To validate our model, we used each subjects’ fitted parameters to simulate behaviour on our task (4000 trials per agent). The stimulated data (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>), although not perfect, resembles the real data reasonably well. Additionally, to validate the behavioural indicators of the two different exploration heuristics we stimulated the behaviour of 200 agents using the winning model on one horizon condition (i.e. trials = 200). For the indicators of value-free random exploration, we stimulated behaviour with low (<inline-formula><mml:math id="inf171"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>) and high (<inline-formula><mml:math id="inf172"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:math></inline-formula>) values of the <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-greedy parameter. The other parameters were set to the mean parameter fits (<inline-formula><mml:math id="inf174"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.312</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>2.625</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3.2</mml:mn></mml:math></inline-formula>). This confirms that higher amounts of value-free random exploration are captured by the proportion of low-value bandit selection (<xref ref-type="fig" rid="fig1">Figure 1f</xref>) and the choice consistency (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). Similarly, for the indicator of novelty exploration, we simulated behaviour with low (<inline-formula><mml:math id="inf175"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>) and high (<inline-formula><mml:math id="inf176"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula>) values of the novelty bonus <inline-formula><mml:math id="inf177"><mml:mi>η</mml:mi></mml:math></inline-formula> to validate the use of the proportion of the novel-bandit selection (<xref ref-type="fig" rid="fig1">Figure 1g</xref>). Again, the remaining parameters were set to the mean parameter fits (<inline-formula><mml:math id="inf178"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.312</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3.2</mml:mn></mml:math></inline-formula>). Parameter values for high and low exploration were selected empirically from pilot and task data. Additionally, we simulated the effects of other exploration strategies in short and long horizon conditions (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>–<xref ref-type="fig" rid="fig1s5">5</xref>). To simulate a long (versus short) horizon condition,we increased the overall exploration by increasing other exploration strategies. Details about parameter values can be found in <xref ref-type="table" rid="app2table7">Appendix 2—table 7</xref>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>MD is a predoctoral fellow of the International Max Planck Research School on Computational Methods in Psychiatry and Ageing Research. The participating institutions are the Max Planck Institute for Human Development and the University College London (UCL). TUH is supported by a Wellcome Sir Henry Dale Fellowship (211155/Z/18/Z), a grant from the Jacobs Foundation (2017-1261-04), the Medical Research Foundation, a 2018 NARSAD Young Investigator Grant (27023) from the Brain and Behavior Research Foundation, and an ERC Starting Grant (946055). RJD holds a Wellcome Trust Investigator Award (098362/Z/12/Z). The Max Planck UCL Centre is a joint initiative supported by UCL and the Max Planck Society. The Wellcome Centre for Human Neuroimaging is supported by core funding from the Wellcome Trust (203147/Z/16/Z).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Funding acquisition, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Software, Formal analysis, Supervision, Writing - original draft, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Human subjects: The study was approved by the UCL research committee (REC No 6218/002) and all subjects provided written informed consent.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-59907-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All necessary resources are publicly available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/MagDub/MFNADA-figures">https://github.com/MagDub/MFNADA-figures</ext-link>.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agrawal</surname> <given-names>S</given-names></name><name><surname>Goyal</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Analysis of Thompson sampling for the multi-armed bandit problem</article-title><source>Journal of Machine Learning Research : JMLR</source><volume>23</volume><fpage>1</fpage><lpage>26</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname> <given-names>G</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auer</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Using confidence bounds for exploitation-exploration trade-offs</article-title><source>Journal of Machine Learning Research : JMLR</source><volume>3</volume><fpage>397</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1162/153244303321897663</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bishop</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>in Information Science and Statistics</source></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname> <given-names>SJ</given-names></name><name><surname>Gagne</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Anxiety, depression, and decision making: a computational perspective</article-title><source>Annual Review of Neuroscience</source><volume>41</volume><fpage>371</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-062007</pub-id><pub-id pub-id-type="pmid">29709209</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname> <given-names>M</given-names></name><name><surname>Braver</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Motivation and cognitive control: from behavior to neural mechanism</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>83</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015044</pub-id><pub-id pub-id-type="pmid">25251491</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouret</surname> <given-names>S</given-names></name><name><surname>Sara</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Network reset: a simplified overarching theory of locus coeruleus noradrenaline function</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>574</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2005.09.002</pub-id><pub-id pub-id-type="pmid">16165227</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bromberg-Martin</surname> <given-names>ES</given-names></name><name><surname>Matsumoto</surname> <given-names>M</given-names></name><name><surname>Hikosaka</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dopamine in motivational control: rewarding, aversive, and alerting</article-title><source>Neuron</source><volume>68</volume><fpage>815</fpage><lpage>834</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.11.022</pub-id><pub-id pub-id-type="pmid">21144997</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bunzeck</surname> <given-names>N</given-names></name><name><surname>Doeller</surname> <given-names>CF</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Duzel</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Contextual interaction between novelty and reward processing within the mesolimbic system</article-title><source>Human Brain Mapping</source><volume>33</volume><fpage>1309</fpage><lpage>1324</lpage><pub-id pub-id-type="doi">10.1002/hbm.21288</pub-id><pub-id pub-id-type="pmid">21520353</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell-Meiklejohn</surname> <given-names>D</given-names></name><name><surname>Wakeley</surname> <given-names>J</given-names></name><name><surname>Herbert</surname> <given-names>V</given-names></name><name><surname>Cook</surname> <given-names>J</given-names></name><name><surname>Scollo</surname> <given-names>P</given-names></name><name><surname>Ray</surname> <given-names>MK</given-names></name><name><surname>Selvaraj</surname> <given-names>S</given-names></name><name><surname>Passingham</surname> <given-names>RE</given-names></name><name><surname>Cowen</surname> <given-names>P</given-names></name><name><surname>Rogers</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Serotonin and dopamine play complementary roles in gambling to recover losses</article-title><source>Neuropsychopharmacology</source><volume>36</volume><fpage>402</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1038/npp.2010.170</pub-id><pub-id pub-id-type="pmid">20980990</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Carpentier</surname> <given-names>A</given-names></name><name><surname>Lazaric</surname> <given-names>A</given-names></name><name><surname>Ghavamzadeh</surname> <given-names>M</given-names></name><name><surname>Munos</surname> <given-names>R</given-names></name><name><surname>Auer</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Upper-confidence-bound algorithms for active learning in multi-armed bandits</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1507.04523">https://arxiv.org/abs/1507.04523</ext-link></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chakroun</surname> <given-names>K</given-names></name><name><surname>Mathar</surname> <given-names>D</given-names></name><name><surname>Wiehler</surname> <given-names>A</given-names></name><name><surname>Ganzer</surname> <given-names>F</given-names></name><name><surname>Peters</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dopaminergic modulation of the exploration/exploitation trade-off in human decision-making</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/706176</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cinotti</surname> <given-names>F</given-names></name><name><surname>Fresno</surname> <given-names>V</given-names></name><name><surname>Aklil</surname> <given-names>N</given-names></name><name><surname>Coutureau</surname> <given-names>E</given-names></name><name><surname>Girard</surname> <given-names>B</given-names></name><name><surname>Marchand</surname> <given-names>AR</given-names></name><name><surname>Khamassi</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dopamine blockade impairs the exploration-exploitation trade-off in rats</article-title><source>Scientific Reports</source><volume>9</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1038/s41598-019-43245-z</pub-id><pub-id pub-id-type="pmid">31043685</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cogliati Dezza</surname> <given-names>I</given-names></name><name><surname>Cleeremans</surname> <given-names>A</given-names></name><name><surname>Alexander</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Should we control? the interplay between cognitive control and information integration in the resolution of the exploration-exploitation dilemma</article-title><source>Journal of Experimental Psychology: General</source><volume>148</volume><fpage>977</fpage><lpage>993</lpage><pub-id pub-id-type="doi">10.1037/xge0000546</pub-id><pub-id pub-id-type="pmid">30667262</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>McClure</surname> <given-names>SM</given-names></name><name><surname>Yu</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Should I stay or should I go? how the human brain manages the trade-off between exploitation and exploration</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>362</volume><fpage>933</fpage><lpage>942</lpage><pub-id pub-id-type="doi">10.1098/rstb.2007.2098</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cost of dopamine for dynamic cognitive control</article-title><source>Current Opinion in Behavioral Sciences</source><volume>4</volume><fpage>152</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2015.05.007</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname> <given-names>VD</given-names></name><name><surname>Tran</surname> <given-names>VL</given-names></name><name><surname>Turchi</surname> <given-names>J</given-names></name><name><surname>Averbeck</surname> <given-names>BB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dopamine modulates novelty seeking behavior during decision making</article-title><source>Behavioral Neuroscience</source><volume>128</volume><fpage>556</fpage><lpage>566</lpage><pub-id pub-id-type="doi">10.1037/a0037128</pub-id><pub-id pub-id-type="pmid">24911320</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Acremont</surname> <given-names>M</given-names></name><name><surname>Bossaerts</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neurobiological studies of risk assessment: a comparison of expected utility and mean-variance approaches</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>8</volume><fpage>363</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.3758/CABN.8.4.363</pub-id><pub-id pub-id-type="pmid">19033235</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David Johnson</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Noradrenergic control of cognition: global attenuation and an interrupt function</article-title><source>Medical Hypotheses</source><volume>60</volume><fpage>689</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/S0306-9877(03)00021-5</pub-id><pub-id pub-id-type="pmid">12710903</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nature04766</pub-id><pub-id pub-id-type="pmid">16778890</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Yu</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Phasic norepinephrine: a neural interrupt signal for unexpected events</article-title><source>Network: Computation in Neural Systems</source><volume>17</volume><fpage>335</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1080/09548980601004024</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname> <given-names>B</given-names></name><name><surname>Strange</surname> <given-names>BA</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Noradrenergic neuromodulation of human attention for emotional and neutral stimuli</article-title><source>Psychopharmacology</source><volume>197</volume><fpage>127</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1007/s00213-007-1015-5</pub-id><pub-id pub-id-type="pmid">18046544</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Visser</surname> <given-names>L</given-names></name><name><surname>van der Knaap</surname> <given-names>LJ</given-names></name><name><surname>van de Loo</surname> <given-names>AJ</given-names></name><name><surname>van der Weerd</surname> <given-names>CM</given-names></name><name><surname>Ohl</surname> <given-names>F</given-names></name><name><surname>van den Bos</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Trait anxiety affects decision-making differently in healthy men and women: towards gender-specific endophenotypes of anxiety</article-title><source>Neuropsychologia</source><volume>48</volume><fpage>1598</fpage><lpage>1606</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.01.027</pub-id><pub-id pub-id-type="pmid">20138896</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Düzel</surname> <given-names>E</given-names></name><name><surname>Penny</surname> <given-names>WD</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Brain oscillations and memory</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>143</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.01.004</pub-id><pub-id pub-id-type="pmid">20181475</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname> <given-names>J</given-names></name><name><surname>Yu</surname> <given-names>PH</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Effect of haloperidol and its metabolites on dopamine and noradrenaline uptake in rat brain slices</article-title><source>Psychopharmacology</source><volume>121</volume><fpage>379</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1007/BF02246078</pub-id><pub-id pub-id-type="pmid">8584621</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foley</surname> <given-names>NC</given-names></name><name><surname>Jangraw</surname> <given-names>DC</given-names></name><name><surname>Peck</surname> <given-names>C</given-names></name><name><surname>Gottlieb</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Novelty enhances visual salience independently of reward in the parietal lobe</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>7947</fpage><lpage>7957</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4171-13.2014</pub-id><pub-id pub-id-type="pmid">24899716</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Doll</surname> <given-names>BB</given-names></name><name><surname>Oas-Terpstra</surname> <given-names>J</given-names></name><name><surname>Moreno</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1062</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1038/nn.2342</pub-id><pub-id pub-id-type="pmid">19620978</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fraundorfer</surname> <given-names>PF</given-names></name><name><surname>Fertel</surname> <given-names>RH</given-names></name><name><surname>Miller</surname> <given-names>DD</given-names></name><name><surname>Feller</surname> <given-names>DR</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Biochemical and pharmacological characterization of high-affinity trimetoquinol analogs on guinea pig and human beta adrenergic receptor subtypes: evidence for partial agonism</article-title><source>The Journal of Pharmacology and Experimental Therapeutics</source><volume>270</volume><fpage>665</fpage><lpage>674</lpage><pub-id pub-id-type="pmid">7915318</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Froböse</surname> <given-names>MI</given-names></name><name><surname>Westbrook</surname> <given-names>A</given-names></name><name><surname>Bloemendaal</surname> <given-names>M</given-names></name><name><surname>Aarts</surname> <given-names>E</given-names></name><name><surname>Cools</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Catecholaminergic modulation of the cost of cognitive control in healthy older adults</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0229294</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0229294</pub-id><pub-id pub-id-type="pmid">32084218</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Froböse</surname> <given-names>MI</given-names></name><name><surname>Cools</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Chemical neuromodulation of cognitive control avoidance</article-title><source>Current Opinion in Behavioral Sciences</source><volume>22</volume><fpage>121</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2018.01.027</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deconstructing the human algorithms for exploration</article-title><source>Cognition</source><volume>173</volume><fpage>34</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.12.014</pub-id><pub-id pub-id-type="pmid">29289795</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Novelty and inductive generalization in human reinforcement learning</article-title><source>Topics in Cognitive Science</source><volume>7</volume><fpage>391</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1111/tops.12138</pub-id><pub-id pub-id-type="pmid">25808176</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibbs</surname> <given-names>ME</given-names></name><name><surname>Hutchinson</surname> <given-names>DS</given-names></name><name><surname>Summers</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Noradrenaline release in the locus coeruleus modulates memory formation and consolidation; roles for α- and β-adrenergic receptors</article-title><source>Neuroscience</source><volume>170</volume><fpage>1209</fpage><lpage>1222</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2010.07.052</pub-id><pub-id pub-id-type="pmid">20709158</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman-Rakic</surname> <given-names>PS</given-names></name><name><surname>Lidow</surname> <given-names>MS</given-names></name><name><surname>Gallager</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Overlap of dopaminergic, adrenergic, and serotoninergic receptors and complementarity of their subtypes in primate prefrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>10</volume><fpage>2125</fpage><lpage>2138</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-07-02125.1990</pub-id><pub-id pub-id-type="pmid">2165520</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>D</given-names></name><name><surname>Yu</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Advances in Neural Information Processing Systems</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>Iannaccone</surname> <given-names>R</given-names></name><name><surname>Ball</surname> <given-names>J</given-names></name><name><surname>Mathys</surname> <given-names>C</given-names></name><name><surname>Brandeis</surname> <given-names>D</given-names></name><name><surname>Walitza</surname> <given-names>S</given-names></name><name><surname>Brem</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Role of the medial prefrontal cortex in impaired decision making in juvenile attention-deficit/hyperactivity disorder</article-title><source>JAMA Psychiatry</source><volume>71</volume><fpage>1165</fpage><lpage>1173</lpage><pub-id pub-id-type="doi">10.1001/jamapsychiatry.2014.1093</pub-id><pub-id pub-id-type="pmid">25142296</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>Fiore</surname> <given-names>VG</given-names></name><name><surname>Moutoussis</surname> <given-names>M</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational psychiatry of ADHD: neural gain impairments across marrian levels of analysis</article-title><source>Trends in Neurosciences</source><volume>39</volume><fpage>63</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2015.12.009</pub-id><pub-id pub-id-type="pmid">26787097</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>Eldar</surname> <given-names>E</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Separate mesocortical and mesolimbic pathways encode effort and reward learning signals</article-title><source>PNAS</source><volume>114</volume><fpage>E7395</fpage><lpage>E7404</lpage><pub-id pub-id-type="doi">10.1073/pnas.1705643114</pub-id><pub-id pub-id-type="pmid">28808037</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>Allen</surname> <given-names>M</given-names></name><name><surname>Purg</surname> <given-names>N</given-names></name><name><surname>Moutoussis</surname> <given-names>M</given-names></name><name><surname>Rees</surname> <given-names>G</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Noradrenaline blockade specifically enhances metacognitive performance</article-title><source>eLife</source><volume>6</volume><elocation-id>e24901</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.24901</pub-id><pub-id pub-id-type="pmid">28489001</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>Moutoussis</surname> <given-names>M</given-names></name><name><surname>Purg</surname> <given-names>N</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Beta-Blocker propranolol modulates decision urgency during sequential information gathering</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>7170</fpage><lpage>7178</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0192-18.2018</pub-id><pub-id pub-id-type="pmid">30006361</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>Eldar</surname> <given-names>E</given-names></name><name><surname>Purg</surname> <given-names>N</given-names></name><name><surname>Moutoussis</surname> <given-names>M</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distinct roles of dopamine and noradrenaline in incidental memory</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>7715</fpage><lpage>7721</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0401-19.2019</pub-id><pub-id pub-id-type="pmid">31405924</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphries</surname> <given-names>MD</given-names></name><name><surname>Khamassi</surname> <given-names>M</given-names></name><name><surname>Gurney</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dopaminergic control of the Exploration-Exploitation Trade-Off via the basal ganglia</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00009</pub-id><pub-id pub-id-type="pmid">22347155</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Iigaya</surname> <given-names>K</given-names></name><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></name><name><surname>O’Doherty, P</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The value of what’s to come: Neural mechanisms coupling prediction error and the utility of anticipation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/588699</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Isaacson</surname> <given-names>JS</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How inhibition shapes cortical activity excitation and inhibition walk hand in hand</article-title><source>Neuron</source><volume>72</volume><fpage>231</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.3389/fnmol.2019.00168</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jahn</surname> <given-names>CI</given-names></name><name><surname>Gilardeau</surname> <given-names>S</given-names></name><name><surname>Varazzani</surname> <given-names>C</given-names></name><name><surname>Blain</surname> <given-names>B</given-names></name><name><surname>Sallet</surname> <given-names>J</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Bouret</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dual contributions of noradrenaline to behavioural flexibility and motivation</article-title><source>Psychopharmacology</source><volume>235</volume><fpage>2687</fpage><lpage>2702</lpage><pub-id pub-id-type="doi">10.1007/s00213-018-4963-z</pub-id><pub-id pub-id-type="pmid">29998349</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname> <given-names>M</given-names></name><name><surname>Te Beek</surname> <given-names>ET</given-names></name><name><surname>Wagenmakers</surname> <given-names>EJ</given-names></name><name><surname>van Gerven</surname> <given-names>JM</given-names></name><name><surname>Nieuwenhuis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The role of the noradrenergic system in the exploration-exploitation trade-off: a psychopharmacological study</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>170</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00170</pub-id><pub-id pub-id-type="pmid">21206527</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname> <given-names>M</given-names></name><name><surname>Nieuwenhuis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil diameter predicts changes in the exploration-exploitation trade-off: evidence for the adaptive gain theory</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>1587</fpage><lpage>1596</lpage><pub-id pub-id-type="doi">10.1162/jocn.2010.21548</pub-id><pub-id pub-id-type="pmid">20666595</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname> <given-names>S</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Kalwani</surname> <given-names>RM</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, Colliculi, and cingulate cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname> <given-names>S</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil size as a window on neural substrates of cognition</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>466</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.005</pub-id><pub-id pub-id-type="pmid">32331857</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahnt</surname> <given-names>T</given-names></name><name><surname>Weber</surname> <given-names>SC</given-names></name><name><surname>Haker</surname> <given-names>H</given-names></name><name><surname>Robbins</surname> <given-names>TW</given-names></name><name><surname>Tobler</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dopamine D2-receptor blockade enhances decoding of prefrontal signals in humans</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>4104</fpage><lpage>4111</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4182-14.2015</pub-id><pub-id pub-id-type="pmid">25740537</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahnt</surname> <given-names>T</given-names></name><name><surname>Tobler</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dopamine modulates the functional organization of the orbitofrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>1493</fpage><lpage>1504</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2827-16.2016</pub-id><pub-id pub-id-type="pmid">28069917</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kane</surname> <given-names>GA</given-names></name><name><surname>Vazey</surname> <given-names>EM</given-names></name><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Aston-Jones</surname> <given-names>G</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Increased locus coeruleus tonic activity causes disengagement from a patch-foraging task</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>17</volume><fpage>1073</fpage><lpage>1083</lpage><pub-id pub-id-type="doi">10.3758/s13415-017-0531-y</pub-id><pub-id pub-id-type="pmid">28900892</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname> <given-names>AS</given-names></name><name><surname>Mitchell</surname> <given-names>JM</given-names></name><name><surname>Weinstein</surname> <given-names>D</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dopamine, locus of control, and the exploration-exploitation tradeoff</article-title><source>Neuropsychopharmacology</source><volume>40</volume><fpage>454</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1038/npp.2014.193</pub-id><pub-id pub-id-type="pmid">25074639</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kool</surname> <given-names>W</given-names></name><name><surname>McGuire</surname> <given-names>JT</given-names></name><name><surname>Rosen</surname> <given-names>ZB</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Decision making and the avoidance of cognitive demand</article-title><source>Journal of Experimental Psychology: General</source><volume>139</volume><fpage>665</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1037/a0020198</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koudas</surname> <given-names>V</given-names></name><name><surname>Nikolaou</surname> <given-names>A</given-names></name><name><surname>Hourdaki</surname> <given-names>E</given-names></name><name><surname>Giakoumaki</surname> <given-names>SG</given-names></name><name><surname>Roussos</surname> <given-names>P</given-names></name><name><surname>Bitsios</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Comparison of Ketanserin, buspirone and propranolol on arousal, pupil size and autonomic function in healthy volunteers</article-title><source>Psychopharmacology</source><volume>205</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1007/s00213-009-1508-5</pub-id><pub-id pub-id-type="pmid">19288084</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krebs</surname> <given-names>RM</given-names></name><name><surname>Schott</surname> <given-names>BH</given-names></name><name><surname>Schütze</surname> <given-names>H</given-names></name><name><surname>Düzel</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The novelty exploration bonus and its attentional modulation</article-title><source>Neuropsychologia</source><volume>47</volume><fpage>2272</fpage><lpage>2281</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2009.01.015</pub-id><pub-id pub-id-type="pmid">19524091</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krugel</surname> <given-names>LK</given-names></name><name><surname>Biele</surname> <given-names>G</given-names></name><name><surname>Mohr</surname> <given-names>PN</given-names></name><name><surname>Li</surname> <given-names>SC</given-names></name><name><surname>Heekeren</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Genetic variation in dopaminergic neuromodulation influences the ability to rapidly and flexibly adapt decisions</article-title><source>PNAS</source><volume>106</volume><fpage>17951</fpage><lpage>17956</lpage><pub-id pub-id-type="doi">10.1073/pnas.0905191106</pub-id><pub-id pub-id-type="pmid">19822738</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marois</surname> <given-names>R</given-names></name><name><surname>Ivanoff</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Capacity limits of information processing in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>296</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.04.010</pub-id><pub-id pub-id-type="pmid">15925809</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname> <given-names>MR</given-names></name><name><surname>Rumsey</surname> <given-names>KM</given-names></name><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Parikh</surname> <given-names>K</given-names></name><name><surname>Heasly</surname> <given-names>B</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Navarro</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><source>Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.5)</source><ext-link ext-link-type="uri" xlink:href="http://ua.edu.au/ccs/teaching/lsr">http://ua.edu.au/ccs/teaching/lsr</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Papadopetraki</surname> <given-names>D</given-names></name><name><surname>Froböse</surname> <given-names>M</given-names></name><name><surname>Westbrook</surname> <given-names>A</given-names></name><name><surname>Zandbelt</surname> <given-names>B</given-names></name><name><surname>Cools</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Quantifying the cost of cognitive stability and flexibility</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/743120</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="software"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group><year iso-8601-date="2011">2011</year><data-title>R: A Language and Environment for Statistical Computing</data-title><publisher-loc>Vienna, Austria</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name><ext-link ext-link-type="uri" xlink:href="http://www.r-project.org">http://www.r-project.org</ext-link></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajkowski</surname> <given-names>J</given-names></name><name><surname>Kubiak</surname> <given-names>P</given-names></name><name><surname>Aston-Jones</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Locus coeruleus activity in monkey: phasic and tonic changes are associated with altered vigilance</article-title><source>Brain Research Bulletin</source><volume>35</volume><fpage>607</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1016/0361-9230(94)90175-9</pub-id><pub-id pub-id-type="pmid">7859118</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname> <given-names>JTE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Eta squared and partial eta squared as measures of effect size in educational research</article-title><source>Educational Research Review</source><volume>6</volume><fpage>135</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1016/j.edurev.2010.12.001</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname> <given-names>RD</given-names></name><name><surname>Lancaster</surname> <given-names>M</given-names></name><name><surname>Wakeley</surname> <given-names>J</given-names></name><name><surname>Bhagwagar</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Effects of beta-adrenoceptor blockade on components of human decision-making</article-title><source>Psychopharmacology</source><volume>172</volume><fpage>157</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1007/s00213-003-1641-5</pub-id><pub-id pub-id-type="pmid">14716472</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossetti</surname> <given-names>ZL</given-names></name><name><surname>Carboni</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Noradrenaline and dopamine elevations in the rat prefrontal cortex in spatial working memory</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>2322</fpage><lpage>2329</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3038-04.2005</pub-id><pub-id pub-id-type="pmid">15745958</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salamone</surname> <given-names>JD</given-names></name><name><surname>Yohn</surname> <given-names>SE</given-names></name><name><surname>López-Cruz</surname> <given-names>L</given-names></name><name><surname>San Miguel</surname> <given-names>N</given-names></name><name><surname>Correa</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Activational and effort-related aspects of motivation: neural mechanisms and implications for psychopathology</article-title><source>Brain</source><volume>139</volume><fpage>1325</fpage><lpage>1347</lpage><pub-id pub-id-type="doi">10.1093/brain/aww050</pub-id><pub-id pub-id-type="pmid">27189581</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salgado</surname> <given-names>H</given-names></name><name><surname>Treviño</surname> <given-names>M</given-names></name><name><surname>Atzori</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Layer- and area-specific actions of norepinephrine on cortical synaptic transmission</article-title><source>Brain Research</source><volume>1641</volume><fpage>163</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2016.01.033</pub-id><pub-id pub-id-type="pmid">26820639</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sara</surname> <given-names>SJ</given-names></name><name><surname>Vankov</surname> <given-names>A</given-names></name><name><surname>Hervé</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Locus coeruleus-evoked responses in behaving rats: a clue to the role of noradrenaline in memory</article-title><source>Brain Research Bulletin</source><volume>35</volume><fpage>457</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1016/0361-9230(94)90159-7</pub-id><pub-id pub-id-type="pmid">7859103</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname> <given-names>W</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Montague</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schulz</surname> <given-names>E</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The algorithmic architecture of exploration in the human brain</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>7</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2018.11.003</pub-id><pub-id pub-id-type="pmid">30529148</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartenbeck</surname> <given-names>P</given-names></name><name><surname>Passecker</surname> <given-names>J</given-names></name><name><surname>Hauser</surname> <given-names>TU</given-names></name><name><surname>FitzGerald</surname> <given-names>TH</given-names></name><name><surname>Kronbichler</surname> <given-names>M</given-names></name><name><surname>Friston</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational mechanisms of curiosity and goal-directed exploration</article-title><source>eLife</source><volume>8</volume><elocation-id>e41703</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.41703</pub-id><pub-id pub-id-type="pmid">31074743</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Servan-Schreiber</surname> <given-names>D</given-names></name><name><surname>Printz</surname> <given-names>H</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A network model of catecholamine effects: gain, signal-to-noise ratio, and behavior</article-title><source>Science</source><volume>249</volume><fpage>892</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1126/science.2392679</pub-id><pub-id pub-id-type="pmid">2392679</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silvetti</surname> <given-names>M</given-names></name><name><surname>Seurinck</surname> <given-names>R</given-names></name><name><surname>van Bochove</surname> <given-names>ME</given-names></name><name><surname>Verguts</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The influence of the noradrenergic system on optimal control of neural plasticity</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>7</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.3389/fnbeh.2013.00160</pub-id><pub-id pub-id-type="pmid">24312028</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silvetti</surname> <given-names>M</given-names></name><name><surname>Vassena</surname> <given-names>E</given-names></name><name><surname>Abrahamse</surname> <given-names>E</given-names></name><name><surname>Verguts</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dorsal anterior cingulate-brainstem ensemble as a reinforcement meta-learner</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006370</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006370</pub-id><pub-id pub-id-type="pmid">30142152</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skvortsova</surname> <given-names>V</given-names></name><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning to minimize efforts versus maximizing rewards: computational principles and neural correlates</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>15621</fpage><lpage>15630</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1350-14.2014</pub-id><pub-id pub-id-type="pmid">25411490</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokol-Hessner</surname> <given-names>P</given-names></name><name><surname>Lackovic</surname> <given-names>SF</given-names></name><name><surname>Tobe</surname> <given-names>RH</given-names></name><name><surname>Camerer</surname> <given-names>CF</given-names></name><name><surname>Leventhal</surname> <given-names>BL</given-names></name><name><surname>Phelps</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Determinants of propranolol's Selective Effect on Loss Aversion</article-title><source>Psychological Science</source><volume>26</volume><fpage>1123</fpage><lpage>1130</lpage><pub-id pub-id-type="doi">10.1177/0956797615582026</pub-id><pub-id pub-id-type="pmid">26063441</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soutschek</surname> <given-names>A</given-names></name><name><surname>Burke</surname> <given-names>CJ</given-names></name><name><surname>Raja Beharelle</surname> <given-names>A</given-names></name><name><surname>Schreiber</surname> <given-names>R</given-names></name><name><surname>Weber</surname> <given-names>SC</given-names></name><name><surname>Karipidis</surname> <given-names>II</given-names></name><name><surname>Ten Velden</surname> <given-names>J</given-names></name><name><surname>Weber</surname> <given-names>B</given-names></name><name><surname>Haker</surname> <given-names>H</given-names></name><name><surname>Kalenscher</surname> <given-names>T</given-names></name><name><surname>Tobler</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The dopaminergic reward system underpins gender differences in social preferences</article-title><source>Nature Human Behaviour</source><volume>1</volume><fpage>819</fpage><lpage>827</lpage><pub-id pub-id-type="doi">10.1038/s41562-017-0226-y</pub-id><pub-id pub-id-type="pmid">31024122</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soutschek</surname> <given-names>A</given-names></name><name><surname>Gvozdanovic</surname> <given-names>G</given-names></name><name><surname>Kozak</surname> <given-names>R</given-names></name><name><surname>Duvvuri</surname> <given-names>S</given-names></name><name><surname>de Martinis</surname> <given-names>N</given-names></name><name><surname>Harel</surname> <given-names>B</given-names></name><name><surname>Gray</surname> <given-names>DL</given-names></name><name><surname>Fehr</surname> <given-names>E</given-names></name><name><surname>Jetter</surname> <given-names>A</given-names></name><name><surname>Tobler</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dopaminergic D1 receptor stimulation affects effort and risk preferences</article-title><source>Biological Psychiatry</source><volume>87</volume><fpage>678</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2019.09.002</pub-id><pub-id pub-id-type="pmid">31668477</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Speekenbrink</surname> <given-names>M</given-names></name><name><surname>Konstantinidis</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Uncertainty and exploration in a restless bandit problem</article-title><source>Topics in Cognitive Science</source><volume>7</volume><fpage>351</fpage><lpage>367</lpage><pub-id pub-id-type="doi">10.1111/tops.12145</pub-id><pub-id pub-id-type="pmid">25899069</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stojić</surname> <given-names>H</given-names></name><name><surname>Schulz</surname> <given-names>E</given-names></name><name><surname>P Analytis</surname> <given-names>P</given-names></name><name><surname>Speekenbrink</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>It's new, but is it good? how generalization and uncertainty guide the exploration of novel options</article-title><source>Journal of Experimental Psychology: General</source><volume>149</volume><fpage>1878</fpage><lpage>1907</lpage><pub-id pub-id-type="doi">10.1037/xge0000749</pub-id><pub-id pub-id-type="pmid">32191080</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname> <given-names>RS</given-names></name><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Introduction to Reinforcement Learning</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tervo</surname> <given-names>DGR</given-names></name><name><surname>Proskurin</surname> <given-names>M</given-names></name><name><surname>Manakov</surname> <given-names>M</given-names></name><name><surname>Kabra</surname> <given-names>M</given-names></name><name><surname>Vollmer</surname> <given-names>A</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name><name><surname>Karpova</surname> <given-names>AY</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Behavioral variability through stochastic choice and its gating by anterior cingulate cortex</article-title><source>Cell</source><volume>159</volume><fpage>21</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.08.037</pub-id><pub-id pub-id-type="pmid">25259917</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="1933">1933</year><article-title>On the likelihood that one unknown probability exceeds another in view of the evidence of two samples</article-title><source>Biometrika</source><volume>25</volume><fpage>285</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1093/biomet/25.3-4.285</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toru</surname> <given-names>M</given-names></name><name><surname>Takashima</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Haloperidol in large doses reduces the cataleptic response and increases noradrenaline metabolism in the brain of the rat</article-title><source>Neuropharmacology</source><volume>24</volume><fpage>231</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1016/0028-3908(85)90079-6</pub-id><pub-id pub-id-type="pmid">4039420</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trofimova</surname> <given-names>I</given-names></name><name><surname>Robbins</surname> <given-names>TW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temperament and arousal systems: a new synthesis of differential psychology and functional neurochemistry</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>64</volume><fpage>382</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2016.03.008</pub-id><pub-id pub-id-type="pmid">26969100</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname> <given-names>M</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Servan-Schreiber</surname> <given-names>D</given-names></name><name><surname>Rajkowski</surname> <given-names>J</given-names></name><name><surname>Aston-Jones</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The role of locus coeruleus in the regulation of cognitive performance</article-title><source>Science</source><volume>283</volume><fpage>549</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1126/science.283.5401.549</pub-id><pub-id pub-id-type="pmid">9915705</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varazzani</surname> <given-names>C</given-names></name><name><surname>San-Galli</surname> <given-names>A</given-names></name><name><surname>Gilardeau</surname> <given-names>S</given-names></name><name><surname>Bouret</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Noradrenaline and dopamine neurons in the reward/effort trade-off: a direct electrophysiological comparison in behaving monkeys</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>7866</fpage><lpage>7877</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0454-15.2015</pub-id><pub-id pub-id-type="pmid">25995472</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wahn</surname> <given-names>B</given-names></name><name><surname>König</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Is attentional resource allocation across sensory modalities Task-Dependent?</article-title><source>Advances in Cognitive Psychology</source><volume>13</volume><fpage>83</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.5709/acp-0209-2</pub-id><pub-id pub-id-type="pmid">28450975</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Bouret</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>What is the relationship between dopamine and effort?</article-title><source>Trends in Neurosciences</source><volume>42</volume><fpage>79</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2018.10.001</pub-id><pub-id pub-id-type="pmid">30391016</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname> <given-names>CM</given-names></name><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>van der Wee</surname> <given-names>NJ</given-names></name><name><surname>Giltay</surname> <given-names>EJ</given-names></name><name><surname>van Noorden</surname> <given-names>MS</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Nieuwenhuis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The effect of atomoxetine on random and directed exploration in humans</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0176034</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0176034</pub-id><pub-id pub-id-type="pmid">28445519</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waterhouse</surname> <given-names>BD</given-names></name><name><surname>Moises</surname> <given-names>HC</given-names></name><name><surname>Yeh</surname> <given-names>HH</given-names></name><name><surname>Woodward</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Norepinephrine enhancement of inhibitory synaptic mechanisms in cerebellum and cerebral cortex: mediation by beta adrenergic receptors</article-title><source>The Journal of Pharmacology and Experimental Therapeutics</source><volume>221</volume><fpage>495</fpage><lpage>506</lpage><pub-id pub-id-type="pmid">6281417</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waterhouse</surname> <given-names>BD</given-names></name><name><surname>Moises</surname> <given-names>HC</given-names></name><name><surname>Yeh</surname> <given-names>HH</given-names></name><name><surname>Geller</surname> <given-names>HM</given-names></name><name><surname>Woodward</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Comparison of norepinephrine- and benzodiazepine-induced augmentation of purkinje cell response to γ-aminobutyric acid (GABA)</article-title><source>The Journal of Pharmacology and Experimental Therapeutics</source><volume>228</volume><fpage>257</fpage><lpage>267</lpage><pub-id pub-id-type="pmid">6319673</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname> <given-names>D</given-names></name><name><surname>Clark</surname> <given-names>LA</given-names></name><name><surname>Tellegen</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1988">1988a</year><article-title>Development and validation of brief measures of positive and negative affect: the PANAS scales</article-title><source>Journal of Personality and Social Psychology</source><volume>54</volume><fpage>1063</fpage><lpage>1070</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.54.6.1063</pub-id><pub-id pub-id-type="pmid">3397865</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname> <given-names>D</given-names></name><name><surname>Clark</surname> <given-names>LA</given-names></name><name><surname>Carey</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1988">1988b</year><article-title>Positive and negative affectivity and their relation to anxiety and depressive disorders</article-title><source>Journal of Abnormal Psychology</source><volume>97</volume><fpage>346</fpage><lpage>353</lpage><pub-id pub-id-type="doi">10.1037/0021-843X.97.3.346</pub-id><pub-id pub-id-type="pmid">3192830</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wechsler</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>WASI -II: wechsler abbreviated scale of intelligence - second edition</article-title><source>Journal of Psychoeducational Assessment</source><volume>13</volume><elocation-id>56</elocation-id><pub-id pub-id-type="doi">10.1177/0734282912467756</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Geana</surname> <given-names>A</given-names></name><name><surname>White</surname> <given-names>JM</given-names></name><name><surname>Ludvig</surname> <given-names>EA</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Humans use directed and random exploration to solve the explore–exploit dilemma</article-title><source>Journal of Experimental Psychology: General</source><volume>143</volume><fpage>2074</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1037/a0038199</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wittmann</surname> <given-names>BC</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Striatal activity underlies novelty-based choice in humans</article-title><source>Neuron</source><volume>58</volume><fpage>967</fpage><lpage>973</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.04.027</pub-id><pub-id pub-id-type="pmid">18579085</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname> <given-names>CM</given-names></name><name><surname>Schulz</surname> <given-names>E</given-names></name><name><surname>Speekenbrink</surname> <given-names>M</given-names></name><name><surname>Nelson</surname> <given-names>JD</given-names></name><name><surname>Meder</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Generalization guides human exploration in vast decision spaces</article-title><source>Nature Human Behaviour</source><volume>2</volume><fpage>915</fpage><lpage>924</lpage><pub-id pub-id-type="doi">10.1038/s41562-018-0467-4</pub-id><pub-id pub-id-type="pmid">30988442</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>AJ</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zajkowski</surname> <given-names>WK</given-names></name><name><surname>Kossut</surname> <given-names>M</given-names></name><name><surname>Wilson</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A causal role for right frontopolar cortex in directed, but not random, exploration</article-title><source>eLife</source><volume>6</volume><elocation-id>e27430</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27430</pub-id><pub-id pub-id-type="pmid">28914605</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zénon</surname> <given-names>A</given-names></name><name><surname>Solopchuk</surname> <given-names>O</given-names></name><name><surname>Pezzulo</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>An information-theoretic perspective on the costs of cognition</article-title><source>Neuropsychologia</source><volume>123</volume><fpage>5</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2018.09.013</pub-id><pub-id pub-id-type="pmid">30268880</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><sec id="s8" sec-type="appendix"><title>Drug effect on response times</title><p>There were no differences in response times (RT) between drug groups in the one-way ANOVA. Neither in the mean RT (ANOVA: F(2, 54) = 1.625, p = 0.206, <inline-formula><mml:math id="inf179"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.057) nor in its variability (standard deviation; F(2, 54)=1.85, p = 0.16, <inline-formula><mml:math id="inf180"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>=0.064).</p></sec><sec id="s9" sec-type="appendix"><title>Bandit effect on response times</title><p>There was no difference in response times between bandits in the repeated-measures ANOVA (bandit main effect: F(1.78, 99.44) = 1.634, p = 0.203, <inline-formula><mml:math id="inf181"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.028; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></sec><sec id="s10" sec-type="appendix"><title>Interaction effects on response times</title><p>When looking at the first choice in both conditions, no differences were evident in RT in the repeated-measures ANOVA with a between-subject factor drug group and within-subject factors horizon and bandit (bandit main effect: F(1.71, 92.46) = 1.203, p = 0.3, <inline-formula><mml:math id="inf182"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.022; horizon main effect: F(1, 54) = 0.71, p = 0.403, <inline-formula><mml:math id="inf183"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.013; drug main effect: F(2, 54) = 2.299, p = 0.11, <inline-formula><mml:math id="inf184"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.078; drug-by-bandit interaction: F(3.42, 92.46) = 0.431, p = 0.757, <inline-formula><mml:math id="inf185"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.016; drug-by-horizon interaction: F(2, 54) = 0.204, p = 0.816, <inline-formula><mml:math id="inf186"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.008; bandit-by-horizon interaction: F(1.39, 75.01) = 0.298, p = 0.662, <inline-formula><mml:math id="inf187"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.005; drug-by-bandit-by-horizon interaction: F(2.78, 75.01) = 1.015, p = 0.387, <inline-formula><mml:math id="inf188"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.036).</p><p>In the long horizon, when looking at all six samples, no differences were evident in RT between drug group in the repeated-measures ANOVA with a between-subject factor drug group and within-subject factors bandits and samples (drug main effect: F(2, 56)=0.542, p = 0.585, <inline-formula><mml:math id="inf189"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.019). There was an effect of bandit (bandit main effect: F(1.61, 90.12)=7.137, p = 0.003, <inline-formula><mml:math id="inf190"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.113), of sample (sample main effect: F(1.54, 86.15) = 427.047, p&lt;0.001, <inline-formula><mml:math id="inf191"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.884) and an interaction between the two (bandit-by-sample interaction: F(3.33, 186.41) = 4.789, p = 0.002, <inline-formula><mml:math id="inf192"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.079; drug-by-bandit interaction: F(3.22, 90.12) = 0.525, p = 0.679, <inline-formula><mml:math id="inf193"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.018; drug-by-sample interaction: F(3.08, 86.15) = 1.039, p = 0.381, <inline-formula><mml:math id="inf194"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.036; drug-by-bandit-by-sample interaction: F(6.66, 186.41) = 0.645, p = 0.71, <inline-formula><mml:math id="inf195"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.023). Further analysis (not corrected for multiple comparisons) revealed that the interaction between bandit and sample reflected the fact that when looking at samples individually, there was a bandit main effect in the second sample (bandit main effect: F(1.27, 70.88) = 27.783, p&lt;0.001, <inline-formula><mml:math id="inf196"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.332; drug main effect: F(2, 56) = 0.201, p = 0.819, <inline-formula><mml:math id="inf197"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.007; drug-by-bandit interaction: F(2.53, 70.88) = 0.906, p = 0.429, <inline-formula><mml:math id="inf198"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.031) and in the third sample (bandit main effect: F(1.23, 68.93) = 21.318, p&lt;0.001, <inline-formula><mml:math id="inf199"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.276; drug main effect: F(2, 56) = 0.102, p = 0.903, <inline-formula><mml:math id="inf200"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.004; drug-by-bandit interaction: F(2.46, 68.93) = 0.208, p = 0.855, <inline-formula><mml:math id="inf201"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.007), but not in the other samples first sample: drug main effect: F(2, 56) = 1.108, p = 0.337, <inline-formula><mml:math id="inf202"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.038; bandit main effect: F(2, 112) = 0.339, p = 0.713, <inline-formula><mml:math id="inf203"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.006; drug-by-bandit interaction: F(4, 112) = 0.414, p = 0.798, <inline-formula><mml:math id="inf204"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.015; fourth sample: (drug main effect: F(2, 56) = 0.43, p = 0.652, <inline-formula><mml:math id="inf205"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.015; bandit main effect: F(1.36, 76.22)=1.348, p = 0.259, <inline-formula><mml:math id="inf206"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>=0.024; drug-by-bandit interaction: F(2.72, 76.22) = 0.396, p = 0.737, <inline-formula><mml:math id="inf207"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.014; fifth sample: drug main effect: F(2, 56) = 0.216, p = 0.806, <inline-formula><mml:math id="inf208"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.008; bandit main effect: F(1.25, 69.79)=0.218, p = 0.696, <inline-formula><mml:math id="inf209"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.004; drug-by-bandit interaction: F(2.49, 69.79) = 0.807, p = 0.474, <inline-formula><mml:math id="inf210"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.028; sixth sample: drug main effect: F(2, 56) = 1.026, p = 0.365, <inline-formula><mml:math id="inf211"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.035; bandit main effect: F(1.05, 58.81)=0.614, p = 0.444, <inline-formula><mml:math id="inf212"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.011; drug-by-bandit interaction: F(2.1, 58.81) = 1.216, p = 0.305, <inline-formula><mml:math id="inf213"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.042). In the second sample, the high-value bandit was chosen faster (high-value bandit vs low-value bandit: t(59) = -5.736, p&lt;0.001, d = 0.917; high-value bandit vs novel bandit: t(59) = -6.24, p&lt;0.001, d = 0.599) and the low-value bandit was chosen slower (low-value bandit vs novel bandit: t(59) = 3.756, p&lt;0.001, d = 0.432). In the third sample, the low-value bandit was chosen slower (high-value bandit vs low-value bandit: t(59) = -5.194, p&lt;0.001, d = 0.571; low-value bandit vs novel bandit: t(59) = 4.448, p&lt;0.001, d = 0.49; high-value bandit vs novel bandit: t(59) = -1.834, p = 0.072, d = 0.09).</p></sec><sec id="s11" sec-type="appendix"><title>Horizon effect on response times</title><p>There were no differences in RT between horizon conditions in the repeated-measures ANOVA with the between-subject factor drug group, the within-subject factor horizon condition and the covariates WASI and PANAS negative score horizon main effect: F(1, 54) = 1.443, p = 0.235, <inline-formula><mml:math id="inf214"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.026; drug main effect: F(2, 54) = 1.625, p = 0206, <inline-formula><mml:math id="inf215"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.057; drug-by-horizon interaction: F(2, 54) = 0.431, p = 0.652, <inline-formula><mml:math id="inf216"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.016. In the long horizon, the RT decreased with each sample (sample main effect: F(1.36, 73.5) = 13.626, p&lt;0.001, <inline-formula><mml:math id="inf217"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.201; Pairwise comparisons: sample 1 vs 2: t(59) = 20.968, p&lt;0.001, d = 2.73; sample 2 vs 3: t(59) = 11.825, p&lt;0.001, d = 1.539; sample 3 vs 4: t(59) = 7.862, p&lt;0.001, d = 1.024; sample 4 vs 5: t(59) = 4.117, p&lt;0.001, d = 1.539; sample 5 vs 6: t(59) = 2.646, p = 0.01, d = 1.024; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1b</xref>).</p></sec><sec id="s12" sec-type="appendix"><title>PANAS</title><p>The Positive Affect and Negative Affect scale (PANAS; <xref ref-type="bibr" rid="bib94">Watson et al., 1988a</xref>) was completed 50 min after the second drug administration and 10 min prior to the task. Groups had similar positive affect but differed in negative affect (<xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>), driven by a higher score in the placebo group (pairwise comparisons: placebo vs propranolol: t(56)=2.801, p = 0.007, d = 0.799; amisulpride vs placebo: t(56)=-2.096, p = 0.041, d = 0.557; amisulpride vs propranolol: t(56) = 0.669, p = 0.506, d = 0.383). It is unclear whether this difference was driven by the drug manipulation, but similar studies have not reported such an effect (e.g. <xref ref-type="bibr" rid="bib41">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Campbell-Meiklejohn et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Rogers et al., 2004</xref>; <xref ref-type="bibr" rid="bib39">Hauser et al., 2017b</xref>). We controlled for a possible influence of these measures in all our analyses.</p></sec><sec id="s13" sec-type="appendix"><title>﻿Physiological effects</title><p>Heart rate, systolic and diastolic pressure were obtained at 3 time points: at the beginning of the experiment before giving the drug (‘at arrival’), after giving the drug just before the task (‘pre-task’), and after finishing task and questionnaires (‘post-task’). The post-task heart rate was lower for participants who received propranolol compared to the other two groups (one-way ANOVA: F(2, 55) = 7.249, p = 0.002, <inline-formula><mml:math id="inf218"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.209; <xref ref-type="table" rid="app2table2">Appendix 2—table 2</xref>). A two-way ANOVA with the between-subject factor of drug group and within-subject factor of time (all three time points), showed a time-dependent decrease in heart rate (F(1.74, 95.97) = 99.341, p&lt;0.001, <inline-formula><mml:math id="inf219"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.644), in systolic pressure (F(2, 110) = 8.967, p&lt;0.001, <inline-formula><mml:math id="inf220"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.14) and in diastolic pressure (F(2, 110) = 0.874, p = 0.42, <inline-formula><mml:math id="inf221"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.016), indicating subjects relaxed across the course of the study. Those reductions did not differ between drug group (drug main effect: heart rate: F(2, 55) = 1.84, p = 0.169, <inline-formula><mml:math id="inf222"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.063; systolic pressure: F(2, 55)=1.08, p = 0.347, <inline-formula><mml:math id="inf223"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.038; diastolic pressure: F(2, 55) = 0.239, p = 0.788, <inline-formula><mml:math id="inf224"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.009; drug-by-time interaction: heart rate: F(3.49, 95.97) = 1.928, p = 0.121, <inline-formula><mml:math id="inf225"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.066; systolic pressure: F(4, 110) = 1.6, p = 0.179, <inline-formula><mml:math id="inf226"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.055; diastolic pressure: F(4, 110) = 0.951, p = 0.438, <inline-formula><mml:math id="inf227"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.033).</p></sec><sec id="s14" sec-type="appendix"><title>Task performance score</title><p>The performance did not differ between drug groups (total score: drug main effect: F(2, 5) = 2.313, p = 0.109, <inline-formula><mml:math id="inf228"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.079) but it was increased in subjects with higher IQ scores (WASI main effect: F(1, 54) = 17.172, p&lt;0.001, <inline-formula><mml:math id="inf229"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.241).</p><p>In the long horizon, the score increased with each sample (sample main effect: F(3.12, 174.97) = 103.469, p&lt;0.001, <inline-formula><mml:math id="inf230"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.649; Pairwise comparisons: sample 1 vs 2: t(59) = -6.737, p&lt;0.001, d=0.877; sample 2 vs 3: t(59)=-3.69, p&lt;0.001, d=0.48; sample 3 vs 4: t(59) = -5.167, p&lt;0.001, d = 0.673; sample 4 vs 5: t(59) = -2.832, p = 0.006, d = 0.48; sample 5 vs 6: t(59) = -2.344, p = 0.022, d = 0.673; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a</xref>). The increase in reward was larger in trials where the first draw was exploratory (linear regression slope coefficient: mean=0.118, sd=0.038) compared to when it was exploitative (linear regression slope coefficient: mean = 0.028, sd = 0.041; t-tests for slope coefficients: t(58) = -12.161, p&lt;0.001, d = -1.583; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1d</xref>), suggesting that exploration was used beneficially and subjects benefitted from their initial exploration.</p></sec><sec id="s15" sec-type="appendix"><title>Dopamine effect on high-value bandit sampling frequency</title><p>The amisulpride group had a marginal tendency towards selecting the high-value bandit, meaning that they were disposed to exploit more overall (propranolol group excluded: horizon main effect: F(1, 35) = 3.035, p = 0.09, <inline-formula><mml:math id="inf231"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.08; drug main effect: F(1, 35) = 3.602, p = 0.066, <inline-formula><mml:math id="inf232"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.093; drug-by-horizon interaction: F(1, 35)=2.15, p = 0.151, <inline-formula><mml:math id="inf233"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.058). This trend effect was not observed when all three groups were included (horizon main effect: F(1, 54) = 3.909, p = 0.053, <inline-formula><mml:math id="inf234"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.068; drug main effect: F(2, 54) = 1.388, p = 0.258, <inline-formula><mml:math id="inf235"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.049; drug-by-horizon interaction: F(2, 54) = 0.834, p = 0.44, <inline-formula><mml:math id="inf236"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.03).</p></sec><sec id="s16" sec-type="appendix"><title>Gender effects</title><p>When adding gender as a between-subjects variable in the repeated-measures ANOVAs, none of the main results changed. Interestingly, we observed a drug-by-gender interaction in the prior variance <inline-formula><mml:math id="inf237"><mml:msub><mml:mrow><mml:mi mathvariant="normal">σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (drug-by-gender interaction: F(2, 51) = 5.914, p = 0.005, <inline-formula><mml:math id="inf238"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.188; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>), driven by the fact that, female subjects in the placebo group had a larger average <inline-formula><mml:math id="inf239"><mml:msub><mml:mrow><mml:mi mathvariant="normal">σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (across both horizon conditions) compared to males (t(20) = 2.836, p = 0.011, d = 1.268), whereas male subjects have a larger <inline-formula><mml:math id="inf240"><mml:msub><mml:mrow><mml:mi mathvariant="normal">σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> compared to females in the amisulpride group, (t(19) = -2.466, p = 0.025, d = 1.124; propranolol group: t(20) = -0.04, p = 0.969, d = 0.018). This suggests that in a placebo setting, females are on average more uncertain about an option’s expected value, whereas in a dopamine blockade setting males are more uncertain. Besides this effect, we observed a trend-level significance in response times (RT), driven primarily by female subjects tending to have a faster RT in the long horizon compared to male subjects (gender main effect: F(1, 51) = 3.54, p = 0.066, <inline-formula><mml:math id="inf241"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.065).</p></sec><sec id="s17" sec-type="appendix"><title>Horizon and drug effects without covariate</title><p>When analysing the results without correcting for IQ (WASI) and negative affect (PANAS), similar results are obtained. The high-value bandit is picked more in the short-horizon condition indicating exploitation (F(1, 56) = 44.844, p&lt;0.001, <inline-formula><mml:math id="inf242"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.445), whereas the opposite phenomenon is observed in the low-value bandit (F(1, 56) = 24.24, p&lt;0.001, <inline-formula><mml:math id="inf243"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.302) and the novel bandit (horizon main effect: F(1, 56) = 30.867, p&lt;0.001, <inline-formula><mml:math id="inf244"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.355), indicating exploration. In line with these results, the model parameters for value-free random exploration (<inline-formula><mml:math id="inf245"><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula>: F(1, 56) = 10.362, p = 0.002, <inline-formula><mml:math id="inf246"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.156) and novelty exploration (<inline-formula><mml:math id="inf247"><mml:mi mathvariant="normal">η</mml:mi></mml:math></inline-formula>: F(1, 56) = 38.103, p&lt;0.001, <inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.405) are larger in the long compared to the short horizon condition. Additionally, noradrenaline blockade reduces value-free random exploration as can be seen in the two behavioural signatures, frequency of picking the low-value bandit (F(2, 56) = 2.523, p = 0.089, <inline-formula><mml:math id="inf249"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.083; Pairwise comparisons: placebo vs propranolol: t(40)=2.923, p = 0.005, d=0.654; amisulpride vs placebo: t(38) = -0.587, p = 0.559, d = 0.133; amisulpride vs propranolol: t(38) = 2.171, p = 0.034, d = 0.496), and in the consistency (F(2, 56) = 3.596, p = 0.034, <inline-formula><mml:math id="inf250"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.114; Pairwise comparisons: placebo vs propranolol: t(40) = -3.525, p = 0.001, d = 0.788; amisulpride vs placebo: t(38) = 1.107, p = 0.272, d = 0.251; amisulpride vs propranolol: t(38) = -2.267, p = 0.026, d = 0.514), as well as in the model parameter for value-free random exploration (<inline-formula><mml:math id="inf251"><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula>: F(2, 56) = 3.205, p = 0.048, <inline-formula><mml:math id="inf252"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.103; Pairwise comparisons: placebo vs propranolol: t(40) = 3.177, p = 0.002, d = 0.71; amisulpride vs placebo: t(38) = 0.251, p = 0.802, d = 0.057; amisulpride vs propranolol: t(38) = 2.723, p = 0.009, d = 0.626).</p></sec><sec id="s18" sec-type="appendix"><title>Horizon and drug effects with heart rate as covariate</title><p>When analysing results but now correcting for the post-experiment heart rate (<xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>) in addition to IQ (WASI) and negative affect (PANAS), we obtained similar results. Noradrenaline blockade reduced value-free random exploration as seen in two behavioural signatures, frequency of picking the low-value bandit (F(2, 52) = 4.014, p = 0.024, <inline-formula><mml:math id="inf253"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.134; Pairwise comparisons:placebo vs propranolol: t(40) = 2.923, p = 0.005, d=0.654; amisulpride vs propranolol: t(38) = 2.171, p = 0.034, d = 0.496; amisulpride vs placebo: t(38) = -0.587, p = 0.559, d = 0.133), and consistency (F(2, 52) = 5.474, p = 0.007, <inline-formula><mml:math id="inf254"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.174; Pairwise comparisons: placebo vs propranolol: t(40) = -3.525, p = 0.001, d=0.788; amisulpride vs propranolol: t(38) = -2.267, p = 0.026, d = 0.514; amisulpride vs placebo: t(38) = 1.107, p = 0.272, d = 0.251), as well as in a model parameter for value-free random exploration (<inline-formula><mml:math id="inf255"><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula>: F(2, 52) = 4.493, p = 0.016, <inline-formula><mml:math id="inf256"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.147; Pairwise comparisons: placebo vs propranolol: t(40) = 3.177, p = 0.002, d = 0.71; amisulpride vs propranolol: t(38) = 2.723, p = 0.009, d = 0.626; amisulpride vs placebo: t(38) = 0.251, p = 0.802, d = 0.057).</p></sec><sec id="s19" sec-type="appendix"><title>Other model results</title><p>When analysing the fitted parameter values of both the second winning model (UCB +<inline-formula><mml:math id="inf257"> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula> + <inline-formula><mml:math id="inf258"><mml:mi mathvariant="normal">η</mml:mi></mml:math></inline-formula>) and third winning model (hybrid +<inline-formula><mml:math id="inf259"> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula> + <inline-formula><mml:math id="inf260"><mml:mi mathvariant="normal">η</mml:mi></mml:math></inline-formula>), similar results pertain. Thus, a value-free random exploration parameter was reduced following noradrenaline blockade in the second winning model (<inline-formula><mml:math id="inf261"><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula>: F(2, 54) = 4.503, p = 0.016, <inline-formula><mml:math id="inf262"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.143; Pairwise comparisons: placebo vs propranolol: t(38)=2.185, p = 0.033, d=0.386; amisulpride vs propranolol: t(40) = 1.724, p = 0.089, d = 0.501; amisulpride vs placebo: t(40) = -0.665, p = 0.508, d = 0.151) and was affected at a trend-level significance in the third winning model (<inline-formula><mml:math id="inf263"><mml:mi mathvariant="normal">ϵ</mml:mi></mml:math></inline-formula>: F(2, 54) = 3.04, p = 0.056, <inline-formula><mml:math id="inf264"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> =0.101). These results highlight our finding that value-free random exploration is modulated by noradrenaline and additionally demonstrates this is independent of the complex exploration strategy used as well as the value function.</p></sec><sec id="s20" sec-type="appendix"><title>Bandit combination effect</title><p>Behavioural results were analysed additionally for each bandit combination separately. The high-value bandit was chosen more when there was no novel bandit (pairwise comparisons: [certain-standard, standard, low] vs [certain-standard, standard, novel]: t(59) = 15.122, p&lt;0.001, d = 1.969; [certain-standard, standard, low] vs [certain-standard, novel, low]: t(59) = 12.905, p&lt;0.001, d = 2.389; [certain-standard, standard, low] vs [standard, novel, low]: t(59) = 18.348, p&lt;0.001, d = 1.68), and less when its value was less certain ([standard, novel, low] vs [certain-standard, standard, novel]: t(59) = -6.986, p&lt;0.001, d=0.407; [standard, novel, low] vs [certain-standard, novel, low]: t(59) = -5.44, p&lt;0.001, d = 0.708; bandit combination main effect: F(1.81, 101.33) = 237.051, p&lt;0.001, <inline-formula><mml:math id="inf265"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.809; [certain-standard, standard, novel] vs [certain-standard, novel, low]: t(59) = 0.364, p = 0.717, d = 0.909; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a</xref>). The novel bandit was chosen most often when the high-value bandit was less certain, then when the high-value bandit was more certain and was chosen least when both certain and certain standard bandits were present ([standard, novel, low] vs [certain-standard, novel, low]: t(59)=5.001, p&lt;0.001, d=0.651; [standard, novel, low] vs [certain-standard, standard, novel]: t(59) = 9.414, p&lt;0.001, d = 1.226; [certain-standard, novel, low] vs [certain-standard, standard, novel]: t(59) = 4.146, p&lt;0.001, d=0.54; bandit combination main effect: F(2, 112) = 42.44, p&lt;0.001, <inline-formula><mml:math id="inf266"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.431; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b</xref>). The low-value bandit was chosen less when the high-value bandit was more certain ([certain-standard, novel, low] vs [certain-standard, standard, low]: t(59) = -2.731, p = 0.008, d = 0.356; [certain-standard, novel, low] vs [standard, novel, low]: t(59) = -1.958, p = 0.055, d = 0.255; bandit combination main effect: F(1.66, 92.74) = 4.534, p = 0.019, <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.075; [certain-standard, standard, low] vs [standard, novel, low]: t(59) = 1.32, p = 0.192, d = 0.172; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c</xref>).</p></sec><sec id="s21" sec-type="appendix"><title>Other effects on choice consistency</title><p>Our results demonstrate a drug-by-horizon interaction on choice consistency (F(2, 54) = 3.352, p = 0.042, <inline-formula><mml:math id="inf268"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.110; <xref ref-type="fig" rid="fig3">Figure 3</xref>), mainly driven by the fact that frequency of selecting the same option is increased in the long (compared to the short) horizon in the amisulpride group, while there is no significant horizon difference in the other two drug groups (pairwise comparison for horizon effect: amisulpride group: t(19) = 2.482, p = 0.023, d = 0.569; propranolol group: t(20) = -1.91, p = 0.071, d = 0.427; placebo group: t(20) = 0.505, p = 0.619, d = 0.113). It is not entirely clear why catecholamines would increase the differentiation between the horizon conditions and this relatively weak effect should be replicated before interpreting.</p></sec><sec id="s22" sec-type="appendix"><title>Stand-alone heuristic models</title><p>We also analysed stand-alone heuristic models, in which there is no value computation (value of each bandit <inline-formula><mml:math id="inf269"><mml:mi mathvariant="normal">i</mml:mi></mml:math></inline-formula>: <inline-formula><mml:math id="inf270"><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub> <mml:mi mathvariant="normal"/><mml:mo>=</mml:mo> <mml:mi mathvariant="normal"/><mml:mn>0</mml:mn></mml:math></inline-formula>). The held-out data likelihood for such heuristic model combined with novelty exploration had a mean of m = 0.367 (sd = 0.005). The model in which we added value-free random exploration on top of novelty exploration had a mean of m=0.384 (sd = 0.006). These models performed poorly, although better than chance level. Importantly, adding value-free random exploration improved performance. This highlights that subjects’ combine complex and heuristic modules in exploration.</p></sec></boxed-text></app><app id="appendix-2"><title>Appendix 2</title><boxed-text><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Characteristics of drug groups.</title><p>The drug groups did not differ in gender, age, nor in intellectual abilities (adapted WASI matrix test).</p><p>Groups differed in negative affect (PANAS), driven by a higher score in the placebo group (pairwise comparisons: placebo vs propranolol: t(56) = 2.801, p = 0.007, d = 0.799; amisulpride vs placebo: t(56) = -2.096, p = 0.041, d = 0.557; amisulpride vs propranolol: t(56) = 0.669, p = 0.506, d = 0.383). For more details cf. Appendix 1. Mean (SD).</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top">Propranolol</th><th valign="top">Placebo</th><th valign="top">Amisulpride</th><th valign="top"/></tr></thead><tbody><tr><td valign="top">Gender (M/F)</td><td valign="top">10/10</td><td valign="top">10/10</td><td valign="top">10/9</td><td valign="top"/></tr><tr><td valign="top">Age</td><td valign="top">22.80 <break/>(3.59)</td><td valign="top">23.80 <break/>(4.23)</td><td valign="top">23.05 <break/>(3.01)</td><td valign="top">F(2,56) = 0.404, <break/>p = 0.669, <inline-formula><mml:math id="inf271"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.014</td></tr><tr><td valign="top">Intellectual abilities</td><td valign="top">22.8 <break/>(1.85)</td><td valign="top">22.6 <break/>(3.70)</td><td valign="top">24.37 <break/>(2.45)</td><td valign="top">F(2,56) = 2.337, <break/>p = 0.106, <inline-formula><mml:math id="inf272"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.077</td></tr><tr><td valign="top">Positive affect</td><td valign="top">24.55 <break/>(8.99)</td><td valign="top">28.90 <break/>(7.56)</td><td valign="top">29.58 <break/>(10.21)</td><td valign="top">F(2,56) = 1.832, <break/>p = 0.170, <inline-formula><mml:math id="inf273"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.061</td></tr><tr><td valign="top">Negative affect</td><td valign="top">10.65 <break/>(.81)</td><td valign="top">12.75 <break/>(3.63)</td><td valign="top">11.16 <break/>(1.71)</td><td valign="top">F(2,56) = 4.259, <break/>p = 0.019, <inline-formula><mml:math id="inf274"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.132</td></tr></tbody></table></table-wrap><table-wrap id="app2table2" position="float"><label>Appendix 2—table 2.</label><caption><title>Physiological effects on drug groups.</title><p>The drug groups also differed in post-experiment heart rate, driven by lower values in the propranolol group (pairwise comparisons: placebo vs propranolol: t(55)=3.5, p = 0.001, d = 1.293; amisulpride vs placebo: t(55) = −0.394, p = 0.695, d = 0.119; amisulpride vs propranolol: t(55)=3.013, p = 0.004, d = 0.921). For detailed statistics and analysis accounting for this cf. Appendix 1. Mean (SD).</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2" valign="top"/><th valign="top">Propranolol</th><th valign="top">Placebo</th><th valign="top">Amisulpride</th><th valign="top"/></tr></thead><tbody><tr><td rowspan="3" valign="top">Heart rate (BPM)</td><td valign="top">At arrival</td><td valign="top">74.9 <break/>(10.8)</td><td valign="top">77,2 <break/>(12,6)</td><td valign="top">77.7 <break/>(13.8)</td><td valign="top">F(2, 55) = 0.290, <break/>p = 0.749, <inline-formula><mml:math id="inf275"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.010</td></tr><tr><td valign="top">Pre-task</td><td valign="top">62,6 <break/>(8,5)</td><td valign="top">65,8 <break/>(8,3)</td><td valign="top">64,6 <break/>(9,8)</td><td valign="top">F(2, 55) = 0.667, <break/>p = 0.517, <inline-formula><mml:math id="inf276"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> =0.024</td></tr><tr><td valign="top">Post-task</td><td valign="top">55,7 <break/>(6,7)</td><td valign="top">64,4 <break/>(6,9)</td><td valign="top">63,4 <break/>(10,0)</td><td valign="top">F(2, 55) = 7.249, <break/>p = 0.002, <inline-formula><mml:math id="inf277"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.209</td></tr><tr><td rowspan="3" valign="top">Systolic blood pressure</td><td valign="top">At arrival</td><td valign="top">117,2 <break/>(10,4)</td><td valign="top">115,0 <break/>(9,7)</td><td valign="top">117,9 <break/>(9,7)</td><td valign="top">F(2, 55) = 0.438, <break/>p = 0.648, <inline-formula><mml:math id="inf278"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.016</td></tr><tr><td valign="top">Pre-task</td><td valign="top">109,4 <break/>(9,2)</td><td valign="top">111,8 <break/>(8,6)</td><td valign="top">114,9 <break/>(8,6)</td><td valign="top">F(2, 55) = 1.841, <break/>p = 0.168, <inline-formula><mml:math id="inf279"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.063</td></tr><tr><td valign="top">Post-task</td><td valign="top">109,5 <break/>(8,2)</td><td valign="top">113,9 <break/>(11,3)</td><td valign="top">114,6 <break/>(9,3)</td><td valign="top">F(2, 55) = 1.584, <break/>p = 0.214, <inline-formula><mml:math id="inf280"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.054</td></tr><tr><td rowspan="3" valign="top">Diastolic blood pressure</td><td valign="top">At arrival</td><td valign="top">71,5 <break/>(7,8)</td><td valign="top">71,2 <break/>(6,7)</td><td valign="top">72,3 <break/>(6,7)</td><td valign="top">F(2, 55) = 0.115, <break/>p = 0.891, <inline-formula><mml:math id="inf281"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.004</td></tr><tr><td valign="top">Pre-task</td><td valign="top">68,3 <break/>(7,0)</td><td valign="top">71,1 <break/>(10,6)</td><td valign="top">72,0 <break/>(5,9)</td><td valign="top">F(2, 55) = 1.111, <break/>p = 0.337, <inline-formula><mml:math id="inf282"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.039</td></tr><tr><td valign="top">Post-task</td><td valign="top">70,8 <break/>(7,3)</td><td valign="top">70,9 <break/>(8,0)</td><td valign="top">70,3 <break/>(6,6)</td><td valign="top">F(2, 55) = 0.037, <break/>p = 0.964, <inline-formula><mml:math id="inf283"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.001</td></tr></tbody></table></table-wrap><table-wrap id="app2table3" position="float"><label>Appendix 2—table 3.</label><caption><title>Table of statistics and behavioural values of <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title><p>All of those measures were modulated by the horizon condition.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2"/><th rowspan="2">Horizon</th><th rowspan="2">Mean (sd)</th><th>Two-way repeated-measures ANOVA</th></tr><tr><th>Main effect of horizon</th></tr></thead><tbody><tr><td rowspan="2">Expected value</td><td>Short</td><td>6.368 (0.335)</td><td rowspan="2">F(1, 56) = 19.457, <break/>p&lt;0.001, <inline-formula><mml:math id="inf284"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.258</td></tr><tr><td>Long</td><td>6.221 (0.379)</td></tr><tr><td rowspan="2">Initial samples</td><td>Short</td><td>1.282 (0.247)</td><td rowspan="2">F(1, 56) = 58.78, <break/>p&lt;0.001, <inline-formula><mml:math id="inf285"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.512</td></tr><tr><td>Long</td><td>1.084 (0.329)</td></tr><tr><td rowspan="2">Score (first sample)</td><td>Short</td><td>5.904 (0.192)</td><td rowspan="2">F(1, 56) = 58.78, <break/>p&lt;0.001, <inline-formula><mml:math id="inf286"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.512</td></tr><tr><td>Long</td><td>5.82 (0.182)</td></tr><tr><td rowspan="2">Score (average)</td><td>Short</td><td>5.904 (0.192)</td><td rowspan="2">F(1, 56) = 103.759, <break/>p&lt;0.001, <inline-formula><mml:math id="inf287"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.649</td></tr><tr><td>Long</td><td>6.098 (0.222)</td></tr></tbody></table></table-wrap><table-wrap id="app2table4" position="float"><label>Appendix 2—table 4.</label><caption><title>Table of statistics and behavioural measure values of <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title><p>The drug groups differed in low-value bandit picking frequency (pairwise comparisons: placebo vs propranolol: t(40) = 2.923, p = 0.005, d = 0.654; amisulpride vs placebo: t(38) = -0.587, p = 0.559, d = 0.133; amisulpride vs propranolol: t(38)=2.171, p = 0.034, d = 0.496) and choice consistency (placebo vs propranolol: t(40) = -3.525, p = 0.01, d = 0.788; amisulpride vs placebo: t(38) = 1.107, p = 0.272, d = 0.251; amisulpride vs propranolol: t(38) = -2.267, p = 0.026, d = 0.514). The main effect is either of drug group (D) or of horizon (H). The interaction is either drug-by-horizon (DH) or horizon-by-WASI (measure of IQ; HW).</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2"/><th/><th colspan="3">Mean (sd)</th><th colspan="4">Two-way repeated-measures ANOVA</th></tr><tr><th>Horizon</th><th>Amisulpride</th><th>Placebo</th><th>Propranolol</th><th colspan="2">Main effect</th><th colspan="2">Interaction</th></tr></thead><tbody><tr><td rowspan="2">High-value bandit</td><td>Short</td><td>54.55 <break/>(8.87)</td><td>49.38 <break/>(9.10)</td><td>50.98 <break/>(11.4)</td><td>D</td><td>F(2, 54) <break/>= 1.388, <break/>p = 0.258, <break/><inline-formula><mml:math id="inf288"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.049</td><td>DH</td><td>F(2, 54) <break/>= 0.834, <break/>p = 0.440, <break/><inline-formula><mml:math id="inf289"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.030</td></tr><tr><td>Long</td><td>41.90 <break/>(8.47)</td><td>44.10 <break/>(13.88)</td><td>41.90 <break/>(13.57)</td><td>H</td><td>F(1, 54) <break/>= 3.909, <break/>p = 0.053, <break/><inline-formula><mml:math id="inf290"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.068</td><td>HW</td><td>F(1, 54) <break/>= 13.304, <break/>p = 0.001, <break/><inline-formula><mml:math id="inf291"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.198</td></tr><tr><td rowspan="2">Low-value bandit</td><td>Short</td><td>3.32 <break/>(2.33)</td><td>4.28 <break/>(2.98)</td><td>2.50 <break/>(2.48)</td><td>D</td><td>F(2, 54) <break/>= 7.003, <break/>p = 0.002, <break/><inline-formula><mml:math id="inf292"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.206</td><td>DH</td><td>F(2, 54) <break/>= 2.154, <break/>p = 0.126, <break/><inline-formula><mml:math id="inf293"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.074</td></tr><tr><td>Long</td><td>5.45 <break/>(3.76)</td><td>5.35 <break/>(3.40)</td><td>3.45 <break/>(2.18)</td><td>H</td><td>F(1, 54) <break/>= 4.069, <break/>p = 0.049, <break/><inline-formula><mml:math id="inf294"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.070</td><td>HW</td><td>F(1, 54) <break/>= 1.199, <break/>p = 0.278, <break/><inline-formula><mml:math id="inf295"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.022</td></tr><tr><td rowspan="2">Novel bandit</td><td>Short</td><td>36.87 <break/>(9.49)</td><td>39.02 <break/>(10.94)</td><td>40.15 <break/>(12.43)</td><td>D</td><td>F(2, 54) <break/>= 1.498, <break/>p = 0.233, <break/><inline-formula><mml:math id="inf296"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.053</td><td>DH</td><td>F(2, 54) <break/>= 0.542, <break/>p = 0.584, <break/><inline-formula><mml:math id="inf297"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.020</td></tr><tr><td>Long</td><td>46.82 <break/>(12.1)</td><td>43.62 <break/>(16.27)</td><td>48.55 <break/>(16.59)</td><td>H</td><td>F(1, 54) <break/>= 5.593, <break/>p = 0.022, <break/><inline-formula><mml:math id="inf298"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.094</td><td>HW</td><td>F(1, 54) <break/>= 13.897, <break/>p&lt;0.001, <break/><inline-formula><mml:math id="inf299"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.205</td></tr><tr><td rowspan="2">Consistency</td><td>Short</td><td>64.16 <break/>(12.27)</td><td>62.70 <break/>(12.59)</td><td>73.00 <break/>(11.33)</td><td>D</td><td>F(2, 54) <break/>= 7.154, <break/>p = 0.002, <break/><inline-formula><mml:math id="inf300"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.209</td><td>DH</td><td>F(2, 54) <break/>= 3.352, <break/>p = 0.042, <break/><inline-formula><mml:math id="inf301"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.110</td></tr><tr><td>Long</td><td>68.11 <break/>(10.34)</td><td>64.00 <break/>(8.93)</td><td>70.55 <break/>(9.91)</td><td>H</td><td>F(1, 54) <break/>= 1.333, <break/>p = 0.253, <break/><inline-formula><mml:math id="inf302"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.024</td><td>HW</td><td>F(1, 54) <break/>= 0.409, <break/>p = 0.525, <break/><inline-formula><mml:math id="inf303"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.008</td></tr></tbody></table></table-wrap><table-wrap id="app2table5" position="float"><label>Appendix 2—table 5.</label><caption><title>Table of parameters used for each model compared during model selection (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</title><p>Each of the 12 columns indicate a model. The three ‘main models’ studied were the Thompson model, the UCB model and a hybrid of both. Variants were then created by adding the <inline-formula><mml:math id="inf304"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter, the novelty bonus and a combination of both. All the parameters besides <inline-formula><mml:math id="inf305"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and w were fitted to each horizon separately. Parameters: <inline-formula><mml:math id="inf306"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> = prior mean (initial estimate of a bandits mean); <inline-formula><mml:math id="inf307"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> = prior variance (uncertainty about <inline-formula><mml:math id="inf308"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>;</mml:mo></mml:math></inline-formula> <inline-formula><mml:math id="inf309"><mml:mi>w</mml:mi></mml:math></inline-formula> = contribution of UCB vs Thompson; <inline-formula><mml:math id="inf310"><mml:mi>γ</mml:mi></mml:math></inline-formula> = information bonus; <inline-formula><mml:math id="inf311"><mml:mi>β</mml:mi></mml:math></inline-formula> = softmax inverse temperature; <inline-formula><mml:math id="inf312"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> = <inline-formula><mml:math id="inf313"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter (stochasticity); <inline-formula><mml:math id="inf314"><mml:mi>η</mml:mi></mml:math></inline-formula> = novelty bonus. Model selection measures include the cross-validation held-out data likelihood averaged over subjects, mean (SD), as well as the subject count for which this model performed better over either 12 models or over the 3 best models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2"/><th rowspan="2">Model</th><th colspan="4">Thompson</th><th colspan="4">UCB</th><th colspan="4">Hybrid</th></tr><tr><th/><th>+ϵ</th><th>+η</th><th>+ϵ+η</th><th/><th>+ϵ</th><th>+η</th><th>+ϵ+η</th><th/><th>+ϵ</th><th>+η</th><th>+ϵ+η</th></tr></thead><tbody><tr><td rowspan="2">Parameters</td><td>Horizon independent</td><td><inline-formula><mml:math id="inf315"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf316"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf317"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf318"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf319"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf320"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf321"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf322"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf323"><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf324"><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf325"><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf326"><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td></tr><tr><td>Horizon dependent</td><td><inline-formula><mml:math id="inf327"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf328"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi/></mml:math></inline-formula> ϵ</td><td><inline-formula><mml:math id="inf329"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>η</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf330"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi/></mml:math></inline-formula> ϵ,η</td><td><inline-formula><mml:math id="inf331"><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf332"><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> ϵ</td><td><inline-formula><mml:math id="inf333"><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> η</td><td><inline-formula><mml:math id="inf334"><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> <break/>ϵ,η</td><td><inline-formula><mml:math id="inf335"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf336"><mml:mi>β</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf337"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf338"><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi/></mml:math></inline-formula> ϵ</td><td><inline-formula><mml:math id="inf339"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf340"><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf341"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf342"><mml:mi>β</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> <break/>ϵ,η</td></tr><tr><td rowspan="3">Model selection</td><td>Mean held-out data likelihood</td><td>550.2 (8.1)</td><td>552.7 (7.1)</td><td>552,2 (8.7)</td><td>555.3 (8.4)</td><td>552.9 (8.0)</td><td>552.9 (8.0)</td><td>553.4 (8.1)</td><td>555.1 (8.8)</td><td>553.5 (8.1)</td><td>553.8 (8.4)</td><td>555.0 <break/>(8.4)</td><td>555.1 (8.5)</td></tr><tr><td>Subjects for which model fits best (out of 12)</td><td>0</td><td>3</td><td>2</td><td>20</td><td>0</td><td>0</td><td>1</td><td>20</td><td>0</td><td>0</td><td>7</td><td>6</td></tr><tr><td>Subjects for which model fits best (out of 3 best)</td><td>-</td><td>-</td><td>-</td><td>27</td><td>-</td><td>-</td><td>-</td><td>22</td><td>-</td><td>-</td><td>-</td><td>10</td></tr></tbody></table></table-wrap><table-wrap id="app2table6" position="float"><label>Appendix 2—table 6.</label><caption><title>Table of statistics and fitted model parameters of <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title><p>The drug groups differed in <inline-formula><mml:math id="inf343"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>-greedy parameter value (pairwise comparisons: placebo vs propranolol: t(40) = 3.177, p = 0.002, d =0 .71; amisulpride vs placebo: t(38) = 0.251, p = 0.802, d = 0.057; amisulpride vs propranolol: t(38) = 2.723, p = 0.009, d = 0.626). The main effect is either of drug group (D) or of horizon (H). The interaction is either drug-by-horizon (DH) or horizon-by-WASI (measure of IQ; HW).</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2"/><th/><th colspan="3">Mean (sd)</th><th colspan="4">Two-way repeated-measures ANOVA</th></tr><tr><th>Horizon</th><th>Amisulpride</th><th>Placebo</th><th>Propranolol</th><th colspan="2">Main effect</th><th colspan="2">Interaction</th></tr></thead><tbody><tr><td rowspan="2"><inline-formula><mml:math id="inf344"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-greedy parameter</td><td>Short</td><td>0.10 <break/>(0.10)</td><td>0.12 <break/>(0.08)</td><td>0.07 <break/>(0.08)</td><td>D</td><td>F(2, 54) <break/>= 6.722, <break/>p = 0.002, <break/><inline-formula><mml:math id="inf345"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.199</td><td>DH</td><td>F(2, 54) <break/>= 1.305, <break/>p = 0.280, <break/><inline-formula><mml:math id="inf346"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.046</td></tr><tr><td>Long</td><td>0.17 <break/>(0.14)</td><td>0.14 <break/>(0.10)</td><td>0.08 <break/>(0.06)</td><td>H</td><td>F(1, 54) <break/>= 1.968, <break/>p = 0.166, <break/><inline-formula><mml:math id="inf347"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.035</td><td>HW</td><td>F(1, 54) <break/>= 6.08, <break/>p = 0.017, <break/><inline-formula><mml:math id="inf348"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.101</td></tr><tr><td rowspan="2">Novelty bonus <inline-formula><mml:math id="inf349"><mml:mi>η</mml:mi></mml:math></inline-formula></td><td>Short</td><td>2.07 <break/>(0.98)</td><td>2.26 <break/>(1.37)</td><td>2.05 <break/>(1.16)</td><td>D</td><td>F(2, 54) <break/>= 0.249, <break/>p = 0.780, <break/><inline-formula><mml:math id="inf350"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.009</td><td>DH</td><td>F(2, 54) <break/>= 0.03, <break/>p = 0.971, <break/><inline-formula><mml:math id="inf351"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.001</td></tr><tr><td>Long</td><td>3.24 <break/>(1.19)</td><td>3.12 <break/>(1.63)</td><td>2.95 <break/>(1.70)</td><td>H</td><td>F(1, 54) <break/>= 1.839, <break/>p = 0.181, <break/><inline-formula><mml:math id="inf352"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.033</td><td>HW</td><td>F(1, 54) <break/>= 8.416, <break/>p = 0.005, <break/><inline-formula><mml:math id="inf353"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.135</td></tr><tr><td rowspan="2">Prior variance <inline-formula><mml:math id="inf354"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td>Short</td><td>1.18 <break/>(0.20)</td><td>1.12 <break/>(0.43)</td><td>1.25 <break/>(0.34)</td><td>D</td><td>F(2, 54) <break/>= 0.060, <break/>p = 0.942, <break/><inline-formula><mml:math id="inf355"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.002</td><td>DH</td><td>F(2, 54) <break/>= 2.162, <break/>p = 0.125, <break/><inline-formula><mml:math id="inf356"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> =0.074</td></tr><tr><td><bold>L</bold>ong</td><td>1.41 <break/>(0.61)</td><td>1.42 <break/>(0.59)</td><td>1.21 <break/>(0.44)</td><td>H</td><td>F(1, 54) <break/>= 0.129, <break/>p = 0.721, <break/><inline-formula><mml:math id="inf357"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.002</td><td>HW</td><td>F(1, 54) <break/>= 0.022, <break/>p = 0.882, <break/><inline-formula><mml:math id="inf358"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> &lt; 0.001</td></tr><tr><td>Prior mean <inline-formula><mml:math id="inf359"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td/><td>3.22 <break/>(1.05)</td><td>3.20 <break/>(1.36)</td><td>3.44 <break/>(1.05)</td><td>D</td><td colspan="3">F(2, 54) = 0.118, p = 0.889, <inline-formula><mml:math id="inf360"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> = 0.004</td></tr></tbody></table></table-wrap><table-wrap id="app2table7" position="float"><label>Appendix 2—table 7.</label><caption><title>Parameter values used for simulations on <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>–<xref ref-type="fig" rid="fig1s5">5</xref>.</title><p>Parameter values for high and low exploration were selected empirically from pilot and task data. Value-free random exploration and novelty exploration were simulated with an argmax decision function, which always selects the value with the highest expected value. For simulating the long (versus short) horizon condition, we assumed that not only the key value but also the other exploration strategies increased, as found in our experimental data. For each simulation Q<sub>0</sub> = 5 and unless otherwise stated, <inline-formula><mml:math id="inf361"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn><mml:mo>.</mml:mo></mml:math></inline-formula></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Horizon</th><th>Low exploration</th><th>High exploration</th><th>Additional parameters</th></tr></thead><tbody><tr><td rowspan="2">Value-free random exploration</td><td>Short</td><td>ϵ = 0.1</td><td>ϵ = 0.2</td><td><inline-formula><mml:math id="inf362"><mml:mi>η</mml:mi></mml:math></inline-formula> = 0</td></tr><tr><td>Long</td><td>ϵ = 0.3</td><td>ϵ = 0.4</td><td><inline-formula><mml:math id="inf363"><mml:mi>η</mml:mi></mml:math></inline-formula> = 2</td></tr><tr><td rowspan="2">Novelty exploration</td><td>Short</td><td><inline-formula><mml:math id="inf364"><mml:mi>η</mml:mi></mml:math></inline-formula> = 0</td><td><inline-formula><mml:math id="inf365"><mml:mi>η</mml:mi></mml:math></inline-formula> = 1</td><td>ϵ = 0</td></tr><tr><td>Long</td><td><inline-formula><mml:math id="inf366"><mml:mi>η</mml:mi></mml:math></inline-formula> = 2</td><td><inline-formula><mml:math id="inf367"><mml:mi>η</mml:mi></mml:math></inline-formula> = 3</td><td>ϵ = 0.2</td></tr><tr><td rowspan="2">Thompson-sampling exploration</td><td>Short</td><td><inline-formula><mml:math id="inf368"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> = 0.8</td><td><inline-formula><mml:math id="inf369"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> = 1.2</td><td><inline-formula><mml:math id="inf370"><mml:mi>η</mml:mi></mml:math></inline-formula> = 0, ϵ = 0</td></tr><tr><td>Long</td><td><inline-formula><mml:math id="inf371"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> = 1.6</td><td><inline-formula><mml:math id="inf372"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> = 2</td><td><inline-formula><mml:math id="inf373"><mml:mi>η</mml:mi></mml:math></inline-formula> = 2, ϵ = 0.2</td></tr><tr><td rowspan="2">UCB exploration</td><td>Short</td><td><inline-formula><mml:math id="inf374"><mml:mi>γ</mml:mi></mml:math></inline-formula> = 0.1</td><td><inline-formula><mml:math id="inf375"><mml:mi>γ</mml:mi></mml:math></inline-formula> = 0.3</td><td><inline-formula><mml:math id="inf376"><mml:mi>β</mml:mi></mml:math></inline-formula> = 5, ϵ = 0</td></tr><tr><td>Long</td><td><inline-formula><mml:math id="inf377"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.7</td><td><inline-formula><mml:math id="inf378"><mml:mi>γ</mml:mi></mml:math></inline-formula> = 1.5</td><td><inline-formula><mml:math id="inf379"><mml:mi>β</mml:mi></mml:math></inline-formula> = 1.5, ϵ = 0.2</td></tr></tbody></table></table-wrap></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.59907.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Kahnt</surname><given-names>Thorsten</given-names></name><role>Reviewing Editor</role><aff><institution>Northwestern University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Warren</surname><given-names>Christopher</given-names> </name><role>Reviewer</role><aff><institution>Utah State</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>How individuals decide to exploit known options or to explore alternatives with unknown payouts is a fundamental question in neuroscience. This study combines human pharmacology and computational modeling to disentangle the role of two neurotransmitters (noradrenaline and dopamine) in driving different exploration strategies. Results show that value-independent &quot;random&quot; exploration heuristics are mediated by noradrenaline. These findings contribute to a better understanding of the neural processes involved in the exploration-exploitation trade-off.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Noradrenaline modulates tabula-rasa exploration&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by Christian Büchel as the Senior Editor, a Reviewing Editor, and three reviewers. The following individual involved in review of your submission has agreed to reveal their identity: Christopher Warren (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Dubois and colleagues investigate how two modes of exploration – tabula-rasa and novelty-seeking – contribute to human choice behavior. They found that subjects used both tabula-rasa and novelty-seeking heuristics when the task conditions were in favor of exploration. Specifically, participants could, and had to, make more responses in the long-horizon condition, which favored exploration, compared to the short-horizon condition, which favored exploitation. Moreover, the authors provide evidence that blockade of norepinephrine β receptors leads to decreased tabula-rasa exploration and increased choice consistency, whereas blockage of D2/D3 dopamine receptors had little effects.</p><p>All reviewers agreed that this paper provides interesting evidence on exploration-exploitation trade-offs and the underlying pharmacological mechanisms. However, reviewers felt that there are a number of major conceptual, methodological and interpretational issues that should be addressed in a revised version of the manuscript.</p><p>Essential revisions:</p><p>1) The term &quot;tabula rasa&quot; exploration is slightly misleading and using &quot;random&quot; exploration would be simpler, and clearer. That is, &quot;tabula rasa&quot; has the connotation that both the current &quot;tabula rasa&quot; choice and all future choices will not take into account information obtained before that choice. Random exploration is a better term because it is easy and intuitive to see that random choices can be sprinkled in with choices based on previous information, whereas &quot;tabular rasa&quot; implies wiping previous information away from that point forward. Indeed, previous related work has not termed the random exploration associated with the e-greedy parameter &quot;tabula rasa&quot;. Problematic in this regard is that there is another parameter in one or more of the models that reflects random exploration (Subsection “Choice rules”, inverse temperature). This may be why the authors opted to call the e-greedy parameter something else. However, this raises the question: what is the difference between the e-greedy parameter and the inverse temperature mathematically, but more importantly, conceptually? At the very least, it would be important to provide a better explanation of the choice of term (tabula rasa) as well as a thorough explanation of the difference between tabula rasa and random exploration. We also recommend changing the term used, but we are amenable to accepting an argument for keeping it.</p><p>2) It is one thing to come up with computational terms and model-based quantities correlating with behavior but a different one to show their psychological meaning. Did the trials with tabula-rasa exploration or novelty exploration differ in terms of response times from the other types of responses? Did participants report that they indeed intended to explore in the tabula-rasa exploration trials? On a related note, how do the authors distinguish random (tabula-rasa) exploration from making a mistake? From how the task was designed, choosing the low value option appears to receive a more natural interpretation as a mistake rather than as exploration because this option was clearly dominated by the other options and remained so within and across trials.</p><p>3) Relatedly, successful performance in the task is based on the ability to discriminate between different reward types and to select the one with the higher value. From the experimental design description, one can see that in order to do so, the subjects needed to distinguish between different apple sizes. In this regard, a question arises: how large was the difference between two adjacent apple sizes? Was it large enough so that after a visual inspection, the participant could easily understand that the apple size = 7 was less rewarding than the apple size = 8? Finally, since the task requires visual inspection of reward stimuli, was the subject vision somehow tested and did it differ between groups?</p><p>4) Previous research of the authors (Hauser et al., 2017, 2018, 2019) has associated β receptor blockade with enhanced metacognition, decreased information gathering/increased commitment to an early decision (Hauser et al., 2018) and an arousal (i.e., reward)-induced boost of processing stimuli. In addition, Rogers et al., (2004) suggest that propranolol affects the processing of possible losses in decision-making paradigms, and might also reduce the discrimination between the different levels of possible gains (Rogers et al. 2004). In another study, Sokol-Hessner et al., (2015) also report a loss aversion reduction after propranolol administration. These effects might also change prior information and reset behavioral adaption to look for new opportunities. In this latter study the authors also report a lack of effect of propranolol onto choice consistency, contrary to what the present study reports. How do the current results relate to these previous findings? Of course, it is possible that norepinephrine plays multiple roles, but it appears not exactly parsimonious to imbue it with a different role for each task tested. Are there some commonalities across these effects that could be explained with some common function(s)?</p><p>5) Previous studies have shown that propranolol significantly decreased heart rate (e.g. Rogers et al., 2004). Did the authors measure heart rate and can they control for the possibility that peripheral effects of the drug explain the findings? And what was the reason for not collecting pupil diameter data, contrary to the previous research of the authors? Relatedly, in terms of norepinephrine influence and given the distributions of β receptors, could the authors be more explicit about the relation of their work to potential mechanisms (e.g. Goldman-Rakic et al., 1990 or Waterhouse et al., 1982)?</p><p>6) One strength of the paper is that the authors compared several computational models. The model selection is presented in Figure 4 and in Figure 4—figure supplement 1, the authors provide additional information regarding the winning model that accounted best for the largest number of subjects in comparison with two other models, namely the UCB model (with novelty and greedy parameters) or hybrid (with novelty and greedy parameters). It would be useful for the reader to get a better sense about the number of subjects which results favored any given model (i.e. a more exhaustive picture). One could use the same table as the one presented as in the Appendix—table 2 with respective number of subjects for which the model achieved the best performance. In fact, as shown in Figure 4, the winning model does not look very different (at least visually) from other models such as UCB (with novelty and greedy parameters) or hybrid (with novelty parameter or novelty and greedy parameters) models. As such, it would be important to know whether the conclusion about the e-greedy parameter would hold true if other model with similar performance were tested e.g. with UCB model (with novelty and greedy parameters) or hybrid (with novelty and greedy parameters)?</p><p>7) Related to this issue, the point of heuristics from a psychological perspective is that they dispense with the need to use full-blown algorithmic calculations. However, in the present models, the heuristics are only added on top of these calculations and the winning model includes Thompson exploration. Stand-alone heuristic models would do the term more justice and one wonders how well a model would fare that includes only tabula rasa exploration and novelty exploration.</p><p>8) The simulations provide a nice intuition for understanding choice proportions from different models/strategies (Figure 1E and 1F). However, it would be helpful to provide simulated results for long and short horizons separately. Do the models make different predictions for the two horizons? Additionally, it would be helpful to also show the results from other models (i.e. the proportion of low value bandit chosen by novelty agent). These could be added in the supplement.</p><p>[Editors” note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your article &quot;Human complex exploration strategies are extended via noradrenaline-modulated heuristics&quot; for consideration by <italic>eLife</italic>. Your revised article has been reviewed by Christian Büchel as the Senior Editor, a Reviewing Editor, and three reviewers. The following individual involved in review of your submission has agreed to reveal their identity: Christopher Warren (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, we are asking editors to accept without delay manuscripts, like yours, that they judge can stand as <italic>eLife</italic> papers without additional data, even if they feel that they would make the manuscript stronger. Thus the revisions requested below only address clarity and presentation.</p><p>Summary:</p><p>The authors have been very responsive to the initial reviews and reviewers feel that the paper is much improved. However, a few points remain. Please address the remaining issues raised by reviewer #1 and #2 and submit a revised version of the manuscript.</p><p><italic>Reviewer #1:</italic></p><p>Thank you for a largely responsive revision. The paper is much improved. A few points remain:</p><p>Related to previous point 1, the argument in subsection “Probing the contributions of heuristic exploration strategies” does not seem to be entirely correct. The authors claim that &quot;A second prediction is that choice consistency, across repeated trials, is substantially affected by value-free random exploration.&quot; However, consistency can also be affected by the softmax parameter. If β is higher then choice consistency is also lower. Also, I am a little bit confused about the simulation results in Figure 1—figure supplement 2E,F. Do both models predict that the consistency of selecting the low value bandit is higher than the consistency of selecting the high value bandit? In line with the argument that higher β also lead to more stochastic choices, I also wonder if that can be the reason why UCB and UCB+𝜖 are not that much different in likelihood.</p><p>Regarding previous point 2: Were response time differences between value-free exploration and exploitation trials larger in the long horizon than the short horizon condition (i.e., while there was no main effect of bandit, was there an interaction with horizon or trial within horizon and was there a three-way interaction with drug)? Moreover, the response to the mistake issue is not entirely satisfactory. If participants paid (gradually) less attention in the long horizon, then it would also be expected that they make more mistakes in the long horizon condition only.</p><p>Regarding previous point 8, it is great that the authors followed our suggestion to simulate all models in both the short and long horizon. However, these figures (Figure 1—figure supplement 3 to Figure 1—figure supplement 5) seem to be somewhat confusing. The problem may lie in the parameters selected for simulation. According to Appendix 2—table 7, the multiple parameters were varied among different models. But I thought they should keep most consistent and only vary the interesting one. For example, shouldn't 𝜂 be kept same or even be zero in the value free random exploration model to show how choices are vary as function of 𝜖? I think the numbers are selected such that the predictions favor the value free random exploration model. If, as authors said, UCB + 𝜖 + 𝜂 is almost as good as Thompson-sampling + 𝜖 + 𝜂, I don’t see what the predictions can be such dramatically different. That is how I interpret the statement that &quot; For simulating the long (versus short) horizon condition, we assumed that not only the key value but also the other exploration strategies increased, as found in our experimental data.&quot; Anyway, I feel the simulation data is somehow misleading and need more explanation.</p><p><italic>Reviewer #2:</italic></p><p>The authors addressed all my comments and made substantial revisions that have strengthened the overall manuscript. Specifically, the new information in Appendix—table 4 with each model's performance and additional analyses on of the other &quot;(close to best)&quot; models further strengthens the authors' claim. The authors also clarified the results on heart rate, RT and PANAS questionnaire, providing additional results and discussing appropriately potential caveats. Further additions in the Discussion address potential mechanisms of propranolol on decision making. The only comment I have relates to the sentence that follows (in the Discussion): “In particular, the results indicate that under propranolol behaviour is more deterministic and less influenced by “task-irrelevant” distractions. This aligns with theoretical ideas, as well as recent optogenetic evidence (32), that propose noradrenaline infuses noise in a temporally targeted way (31). It also accords with studies implicating noradrenaline in attention shifts (for a review cf. (76)). Other theories of noradrenaline/catecholamine function can link to determinism (64, 65), although the hypothesized direction of effect is different (i.e. noradrenaline increases determinism).&quot; Here, it is unclear to me how the authors define determinism and how either increasing or decreasing noradrenaline can increase determinism?</p><p>Apart from that, the manuscript is well-written and provides an interesting account about the role of neuromodulatory systems on the processes at play during exploration.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.59907.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Summary:</p><p>Dubois and colleagues investigate how two modes of exploration – tabula-rasa and novelty-seeking – contribute to human choice behavior. They found that subjects used both tabula-rasa and novelty-seeking heuristics when the task conditions were in favor of exploration. Specifically, participants could, and had to, make more responses in the long-horizon condition, which favored exploration, compared to the short-horizon condition, which favored exploitation. Moreover, the authors provide evidence that blockade of norepinephrine β receptors leads to decreased tabula-rasa exploration and increased choice consistency, whereas blockage of D2/D3 dopamine receptors had little effects.</p><p>All reviewers agreed that this paper provides interesting evidence on exploration-exploitation trade-offs and the underlying pharmacological mechanisms. However, reviewers felt that there are a number of major conceptual, methodological and interpretational issues that should be addressed in a revised version of the manuscript.</p></disp-quote><p>We thank the editors and reviewers for their positive evaluation of our manuscript and appreciate the helpful suggestions. We have now addressed all raised concerns and conducted substantial additional analyses in light of these comments.</p><p>In short, we have conducted analysis of physiological measures and have analysed our data with the relevant covariates. We have also analysed, in greater depth, the second and third best models in the computational modelling. We have also tested new models, run substantial additional model simulations, behavioural analyses, and analysed reaction times.</p><p>Regarding the text, we have clarified the manuscript by replacing the name “tabula-rasa” exploration with “value-free random” exploration and adapting the drug group names according to the reviewers’ suggestions. Moreover, we now provide substantial data simulations/illustrations to illustrate further the different exploration mechanisms. Lastly, we have expanded the discussion taking account of all the reviewers’ constructive suggestions. Importantly, all new analyses support our original Results and we believe this strengthens further the paper. We report key new results in the revised manuscript and trust that it meets the rigorous standards of your journal.</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The term &quot;tabula rasa&quot; exploration is slightly misleading and using &quot;random&quot; exploration would be simpler, and clearer. That is, &quot;tabula rasa&quot; has the connotation that both the current &quot;tabula rasa&quot; choice and all future choices will not take into account information obtained before that choice. Random exploration is a better term because it is easy and intuitive to see that random choices can be sprinkled in with choices based on previous information, whereas &quot;tabular rasa&quot; implies wiping previous information away from that point forward. Indeed, previous related work has not termed the random exploration associated with the e-greedy parameter &quot;tabula rasa&quot;. Problematic in this regard is that there is another parameter in one or more of the models that reflects random exploration (subsection “Choice rules”, inverse temperature). This may be why the authors opted to call the e-greedy parameter something else. However, this raises the question: what is the difference between the e-greedy parameter and the inverse temperature mathematically, but more importantly, conceptually? At the very least, it would be important to provide a better explanation of the choice of term (tabula rasa) as well as a thorough explanation of the difference between tabula rasa and random exploration. We also recommend changing the term used, but we are amenable to accepting an argument for keeping it.</p></disp-quote><p>We thank the reviewer for raising this relevant point. We apologise for using a potentially misleading term. We chose the term “tabula-rasa” to distinguish it from other forms of stochasticity, such as the modulation of an inverse temperature. We agree that the form of exploration we wish to describe here is a pure form of randomness, one that ignores all available information. However, because “random” exploration has previously been used for inverse temperature related exploration, we refrained from using this term in our original manuscript and instead chose “tabula-rasa” to emphasize the fact that prior beliefs were not taken into account. We agree that tabula-rasa may have a connotation about future use of information, which the reviewer rightly highlights.</p><p>On the above basis we think it best to change the terminology. We now refer to “value-free random exploration” in the revised version of the manuscript, as distinct from “value-based random exploration” (as captured by Thompson sampling or softmax temperature). We believe these revised terms adequately reflect the putative computational mechanisms, whilst also highlighting a difference between them.</p><p>We apologise if the distinction between these two forms of exploration was not clear in the original manuscript. Mathematically, the value-based random exploration is captured by scaling the inverse temperature with the expected values in a softmax algorithm. This means that this form of exploration is still guided by the value of the choice options (hence “value-based”), and it requires an agent to keep track of each expected value that is compared. In contrast, the 𝜖-greedy algorithm ignores choice option values completely in 𝜖% of the time (hence “value-free”). Importantly, the difference between the inverse temperature and the 𝜖-greedy parameter is that the former requires more cognitive resources. We tabulate a summary of the strategies:</p><table-wrap id="resptable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Exploration strategy</th><th>Value-based random exploration</th><th>Value-free random exploration</th></tr></thead><tbody><tr><td><bold>Algorithm</bold></td><td>Softmax</td><td>𝜖-greedy</td></tr><tr><td><bold>Equation</bold></td><td>P (i)=eBVi∑xeBVi</td><td>P(i)={(1−∈)ifi=bestaction∈otherwise</td></tr><tr><td><bold>Free parameters</bold></td><td>𝑉: bandit’s mean <break/>𝛽: inverse temperature</td><td>𝜖: 𝜖-greedy parameter</td></tr><tr><td><bold>Values to compute</bold></td><td>𝑛 (number of bandits)</td><td>0</td></tr></tbody></table></table-wrap><p>Although eventually both strategies increase noise in the decision process, their effect differs. Changing the softmax inverse temperature (cf. Figure 1—figure supplement 2A) affects the slope of the sigmoid, while changing the 𝜖-greedy parameter affects the compression of the sigmoid (cf. Figure 1—figure supplement 2B). Conceptually, in a softmax (value-based random) exploration mode (cf. Figure 1—figure supplement 2C), as each bandit's expected value is taken into account, an agent will still favour the second best bandit (i.e. medium-value bandit) over one with an even lower value (i.e. low-value bandit) when injecting noise. In contrast, in an 𝜖-greedy (value-free random) exploration mode (cf. Figure 1—figure supplement 2D), bandits are explored equally often irrespective of their expected value. This also has a consequence for choice consistency, in value-based random exploration the second best option is most probably explored (i.e. choice is still somehow consistent; cf. Figure 1—figure supplement 2E) versus equal probability of exploring any of the non-optimal options in an 𝜖-greedy (value-free random) exploration mode (i.e. low consistency, cf. Figure 1—figure supplement 2F). Please also see our response to comment 6., where we demonstrate that our effects remain unchanged even when allowing value-based and value-free random exploration to directly compete.</p><p>In addition to changing the name of these exploration strategies in the revised manuscript, we now also provide a more thorough explanation of the difference between the two random exploration strategies and we illustrate the difference in the newly added Figure 1—figure supplement 2.</p><p>Introduction: “An alternative strategy, sometimes termed “random” exploration, is to induce stochasticity after value computations in the decision process. […] Of relevance in this context is a view that exploration strategies depend on dissociable neural mechanisms (21). Influences from noradrenaline and dopamine are plausible candidates in this regard based on prior evidence (9, 22).”</p><disp-quote content-type="editor-comment"><p>2) It is one thing to come up with computational terms and model-based quantities correlating with behavior but a different one to show their psychological meaning. Did the trials with tabula-rasa exploration or novelty exploration differ in terms of response times from the other types of responses? Did participants report that they indeed intended to explore in the tabula-rasa exploration trials? On a related note, how do the authors distinguish random (tabula-rasa) exploration from making a mistake? From how the task was designed, choosing the low value option appears to receive a more natural interpretation as a mistake rather than as exploration because this option was clearly dominated by the other options and remained so within and across trials.</p></disp-quote><p>We thank the reviewers for raising this important point, on which we now elaborate in more detail in the manuscript.</p><p>The key dissociation between value-free random exploration and simply making a mistake is that the former is sensitive to our task (horizon) condition, which would not be expected for mistakes. This means that pure “mistakes” (i.e. independent of any cognitive process) should be equally distributed across all experimental conditions, whereas value-free exploration is deployed more strategically, increasing exploration over a long horizon.</p><p>In our data, we find that value-free exploration increases over the long horizon, i.e. when exploration is more useful (low-value bandit: horizon main effect: F(1, 54)=4.069, p=.049, 𝜂<sup>2</sup>=.070; 𝜖-greedy parameter: horizon-by-WASI interaction: F(1, 54)=6.08, p=.017, 𝜂<sup>2</sup>=.101). Importantly, we since reproduced this horizon effect multiple times across independent studies and cohorts. We found the same horizon effect in children and adolescents (low-value bandit: horizon main effect: F(1, 94)=8.837, p=.004, 𝜂<sup>2</sup>=.086; 𝜖-greedy parameter: horizon main effect: F(1, 94)=20.63, p&lt;.001, 𝜂<sup>2</sup>=.180; Dubois et al., 2020, BioRxiv) as well as in healthy adults online (unpublished pilot data: low-value bandit: t(61)=-3.621, p=.001, d=.46, 95%CI=[-1.615, -.466]; 𝜖-greedy parameter: pilot data: t(61)=-3.286, p=.002, d=.417, 95%CI=[-.058, -.014]). These results demonstrate that this form of exploration is modulated by horizon, which would not be the case if they were simple mistakes.</p><p>Based on the reviewers’ suggestion, we also investigated response times, based on a hypothesis that simple mistakes would lead to faster responses. We did not observe any response times difference between low-value bandit trials and trials in which the high-value bandit (i.e. exploitation) or the novel bandit were chosen (bandit main effect: F(1.78 , 99.44)=1.634 , p=.203 , 𝜂<sup>2</sup>=.028; Figure 3—figure supplement 1). This further speaks against a hypothesis that these choices represent mere mistakes.</p><p>Lastly, it is important to note our finding that value-free random exploration is modulated by propranolol. To our knowledge, previous studies using the same drug (Sokol-Hessner et al., 2015; Campbell-Meiklejohn et al., 2011; Rogers et al., 2004; Hauser et al., 2019) did not report any impact on behavioural features that could be interpreted as “mistakes”. For example, our own previous study did not find an effect of propranolol on choice accuracy (Hauser et al., 2019). Instead, in prior studies propranolol impacted a directed cognitive process, similar to what we find here.</p><p>In line with previous papers on exploration (e.g. Warren et al., 2017; Wilson et al., 2014; Wu et al., 2018; Stojic et al., 2020), for several reasons we did not collect subjects’ reports about their intentions. Firstly, we were concerned this could have biased the task as subjects might feel compelled to focus on exploration, rather than performing the task and earning as much money as possible. This means that exploration might be perceived as a means to satisfy an experimenter’s intentions, rather than harvesting information for later use. Second, it is unclear whether all forms of exploration invoke a conscious representation (and hence are accessible to self-reports). It is possible that associated heuristics might be phylogenetically old, and not represented explicitly. Lastly, seeking subject reports would have either extended the task duration substantially, or reduced the number of trials, both restrictions that we wished to avoid.</p><p>In the revised manuscript, we discuss the psychological meaning of these exploration strategies in more detail with a focus on the dissociation between mistakes and value-free random exploration. We also added the new response latency analyses.</p><p>Discussion: “Value-free random exploration might reflect other influences, such as attentional lapses or impulsive motor responses. […] However, future studies could explore these exploration strategies in more detail including by reference to subjects’ own self-reports.”</p><p>Appendix I: “There was no difference in response times between bandits in the repeated-measures ANOVA (bandit main effect: F(1.78 , 99.44)=1.634 , p=.203 , <inline-formula><mml:math id="inf380"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>=.028; Figure 3—figure supplement 1).”</p><disp-quote content-type="editor-comment"><p>3) Relatedly, successful performance in the task is based on the ability to discriminate between different reward types and to select the one with the higher value. From the experimental design description, one can see that in order to do so, the subjects needed to distinguish between different apple sizes. In this regard, a question arises: how large was the difference between two adjacent apple sizes? Was it large enough so that after a visual inspection, the participant could easily understand that the apple size = 7 was less rewarding than the apple size = 8? Finally, since the task requires visual inspection of reward stimuli, was the subject vision somehow tested and did it differ between groups?</p></disp-quote><p>We agree, this is a relevant point and one we investigated in detail when developing the task. In fact, we originally tested versions with different apple size ranges and based upon this opted for a smaller range of 9 different apple sizes, as our pilots showed that they were easily distinguishable. Moreover, the apples were presented (and remained) next to each other on the screen in the “crate”, so that apple sizes were directly comparable.</p><p>Even though we did not assess the vision of our subjects formally, we only recruited subjects who had (self-reported) normal or corrected-to-normal vision. This is the standard procedure for participant recruitment at the Wellcome Centre for Human Neuroimaging. To assess subjects’ understanding of apple sizes and to confirm normal vision, we conducted extensive training prior to the main experiment, in which they had to categorise different apple sizes. This training was successfully completed by all participants. We have now added this information and Figure 1—figure supplement 1.</p><p>Materials and methods: “Each distribution was truncated to [2, 10], meaning that rewards with values above or below this interval were excluded, resulting in a total of 9 possible rewards (i.e. 9 different apple sizes; cf. Figure 1—figure supplement 1 for a representation). […] In training, based on three displayed apples of similar size, they were tasked to guess between two options, namely which apple was most likely to come from the same tree and then received feedback about their choice.”</p><disp-quote content-type="editor-comment"><p>4) Previous research of the authors (Hauser et al., 2017, 2018, 2019) has associated β receptor blockade with enhanced metacognition, decreased information gathering/increased commitment to an early decision (Hauser et al., 2018) and an arousal (i.e., reward)-induced boost of processing stimuli. In addition, Rogers et al., (2004) suggest that propranolol affects the processing of possible losses in decision-making paradigms, and might also reduce the discrimination between the different levels of possible gains (Rogers et al., 2004). In another study, Sokol-Hessner et al., (2015) also report a loss aversion reduction after propranolol administration. These effects might also change prior information and reset behavioral adaption to look for new opportunities. In this latter study the authors also report a lack of effect of propranolol onto choice consistency, contrary to what the present study reports. How do the current results relate to these previous findings? Of course, it is possible that norepinephrine plays multiple roles, but it appears not exactly parsimonious to imbue it with a different role for each task tested. Are there some commonalities across these effects that could be explained with some common function(s)?</p></disp-quote><p>We thank the reviewers for raising this interesting point about the overarching function of noradrenaline. As the referee indicates we previously associated β receptor blockade with enhanced metacognition, decreased information gathering and decreased arousal-induced boosts of processing stimuli (please note that these studies were conducted in different subjects and are thus not directly relatable). Together with our current findings, the overall pattern of results might suggest that propranolol impacts how neural noise affects information processing in the brain, in line with prior theoretical work (Dayan and Yu, 2006). In particular, all of these results show that by administering propranolol, behaviour is more deterministic and less influenced by “task-irrelevant distractions”, an observation that accords also with reports implicating noradrenaline in attention shifting (for a review cf. Trofimova and Robbins, 2016). For example, an arousal-induced boost in incidental memory is abolished after propranolol (Hauser et al., 2019), a finding that aligns well with the suggestion of Dayan and Yu (2006) that noradrenaline can infuse noise into a system in a temporally targeted way. The latter idea also gains support from recent optogenetic based studies (Tervo et al., 2014) and relates also to other theories of noradrenaline/catecholamine function (Servan-Schreiber et al., 1990; Aston-Jones and Cohen, 2005), although an assumption here was that increases in noradrenaline would lead to an increase in determinism.</p><p>The studies pointed out by the reviewers (Rogers et al., 2004; Sokol-Hessner et al., 2015) make an interesting point about loss processing, including a demonstration that propranolol attenuates processing of punishment cues (Rogers et al., 2004) and reduces loss aversion (Sokol-Hessner et al., 2015), suggesting an effect of noradrenaline on prior information in a loss context. As the referee will appreciate our task was conducted in a reward-context, and it is entirely possible that an exploration task in a loss setting would reveal additional interesting results. Our interpretation of the existing data is that propranolol has a minimal, if any, effect on levels of reward. Firstly, the above-mentioned study by Rogers et al., (2004) only found a trend-level result. In addition, unpublished data from our group (Habicht et al., in prep) has not revealed any effect of propranolol on representations of gain and reward magnitudes.</p><p>It is interesting to speculate why Sokol-Hessner et al., (2015) did not find an effect on consistency. We do not believe that the latter results question our findings. It is important to note we refer to as consistency as the number of times subjects made the same exact choice on the exact same trial. We built this into the design of our task by duplicating each trial. In the study by Sokol-Hessner et al., (2015), the authors defined consistency as the softmax temperature parameter in a non-exploration related context. In line with their findings, we did not observe any drug effect on our prior variance 𝜎<sub>&quot;</sub> parameter, the one most closely related to the parameter in the Sokol-Hessner et al., (2015) study.</p><p>We now incorporate these points into the revised version of the paper. We have clarified how we measure consistency and how this is different from other studies. We add a paragraph discussing the above papers and speculate on an overarching explanatory framework and how this might relate to the previous theories about the role of noradrenaline.</p><p>Discussion: “Noradrenaline blockade by propranolol has been shown previously to enhance metacognition (75), decrease information gathering (59), and attenuate arousal-induced boosts in incidental memory (36). […] Future studies investigating exploration in loss contexts might provide important additional information on these questions.”</p><p>Materials and methods: “[Trials] were then duplicated to measure choice consistency, defined as the frequency of making the same choice on identical trials (in contrast to a previous propranolol study where consistency was defined in terms of a value-based exploration parameter (60)).”</p><disp-quote content-type="editor-comment"><p>5) Previous studies have shown that propranolol significantly decreased heart rate (e.g. Rogers et al., 2004). Did the authors measure heart rate and can they control for the possibility that peripheral effects of the drug explain the findings? And what was the reason for not collecting pupil diameter data, contrary to the previous research of the authors? Relatedly, in terms of norepinephrine influence and given the distributions of β receptors, could the authors be more explicit about the relation of their work to potential mechanisms (e.g. Goldman-Rakic et al., 1990 or Waterhouse et al., 1982)?</p></disp-quote><p>We thank the reviewers for raising these points and suggesting these additional analyses. We recorded heart rate and blood pressure (systolic and diastolic) as part of our standard protocol to ensure subjects’ health and safety. Those were collected at 3 time points: at the beginning of the experiment before giving the drug (“at arrival”), after giving the drug just before playing the task (“pre-task”), and after finishing the experiment (“post-task”). We have now, as suggested, analysed these data.</p><p>In line with the known physiological effects of propranolol (Koudas et al., 2019) and previous cognitive studies (e.g. Rogers et al., 2004, Hauser et al., 2019), the propranolol group had a lower post-task heart rate (F(2, 55)=7.249, p=.002, 𝜂<sup>2</sup>=.209). None of the other measures and timepoints showed any drug effect (cf. Appendix 2 Table 2 for all comparisons).</p><p>To further evaluate these effects, we ran a two-way ANOVA with the between-subject factor drug group and the within-subject factor time (all three time points). In this analysis, we found a change in all measures for all subjects over time (heart rate: F(1.74, 95.97)=99.341, p&lt;.001, 𝜂<sup>2</sup>=.644); systolic pressure: F(2, 110)=8.967, p&lt;.001, 𝜂<sup>2</sup>=.14; diastolic pressure: F(2, 110)=.874, p=.42, 𝜂<sup>2</sup>=.016, meaning these measures decreased throughout the experiment. However, did not differ between groups (drug main effect: heart rate: F(2, 55)=1.84, p=.169, 𝜂<sup>2</sup>=.063; systolic pressure: F(2, 55)=1.08, p=.347, 𝜂<sup>2</sup>=.038; diastolic pressure: F(2, 55)=.239, p=.788, 𝜂<sup>2</sup>=.009; drug-by-time interaction: heart rate: F(3.49, 95.97)=1.928, p=.121, 𝜂<sup>2</sup>=.066; systolic pressure: F(4, 110)=1.6, p=.179, 𝜂<sup>2</sup>=.055; diastolic pressure: F(4, 110)=.951, p=.438, 𝜂<sup>2</sup>=.033).</p><p>To ensure a lower heart rate in the post experiment measurement did not impact our results, we reanalysed all our data by adding the post-experiment heart-rate as an additional covariate. We found that controlling for this peripheral marker did not alter any of our findings. In particular, we replicated the same drug effects for value-free random exploration, in the behavioural measures: frequency of picking the low-value bandit (main effect of drug: F(2, 52) = 4.014, p=.024, 𝜂<sup>2</sup>=.134; Pairwise comparisons: placebo vs propranolol: t(40) = 2.923, p=.005, d=.654; amisulpride vs propranolol: t(38) = 2.171, p=.034, d=.496; amisulpride vs placebo: t(38) = -.587, p=.559, d=.133) and choice consistency (F(2, 52) = 5.474, p=.007, 𝜂<sup>2</sup>=.174; Pairwise comparisons: placebo vs propranolol: t(40) = -3.525, p=.001, d=.788; amisulpride vs propranolol: t(38) = -2.267, p=.026, d=.514; amisulpride vs placebo: t(38) = 1.107, p=.272, d=.251), and also the modeling parameter 𝜖-greedy (F(2, 52) = 4.493, p=.016, 𝜂<sup>2</sup>=.147; Pairwise comparisons: placebo vs propranolol: t(40) = 3.177, p=.002, d=.71; amisulpride vs propranolol: t(38) = 2.723, p=.009, d=.626; amisulpride vs placebo: t(38)=.251, p=.802, d=.057). Thus, we believe our findings are unlikely to have arisen from peripheral effects of the drug. We now mention this in the discussion and report traditional analyses in the revised manuscript (cf. Appendix 1, Appendix 2—table 2).</p><p>We thank the reviewers for raising the question about pupillometry, an important topic which we believe is more complex than commonly perceived. We appreciate there is a lot of enthusiasm about pupil size as an indirect measure of noradrenaline function, and indeed animal recordings show a nice alignment between locus coeruleus firing and pupil size (e.g. Joshi et al., 2016). However, there are several issues with respect to human studies that remain unclear, including specificity, directionality and causality of these effects. We discuss this in detail in Hauser et al., (2019), and a summary of these limitations can be found in the recent review by Joshi and Gold, (2020). In short, it is important to highlight that the link between noradrenaline and pupil dilation remains unresolved (Nieuwenhuis et al., 2011). In fact, it has been suggested that noradrenaline does not directly drive pupil dilation, but instead both are driven by a common input (e.g. Nieuwenhuis et al., 2011). Therefore, even though pupillometry might reflect endogenous fluctuations in noradrenaline, pharmacologically induced changes of noradrenaline levels may have very different effects that remain poorly understood. In fact, our own, and others, previous studies have found no effect of propranolol on pupil diameter (Koudas et al., 2009; Hauser et al., 2019), but instead a significant effect of drugs other than noradrenaline (e.g. dopamine; Samuels et al., 2006; Hauser et al., 2019).</p><p>An additional reason for not including pupillometry was that pupillometry has strong restrictions in terms of task presentations (luminance matching, absence of eye gaze). In fact, our pilot studies showed that this current task was not feasible when applying these restrictions.</p><p>Based on these concerns, we decided against using pupillometry. We now discuss this in detail in the revised version of the manuscript, including highlighting limitations and elaborating on future applications.</p><p>Regarding β-receptors and potential mechanisms, we thank the reviewers for pointing out those interesting papers. Waterhouse et al., (1982) have shown that β-receptors increase synaptic inhibition specifically through inhibitory GABA-mediated transmission (Waterhouse et al., 1984). This in line with findings from Goldman-Rakic et al., (1990) who found that intermediate layers in the prefrontal areas, within which inhibition is favored (Isaacson et al., 2011), host a high concentration of β-receptors. All of these results suggest that noradrenaline-related task-distractibility, and randomness, could reflect inhibitory mechanisms. We discuss this in detail in the revised Discussion. Please also see our response 5., where we speculate about the specific receptor effects and the implications on our findings.</p><p>Materials and methods: “The groups consisted of 20 subjects each matched (cf. Appendix 2—table 1) for gender and age. To evaluate peripheral drug effects, heart rate, systolic and diastolic blood pressure were collected at three different time-points: “at arrival”, “pre-task” and “post-task”, cf. Appendix 1 for details.”</p><p>Results: “Similar results were obtained in an analysis that corrected for physiological effects as from the analysis without covariates (cf. Appendix 1).”</p><p>Discussion: “Because the effect of pharmacologically induced changes of noradrenaline levels on pupil size remains poorly understood (36, 67), including the fact that previous studies found no effect of propranolol on pupil diameter (36, 68), we opted against using pupillometry in this study. […] However, future studies using drugs that exclusively targets peripheral, but not central, noradrenaline receptors (e.g. (82)) are needed to answer this question conclusively.”</p><p>Appendix 1: “Heart rate, systolic and diastolic pressure were obtained at 3 time points: at the beginning of the experiment before giving the drug (“at arrival”), after giving the drug just before the task (“pre-task”), and after finishing task and questionnaires (“post-task”). […] When analysing results but now correcting for the post-experiment heart rate (cf. Appendix 2 Table 1) in addition to IQ (WASI) and negative affect (PANAS), we obtained similar results. Noradrenaline blockade reduced value-free random exploration as seen in two behavioural signatures, frequency of picking the low-value bandit (F(2, 52) = 4.014, p=.024, 𝜂<sup>2</sup>=.134; Pairwise comparisons:(placebo vs propranolol: t(40) = 2.923, p=.005, d=.654; amisulpride vs propranolol: t(38) = 2.171, p=.034, d=.496; amisulpride vs placebo: t(38) = -.587, p=.559, d=.133), and consistency F(2, 52) = 5.474, p=.007, 𝜂<sup>2</sup>=.174; Pairwise comparisons: placebo vs propranolol: t(40) = -3.525, p=.001, d=.788; amisulpride vs propranolol: t(38) = -2.267, p=.026, d=.514; amisulpride vs placebo: t(38) = 1.107, p=.272, d=.251), as well as in a model parameter for value-free random exploration (ϵ: F(2, 52) = 4.493, p=.016, 𝜂<sup>2</sup>=.147; Pairwise comparisons: placebo vs propranolol: t(40) = 3.177, p=.002, d=.71; amisulpride vs propranolol: t(38) = 2.723, p=.009, d=.626; amisulpride vs placebo: t(38)=.251, p=.802, d=.057).”</p><disp-quote content-type="editor-comment"><p>6) One strength of the paper is that the authors compared several computational models. The model selection is presented in Figure 4 and in Figure 4—figure supplement 1, the authors provide additional information regarding the winning model that accounted best for the largest number of subjects in comparison with two other models, namely the UCB model (with novelty and greedy parameters) or hybrid (with novelty and greedy parameters). It would be useful for the reader to get a better sense about the number of subjects which results favored any given model (i.e. a more exhaustive picture). One could use the same table as the one presented as in the Appendix—table 2 with respective number of subjects for which the model achieved the best performance. In fact, as shown in Figure 4, the winning model does not look very different (at least visually) from other models such as UCB (with novelty and greedy parameters) or hybrid (with novelty parameter or novelty and greedy parameters) models. As such, it would be important to know whether the conclusion about the e-greedy parameter would hold true if other model with similar performance were tested e.g. with UCB model (with novelty and greedy parameters) or hybrid (with novelty and greedy parameters)?</p></disp-quote><p>We thank the reviewer for acknowledging our efforts in terms of model selection. As suggested, we now expand on this section and provide additional details.</p><p>We now show that Thompson+𝜖+𝜂 model has the highest subject count when comparing the 3 best models. When comparing across all models, this same model is equally first with the UCB+𝜖+𝜂 model in subject count with a highest average likelihood of held-out data making it the winning model (N=20 for each model). We now show this in Figure 4—figure supplement 1 and we extended Appendix—table 4 with each model’s performance.</p><p>It is important to note that the purpose of the model comparison was to demonstrate the relevance of the two new heuristics, in addition to complex exploration strategies. The model comparison, as well as the new head counts, show clearly that the winning models all incorporate both the novelty and value-free exploration modules, strongly supporting our key message. The fact that the Thompson, UCB and hybrid model performed relatively similar may highlight that they make fairly similar predictions in our task, and that benefits of a particular complex model may be explained by these similar heuristic strategies. We discuss this now in more detail in the revised manuscript.</p><p>We thank the reviewers for suggesting these additional analyses of the other (close to best) models. We indeed find a very similar effect (i.e. reduction of value-free random exploration following propranolol) in the second winning model (UCB+𝜖+𝜂; drug main effect on 𝜖: F(2, 54)=4.503, p=.016, η2=.143) and (almost) in the third place model (hybrid+𝜖+𝜂; drug main effect on 𝜖: F(2, 54 )=3.04, p=.056, η2=.101). We believe that these effects further extend and support our findings and we now discuss them in the revised Discussion and provide detail in the Appendix.</p><p>Results: “Interestingly, although the second and third place models made different prediction about the complex exploration strategy, using a directed exploration with value-based random exploration (UCB) or a combination of complex strategies (hybrid) respectively, they share the characteristic of benefitting from value-free random and novelty exploration. This highlights that subjects used a mixture of computationally demanding and heuristic exploration strategies. […]. Critically, the effect on ϵ was also significant when the complex exploration strategy was a directed exploration with value-based random exploration (second place model) and, marginally significant, when it was a combination of the above (third place model; cf. Appendix 1).”</p><p>Discussion: “Importantly, these heuristics were observed in all best models (first, second and third position) even though each incorporated different exploration strategies. This suggests that the complex models made similar predictions in our task, and demonstrates that value-free random exploration is at play even when accounting for other value-based forms of random exploration (1, 7), whether fixed or uncertainty-driven. […] Importantly, this effect was observed whether the complex exploration was an uncertainty-driven value-based random exploration (winning model), a directed exploration with value-based random exploration (second place model) or a combination of the above (third place model; cf. Appendix 1).”</p><p>Appendix 1: “When analysing the fitted parameter values of both the second winning model (UCB + ϵ + η) and third winning model (hybrid + ϵ + η), similar results pertain. Thus, a value-free random exploration parameter was reduced following noradrenaline blockade in the second winning model (ϵ: F(2, 54)=4.503, p=.016, 𝜂<sup>2</sup>=.143; Pairwise comparisons: placebo vs propranolol: t(38)=2.185, p=.033, d=.386; amisulpride vs propranolol: t(40)=1.724, p=.089, d=.501; amisulpride vs placebo: t(40)=-.665, p=.508, d=.151) and was affected at a trend-level significance in the third winning model (ϵ: F(2, 54 )=3.04, p=.056, 𝜂<sup>2</sup>=.101).”</p><disp-quote content-type="editor-comment"><p>7) Related to this issue, the point of heuristics from a psychological perspective is that they dispense with the need to use full-blown algorithmic calculations. However, in the present models, the heuristics are only added on top of these calculations and the winning model includes Thompson exploration. Stand-alone heuristic models would do the term more justice and one wonders how well a model would fare that includes only tabula rasa exploration and novelty exploration.</p></disp-quote><p>We thank the reviewers for this suggestion. We based our hypotheses/analyses on recent evidence for complex exploration strategies and used model selection to show the presence of explorations heuristics in addition to these complex strategies. Based on the reviewers’ suggestions, we have added stand-alone heuristic models (value-free random exploration and novelty exploration with no value function computation; cf. Appendix 1).</p><p>As can be seen from the results in Appendix 1, these models performed poorly, although better than chance level, while adding value-free random exploration substantially improved their performance. Our results thus highlight that subjects combine complex and heuristic modules in exploration. We believe this is a valuable new insight and we have now added these additional models to the revised manuscript.</p><p>Appendix 1: “We also analysed stand-alone heuristic models, in which there is no value computation (value of each bandit i: 𝑉<sub>i</sub> = 0). The held-out data likelihood for such heuristic model combined with novelty exploration had a mean of m=0.367 (sd=0.005). The model in which we added value-free random exploration on top of novelty exploration had a mean of m=0.384 (sd=0.006). These models performed poorly, although better than chance level. Importantly, adding value-free random exploration improved performance. This highlights that subjects’ combine complex and heuristic modules in exploration.”</p><disp-quote content-type="editor-comment"><p>8) The simulations provide a nice intuition for understanding choice proportions from different models/strategies (Figure 1E and 1F). However, it would be helpful to provide simulated results for long and short horizons separately. Do the models make different predictions for the two horizons? Additionally, it would be helpful to also show the results from other models (i.e. the proportion of low value bandit chosen by novelty agent). These could be added in the supplement.</p></disp-quote><p>We now extend the model simulations and agree that they can provide a more detailed understanding. To ensure an intuitive understanding for a general audience, we provide these additional simulations as 3 additional figures in the Figure supplement, and to keep the original simulation graphs as intuitive illustrations.</p><p>From the new figures, one can see that the frequency of picking the low-value bandit, as well as choice consistency, are affected specifically by value-free random exploration but not by other exploration strategies; Figure 1—figure supplement 3 and Figure 1—figure supplement 4. Moreover, the frequency of picking the novel bandit is affected mainly by a novelty exploration strategy and to a lower extend by UCB exploration (Figure 1—figure supplement 5).</p><p>Based on the reviewers’ suggestion, we now add simulations specific to the short and long horizons (to simulate the latter we allowed all other exploration strategies to increase as well; in Appendix 2—table 7). Our simulations show effects were observed both in the short and long horizon condition. We believe that these new simulations provide additional intuitions regarding the two new exploration heuristics and we mention these simulations in the revised manuscript. Please also see the added simulations and illustrations in Figure 1 —figure supplement 3, Figure 1—figure supplement 4, Figure 1—figure supplement 5, which further expand on our findings.</p><p>Results: “Additionally, we simulated the effects of other exploration strategies in short and long horizon conditions (Figure 1—figure supplement 3, Figure 1—figure supplement 4, Figure 1—figure supplement 5). To simulate a long (versus short) horizon condition we increased the overall exploration by increasing other exploration strategies. Details about parameter values can be found in Appendix 2—table 7.”</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>Thank you for a largely responsive revision. The paper is much improved. A few points remain:</p><p>Related to previous point 1, the argument in subsection “Probing the contributions of heuristic exploration strategies” does not seem to be entirely correct. The authors claim that &quot;A second prediction is that choice consistency, across repeated trials, is substantially affected by value-free random exploration.&quot; However, consistency can also be affected by the softmax parameter. If β is higher then choice consistency is also lower. Also, I am a little bit confused about the simulation results in Figure 1- figure supplement 2E,F. Do both models predict that the consistency of selecting the low value bandit is higher than the consistency of selecting the high value bandit? In line with the argument that higher β also lead to more stochastic choices, I also wonder if that can be the reason why UCB and UCB+ϵ are not that much different in likelihood.</p></disp-quote><p>We apologise for a lack of clarity on this point. A key feature of value-free random exploration is that it ignores all information, leading to a completely random selection among the choice options. None of the other exploration strategies shows a similarly strong effect on consistency, because they are still guided by the value of the options, and are disposed to choose the most valuable alternative (in the model’s eye).</p><p>The sentence in subsection “Probing the contributions of heuristic exploration strategies”, referred to by the referee, was meant to highlight a comparison to complex exploration strategies, such as directed exploration which consistently explores the less known option. We have now revised this passage to explain what we mean better.</p><p>Regarding Figure 1—figure supplement 2E,F, we believe that the referee has misunderstood this figure. We would highlight that the simulations we present here refer to the consistency across all bandits (as consistency is the inverse of switching between bandits). The x-axis shows the simulation of two different levels of our parameters (𝛽, 𝜖, respectively). We agree that this should have been more clear and we have now revised the figure legend to avoid any misunderstanding by the readership. As the reviewer can see, the 𝛽 parameter also has an effect on the consistency, but to a lesser degree, because this clearly prefers medium-valued bandits over low-valued bandits (cf. Figure 1—figure supplement 2C,D).</p><p>We agree with the reviewer that this parameter may capture some of the randomness in the UCB model, which leads to a more similar performance between the two models considered. We think this is an interesting observation and we address this point in more detail in the revised discussion.</p><p>Results (subsection “Probing the contributions of heuristic exploration strategies”): “A second prediction is that choice consistency, across repeated trials, is directly affected by value-free random exploration, in particular by comparison to more deterministic exploration strategies (e.g. directed exploration) that are value-guided and thus will consistently select the most informative and valuable options.”</p><p>Discussion: “A second exploration heuristic that also requires minimal computational resources, value-free random exploration, also plays a role in our task. Even though less optimal, its simplicity and neural plausibility renders it a viable strategy. Indeed, we observe an increase in performance in each model after adding 𝜖, supporting the notion that this strategy is a relevant additional human exploration heuristic. Interestingly, the benefit of 𝜖 is somewhat smaller in a simple UCB model (without novelty bonus), which probably arises because value-based random exploration partially captures some of the increased noisiness.”</p><p>Figure 1—figure supplement 2 legend: “Comparison of value-based (softmax) and value-free (𝜖greedy) random exploration. (a) Changing the softmax inverse temperature affects the slope of the sigmoid while changing the 𝜖-greedy parameter (b) affects the compression of the sigmoid. Conceptually, in a softmax exploration mode, as each bandit's expected value is taken into account, (c) the second best bandit (medium-value bandit) is favoured over one with a lower value (low-value bandit) when injecting noise. In contrast, in an 𝜖-greedy exploration mode, (d) bandits are explored equally often irrespective of their expected value. Both simulations were performed on trials without novel bandit. When simulating on all trials we observe this also has a consequence for choice consistency. (e) Choices are more consistent in a low (versus high) softmax exploration mode (i.e. high and low values of 𝛽 respectively), and similarly (f) choices are more consistent in a low (versus high) 𝜖-greedy exploration mode (i.e. low and high values of 𝜖 respectively). When comparing the overall consistency of the two random exploration strategies, consistency is higher in the value-based mode, reflecting a higher probability of (consistently) exploring the second best option, compared to an equal probability of exploring any non-optimal option (inconsistently) in the value-free mode.”</p><disp-quote content-type="editor-comment"><p>Regarding previous point 2: Were response time differences between value-free exploration and exploitation trials larger in the long horizon than the short horizon condition (i.e., while there was no main effect of bandit, was there an interaction with horizon or trial within horizon and was there a three-way interaction with drug)? Moreover, the response to the mistake issue is not entirely satisfactory. If participants paid (gradually) less attention in the long horizon, then it would also be expected that they make more mistakes in the long horizon condition only.</p></disp-quote><p>We would like to highlight here that our previous analysis only investigated the first choice made in each horizon (in line with all other analyses). As previously presented in Figure 2—figure supplement 1B, there is a substantial decrease in response latencies for the long horizon after the first choice, and this could have confounded the analysis. We have now clarified this. We believe that by focusing on the first choice, our analysis should not be affected by subjects paying ‘gradually less attention’ in the long horizon.</p><p>Nevertheless, we have now conducted a three-factor analysis that the reviewer suggests, where we investigated the response latencies of the first choice using factors horizon, drug, and bandit. As in our previous findings, we observed no main effect of either bandit (F(1.71,92.46)=1.203, p=.3, 𝜂<sup>2</sup>=.022), horizon (F(1,54)=.71, p=.403, 𝜂<sup>2</sup>=.013), or drug (F(2,54)=2.299, p=.11, 𝜂<sup>2</sup>=.078).</p><p>Additionally, there was no interaction between any of the factors (drug-by-bandit interaction: F(3.42,92.46)=.431, p=.757, 𝜂<sup>2</sup>=.016; drug-by-horizon interaction: F(2,54)=.204, p=.816, 𝜂<sup>2</sup>=.008; bandit-by-horizon interaction: F(1.39,75.01)=.298, p=.662, 𝜂<sup>2</sup>=.005; drug-by-bandit-by-horizon interaction: F(2.78,75.01)=1.015, p=.387, 𝜂<sup>2</sup>=.036). We believe this further strengthens our findings and interpretation, and we have now added this analysis to the revised manuscript.</p><p>As the reviewer raised an interesting point about the subsequent choices in the long horizon, we have now conducted a new analysis across all long horizon choices using the three factors of bandit, drug and sample (/choice). As shown in our previous Figure 2—figure supplement 1B, we observed a strong effect of sample ((1.54,86.15)=427.047, p&lt;.001, 𝜂<sup>2</sup>=.884), meaning that the response latencies decrease over time. Interestingly, we also observed an effect of bandit (F(1.61,90.12)=7.137, p=.003, 𝜂<sup>2</sup>=.113), as well as a bandit-by-sample interaction (F(3.33,186.41)=4.789, p=.002, 𝜂<sup>2</sup>=.079). No drug effect or other interaction was observed (drug main effect: F(2,56)=.542, p=.585, 𝜂<sup>2</sup>=.019; drug-by-bandit interaction: F(3.22,90.12)=.525, p=.679, 𝜂<sup>2</sup>=.018; drug-by-sample interaction: F(3.08,86.15)=1.039, p=.381, 𝜂<sup>2</sup>=.036, 𝜂<sup>2</sup>=.078; drug-bybandit-by-sample interaction: F(6.66,186.41)=.645, p=.71, 𝜂<sup>2</sup>=.023). Analysing the bandit-sample effect further (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>), we found this was driven by faster response times for the high-value (exploitation) bandit at the second choice (high-value bandit vs low-value bandit : t(59)=-5.736, p&lt;.001, d=.917; high-value bandit vs novel bandit: t(59)=-6.24, p&lt;.001, d=.599; bandit main effect: F(1.27,70.88)=27.783, p&lt;.001, 𝜂<sup>2</sup>=.332) and a slower response time for the low-value bandit at the second (low-value bandit vs novel bandit: t(59)=3.756, p&lt;.001, d=.432) and third choice (high-value bandit vs low-value bandit : t(59)=-5.194, p&lt;.001, d=.571; low-value bandit vs novel bandit: t(59)=4.448, p&lt;.001, d=.49; high-value bandit vs novel bandit: t(59)=-1.834, p=.072, d=.09; bandit main effect: F(1.23,68.93)=21.318, p&lt;.001, 𝜂<sup>2</sup>=.276). We believe this reflects that when subjects decide to exploit for the remainder of the samples, they respond more quickly than in a situation where they continue to explore. Given that the response times are slower, rather than faster, than the other bandits does not support a notion of hasty mistakes. We have now added this observation to Appendix 1.</p><fig id="respfig1"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-59907-resp-fig1-v2.tif"/></fig><p>Appendix: “When looking at the first choice in both conditions, no differences were evident in RT in a repeated-measures ANOVA with the between-subject factor drug group and the within-subject factors horizon and bandit (bandit main effect: F(1.71,92.46)=1.203, p=.3, 𝜂<sup>2</sup>=.022; horizon main effect: F(1,54)=.71, p=.403, 𝜂<sup>2</sup>=.013; drug main effect: F(2,54)=2.299, p=.11, 𝜂<sup>2</sup>=.078; drug-by-bandit interaction: F(3.42,92.46)=.431, p=.757, 𝜂<sup>2</sup>=.016; drug-by-horizon interaction: F(2,54)=.204, p=.816, 𝜂<sup>2</sup>=.008; bandit-by-horizon interaction: F(1.39,75.01)=.298, p=.662, 𝜂<sup>2</sup>=.005; drug-by-bandit-by-horizon interaction: F(2.78,75.01)=1.015, p=.387, 𝜂<sup>2</sup>=.036).In the long horizon, when looking at all 6 samples, no differences were evident in RT between drug group in the repeated-measures ANOVA with a between-subject factor drug group, and within subject factors bandits and samples (drug main effect: F(2,56)=.542, p=.585, 𝜂<sup>2</sup>=.019). There was an effect of bandit (bandit main effect: F(1.61,90.12)=7.137, p=.003, 𝜂<sup>2</sup>=.113), of sample (sample main effect: F(1.54,86.15)=427.047, p&lt;.001, 𝜂<sup>2</sup>=.884) and an interaction between the two (bandit-by-sample interaction: F(3.33,186.41)=4.789, p=.002, 𝜂<sup>2</sup>=.079; drug-by-bandit interaction: F(3.22,90.12)=.525, p=.679, 𝜂<sup>2</sup>=.018; drug-by-sample interaction: F(3.08,86.15)=1.039, p=.381, 𝜂<sup>2</sup>=.036; drug-by-bandit-by-sample interaction: F(6.66,186.41)=.645, p=.71, 𝜂<sup>2</sup>=.023). Further analysis (not corrected for multiple comparisons) revealed that the interaction between bandit and sample reflected the fact that when looking at samples individually, there was a bandit main effect in the second sample (bandit main effect: F(1.27,70.88)=27.783, p&lt;.001, 𝜂<sup>2</sup>=.332; drug main effect: F(2,56)=.201, p=.819, 𝜂<sup>2</sup>=.007; drug-by-bandit interaction: F(2.53,70.88)=.906, p=.429, 𝜂<sup>2</sup>=.031) and in the third sample (bandit main effect: F(1.23,68.93)=21.318, p&lt;.001, 𝜂<sup>2</sup>=.276; drug main effect: F(2,56)=.102, p=.903, 𝜂<sup>2</sup>=.004; drug-by-bandit interaction: F(2.46,68.93)=.208, p=.855, 𝜂<sup>2</sup>=.007), but not in the other samples first sample: drug main effect: F(2,56)=1.108, p=.337, 𝜂<sup>2</sup>=.038; bandit main effect: F(2,112)=.339, p=.713, 𝜂<sup>2</sup>=.006; drug-by-bandit interaction: F(4,112)=.414, p=.798, 𝜂<sup>2</sup>=.015; 4<sup>th</sup> sample: (drug main effect: F(2,56)=.43, p=.652, 𝜂<sup>2</sup>=.015; bandit main effect: F(1.36,76.22)=1.348, p=.259, 𝜂<sup>2</sup>=.024; drug-by-bandit interaction: F(2.72,76.22)=.396, p=.737, 𝜂<sup>2</sup>=.014; 5<sup>th</sup> sample: drug main effect: F(2,56)=.216, p=.806, 𝜂<sup>2</sup>=.008; bandit main effect: F(1.25,69.79)=.218, p=.696, 𝜂<sup>2</sup>=.004; drug-by-bandit interaction: F(2.49,69.79)=.807, p=.474, 𝜂<sup>2</sup>=.028; 6<sup>th</sup> sample: drug main effect: F(2,56)=1.026, p=.365, 𝜂<sup>2</sup>=.035; bandit main effect: F(1.05,58.81)=.614, p=.444, 𝜂<sup>2</sup>=.011; drug-by-bandit interaction: F(2.1,58.81)=1.216, p=.305, 𝜂<sup>2</sup>=.042). In the second sample, the high-value bandit was chosen faster (high-value bandit vs low-value bandit: t(59)=-5.736, p&lt;.001, d=.917; high-value bandit vs novel bandit: t(59)=-6.24, p&lt;.001, d=.599) and the low-value bandit was chosen slower (low-value bandit vs novel bandit: t(59)=3.756, p&lt;.001, d=.432). In the third sample, the low-value bandit was chosen slower (high-value bandit vs low-value bandit: t(59)=-5.194, p&lt;.001, d=.571; low-value bandit vs novel bandit: t(59)=4.448, p&lt;.001, d=.49; high-value bandit vs novel bandit: t(59)=-1.834, p=.072, d=.09).”</p><disp-quote content-type="editor-comment"><p>Regarding previous point 8, it is great that the authors followed our suggestion to simulate all models in both the short and long horizon. However, these figures (Figure 1—figure supplement 3 to Figure 1—figure supplement 5) seem to be somewhat confusing. The problem may lie in the parameters selected for simulation. According to Appendix 2 Table 7, the multiple parameters were varied among different models. But I thought they should keep most consistent and only vary the interesting one. For example, shouldn't 𝜂 be kept same or even be zero in the value free random exploration model to show how choices are vary as function of 𝜖? I think the numbers are selected such that the predictions favor the value free random exploration model. If, as authors said, UCB + 𝜖 + 𝜂 is almost as good as Thompson-sampling + 𝜖 + 𝜂, I don’t see what the predictions can be such dramatically different. That is how I interpret the statement that &quot; For simulating the long (versus short) horizon condition, we assumed that not only the key value but also the other exploration strategies increased, as found in our experimental data.&quot; Anyway, I feel the simulation data is somehow misleading and need more explanation.</p></disp-quote><p>We thank the reviewer for appreciating our effort and apologise that we were not sufficiently clear in explaining what these simulations illustrate. The key purpose of these figures is to illustrate how different aspects of the models affect bandit choices.</p><p>In the original reviews, the reviewer suggested to simulate both short and long horizon, and the effects of low and high exploration of a specific exploration strategy. For the low and high exploration, we indeed kept all parameters identical bar the parameter of interest, which is what we changed (as suggested by this reviewer). This is what we show in the short horizon.</p><p>For illustrating the long horizon, we tried to accommodate the fact that multiple exploration strategies are elevated in our subjects (compared to the short horizon). We thus decided to also increase other exploration strategies, as listed in Appendix 2—table 7, and correctly observed by this reviewer. However, we do agree that this can be confusing and are happy to remove what we label “long horizon” for clarity.</p><p>The parameter values for these simulations are well within the range of fitted model parameters. However, because these are primarily to illustrate the effects of the model (rather than align with exact subjects’ behaviours), we have taken somewhat accentuated values that highlight the specific effects of the parameter more clearly. It is important to note that the key purpose of these illustrations is to compare the effect of low and high exploration within each model, rather than comparing the absolute height of the bars. This was not clear enough in the original captions, and we have now entirely revised these captions.</p><p>Besides these simulations, we also provide the model simulations of the complete winning model in the original manuscript. This was shown in Figure 5—figure supplement 1. The reviewer indeed raised a relevant point about this, which is that we did not show the same model fit using the second winning model (UCB). We have now performed this simulation using each participants’ fitted model parameters for the second winning model and have added it as a figure to the manuscript (cf. Figure 5 – figure supplement 3). As one can see, both complex models simulations make fairly similar predictions for our data, as we had previously mentioned, but not shown. We hope this now illustrates our previous notion and we have now detailed this in the revised manuscript.</p><p>Discussion: “Importantly, these heuristics were observed in all best models (first, second and third position) even though each incorporated different exploration strategies. This suggests that the complex models make similar predictions in our task. This is also observed in our simulations, and demonstrates that value-free random exploration is at play even when accounting for other value-based forms of random exploration (1, 7), whether fixed or uncertainty-driven.”</p><p>Figure 1—figure supplement 3 legend: “Simulation illustrations of high and low exploration on the frequency of picking the low-value bandit using different exploration strategies shows that (a) a high (versus low) value-free random exploration increases the selection of the low-value bandit, whereas neither (b) a high (versus low) novelty exploration, (c) a high (versus low) Thompson-sampling exploration nor (d) a high (versus low) UCB exploration affected this frequency. To illustrate the long (versus short) horizon condition, we accommodated the fact that not only key values but also other exploration strategies were enhanced by increasing multiple exploration strategies, as found in our experimental data (cf. Appendix 2 —table 7 for parameter values). Please note that the difference between low and high exploration is critical here, rather than a comparison of the absolute height of the bars between strategies (which is influences in the models by multiple different exploration strategies). For simulations fitting participants’ data, please see Figure 5—figure supplement 1 and Figure 5—figure supplement 3.”</p><p>Figure 1—figure supplement 4 legend: “Simulation illustrations of high and low exploration choice consistency using different exploration strategies shows that (a) a high (versus low) value-free random exploration decreases the proportion of same choices, whereas neither (b) a high (versus low) novelty exploration, (c) a high (versus low) Thompson-sampling exploration nor (d) a high (versus low) UCB exploration affected this measure. To illustrate the long (versus short) horizon condition, accommodated the fact that not only the key value but also other exploration strategies were enhanced by increasing multiple exploration strategies, as found in our experimental data (cf. Appendix 2—table 7 for parameter values). Please note that the difference between low and high exploration is critical here, rather than a comparison of the absolute height of the bars between strategies (which is influences in the models by multiple different exploration strategies). For simulations fitting participants’ data, please see Figure 5—figure supplement 1 and Figure 5—figure supplement 3.”</p><p>Figure 1—figure supplement 5 legend: “Simulation illustrations of high and low exploration on the frequency of picking the novel bandit using different exploration strategies shows that (a) a high (versus low) value-free random exploration has little effect on the selection of the novel bandit, whereas (b) a high (versus low) novelty exploration increases this frequency. (c) A high (versus low) Thompson-sampling exploration had little effect and (d) a high (versus low) UCB exploration affected this frequency but to a lower extend than novelty exploration. To illustrate the long (versus short) horizon condition, we accommodated the fact that not only the key value but also other exploration strategies were enhanced by increasing multiple exploration strategies, as found in our experimental data (cf. Appendix 2—table 7 for parameter values). Please note that the difference between low and high exploration is critical here, rather than a comparison of the absolute height of the bars between strategies (which is influences in the models by multiple different exploration strategies). For simulations fitting participants’ data, please see Figure 5—figure supplement 1 and Figure 5—figure supplement 3.”</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>The authors addressed all my comments and made substantial revisions that have strengthened the overall manuscript. Specifically, the new information in Appendix Table 4 with each model's performance and additional analyses on of the other &quot;(close to best)&quot; models further strengthens the authors' claim. The authors also clarified the results on heart rate, RT and PANAS questionnaire, providing additional results and discussing appropriately potential caveats. Further additions in the Discussion address potential mechanisms of propranolol on decision making.</p></disp-quote><p>We thank this reviewer for a very positive endorsement of our revisions and for acknowledging our additional analyses have strengthened the paper. We have now addressed the remaining point below.</p><disp-quote content-type="editor-comment"><p>The only comment I have relates to the sentence that follows (in the Discussion): “In particular, the results indicate that under propranolol behaviour is more deterministic and less influenced by “task-irrelevant” distractions. This aligns with theoretical ideas, as well as recent optogenetic evidence (32), that propose noradrenaline infuses noise in a temporally targeted way (31). It also accords with studies implicating noradrenaline in attention shifts (for a review cf. (76)). Other theories of noradrenaline/catecholamine function can link to determinism (64, 65), although the hypothesized direction of effect is different (i.e. noradrenaline increases determinism).&quot; Here, it is unclear to me how the authors define determinism and how either increasing or decreasing noradrenaline can increase determinism?</p></disp-quote><p>Firstly, we apologise for the unclear sentence and confusing wording. We chose “determinism” as the opposite of “stochasticity” (as also capture in our value-free random exploration), but we agree that the term is confusing and have therefore decided to use the latter, more clear terminology.</p><p>The directionality of this effect is indeed interesting, and to our understanding not entirely clear.</p><p>Theoretical accounts are somewhat contradictory, with a gain-modulation account (Aston-Jones and Cohen, 2005; Servan-Schreiber et al., 1990) suggesting a decrease of stochasticity with increasing noradrenaline function. On the other hand, other theoretical accounts (Dayan and Yu, 2006) suggest that noradrenaline can induce stochasticity. Our findings, showing a reduction in stochasticity after propranolol, favour the latter. However, several other aspects of noradrenaline functioning may explain differential theoretical accounts. They are likely to capture different aspects of the assumed U-shaped noradrenaline functioning curve, and/or they may be relevant in distinct activity modes, such as tonic and phasic firing (cf. Aston-Jones and Cohen, 2005). We have now implemented this discussion in more detail in the revised manuscript.</p><p>Discussion: “In particular, the results indicate that under propranolol behaviour is less stochastic and less influenced by “task-irrelevant” distractions. […] Further studies can shed light on how different modes of activity affect value-free random exploration.”</p></body></sub-article></article>