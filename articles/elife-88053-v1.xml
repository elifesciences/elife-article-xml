<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">88053</article-id><article-id pub-id-type="doi">10.7554/eLife.88053</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.88053.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Short Report</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Drift of neural ensembles driven by slow fluctuations of intrinsic excitability</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-293740"><name><surname>Delamare</surname><given-names>Geoffroy</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6217-4370</contrib-id><email>g.delamare21@imperial.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-168818"><name><surname>Zaki</surname><given-names>Yosif</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-67465"><name><surname>Cai</surname><given-names>Denise J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7729-0523</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-17772"><name><surname>Clopath</surname><given-names>Claudia</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4507-8648</contrib-id><email>c.clopath@imperial.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Department of Bioengineering, Imperial College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04a9tmd77</institution-id><institution>Department of Neuroscience, Icahn School of Medicine at Mount Sinai</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Giocomo</surname><given-names>Lisa M</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03mtd9a03</institution-id><institution>Stanford School of Medicine</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>07</day><month>05</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP88053</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-04-07"><day>07</day><month>04</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-03-17"><day>17</day><month>03</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.16.532958"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-06-08"><day>08</day><month>06</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88053.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-12-15"><day>15</day><month>12</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88053.2"/></event></pub-history><permissions><copyright-statement>Â© 2023, Delamare et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Delamare et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-88053-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-88053-figures-v1.pdf"/><abstract><p>Representational drift refers to the dynamic nature of neural representations in the brain despite the behavior being seemingly stable. Although drift has been observed in many different brain regions, the mechanisms underlying it are not known. Since intrinsic neural excitability is suggested to play a key role in regulating memory allocation, fluctuations of excitability could bias the reactivation of previously stored memory ensembles and therefore act as a motor for drift. Here, we propose a rate-based plastic recurrent neural network with slow fluctuations of intrinsic excitability. We first show that subsequent reactivations of a neural ensemble can lead to drift of this ensemble. The model predicts that drift is induced by co-activation of previously active neurons along with neurons with high excitability which leads to remodeling of the recurrent weights. Consistent with previous experimental works, the drifting ensemble is informative about its temporal history. Crucially, we show that the gradual nature of the drift is necessary for decoding temporal information from the activity of the ensemble. Finally, we show that the memory is preserved and can be decoded by an output neuron having plastic synapses with the main region.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>excitability</kwd><kwd>drift</kwd><kwd>memory</kwd><kwd>synaptic plasticity</kwd><kwd>intrinsic plasticity</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/N013956/1</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.35802/200790</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>564408</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000266</institution-id><institution>Engineering and Physical Sciences Research Council</institution></institution-wrap></funding-source><award-id>EP/R035806/1</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Internal neural variability can induce drift of memory ensembles through synaptic plasticity, allowing for encoding of temporal information.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In various brain regions, the neural code tends to be dynamic although behavioral outputs remain stable. Representational drift refers to the dynamic nature of internal representations as they have been observed in sensory cortical areas (<xref ref-type="bibr" rid="bib10">Driscoll et al., 2017</xref>; <xref ref-type="bibr" rid="bib34">Sadeh and Clopath, 2022</xref>; <xref ref-type="bibr" rid="bib11">Driscoll et al., 2022</xref>) or the hippocampus (<xref ref-type="bibr" rid="bib39">Ziv et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Hainmueller and Bartos, 2018</xref>) despite stable behavior. It has even been suggested that pyramidal neurons from the CA1 and CA3 regions form dynamic rather than static memory engrams (<xref ref-type="bibr" rid="bib14">Hainmueller and Bartos, 2018</xref>; <xref ref-type="bibr" rid="bib36">Spalla et al., 2021</xref>), namely that the set of neurons encoding specific memories varies across days. In the amygdala, retraining of a fear memory task induces a turnover of the memory engram (<xref ref-type="bibr" rid="bib4">Cho et al., 2021</xref>). Additionally, plasticity mechanisms have been proposed to compensate for drift and to provide a stable read-out of the neural code (<xref ref-type="bibr" rid="bib33">Rule and OâLeary, 2022</xref>), suggesting that information is maintained. Altogether, this line of evidence suggests that drift might be a general mechanism with dynamical representations observed in various brain regions.</p><p>However, the mechanisms underlying the emergence of drift and its relevance for the neural computation are not known. Drift is often thought to arise from variability of internal states (<xref ref-type="bibr" rid="bib34">Sadeh and Clopath, 2022</xref>), neurogenesis (<xref ref-type="bibr" rid="bib30">Rechavi et al., 2022</xref>; <xref ref-type="bibr" rid="bib10">Driscoll et al., 2017</xref>) or synaptic turnover (<xref ref-type="bibr" rid="bib2">Attardo et al., 2015</xref>) combined with noise (<xref ref-type="bibr" rid="bib19">Kossio et al., 2021</xref>; <xref ref-type="bibr" rid="bib22">Manz and Memmesheimer, 2023</xref>). On the other hand, excitability might also play a role in memory allocation (<xref ref-type="bibr" rid="bib38">Zhou et al., 2009</xref>; <xref ref-type="bibr" rid="bib24">Mau et al., 2020</xref>; <xref ref-type="bibr" rid="bib31">Rogerson et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Silva et al., 2009</xref>), so that neurons having high excitability are preferentially allocated to memory ensembles (<xref ref-type="bibr" rid="bib3">Cai et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Rashid et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Silva et al., 2009</xref>). Moreover, excitability is known to fluctuate over timescales from hours to days, in the amygdala (<xref ref-type="bibr" rid="bib29">Rashid et al., 2016</xref>), the hippocampus (<xref ref-type="bibr" rid="bib3">Cai et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">Grosmark and BuzsÃ¡ki, 2016</xref>), or the cortex (<xref ref-type="bibr" rid="bib15">Huber et al., 2013</xref>; <xref ref-type="bibr" rid="bib21">Levenstein et al., 2019</xref>). Subsequent reactivations of a neural ensemble at different time points could therefore be biased by excitability (<xref ref-type="bibr" rid="bib25">Mau et al., 2022</xref>), which varies at similar timescales than drift (<xref ref-type="bibr" rid="bib23">Mau et al., 2018</xref>). Altogether, this evidence suggest that fluctuations of excitability could act as a cellular mechanism for drift (<xref ref-type="bibr" rid="bib24">Mau et al., 2020</xref>).</p><p>In this short communication, we aimed at proposing how excitability could indeed induce a drift of neural ensembles at the mechanistic level. We simulated a recurrent neural network (<xref ref-type="bibr" rid="bib7">Delamare et al., 2022</xref>) equipped with intrinsic neural excitability and Hebbian learning. As a proof of principle, we first show that slow fluctuations of excitability can induce neural ensembles to drift in the network. We then explore the functional implications of such drift. Consistent with previous works (<xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>; <xref ref-type="bibr" rid="bib6">Clopath et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Miller et al., 2018</xref>), we show that neural activity of the drifting ensemble is informative about the temporal structure of the memory. This suggest that fluctuations of excitability can be useful for time-stamping memories (<italic>i.e</italic>. for making the neural ensemble informative about the time at which it was form). Finally, we confirmed that the content of the memory itself can be steadily maintained using a read-out neuron and local plasticity rule, consistently with previous computational works (<xref ref-type="bibr" rid="bib33">Rule and OâLeary, 2022</xref>). The goal of this study is to show one possible mechanistic implementation of how excitability can drive drift.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Many studies have shown that memories are encoded in sparse neural ensembles that are activated during learning and many of the same cells are reactivated during recall, underlying a stable neural representation (<xref ref-type="bibr" rid="bib16">Josselyn and Tonegawa, 2020</xref>; <xref ref-type="bibr" rid="bib28">Poo et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Mau et al., 2020</xref>). After learning, subsequent reactivations of the ensemble can happen spontaneously during replay, retraining or during a memory recall task (e.g. following presentation of a cue <xref ref-type="bibr" rid="bib16">Josselyn and Tonegawa, 2020</xref>; <xref ref-type="bibr" rid="bib17">KÃ¡li and Dayan, 2004</xref>). Here, we directly tested the hypothesis that slow fluctuations of excitability can change the structure of a newly-formed neural ensemble, through subsequent reactivations of this ensemble.</p><p>To that end, we designed a rate-based, recurrent neural network, equipped with intrinsic neural excitability (Methods). We considered that the recurrent weights are all-to-all and plastic, following a Hebbian rule (Methods). The network was then stimulated following a 4day protocol: the first day corresponds to the initial encoding of a memory and the other days correspond to spontaneous or cue-induced reactivations of the neural ensemble (Methods). Finally, we considered that excitability of each neuron can vary on a day long timescale: each day, a different subset of neurons has increased excitability (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, Methods).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Excitability-induced drift of memory ensembles.</title><p>(<bold>a</bold>) Distribution of excitability <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ïµ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> for each neuron <italic>i</italic>, fluctuating over time. During each stimulation, a different pool of neurons has a high excitability (Methods). (<bold>b, c</bold>) Firing rates of the neurons across time. The red traces in panel (<bold>c</bold>) correspond to neurons belonging to the first assembly, namely that have a firing rate higher than the active threshold after the first stimulation. The black bars show the stimulation and the dashed line shows the active threshold. (<bold>d</bold>) Recurrent weights matrices after each of the four stimuli show the drifting assembly.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 1.</label><caption><title>Comparison of drifting behavior for different values of excitability amplitude.</title><p>(<bold>a</bold>) <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, no drift. A neural assembly is initially formed during the first stimulation and later reactivated every subsequent day. (<bold>b</bold>) <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mstyle></mml:math></inline-formula>, partial drift. The ensemble is gradually modified during each new stimulation. (<bold>c</bold>) <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>, full drift. Each new stimulation leads to formation of a new ensemble, containing neurons that have high excitability during this time.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 2.</label><caption><title>The rate of the drift does not depend on the size of the initial engram.</title><p>Drift rate against the size of the original engram. Bars show minimum, mean and maximum values. n=100 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig1-figsupp2-v1.tif"/></fig></fig-group><sec id="s2-1"><title>Fluctuations of intrinsic excitability induce drifting of neural ensembles</title><p>While stimulating the naive network on the first day, we observed the formation of a neural ensemble: some neurons gradually increase their firing rate (<xref ref-type="fig" rid="fig1">Figure 1b and c</xref>, neurons 10â20, time steps 1000â3000) during the stimulation. We observed that these neurons are highly recurrently connected (<xref ref-type="fig" rid="fig1">Figure 1d</xref>, leftmost matrix) suggesting that they form an assembly. This assembly is composed of neurons that have a high excitability (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, neurons 10â20 have increase excitability) at the time of the stimulation. We then show that further stimulations of the network induce a remodeling of the synaptic weights. During the second stimulation for instance (<xref ref-type="fig" rid="fig1">Figure 1b and c</xref>, time steps 4000â6000), neurons from the previous assembly (10â20) are reactivated along with neurons having high excitability at the time of the second stimulation (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, neurons 20â30). Moreover, across several days, recurrent weights from previous assemblies tend to decrease while others increase (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). Indeed, neurons from the original assembly (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, red traces) tend to be replaced by other neurons, either from the latest assembly or from the pool of neurons having high excitability. This is translated at the synaptic level, where weights from previous assemblies tend to decay and be replaced by new ones. Overall, each new stimulation updates the ensemble according to the current distribution of excitability, inducing a drift towards neurons with high excitability. Finally, in our model, the drift rate does not depend on the size of the original ensemble (<xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2</xref>, Methods).</p></sec><sec id="s2-2"><title>Activity of the drifting ensemble is informative about the temporal structure of the past experience</title><p>After showing that fluctuations of excitability can induce a drift among neural ensembles, we tested whether the drifting ensemble could contain temporal information about its past experiences, as suggested in previous works (<xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>).</p><p>Inspired by these works, we asked whether it was possible to decode relevant temporal information from the patterns of activity of the neural ensemble. We first observed that the correlation between patterns of activity after just after encoding decreases across days (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, Methods), indicating that after each day, the newly formed ensemble resembles less the original one. Because the patterns of activity differ across days, they should be informative about the absolute day from which they were recorded. To test this hypothesis, we designed a day decoder (<xref ref-type="fig" rid="fig2">Figure 2b</xref>, Methods), following the work of <xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>. This decoder aims at inferring the reactivation day of a given activity pattern by comparing the activity of this pattern during training and the activity just after memory encoding without increase in excitability (<xref ref-type="fig" rid="fig2">Figure 2b</xref>, Methods). We found that the day decoder perfectly outputs the reactivation day as compared to using shuffled data (<xref ref-type="fig" rid="fig2">Figure 2c</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Neuronal activity is informative about the temporal structure of the reactivations.</title><p>(<bold>a</bold>) Correlation of the patterns of activity between the first day and every other days, for n=10 simulations. Data are shown as mean Â± s.e.m. (<bold>b</bold>) Schema of the day decoder. The day decoder maximises correlation between the patterns of each day with the pattern from the simulation with no increase in excitability. (<bold>c</bold>) Results of the day decoder for the real data (red) and the shuffled data (orange). Shuffled data consist of the same activity pattern for which the label of each cell for every seed has been shuffled randomly. For each simulation, the error is measured for each day as the difference between the decoded and the real day. Data are shown for n=10 simulations and for each of the 4 days. (<bold>d</bold>) Schema of the ordinal time decoder. This decoder output the permutation <inline-formula><mml:math id="inf5"><mml:mi mathvariant="bold-italic">ð</mml:mi></mml:math></inline-formula> that maximises the sum <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>S</mml:mi><mml:mo mathvariant="normal">â¢</mml:mo><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo mathvariant="normal" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the correlations of the patterns for each pairs of days. (<bold>e</bold>) Distribution of the value <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>S</mml:mi><mml:mo mathvariant="normal">â¢</mml:mo><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo mathvariant="normal" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for each permutation of days <inline-formula><mml:math id="inf8"><mml:mi mathvariant="bold-italic">ð</mml:mi></mml:math></inline-formula>. The value for the real permutation <inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>S</mml:mi><mml:mo mathvariant="normal">â¢</mml:mo><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext mathvariant="normal">real</mml:mtext></mml:msub><mml:mo mathvariant="normal" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is shown in black. (<bold>f</bold>) Studentâs test t-value for n=10 simulations, for the real (red) and shuffled (orange) data and for different amplitudes of excitability <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula>. Data are shown as mean Â± s.e.m. for n=10 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 1.</label><caption><title>Sparse recurrent connectivity shows similar drifting behavior as all-to-all connectivity.</title><p>The same simulation protocol as <xref ref-type="fig" rid="fig1">Figure 1</xref> was used while the recurrent weights matrix was made 50% sparse (Methods). (<bold>a</bold>) Firing rates of the neurons across time. The red traces correspond to neurons belonging to the first assembly, namely that have a firing rate higher than the active threshold after the first stimulation. The black bars show the stimulation and the dashed line shows the active threshold. (<bold>b</bold>) Recurrent weights matrices after each of the four stimuli show the drifting assembly. (<bold>c</bold>) Correlation of the patterns of activity between the first day and every other days. (<bold>d</bold>) Studentâs test t-value of the ordinal time decoder, for the real (red) and shuffled (orange) data and for different amplitudes of excitability <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula>. (<bold>e</bold>) Center of mass of the distribution of the output weights (Methods) across days. (<bold>câe</bold>) Data are shown as mean Â± s.e.m. for n=10 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 2.</label><caption><title>Change of excitability as a variable slope of the input-output function shows similar drifting behavior as considering a change in the threshold.</title><p>The same simulation protocol as <xref ref-type="fig" rid="fig1">Figure 1</xref> was used while the excitability changes were modeled as a change in the slope of the activation function (Methods). (<bold>a</bold>) Schema showing two different ways of defining excitability, as a threshold (top) or slope (bottom) of the activation function. Each line shows one neuron and darker lines correspond to neurons with increased excitability. (<bold>b</bold>) Firing rates of the neurons across time. The red traces correspond to neurons belonging to the first assembly, namely that have a firing rate higher than the active threshold after the first stimulation. The black bars show the stimulation and the dashed line shows the active threshold. (<bold>c</bold>) Recurrent weights matrices after each of the four stimuli show the drifting assembly. (<bold>d</bold>) Correlation of the patterns of activity between the first day and every other days. (<bold>e</bold>) Studentâs test t-value of the ordinal time decoder, for the real (red) and shuffled (orange) data and for different amplitudes of excitability <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula>. (<bold>f</bold>) Center of mass of the distribution of the output weights (Methods) across days. (<bold>d-f</bold>) Data are shown as mean Â± s.e.m. for n=10 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 3.</label><caption><title>Two distinct ensembles can be encoded and drift independently.</title><p>(<bold>a, b</bold>) Firing rates of the neurons across time. The red traces in panel (<bold>b</bold>) correspond to neurons belonging to the first assembly and the green traces to the second assembly on the first day. They correspond to neurons having a firing rate higher than the active threshold after the first stimulation of each assembly. The black bars show the stimulation and the dashed line shows the active threshold. (<bold>c</bold>) Recurrent weights matrices after each of the eight stimuli showing the drifting of the first (top) and second (bottom) assembly.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 4.</label><caption><title>The two ensembles are informative about their temporal history and can be decoded using two output neurons.</title><p>(<bold>a</bold>) Correlation of the patterns of activity between the first day and every other days, for the first assembly (red) and the second assembly (green). (<bold>b</bold>) Studentâs test t-value of the ordinal time decoder, for the first (red, left) and second ensemble (green, right) for different amplitudes of excitability <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula>. Shuffled data are shown in orange. (<bold>c</bold>) Center of mass of the distribution of the output weights (Methods) across days for the first (<inline-formula><mml:math id="inf14"><mml:msubsup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mn mathvariant="normal">1</mml:mn><mml:mtext mathvariant="normal">out</mml:mtext></mml:msubsup></mml:math></inline-formula>, red) and second (<inline-formula><mml:math id="inf15"><mml:msubsup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mn mathvariant="normal">2</mml:mn><mml:mtext mathvariant="normal">out</mml:mtext></mml:msubsup></mml:math></inline-formula>, green) ensemble. (<bold>aâc</bold>) Data are shown as mean Â± s.e.m. for n=10 simulations. (<bold>d</bold>) Output neurons firing rate across time for the first ensemble (<inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, top) and the second ensemble (<inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, bottom). The red and green traces correspond to the real output. The dark blue, light blue and yellow traces correspond to the cases where the output weights were randomly shuffled for every time points after presentation of the first, second and third stimulus, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig2-figsupp4-v1.tif"/></fig></fig-group><p>After showing that the patterns of activity are informative about the reactivation day, we took a step further by asking whether the activity of the neurons is also informative about the order in which the memory evolved. To that end, we used an ordinal time decoder (Methods, as in <xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>) that uses the correlations between activity patterns for pairs of successive days, and for each possible permutation of days <inline-formula><mml:math id="inf18"><mml:mi mathvariant="bold-italic">ð</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2d</xref>, Methods). The sum of these correlations <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> differs from each permutation <inline-formula><mml:math id="inf20"><mml:mi mathvariant="bold-italic">ð</mml:mi></mml:math></inline-formula> and we assumed that the neurons are informative about the order at which the reactivations of the ensemble happened if the permutation maximising <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> corresponds to the real permutation <inline-formula><mml:math id="inf22"><mml:msup><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>real</mml:mtext></mml:msup></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, Methods). We found that <inline-formula><mml:math id="inf23"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>real</mml:mtext></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was indeed statistically higher than <inline-formula><mml:math id="inf24"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for the other permutations <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, Studentâs t-test, Methods). However, this was only true when the amplitude of the fluctuations of excitability <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula> was in a certain range. Indeed, when the amplitude of the fluctuations is null, that is when excitability is not increased (<inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), the ensemble does not drift (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1a</xref>). In this case, the patterns of activity are not informative about the order of reactivations. On the other hand, if the excitability amplitude is too high (<inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>), each new ensemble is fully determined by the distribution of excitability, regardless of any previously formed ensemble (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1c</xref>). In this regime, the patterns of activity are not informative about the order of the reactivations either. In the intermediate regime (<inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mstyle></mml:math></inline-formula>), the decoder is able to correctly infer the order at which the reactivations happened, better than using the shuffled data (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1b</xref>).</p><p>Finally, we sought to test whether the results are independent on the specific architecture of the model. To that end, we defined a change of excitability as a change in the slope of the activation function, rather than of the threshold (<xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref>, Methods). We also used sparse recurrent synaptic weights instead of the original all-to-all connectivity matrix (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>, Methods). In both cases, we observed a similar drifting behavior and were able to decode the temporal order in which the memory evolved.</p></sec><sec id="s2-3"><title>A read-out neuron can track the drifting ensemble</title><p>So far, we showed that the drifting ensemble contains information about its history, namely about the days and the order at which the subsequent reactivations of the memory happened.</p><p>However, we have not shown that we could use the neural ensemble to actually decode the memory itself, in addition to its temporal structure. To that end, we introduced a decoding output neuron connected to the recurrent neural network, with plastic weights following a Hebbian rule (Methods). As shown by <xref ref-type="bibr" rid="bib33">Rule and OâLeary, 2022</xref>, the goal was to make sure that the output neuron can track the ensemble even if it is drifting. This can be down by constantly decreasing weights from neurons that are no longer in the ensemble and increasing those associated with neurons joining the ensemble (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). We found that the output neuron could steadily decode the memory (<italic>i.e</italic>. it has a higher firing than in the case where the output weights are randomly shuffled; <xref ref-type="fig" rid="fig3">Figure 3b</xref>). This is due to the fact that weights are plastic under Hebbian learning, as shown by <xref ref-type="bibr" rid="bib33">Rule and OâLeary, 2022</xref>. We confirmed that this was induced by a change in the output weights across time (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). In particular, the weights from neurons that no longer belong to the ensemble are decreased while weights from newly recruited neurons are increased, so that the center of mass of the weights distribution drifts across time (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). Finally, we found that the quality of the read-out decreases with the rate of the drift (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>, Methods).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>A single output neuron can track the memory ensemble through Hebbian plasticity.</title><p>(<bold>a</bold>) Conceptual architecture of the network: the read-out neuron <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> in red âtracksâ the ensemble by decreasing synapses linked to the previous ensemble and increasing new ones to linked to the new assembly. (<bold>b</bold>) Output neuronâs firing rate across time. The red trace corresponds to the real output. The dark blue, light blue and yellow traces correspond to the cases where the output weights were randomly shuffled for every time points after presentation of the first, second and third stimulus, respectively. (<bold>c</bold>) Output weights for each neuron across time. (<bold>d</bold>) Center of mass of the distribution of the output weights (Methods) across days. The output weights are centered around the neurons that belong to the assembly at each day. Data are shown as mean Â± s.e.m. for n=10 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>The quality of the read-out decreases with the rate of the drift.</title><p>Read-out quality computed on the firing rate of the output neuron against the rate of the drift (Methods). Each dot shows one simulation. n=100 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-fig3-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Two memories drift independently</title><p>Finally, we tested whether the network is able to encode two different memories and whether excitability could make two ensembles drift. On each day, we stimulated a random half of the neurons (context A) and the other half (context B) sequentially (Methods). We found that, day after day, the two ensembles show a similar drift than when only one ensemble was formed (<xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplement 3</xref>). In particular, the correlation between the patterns activity on the first day and the other days decay in a similar way (<xref ref-type="fig" rid="fig2s4">Figure 2âfigure supplement 4a</xref>). For both contexts, the temporal order of the reactivations can be decoded for a certain range of excitability amplitude (<xref ref-type="fig" rid="fig2s4">Figure 2âfigure supplement 4b</xref>). Finally, we found that using two output decoders allowed us to decode both memories independently. The output weights associated to both ensembles are remodeled to follow the drifting ensembles, but are not affected by the reactivation of the other ensemble (<xref ref-type="fig" rid="fig2s4">Figure 2âfigure supplement 4c</xref>). Indeed, both neurons are able to âtrackâ the reactivation of their associated ensemble while not responding to the other ensemble (<xref ref-type="fig" rid="fig2s4">Figure 2âfigure supplement 4d</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Overall, our model suggests a potential cellular mechanisms for the emergence of drift that can serve a computational purpose by âtime-stampingâ memories while still being able to decode the memory across time. Although the high performance of the day decoder was expected, the performance of the ordinal time decoder is not trivial. Indeed, the patterns of activity of each day are informative about the distribution of excitability and therefore about the day at which the reactivation happened. However, the ability for the neural ensemble to encode the order of past reactivations requires drift to be gradual (i.e. requires consecutive patterns of activity to remain correlated across days). Indeed, if the amplitude of excitability is too low (<inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) or too high (<inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>), it is not possible to decode the order at which the successive reactivations happened. This result is consistent with the previous works showing gradual change in neural representations, that allows for decoding temporal information of the ensemble (<xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>). Moreover, such gradual drifts could support complex cognitive mechanisms like mental time-travel during memory recall (<xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>).</p><p>In our model, drift is induced by co-activation of the previously formed ensemble and neurons with high excitability at the time of the reactivation. The pool of neurons having high excitability can therefore âtime-stampsâ memory ensembles by biasing allocation of these ensembles (<xref ref-type="bibr" rid="bib6">Clopath et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>). We suggest that such time-stamping mechanism could also help link memories that are temporally close and dissociate those which are spaced by longer time (<xref ref-type="bibr" rid="bib11">Driscoll et al., 2022</xref>; <xref ref-type="bibr" rid="bib24">Mau et al., 2020</xref>; <xref ref-type="bibr" rid="bib1">Aimone et al., 2006</xref>). Indeed, the pool of neurons with high excitability varies across time so that any new memory ensemble is allocated to neurons which are shared with other ensembles formed around the same time. This mechanism could be complementary to the learning-induced increase in excitability observed in amygdala (<xref ref-type="bibr" rid="bib29">Rashid et al., 2016</xref>), hippocampal CA1 (<xref ref-type="bibr" rid="bib3">Cai et al., 2016</xref>) and dentate gyrus (<xref ref-type="bibr" rid="bib27">Pignatelli et al., 2019</xref>).</p><p>Finally, we intended to model drift in the firing rates, as opposed to a drift in the turning curve, of the neurons. Recent studies suggest that drifts in the mean firing rate and tuning curve arise from two different mechanisms (<xref ref-type="bibr" rid="bib12">Geva et al., 2023</xref>; <xref ref-type="bibr" rid="bib18">Khatib et al., 2023</xref>). Experience drives a drift in neurons turning curve while the passage of time drives a drift in neurons firing rate. In this sense, our study is consistent with these findings by providing a possible mechanism for a drift in the mean firing rates of the neurons driven a dynamical excitability. Our work suggests that drift can depend on any experience having an impact on excitability dynamics such as exercise as previously shown experimentally (<xref ref-type="bibr" rid="bib30">Rechavi et al., 2022</xref>; <xref ref-type="bibr" rid="bib9">de Snoo et al., 2023</xref>) but also neurogenesis (<xref ref-type="bibr" rid="bib1">Aimone et al., 2006</xref>; <xref ref-type="bibr" rid="bib37">Tran et al., 2022</xref>; <xref ref-type="bibr" rid="bib30">Rechavi et al., 2022</xref>), sleep (<xref ref-type="bibr" rid="bib20">Levenstein et al., 2017</xref>) or increase in dopamine level (<xref ref-type="bibr" rid="bib5">Chowdhury et al., 2022</xref>).</p><p>Overall, our work is a proof of principle which highlights the importance of considering excitability when studying drift, although further work would be needed to test this link experimentally.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Recurrent neural network with excitability</title><p>Our rate-based model consists of a single region of <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> neurons (with firing rate <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>â¤</mml:mo><mml:mi>i</mml:mi><mml:mo>â¤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). All-to-all recurrent connections <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>W</mml:mi></mml:mstyle></mml:math></inline-formula> are plastic and follow a Hebbian rule given by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mtext>decay</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula> correspond to the pre- and post-synaptic neuron respectively. <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>W</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>decay</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> are the learning and the decay time constants of the weights, respectively.</p><p>A hard bound of <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula> was applied to these weights. We also introduced a global inhibition term dependent on the activity of the neurons:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>here <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> are positive constants. All neurons receive the same input, <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Î</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, during stimulation of the network (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, black bars). Finally, excitability is modeled as a time-varying threshold <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ïµ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> of the input-output function of each neuron <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula>. The rate dynamics of a neuron <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> is given by:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>ReLU</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Î</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>Ïµ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the decay time of the rates and ReLU is the rectified linear activation function. We considered that a neurons is active when its firing rate reaches the active threshold <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Î¸</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>In <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>, we applied a random binary mask to the recurrent weights in order to set 50% of the synapses at 0. A new mask was randomly sampled for each simulation.</p><p>In <xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref>, we modeled excitability as a change of the slope of the activation function (ReLU) instead of a change of the threshold as previously used (<xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2a</xref>):<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>Ïµ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mtext>ReLU</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Î</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2"><title>Protocol</title><p>We designed a 4-day protocol, corresponding to the initial encoding of a memory (first day) and subsequent random or cue-induced reactivations of the ensemble (<xref ref-type="bibr" rid="bib16">Josselyn and Tonegawa, 2020</xref>; <xref ref-type="bibr" rid="bib17">KÃ¡li and Dayan, 2004</xref>) (second, third, and fourth day). Each stimulation consists of <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>rep</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> repetitions of interval <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi></mml:mstyle></mml:math></inline-formula> spaced by a inter-repetition delay <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Î</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> takes the value <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Î´</mml:mi></mml:mstyle></mml:math></inline-formula> during these repetitions and is set to 0 otherwise. The stimulation is repeated four times, modeling four days of reactivation, spaced by an inter-day delay <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mi>D</mml:mi></mml:mstyle></mml:math></inline-formula>. Excitability <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ïµ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> of each neuron <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> is sampled from the absolute value of a normal distribution of mean 0 and standard deviation 1. In <xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref>, excitability <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ïµ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is sampled from the absolute value of a normal distribution of mean 0.4 and standard deviation 0.2. Neurons 10â20, 20â30, 30â40, and 40â50 then receive an increase of excitability of amplitude <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula>, respectively on days 1, 2, 3, and 4 (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). A different random seed is used for each repetition of the simulation. When two memories were modeled (<xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplements 3</xref> and <xref ref-type="fig" rid="fig2s4">4</xref>), we stimulated a random half of the neurons (context A) and the other half (context B) successively (<xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplement 3a</xref>), every day.</p></sec><sec id="s4-3"><title>Decoders</title><p>For each day <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula>, we recorded the activity pattern <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, which is a vector composed of the firing rate of the neurons at the end of the last repetition of stimulation. To test the decoder, we also stimulated the network while setting the excitability at baseline (<inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), and recorded the resulted pattern of activity <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> for each day <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula>. We then designed two types of decoders, inspired by previous works (<xref ref-type="bibr" rid="bib32">Rubin et al., 2015</xref>): (1) a day decoder which infers the day at which each stimulation happened and (2) an ordinal time decoder which infers the order at which the reactivations occurred. For both decoders, the shuffled data was obtained by randomly shuffling the day label of each neuron. When two memories were modeled (<xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplements 3</xref> and <xref ref-type="fig" rid="fig2s4">4</xref>), the patterns of activity were taken at the end of the stimulations by context A and B, and the decoders were used independently on each memory.</p><p>1. The day decoder aims at inferring the day at which a specific pattern of activity occurred. To that end, we computed the Pearson correlation between the pattern with no excitability <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> of the day <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula> and the patterns of all days <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">â²</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> from the first simulation <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">â²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. Then, the decoder outputs the day <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>inf</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> that maximises the correlation:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:msub><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>inf</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow class="MJX-TeXAtom-OP"><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>d</mml:mi><mml:mo>â²</mml:mo></mml:msup></mml:mrow></mml:munder><mml:mo>â¡</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mtext>corr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>d</mml:mi><mml:mo>â²</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math></disp-formula></p><p>The error was defined as the difference between the inferred and the real day <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>inf</mml:mtext></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula>.</p><p>2. The ordinal time decoder aims at inferring the order at which the reactivations happened from the patterns of activity <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> of every day <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula>. To that end, we computed the pairwise correlations of each pair of consecutive days, for the <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>4</mml:mn><mml:mo>!</mml:mo></mml:mstyle></mml:math></inline-formula> possible permutations of days <inline-formula><mml:math id="inf75"><mml:mi mathvariant="bold-italic">ð</mml:mi></mml:math></inline-formula>. The real permutation is called <inline-formula><mml:math id="inf76"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>real</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and corresponds to the real order of reactivations: day 1 â day 2 â day 3 â day 4. The sum of these correlations over the 3 pairs of consecutive days is expressed as:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>corr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We then compared the distribution of these quantities for each permutation <inline-formula><mml:math id="inf77"><mml:mi mathvariant="bold-italic">ð</mml:mi></mml:math></inline-formula> to that of the real permutation <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>real</mml:mtext></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The patterns of activity are informative about the order of reactivations if <inline-formula><mml:math id="inf79"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>real</mml:mtext></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> corresponds to the maximal value of <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. To compare <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>real</mml:mtext></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with the distribution <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we performed a Studentâs t-test, where the t-value is defined as:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>real</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mi>Î¼</mml:mi></mml:mrow><mml:mrow><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where Î¼ and Ï correspond to the mean and standard deviation of the distribution <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively.</p><p>The drift rate Î (<xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>) was computed as:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mi mathvariant="normal">Î</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:munderover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mtext>corr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-4"><title>Memory read-out</title><p>To test if the network is able to decode the memory at any time point, we introduced a read-out neuron with plastic synapses to neurons from the recurrent network, inspired by previous computational works (<xref ref-type="bibr" rid="bib33">Rule and OâLeary, 2022</xref>). The weights of these synapses are named <inline-formula><mml:math id="inf84"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mtext>out</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mtext>out</mml:mtext></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>â¤</mml:mo><mml:mi>i</mml:mi><mml:mo>â¤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and follow the Hebbian rule defined as:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>â</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow><mml:mo>â</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>â</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> corresponds to the learning time and decay time constant, respectively. <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>h</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mtext>out</mml:mtext></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a homeostatic term defined as <inline-formula><mml:math id="inf88"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mtext>out</mml:mtext></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msubsup><mml:mi>W</mml:mi><mml:mi>j</mml:mi><mml:mtext>out</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> which decreases to 0 throughout learning. <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> takes the value 1 before learning and 0 when the sum of the weights reaches the value 1. <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> is the firing rate of the output neuron defined <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> as:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>out</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></disp-formula></p><p>The read-out quality index <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>) was defined as:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">â¨</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:munderover><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>y</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>shuffle</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:msub><mml:mo fence="false" stretchy="false">â©</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>shuffle</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> corresponds to the value of <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> taken at the end of the last repetition of day <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>shuffle</mml:mtext></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> the equivalent with shuffled outputs weights. <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">â¨</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">â©</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>shuffle</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> indicates the average over <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>shuffle</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mstyle></mml:math></inline-formula> simulations.</p><p>In <xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplements 3</xref> and <xref ref-type="fig" rid="fig2s4">4</xref>, two output decoders <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>â</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, with corresponding weights <inline-formula><mml:math id="inf101"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>out</mml:mtext></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mtext>out</mml:mtext></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>â¤</mml:mo><mml:mi>i</mml:mi><mml:mo>â¤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are defined as:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>out</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>Î²</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></disp-formula></p><p>and follow the Hebbian rule defined as:<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>â</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow><mml:mo>â</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p><p>Then, we aimed at allocating <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> to the first and the second ensemble (context A and B), respectively. To that end, we used supervised learning on the first day by adding a current <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Î²</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> to the output neurons which is positive when the corresponding context is on:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>Î²</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mrow><mml:mtext>Â ifÂ </mml:mtext><mml:mrow><mml:mn>1000</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>3000</mml:mn></mml:mrow><mml:mtext>,Â </mml:mtext><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mtext>Â otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>Î²</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mrow><mml:mtext>Â ifÂ </mml:mtext><mml:mrow><mml:mn>4000</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>6000</mml:mn></mml:mrow><mml:mtext>,Â </mml:mtext><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mtext>Â otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The shuffled traces were obtained by randomly shuffling the output weights <inline-formula><mml:math id="inf105"><mml:msup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mtext>out</mml:mtext></mml:msup></mml:math></inline-formula> or <inline-formula><mml:math id="inf106"><mml:msubsup><mml:mi mathvariant="bold-italic">ð¾</mml:mi><mml:mi mathvariant="bold-italic">ð</mml:mi><mml:mtext>out</mml:mtext></mml:msubsup></mml:math></inline-formula> for each ensemble <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-5"><title>Table of parameters</title><p>The following parameters have been used for the simulations. When unspecified, the defaults values were used. All except <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> are in arbitrary unit. <xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref> corresponds to the change from a threshold-based to a slope-based excitability. <xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplements 3</xref> and <xref ref-type="fig" rid="fig2s4">4</xref> corresponds to the stimulation of two ensembles. <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref> corresponds to the sparsity simulation.</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Param.</th><th align="left" valign="bottom">Description</th><th align="left" valign="bottom">Default</th><th align="left" valign="bottom"><xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref></th><th align="left" valign="bottom"><xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplements 3</xref> and <xref ref-type="fig" rid="fig2s4">4</xref></th><th align="left" valign="bottom"><xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref></th></tr></thead><tbody><tr><td align="left" valign="bottom">N</td><td align="left" valign="bottom">Number of neurons</td><td align="left" valign="bottom">50</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>W</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Learning time constant of the recurrent weights</td><td align="left" valign="bottom">800</td><td align="left" valign="bottom">700</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>decay</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Decay time constant of the recurrent weights</td><td align="left" valign="bottom">1000</td><td align="left" valign="bottom">800</td><td align="left" valign="bottom">4000</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Decay time constant of the firing rates</td><td align="left" valign="bottom">20</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Learning time constant of the output weights</td><td align="left" valign="bottom">200</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>â</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Decay time constant of the output weights</td><td align="left" valign="bottom">1000</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">First inhibition parameter</td><td align="left" valign="bottom">12</td><td align="left" valign="bottom">4</td><td align="left" valign="bottom">8</td><td align="left" valign="bottom">7</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Second inhibition parameter</td><td align="left" valign="bottom">0.5</td><td align="left" valign="bottom">0.7</td><td align="left" valign="bottom">0.8</td><td align="left" valign="bottom">0.8</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Third inhibition parameter</td><td align="left" valign="bottom">0.05</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Î´</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Input current during stimulation</td><td align="left" valign="bottom">15</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">12</td><td align="left" valign="bottom">20</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Amplitude of the fluctuations of excitability</td><td align="left" valign="bottom">1.5</td><td align="left" valign="bottom">0.5</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>rep</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Number of repetitions</td><td align="left" valign="bottom">10</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Duration of each repetition</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mi>R</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Inter-repetition delay</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mi>D</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Inter-stimulation delay</td><td align="left" valign="bottom">1000</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Î¸</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Active threshold</td><td align="left" valign="bottom">5</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Cap on the recurrent weights</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">.5</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td></tr></tbody></table></table-wrap></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Validation, Investigation, Methodology, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-88053-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The code for simulations and figures is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/gdelamar/drift">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib8">Delamare, 2024</xref>).</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aimone</surname><given-names>JB</given-names></name><name><surname>Wiles</surname><given-names>J</given-names></name><name><surname>Gage</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Potential role for adult neurogenesis in the encoding of time in new memories</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>723</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1038/nn1707</pub-id><pub-id pub-id-type="pmid">16732202</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attardo</surname><given-names>A</given-names></name><name><surname>Fitzgerald</surname><given-names>JE</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Impermanence of dendritic spines in live adult CA1 hippocampus</article-title><source>Nature</source><volume>523</volume><fpage>592</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1038/nature14467</pub-id><pub-id pub-id-type="pmid">26098371</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>DJ</given-names></name><name><surname>Aharoni</surname><given-names>D</given-names></name><name><surname>Shuman</surname><given-names>T</given-names></name><name><surname>Shobe</surname><given-names>J</given-names></name><name><surname>Biane</surname><given-names>J</given-names></name><name><surname>Song</surname><given-names>W</given-names></name><name><surname>Wei</surname><given-names>B</given-names></name><name><surname>Veshkini</surname><given-names>M</given-names></name><name><surname>La-Vu</surname><given-names>M</given-names></name><name><surname>Lou</surname><given-names>J</given-names></name><name><surname>Flores</surname><given-names>SE</given-names></name><name><surname>Kim</surname><given-names>I</given-names></name><name><surname>Sano</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>M</given-names></name><name><surname>Baumgaertel</surname><given-names>K</given-names></name><name><surname>Lavi</surname><given-names>A</given-names></name><name><surname>Kamata</surname><given-names>M</given-names></name><name><surname>Tuszynski</surname><given-names>M</given-names></name><name><surname>Mayford</surname><given-names>M</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A shared neural ensemble links distinct contextual memories encoded close in time</article-title><source>Nature</source><volume>534</volume><fpage>115</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1038/nature17955</pub-id><pub-id pub-id-type="pmid">27251287</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>HY</given-names></name><name><surname>Shin</surname><given-names>W</given-names></name><name><surname>Lee</surname><given-names>HS</given-names></name><name><surname>Lee</surname><given-names>Y</given-names></name><name><surname>Kim</surname><given-names>M</given-names></name><name><surname>Oh</surname><given-names>JP</given-names></name><name><surname>Han</surname><given-names>J</given-names></name><name><surname>Jeong</surname><given-names>Y</given-names></name><name><surname>Suh</surname><given-names>B</given-names></name><name><surname>Kim</surname><given-names>E</given-names></name><name><surname>Han</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Turnover of fear engram cells by repeated experience</article-title><source>Current Biology</source><volume>31</volume><fpage>5450</fpage><lpage>5461</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.10.004</pub-id><pub-id pub-id-type="pmid">34687608</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chowdhury</surname><given-names>A</given-names></name><name><surname>Luchetti</surname><given-names>A</given-names></name><name><surname>Fernandes</surname><given-names>G</given-names></name><name><surname>Filho</surname><given-names>DA</given-names></name><name><surname>Kastellakis</surname><given-names>G</given-names></name><name><surname>Tzilivaki</surname><given-names>A</given-names></name><name><surname>Ramirez</surname><given-names>EM</given-names></name><name><surname>Tran</surname><given-names>MY</given-names></name><name><surname>Poirazi</surname><given-names>P</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A locus coeruleus-dorsal CA1 dopaminergic circuit modulates memory linking</article-title><source>Neuron</source><volume>110</volume><fpage>3374</fpage><lpage>3388</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.08.001</pub-id><pub-id pub-id-type="pmid">36041433</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>HÃ¼bener</surname><given-names>M</given-names></name><name><surname>Rose</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Variance and invariance of neuronal long-term representations</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>372</volume><elocation-id>20160161</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0161</pub-id><pub-id pub-id-type="pmid">28093555</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Delamare</surname><given-names>G</given-names></name><name><surname>Feitosa TomÃ©</surname><given-names>D</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Intrinsic Neural Excitability Induces Time-Dependent Overlap of Memory Engrams</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.08.27.505441</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Delamare</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Drift</data-title><version designator="swh:1:rev:c79e1baeff8e3c3294ef794c77287827e3af9cec">swh:1:rev:c79e1baeff8e3c3294ef794c77287827e3af9cec</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:50f44c9d73aa82fd3cd38347b9b6ed5c9af43a53;origin=https://github.com/gdelamar/drift;visit=swh:1:snp:d7c0ec941cf4282bc25b00df0862de834b7e1ed1;anchor=swh:1:rev:c79e1baeff8e3c3294ef794c77287827e3af9cec">https://archive.softwareheritage.org/swh:1:dir:50f44c9d73aa82fd3cd38347b9b6ed5c9af43a53;origin=https://github.com/gdelamar/drift;visit=swh:1:snp:d7c0ec941cf4282bc25b00df0862de834b7e1ed1;anchor=swh:1:rev:c79e1baeff8e3c3294ef794c77287827e3af9cec</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Snoo</surname><given-names>ML</given-names></name><name><surname>Miller</surname><given-names>AMP</given-names></name><name><surname>Ramsaran</surname><given-names>AI</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Exercise accelerates place cell representational drift</article-title><source>Current Biology</source><volume>33</volume><fpage>R96</fpage><lpage>R97</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.12.033</pub-id><pub-id pub-id-type="pmid">36750030</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driscoll</surname><given-names>LN</given-names></name><name><surname>Pettit</surname><given-names>NL</given-names></name><name><surname>Minderer</surname><given-names>M</given-names></name><name><surname>Chettih</surname><given-names>SN</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic reorganization of neuronal activity patterns in parietal cortex</article-title><source>Cell</source><volume>170</volume><fpage>986</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.07.021</pub-id><pub-id pub-id-type="pmid">28823559</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driscoll</surname><given-names>LN</given-names></name><name><surname>Duncker</surname><given-names>L</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Representational drift: Emerging theories for continual learning and experimental future directions</article-title><source>Current Opinion in Neurobiology</source><volume>76</volume><elocation-id>102609</elocation-id><pub-id pub-id-type="doi">10.1016/j.conb.2022.102609</pub-id><pub-id pub-id-type="pmid">35939861</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geva</surname><given-names>N</given-names></name><name><surname>Deitch</surname><given-names>D</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Time and experience differentially affect distinct aspects of hippocampal representational drift</article-title><source>Neuron</source><volume>111</volume><fpage>2357</fpage><lpage>2366</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2023.05.005</pub-id><pub-id pub-id-type="pmid">37315556</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grosmark</surname><given-names>AD</given-names></name><name><surname>BuzsÃ¡ki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences</article-title><source>Science</source><volume>351</volume><fpage>1440</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1126/science.aad1935</pub-id><pub-id pub-id-type="pmid">27013730</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hainmueller</surname><given-names>T</given-names></name><name><surname>Bartos</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Parallel emergence of stable and dynamic memory engrams in the hippocampus</article-title><source>Nature</source><volume>558</volume><fpage>292</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0191-2</pub-id><pub-id pub-id-type="pmid">29875406</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huber</surname><given-names>R</given-names></name><name><surname>MÃ¤ki</surname><given-names>H</given-names></name><name><surname>Rosanova</surname><given-names>M</given-names></name><name><surname>Casarotto</surname><given-names>S</given-names></name><name><surname>Canali</surname><given-names>P</given-names></name><name><surname>Casali</surname><given-names>AG</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Massimini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Human cortical excitability increases with time awake</article-title><source>Cerebral Cortex</source><volume>23</volume><fpage>332</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs014</pub-id><pub-id pub-id-type="pmid">22314045</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Josselyn</surname><given-names>SA</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Memory engrams: Recalling the past and imagining the future</article-title><source>Science</source><volume>367</volume><elocation-id>eaaw4325</elocation-id><pub-id pub-id-type="doi">10.1126/science.aaw4325</pub-id><pub-id pub-id-type="pmid">31896692</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>KÃ¡li</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Off-line replay maintains declarative memories in a model of hippocampal-neocortical interactions</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>286</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1038/nn1202</pub-id><pub-id pub-id-type="pmid">14983183</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khatib</surname><given-names>D</given-names></name><name><surname>Ratzon</surname><given-names>A</given-names></name><name><surname>Sellevoll</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Morris</surname><given-names>G</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Active experience, not time, determines within-day representational drift in dorsal CA1</article-title><source>Neuron</source><volume>111</volume><fpage>2348</fpage><lpage>2356</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2023.05.014</pub-id><pub-id pub-id-type="pmid">37315557</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kossio</surname><given-names>YFK</given-names></name><name><surname>Goedeke</surname><given-names>S</given-names></name><name><surname>Klos</surname><given-names>C</given-names></name><name><surname>Memmesheimer</surname><given-names>R-M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Drifting assemblies for persistent memory: Neuron transitions and unsupervised compensation</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2023832118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2023832118</pub-id><pub-id pub-id-type="pmid">34772802</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levenstein</surname><given-names>D</given-names></name><name><surname>Watson</surname><given-names>BO</given-names></name><name><surname>Rinzel</surname><given-names>J</given-names></name><name><surname>BuzsÃ¡ki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sleep regulation of the distribution of cortical firing rates</article-title><source>Current Opinion in Neurobiology</source><volume>44</volume><fpage>34</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.02.013</pub-id><pub-id pub-id-type="pmid">28288386</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levenstein</surname><given-names>D</given-names></name><name><surname>BuzsÃ¡ki</surname><given-names>G</given-names></name><name><surname>Rinzel</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>NREM sleep in the rodent neocortex and hippocampus reflects excitable dynamics</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2478</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10327-5</pub-id><pub-id pub-id-type="pmid">31171779</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manz</surname><given-names>P</given-names></name><name><surname>Memmesheimer</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Purely STDP-based assembly dynamics: Stability, learning, overlaps, drift and aging</article-title><source>PLOS Computational Biology</source><volume>19</volume><elocation-id>e1011006</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011006</pub-id><pub-id pub-id-type="pmid">37043481</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Sullivan</surname><given-names>DW</given-names></name><name><surname>Kinsky</surname><given-names>NR</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Same Hippocampal CA1 population simultaneously codes temporal information over multiple timescales</article-title><source>Current Biology</source><volume>28</volume><fpage>1499</fpage><lpage>1508</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.03.051</pub-id><pub-id pub-id-type="pmid">29706516</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Cai</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The brain in motion: How ensemble fluidity drives memory-updating and flexibility</article-title><source>eLife</source><volume>9</volume><elocation-id>e63550</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.63550</pub-id><pub-id pub-id-type="pmid">33372892</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Morales-Rodriguez</surname><given-names>D</given-names></name><name><surname>Dong</surname><given-names>Z</given-names></name><name><surname>Pennington</surname><given-names>ZT</given-names></name><name><surname>Francisco</surname><given-names>T</given-names></name><name><surname>Baxter</surname><given-names>MG</given-names></name><name><surname>Shuman</surname><given-names>T</given-names></name><name><surname>Cai</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Ensemble Remodeling Supports Memory-Updating</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.06.02.494530</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>AMP</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Memory: Ironing out a wrinkle in time</article-title><source>Current Biology</source><volume>28</volume><fpage>R599</fpage><lpage>R601</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.03.053</pub-id><pub-id pub-id-type="pmid">29787721</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pignatelli</surname><given-names>M</given-names></name><name><surname>Ryan</surname><given-names>TJ</given-names></name><name><surname>Roy</surname><given-names>DS</given-names></name><name><surname>Lovett</surname><given-names>C</given-names></name><name><surname>Smith</surname><given-names>LM</given-names></name><name><surname>Muralidhar</surname><given-names>S</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Engram cell excitability state determines the efficacy of memory retrieval</article-title><source>Neuron</source><volume>101</volume><fpage>274</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.11.029</pub-id><pub-id pub-id-type="pmid">30551997</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poo</surname><given-names>MM</given-names></name><name><surname>Pignatelli</surname><given-names>M</given-names></name><name><surname>Ryan</surname><given-names>TJ</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Martin</surname><given-names>KC</given-names></name><name><surname>Rudenko</surname><given-names>A</given-names></name><name><surname>Tsai</surname><given-names>LH</given-names></name><name><surname>Tsien</surname><given-names>RW</given-names></name><name><surname>Fishell</surname><given-names>G</given-names></name><name><surname>Mullins</surname><given-names>C</given-names></name><name><surname>GonÃ§alves</surname><given-names>JT</given-names></name><name><surname>Shtrahman</surname><given-names>M</given-names></name><name><surname>Johnston</surname><given-names>ST</given-names></name><name><surname>Gage</surname><given-names>FH</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name><name><surname>Long</surname><given-names>J</given-names></name><name><surname>BuzsÃ¡ki</surname><given-names>G</given-names></name><name><surname>Stevens</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>What is memory? The present state of the engram</article-title><source>BMC Biology</source><volume>14</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.1186/s12915-016-0261-6</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rashid</surname><given-names>AJ</given-names></name><name><surname>Yan</surname><given-names>C</given-names></name><name><surname>Mercaldo</surname><given-names>V</given-names></name><name><surname>Hsiang</surname><given-names>H-LL</given-names></name><name><surname>Park</surname><given-names>S</given-names></name><name><surname>Cole</surname><given-names>CJ</given-names></name><name><surname>De Cristofaro</surname><given-names>A</given-names></name><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Ramakrishnan</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>SY</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Competition between engrams influences fear memory formation and recall</article-title><source>Science</source><volume>353</volume><fpage>383</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1126/science.aaf0594</pub-id><pub-id pub-id-type="pmid">27463673</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rechavi</surname><given-names>Y</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Yizhar</surname><given-names>O</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Exercise increases information content and affects long-term stability of hippocampal place codes</article-title><source>Cell Reports</source><volume>41</volume><elocation-id>111695</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2022.111695</pub-id><pub-id pub-id-type="pmid">36417871</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogerson</surname><given-names>T</given-names></name><name><surname>Cai</surname><given-names>DJ</given-names></name><name><surname>Frank</surname><given-names>A</given-names></name><name><surname>Sano</surname><given-names>Y</given-names></name><name><surname>Shobe</surname><given-names>J</given-names></name><name><surname>Lopez-Aranda</surname><given-names>MF</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Synaptic tagging during memory allocation</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>157</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1038/nrn3667</pub-id><pub-id pub-id-type="pmid">24496410</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Geva</surname><given-names>N</given-names></name><name><surname>Sheintuch</surname><given-names>L</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal ensemble dynamics timestamp events in long-term memory</article-title><source>eLife</source><volume>4</volume><elocation-id>e12247</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12247</pub-id><pub-id pub-id-type="pmid">26682652</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rule</surname><given-names>ME</given-names></name><name><surname>OâLeary</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Self-healing codes: How stable neural populations can track continually reconfiguring neural representations</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2106692119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2106692119</pub-id><pub-id pub-id-type="pmid">35145024</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadeh</surname><given-names>S</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Contribution of behavioural variability to representational drift</article-title><source>eLife</source><volume>11</volume><elocation-id>e77907</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.77907</pub-id><pub-id pub-id-type="pmid">36040010</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silva</surname><given-names>AJ</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Rogerson</surname><given-names>T</given-names></name><name><surname>Shobe</surname><given-names>J</given-names></name><name><surname>Balaji</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Molecular and cellular approaches to memory allocation in neural circuits</article-title><source>Science</source><volume>326</volume><fpage>391</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.1126/science.1174519</pub-id><pub-id pub-id-type="pmid">19833959</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spalla</surname><given-names>D</given-names></name><name><surname>Cornacchia</surname><given-names>IM</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Continuous attractors for dynamic memories</article-title><source>eLife</source><volume>10</volume><elocation-id>e69499</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.69499</pub-id><pub-id pub-id-type="pmid">34520345</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tran</surname><given-names>LM</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Adult neurogenesis acts as a neural regularizer</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2206704119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2206704119</pub-id><pub-id pub-id-type="pmid">36322739</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Won</surname><given-names>J</given-names></name><name><surname>Karlsson</surname><given-names>MG</given-names></name><name><surname>Zhou</surname><given-names>M</given-names></name><name><surname>Rogerson</surname><given-names>T</given-names></name><name><surname>Balaji</surname><given-names>J</given-names></name><name><surname>Neve</surname><given-names>R</given-names></name><name><surname>Poirazi</surname><given-names>P</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CREB regulates excitability and the allocation of memory to subsets of neurons in the amygdala</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1438</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1038/nn.2405</pub-id><pub-id pub-id-type="pmid">19783993</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname><given-names>Y</given-names></name><name><surname>Burns</surname><given-names>LD</given-names></name><name><surname>Cocker</surname><given-names>ED</given-names></name><name><surname>Hamel</surname><given-names>EO</given-names></name><name><surname>Ghosh</surname><given-names>KK</given-names></name><name><surname>Kitch</surname><given-names>LJ</given-names></name><name><surname>El Gamal</surname><given-names>A</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-term dynamics of CA1 hippocampal place codes</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nn.3329</pub-id><pub-id pub-id-type="pmid">23396101</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88053.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Giocomo</surname><given-names>Lisa M</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Stanford School of Medicine</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This is an <bold>important</bold> theoretical study providing insight into how fluctuations in excitability can contribute to gradual changes in the mapping between population activity and stimulus, commonly referred to as representational drift. The authors provide <bold>convincing</bold> evidence that fluctuations can contribute to drift. Overall, this is a well-presented study that explores the question of how changes in intrinsic excitability can influence distinct memory representations.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88053.3.sa1</article-id><title-group><article-title>Reviewer #3 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary of the findings:</p><p>The authors explore an important question concerning the underlying mechanism of representational drift, which despite intense recent interest remains obscure. The paper explores the intriguing hypothesis that drift may reflect changes in the intrinsic excitability of neurons. The authors set out to provide theoretical insight into this potential mechanism.</p><p>They construct a rate model with all-to-all recurrent connectivity, in which recurrent synapses are governed by a standard Hebbian plasticity rule. This network receives a global input, constant across all neurons, which can be varied with time. Each neuron also is driven by an &quot;intrinsic excitability&quot; bias term, which does vary across cells. The authors study how activity in the network evolves as this intrinsic excitability term is changed.</p><p>They find that after initial stimulation of the network, those neurons where the excitability term is set high become more strongly connected and are in turn more responsive to the input. Each day the subset of neurons with high intrinsic excitability is changed, and the network's recurrent synaptic connectivity and responsiveness gradually shift, such that the new high intrinsic excitability subset becomes both more strongly activated by the global input and also more strongly recurrently connected. These changes result in drift, reflected by a gradual decrease across time in the correlation of the neuronal population vector response to the stimulus.</p><p>The authors are able to build a classifier that decodes the &quot;day&quot; (i.e. which subset of neurons had high intrinsic excitability) with perfect accuracy. This is despite the fact that the excitability bias during decoding is set to 0 for all neurons, and so the decoder is really detecting those neurons with strong recurrent connectivity, and in turn strong responses to the input. The authors show that it is also possible to decode the order in which different subsets of neurons were given high intrinsic excitability on previous &quot;days&quot;. This second result depends on the extent by which intrinsic excitability was increased: if the increase in intrinsic excitability was either too high or too low, it was not possible to read out any information about the past ordering of excitability changes.</p><p>Finally, using another Hebbian learning rule, the authors show that an output neuron, whose activity is a weighted sum of the activity of all neurons in the network, is able to read out the activity of the network. What this means specifically, is that although the set of neurons most active in the network changes, the output neuron always maintains a higher firing rate than a neuron with randomly shuffled synaptic weights, because the output neuron continuously updates its weights to sample from the highly active population at any given moment. Thus, the output neuron can read out a stable memory despite drift.</p><p>Strengths:</p><p>The authors are clear in their description of the network they construct and in their results. They convincingly show that when they change their &quot;intrinsic excitability term&quot;, upon stimulation, the Hebbian synapses in their network gradually evolve, and the combined synaptic connectivity and altered excitability result in drifting patterns of activity in response to an unchanging input (Fig. 1, Fig. 2a). Furthermore, their classification analyses (Fig. 2) show that information is preserved in the network, and their readout neuron successfully tracks the active cells (Fig. 3). Finally, the observation that only a specific range of excitability bias values permits decoding of the temporal structure of the history of intrinsic excitability (Fig. 2f and Figure S1) is interesting, and as the authors point out, not trivial.</p><p>Weaknesses:</p><p>1. The way the network is constructed, there is no formal difference between what the authors call &quot;input&quot;, Î(t), and what they call &quot;intrinsic excitability&quot; Æ_i(t) (see Equation 3). These are two separate terms that are summed (Eq. 3) to define the rate dynamics of the network. The authors could have switched the names of these terms: Î(t) could have been considered a global &quot;intrinsic excitability term&quot; that varied with time and Æ_i(t) could have been the external input received by each neuron in the network. In that case, the paper would have considered the consequence of &quot;slow fluctuations of external input&quot; rather than &quot;slow fluctuations of intrinsic excitability&quot;, but the results would have been the same. The difference is therefore semantic. The consequence is that this paper is not necessarily about &quot;intrinsic excitability&quot;, rather it considers how a Hebbian network responds to changes in excitatory drive, regardless of whether those drives are labeled &quot;input&quot; or &quot;intrinsic excitability&quot;.</p><p>A revised version of the manuscript models &quot;slope-based&quot; excitability changes in addition to &quot;threshold-based&quot; changes. This serves to address the above concern that as constructed here changes in excitability threshold are not distinguishable from changes in input. However, it remains unclear what the model would do should only a subset of neurons receive a given, fixed input. In that case, are excitability changes sufficient to induce drift? This remains an important question that is not addressed by the paper in its current form.</p><p>1. Given how the learning rule that defines the input to the readout neuron is constructed, it is trivial that this unit responds to the most active neurons in the network, more so than a neuron assigned random weights. What would happen if the network included more than one &quot;memory&quot;? Would it be possible to construct a readout neuron that could classify two distinct patterns? Along these lines, what if there were multiple, distinct stimuli used to drive this network, rather than the global input the authors employ here? Does the system, as constructed, have the capacity to provide two distinct patterns of activity in response to two distinct inputs?</p><p>A revised version of the manuscript addresses this question, demonstrating that the network is capable of maintaining two distinct memories.</p><p>Impact:</p><p>Defining the potential role of changes in intrinsic excitability in drift is fundamental. Thus, this paper represents an important contribution. What we see here is that changes in intrinsic excitability are sufficient to induce drift. This raises the question for future work of the specific contributions of changing excitability from changing input to representational drift.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88053.3.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Delamare</surname><given-names>Geoffroy</given-names></name><role specific-use="author">Author</role><aff><institution>Imperial College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Zaki</surname><given-names>Yosif</given-names></name><role specific-use="author">Author</role><aff><institution>Icahn School of Medicine at Mount Sinai</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Cai</surname><given-names>Denise J</given-names></name><role specific-use="author">Author</role><aff><institution>Icahn School of Medicine at Mount Sinai</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Clopath</surname><given-names>Claudia</given-names></name><role specific-use="author">Author</role><aff><institution>Imperial College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authorsâ response to the latest reviews.</p><disp-quote content-type="editor-comment"><p>A revised version of the manuscript models &quot;slope-based&quot; excitability changes in addition to &quot;threshold-based&quot; changes. This serves to address the above concern that as constructed here changes in excitability threshold are not distinguishable from changes in input. However, it remains unclear what the model would do should only a subset of neurons receive a given, fixed input. In that case, are excitability changes sufficient to induce drift? This remains an important question that is not addressed by the paper in its current form.</p></disp-quote><p>Thank you for this important point. In the simulation of two memories (Fig. S6), we stimulated half of the neural population for each of the two memories. We therefore also showed that drift happens when only a subset of neuron was simulated.</p><p>The following is the authorsâ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>Current experimental work reveals that brain areas implicated in episodic and spatial memory have a dynamic code, in which activity r imulated networks for epresenting familiar events/locations changes over time. This paper shows that such reconfiguration is consistent with underlying changes in the excitability of cells in the population, which ties these observations to a physiological mechanism.</p><p>Delamare et al. use a recurrent network model to consider the hypothesis that slow fluctuations in intrinsic excitability, together with spontaneous reactivations of ensembles, may cause the structure of the ensemble to change, consistent with the phenomenon of representational drift. The paper focuses on three main findings from their model: (1) fluctuations in intrinsic excitability lead to drift, (2) this drift has a temporal structure, and (3) a readout neuron can track the drift and continue to decode the memory. This paper is relevant and timely, and the work addresses questions of both a potential mechanism (fluctuations in intrinsic excitability) and purpose (time-stamping memories) of drift.</p><p>The model used in this study consists of a pool of 50 all-to-all recurrently connected excitatory neurons with weights changing according to a Hebbian rule. All neurons receive the same input during stimulation, as well as global inhibition. The population has heterogeneous excitability, and each neuron's excitability is constant over time apart from a transient increase on a single day. The neurons are divided into ensembles of 10 neurons each, and on each day, a different ensemble receives a transient increase in the excitability of each of its neurons, with each neuron experiencing the same amplitude of increase. Each day for four days, repetitions of a binary stimulus pulse are applied to every neuron.</p><p>The modeling choices focus in on the parameter of interest-the excitability-and other details are generally kept as straightforward as possible. That said, I wonder if certain aspects may be overly simple. The extent of the work already performed, however, does serve the intended purpose, and so I think it would be sufficient for the authors to comment on these choices rather than to take more space in this paper to actually implement these choices. What might happen were more complex modeling choices made? What is the justification for the choices that are made in the present work?</p><p>The two specific modeling choices I question are (1) the excitability dynamics and (2) the input stimulus. The ensemble-wide synchronous and constant-amplitude excitability increase, followed by a return to baseline, seems to be a very simplified picture of the dynamics of intrinsic excitability. At the very least, justification for this simplified picture would benefit the reader, and I would be interested in the authors' speculation about how a more complex and biologically realistic dynamics model might impact the drift in their network model. Similarly, the input stimulus being binary means that, on the singleneuron level, the only type of drift that can occur is a sort of drop-in/drop-out drift; this choice excludes the possibility of a neuron maintaining significant tuning to a stimulus but changing its preferred value. How would the use of a continuous input variable influence the results.</p></disp-quote><p>(1) In our model, neurons tend to compete for allocation to the memory ensemble: neurons with higher excitability tend to be preferentially allocated and neurons with lower excitability do not respond to the stimulus. Because relative, but not absolute excitability biases this competition, we suggest that the exact distribution of excitability would not impact the results qualitatively. On the other hand, the results might vary if excitability was considered dependent on the activity of the neurons as previously reported experimentally (Cai 2016, Rachid 2016, Pignatelli 2019). An increase in excitability following neural activity might induce higher correlation among ensembles on consecutive days, decreasing the drift.</p><p>(2) We thank the reviewer for this very good point. Indeed, two recent studies (Geva 2023 , Khatib 2023) have highlighted distinct mechanisms for a drift of the mean firing rate and the tuning curve. We extended the last part of the discussion to include this point: âFinally, we intended to model drift in the firing rates, as opposed to a drift in the turning curve of the neurons. Recent studies suggest that drifts in the mean firing rate and tuning curve arise from two different mechanisms [33, 34]. Experience drives a drift in neurons turning curve while the passage of time drives a drift in neurons firing rate. In this sense, our study is consistent with these findings by providing a possible mechanism for a drift in the mean firing rates of the neurons driven a dynamical excitability. Our work suggests that drift can depend on any experience having an impact on excitability dynamics such as exercise as previously shown experimentally [9, 35] but also neurogenesis [9, 31, 36], sleep [37] or increase in dopamine level [38]â</p><disp-quote content-type="editor-comment"><p>Result (1): Fluctuations in intrinsic excitability induce drift</p><p>The two choices highlighted above appear to lead to representations that never recruit the neurons in the population with the lowest baseline excitability (Figure 1b: it appears that only 10 neurons ever show high firing rates) and produce networks with very strong bidirectional coupling between this subset of neurons and weak coupling elsewhere (Figure 1d). This low recruitment rate need may not necessarily be problematic, but it stands out as a point that should at least be commented on. The fact that only 10 neurons (20% of the population) are ever recruited in a representation also raises the question of what would happen if the model were scaled up to include more neurons.</p></disp-quote><p>This is a very good point. To test how the model depends on the network size, we plotted the drift index against the size of the ensemble. With this current implementation, we did not observe a significant correlation between the drift rate and size of the initial ensemble (Figure S2).</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>The rate of the drift does not depend on the size of the engram.</title><p>Drift rate against the size of the original engram. Each dot shows one simulation (Methods). n = 100 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-sa2-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>Result (2): The observed drift has a temporal structure</p><p>The authors then demonstrate that the drift has a temporal structure (i.e., that activity is informative about the day on which it occurs), with methods inspired by Rubin et al. (2015). Rubin et al. (2015) compare single-trial activity patterns on a given session with full-session activity patterns from each session. In contrast, Delamare et al. here compare full-session patterns with baseline excitability (E = 0) patterns. This point of difference should be motivated. What does a comparison to this baseline excitability activity pattern tell us? The ordinal decoder, which decodes the session order, gives very interesting results: that an intermediate amplitude E of excitability increase maximizes this decoder's performance. This point is also discussed well by the authors. As a potential point of further exploration, the use of baseline excitability patterns in the day decoder had me wondering how the ordinal decoder would perform with these baseline patterns.</p></disp-quote><p>This is a good point. Here, we aimed at dissociating the role of excitability from the one of the recurrent currents. We introduced a time decoder that compares the pattern with baseline excitability (E = 0), in order to test whether the temporal information was encoded in the ensemble i.e. in the recurrent weights. By contrast, because the neural activity is by construction biased towards excitability, a time decoder performed on the full session would work in a trivial way.</p><disp-quote content-type="editor-comment"><p>Result (3): A readout neuron can track drift</p><p>The authors conclude their work by connecting a readout neuron to the population with plastic weights evolving via a Hebbian rule. They show that this neuron can track the drifting ensemble by adjusting its weights. These results are shown very neatly and effectively and corroborate existing work that they cite very clearly.</p><p>Overall, this paper is well-organized, offers a straightforward model of dynamic intrinsic excitability, and provides relevant results with appropriate interpretations. The methods could benefit from more justification of certain modeling choices, and/or an exploration (either speculative or viaimplementation) of what would happen with more complex choices. This modeling work paves the way for further explorations of how intrinsic excitability fluctuations influence drifting representations.</p><p><bold>Reviewer #2 (Public Review):</bold></p><p>In this computational study, Delamare et al identify slow neuronal excitability as one mechanism underlying representational drift in recurrent neuronal networks and that the drift is informative about the temporal structure of the memory and when it has been formed. The manuscript is very well written and addresses a timely as well as important topic in current neuroscience namely the mechanisms that may underlie representational drift.</p><p>The study is based on an all-to-all recurrent neuronal network with synapses following Hebbian plasticity rules. On the first day, a cue-related representation is formed in that network and on the next 3 days it is recalled spontaneously or due to a memory-related cue. One major observation is that representational drift emerges day-by-day based on intrinsic excitability with the most excitable cells showing highest probability to replace previously active members of the assembly. By using a daydecoder, the authors state that they can infer the order at which the reactivation of cell assemblies happened but only if the excitability state was not too high. By applying a read-out neuron, the authors observed that this cell can track the drifting ensemble which is based on changes of the synaptic weights across time. The only few questions which emerged and could be addressed either theoretically or in the discussion are as follows:</p><p>1. Would the similar results be obtained if not all-to-all recurrent connections would have been molded but more realistic connectivity profiles such as estimated for CA1 and CA3?</p></disp-quote><p>This is a very interesting point. We performed further simulations to show that the results are not dependent on the exact structure of the network. In particular, we show that all-to-all connectivity is not required to observe a drift of the ensemble. We found similar results when the recurrent weights matrix was made sparse (Fig. S4a-c, Methods). Similarly to all-to-all connectivity, we found that the ensemble is informative about its temporal history (Fig. S4d) and that an output neuron can decode the ensemble continuously (Fig. S4e).</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>Sparse recurrent connectivity shows similar drifting behavior as all-to-all connectivity.</title><p>The same simulation protocol as Fig. 1 was used while the recurrent weights matrix was made 50% sparse (Methods). (a) Firing rates of the neurons across time. The red traces correspond to neurons belonging to the first assembly, namely that have a firing rate higher than the active threshold after the first stimulation. The black bars show the stimulation and the dashed line shows the active threshold. (b) Recurrent weights matrices after each of the four stimuli show the drifting assembly. (c) Correlation of the patterns of activity between the first day and every other days. (d) Student's test t-value of the ordinal time decoder, for the real (red) and shuffled (orange) data and for different amplitudes of excitability E. (e) Center of mass of the distribution of the output weights (Methods) across days. (c-e) Data are shown as mean Â± s.e.m. for n = 10 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-sa2-fig2-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>1. How does the number of excited cells that could potentially contribute to an engram influence the representational drift and the decoding quality?</p></disp-quote><p>This is indeed a very good question. We did not observe a significant correlation between the drift rate and size of the initial ensemble (Fig. S2).</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><caption><title>The rate of the drift does not depend on the size of the engram.</title><p>Drift rate against the size of the original engram. Each dot shows one simulation (Methods). n = 100 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-sa2-fig3-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>1. How does the rate of the drift influence the quality of readout from the readout-out neuron?</p></disp-quote><p>We thank the reviewer for this interesting question. We introduced a measure of the âread-out qualityâ and plotted this value against the rate of the drift. We found a small correlation between the two quantities. Indeed, the read-out quality decreases with the rate of the drift.</p><fig id="sa2fig4" position="float"><label>Author response image 4.</label><caption><title>The quality of the read-out decreases with the rate of the drift.</title><p>Read-out quality computed on the firing rate of the output neuron against the rate of the drift (Methods). Each dot shows one simulation. n = 100 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-sa2-fig4-v1.tif"/></fig><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>The authors explore an important question concerning the underlying mechanism of representational drift, which despite intense recent interest remains obscure. The paper explores the intriguing hypothesis that drift may reflect changes in the intrinsic excitability of neurons. The authors set out to provide theoretical insight into this potential mechanism.</p><p>They construct a rate model with all-to-all recurrent connectivity, in which recurrent synapses are governed by a standard Hebbian plasticity rule. This network receives a global input, constant across all neurons, which can be varied with time. Each neuron also is driven by an &quot;intrinsic excitability&quot; bias term, which does vary across cells. The authors study how activity in the network evolves as this intrinsic excitability term is changed.</p><p>They find that after initial stimulation of the network, those neurons where the excitability term is set high become more strongly connected and are in turn more responsive to the input. Each day the subset of neurons with high intrinsic excitability is changed, and the network's recurrent synaptic connectivity and responsiveness gradually shift, such that the new high intrinsic excitability subset becomes both more strongly activated by the global input and also more strongly recurrently connected. These changes result in drift, reflected by a gradual decrease across time in the correlation of the neuronal population vector response to the stimulus.</p><p>The authors are able to build a classifier that decodes the &quot;day&quot; (i.e. which subset of neurons had high intrinsic excitability) with perfect accuracy. This is despite the fact that the excitability bias during decoding is set to 0 for all neurons, and so the decoder is really detecting those neurons with strong recurrent connectivity, and in turn strong responses to the input. The authors show that it is also possible to decode the order in which different subsets of neurons were given high intrinsic excitability on previous &quot;days&quot;. This second result depends on the extent by which intrinsic excitability was increased: if the increase in intrinsic excitability was either too high or too low, it was not possible to read out any information about past ordering of excitability changes.</p><p>Finally, using another Hebbian learning rule, the authors show that an output neuron, whose activity is a weighted sum of the activity of all neurons in the network, is able to read out the activity of the network. What this means specifically, is that although the set of neurons most active in the network changes, the output neuron always maintains a higher firing rate than a neuron with randomly shuffled synaptic weights, because the output neuron continuously updates its weights to sample from the highly active population at any given moment. Thus, the output neuron can readout a stable memory despite drift.</p><p>Strengths:</p><p>The authors are clear in their description of the network they construct and in their results. They convincingly show that when they change their &quot;intrinsic excitability term&quot;, upon stimulation, the Hebbian synapses in their network gradually evolve, and the combined synaptic connectivity and altered excitability result in drifting patterns of activity in response to an unchanging input (Fig. 1, Fig. 2a). Furthermore, their classification analyses (Fig. 2) show that information is preserved in the network, and their readout neuron successfully tracks the active cells (Fig. 3). Finally, the observation that only a specific range of excitability bias values permits decoding of the temporal structure of the history of intrinsic excitability (Fig. 2f and Figure S1) is interesting, and as the authors point out, not trivial.</p><p>Weaknesses:</p><p>1. The way the network is constructed, there is no formal difference between what the authors call &quot;input&quot;, Î(t), and what they call &quot;intrinsic excitability&quot; Æ_i(t) (see Equation 3). These are two separate terms that are summed (Eq. 3) to define the rate dynamics of the network. The authors could have switched the names of these terms: Î(t) could have been considered a global &quot;intrinsic excitability term&quot; that varied with time and Æ_i(t) could have been the external input received by each neuron i in the network. In that case, the paper would have considered the consequence of &quot;slow fluctuations of external input&quot; rather than &quot;slow fluctuations of intrinsic excitability&quot;, but the results would have been the same. The difference is therefore semantic. The consequence is that this paper is not necessarily about &quot;intrinsic excitability&quot;, rather it considers how a Hebbian network responds to changes in excitatory drive, regardless of whether those drives are labeled &quot;input&quot; or &quot;intrinsic excitability&quot;.</p></disp-quote><p>This is a very good point. We performed further simulations to model âslope-basedâ, instead of âthreshold-basedâ, changes in excitability (Fig. S5a, Methods). In this new definition of excitability, we changed the slope of the activation function, which is initially sampled from a random distribution. By introducing a varying excitability, we found very similar results than when excitability was varied as the threshold of the activation function (Fig. S5b-d). We also found similarly that the ensemble is informative about its temporal history (Fig. S5e) and that an output neuron can decode the ensemble continuously (Fig. S5f).</p><fig id="sa2fig5" position="float"><label>Author response image 5.</label><caption><title>Change of excitability as a variable slope of the input-output function shows similar drifting behavior as considering a change in the threshold.</title><p>The same simulation protocol as Fig. 1 was used while the excitability changes were modeled as a change in the activation function slope (Methods). (a) Schema showing two different ways of defining excitability, as a threshold (top) or slope (bottom) of the activation function. Each line shows one neuron and darker lines correspond to neurons with increased excitability. (b) Firing rates of the neurons across time. The red traces correspond to neurons belonging to the first assembly, namely that have a firing rate higher than the active threshold after the first stimulation. The black bars show the stimulation and the dashed line shows the active threshold. (c) Recurrent weights matrices after each of the four stimuli show the drifting assembly. (d) Correlation of the patterns of activity between the first day and every other days. (e) Student's test t-value of the ordinal time decoder, for the real (red) and shuffled (orange) data and for different amplitudes of excitability E. (f) Center of mass of the distribution of the output weights (Methods) across days. (d-f) Data are shown as mean Â± s.e.m. for n = 10 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-sa2-fig5-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>1. Given how the learning rule that defines input to the readout neuron is constructed, it is trivial that this unit responds to the most active neurons in the network, more so than a neuron assigned random weights. What would happen if the network included more than one &quot;memory&quot;? Would it be possible to construct a readout neuron that could classify two distinct patterns? Along these lines, what if there were multiple, distinct stimuli used to drive this network, rather than the global input the authors employ here? Does the system, as constructed, have the capacity to provide two distinct patterns of activity in response to two distinct inputs?</p></disp-quote><p>This is an interesting point. In order to model multiple memories, we introduced non-uniform feedforward inputs, defining different âcontextsâ (Methods). We adapted our model so that two contexts target two random sub-populations in the network. We also introduced a second output neuron to decode the second memory. The simulation protocol was adapted so that each of the two contexts are stimulated every day (Fig. S6a). We found that the network is able to store two ensembles that drift independently (Fig. S6 and S7a). We were also able to decode temporal information from the patterns of activity of both ensembles (Fig. S7b). Finally, both memories could be decoded independently using two output neurons (Fig. S7c and d).</p><fig id="sa2fig6" position="float"><label>Author response image 6.</label><caption><title>Two distinct ensembles can be encoded and drift independently.</title><p>a) and b) Firing rates of the neurons across time. The red traces in panel b) correspond to neurons belonging to the first assembly and the green traces to the second assembly on the first day. They correspond to neurons having a firing rate higher than the active threshold after the first stimulation of each assembly. The black bars show the stimulation and the dashed line shows the active threshold. c) Recurrent weights matrices after each of the eight stimuli showing the drifting of the first (top) and second (bottom) assembly.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-sa2-fig6-v1.tif"/></fig><fig id="sa2fig7" position="float"><label>Author response image 7.</label><caption><title>The two ensembles are informative about their temporal history and can be decoded using two output neurons.</title><p>a) Correlation of the patterns of activity between the first day and every other days, for the first assembly (red) and the second assembly (green). b) Student's test t-value of the ordinal time decoder, for the first (red, left) and second ensemble (green, right) for different amplitudes of excitability E. Shuffled data are shown in orange. c) Center of mass of the distribution of the output weights (Methods) across days for the first (w?ut , red) and second (W20L't , green) ensemble. a-c) Data are shown as mean Â± s.e.m. for n = 10 simulations. d) Output neurons firing rate across time for the first ensemble (Yl, top) and the second ensemble (h, bottom). The red and green traces correspond to the real output. The dark blue, light blue and yellow traces correspond to the cases where the output weights were randomly shuffled for every time points after presentation of the first, second and third stimulus, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88053-sa2-fig7-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>Impact:</p><p>Defining the potential role of changes in intrinsic excitability in drift is fundamental. Thus, this paper represents a potentially important contribution. Unfortunately, given the way the network employed here is constructed, it is difficult to tease apart the specific contribution of changing excitability from changing input. This limits the interpretability and applicability of the results.</p></disp-quote></body></sub-article></article>