<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">77945</article-id><article-id pub-id-type="doi">10.7554/eLife.77945</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Automated hippocampal unfolding for morphometry and subfield segmentation with HippUnfold</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-143573"><name><surname>DeKraker</surname><given-names>Jordan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4093-0582</contrib-id><email>jordan.dekraker@mail.mcgill.ca</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-272852"><name><surname>Haast</surname><given-names>Roy AM</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8543-2467</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-272854"><name><surname>Yousif</surname><given-names>Mohamed D</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-272855"><name><surname>Karat</surname><given-names>Bradley</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6550-1418</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-292278"><name><surname>Lau</surname><given-names>Jonathan C</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-20234"><name><surname>Köhler</surname><given-names>Stefan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1905-6453</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-160397"><name><surname>Khan</surname><given-names>Ali R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0760-8647</contrib-id><email>ali.khan@uwo.ca</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Robarts Research Institute, Schulich School of Medicine and Dentistry, The University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Western Institute for Neuroscience, The University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Clinical Neurological Sciences, Division of Neurosurgery, Schulich School of Medicine &amp; Dentistry, The University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>School of Biomedical Engineering, The University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Psychology, Faculty of Social Science, The University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Medical Biophysics, Schulich School of Medicine and Dentistry, The University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Forstmann</surname><given-names>Birte U</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution></institution-wrap><country>Netherlands</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>15</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e77945</elocation-id><history><date date-type="received" iso-8601-date="2022-02-17"><day>17</day><month>02</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-12-13"><day>13</day><month>12</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-12-05"><day>05</day><month>12</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.12.03.471134"/></event></pub-history><permissions><copyright-statement>© 2022, DeKraker et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>DeKraker et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-77945-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-77945-figures-v2.pdf"/><abstract><p>Like neocortical structures, the archicortical hippocampus differs in its folding patterns across individuals. Here, we present an automated and robust BIDS-App, HippUnfold, for defining and indexing individual-specific hippocampal folding in MRI, analogous to popular tools used in neocortical reconstruction. Such tailoring is critical for inter-individual alignment, with topology serving as the basis for homology. This topological framework enables qualitatively new analyses of morphological and laminar structure in the hippocampus or its subfields. It is critical for refining current neuroimaging analyses at a meso- as well as micro-scale. HippUnfold uses state-of-the-art deep learning combined with previously developed topological constraints to generate uniquely folded surfaces to fit a given subject’s hippocampal conformation. It is designed to work with commonly employed sub-millimetric MRI acquisitions, with possible extension to microscopic resolution. In this paper, we describe the power of HippUnfold in feature extraction, and highlight its unique value compared to several extant hippocampal subfield analysis methods.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>hippocampal subfields</kwd><kwd>magnetic resonance imaging</kwd><kwd>deep learning</kwd><kwd>Brain Imaging Data Standards</kwd><kwd>hippocampus</kwd><kwd>computational anatomy</kwd><kwd>image segmentation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><award-id>366062</award-id><principal-award-recipient><name><surname>Köhler</surname><given-names>Stefan</given-names></name><name><surname>Khan</surname><given-names>Ali R</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001804</institution-id><institution>Canada Research Chairs</institution></institution-wrap></funding-source><award-id>950-231964</award-id><principal-award-recipient><name><surname>Khan</surname><given-names>Ali R</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN-2015-06639</award-id><principal-award-recipient><name><surname>Khan</surname><given-names>Ali R</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000196</institution-id><institution>Canada Foundation for Innovation</institution></institution-wrap></funding-source><award-id>37427</award-id><principal-award-recipient><name><surname>Khan</surname><given-names>Ali R</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009408</institution-id><institution>Brain Canada</institution></institution-wrap></funding-source><award-id>Platform Support Grant for the Centre for Functional and Metabolic Mapping</award-id><principal-award-recipient><name><surname>Khan</surname><given-names>Ali R</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010785</institution-id><institution>Canada First Research Excellence Fund</institution></institution-wrap></funding-source><award-id>BrainsCAN</award-id><principal-award-recipient><name><surname>Khan</surname><given-names>Ali R</given-names></name><name><surname>Köhler</surname><given-names>Stefan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Automated computational unfolding of the hippocampus allows analyses at its mesoscale and facilitates novel discoveries in the study of cognition and disease.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Most neurological or psychiatric diseases with widespread effects on the brain show strong and early impact on the hippocampus (e.g. <xref ref-type="bibr" rid="bib48">Thom, 2014</xref>). This highly plastic grey matter (GM) structure is also critical in the fast formation of episodic and spatial memories (e.g. <xref ref-type="bibr" rid="bib41">O’Keefe and Nadel, 1978</xref>). Examination of this structure with non-invasive neuroimaging, such as MRI, provides great promise for furthering our understanding, diagnosis, and subtyping of these diseases and cognitive processes in the hippocampus and its component subfields (<xref ref-type="bibr" rid="bib16">Dill et al., 2015</xref>).</p><p>In current neuroimaging analyses the hippocampus is typically modelled as a subcortical volume, but it is actually made up of a folded archicortical mantle, or ‘ribbon’ (<xref ref-type="bibr" rid="bib19">Duvernoy, 1998</xref>). Representing the hippocampus as such can be leveraged to enable qualitatively new analyses, such as registration, despite inter-individual differences in gyrification or folding structure, through topological alignment. In previous work, this was shown to account for much inter-individual variability in MRI-based manual subfield segmentations (<xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>). Additionally, representation as a ribbon allows the hippocampus to be factorized into surface area and thickness, which can be further subdivided for laminar analyses. These methods are thus critical in advancing MRI research from the macroscopic scale to the subfield, cortical column, and laminar scales. Similar approaches have already yielded advances in neocortical analysis methods (<xref ref-type="bibr" rid="bib49">Van Essen et al., 2000</xref>; <xref ref-type="bibr" rid="bib53">Waehnert et al., 2014</xref>).</p><p>Denoting the hippocampal archicortical ribbon is challenging because it is thin (0.5–2 mm), its folding pattern varies considerably between individuals (<xref ref-type="bibr" rid="bib10">Chang et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Ding and Van Hoesen, 2015</xref>), and this folding may even continue to change from early development through adulthood (<xref ref-type="bibr" rid="bib7">Cai et al., 2019</xref>). We present here a set of tools to overcome these challenges using a highly sensitive and generalizable ‘U-Net’ deep learning architecture (<xref ref-type="bibr" rid="bib33">Isensee et al., 2021</xref>), combined with previous work that enforces topological constraints on hippocampal tissue (<xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>).</p><p>In previous work (<xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>), we developed a method to computationally unfold the hippocampus along its geodesic anterior-posterior (AP) and proximal-distal (PD, i.e. proximal to the neocortex, with the dentate gyrus [DG] being most distal) axes. We demonstrated for the first time several qualitative properties using in vivo MRI, such as the contiguity of all subfields along the curvature of the hippocampal head (anterior) and tail (posterior), previously described only in histology. This pioneering work relied heavily on detailed manual tissue segmentations including the high-myelinated stratum radiatum, lacunosum, and moleculare (SRLM), a commonly used landmark that separates hippocampal folds along the inward ‘curl’ of the hippocampus. In this work we also considered curvature and digitations along the AP axis of the hippocampus, most prominently occurring in the hippocampal head (<xref ref-type="bibr" rid="bib19">Duvernoy, 1998</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Ding and Van Hoesen, 2015</xref>; <xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>). Each of these features are highly variable between individuals, making them difficult to capture using automated volumetric atlas-based methods and time-consuming to detect manually.</p><p>The current work automates the detailed tissue segmentation required for hippocampal unfolding using a state-of-the-art ‘U-Net’ deep convolutional neural network (<xref ref-type="bibr" rid="bib33">Isensee et al., 2021</xref>). In particular, we aimed to capture morphological variability between hippocampi at the level of digitations or gyrifications which are not typically considered using existing automated methods which employ either a single atlas or multi-atlas fusion (e.g. <xref ref-type="bibr" rid="bib61">Yushkevich et al., 2015b</xref>; <xref ref-type="bibr" rid="bib9">Chakravarty et al., 2013</xref>; <xref ref-type="bibr" rid="bib43">Pipitone et al., 2014</xref>). U-Net architectures have been shown to be generalizable and sensitive to anatomical variations in many medical image processing tasks (<xref ref-type="bibr" rid="bib18">Du et al., 2020</xref>), making them ideal to overcome this challenge.</p><p>Estimating hippocampal subfield boundaries in MRI is challenging since their histological hallmarks are not directly available in MRI due to lower spatial resolution and lack of appropriate contrasts, which is an ongoing hurdle in neuroimaging (<xref ref-type="bibr" rid="bib58">Wisse et al., 2017b</xref>; <xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>). However, post-mortem studies show that the subfields are topologically constrained according to their differentiation from a common flat cortical mantle (<xref ref-type="bibr" rid="bib19">Duvernoy, 1998</xref>). Thus, a folded representation of hippocampal tissue provides a powerful intermediate between a raw MRI and subfield labels (<xref ref-type="bibr" rid="bib14">DeKraker et al., 2021</xref>), analogous to the reconstruction of a 3D neocortical surface. This surface can then be parcellated into subregions without topological breaks (<xref ref-type="bibr" rid="bib49">Van Essen et al., 2000</xref>), overcoming many limitations of current subfield segmentation methods (<xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>). Here, we apply surface-based subfield boundary definitions obtained via manual segmentation of BigBrain 3D histology (<xref ref-type="bibr" rid="bib1">Amunts et al., 2013</xref>) which was additionally supported by a data-driven parcellation (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>). We additionally demonstrate how labels used in the popular Freesurfer (FS7) (<xref ref-type="bibr" rid="bib31">Iglesias et al., 2015</xref>) and Automatic Segmentation of Hippocampal Subfields (ASHS) (<xref ref-type="bibr" rid="bib61">Yushkevich et al., 2015b</xref>) software packages can be applied under our topologically constrained framework.</p><p>Altogether, we combine novel U-Net tissue classification, previously developed hippocampal unfolding (<xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>), and topologically constrained subfield labelling (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>) together into a single pipeline which we refer to as ‘HippUnfold’ hereinafter. We designed this pipeline to employ FAIR principles (findability, accessibility, interoperability, reusability) with support across a wide range of use-cases centred around sub-millimetric MRI.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>HippUnfold aligns and visualizes data on folded or unfolded surfaces</title><p>HippUnfold is presented here as a fully automated pipeline with outputs including hippocampal tissue and subfield segmentations, geodesic Laplace coordinates spanning over hippocampal GM voxels, and inner, midthickness and outer hippocampal surfaces. These surfaces have corresponding vertices, providing an implicit topological registration between individuals.</p><p>The overall pipeline for HippUnfold is illustrated briefly in <xref ref-type="fig" rid="fig1">Figure 1</xref>. A comprehensive breakdown of each step is provided in the Materials and methods.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Overview of HippUnfold pipeline.</title><p>First, input MRI images are preprocessed and cropped around the left and right hippocampi. Second, a U-Net neural network architecture (nnUNet; <xref ref-type="bibr" rid="bib33">Isensee et al., 2021</xref>) is used to segment hippocampal grey matter (GM), the high-myelinated stratum radiatum, lacunosum, and moleculare (SRLM), and structures surrounding the hippocampus. Segmentations are post-processed via template shape injection. Third, Laplace’s equation is solved across the anterior-posterior (AP), proximal-distal (PD), and inner-outer (IO) extent of hippocampal GM, making up a geodesic coordinate framework. Fourth, scattered interpolants are used to determine equivalent coordinates between native Cartesian space and unfolded space. Fifth, unfolded surfaces with template subfield labels (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>) are transformed to subjects’ native folded hippocampal configurations. Morphological features (e.g. thickness) are extracted using Connectome Workbench (<xref ref-type="bibr" rid="bib22">Glasser et al., 2013</xref>) on these folded native space surfaces. Sixth, volumetric subfields are generated by filling the voxels between inner and outer surfaces with the corresponding subfield labels. Additional details on this pipeline can be found in the Materials and methods.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Diagram of the nnU-net architecture used for HippUnfold.</title><p>This architecture was automatically configured as the 3D_fullres network, using the 128 × 256 × 128 (0.3 × 0.3 × 0.3 mm<sup>3</sup>) hippocampal subregion images as training data. All conv3D blocks have stride = 1,1,1 (unless otherwise specified), padding=(1,1,1), instance normalization, and leaky ReLu activation functions (negative slope = 0.01). Output layers for the nine-label (including background) tissue segmentation are present at five feature-map resolutions (deep supervision), and the loss function used for training is an average of a Dice and cross-entropy loss functions. For full details on the training scheme, we refer readers to the supplementary material provided in <xref ref-type="bibr" rid="bib53">Waehnert et al., 2014</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig1-figsupp1-v2.tif"/></fig></fig-group><p>In addition to subfield segmentation, HippUnfold extracts morphological features and can be used to sample quantitative MRI data along a midthickness surface to minimize partial voluming with surrounding structures (see Materials and methods section ‘HippUnfold detailed pipeline’ for details). This is visualized across n=148 test subjects on an unfolded surface and group-averaged folded surface in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Note that the group averaging takes place on a surface and so does not break individual subjects’ topologies. Quantitative MRI features examined here include T1w/T2w ratio as a proxy measure for intracortical myelin (<xref ref-type="bibr" rid="bib20">Ganzetti et al., 2014</xref>), mean diffusivity, and fractional anisotropy (<xref ref-type="bibr" rid="bib29">Hernández et al., 2013</xref>; <xref ref-type="bibr" rid="bib45">Sotiropoulos et al., 2016</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Average hippocampal folded and unfolded surfaces showing subfields, morphometric, and quantitative MRI measures from the Human Connectome Project-Young Adult (HCP-YA) test dataset (see <xref ref-type="table" rid="table1">Table 1</xref> of Materials and methods).</title><p>The same topologically defined subfields were applied in unfolded space to all subjects (top), which are also overlaid on quantitative MRI plots (black lines). The dentate gyrus (DG) is represented as a distinct surface, reflecting its unique topology, and is mostly occluded in native space. Thickness was not measured across the DG surface. Note that many morphological and quantitative MRI measures show clear distinctions across subfield boundaries.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Examination of distortions (or difference in vertex spacing) between an average folded and unfolded space.</title><p>Distortions were greatest in the tail of the hippocampus where its proximal-distal distance becomes quite narrow.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig2-figsupp1-v2.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>MRI datasets used in training, evaluation, and comparison to extant methods.</title><p>Methods employed include those proposed here (HippUnfold), the same processing but with manual segmentation (similar to previous work; <xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>) (manual unfold), Freesurfer v7.2.0 (FS7) (<xref ref-type="bibr" rid="bib31">Iglesias et al., 2015</xref>), and an atlas of manual segmentations (<xref ref-type="bibr" rid="bib3">Berron et al., 2017</xref>) used in ASHS (<xref ref-type="bibr" rid="bib61">Yushkevich et al., 2015b</xref>).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Name</th><th align="left" valign="top">Modalities</th><th align="left" valign="top">Resolution</th><th align="left" valign="top">Sample size (L+R)</th><th align="left" valign="top">Methods employed</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="2">HCP-YA</td><td align="left" valign="top" rowspan="2">T1w, T2w</td><td align="char" char="." valign="top" rowspan="2">0.7 × 0.7 × 0.7 mm<sup>3</sup></td><td align="left" valign="top">n=590 (training)</td><td align="left" valign="top">HippUnfold<break/>Manual unfold</td></tr><tr><td align="left" valign="top">n=148 (testing)</td><td align="left" valign="top">HippUnfold<break/>Manual unfold<break/>FS7</td></tr><tr><td align="left" valign="top">HCP-A</td><td align="left" valign="top">T1w<break/>T2w SPACE<break/>T2w TSE</td><td align="left" valign="top">0.8 × 0.8 × 0.8 mm<sup>3</sup><break/>0.8 × 0.8 × 0.8 mm<sup>3</sup><break/>0.4 × 0.4 × 2.0 mm<sup>3</sup></td><td align="left" valign="top">n=1312 for T1w, T2w SPACE<break/>n=200 for T2w TSE (FS7, ASHS)<break/>n=200 for T1w (HippUnfold)</td><td align="left" valign="top">HippUnfold<break/>FS7<break/>ASHS</td></tr><tr><td align="left" valign="top">7T-TSE (from ASHS atlas)</td><td align="left" valign="top">T2w</td><td align="char" char="." valign="top">0.4 × 0.4 × 1.0 mm<sup>3</sup></td><td align="left" valign="top">n=70</td><td align="left" valign="top">HippUnfold<break/>Manual subfields</td></tr></tbody></table></table-wrap><p>Clear differences in morphological and quantitative MRI features can be seen across the hippocampus, particularly across subfields as defined here from a histologically derived unfolded reference atlas (3D BigBrain) (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>). This highlights the advantages of the present method. These folded and unfolded representations of hippocampal characteristics are broadly in line with previous work examining differences in such morphological and quantitative MRI features across hippocampal subfields or along the hippocampal AP extent (e.g. <xref ref-type="bibr" rid="bib52">Vos de Wael et al., 2018</xref>; <xref ref-type="bibr" rid="bib11">Crombe et al., 2018</xref>). However, in previous work these features differed between predefined subfields on average, but did not necessarily follow subfield contours as seen here. Some advantages of the current pipeline that likely contribute to this clarity include (i) the detail of the hippocampal GM segmentation, (ii) sampling along a midthickness surface to minimize partial voluming with surrounding structures, and (iii) the fact that subjects are topologically aligned across digitations or gyri, leading to less blurring of features after group-averaging.</p></sec><sec id="s2-2"><title>Extant methods do not respect the topological continuity of hippocampal subfields</title><p>Several automatic methods for labelling hippocampal subfields in MRI exist, of which FS7 (<xref ref-type="bibr" rid="bib31">Iglesias et al., 2015</xref>) and ASHS (<xref ref-type="bibr" rid="bib61">Yushkevich et al., 2015b</xref>) are among the most widely adopted. These methods rely on volumetric registrations between a target hippocampus and a reference or atlas. Specifically, ASHS makes use of multi-atlas registration, wherein multiple gold standard manual hippocampal subfield segmentations are registered to a target sample. Typically the multi-atlas consists of roughly a dozen samples which are then fused together to generate a reliable yet oftentimes smooth or simplified final product. FS uses a combination of voxel-wise classification and, bijectively, volumetric registration between a target hippocampus and a probabilistic reference atlas, which is generated via combined in vivo MRI and 9.4T ex vivo hippocampal subfield segmentations (<xref ref-type="bibr" rid="bib31">Iglesias et al., 2015</xref>). When hippocampi take on different folding configurations, such registrations can become ill-posed. HippUnfold overcomes these limitations in two ways: with extensive training (in this case n=590), U-Net can capture detailed inter-individual differences in folding and, secondly, our unfolding technique ensures that subfield labelling is topologically constrained (<xref ref-type="bibr" rid="bib14">DeKraker et al., 2021</xref>).</p><p>We made use of 100 randomly chosen subjects from the Human Connectome Project-Aging (HCP-A) dataset to compare the approach with the FS7 hippocampal subfields pipeline and ASHS using a recent manual subfield multi-atlas (<xref ref-type="bibr" rid="bib3">Berron et al., 2017</xref>). <xref ref-type="fig" rid="fig3">Figure 3A</xref> shows a side-by-side comparison of HippUnfold, ASHS, and FS7 to one representative 81-year-old female. <xref ref-type="fig" rid="fig3">Figure 3B</xref> shows Bland-Altmann plots comparing subfields CA1, CA3, and subiculum volume across the three methods in all 100 subjects, as well as their correlation with subjects’ ages. Quantitative comparison between methods shows an age-related decline in subfield volumes for all methods, with a relative sparing of CA3. Thus, HippUnfold replicates the widely observed phenomenon of age-related decline, with similar effect sizes to FS and ASHS (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). A similar pattern can be seen across the other subfield volumes and in total hippocampal volume. Bland-Altman plots show major differences in hippocampal subfield sizes between methods, which most likely results from inclusion of the hippocampal tail in HippUnfold.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Out of sample performance of HippUnfold, Automatic Segmentation of Hippocampal Subfields (ASHS), and Freesurfer (FS7).</title><p>(<bold>A</bold>) Side-by-side comparison of results obtained from each method from one representative individual from the Human Connectome Project-Aging (HCP-A) datasets, which was not seen during training. (<bold>B</bold>) Quantitative comparison of subfield volumes (left) and age-related volume changes (right) between methods. For a full set of snapshots illustrating the differences between these methods, see <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>, <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Additional comparisons of results obtained from Freesurfer (FS7), Automatic Segmentation of Hippocampal Subfields (ASHS), and HippUnfold in 100 Human Connectome Project- Aging (HCP-A) subjects.</title><p>All three methods showed a moderate correlation with age, as expected based on previous literature. Volumetric comparison of each method to HippUnfold directly revealed that there is a strong correlation between total hippocampal volumes obtained using HippUnfold and those obtained using FS7 or ASHS. HippUnfold and FS7 showed a moderate difference in overall volume (FS7 being on average 540 mm<sup>3</sup> larger), whereas ASHS volumes were consistently smaller (by an average of 270 mm<sup>3</sup>). At the subfield level, using an unfolded subfield atlas from the corresponding method, there was relatively low Dice overlap between labels obtained using these three different methods in native space, which is likely driven by the gross volume differences between methods (i.e. which tissues are included or excluded prior to unfolding) since subfield definitions are nearly identical after unfolding.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig3-figsupp1-v2.tif"/></fig></fig-group><p>Within the HCP-YA test set, we compared subfield segmentations from ASHS and FS7 to those generated via HippUnfold in unfolded space, which is shown in <xref ref-type="fig" rid="fig4">Figure 4</xref> in one representative subject. We then generated an unfolded subfield atlas using the maximum probability labels from all ASHS and FS7 subjects, which can be used in place of the default HippUnfold atlas generated via 3D BigBrain histology (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>). For comparison, we additionally show native space HippUnfold results obtained when using these alternative unfolded atlases.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Comparison of HippUnfold, Automatic Segmentation of Hippocampal Subfields (ASHS), and Freesurfer (FS7) subfield segmentations in native and unfolded space.</title><p>Sagittal and coronal slices and 3D models are shown for one representative subject. Note that for HippUnfold hippocampal subfields are the same for all individuals in unfolded space, but for ASHS and FS we mapped all subjects’ subfield boundaries which are shown in the black lines in column 4 rows 2 and 4. We then took the maximum probability subfield label from ASHS and FS in unfolded space and used it for HippUnfold subfield segmentation in native space, which is shown in rows 3 and 5.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Comparison of HippUnfold and fully manual subfield segmentations (data from <xref ref-type="bibr" rid="bib48">Thom, 2014</xref>) in native and unfolded space from one representative subject.</title><p>Sagittal and coronal slices and 3D models are shown for one representative subject. Note that the 3D model of a fully manual segmentation shows clear anterior and posterior digitations which were also present but considerably smoothed in HippUnfold.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig4-figsupp1-v2.tif"/></fig></fig-group><p>Both ASHS and FS showed subfield discontinuities in unfolded space in at least some subjects, and FS even showed discontinuities in the group-averaged unfolded subfields. That is, some pieces of a given label were separated from the rest of that label. ASHS does not include an SRLM label and the SRLM produced by FS was not consistently aligned with that used in unfolding. Thus, subfields sometimes erroneously crossed the SRLM, breaking topology and explaining why discontinuities were sometimes observed in unfolded space. Ordering of labels was also not consistent in ASHS and FS. For example, sometimes CA1 would border not only CA2 but also CA3, CA4, and/or DG. Additionally, neither ASHS nor FS extends all subfields to the full anterior and posterior extent of the hippocampus. Instead, both methods simplify most of the anterior hippocampus as being CA1 and opt not to label subfields in the posterior hippocampus at all. These qualities are not in line with the anatomical ground truth shown in both classic and contemporary ex vivo histological studies (<xref ref-type="bibr" rid="bib19">Duvernoy, 1998</xref>; <xref ref-type="bibr" rid="bib17">Ding and Van Hoesen, 2015</xref>), which were indeed well captured by HippUnfold. FS also over-labelled hippocampal tissue, which can be seen reaching laterally into the ventricles in the coronal view. Similar errors have been documented for FS in other recent work (<xref ref-type="bibr" rid="bib56">Wisse et al., 2014</xref>; <xref ref-type="bibr" rid="bib27">Haast et al., 2021</xref>).</p></sec><sec id="s2-3"><title>Trained U-Net performance is similar to manual segmentation</title><p>From the HCP-YA dataset, a set of 738 (left and right from 369 subjects) gold standard hippocampal tissue (i.e. hippocampal GM and surrounding structures) segmentations were generated according to the manual protocol defined in <xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>. Specifically, this was done by raters JD, MY, and BK using an incremental learning U-Net training regime described in the Materials and methods ‘nnUNet training’ section. Automated tissue segmentation was performed using nnUNet, a recent and highly generalizable implementation of a U-Net architecture (<xref ref-type="bibr" rid="bib33">Isensee et al., 2021</xref>). This software was trained on 80% (n=590) of the gold standard segmentation data described above, with the remaining 20% (n=148) making up a test set. Dice overlap scores on the test set are shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Left and right hippocampi from the same participant were never split across training and testing sets due to their high symmetry. Note that all input images were preprocessed, resampled, and cropped (see <xref ref-type="fig" rid="fig1">Figure 1</xref> and Materials and methods) prior to training. Within the training set, fivefold cross-validation was performed as implemented in the nnUNet code. Training took place on an NVIDIA T4 Turing GPU over 72 hr. This process was carried out using either T1w or T2w input data with the same training/testing data split. All default nnUNet data augmentation and hyperparameters were used.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Test set performance in Dice overlaps between HippUnfold and manually unfolded subfields.</title><p>All values are compared to ground truth manually defined tissues followed by unfolded subfield definition (manual unfold) to determine how small differences in grey matter parcellation propagate through the unfolding, subfield definition, and re-folding. Two models were trained in parallel using the same labels but different input MRI data modalities consisting of T1w or T2w data. Dotted black lines indicate corresponding values from <xref ref-type="bibr" rid="bib61">Yushkevich et al., 2015b</xref>, who include stratum radiatum, lacunosum, and moleculaire (SRLM) in all labels and combine CA4 and DG into one label.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig5-v2.tif"/></fig><p>Dice overlap depends heavily on the size of the label in question, being lower for smaller labels. Typically a score of &gt;0.7 is considered good, and many fully manual protocols show dice scores of &gt;0.8 for the larger subfields like CA1 or the subiculum, and 0.6–0.8 for smaller subfields like CA2 or CA3 (see <xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>, for overview). Within the HCP-YA test set, performance was similar or better than most fully manual protocols for T1w and T2w data. Performance on T1w images was only marginally poorer than T2w images which typically better show the SRLM and are popular in manual subfield segmentation protocols (<xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>).</p></sec><sec id="s2-4"><title>Generalizability to unseen datasets and populations</title><p>We aimed to determine whether our pipeline would generalize to unseen datasets with different acquisition protocols and sample populations. Hippocampal morphometry, integrity, and subfields are often of interest in disease states where atrophy or other structural abnormalities are observed (<xref ref-type="bibr" rid="bib48">Thom, 2014</xref>; <xref ref-type="bibr" rid="bib28">Haukvik et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Steve et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Carr et al., 2017</xref>). For this reason, we examined the HCP-A datasets in which we anticipated cases of severe atrophy would be present in some older subjects. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows results from one representative individual (an 80-year-old female with signs of age-related atrophy but good scan quality). Another common use-case for hippocampal subfield segmentation is on anisotropic T2w data which is considered optimal for performing manual segmentation in most protocols (<xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>), but may impose challenges for our method due to the difference in resolution. We thus applied HippUnfold to 7T-TSE data and also illustrate one representative subfield segmentation result in <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p><p>To demonstrate generalizability to pathological cases where hippocampal abnormalities can be confirmed, we also applied HippUnfold to a surgical epilepsy patient case. A 37-year-old female right-handed patient was investigated for surgical treatment of temporal lobe epilepsy, and clinical MR imaging at 1.5 T revealed a FLAIR hyper-intensity in the right hippocampus. The patient was imaged pre-surgically for a 7 T MRI research study, and the 0.7 mm MP2RAGE T1w (UNI-DEN) image was segmented using HippUnfold, which is shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>. The patient underwent a right anterior temporal lobectomy and has been seizure-free (Engel class 1) for 4 years. Bilateral asymmetry is a strong indicator of epileptogenesis, and so results are examined for both the left and right hippocampi. Note that in addition to a loss in overall volume, the afflicted hippocampus showed relative sparing of CA2 which is a common observation in hippocampal sclerosis (<xref ref-type="bibr" rid="bib4">Blümcke et al., 2013</xref>), as well as reduced digitations compared to the left hemisphere. Examining additional patients in future work may reveal whether morphometry could be a clinical marker of epileptogenesis in patients with no remarkable clinical lesions.</p></sec><sec id="s2-5"><title>Automated error flagging</title><p>Gold standard manual segmentations under the protocol used for subsequent unfolding were not available in novel datasets. Manually inspecting results from hundreds of subjects is time-consuming. We thus streamlined this process by flagging potential segmentation errors by examining Dice overlap with a more conventional segmentation approach: deformable registration. For all datasets described above, we applied deformable fast B-spline registration (<xref ref-type="bibr" rid="bib39">Modat et al., 2010</xref>) to the corresponding T1w or T2w template. Tissue segmentation results (generated at the nnUNet stage) were then propagated to template space and overlap with standard template hippocampal masks were examined, which is shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Any subject with a Dice overlap score of less than 0.7 was flagged and manually inspected for quality assurance. This made up 34/2126 (1.6%) samples in the HCP-YA T2w set (including training and testing subsets), 188/1312 (14.3%) samples from the HCP-A T2w set, 37/1312 (2.8%) samples from the HCP-A T1w set, and 3/92 (3.3%) samples from the 7T-TSE set. Closer inspection revealed that the vast majority of flagged cases were due to missed tissue in the nnUNet segmentation, an example of which is shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>. It is interesting to note that the most flagged cases were seen in the HCP-A T2w dataset even though T2w is a popular acquisition protocol for hippocampal subfield segmentation (<xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>; <xref ref-type="bibr" rid="bib59">Wisse et al., 2021</xref>), and showed the best performance within the HCP-YA test set (<xref ref-type="fig" rid="fig5">Figure 5</xref>; <xref ref-type="fig" rid="fig6">Figure 6A and B</xref>). This was likely not due to the age of subjects since few of the HCP-A T1w were flagged as possible errors, but instead may have been due to T2w scan quality, which was observed to be poor in some subjects, causing poor definition of the outer hippocampal boundaries. We recommend that future users carefully inspect results from any flagged subjects, and cases with errors can be either discarded or manually corrected. Some work has already demonstrated that it is possible to synthesize or convert between MRI modalities (<xref ref-type="bibr" rid="bib32">Iglesias et al., 2021</xref>), which could be used to alleviate the dependency on any single MR contrast. We cannot determine whether HippUnfold will work as intended on all new datasets, but within the generalization datasets examined here, results were excellent.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Examination of HippUnfold performance on additional datasets Human Connectome Project-Aging (HCP-A) (T1w and T2w) and anisotropic 7T-TSE data.</title><p>(<bold>A</bold>) Sample subjects’ HippUnfold subfield segmentation in native resolution. The first two rows come from the same subjects but using different input data modalities. (<bold>B</bold>) HippUnfold results from a 7 T MRI of a temporal lobe epilepsy patient with surgically confirmed right hippocampal sclerosis.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig6-v2.tif"/></fig><p>It is interesting to note that fewer failures were observed in HippUnfold using T1w data compared to T2w data (<xref ref-type="fig" rid="fig7">Figure 7</xref>), even though performance of nnUNet tissue classification were slightly higher with T2w images (<xref ref-type="fig" rid="fig5">Figure 5</xref>) and these are more common in hippocampal subfield imaging literature. Examining some failed cases, we see that these often had poor image quality, with subsequent issues like linear misregistration to the common CITI168 atlas or catastrophic nnUNet tissue classification failures.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Automated error flagging via overlap with coarse, registration-based segmentation.</title><p>(<bold>A</bold>) Subjects flagged for quality assurance from each dataset based on Dice overlap with a reference mask approximated via deformable registration. (<bold>B</bold>) Failed subject example illustrating missed tissue (red arrows) at the nnUNet stage of the HippUnfold pipeline.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77945-fig7-v2.tif"/></fig></sec><sec id="s2-6"><title>FAIR principles in development</title><p>We designed this pipeline to employ FAIR principles. As such, we have made use of several tools, conventions, and data standards to make HippUnfold extensible and easy to use.</p><p>The default file input-output structure of the HippUnfold command-line interface was built in compliance with the Brain Imaging Data Standards (BIDS) (<xref ref-type="bibr" rid="bib24">Gorgolewski et al., 2016</xref>) Applications (BIDS-Apps) guidelines (<xref ref-type="bibr" rid="bib25">Gorgolewski et al., 2017</xref>), and easily findable amongst the list of available BIDS Apps [<ext-link ext-link-type="uri" xlink:href="https://bids-apps.neuroimaging.io/apps/">https://bids-apps.neuroimaging.io/apps/</ext-link>]. This is achieved via Snakebids, a tool designed to interface between BIDS datasets and Snakemake (<xref ref-type="bibr" rid="bib34">Khan and Haast, 2021</xref>). All aspects of HippUnfold use Snakemake (<xref ref-type="bibr" rid="bib40">Mölder et al., 2021</xref>), a workflow management system based on Python which is reproducible, scalable, and seamlessly combines shell commands, Python code, and external dependencies in a human-readable workflow. There is no need to install these dependencies, which are containerized within the Singularity or Docker versions of HippUnfold.</p><p>Altogether, this means that in a single line this pipeline can be applied intelligently to any BIDS-complaint dataset containing a whole-brain T1w image or a T2w image (whole-brain or limited field of view) without having to specify further details. Typical runtimes on a standard desktop are 30–60 min per subject, but this is further parallelized for faster processing when multiple subjects and added compute resources (or cloud computing) are available. Additional flags can be used to extend functionality to many other use-cases, including T1w only, T2w only, diffusion-weighted imaging, cases where a manual tissue segmentation is already available, or ex vivo tissue samples.</p><p>Outputs of HippUnfold follow the standards for BIDS derivatives, and include preprocessed input images, volumetric subfield segmentations, inner, midthickness, and outer hippocampal surfaces, vertex-wise morphometric measures of thickness, curvature, and gyrification, and a brief quality control (QC) report. All surface-based outputs are combined into a Connectome Workbench (<xref ref-type="bibr" rid="bib38">Marcus et al., 2013</xref>) specification file for straightforward visualization analogous to HCP neocortical reconstructions. Outputs can be specified to include images in the original T1w space or in the resampled, cropped space that processing is performed in.</p><p>All code, code history, documentation, and support are offered online (<xref ref-type="bibr" rid="bib35">Khan, 2022</xref>) (<ext-link ext-link-type="uri" xlink:href="https://github.com/khanlab/hippunfold">https://github.com/khanlab/hippunfold</ext-link>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>One of the most powerful features of HippUnfold is its ability to provide topological alignment between subjects despite differences in folding (or digitation) structure. This is a critical element of mainstream neocortical analysis methods that, until now, has not been carried out systematically in the archicortex, or hippocampus. The power of this form of topological alignment is evident when mapping morphological or quantitative features across the hippocampus in a large population, which we demonstrate in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><p>Segmentation of subfields is a task that is conceptually simplified through unfolding of the hippocampus to provide intrinsic anatomical axes. The axis we define as PD, which follows along the SLM in a coronal slice, is also a landmark relied upon in many manual segmentation protocols for the hippocampal subfields, including a histologically validated protocol that defines subfield boundaries by the proportional distance along the SLM (<xref ref-type="bibr" rid="bib47">Steve et al., 2017</xref>). The head and tail are areas where these heuristics have conventionally been very difficult to apply, since the slice angulation optimal for the body is not optimal for the curved head and tail, and work using multiplanar reformatting provides one alternative for curved regions of the hippocampus (<xref ref-type="bibr" rid="bib26">Gross et al., 2020</xref>). Our unfolding approach is conceptually analogous to these approaches, however, the added strength of our approach is that we apply the same conceptual rule (proportional distance along the SLM) while considering the entire 3D structure of the hippocampus.</p><p>We compare HippUnfold to other commonly used tools for hippocampal analysis, FS7 and ASHS (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Both of these methods rely on smooth deformation of single or multi-atlas references, indicating they do not easily transfer to drastically different hippocampal folding patterns, which are often seen in the hippocampal head and tail across individuals. Both of these methods showed unfolded subfield patterns that were less consistent with ground truth histological literature than the output provided by HippUnfold. Common issues in other methods include introducing breaks in subfield topology, simplifications like the exclusion of the hippocampal tail, or inconsistent ordering of subfields. This highlights some of the advantages of HippUnfold, which was designed to overcome these issues explicitly.</p><p>Several factors make surface-based methods difficult to implement in the hippocampus, including its small size, and the difficulty of distinguishing the hippocampal sulcus or SRLM laminae that separate hippocampal folds. Here, we have overcome these issues using a highly generalizable and sensitive neural network ‘U-Net’ architecture, combined with our previously developed topological unfolding framework. Together, these methods achieved similar or better Dice overlap scores than what is typically seen between two manual raters on all subfields. We tested performance on new datasets (‘generalization’ datasets with different characteristics than the HCP training set) and saw good performance in nearly all cases. Specifically, we tested other common imaging protocols including different sample age groups (HCP-A) and thick-slice 7T-TSE acquisitions often used in targeted hippocampal subfield imaging (<xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>). Though error rates were low, we do show how and why such errors sometimes occur, highlighting the importance that future users examine the brief QC reports included for each subject. Thus, while HippUnfold is shown to work well with all datasets examined here, we expect that the widespread adoption of higher-resolution acquisition techniques will further improve feasibility at other research institutes.</p><p>One important limitation of our method is that HippUnfold did not consistently show clear digitation in the hippocampal head, body, and tail which was sometimes seen in manual segmentation in the training set and in other work (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). This reflects a lack of detail compared to histological ground truth materials, and affects downstream processing. That is, an overly smoothed hippocampal surface will appear thicker and have a smaller surface area compared to one that captures the full extent of digitations. This smaller surface area also results in each subfield boundary being proportionally shifted. Future work could improve this pipeline by training and testing with higher-resolution data where digitations can more clearly be distinguished both in labelmaps and in the underlying images.</p><p>A single unfolded subfield atlas based on 3D BigBrain ground truth histology (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>) was employed within HippUnfold for all subjects here. As illustrated in <xref ref-type="fig" rid="fig4">Figure 4</xref>, alternative unfolded subfield atlases can be used as well. Though previous work demonstrated reduced inter-individual variability of subfield boundaries in unfolded space (<xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>), the extent to which subfield boundaries vary after unfolding is not yet known. In the neocortex, this issue is also present but partially mitigated with surface-based registration of available features like intracortical myelin, sulcal patterns, or thickness (e.g. <xref ref-type="bibr" rid="bib23">Glasser et al., 2016</xref>). Such information could also be used in the unfolded hippocampus to further refine subject-specific subfield delineation, but would require histological ground truth data from multiple subjects to evaluate, ideally in 3D to avoid common out-of-plane sampling issues (<xref ref-type="bibr" rid="bib14">DeKraker et al., 2021</xref>). This level of precision is likely beyond current typical MRI resolution levels, but should be investigated in future work aiming to combine in vivo and ex vivo or other more specialized imaging.</p><p>The current work has applications beyond subfield imaging, enabling new investigations of the hippocampus on a columnar and laminar scale. For example, rather than employing subfield ROI-based analyses, statistics can be performed on a per-vertex basis for vertices generated at different depths. This is in line with state-of-the-art neocortical analysis methods (<xref ref-type="bibr" rid="bib49">Van Essen et al., 2000</xref>), and opens up the possibility of more precise localization of hippocampal properties. Similarly, it is worth noting that the methods used here are not necessarily restricted to MRI, as we have used the same surface-based unfolding in combination with manual segmentation to characterize the hippocampus in 3D BigBrain histology (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>).</p><p>Altogether, we show that the BIDS App ‘HippUnfold’ that we have developed in this work (i) respects the different internal hippocampal folding configurations seen between individuals, (ii) can be applied flexibly to T1w or T2w data, sub-millimetric isotropic or thick-slice anisotropic data, and (iii) compares favourably to other popular methods including manual segmentation, ASHS and FS7. We believe this tool will open up many avenues for future work including examination of variability in hippocampal morphology which may show developmental trajectories or be linked to disease, or the examination of hippocampal properties perpendicular or tangential to its laminar organization with diffusion-weighted imaging. Finally, it is worth noting that the methods described here stand to improve existing techniques by providing greater anatomical detail and, critically, greater precision through topological alignment across individuals who vary in anatomical structure.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Data</title><p>HippUnfold was designed and trained with the HCP 1200 young adult subject data release (HCP-YA) (<xref ref-type="bibr" rid="bib50">Van Essen et al., 2013</xref>), and additionally tested on the HCP-A dataset (<xref ref-type="bibr" rid="bib5">Bookheimer et al., 2019</xref>), and anisotropic (or thick-slice) 7T data (7T-TSE) from <xref ref-type="bibr" rid="bib3">Berron et al., 2017</xref>, which is considered optimal by many hippocampal subfield researchers (<xref ref-type="bibr" rid="bib60">Yushkevich et al., 2015a</xref>). Informed consent and consent to publish were obtained by the original authors of the open source data examined here. Each of the three datasets included research ethics board approvals, as well as informed consent and, in the HCP-A dataset, assessment of the subjects’ ability to provide consent. For the single epilepsy patient case examined here, research ethics board approval and informed consent were collected at the Western University (HSREB # 108952, Lawson: R-17-156). These data are summarized briefly in <xref ref-type="table" rid="table1">Table 1</xref>.</p></sec><sec id="s4-2"><title>nnUNet training</title><p>U-Nets perform classification of each input image voxel, and it is not constrained by smooth displacements used in deformable atlas registration. This is important because smooth deformable registration can be ill-posed for an atlas with a different hippocampal folding configuration than the target. For example, when trying to register a hippocampus with two anterior digitations to one with four anterior digitations, topological breaks may be seen which leads to loss of detail and disproportionate stretching or compression of some subfields, an issue that is discussed in <xref ref-type="bibr" rid="bib14">DeKraker et al., 2021</xref>. Instead, a U-Net classifies voxels individually based on a combination of local low-level and global high-level image features with no explicit smoothness constraints.</p><p>In the current work, gold standard training and test comparison segmentations were generated in a semi-automated but heavily supervised manner: a U-Net implementation (NiftyNet; <xref ref-type="bibr" rid="bib21">Gibson et al., 2018</xref>, which is no longer maintained) was trained on existing data from <xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>. This was then applied to new HCP-YA data and results were manually inspected. In many cases, results were poor due to the relatively small training sample size, but good quality segmentations from roughly 50% of subjects were selected and corrected by a manual rater (JD or MY) before being added to the initial training set for a new, de novo application of U-Net training. The process of inspection and manual correction was always performed according to the protocol outlined in <xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>, to avoid systematic drift in rater performance. This process is typically referred to as incremental learning, and was applied in four iterations until a larger set of high quality, manually inspected and corrected segmentations (738 samples from 369 subjects) was achieved.</p><p>Once the gold-standard training data was obtained, we applied a U-Net implementation called nnUNet (<xref ref-type="bibr" rid="bib33">Isensee et al., 2021</xref>). nnUNet was built to include many state-of-the art deep learning techniques including sensible hyperparameter selection, built-in fivefold cross-validation, and other features that have been shown to perform well and minimize possible sources of bias in medical imaging. We thus applied all default parameters in our use of this tool. Training was repeated using the same labelmaps but different underlying images for T1w, T2w, and DWI images. For each of these modalities, training took place on an NVIDIA T4 Turing GPU over 72 hr. Additional new models (or fine-tuned models) can also be trained and supplied within our code framework. Training data is available online at <xref ref-type="bibr" rid="bib15">Dekraker and Khan, 2022</xref>.</p></sec><sec id="s4-3"><title>HippUnfold detailed pipeline</title><p>The command-line interface and options for HippUnfold are fully described online and in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. A brief description of this pipeline is outlined here:</p><list list-type="order"><list-item><p>Preprocessing and resampling. Data is gathered via snakebids (<xref ref-type="bibr" rid="bib34">Khan and Haast, 2021</xref>), which automatically and flexibly queries the specified BIDS directory for T1w and T2w images. Data is loaded and saved using NiBabel (<xref ref-type="bibr" rid="bib6">Brett et al., 2020</xref>). Processing of each image is as follows:</p><list list-type="alpha-lower"><list-item><p>T1w: N4 bias correction is performed using the Advanced Normalization Toolkit (ANTs) (<xref ref-type="bibr" rid="bib2">Avants et al., 2008</xref>) followed by affine registration (NiftyReg; <xref ref-type="bibr" rid="bib39">Modat et al., 2010</xref>) to CITI168 atlas (<xref ref-type="bibr" rid="bib42">Pauli et al., 2018</xref>). This transformation is composed (Convert 3D or c3d; <xref ref-type="bibr" rid="bib62">Yushkevich et al., 2019</xref>) with a precomputed transform from CITI168 to oblique to the long axis of the hippocampus. Images are resampled to 0.3 mm<sup>3</sup> and cropped to 128 × 256 × 128 voxels centred on the CITI168 left and right hippocampi. Left hippocampi are flipped sagittally to resemble right hippocampi. We refer to this as cropped coronal oblique space.</p></list-item><list-item><p>T2w: N4 bias correction is performed as above, and if multiple T2w images are present then they are rigidly registered (NiftyReg) and then averaged, a rudimentary form of super-resolution sampling (e.g. <xref ref-type="bibr" rid="bib55">Winterburn et al., 2013</xref>). Rigid registration to the corresponding T1w image is then performed (NiftyReg), and resampled to cropped coronal oblique space as above.</p><p>A ‘modality’ flag is used to determine which image modalities should be used if multiple are present in the input BIDS directory. Within the HippUnfold code, optional flags can be used to skip preprocessing and registration. Manually segmented hippocampal tissues can also be specified, which can be useful in ex vivo MRI or other modalities on which the current nnUNet-based segmentation is not expected to work. In all cases, data are resampled to cropped coronal oblique space to match the nnUNet training setup. It is possible to skip this step only if a manually segmented hippocampal tissue class image is also provided (in which case nnUNet is not applied).</p></list-item></list></list-item><list-item><p>Tissue class segmentation. If a manually segmented hippocampal tissue image is not supplied, then the input image will be run through nnUNet (<xref ref-type="bibr" rid="bib33">Isensee et al., 2021</xref>), a state-of-the-art implementation of a deep convolutional neural network (U-Net) designed for image segmentation (<xref ref-type="bibr" rid="bib54">Wiestler and Menze, 2020</xref>; <xref ref-type="bibr" rid="bib36">Lu et al., 2017</xref>). The output of nnUNet is a segmentation of tissue classes: hippocampal GM and the surrounding tissues which are used in defining unfolded coordinate boundaries: SRLM, medial temporal lobe cortex (MTLc), pial surface, hippocampal-amygdalar transition area (HATA), indusium griseum (IndGris), cysts, and the DG granule cell layer (which also makes up part of hippocampal GM but which marks an endpoint of the unfolding coordinate framework and so it was given a distinct label).</p></list-item><list-item><p>Post-processing. Here, we employed template shape injection (<xref ref-type="bibr" rid="bib44">Qiu and Miller, 2008</xref>) to correct possible segmentation errors, making labelmaps more amenable to the previously developed hippocampal unfolding methods. The basic principle of template shape injection is to perform highly fluid deformable registration of a template segmentation labelmap to a given subject’s segmentation labelmap. This differs from typical registration-based segmentation methods in that the registration is optimizing labels rather than image feature similarity (i.e. registration is performed with binarized and smoothed labels as multiple contrasts, rather than on MRI intensities). Specifically, we used mean squared error between labels as the cost function, which is minimized when identical labels are overlapping. In our implementation, we apply multi-contrast deformable registration using Greedy (<xref ref-type="bibr" rid="bib62">Yushkevich et al., 2019</xref>). It should be noted that in principle this step is not necessary for our pipeline, but in practice it helps avoid possible errors due to nnUNet segmentation faults (see main text <xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><p>The reference template that we applied was created using manual segmentations from an open source ex vivo dataset (<xref ref-type="bibr" rid="bib57">Wisse et al., 2017a</xref>) that was manually segmented according to our previous manual hippocampal unfolding protocol (<xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>). Labelmaps from 22 samples were combined using a standard template building ANTs script ‘buildtemplateparallel.sh’ (<xref ref-type="bibr" rid="bib2">Avants et al., 2008</xref>). This template generation entails averaging all images and then registering each sample to the average, iteratively refining and sharpening the average image. This ex vivo dataset was selected for template building because we had high confidence in the quality of these segmentation since they contained higher resolution and contrast than other datasets while still including multiple samples.</p></list-item><list-item><p>Unfolding. This code is described in <xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>, and was modified in <xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>, but we will provide a short summary here.</p></list-item></list><sec id="s4-3-1"><title>Intuition</title><p>Imagine we have a tangled piece of wire. We attach one end to something hot (100°C) and the other to something cold (0°C), and then wait for the temperature to equilibrate along the entire wire. We then have a second wire that is tangled up in a different pattern (and possibly with a different length). We attach the same hot and cold endpoints, and wait for it to equilibrate as well. Then, when we want to find topologically homologous points between the two wires, we find the spot where they have the same temperature, say 10°C (or 10% its length), or the same for any other pair of homologous points. This explanation works since the heat equation describing the equilibrium temperatures is the same as the Laplace equation if we assume that the heat conductance (or thermal diffusivity) is constant. These wires make up a 1D example, but the same principle also applies to a folded 2D sheet, where the endpoints are edges rather than ends. Here, we apply endpoints in two perpendicular directions: AP (or HATA to ind.gris.) and PD (sub to DG), making up a standardized 2D indexing system (or ‘unfolded space’).</p></sec><sec id="s4-3-2"><title>Details</title><p>A Laplace field varying from 0 to 1 is generated across hippocampal GM, with 0 being at its anterior boundary with the HATA and 1 being at its posterior boundary with the IndGris (AP). This provides a scaled, smooth, geodesic way to index points along this axis. Another Laplace field is generated across the PD axis of the hippocampus (MTLc to DG), and together these two fields provide a coordinate system spanning hippocampus GM along two dimensions, which we plot as a flat rectangle (with a 2:1 aspect ratio to reflect the fact that the hippocampus is longer than it is wide). A third field is generated across the thickness of hippocampal GM (SRLM to outer boundary, or inner to outer, or IO). By default, the IO Laplace field is replaced by an equivolumetric model (<xref ref-type="bibr" rid="bib53">Waehnert et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Huntenburg et al., 2018</xref>), which helps account for the effects of curvature on laminar features (though this replacement can optionally be disabled). We then compute displacement fields for transforming each voxel from native space to the ‘unfolded’ space spanned by these three (AP, PD, and IO) fields, and vice versa.</p><p>Specifically, transformations for going between this unfolded space and native space are defined from Cartesian coordinates (x,y,z) to each Laplace field (AP, PD, and IO) for all hippocampal GM voxels. We performed piecewise linear interpolation (griddata from SciPy; <xref ref-type="bibr" rid="bib51">Virtanen et al., 2020</xref>) to go from each unfolded coordinate (AP, PD, IO) to back to Cartesian coordinates (x,y,z). Rather than map Cartesian coordinates to Laplace coordinates ranging from 0 to 1 (as in previous work; <xref ref-type="bibr" rid="bib12">DeKraker et al., 2018</xref>), we scale these gradients to make up a standard rectangular prism with a size of 256 × 128 × 16 voxels (dimensions corresponding to AP, PD, and IO, respectively), at a voxel size of 0.15625 mm<sup>3</sup> isotropic. This reference space is easily changed in the config file if a different unfolded resolution, size, or aspect ratio is desired. Each of these displacement fields is saved as a standard ITK 3D warp file in NIfTI format that can subsequently be applied to NIfTI or GIfTI files.</p><p>Unfolding of the DG is introduced in the current work. This is performed with the same methods described above but over the domain of the DG rather than all hippocampal GM. IO and PD fields are swapped with respect to the rest of the hippocampus reflecting the fact that during its development, the DG breaks from the rest of the cortical mantle and wraps around its terminus (CA4), making it topologically perpendicular to the rest of the hippocampus (<xref ref-type="bibr" rid="bib19">Duvernoy, 1998</xref>). Endpoints for the DG are defined within the template shape used in step 3. Due to the thinness of the DG, it is often thinner than one voxel and so Laplace fields cannot easily be generated with the methods used in previous work. Thus, template shape injection is used to define the AP, PD, and IO fields within the DG, which were precomputed in the reference template with an idealized DG shape for unfolding. Thus, topological alignment between individuals does not perfectly follow the same Laplacian coordinate framework used in the rest of the hippocampus. Rather, this represents a more traditional volumetric approach to alignment via a template. The unfolded DG was defined by a rectangular prism with a size of 256 × 32 × 16, reflecting the fact that it is smaller than the rest of the hippocampus (PD) but still spans the same long (AP) axis.</p><list list-type="order"><list-item><p>Subfield definition. In previous work (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>) we performed a highly detailed 3D ground truth segmentation of hippocampal subfields using 3D BigBrain histology (<xref ref-type="bibr" rid="bib13">DeKraker et al., 2020</xref>). We mapped subfields using our Laplace coordinate framework, which provides implicit, topologically constrained registration between hippocampi. Thus, HippUnfold applies the same subfield boundary definitions to new samples in unfolded space, which are then propagated back to native space. Specifically, reference subfield labels already in unfolded space are warped to each subjects’ native space using the warp files generated in step 4. Other unfolded subfield atlases can also be used, but BigBrain is the default since it is the most complete and detailed model of the hippocampal subfields to date.</p></list-item><list-item><p>GIfTI formatted outputs. In order to facilitate integration with other popular neuroimaging analysis tools, we have provided outputs in commonly used gifti surface formats in addition to volumetric nifti formats. Standardized unfolded surfaces corresponding to the inner, midthickness, and outer surface were generated for one standard unfolded template and propagated to each subjects’ native, folded space using the warp files generated in step 4. Note that unfolded space is mapped to a rectangle rather than a sphere as is typically used in the neocortex, and so surfaces are not fully enclosed. Tessellation of vertices are available in a variety of densities categorized by their average vertex spacing in the native space: 0.5 mm (7262 vertices), 1 mm (2004 vertices), 2 mm (419 vertices), or the legacy unfoldiso (32,004, ~32K, corresponding to the number of unfolded coordinates used in previous work, or 254×126).</p></list-item></list><p>Standardized unfolded tessellations were generated by starting with a 512×256 grid with each point connected to its neighbours, making a uniform mesh in unfolded space. Mesh vertices were iteratively removed until vertex distances after transforming to an averaged native space were achieved with the above spacings. In the case of the 32K surfaces, meshes were generated with 254×126 points with no vertices being removed, meaning that vertex distances are uniformly spaced in unfolded space but distorted in native space. In addition to hippocampal surfaces, DG surfaces are also generated, with the following unfolded meshes: 0.5 mm (1788 vertices), 1 mm (449 vertices), 2 mm (64 vertices), and unfoldiso (7620 vertices, 254×30).</p><list list-type="order"><list-item><p>Morphometry. Connectome Workbench commands (<xref ref-type="bibr" rid="bib22">Glasser et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Marcus et al., 2011</xref>) are used to extract measures of thickness between inner and outer surfaces, as well as curvature and gyrification along midthickness surfaces. The curvature metric is calculated using the mean curvature, calculated on a midthickness surface smoothed with the mean curvature midthickness surfaces, first smoothed by neighbourhood averaging (strength = 0.6, iterations = 100). The gyrification metric is defined as the ratio of native space surface area over unfolded space surface area, where the surface area is calculated at each vertex as the average of areas of connected triangles. Additional data (e.g. fMRI, DWI, or others) can be sampled at each vertex with the code provided in HippUnfold (the volume to surface mapping command in Connectome Workbench). With the implicit registration provided by unfolded space and the tessellation of these surfaces, such data can readily be compared across hippocampal samples without the need for further registration. These data can be subgrouped according to subfield labels, as in ROI analysis styles, or each vertex can be examined separately as in searchlight or data-driven analysis styles. Alternatively, gradient-based analyses can be applied based on Laplace coordinates and their corresponding surface mesh tessellations (see <xref ref-type="bibr" rid="bib52">Vos de Wael et al., 2018</xref>, for example).</p></list-item></list><p>For even more implementation details, see <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref> – HippunFold algorithms.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Validation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Data curation, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Data curation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Funding acquisition, Validation, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Software, Supervision, Funding acquisition, Validation, Methodology, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Data curation, Software, Supervision, Funding acquisition, Validation, Methodology, Project administration, Writing – review and editing, Visualization, Writing – original draft</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Informed consent and consent to publish were obtained by the original authors of the open source data examined here. Each of the three datasets included research ethics board approvals, as well as informed consent and, in the HCP-Aging dataset, assessment of the subjects' ability to provide consent. For the single epilepsy patient case examined here, research ethics board approval and informed consent were collected at the Western University (HSREB # 108952, Lawson: R-17-156).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>HippUnfold Documentation.</title><p>This document fully describes the HippUnfold installation, command-line interface, options, outputs, and provides several useful pieces of information including worked examples and useful tips on viewing data in other common platforms.</p></caption><media xlink:href="elife-77945-supp1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Side-by-side snapshot comparison of Human Connectome Project-Aging (HCP-A) segmentations results from HippUnfold, Freesurfer (FS7), and Automatic Segmentation of Hippocampal Subfields (ASHS) from the left hemisphere.</title><p>Snapshots were taken at the conronal centroid, centroid + 15 slices, centroid + 30 slices, and the sagittal centroid.</p></caption><media xlink:href="elife-77945-supp2-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>Side-by-side snapshot comparison of Human Connectome Project-Aging (HCP-A) segmentations results from HippUnfold, Freesurfer (FS7), and Automatic Segmentation of Hippocampal Subfields (ASHS) from the right hemisphere.</title><p>Snapshots were taken at the conronal centroid, centroid + 15 slices, centroid + 30 slices, and the sagittal centroid.</p></caption><media xlink:href="elife-77945-supp3-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp4"><label>Supplementary file 4.</label><caption><title>Detailed mathematical formulation of algorithms used throughout HippUnfold.</title></caption><media xlink:href="elife-77945-supp4-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-77945-transrepform1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All code for the HippUnfold application has been made available at <ext-link ext-link-type="uri" xlink:href="https://github.com/khanlab/hippunfold">https://github.com/khanlab/hippunfold</ext-link>, (v1.2.0 release at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/7063098">https://zenodo.org/record/7063098</ext-link>). Data and code to generate the Figures shown in this study have been made available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/6360647">https://zenodo.org/record/6360647</ext-link>. Training data for machine learning models have been made available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/7007362">https://zenodo.org/record/7007362</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>AR</given-names></name><name><surname>DeKraker</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>HippUnfold HCP-YA Training Data</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.7007362</pub-id></element-citation></p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Bookheimer</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Human Connectome Project - Aging</data-title><source>Connectome Coordination Facility</source><pub-id pub-id-type="doi">10.15154/1520707</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by a Canadian Institutes for Health Research Project Grant (CIHR Grant # 366062) to AK and SK. AK was supported by the Canada Research Chairs program #950-231964, NSERC Discovery Grant #6639, and Canada Foundation for Innovation (CFI) John R Evans Leaders Fund project #37427, the Canada First Research Excellence Fund, and Brain Canada. JD was funded through a Natural Sciences and Engineering Research Council doctoral Canadian Graduate Scholarship (NSERC CGS-D). RAMH was supported by a BrainsCAN postdoctoral fellowship for this work.</p><p>Data were provided in part by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University.</p><p>Data and/or research tools used in the preparation of this manuscript were obtained from the National Institute of Mental Health (NIMH) Data Archive (NDA). NDA is a collaborative informatics system created by the National Institutes of Health to provide a national resource to support and accelerate research in mental health. Dataset identifier: 10.15154/1520707. This manuscript reflects the views of the authors and may not reflect the opinions or views of the NIH or of the Submitters submitting original data to NDA.</p><p>Data was also provided in part by <xref ref-type="bibr" rid="bib3">Berron et al., 2017</xref>, in their published work 'A protocol for manual segmentation of medial temporal lobe subregions in 7 T MRI' (<xref ref-type="bibr" rid="bib3">Berron et al., 2017</xref>) which includes MRI images and subfield segmentations.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Lepage</surname><given-names>C</given-names></name><name><surname>Borgeat</surname><given-names>L</given-names></name><name><surname>Mohlberg</surname><given-names>H</given-names></name><name><surname>Dickscheid</surname><given-names>T</given-names></name><name><surname>Rousseau</surname><given-names>M-É</given-names></name><name><surname>Bludau</surname><given-names>S</given-names></name><name><surname>Bazin</surname><given-names>P-L</given-names></name><name><surname>Lewis</surname><given-names>LB</given-names></name><name><surname>Oros-Peusquens</surname><given-names>A-M</given-names></name><name><surname>Shah</surname><given-names>NJ</given-names></name><name><surname>Lippert</surname><given-names>T</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name><name><surname>Evans</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>BigBrain: an ultrahigh-resolution 3D human brain model</article-title><source>Science</source><volume>340</volume><fpage>1472</fpage><lpage>1475</lpage><pub-id pub-id-type="doi">10.1126/science.1235381</pub-id><pub-id pub-id-type="pmid">23788795</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avants</surname><given-names>BB</given-names></name><name><surname>Epstein</surname><given-names>CL</given-names></name><name><surname>Grossman</surname><given-names>M</given-names></name><name><surname>Gee</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</article-title><source>Medical Image Analysis</source><volume>12</volume><fpage>26</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.media.2007.06.004</pub-id><pub-id pub-id-type="pmid">17659998</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berron</surname><given-names>D</given-names></name><name><surname>Vieweg</surname><given-names>P</given-names></name><name><surname>Hochkeppler</surname><given-names>A</given-names></name><name><surname>Pluta</surname><given-names>JB</given-names></name><name><surname>Ding</surname><given-names>S-L</given-names></name><name><surname>Maass</surname><given-names>A</given-names></name><name><surname>Luther</surname><given-names>A</given-names></name><name><surname>Xie</surname><given-names>L</given-names></name><name><surname>Das</surname><given-names>SR</given-names></name><name><surname>Wolk</surname><given-names>DA</given-names></name><name><surname>Wolbers</surname><given-names>T</given-names></name><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name><name><surname>Wisse</surname><given-names>LEM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A protocol for manual segmentation of medial temporal lobe subregions in 7 Tesla MRI</article-title><source>NeuroImage. Clinical</source><volume>15</volume><fpage>466</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1016/j.nicl.2017.05.022</pub-id><pub-id pub-id-type="pmid">28652965</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blümcke</surname><given-names>I</given-names></name><name><surname>Thom</surname><given-names>M</given-names></name><name><surname>Aronica</surname><given-names>E</given-names></name><name><surname>Armstrong</surname><given-names>DD</given-names></name><name><surname>Bartolomei</surname><given-names>F</given-names></name><name><surname>Bernasconi</surname><given-names>A</given-names></name><name><surname>Bernasconi</surname><given-names>N</given-names></name><name><surname>Bien</surname><given-names>CG</given-names></name><name><surname>Cendes</surname><given-names>F</given-names></name><name><surname>Coras</surname><given-names>R</given-names></name><name><surname>Cross</surname><given-names>JH</given-names></name><name><surname>Jacques</surname><given-names>TS</given-names></name><name><surname>Kahane</surname><given-names>P</given-names></name><name><surname>Mathern</surname><given-names>GW</given-names></name><name><surname>Miyata</surname><given-names>H</given-names></name><name><surname>Moshé</surname><given-names>SL</given-names></name><name><surname>Oz</surname><given-names>B</given-names></name><name><surname>Özkara</surname><given-names>Ç</given-names></name><name><surname>Perucca</surname><given-names>E</given-names></name><name><surname>Sisodiya</surname><given-names>S</given-names></name><name><surname>Wiebe</surname><given-names>S</given-names></name><name><surname>Spreafico</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>International consensus classification of hippocampal sclerosis in temporal lobe epilepsy: a task force report from the ILAE Commission on diagnostic methods</article-title><source>Epilepsia</source><volume>54</volume><fpage>1315</fpage><lpage>1329</lpage><pub-id pub-id-type="doi">10.1111/epi.12220</pub-id><pub-id pub-id-type="pmid">23692496</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bookheimer</surname><given-names>SY</given-names></name><name><surname>Salat</surname><given-names>DH</given-names></name><name><surname>Terpstra</surname><given-names>M</given-names></name><name><surname>Ances</surname><given-names>BM</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Burgess</surname><given-names>GC</given-names></name><name><surname>Curtiss</surname><given-names>SW</given-names></name><name><surname>Diaz-Santos</surname><given-names>M</given-names></name><name><surname>Elam</surname><given-names>JS</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Greve</surname><given-names>DN</given-names></name><name><surname>Hagy</surname><given-names>HA</given-names></name><name><surname>Harms</surname><given-names>MP</given-names></name><name><surname>Hatch</surname><given-names>OM</given-names></name><name><surname>Hedden</surname><given-names>T</given-names></name><name><surname>Hodge</surname><given-names>C</given-names></name><name><surname>Japardi</surname><given-names>KC</given-names></name><name><surname>Kuhn</surname><given-names>TP</given-names></name><name><surname>Ly</surname><given-names>TK</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Somerville</surname><given-names>LH</given-names></name><name><surname>Uğurbil</surname><given-names>K</given-names></name><name><surname>van der Kouwe</surname><given-names>A</given-names></name><name><surname>Van Essen</surname><given-names>D</given-names></name><name><surname>Woods</surname><given-names>RP</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The lifespan human connectome project in aging: an overview</article-title><source>NeuroImage</source><volume>185</volume><fpage>335</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.009</pub-id><pub-id pub-id-type="pmid">30332613</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Markiewicz</surname><given-names>CJ</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Côté</surname><given-names>MA</given-names></name><name><surname>Cipollini</surname><given-names>B</given-names></name><name><surname>McCarthy</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Nipy/nibabel</data-title><version designator="3.2.1">3.2.1</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4295521">https://doi.org/10.5281/zenodo.4295521</ext-link></element-citation></ref><ref id="bib7"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Angelini</surname><given-names>ED</given-names></name><name><surname>Landman</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Is hippocampus getting bumpier with age: a quantitative analysis of fine-scale dentational feature under the hippocampus on 552 healthy subjects</article-title><conf-name>Image Processing</conf-name><conf-loc>San Diego, United States</conf-loc><elocation-id>e701</elocation-id><pub-id pub-id-type="doi">10.1117/12.2512701</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname><given-names>VA</given-names></name><name><surname>Bernstein</surname><given-names>JD</given-names></name><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Rutt</surname><given-names>BK</given-names></name><name><surname>Kerchner</surname><given-names>GA</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Individual differences in associative memory among older adults explained by hippocampal subfield structure and function</article-title><source>PNAS</source><volume>114</volume><fpage>12075</fpage><lpage>12080</lpage><pub-id pub-id-type="doi">10.1073/pnas.1713308114</pub-id><pub-id pub-id-type="pmid">29078387</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chakravarty</surname><given-names>MM</given-names></name><name><surname>Steadman</surname><given-names>P</given-names></name><name><surname>van Eede</surname><given-names>MC</given-names></name><name><surname>Calcott</surname><given-names>RD</given-names></name><name><surname>Gu</surname><given-names>V</given-names></name><name><surname>Shaw</surname><given-names>P</given-names></name><name><surname>Raznahan</surname><given-names>A</given-names></name><name><surname>Collins</surname><given-names>DL</given-names></name><name><surname>Lerch</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Performing label-fusion-based segmentation using multiple automatically generated templates</article-title><source>Human Brain Mapping</source><volume>34</volume><fpage>2635</fpage><lpage>2654</lpage><pub-id pub-id-type="doi">10.1002/hbm.22092</pub-id><pub-id pub-id-type="pmid">22611030</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Zhou</surname><given-names>N</given-names></name><name><surname>Li</surname><given-names>SX</given-names></name><name><surname>Ver Hoef</surname><given-names>L</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The bumps under the hippocampus</article-title><source>Human Brain Mapping</source><volume>39</volume><fpage>472</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1002/hbm.23856</pub-id><pub-id pub-id-type="pmid">29058349</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crombe</surname><given-names>A</given-names></name><name><surname>Planche</surname><given-names>V</given-names></name><name><surname>Raffard</surname><given-names>G</given-names></name><name><surname>Bourel</surname><given-names>J</given-names></name><name><surname>Dubourdieu</surname><given-names>N</given-names></name><name><surname>Panatier</surname><given-names>A</given-names></name><name><surname>Fukutomi</surname><given-names>H</given-names></name><name><surname>Dousset</surname><given-names>V</given-names></name><name><surname>Oliet</surname><given-names>S</given-names></name><name><surname>Hiba</surname><given-names>B</given-names></name><name><surname>Tourdias</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deciphering the microstructure of hippocampal subfields with in vivo DTI and NODDI: applications to experimental multiple sclerosis</article-title><source>NeuroImage</source><volume>172</volume><fpage>357</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.061</pub-id><pub-id pub-id-type="pmid">29409838</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeKraker</surname><given-names>J</given-names></name><name><surname>Ferko</surname><given-names>KM</given-names></name><name><surname>Lau</surname><given-names>JC</given-names></name><name><surname>Köhler</surname><given-names>S</given-names></name><name><surname>Khan</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Unfolding the hippocampus: an intrinsic coordinate system for subfield segmentations and quantitative mapping</article-title><source>NeuroImage</source><volume>167</volume><fpage>408</fpage><lpage>418</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.11.054</pub-id><pub-id pub-id-type="pmid">29175494</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeKraker</surname><given-names>J</given-names></name><name><surname>Lau</surname><given-names>JC</given-names></name><name><surname>Ferko</surname><given-names>KM</given-names></name><name><surname>Khan</surname><given-names>AR</given-names></name><name><surname>Köhler</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hippocampal subfields revealed through unfolding and unsupervised clustering of laminar and morphological features in 3D bigbrain</article-title><source>NeuroImage</source><volume>206</volume><elocation-id>116328</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116328</pub-id><pub-id pub-id-type="pmid">31682982</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeKraker</surname><given-names>J</given-names></name><name><surname>Köhler</surname><given-names>S</given-names></name><name><surname>Khan</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Surface-Based hippocampal subfield segmentation</article-title><source>Trends in Neurosciences</source><volume>44</volume><fpage>856</fpage><lpage>863</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2021.06.005</pub-id><pub-id pub-id-type="pmid">34304910</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Dekraker</surname><given-names>J</given-names></name><name><surname>Khan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>HippUnfold HCP-YA training data</data-title><version designator="1.0.0">1.0.0</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.7007362">https://doi.org/10.5281/zenodo.7007362</ext-link></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dill</surname><given-names>V</given-names></name><name><surname>Franco</surname><given-names>AR</given-names></name><name><surname>Pinho</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Automated methods for hippocampus segmentation: the evolution and a review of the state of the art</article-title><source>Neuroinformatics</source><volume>13</volume><fpage>133</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1007/s12021-014-9243-4</pub-id><pub-id pub-id-type="pmid">26022748</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>SL</given-names></name><name><surname>Van Hoesen</surname><given-names>GW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Organization and detailed parcellation of human hippocampal head and body regions based on a combined analysis of cyto- and chemoarchitecture</article-title><source>The Journal of Comparative Neurology</source><volume>523</volume><fpage>2233</fpage><lpage>2253</lpage><pub-id pub-id-type="doi">10.1002/cne.23786</pub-id><pub-id pub-id-type="pmid">25872498</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>G</given-names></name><name><surname>Cao</surname><given-names>X</given-names></name><name><surname>Liang</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Zhan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Medical image segmentation based on U-net: a review</article-title><source>Journal of Imaging Science and Technology</source><volume>64</volume><fpage>20508</fpage><lpage>20511</lpage><pub-id pub-id-type="doi">10.2352/J.ImagingSci.Technol.2020.64.2.020508</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Duvernoy</surname><given-names>HM</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>The Human Hippocampus</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-662-03628-0</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganzetti</surname><given-names>M</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name><name><surname>Mantini</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Whole brain myelin mapping using T1- and T2-weighted MR imaging data</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>671</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00671</pub-id><pub-id pub-id-type="pmid">25228871</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>E</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Sudre</surname><given-names>C</given-names></name><name><surname>Fidon</surname><given-names>L</given-names></name><name><surname>Shakir</surname><given-names>DI</given-names></name><name><surname>Wang</surname><given-names>G</given-names></name><name><surname>Eaton-Rosen</surname><given-names>Z</given-names></name><name><surname>Gray</surname><given-names>R</given-names></name><name><surname>Doel</surname><given-names>T</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Whyntie</surname><given-names>T</given-names></name><name><surname>Nachev</surname><given-names>P</given-names></name><name><surname>Modat</surname><given-names>M</given-names></name><name><surname>Barratt</surname><given-names>DC</given-names></name><name><surname>Ourselin</surname><given-names>S</given-names></name><name><surname>Cardoso</surname><given-names>MJ</given-names></name><name><surname>Vercauteren</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>NiftyNet: a deep-learning platform for medical imaging</article-title><source>Computer Methods and Programs in Biomedicine</source><volume>158</volume><fpage>113</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1016/j.cmpb.2018.01.025</pub-id><pub-id pub-id-type="pmid">29544777</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name><name><surname>Wilson</surname><given-names>JA</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Andersson</surname><given-names>JL</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Webster</surname><given-names>M</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>The minimal preprocessing pipelines for the human connectome project</article-title><source>NeuroImage</source><volume>80</volume><fpage>105</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id><pub-id pub-id-type="pmid">23668970</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Hacker</surname><given-names>CD</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A multi-modal parcellation of human cerebral cortex</article-title><source>Nature</source><volume>536</volume><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1038/nature18933</pub-id><pub-id pub-id-type="pmid">27437579</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Auer</surname><given-names>T</given-names></name><name><surname>Calhoun</surname><given-names>VD</given-names></name><name><surname>Craddock</surname><given-names>RC</given-names></name><name><surname>Das</surname><given-names>S</given-names></name><name><surname>Duff</surname><given-names>EP</given-names></name><name><surname>Flandin</surname><given-names>G</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Glatard</surname><given-names>T</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Handwerker</surname><given-names>DA</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Keator</surname><given-names>D</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Michael</surname><given-names>Z</given-names></name><name><surname>Maumet</surname><given-names>C</given-names></name><name><surname>Nichols</surname><given-names>BN</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Pellman</surname><given-names>J</given-names></name><name><surname>Poline</surname><given-names>JB</given-names></name><name><surname>Rokem</surname><given-names>A</given-names></name><name><surname>Schaefer</surname><given-names>G</given-names></name><name><surname>Sochat</surname><given-names>V</given-names></name><name><surname>Triplett</surname><given-names>W</given-names></name><name><surname>Turner</surname><given-names>JA</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</article-title><source>Scientific Data</source><volume>3</volume><elocation-id>160044</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2016.44</pub-id><pub-id pub-id-type="pmid">27326542</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Alfaro-Almagro</surname><given-names>F</given-names></name><name><surname>Auer</surname><given-names>T</given-names></name><name><surname>Bellec</surname><given-names>P</given-names></name><name><surname>Capotă</surname><given-names>M</given-names></name><name><surname>Chakravarty</surname><given-names>MM</given-names></name><name><surname>Churchill</surname><given-names>NW</given-names></name><name><surname>Cohen</surname><given-names>AL</given-names></name><name><surname>Craddock</surname><given-names>RC</given-names></name><name><surname>Devenyi</surname><given-names>GA</given-names></name><name><surname>Eklund</surname><given-names>A</given-names></name><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Flandin</surname><given-names>G</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Keshavan</surname><given-names>A</given-names></name><name><surname>Kiar</surname><given-names>G</given-names></name><name><surname>Liem</surname><given-names>F</given-names></name><name><surname>Raamana</surname><given-names>PR</given-names></name><name><surname>Raffelt</surname><given-names>D</given-names></name><name><surname>Steele</surname><given-names>CJ</given-names></name><name><surname>Quirion</surname><given-names>P-O</given-names></name><name><surname>Smith</surname><given-names>RE</given-names></name><name><surname>Strother</surname><given-names>SC</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Yarkoni</surname><given-names>T</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>BIDS apps: improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005209</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005209</pub-id><pub-id pub-id-type="pmid">28278228</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>DW</given-names></name><name><surname>Misaghi</surname><given-names>E</given-names></name><name><surname>Steve</surname><given-names>TA</given-names></name><name><surname>Wilman</surname><given-names>AH</given-names></name><name><surname>Beaulieu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Curved multiplanar reformatting provides improved visualization of hippocampal anatomy</article-title><source>Hippocampus</source><volume>30</volume><fpage>156</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1002/hipo.23177</pub-id><pub-id pub-id-type="pmid">31743546</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haast</surname><given-names>RAM</given-names></name><name><surname>Lau</surname><given-names>JC</given-names></name><name><surname>Ivanov</surname><given-names>D</given-names></name><name><surname>Menon</surname><given-names>RS</given-names></name><name><surname>Uludağ</surname><given-names>K</given-names></name><name><surname>Khan</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Effects of MP2RAGE b1+ sensitivity on inter-site T1 reproducibility and hippocampal morphometry at 7T</article-title><source>NeuroImage</source><volume>224</volume><elocation-id>117373</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117373</pub-id><pub-id pub-id-type="pmid">32949709</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haukvik</surname><given-names>UK</given-names></name><name><surname>Tamnes</surname><given-names>CK</given-names></name><name><surname>Söderman</surname><given-names>E</given-names></name><name><surname>Agartz</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuroimaging hippocampal subfields in schizophrenia and bipolar disorder: a systematic review and meta-analysis</article-title><source>Journal of Psychiatric Research</source><volume>104</volume><fpage>217</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1016/j.jpsychires.2018.08.012</pub-id><pub-id pub-id-type="pmid">30107268</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernández</surname><given-names>M</given-names></name><name><surname>Guerrero</surname><given-names>GD</given-names></name><name><surname>Cecilia</surname><given-names>JM</given-names></name><name><surname>García</surname><given-names>JM</given-names></name><name><surname>Inuggi</surname><given-names>A</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Accelerating fibre orientation estimation from diffusion weighted magnetic resonance imaging using GPUs</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e61892</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0061892</pub-id><pub-id pub-id-type="pmid">23658616</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huntenburg</surname><given-names>JM</given-names></name><name><surname>Steele</surname><given-names>CJ</given-names></name><name><surname>Bazin</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Nighres: processing tools for high-resolution neuroimaging</article-title><source>GigaScience</source><volume>7</volume><elocation-id>giy082</elocation-id><pub-id pub-id-type="doi">10.1093/gigascience/giy082</pub-id><pub-id pub-id-type="pmid">29982501</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iglesias</surname><given-names>JE</given-names></name><name><surname>Augustinack</surname><given-names>JC</given-names></name><name><surname>Nguyen</surname><given-names>K</given-names></name><name><surname>Player</surname><given-names>CM</given-names></name><name><surname>Player</surname><given-names>A</given-names></name><name><surname>Wright</surname><given-names>M</given-names></name><name><surname>Roy</surname><given-names>N</given-names></name><name><surname>Frosch</surname><given-names>MP</given-names></name><name><surname>McKee</surname><given-names>AC</given-names></name><name><surname>Wald</surname><given-names>LL</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Van Leemput</surname><given-names>K</given-names></name><collab>Alzheimer’s Disease Neuroimaging Initiative</collab></person-group><year iso-8601-date="2015">2015</year><article-title>A computational atlas of the hippocampal formation using ex vivo, ultra-high resolution MRI: application to adaptive segmentation of in vivo MRI</article-title><source>NeuroImage</source><volume>115</volume><fpage>117</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.04.042</pub-id><pub-id pub-id-type="pmid">25936807</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iglesias</surname><given-names>JE</given-names></name><name><surname>Billot</surname><given-names>B</given-names></name><name><surname>Balbastre</surname><given-names>Y</given-names></name><name><surname>Tabari</surname><given-names>A</given-names></name><name><surname>Conklin</surname><given-names>J</given-names></name><name><surname>Gilberto González</surname><given-names>R</given-names></name><name><surname>Alexander</surname><given-names>DC</given-names></name><name><surname>Golland</surname><given-names>P</given-names></name><name><surname>Edlow</surname><given-names>BL</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><collab>Alzheimer’s Disease Neuroimaging Initiative</collab></person-group><year iso-8601-date="2021">2021</year><article-title>Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes from clinical MRI exams with scans of different orientation, resolution and contrast</article-title><source>NeuroImage</source><volume>237</volume><elocation-id>118206</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118206</pub-id><pub-id pub-id-type="pmid">34048902</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Isensee</surname><given-names>F</given-names></name><name><surname>Jaeger</surname><given-names>PF</given-names></name><name><surname>Kohl</surname><given-names>SAA</given-names></name><name><surname>Petersen</surname><given-names>J</given-names></name><name><surname>Maier-Hein</surname><given-names>KH</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>NnU-net: a self-configuring method for deep learning-based biomedical image segmentation</article-title><source>Nature Methods</source><volume>18</volume><fpage>203</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1038/s41592-020-01008-z</pub-id><pub-id pub-id-type="pmid">33288961</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>A</given-names></name><name><surname>Haast</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Snakebids - BIDS integration into snakemake workflows</data-title><version designator="0.2.1">0.2.1</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4488249">https://doi.org/10.5281/zenodo.4488249</ext-link></element-citation></ref><ref id="bib35"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Khanlab/hippunfold</data-title><version designator="v1.2.0">v1.2.0</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.7063098">https://doi.org/10.5281/zenodo.7063098</ext-link></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Carneiro</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><chapter-title>Deep learning and convolutional neural networks for medical image computing</chapter-title><person-group person-group-type="editor"><name><surname>Yang</surname><given-names>L</given-names></name></person-group><source>Deep Learning and Convolutional Neural Networks for Medical Image Computing: Precision Medicine, High Performance and Large-Scale Datasets</source><publisher-loc>Cham</publisher-loc><publisher-name>Springer</publisher-name><fpage>XIII</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-42999-1</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>DS</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Olsen</surname><given-names>T</given-names></name><name><surname>Hodge</surname><given-names>M</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Prior</surname><given-names>F</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Laumann</surname><given-names>T</given-names></name><name><surname>Curtiss</surname><given-names>SW</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Informatics and data mining tools and strategies for the human connectome project</article-title><source>Frontiers in Neuroinformatics</source><volume>5</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2011.00004</pub-id><pub-id pub-id-type="pmid">21743807</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>DS</given-names></name><name><surname>Harms</surname><given-names>MP</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>JA</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Archie</surname><given-names>KA</given-names></name><name><surname>Burgess</surname><given-names>GC</given-names></name><name><surname>Ramaratnam</surname><given-names>M</given-names></name><name><surname>Hodge</surname><given-names>M</given-names></name><name><surname>Horton</surname><given-names>W</given-names></name><name><surname>Herrick</surname><given-names>R</given-names></name><name><surname>Olsen</surname><given-names>T</given-names></name><name><surname>McKay</surname><given-names>M</given-names></name><name><surname>House</surname><given-names>M</given-names></name><name><surname>Hileman</surname><given-names>M</given-names></name><name><surname>Reid</surname><given-names>E</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Coalson</surname><given-names>T</given-names></name><name><surname>Schindler</surname><given-names>J</given-names></name><name><surname>Elam</surname><given-names>JS</given-names></name><name><surname>Curtiss</surname><given-names>SW</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>Human connectome project informatics: quality control, database services, and data visualization</article-title><source>NeuroImage</source><volume>80</volume><fpage>202</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.077</pub-id><pub-id pub-id-type="pmid">23707591</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Modat</surname><given-names>M</given-names></name><name><surname>Ridgway</surname><given-names>GR</given-names></name><name><surname>Taylor</surname><given-names>ZA</given-names></name><name><surname>Lehmann</surname><given-names>M</given-names></name><name><surname>Barnes</surname><given-names>J</given-names></name><name><surname>Hawkes</surname><given-names>DJ</given-names></name><name><surname>Fox</surname><given-names>NC</given-names></name><name><surname>Ourselin</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Fast free-form deformation using graphics processing units</article-title><source>Computer Methods and Programs in Biomedicine</source><volume>98</volume><fpage>278</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1016/j.cmpb.2009.09.002</pub-id><pub-id pub-id-type="pmid">19818524</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mölder</surname><given-names>F</given-names></name><name><surname>Jablonski</surname><given-names>KP</given-names></name><name><surname>Letcher</surname><given-names>B</given-names></name><name><surname>Hall</surname><given-names>MB</given-names></name><name><surname>Tomkins-Tinch</surname><given-names>CH</given-names></name><name><surname>Sochat</surname><given-names>V</given-names></name><name><surname>Forster</surname><given-names>J</given-names></name><name><surname>Lee</surname><given-names>S</given-names></name><name><surname>Twardziok</surname><given-names>SO</given-names></name><name><surname>Kanitz</surname><given-names>A</given-names></name><name><surname>Wilm</surname><given-names>A</given-names></name><name><surname>Holtgrewe</surname><given-names>M</given-names></name><name><surname>Rahmann</surname><given-names>S</given-names></name><name><surname>Nahnsen</surname><given-names>S</given-names></name><name><surname>Köster</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Sustainable data analysis with snakemake</article-title><source>F1000Research</source><volume>10</volume><elocation-id>33</elocation-id><pub-id pub-id-type="doi">10.12688/f1000research.29032.2</pub-id><pub-id pub-id-type="pmid">34035898</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><chapter-title>Regents Professor of Psychology Lynn Nadel</chapter-title><source>The Hippocampus as a Cognitive Map</source><publisher-loc>USA</publisher-loc><publisher-name>Oxford University Press</publisher-name><fpage>663</fpage><lpage>694</lpage></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pauli</surname><given-names>WM</given-names></name><name><surname>Nili</surname><given-names>AN</given-names></name><name><surname>Tyszka</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A high-resolution probabilistic in vivo atlas of human subcortical brain nuclei</article-title><source>Scientific Data</source><volume>5</volume><elocation-id>180063</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2018.63</pub-id><pub-id pub-id-type="pmid">29664465</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pipitone</surname><given-names>J</given-names></name><name><surname>Park</surname><given-names>MTM</given-names></name><name><surname>Winterburn</surname><given-names>J</given-names></name><name><surname>Lett</surname><given-names>TA</given-names></name><name><surname>Lerch</surname><given-names>JP</given-names></name><name><surname>Pruessner</surname><given-names>JC</given-names></name><name><surname>Lepage</surname><given-names>M</given-names></name><name><surname>Voineskos</surname><given-names>AN</given-names></name><name><surname>Chakravarty</surname><given-names>MM</given-names></name><collab>Alzheimer’s Disease Neuroimaging Initiative</collab></person-group><year iso-8601-date="2014">2014</year><article-title>Multi-atlas segmentation of the whole hippocampus and subfields using multiple automatically generated templates</article-title><source>NeuroImage</source><volume>101</volume><fpage>494</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.04.054</pub-id><pub-id pub-id-type="pmid">24784800</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiu</surname><given-names>A</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Multi-structure network shape analysis via normal surface momentum maps</article-title><source>NeuroImage</source><volume>42</volume><fpage>1430</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.04.257</pub-id><pub-id pub-id-type="pmid">18675553</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name><name><surname>Hernández-Fernández</surname><given-names>M</given-names></name><name><surname>Vu</surname><given-names>AT</given-names></name><name><surname>Andersson</surname><given-names>JL</given-names></name><name><surname>Moeller</surname><given-names>S</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Lenglet</surname><given-names>C</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fusion in diffusion MRI for improved fibre orientation estimation: an application to the 3T and 7T data of the human connectome project</article-title><source>NeuroImage</source><volume>134</volume><fpage>396</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.04.014</pub-id><pub-id pub-id-type="pmid">27071694</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steve</surname><given-names>TA</given-names></name><name><surname>Jirsch</surname><given-names>JD</given-names></name><name><surname>Gross</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Quantification of subfield pathology in hippocampal sclerosis: a systematic review and meta-analysis</article-title><source>Epilepsy Research</source><volume>108</volume><fpage>1279</fpage><lpage>1285</lpage><pub-id pub-id-type="doi">10.1016/j.eplepsyres.2014.07.003</pub-id><pub-id pub-id-type="pmid">25107686</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steve</surname><given-names>TA</given-names></name><name><surname>Yasuda</surname><given-names>CL</given-names></name><name><surname>Coras</surname><given-names>R</given-names></name><name><surname>Lail</surname><given-names>M</given-names></name><name><surname>Blumcke</surname><given-names>I</given-names></name><name><surname>Livy</surname><given-names>DJ</given-names></name><name><surname>Malykhin</surname><given-names>N</given-names></name><name><surname>Gross</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Development of a histologically validated segmentation protocol for the hippocampal body</article-title><source>NeuroImage</source><volume>157</volume><fpage>219</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.008</pub-id><pub-id pub-id-type="pmid">28587896</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thom</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Review: hippocampal sclerosis in epilepsy: a neuropathology review</article-title><source>Neuropathology and Applied Neurobiology</source><volume>40</volume><fpage>520</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1111/nan.12150</pub-id><pub-id pub-id-type="pmid">24762203</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Drury</surname><given-names>HA</given-names></name><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Functional and structural mapping of human cerebral cortex: solutions are in the surfaces</article-title><source>Advances in Neurology</source><volume>84</volume><fpage>23</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">11091855</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>The WU-minn human connectome project: an overview</article-title><source>NeuroImage</source><volume>80</volume><fpage>62</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.041</pub-id><pub-id pub-id-type="pmid">23684880</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Carey</surname><given-names>CJ</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Henriksen</surname><given-names>I</given-names></name><name><surname>Quintero</surname><given-names>EA</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>van Mulbregt</surname><given-names>P</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vos de Wael</surname><given-names>R</given-names></name><name><surname>Larivière</surname><given-names>S</given-names></name><name><surname>Caldairou</surname><given-names>B</given-names></name><name><surname>Hong</surname><given-names>SJ</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Bernasconi</surname><given-names>A</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Bernasconi</surname><given-names>N</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Anatomical and microstructural determinants of hippocampal subfield functional connectome embedding</article-title><source>PNAS</source><volume>115</volume><fpage>10154</fpage><lpage>10159</lpage><pub-id pub-id-type="doi">10.1073/pnas.1803667115</pub-id><pub-id pub-id-type="pmid">30249658</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waehnert</surname><given-names>MD</given-names></name><name><surname>Dinse</surname><given-names>J</given-names></name><name><surname>Weiss</surname><given-names>M</given-names></name><name><surname>Streicher</surname><given-names>MN</given-names></name><name><surname>Waehnert</surname><given-names>P</given-names></name><name><surname>Geyer</surname><given-names>S</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name><name><surname>Bazin</surname><given-names>P-L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anatomically motivated modeling of cortical laminae</article-title><source>NeuroImage</source><volume>93 Pt 2</volume><fpage>210</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.03.078</pub-id><pub-id pub-id-type="pmid">23603284</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiestler</surname><given-names>B</given-names></name><name><surname>Menze</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Deep learning for medical image analysis: a brief introduction</article-title><source>Neuro-Oncology Advances</source><volume>2</volume><fpage>iv35</fpage><lpage>iv41</lpage><pub-id pub-id-type="doi">10.1093/noajnl/vdaa092</pub-id><pub-id pub-id-type="pmid">33521639</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winterburn</surname><given-names>JL</given-names></name><name><surname>Pruessner</surname><given-names>JC</given-names></name><name><surname>Chavez</surname><given-names>S</given-names></name><name><surname>Schira</surname><given-names>MM</given-names></name><name><surname>Lobaugh</surname><given-names>NJ</given-names></name><name><surname>Voineskos</surname><given-names>AN</given-names></name><name><surname>Chakravarty</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A novel in vivo atlas of human hippocampal subfields using high-resolution 3 T magnetic resonance imaging</article-title><source>NeuroImage</source><volume>74</volume><fpage>254</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.02.003</pub-id><pub-id pub-id-type="pmid">23415948</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wisse</surname><given-names>LEM</given-names></name><name><surname>Biessels</surname><given-names>GJ</given-names></name><name><surname>Geerlings</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A critical appraisal of the hippocampal subfield segmentation package in freesurfer</article-title><source>Frontiers in Aging Neuroscience</source><volume>6</volume><elocation-id>261</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2014.00261</pub-id><pub-id pub-id-type="pmid">25309437</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wisse</surname><given-names>LEM</given-names></name><name><surname>Adler</surname><given-names>DH</given-names></name><name><surname>Ittyerah</surname><given-names>R</given-names></name><name><surname>Pluta</surname><given-names>JB</given-names></name><name><surname>Robinson</surname><given-names>JL</given-names></name><name><surname>Schuck</surname><given-names>T</given-names></name><name><surname>Trojanowski</surname><given-names>JQ</given-names></name><name><surname>Grossman</surname><given-names>M</given-names></name><name><surname>Detre</surname><given-names>JA</given-names></name><name><surname>Elliott</surname><given-names>MA</given-names></name><name><surname>Toledo</surname><given-names>JB</given-names></name><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>Pickup</surname><given-names>S</given-names></name><name><surname>Das</surname><given-names>SR</given-names></name><name><surname>Wolk</surname><given-names>DA</given-names></name><name><surname>Yushkevich</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Comparison of in vivo and ex vivo MRI of the human hippocampal formation in the same subjects</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>5185</fpage><lpage>5196</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw299</pub-id><pub-id pub-id-type="pmid">27664967</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wisse</surname><given-names>LEM</given-names></name><name><surname>Daugherty</surname><given-names>AM</given-names></name><name><surname>Olsen</surname><given-names>RK</given-names></name><name><surname>Berron</surname><given-names>D</given-names></name><name><surname>Carr</surname><given-names>VA</given-names></name><name><surname>Stark</surname><given-names>CEL</given-names></name><name><surname>Amaral</surname><given-names>RSC</given-names></name><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Augustinack</surname><given-names>JC</given-names></name><name><surname>Bender</surname><given-names>AR</given-names></name><name><surname>Bernstein</surname><given-names>JD</given-names></name><name><surname>Boccardi</surname><given-names>M</given-names></name><name><surname>Bocchetta</surname><given-names>M</given-names></name><name><surname>Burggren</surname><given-names>A</given-names></name><name><surname>Chakravarty</surname><given-names>MM</given-names></name><name><surname>Chupin</surname><given-names>M</given-names></name><name><surname>Ekstrom</surname><given-names>A</given-names></name><name><surname>de Flores</surname><given-names>R</given-names></name><name><surname>Insausti</surname><given-names>R</given-names></name><name><surname>Kanel</surname><given-names>P</given-names></name><name><surname>Kedo</surname><given-names>O</given-names></name><name><surname>Kennedy</surname><given-names>KM</given-names></name><name><surname>Kerchner</surname><given-names>GA</given-names></name><name><surname>LaRocque</surname><given-names>KF</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Maass</surname><given-names>A</given-names></name><name><surname>Malykhin</surname><given-names>N</given-names></name><name><surname>Mueller</surname><given-names>SG</given-names></name><name><surname>Ofen</surname><given-names>N</given-names></name><name><surname>Palombo</surname><given-names>DJ</given-names></name><name><surname>Parekh</surname><given-names>MB</given-names></name><name><surname>Pluta</surname><given-names>JB</given-names></name><name><surname>Pruessner</surname><given-names>JC</given-names></name><name><surname>Raz</surname><given-names>N</given-names></name><name><surname>Rodrigue</surname><given-names>KM</given-names></name><name><surname>Schoemaker</surname><given-names>D</given-names></name><name><surname>Shafer</surname><given-names>AT</given-names></name><name><surname>Steve</surname><given-names>TA</given-names></name><name><surname>Suthana</surname><given-names>N</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Winterburn</surname><given-names>JL</given-names></name><name><surname>Yassa</surname><given-names>MA</given-names></name><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>la Joie</surname><given-names>R</given-names></name><collab>Hippocampal Subfields Group</collab></person-group><year iso-8601-date="2017">2017b</year><article-title>A harmonized segmentation protocol for hippocampal and parahippocampal subregions: why do we need one and what are the key goals?</article-title><source>Hippocampus</source><volume>27</volume><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1002/hipo.22671</pub-id><pub-id pub-id-type="pmid">27862600</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wisse</surname><given-names>LEM</given-names></name><name><surname>Chételat</surname><given-names>G</given-names></name><name><surname>Daugherty</surname><given-names>AM</given-names></name><name><surname>de Flores</surname><given-names>R</given-names></name><name><surname>la Joie</surname><given-names>R</given-names></name><name><surname>Mueller</surname><given-names>SG</given-names></name><name><surname>Stark</surname><given-names>CEL</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>Berron</surname><given-names>D</given-names></name><name><surname>Raz</surname><given-names>N</given-names></name><name><surname>Bakker</surname><given-names>A</given-names></name><name><surname>Olsen</surname><given-names>RK</given-names></name><name><surname>Carr</surname><given-names>VA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Hippocampal subfield volumetry from structural isotropic 1 MM3 MRI scans: a note of caution</article-title><source>Human Brain Mapping</source><volume>42</volume><fpage>539</fpage><lpage>550</lpage><pub-id pub-id-type="doi">10.1002/hbm.25234</pub-id><pub-id pub-id-type="pmid">33058385</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>Amaral</surname><given-names>RSC</given-names></name><name><surname>Augustinack</surname><given-names>JC</given-names></name><name><surname>Bender</surname><given-names>AR</given-names></name><name><surname>Bernstein</surname><given-names>JD</given-names></name><name><surname>Boccardi</surname><given-names>M</given-names></name><name><surname>Bocchetta</surname><given-names>M</given-names></name><name><surname>Burggren</surname><given-names>AC</given-names></name><name><surname>Carr</surname><given-names>VA</given-names></name><name><surname>Chakravarty</surname><given-names>MM</given-names></name><name><surname>Chételat</surname><given-names>G</given-names></name><name><surname>Daugherty</surname><given-names>AM</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name><name><surname>Ding</surname><given-names>SL</given-names></name><name><surname>Ekstrom</surname><given-names>A</given-names></name><name><surname>Geerlings</surname><given-names>MI</given-names></name><name><surname>Hassan</surname><given-names>A</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Iglesias</surname><given-names>JE</given-names></name><name><surname>La Joie</surname><given-names>R</given-names></name><name><surname>Kerchner</surname><given-names>GA</given-names></name><name><surname>LaRocque</surname><given-names>KF</given-names></name><name><surname>Libby</surname><given-names>LA</given-names></name><name><surname>Malykhin</surname><given-names>N</given-names></name><name><surname>Mueller</surname><given-names>SG</given-names></name><name><surname>Olsen</surname><given-names>RK</given-names></name><name><surname>Palombo</surname><given-names>DJ</given-names></name><name><surname>Parekh</surname><given-names>MB</given-names></name><name><surname>Pluta</surname><given-names>JB</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name><name><surname>Pruessner</surname><given-names>JC</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Raz</surname><given-names>N</given-names></name><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Schoemaker</surname><given-names>D</given-names></name><name><surname>Singh</surname><given-names>S</given-names></name><name><surname>Stark</surname><given-names>CEL</given-names></name><name><surname>Suthana</surname><given-names>N</given-names></name><name><surname>Tompary</surname><given-names>A</given-names></name><name><surname>Turowski</surname><given-names>MM</given-names></name><name><surname>Van Leemput</surname><given-names>K</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Winterburn</surname><given-names>JL</given-names></name><name><surname>Wisse</surname><given-names>LEM</given-names></name><name><surname>Yassa</surname><given-names>MA</given-names></name><name><surname>Zeineh</surname><given-names>MM</given-names></name><collab>Hippocampal Subfields Group</collab></person-group><year iso-8601-date="2015">2015a</year><article-title>Quantitative comparison of 21 protocols for labeling hippocampal subfields and parahippocampal subregions in in vivo MRI: towards a harmonized segmentation protocol</article-title><source>NeuroImage</source><volume>111</volume><fpage>526</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.01.004</pub-id><pub-id pub-id-type="pmid">25596463</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>Pluta</surname><given-names>JB</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Xie</surname><given-names>L</given-names></name><name><surname>Ding</surname><given-names>SL</given-names></name><name><surname>Gertje</surname><given-names>EC</given-names></name><name><surname>Mancuso</surname><given-names>L</given-names></name><name><surname>Kliot</surname><given-names>D</given-names></name><name><surname>Das</surname><given-names>SR</given-names></name><name><surname>Wolk</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Automated volumetry and regional thickness analysis of hippocampal subfields and medial temporal cortical structures in mild cognitive impairment</article-title><source>Human Brain Mapping</source><volume>36</volume><fpage>258</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1002/hbm.22627</pub-id><pub-id pub-id-type="pmid">25181316</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>Pashchinskiy</surname><given-names>A</given-names></name><name><surname>Oguz</surname><given-names>I</given-names></name><name><surname>Mohan</surname><given-names>S</given-names></name><name><surname>Schmitt</surname><given-names>JE</given-names></name><name><surname>Stein</surname><given-names>JM</given-names></name><name><surname>Zukić</surname><given-names>D</given-names></name><name><surname>Vicory</surname><given-names>J</given-names></name><name><surname>McCormick</surname><given-names>M</given-names></name><name><surname>Yushkevich</surname><given-names>N</given-names></name><name><surname>Schwartz</surname><given-names>N</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Gerig</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>User-guided segmentation of multi-modality medical imaging datasets with ITK-SNAP</article-title><source>Neuroinformatics</source><volume>17</volume><fpage>83</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1007/s12021-018-9385-x</pub-id><pub-id pub-id-type="pmid">29946897</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77945.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Forstmann</surname><given-names>Birte U</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.12.03.471134" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.03.471134"/></front-stub><body><p>This study presents a useful automated package called 'HippUnfold' in form of a BIDS App. The approach is solid and validated by comparing it against other methods in the field and has the potential to be used by a wide audience.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77945.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Forstmann</surname><given-names>Birte U</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Bazin</surname><given-names>Pierre-Louis</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.03.471134">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.12.03.471134v2">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;HippUnfold: Automated hippocampal unfolding, morphometry, and subfield segmentation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Floris de Lange as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Pierre-Louis Bazin (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>Overall, this manuscript is well written, interesting, timely and will help resolve the debate in the field. We have the following suggestions to improve the manuscript:</p><p>1. As far as I understood, the U-Net approach defines individual landmarks needed for the unfolding and the unfolding provides a unique mapping between folded and unfolded space. However, if I understood correctly, in the next step the same subfield labels are enforced on every unfolded surface in the same way. My biggest concern is how we can be sure that these labels are valid for everyone.</p><p>2. Adding to this point, I find it very difficult to see any hippocampal structure in the 3T T1 data, for example HCP-YA case in figure 6 (but also HCP-A case in Figure 5 A, even true for the T2 image in the HCP-A case). This might be due to the image in the PDF and look better in the actual scan. However, as a human rater I would have no idea how to segment these cases and am wondering how the author's make sure that their approach produces a valid result and does not rely on the respective priors too much.</p><p>3. While the authors have addressed this in part by comparing the automated segmentation labels with the manual labels in young adults, there is no such data for populations that deviate more from young and healthy adults. Thus, there remains the question how their approach would deal with data from such populations.</p><p>4. I understand that manual segmentations are very tedious and labor intensive and might not be feasible in this project. However, maybe the authors could apply their pipeline to a dataset of a patient case with well-known abnormality and investigate the result? Alternatively, although the literature is less clear here, the authors could report on the differences that they see between HCP-A and HCP-YA on a group level and relate this to other findings in ageing or maybe even already existing work on these specific cohorts (in case these exist).</p><p>5. First, I would like to congratulate the authors in building an elegant toolbox for hippocampal analysis, with many valuable features for the basic and advanced users alike. I expect the points I raised can be addressed by reframing the presentation of the software, focusing more on what it provides in terms of a representation and less on whether or not it provides a better subfields definition.</p><p>6. My first point above should be addressable by including all algorithmic details either in the main text or in an appendix, so the article is self-contained with regard to the methodology. Details of the UNet preprocessing and architecture, Laplacian coordinate mapping algorithm, and morphometric feature extraction should be included. The 'Hippunfold detailed pipeline' section remains vague: concrete descriptions including mathematical formulas and algorithm parameters would be better. A figure showing the outputs of the different steps would also be helpful.</p><p>7. The second point requires carefully re-evaluating the claims made about topology, and separating the unfolding and labeling question. In the end, the provided algorithm does not perform any subfield labeling of individual hippocampi, but only transfers a fixed label map from BigBrain onto individual anatomies, using the unfolding coordinates as a proxy. Thus the results of Figure 4 are misleading, since they compare the quality of the unfolding and not the labeling. This point should be made clear, and the comparisons of Figure 3 need to be altered, maybe discussing rather the limited variability of the unfolded labels from ASHS and FreeSurfer as an indication of the quality of the unfolded representation. If the authors want to compare the quality of subfield labelings across methods, those comparisons should be done in voxel space. Note also that the claim that ASHS and FreeSurfer do not preserve topology is unnecessary and debatable (e.g. internally the FreeSurfer algorithm uses a fixed-topology mesh, so it does preserve its own definition of topology).</p><p>8. Here I would rather have a comparison with other representations, e.g. using the volumetric space directly, mapping to the outer surface, or defining a medial axis representation. Why is mapping hippocampal information onto a 2D plane better? Does this preserve more the common features across hippocampi than other options? While this idea is hinted at when discussing variability in folding, it could be empirically tested.</p><p>9. This also links to the third question of implicit alignment which could be tested for instance by inspecting the variation in subfield boundaries from volumetric methods in the experiment of Figure 3. Note also that features mapped onto the unfolded representation of Figure 2 could be co-registered into a 2D atlas, and the corresponding deformations could be evaluated.</p><p>10. Another question related to representation is the decision to use a rectangular map rather than a more irregular one similar to those used in cortical and cerebellar flat maps: by doing so, some of the regions get a distorted importance (as shown in the mesh maps presented in the documentation). It would be good to provide a measure of the distortion to be expected.</p><p>11. Finally, while the software and documentation are very well organized, I was unable to run the app on the test data folders or my own data, using docker, singularity or the poetry installation option, which is absolutely required to complete this review. The 'getting started' section should also include a full processing script example on a test data set, outlining the main steps and basic parameters, especially as the toolbox is quite flexible and thus quite complex. Commands used for visualizing the various results should also be given in the 'Outputs' section, so users can visualize their data as in the examples. Given the richness of the manual delineation and segmentation effort, it would be valuable to release the training and testing data openly (note also that it is quite important for the U-Net step, where the training set properties have a strong impact on performance and potential biases).</p><p>12. In general, the paper is well written, but there are multiple areas that I have some issues with following the logical flow of what is being proposed. For example, the paper begins with demonstrating multiple metrics that are projected onto the hippocampal flatmap that includes thickness, myelin, curvature, gyrification, etc. It is unclear as to what information the authors want to convey here. This is the first mention of many of these multiple metrics as well and therefore their relevance is ultimately not extremely clear. As a result, it is hard to support their claim that &quot;differences in morphological and quantitative features can be seen across the hippocampus, particularly across the subfields&quot; as the goals of this particular figure are not at all clear.</p><p>13. Line 147: It is not totally accurate to state that ASHS makes use of multi-atlas registration as it also uses AdaBoost to correct for segmentation inaccuracies.</p><p>14. For the FreeSufer and ASHS comparisons – is it possible to provide some quantification of errors or anything like that? I think it would be helpful to quantify the differences in a more accurate manner. If this is in a previous publication and I missed it, it could be useful to reiterate here. The qualitative difference is nice – but there is room to compare them more quantitatively to one another.</p><p>15. For the validation of the U-NET, details on the manual segmentation protocol, who did it, and its reliability are crucial. Training/testing paradigms would be helpful here. So would Bland-Altmann plots. I think in general the validation of these segmentations is quite poor – so more metrics that demonstrate the segmentation beyond dice overlaps would be helpful.</p><p>16. It is unclear how generalizable the method is outside of HCP acquisitions.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>As far as I understood, the U-Net approach defines individual landmarks needed for the unfolding and the unfolding provides a unique mapping between folded and unfolded space. However, if I understood correctly, in the next step the same subfield labels are enforced on every unfolded surface in the same way. My biggest concern is how we can be sure that these labels are valid for everyone.</p><p>Adding to this point, I find it very difficult to see any hippocampal structure in the 3T T1 data, for example HCP-YA case in figure 6 (but also HCP-A case in Figure 5 A, even true for the T2 image in the HCP-A case). This might be due to the image in the PDF and look better in the actual scan. However, as a human rater I would have no idea how to segment these cases and am wondering how the author's make sure that their approach produces a valid result and does not rely on the respective priors too much.</p><p>While the authors have addressed this in part by comparing the automated segmentation labels with the manual labels in young adults, there is no such data for populations that deviate more from young and healthy adults. Thus, there remains the question how their approach would deal with data from such populations.</p><p>I understand that manual segmentations are very tedious and labor intensive and might not be feasible in this project. However, maybe the authors could apply their pipeline to a dataset of a patient case with well-known abnormality and investigate the result? Alternatively, although the literature is less clear here, the authors could report on the differences that they see between HCP-A and HCP-YA on a group level and relate this to other findings in ageing or maybe even already existing work on these specific cohorts (in case these exist).</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>First, I would like to congratulate the authors in building an elegant toolbox for hippocampal analysis, with many valuable features for the basic and advanced users alike. I expect the points I raised can be addressed by reframing the presentation of the software, focusing more on what it provides in terms of a representation and less on whether or not it provides a better subfields definition.</p><p>My first point above should be addressable by including all algorithmic details either in the main text or in appendix, so the article is self-contained with regard to the methodology. Details of the UNet preprocessing and architecture, Laplacian coordinate mapping algorithm, and morphometric feature extraction should be included. The 'Hippunfold detailled pipeline' section remains vague: concrete descriptions including mathematical formulas and algorithm parameters would be better. A figure showing the outputs of the different steps would also be helpful.</p><p>The second point requires carefully re-evaluating the claims made about topology, and separating the unfolding and labeling question. In the end, the provided algorithm does not perform any subfield labeling of individual hippocampi, but only transfers a fixed label map from BigBrain onto individual anatomies, using the unfolding coordinates as a proxy. Thus the results of Figure 4 are misleading, since they compare the quality of the unfolding and not the labeling. This point should be made clear, and the comparisons of Figure 3 need to be altered, maybe discussing rather the limited variability of the unfolded labels from ASHS and FreeSurfer as an indication of the quality of the unfolded representation. If the authors want to compare the quality of subfield labelings across methods, those comparisons should be done in voxel space. Note also that the claim that ASHS and FreeSurfer do not preserve topology is unnecessary and debatable (e.g. internally the FreeSurfer algorithm uses a fixed-topology mesh, so it does preserve its own definition of topology).</p><p>Here I would rather have a comparison with other representations, e.g. using the volumetric space directly, mapping to the outer surface, or defining a medial axis representation. Why is mapping hippocampal information onto a 2D plane better? Does this preserve more the common features across hippocampi than other options? While this idea is hinted at when discussing variability in folding, it could be empirically tested.</p><p>This also links to the third question of implicit alignment which could be tested for instance by inspecting the variation in subfield boundaries from volumetric methods in the experiment of Figure 3. Note also that features mapped onto the unfolded representation of Figure 2 could be co-registered into a 2D atlas, and the corresponding deformations could be evaluated.</p><p>Another question related to representation is the decision to use a rectangular map rather than a more irregular one similar to those used in cortical and cerebellar flat maps: by doing so, some of the regions get a distorted importance (as shown in the mesh maps presented in the documentation). It would be good to provide a measure of the distortion to be expected.</p><p>Finally, while the software and documentation are very well organized, I was unable to run the app on the test data folders or my own data, using docker, singularity or the poetry installation option, which is absolutely required to complete this review. The 'getting started' section should also include a full processing script example on a test data set, outlining the main steps and basic parameters, especially as the toolbox is quite flexible and thus quite complex. Commands used for visualizing the various results should also be given in the 'Outputs' section, so users can visualize their data as in the examples. Given the richness of the manual delineation and segmentation effort, it would be valuable to release the training and testing data openly (note also that it is quite important for the U-Net step, where the training set properties have a strong impact on performance and potential biases).</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>– Clear definition of goals and the novelty of the work.</p><p>– Better comparison against other methods.</p><p>– Better comparison against manual segmentation (needs more than just the Dice).</p><p>– Lack of demonstration of generalizability. Need to see how this may work in the context of other data acquisition streams.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Automated hippocampal unfolding for morphometry and subfield segmentation using HippUnfold&quot; for further consideration by eLife. Your revised article has been evaluated by Floris de Lange (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>1. The description of some of the central methods used in the article (Laplacian embedding, shape injection) is too limited to understand fully how we obtain the unfolding. I see the point of 'increased complexity with increasing depth', but the article does not reach the level where the algorithms are explicitly described. It is also unclear if the authors used third-party software or their own implementation of these two methods.</p><p>2. A second remaining issue I have is the somewhat puzzling fact that the T1w trained version of hippunfold performed better than the T2w one for the HCP-aging dataset: it would be good to understand why that is the case.</p><p>3. Finally, I still could not run the algorithm successfully on the provided example. Both Docker and Singularity provide very little information about why they fail. Installing and running the development version almost works, but only after installing several additional packages and non-standard research software from other groups (connectome workbench, NiftyReg, c3d...). None of these dependencies are described in the documentation. I would recommend the authors test their installation procedure on a bare-bones OS, for instance in a Linux virtual machine, as it is often challenging to remember what elements of a customized installation are being used or not. I am confident that the remaining issues are small, and that the usability of the software will be increased in the exercise.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I thank the authors for a thorough revision with additional validation experiments, which generally addresses my concerns and issues. I particularly appreciate the addition of the FreeSurfer and ASHS/Magdeburg labelings as options: it clarifies the separation between unfolding and labeling, and also provides continuity for users who have worked with these labels in previous studies. I also commend the authors for releasing their training data, increasing transparency, and for providing actual test data sets.</p><p>However, I would still argue that the description of some of the central methods used in the article (Laplacian embedding, shape injection) is too limited to understand fully how we obtain the unfolding. I see the point of 'increased complexity with increasing depth', but the article does not reach the level where the algorithms are explicitly described. It is also unclear if the authors used third-party software or their own implementation of these two methods.</p><p>A second remaining issue I have is the somewhat puzzling fact that the T1w trained version of hippunfold performed better than the T2w one for the HCP-aging dataset: it would be good to understand why that is the case.</p><p>Finally, while these two issues above are minor, I still could not run the algorithm successfully on the provided example. Both Docker and Singularity provide very little information about why they fail. Installing and running the development version almost works, but only after installing several additional packages and non-standard research software from other groups (connectome workbench, NiftyReg, c3d...). None of these dependencies are described in the documentation. I would recommend the authors to test their installation procedure on a bare-bones OS, for instance in a Linux virtual machine, as it is often challenging to remember what elements of a customized installation are being used or not. I am confident that the remaining issues are small, and that the usability of the software will be increased in the exercise.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77945.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Overall, this manuscript is well written, interesting, timely and will help resolve the debate in the field. We have the following suggestions to improve the manuscript:</p><p>1. As far as I understood, the U-Net approach defines individual landmarks needed for the unfolding and the unfolding provides a unique mapping between folded and unfolded space. However, if I understood correctly, in the next step the same subfield labels are enforced on every unfolded surface in the same way. My biggest concern is how we can be sure that these labels are valid for everyone.</p></disp-quote><p>Yes, the unfolding provides a unique mapping for each hippocampus between native (folded) and unfolded space, which allows an atlas defined in the unfolded space to be mapped to any hippocampus. There are a number of reasons, both conceptually and empirically why we believe this approach is a valid one:</p><p>a. The landmarks we use decompose the hippocampus along intrinsic anatomical axes of the hippocampus. The axis we define as proximal-distal (PD), which follows along the SLM in coronal slice, is also a landmark relied upon in many manual segmentation protocols for the hippocampal subfields. As one example, Steve et al. (2017) developed a histologically-validated protocol that defined subfield boundaries by the proportional distance along the SLM in a coronal slice through the body of the hippocampus. Our unfolding approach is conceptually analogous to this approach, since a vertical line through the unfolded space at a mid-body slice will similarly describe subfield boundaries as a proportional distance along the SLM. Protocols developed for segmenting the body of the hippocampus on MRI that are based on geometric heuristics can also be seen as analogous to our approach. For example, the proposed Hippocampal Subfield Group harmonized protocol (protocol still under community review, as yet unpublished), that defines boundaries based on angles relative to axes drawn on the hippocampus, is also conceptually using the proportional distance (or arc length) along the SLM if we assume a circular shape is used to model the SLM.</p><p>Steve TA, Yasuda CL, Coras R, Lail M, Blumcke I, Livy DJ, Malyhkin N, Gross DW. (2017) Development of a histologically validated segmentation protocol for the hippocampal body. NeuroImage, 157, 219-232.</p><p>b. The added strength of our approach over these analogous methods (applied in the body) is that we apply the same conceptual rule (proportional distance along the SLM) as a means to segment the head and tail as well. The head and tail are areas where the heuristics have conventionally been very difficult to apply, since the slice angulation optimal for the body is not optimal for the curved head and tail; in certain regions, a slice perpendicular to the body is the optimal one. This phenomenon has also been observed by others (Gross et al., 2020), and has even been used to more accurately apply the known heuristics to the more curved regions of the hippocampus anterior and posterior. We have added a new paragraph to the discussion to provide a succinct overview of these points.</p><p>Gross D, Misaghi E, Steve TA, Wilman AH, Beaulieu C. (2020) Curved multiplanar reformatting provides improved visualization of hippocampal anatomy. Hippocampus 30(2), 156-161.</p><p>c. Empirical validity of the unfolding approach could also be assessed by demonstrating that the same subfields defined independently on multiple subjects/hippocampi map to the same regions in the unfolded space. We have performed this validation in our initial paper that described our unfolding approach (Dekraker et al., 2018). Here, manually segmented subfields from multiple subjects were mapped consistently to the unfolded space, as demonstrated by 1) depiction of manual subfields from all individuals mapped to the unfolded space with the standard error in subfield boundaries visualized (Figure 5C), and 2) Dice scores using a leave-one-out approach to segment each subject with an average atlas of the other subjects (red/blue bars in Figure 5). Note that this method made use of our semi-automated tool for unfolding the hippocampus, and the codebase for our toolset has evolved considerably since. Thus, we have also included an updated analogous experiment with our current HippUnfold tool on a larger set of hippocampi, and manual segmentations from a completely independent rater and dataset. This is shown in Figure 4 – Supplement 1, specifically the panel in the top right that depicts the manual subfield boundaries of N=70 hippocampi (35 subjects) after being transformed to the unfolded space. Similar figures for subfields from existing automated methods (ASHS, Freesurfer) are also shown in Figure 4 of the manuscript. These all demonstrate that the boundaries between subfields have a high level of agreement, with much of the inter-subject variability accounted for in the unfolding.</p><p>DeKraker, Jordan, Kayla M. Ferko, Jonathan C. Lau, Stefan Köhler, and Ali R. Khan. &quot;Unfolding the hippocampus: An intrinsic coordinate system for subfield segmentations and quantitative mapping.&quot; <italic>Neuroimage</italic> 167 (2018): 408-418.</p><p>d. In our approach, the same atlas is mapped to every subject; we have used a manual segmentation from the BigBrain hippocampi since it was (and currently still is) the highest resolution 3D reference that exists for the hippocampus. However, it is still a single subject, and thus no anatomical variability is encoded in this labelling. We have now provided alternatives to this single-subject subfield atlas, generated by mapping many segmented individual hippocampi to the unfolded space to derive a probabilistic labelling of each subfield. Maximum-probability label maps of the Magdeburg atlas (35 subjects released as a 7T ASHS atlas) along with Freesurfer segmentations of the same subjects were generated using companion scripts in http://github.com/khanlab/hippunfold-create-atlas (main and freesurfer branches respectively). These are now available in the HippUnfold tool as command-line options. Note that although these atlases will provide labels that are generally consistent with ASHS and Freesurfer, they still could differ substantially since the gray-matter and SRLM segmentations are defined by our trained U-net. These atlases are as seen in Figure 4 of the manuscript.</p><p>e. Finally, as evident by the probabilistic nature of subfields mapped to the unfolded spaces, we are aware that there is still some residual variability that our unfolding does not account for. One could potentially to account for this remaining variability by performing a subsequent non-linear registration in the unfolded space. However, implementation of this, including the optimal features to drive this registration and how much to regularize are choices that need to be further explored in future work. We have added a new paragraph in the Discussion section detailing this possibility.</p><disp-quote content-type="editor-comment"><p>2. Adding to this point, I find it very difficult to see any hippocampal structure in the 3T T1 data, for example HCP-YA case in figure 6 (but also HCP-A case in Figure 5 A, even true for the T2 image in the HCP-A case). This might be due to the image in the PDF and look better in the actual scan. However, as a human rater I would have no idea how to segment these cases and am wondering how the author's make sure that their approach produces a valid result and does not rely on the respective priors too much.</p></disp-quote><p>We have added Figure 3 to more clearly show the visible internal hippocampal structures like the SRLM and digitations. Note that the out-of-plane issue discussed above is a major reason these scans are difficult to interpret, and is not an issue for U-Net automated segmentation.</p><p>Note also that one advantage that U-Net has over a human rater is that it makes use of fully 3D convolutional layers, meaning that it is sensitive to multiple slices and slice directions in concert. The advantage of this can be seen when interactively scrolling through volumes, but is hard to capture in a static image. For example, digitations in the hippocampal head are often only clear in the coronal plane, while digitations in the body and tail of the hippocampus are often only evident in the sagittal plane. The same is true of the SRLM, which enters into the ‘crease’ of each digitation, making it hard to see in some ‘out-of-plane’ slices at any resolution (but especially at lower resolutions). We discuss some of these issues in our recent Opinion paper (DeKraker et al., 2021), but wanted to avoid these more technical discussions in the present manuscript.</p><p>It is also true that U-Net relies on a prior distribution in the absence of clear image features, and indeed, this can produce overly smooth hippocampal segmentations when definitive digitations are not visible. This is certainly a limitation and is discussed at length (Discussion section). We feel the current HippUnfold behaviour of relying on priors in the absence of detailed image features, and flagging subjects that show possible catastrophic failures, is desirable in most large-scale neuroimaging applications.</p><disp-quote content-type="editor-comment"><p>3. While the authors have addressed this in part by comparing the automated segmentation labels with the manual labels in young adults, there is no such data for populations that deviate more from young and healthy adults. Thus, there remains the question how their approach would deal with data from such populations.</p></disp-quote><p>We have now included additional analyses and visual examples from a convenience sample of 100 subjects from the HCP-aging dataset, with ages that range from 37 to 87 years of age, comparing subfield segmentations and volumes using HippUnfold against Freesurfer and ASHS (Figure 3). The HCP-aging dataset MRI protocol includes a high-resolution hippocampal T2 TSE sequence, and since this sequence depicts coronal slices of the hippocampus in greatest detail, we used these images as inputs to Freesurfer and ASHS. For HippUnfold we used the T1w image and corresponding T1w trained model since it provides the most robust outputs, but we have registered the outputs to the T2 TSE space for visual comparison against the other approaches. The comparisons of subfield volume demonstrate a generally high level of agreement across methods, and similar age-related declines in volume. Note that since the subfield boundary definitions differ across segmentation methods, absolute agreement was not expected. The visual comparisons between volumetric segmentations (e.g. a single subject shown in Figure 3), demonstrates anatomical accuracy of the proposed approach. Comparisons for all 100 subjects are shown in Figure 3 and Figure 3 – Supplement 1, and qualitatively demonstrates the robustness of the T1w HippUnfold model.</p><disp-quote content-type="editor-comment"><p>4. I understand that manual segmentations are very tedious and labor intensive and might not be feasible in this project. However, maybe the authors could apply their pipeline to a dataset of a patient case with well-known abnormality and investigate the result?</p></disp-quote><p>We have now added results on an epilepsy patient case as an example where the hippocampal pathology is well-characterized. A 37 year-old female right-handed patient was investigated for surgical treatment of temporal lobe epilepsy, and clinical MR imaging at 1.5T revealed a FLAIR hyper-intensity and volume loss in the right hippocampus consistent with a radiological diagnosis of mesial temporal sclerosis. The patient was imaged pre-surgically for a 7 Tesla MRI research study, and the 0.7mm MP2RAGE T1w (UNI-DEN) image was segmented using HippUnfold. Figure 6B demonstrates a unilateral volumetric reduction in all subfields except for CA2, characteristic of classical mesial temporal sclerosis. The patient underwent a right anterior temporal lobectomy and has been seizure-free (Engel class 1) for 4 years.</p><disp-quote content-type="editor-comment"><p>Alternatively, although the literature is less clear here, the authors could report on the differences that they see between HCP-A and HCP-YA on a group level and relate this to other findings in ageing or maybe even already existing work on these specific cohorts (in case these exist).</p></disp-quote><p>We have been investigating lifespan changes in hippocampal structure and function in separate ongoing work (see the OHBM abstract listed below), using HippUnfold to examine morphological differences from the Aging and Development HCP datasets. Indeed, early results showed thinning and reduced surface areas in older adults, which was presented at OHBM 2022. As detailed in response 3 above, we have also now added a comparison of 100 HCP-A subjects with extant Freesurfer and ASHS methods as well.</p><p><bold>“</bold>Unfolding the human hippocampal lifespan: changes in morphology and functional connectivity” at: Annual Meeting of the Organization of Human Brain Mapping, Glasgow, UK, 2022 (international)</p><disp-quote content-type="editor-comment"><p>5. First, I would like to congratulate the authors in building an elegant toolbox for hippocampal analysis, with many valuable features for the basic and advanced users alike. I expect the points I raised can be addressed by reframing the presentation of the software, focusing more on what it provides in terms of a representation and less on whether or not it provides a better subfields definition.</p><p>6. My first point above should be addressable by including all algorithmic details either in the main text or in an appendix, so the article is self-contained with regard to the methodology. Details of the UNet preprocessing and architecture, Laplacian coordinate mapping algorithm, and morphometric feature extraction should be included. The 'Hippunfold detailed pipeline' section remains vague: concrete descriptions including mathematical formulas and algorithm parameters would be better. A figure showing the outputs of the different steps would also be helpful.</p></disp-quote><p>Thank you, we have now included additional information, especially in the “detailed pipeline” section. We would like to note that the project generally aimed to the follow the principle of increased complexity with increased depth: the main body of the text should be intuitively comprehensible for a broad audience, the detailed pipeline for people familiar with image segmentation, registration, and surface mapping methods, and the online documentation should fully describe all possible parameter choices. Note that we reuse many existing tools for segmentation (eg. UNet) and registration (eg. ANTs, wb_command) which are described in other, referenced works. The Laplace coordinate system is a very unique component, and we have published another paper where we fully describe and utilize this method with manual segmentation (DeKraker et al., 2018; updates in 2019). We have now included some additional descriptions from these papers here, as well as generally adding more descriptions throughout.</p><disp-quote content-type="editor-comment"><p>7. The second point requires carefully re-evaluating the claims made about topology, and separating the unfolding and labeling question. In the end, the provided algorithm does not perform any subfield labeling of individual hippocampi, but only transfers a fixed label map from BigBrain onto individual anatomies, using the unfolding coordinates as a proxy.</p></disp-quote><p>Yes, and we refer to Response 1 for evidence of why we believe this approach is a valid one, both conceptually and empirically.</p><disp-quote content-type="editor-comment"><p>Thus the results of Figure 4 are misleading, since they compare the quality of the unfolding and not the labeling. This point should be made clear, and the comparisons of Figure 3 need to be altered, maybe discussing rather the limited variability of the unfolded labels from ASHS and FreeSurfer as an indication of the quality of the unfolded representation. If the authors want to compare the quality of subfield labelings across methods, those comparisons should be done in voxel space.</p></disp-quote><p>You are right that Figure 3 and 4 depend on the quality of unfolding, and this quality is perhaps the most critical component of the work shown here. The only available reference or gold standard to which we can compare unfolding quality is using manually defined hippocampal gray matter and surrounding labels, which was our comparison for the Dice scores in Figure 5. Note that these comparisons were all made in native space on a voxel wise basis. If we include only gray matter without parcellating it into subfields, Dice scores were &gt;0.95 since this tissue is large and Dice scores depend on the sizes of the regions being compared. We thus calculated Dice scores on the subfield level in order to determine how small differences in gray matter parcellation propagate through the unfolding, subfield definition, and re-folding. Calculating Dice scores of the individual subfields also makes this evaluation more comparable to other methods used in the literature.</p><p>We have also now added a comparison of HippUnfold, ASHS, and FS subfield pipelines in Figure 3 and Figure 3 – Supplement 1, but this analysis reveals only that these methods differ, and not which method shows best correspondence to ground truth histology observations.</p><p>We have now also included some discussion of variability of subfield boundaries in unfolded space. We acknowledge this is a limitation, though it is not unique to surface-based parcellation in the hippocampus but rather is also an issue in surface-based neocortical parcellation.</p><disp-quote content-type="editor-comment"><p>Note also that the claim that ASHS and FreeSurfer do not preserve topology is unnecessary and debatable (e.g. internally the FreeSurfer algorithm uses a fixed-topology mesh, so it does preserve its own definition of topology).</p></disp-quote><p>You are right that Freesurfer preserves its own intrinsic topology, however, it does not have the topological ordering of subfields which has been shown consistently in histology (eg. CA1 should never directly border CA3; all subfields should be present through the full longitudinal extent of the hippocampus). Additionally, histology and other work reveals that the underlying tissue of the hippocampus is folded but Freesurfer labels often stretch or compress multiple folds/digitations together which, when ideally unfolded, leads to discontinuities on both the subject and the average level (Figure 4). The same is true of ASHS, though to a lesser extent and not in the average as unfolded via HippUnfold. We have clarified this sense in which we use the term ‘topology’ in text to avoid confusion.</p><disp-quote content-type="editor-comment"><p>8. Here I would rather have a comparison with other representations, e.g. using the volumetric space directly, mapping to the outer surface, or defining a medial axis representation. Why is mapping hippocampal information onto a 2D plane better? Does this preserve more the common features across hippocampi than other options? While this idea is hinted at when discussing variability in folding, it could be empirically tested.</p></disp-quote><p>Although this is an interesting suggestion, we believe that a comprehensive comparison of representations would be outside of the scope of this work. The conceptual advantages are mainly gained through the use of hippocampal-centric coordinates, defined by hippocampal anatomical landmarks, and not necessarily in their projection to a 2D plane. A review of the conceptual advantages to the unfolding approach is described in Response 1, and these relate mainly to inter-subject alignment and subfield segmentation. The sensitivity and specificity of morphometric analyses using different hippocampal representations would require further study to evaluate what differences may exist.</p><disp-quote content-type="editor-comment"><p>9. This also links to the third question of implicit alignment which could be tested for instance by inspecting the variation in subfield boundaries from volumetric methods in the experiment of Figure 3. Note also that features mapped onto the unfolded representation of Figure 2 could be co-registered into a 2D atlas, and the corresponding deformations could be evaluated.</p></disp-quote><p>Yes, a deformation-based morphometry approach applied in the 2D atlas space would provide quantitative estimates of how much subfield variation is accounting for via unfolding/alignment. This analysis, however, is less anatomically-meaningful when the subfield boundaries are defined based on manual segmentation heuristics, rather than the underlying ground-truth anatomy. We have added a Discussion section on this issue.</p><disp-quote content-type="editor-comment"><p>10. Another question related to representation is the decision to use a rectangular map rather than a more irregular one similar to those used in cortical and cerebellar flat maps: by doing so, some of the regions get a distorted importance (as shown in the mesh maps presented in the documentation). It would be good to provide a measure of the distortion to be expected.</p></disp-quote><p>Thank you for this point, it is indeed something we have considered at multiple stages. A representation that minimizes distortion is often more difficult to orient (e.g. by labeling axes). The choice to stick to a rectangle was thus made to improve readability and for aesthetic purposes. We have now additionally provided a map (in mm<sup>2</sup>) of the average distortion between folded and unfolded space in Figure 2 – Supplement 1.</p><disp-quote content-type="editor-comment"><p>11. Finally, while the software and documentation are very well organized, I was unable to run the app on the test data folders or my own data, using docker, singularity or the poetry installation option, which is absolutely required to complete this review. The 'getting started' section should also include a full processing script example on a test data set, outlining the main steps and basic parameters, especially as the toolbox is quite flexible and thus quite complex. Commands used for visualizing the various results should also be given in the 'Outputs' section, so users can visualize their data as in the examples. Given the richness of the manual delineation and segmentation effort, it would be valuable to release the training and testing data openly (note also that it is quite important for the U-Net step, where the training set properties have a strong impact on performance and potential biases).</p></disp-quote><p>We are surprised and disappointed the software did not work out-of-the-box, and we agree that it should be fully functional before publication. We have continued to improve the documentation as several collaborating labs have begun taking up this tool. Thus, we have found some common installation pitfalls and made improvements to the documentation accordingly, including a complete test-case example. We have now also provided additional pages on how to easily visualize these outputs in the online documentation.</p><p>We have now made the training dataset available online at https://zenodo.org/record/7007362.</p><disp-quote content-type="editor-comment"><p>12. In general, the paper is well written, but there are multiple areas that I have some issues with following the logical flow of what is being proposed. For example, the paper begins with demonstrating multiple metrics that are projected onto the hippocampal flatmap that includes thickness, myelin, curvature, gyrification, etc. It is unclear as to what information the authors want to convey here. This is the first mention of many of these multiple metrics as well and therefore their relevance is ultimately not extremely clear. As a result, it is hard to support their claim that &quot;differences in morphological and quantitative features can be seen across the hippocampus, particularly across the subfields&quot; as the goals of this particular figure are not at all clear.</p></disp-quote><p>Thank you for this comment, we have made some edits to try and improve the clarity and flow around Figure 2. It was our intention to show what we hope will become an increasingly standard view of the hippocampus, similar to how the neocortex is often represented in a semi-inflated surface view from the medial and lateral aspects. We felt that the differences seen in these quantitative measures is exciting as it aligns nicely to expected subfield borders with a clarity that is not often seen in hippocampal subfield imaging (for example some studies have observed subtle differences between predefined ROIs but it is rare to be able to differentiate, for example, CA1 from CA2 on the basis of thickness alone). We thus hoped to show off the types and clarity of information that could be gathered with HippUnfold.</p><disp-quote content-type="editor-comment"><p>13. Line 147: It is not totally accurate to state that ASHS makes use of multi-atlas registration as it also uses AdaBoost to correct for segmentation inaccuracies.</p></disp-quote><p>We have corrected this.</p><disp-quote content-type="editor-comment"><p>14. For the FreeSufer and ASHS comparisons – is it possible to provide some quantification of errors or anything like that? I think it would be helpful to quantify the differences in a more accurate manner. If this is in a previous publication and I missed it, it could be useful to reiterate here. The qualitative difference is nice – but there is room to compare them more quantitatively to one another.</p></disp-quote><p>As described in Response 3, we have now added more comparisons against Freesurfer and ASHS in a subset of 100 HCP Aging subjects, specifically examining subfield volume agreement, and trends with respect to aging (Figure 3). We also provide additional quantitative and qualitative visual comparisons for all subjects in Figure 3 – Supplement 1.</p><p>A more granular quantitative comparison, such as Dice scoresis somewhat challenging to do in detail since FS and ASHS both differ in the labels and the ways in which they simplify hippocampal subfields to suit the precision afforded by MRI. None of the three methods compared here can be validated against a ground truth subfield segmentation from the datasets examined here, which would require histological data. Thus, it's hard to say definitively what is an error or a simplification. Indeed, most MRI segmentation protocols rely on qualitative descriptions from histological work rather than quantitative information.</p><disp-quote content-type="editor-comment"><p>15. For the validation of the U-NET, details on the manual segmentation protocol, who did it, and its reliability are crucial. Training/testing paradigms would be helpful here. So would Bland-Altmann plots. I think in general the validation of these segmentations is quite poor – so more metrics that demonstrate the segmentation beyond dice overlaps would be helpful.</p></disp-quote><p>We have included additional rater details, as well as details about the protocol used. Validation of this protocol was performed in a separate paper (DeKraker et al., 2018), and we would like to note that the current paper is not a manual segmentation protocol but rather relies on this previously published work. Briefly, DeKraker et al. (2018) showed high intra- and inter-rater agreement, showed many qualitative features seen in histological reference materials, and included one same-subject MRI and histological validation from a temporal lobe epilepsy patient.</p><p>Training and testing protocols are described in the Materials and methods section “nnUNet training”, which has now been updated with additional details.</p><p>Bland-Altman plots comparing HippUnfold results to extant Freesurfer and ASHS methods are provided in Figure 3 and Figure 3 – Supplement 1.</p><p>With very high throughput segmentation, some manual errors are a certainty. By sticking to a fixed protocol we tried to avoid rater ‘drift’ towards a systematic bias, and in general we were pleased that UNet training appeared to generalize well across training samples. With successive iterations of training, we were able to identify and remove some common errors that may have stemmed from several low quality segmentations in the first training batch, but it is difficult to quantify this given the subjective nature of manual inspection and segmentation.</p><p>We have now made the training dataset available online at https://zenodo.org/record/7007362.</p><p>We encourage anybody who is interested to provide feedback or additional data that could be used as training data, which we see as an invaluable resource.</p><disp-quote content-type="editor-comment"><p>16. It is unclear how generalizable the method is outside of HCP acquisitions.</p></disp-quote><p>We included one non-HCP dataset (TSE-7T, n=70 L+R), on which automated QC showed good performance on nearly all subjects (see Automated error flagging sections). In addition, we have now included one temporal lobe epilepsy patient case.</p><p>We would also like to note that since the time of our initial submission, performance on other datasets and in different labs appears to be equally good. For example, see:</p><p>“Automated characterisation and lateralisation of hippocampal sclerosis from MRI in children with epilepsy” (first author Mathilde Ripart) at: Annual Meeting of the Organization of Human Brain Mapping, Glasgow, UK, 2022 [Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>1. The description of some of the central methods used in the article (Laplacian embedding, shape injection) is too limited to understand fully how we obtain the unfolding. I see the point of 'increased complexity with increasing depth', but the article does not reach the level where the algorithms are explicitly described. It is also unclear if the authors used third-party software or their own implementation of these two methods.</p></disp-quote><p>We have decided to address this in two ways: we now include a new detailed Supplementary file detailing the algorithms used, AND we have added to the main text an intuitive explanation for how and why Laplace coordinates are used (“HippUnfold detailed pipeline” Materials and methods section). The latter was not requested by the Reviewer per se, but we have found it alleviates a lot of confusion about this issue.</p><p>“Intuition:</p><p>Imagine we have a tangled piece of wire. We attach one end to something hot (100OC) and the other to something cold (0OC), and then wait for the temperature to equilibrate along the entire wire. We then have a second wire that is tangled up in a different pattern (and possibly with a different length). We attach the same hot and cold endpoints, and wait for it to equilibrate as well. Then, when we want to find topologically homologous points between the two wires, we find the spot where they have the same temperature, say 10OC (or 10% its length), or the same for any other pair of homologous points. This explanation works since the heat equation describing the equilibrium temperatures is the same as the Laplace equation if we assume that the heat conductance (or thermal diffusivity) is constant. These wires make up a 1D example, but the same principle also applies to a folded 2D sheet, where the endpoints are edges rather than ends. Here we apply endpoints in two perpendicular directions: anterior-posterior (or HATA to ind.gris.) and proximal-distal (Sub to DG), making up a standardized 2D indexing system (or 'unfolded space').”</p><disp-quote content-type="editor-comment"><p>2. A second remaining issue I have is the somewhat puzzling fact that the T1w trained version of hippunfold performed better than the T2w one for the HCP-aging dataset: it would be good to understand why that is the case.</p></disp-quote><p>Please note that 1) T2w is actually more accurate with SRLM and GM segmentation (based on Dice shown in Figure 5), 2) the failure rate is higher for T2w but this is often related to image artifacts, failures in linear registration, or U-Net failures, 3) the context from surrounding tissue in the T1w images may be beneficial for avoiding U-Net failures.</p><p>We have added the following to the “Automated error flagging” Results section:</p><p>“It is interesting to note that fewer failures were observed in HippUnfold using T1w data compared to T2w data (Figure 7), even though performance of nnUNet tissue classification were slightly higher with T2w images (Figure 5) and these are more common in hippocampal subfield imaging literature. Examining some failed cases, we see that these often had poor image quality or artifacts, with subsequent issues like linear misregistration to the common CITI168 atlas or catastrophic nnUNet tissue classification failures.”</p><disp-quote content-type="editor-comment"><p>3. Finally, I still could not run the algorithm successfully on the provided example. Both Docker and Singularity provide very little information about why they fail. Installing and running the development version almost works, but only after installing several additional packages and non-standard research software from other groups (connectome workbench, NiftyReg, c3d…). None of these dependencies are described in the documentation. I would recommend the authors test their installation procedure on a bare-bones OS, for instance in a Linux virtual machine, as it is often challenging to remember what elements of a customized installation are being used or not. I am confident that the remaining issues are small, and that the usability of the software will be increased in the exercise.</p></disp-quote><p>The many different ways the app can be run were initially intended as features for flexibility, but we admit that it may also be a source of confusion. We have now tested HippUnfold on a fresh Linux (Singularity), Windows (Docker), and Linux Virtual Machine (Vagrant) environments. In all cases the pipeline works without software dependency issues since all required dependencies are in the HippUnfold container, but challenges may be faced when binding paths to the container, thus we have revised the “Getting Started” sections for each set-up with more specific details, including screencasts for the Virtual Machine option as well. Another issue often encountered is that pulling the singularity container may fail (since it can require a large amount of disk space and memory). As an alternative, we now also provide the latest release as a DropBox download. We have also added an additional “FAQ” section for issues that other collaborators have encountered in the past.</p><p>We are glad to hear the “pip install” worked, albeit with issues. The HippUnfold container (e.g. at Docker URI khanlab/hippunfold:v1.2.0) with all dependencies included, is the recommended method for end-users, but if the app is installed with pip, then the command-line run *must* include the `--use-singularity` flag, which will enable the workflow to download the dependency containers as needed for each rule in the workflow. The “Contributing to HippUnfold” documentation has now been updated to make this instruction more explicit. This setup executes the code in the same environment as the “pip installation” but with Snakemake handling these additional dependencies via Singularity. This setup is more complex, but works well when modifying the HippUnfold code while holding dependencies fixed, which is why we recommend standard users follow the Docker/Singularity instructions whereas advanced users wishing to further customize the code use “pip install”, or “poetry install”.</p></body></sub-article></article>