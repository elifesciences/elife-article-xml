<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">77262</article-id><article-id pub-id-type="doi">10.7554/eLife.77262</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Short Report</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Self-organization of songbird neural sequences during social isolation</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-281603"><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6593-4398</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-270676"><name><surname>Gu</surname><given-names>Shijie</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6257-5756</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-10225"><name><surname>Denisenko</surname><given-names>Natalia I</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-10226"><name><surname>Fee</surname><given-names>Michale S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7539-1745</contrib-id><email>fee@mit.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/042nb2s44</institution-id><institution>McGovern Institute for Brain Research, Department of Brain and Cognitive Sciences, MIT</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Goldberg</surname><given-names>Jesse H</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05bnh6r87</institution-id><institution>Cornell University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>30</day><month>05</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e77262</elocation-id><history><date date-type="received" iso-8601-date="2022-01-21"><day>21</day><month>01</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-04-19"><day>19</day><month>04</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-02-18"><day>18</day><month>02</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.02.18.480996"/></event></pub-history><permissions><copyright-statement>© 2023, Mackevicius et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Mackevicius et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-77262-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-77262-figures-v1.pdf"/><abstract><p>Behaviors emerge via a combination of experience and innate predispositions. As the brain matures, it undergoes major changes in cellular, network, and functional properties that can be due to sensory experience as well as developmental processes. In normal birdsong learning, neural sequences emerge to control song syllables learned from a tutor. Here, we disambiguate the role of tutor experience and development in neural sequence formation by delaying exposure to a tutor. Using functional calcium imaging, we observe neural sequences in the absence of tutoring, demonstrating that tutor experience is not necessary for the formation of sequences. However, after exposure to a tutor, pre-existing sequences can become tightly associated with new song syllables. Since we delayed tutoring, only half our birds learned new syllables following tutor exposure. The birds that failed to learn were the birds in which pre-tutoring neural sequences were most ‘crystallized,’ that is, already tightly associated with their (untutored) song.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>zebra finch</kwd><kwd>neural sequences</kwd><kwd>calcium imaging</kwd><kwd>vocal learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 DC009183</award-id><principal-award-recipient><name><surname>Gu</surname><given-names>Shijie</given-names></name><name><surname>Denisenko</surname><given-names>Natalia I</given-names></name><name><surname>Fee</surname><given-names>Michale S</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>Simons Collaboration for the Global Brain</award-id><principal-award-recipient><name><surname>Gu</surname><given-names>Shijie</given-names></name><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name><name><surname>Fee</surname><given-names>Michale S</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011671</institution-id><institution>G. Harold and Leila Y. Mathers Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Gu</surname><given-names>Shijie</given-names></name><name><surname>Denisenko</surname><given-names>Natalia I</given-names></name><name><surname>Fee</surname><given-names>Michale S</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000005</institution-id><institution>Department of Defense</institution></institution-wrap></funding-source><award-id>National Defense Science and Engineering Graduate Fellowship</award-id><principal-award-recipient><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>Society of Fellows</award-id><principal-award-recipient><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000324</institution-id><institution>Gatsby Charitable Foundation</institution></institution-wrap></funding-source><award-id>GAT3708</award-id><principal-award-recipient><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>In juvenile songbirds, neural sequences pre-exist tutor exposure, and the process of learning a new song may make use of existing neural sequences as a stable substrate for new behavioral changes.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>On the one hand, sensory experience is known to be essential for the normal development of brain circuits. On the other hand, genetically specified developmental processes are also essential – we learn too quickly and from too sparse data to rely on sensory experience alone (<xref ref-type="bibr" rid="bib8">Chomsky et al., 2002</xref>). Thus, it appears that the brain is able to use genetically specified predispositions to fill in gaps in its sensory experience. When typical sensory experience is absent or delayed, certain aspects of brain development proceed anyway, while other aspects are delayed. This is true both in primary sensory systems (<xref ref-type="bibr" rid="bib60">Wiesel and Hubel, 1963</xref>; <xref ref-type="bibr" rid="bib3">Bear and Singer, 1986</xref>; <xref ref-type="bibr" rid="bib14">Farley et al., 2007</xref>; <xref ref-type="bibr" rid="bib62">Ye et al., 2021</xref>), and for more cognitive behaviors such as social interaction and language (<xref ref-type="bibr" rid="bib27">Hildyard and Wolfe, 2002</xref>; <xref ref-type="bibr" rid="bib47">Moreno-Torres et al., 2016</xref>; <xref ref-type="bibr" rid="bib31">Kral et al., 2019</xref>). Brain circuits acquire structure and organization even in the absence of typical training inputs. Here, we examine this self-organized structure, and what happens when the sensory experience of a conspecific tutor is reintroduced, in the context of songbird vocal learning.</p><p>Song learning is influenced by both auditory exposure to a particular tutor song, and by inherited preferences (<xref ref-type="bibr" rid="bib57">Tchernichovski and Marcus, 2014</xref>). It is well known that songbirds, in the absence of exposure to a tutor bird, develop ‘isolate’ songs, with highly variable and atypical syllable rhythms (<xref ref-type="bibr" rid="bib52">Price, 1979</xref>; <xref ref-type="bibr" rid="bib61">Williams et al., 1993</xref>; <xref ref-type="bibr" rid="bib17">Fehér et al., 2009</xref>). However, when these ‘isolate’ songs are used as tutor songs, after two generations birds sing normally again, suggesting that an ‘innate’ preference filters what aspects of a tutor song are actually imitated (<xref ref-type="bibr" rid="bib17">Fehér et al., 2009</xref>). Song imitation requires remarkably little total exposure to a tutor song – approximately 75 s total on a single day is enough for a bird to remember a song, and subsequently practice and imitate it (<xref ref-type="bibr" rid="bib10">Deshpande et al., 2014</xref>). Zebra finches, like many songbird species, are able to imitate songs of birds from other species, but when given a choice they prefer zebra finch songs (<xref ref-type="bibr" rid="bib13">Eales, 1987</xref>). Furthermore, inherited genetic predispositions have a strong effect on both the precise tempo at which a zebra finch sings its song (<xref ref-type="bibr" rid="bib44">Mets and Brainard, 2018</xref>), as well as the particular learning styles of individual birds (<xref ref-type="bibr" rid="bib45">Mets and Brainard, 2019</xref>). Thus, within the songbird brain, we expect to see an interplay between developmentally specified and learned structure.</p><p>There are several possibilities for what happens in the brain during isolate song, and how it compares to typical (tutored) brain development. In typical birds, neurons in HVC are initially only weakly coupled to a song, firing only at the onsets of syllables when birds are babbling subsong (<xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>), and HVC is not necessary for subsong production (<xref ref-type="bibr" rid="bib2">Aronov et al., 2008</xref>). Then, as the song becomes more mature and repeatable, each HVC projection neuron fires at its own precise moment during the song, with neurons firing one after the other, together forming a stable sequence of neural firing that tiles the song (<xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>; <xref ref-type="bibr" rid="bib37">Lynch et al., 2016</xref>; <xref ref-type="bibr" rid="bib51">Picardo et al., 2016</xref>), in interplay with inhibitory neurons (<xref ref-type="bibr" rid="bib30">Kosche et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Vallentin et al., 2016</xref>). This maturation process in HVC has been modeled as an initially random network of neurons that, with the right training inputs and plasticity rules, assembles into a chain of sequentially connected neurons (<xref ref-type="bibr" rid="bib6">Buonomano, 2005</xref>; <xref ref-type="bibr" rid="bib29">Jun and Jin, 2007</xref>; <xref ref-type="bibr" rid="bib19">Fiete et al., 2010</xref>; <xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>; <xref ref-type="fig" rid="fig1">Figure 1A</xref>). However, what happens in birds isolated from a tutor? Compared to typical adult zebra finch songs, isolate song has a much less stable sequence of syllables and abnormally variable acoustic structure and timing (<xref ref-type="bibr" rid="bib17">Fehér et al., 2009</xref>). In fact, aspects of isolate songs resemble features of early babbling (subsong). Does HVC in isolate birds resemble that of subsong birds? Or does HVC mature to form sequences, even without the experience of a tutor, and without the behavioral stereotypy seen in adult birds? We use functional calcium imaging in singing isolated birds to address these questions.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Sequences in isolated birds.</title><p>(<bold>A</bold>) Diagram of HVC maturation. In typically tutored birds, HVC sequences appear to grow and differentiate over time. (<bold>B</bold>) Example neural sequences recorded in a singing isolated bird (older juvenile, 61 dph). Main panel (lower right), functional calcium imaging recordings from 98 neurons. Rows (neurons) are sorted according to sequences (factors) extracted by unsupervised algorithm seqNMF (see Methods). (Above) Song spectrogram (0–10kHz). The four sequence factor exemplars and timecourses are shown to the left and above, in corresponding colors. Duration of factor exemplars: 0.5s. (<bold>C</bold>) Same as B, for another example isolated bird (adult, 117 dph). (<bold>D</bold>) Same as in B, for a typically tutored bird (adult, 217 dph). (<bold>E</bold>) Time-lagged cross-correlation between each neuron and each of the three extracted factors recorded in a singing isolated bird (older juvenile, 68 dph). Only significant bins in the cross correlation are shown (p&lt;0.05, Bonferroni corrected, compared to a circularly-shifted control). (<bold>F, G, J, K</bold>) Sequence properties in isolated birds. For reference, the median for a typically tutored bird in D is shown by a red triangle, and the median for a control dataset where each row was circularly shifted by a random amount is shown by a red line. (<bold>F</bold>) Percent of neurons participating in at least one extracted sequence. (<bold>G</bold>) Reliability of participating neurons across sequence renditions. Note that in the control dataset, relatively few neurons participate. (<bold>H</bold>) Example song spectrograms (0.5s) extracted at moments when neural sequences were detected in an isolated bird (older juvenile, 64 dph) (<bold>I</bold>) Correlation of these sequences with eight song features (top to bottom: amplitude, entropy, pitch goodness, aperiodicity, mean frequency, pitch, frequency modulation, amplitude modulation). (<bold>J</bold>) Strength of song locking (see Methods). (<bold>K</bold>) Percent of the song covered by some sequence. (<bold>L</bold>) Example of sequence abnormalities in an isolated bird (same as in E). Sequences of inconsistent length (8/8 isolated birds) and ensemble persistent activity (7/8 isolated birds) are annotated in red.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>HVC sequences exist even in young isolated birds.</title><p>(<bold>A</bold>) Example HVC sequences recorded in a young isolated bird (59 dph) (<bold>B–F</bold>) Sequence properties as a function of age in seven juvenile isolated birds (five birds recorded prior to the closing of the traditional critical period (&lt;65dph), and two older juvenile birds (65 dph-90 dph)). Line denotes least squares fit, gray area 95% confidence interval. (<bold>B</bold>) Number of HVC sequences extracted. (<bold>C</bold>) Percent of neurons participating in at least one sequence. (<bold>D</bold>) Reliability of neural participation across sequence renditions. (<bold>E</bold>) Song locking. (<bold>F</bold>) Percent of the song covered by at least one sequence.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Estimating the number of significant sequences in each dataset.</title><p>(<bold>A</bold>) Reconstruction cost (red) and correlation cost (blue) as a function of <inline-formula><mml:math id="inf1"><mml:mi>λ</mml:mi></mml:math></inline-formula> (with K=10, L=0.5s) for eight datasets (pre-tutoring data from eight different birds). The crossover point, <inline-formula><mml:math id="inf2"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, is stated and marked by a dashed line. (<bold>B</bold>) Histogram of the number of significant sequences at <inline-formula><mml:math id="inf3"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf4"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> for these datasets. (<bold>C</bold>) For the chosen K, and <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, consistency across 25 runs of seqNMF from different random initializations. Factorizations are sorted from most to least consistent. (<bold>D</bold>) Consistency matrix for 25 runs at K above the estimated K.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Enlarged data, bird 6961.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp3-v1.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 4.</label><caption><title>Enlarged data, bird 6991.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp4-v1.tif"/></fig><fig id="fig1s5" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 5.</label><caption><title>Enlarged data, bird 7030.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp5-v1.tif"/></fig><fig id="fig1s6" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 6.</label><caption><title>Enlarged data, bird 7187.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp6-v1.tif"/></fig><fig id="fig1s7" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 7.</label><caption><title>Enlarged data, bird 6938.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp7-v1.tif"/></fig><fig id="fig1s8" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 8.</label><caption><title>Enlarged data, bird 6992.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp8-v1.tif"/></fig><fig id="fig1s9" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 9.</label><caption><title>Enlarged data, bird 6962.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp9-v1.tif"/></fig><fig id="fig1s10" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 10.</label><caption><title>Enlarged data, bird 6922.</title><p>Enlarged panel showing spectrogram, neural data, and seqNMF factorization for 6 s of pre-tutoring data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig1-figsupp10-v1.tif"/></fig></fig-group><p>By observing the neural activity in the HVC of isolated birds, we found that the HVC network activity can mature into long repeatable sequences even without exposure to a tutor. However, there are some key differences between typical adult HVC sequences and those found in isolated birds, suggesting which features of HVC development rely on exposure to a tutor. Next, we observe HVC in isolated birds immediately before and after delayed exposure to a tutor. Birds isolated from a tutor are able to learn a song if exposed to a tutor before the end of a critical period, typically around age 65 days post-hatch (dph), but are increasingly unable to learn at later ages (<xref ref-type="bibr" rid="bib35">London, 2019</xref>; <xref ref-type="bibr" rid="bib21">Gobes et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">Immelmann, 1969</xref>). Although only half of our late tutored birds successfully learned from the tutor, we observed an interesting correlation between HVC activity prior to tutoring and the degree to which birds learned. Namely, birds with highly song-locked HVC activity prior to tutoring typically failed to learn, while birds with less song-locked activity tended to learn. In the birds that did learn, we were able to track sequences throughout the course of learning. Pre-existing self-organized HVC sequences persisted throughout major changes to the song, forming a substrate for newly learned song elements. Together, these results point to how the brain may self-organize, and at the interplay between self-organized structure and the ability to incorporate new information from a tutor.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Neural sequences are present in isolated birds, but atypical</title><p>We first asked whether the songs of isolated birds involve the same pre-motor neural pathways and neuronal sequences responsible for generating typical songs. We carried out functional calcium imaging of large populations of neurons in HVC of isolated birds at a range of ages. Sequences of neuronal activity in HVC have previously been analyzed by aligning neuronal activity to repeatable elements of the song (<xref ref-type="bibr" rid="bib36">Long et al., 2010</xref>), an approach with limited utility in isolated birds due to the high variability of their songs. Instead, we extract neural sequences directly from the calcium signals using an unsupervised algorithm, seqNMF, (<xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref>) to find the sequences that best fit the neural data.</p><p>The seqNMF algorithm is designed to find patterns in data, and identify the times when each pattern occurs. It is a generalization of non-negative matrix factorization, allowing for non-synchronous patterns of neural activity, for example, sequential firing of neurons in a chain. In the context of seqNMF, a sequence is defined as a pattern of activity in a population of neurons that extends for more than one time step. The algorithm allows for an individual neuron to be active at more than one time in a sequence, but in practice neurons in HVC or the hippocampus are typically active only once in a sequence. Each seqNMF factor is represented as an exemplar sequence <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and a vector of times when the sequence occurs, <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. A sequence in the data is factorized as the convolution of a <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> with its corresponding <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Data often contain multiple sequences, each represented by different <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>s and <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>s, and the full data matrix is represented as a sum across all different extracted sequences. Using gradient descent, the algorithm automatically finds sequences that best fit the data, while avoiding redundancies between sequences. It allows for explicitly selecting between ‘parts-based’ and ‘events-based’ factorizations, but here we are agnostic to this distinction, selecting the factorization that best fits the data. SeqNMF has been shown to be robust to several forms of neural variability (<xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref>). In addition, it includes a measure of ‘sequenciness,’ which quantifies the extent to which data are better explained by temporally extended sequences than by synchronized activity. This measure ranges from zero (only synchronized activity) to one (only temporally extended sequences, such that shuffling timebins in the data erases all repeatable structure).</p><p>This technique reveals the existence of significant sequential activity in HVC of singing isolated birds (<xref ref-type="fig" rid="fig1">Figure 1B and C</xref>, data in C also presented in <xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref>). In these birds, the seqNMF factorization explained 27 ± 9% of the power in the neural data, with a sequenciness score of 0.55 ± 0.88 (mean ± standard deviation). SeqNMF also reveals long continuous sequences in data acquired from typical adult HVC (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) as expected from previous work (<xref ref-type="bibr" rid="bib36">Long et al., 2010</xref>; <xref ref-type="bibr" rid="bib51">Picardo et al., 2016</xref>; <xref ref-type="bibr" rid="bib37">Lynch et al., 2016</xref>). Here, 46% of the data is explained by the seqNMF factorization, with sequenciness score of 0.74.</p><p>The sequences found in isolated birds are surprisingly typical in some respects, but atypical in others, especially in their correlation to vocal output. As in typical HVC sequences, neurons in isolated birds participate at characteristic moments during the sequence (<xref ref-type="fig" rid="fig1">Figure 1E</xref>), and many neurons participate in at least one sequence (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). Neurons that participate in a sequence tend to fire at a majority of sequence occurrences (<xref ref-type="fig" rid="fig1">Figure 1G</xref>). On average, 45.21 ± 7% of these neurons’ activity was specific to sequences. Neural sequences are correlated with precisely timed song features in isolated birds’ songs (<xref ref-type="fig" rid="fig1">Figure 1H1</xref>, song features calculated as in <xref ref-type="bibr" rid="bib55">Tchernichovski et al., 2000</xref>). The extent of song locking is quantified by computing the cross-correlation between sequences and song features, and summing across significant time lags (see Methods). Song locking in isolated birds was only on average 0.58 times as strong as in a typically tutored adult bird (<xref ref-type="fig" rid="fig1">Figure 1J</xref>). Finally, in isolated birds, on average only 61% of each song bout is represented by a detected HVC sequence, substantially less than the complete sequence coverage found in typically tutored birds (<xref ref-type="bibr" rid="bib51">Picardo et al., 2016</xref>; <xref ref-type="bibr" rid="bib37">Lynch et al., 2016</xref>; <xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>; <xref ref-type="fig" rid="fig1">Figure 1K</xref>, see Methods). By each of these measures, HVC sequences in isolated birds are more strongly present than would be expected from per-neuron circularly shifted data (red lines in <xref ref-type="fig" rid="fig1">Figure 1F–K</xref>), but not as robust as sequences observed in typically tutored birds (red triangles in <xref ref-type="fig" rid="fig1">Figure 1F–K</xref>). The per-neuron circular shifting controls for the possibility that neurons in isolate HVC may be firing independently. For enlarged panels of pre-tutoring neural and song data from each of the eight isolated birds, see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplements 3</xref>–<xref ref-type="fig" rid="fig1s10">10</xref>.</p><p>HVC activity in isolated birds exhibits additional qualitative differences from that in typically tutored birds. While HVC neurons generate only brief bursts of spikes in tutored birds, neurons in isolated birds sometimes generated extended periods of continuous activity, especially during long syllables of variable duration (<xref ref-type="fig" rid="fig1">Figure 1L</xref>, 7/8 birds exhibited multiple instances of persistent activity, coordinated across at least three neurons, and lasting at least 500 ms). This contrasts with the long syllables of typical adult songs which are all generated by extended sequences of brief bursts. In addition, HVC sequences in isolated birds exhibit variable durations, often truncating at different points (<xref ref-type="fig" rid="fig1">Figure 1L</xref>, 8/8 birds), producing syllables of highly variable duration. Such truncations in the middle of a syllable, as opposed to at stereotyped gaps between syllables, are very unusual in typically tutored birds (<xref ref-type="bibr" rid="bib9">Cynx, 1990</xref>). These atypical modes of HVC activity suggest several possible mechanisms to understand characteristic features of isolate songs, abnormally long syllables, and those of variable duration (<xref ref-type="bibr" rid="bib17">Fehér et al., 2009</xref>). For example, syllables in isolated birds may exhibit variable duration when their underlying HVC sequences are truncated at different points. We wondered if the existence of sequences in HVC of socially isolated birds occurs only after the closure of the critical period (i.e. a product of an already atypical isolate song) or whether they develop at an even earlier age when birds have not yet heard a tutor song, but can still be tutored. We recorded in 5 birds at ages 57–64 dph, prior to tutor exposure, and found strong evidence for HVC sequences (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). In each bird, HVC data exhibited significantly higher sequenciness scores than time-shuffled control datasets (<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). There was not a significant correlation between the age of the bird and any sequence features we measured (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B-F</xref>, linear regression model, significance threshold p&lt;0.5, compared to a constant model). The correlations were not significant both when we restricted to birds within the traditional critical period (<italic>lt</italic><sub>65</sub> dph), and when we included data from three older isolated birds (68–117 dph). Thus, the large (several fold) bird-to-bird variability in sequence properties (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B-F</xref>) is not explained by age, and is likely due to inter-individual variability in developmental timecourses.</p></sec><sec id="s2-2"><title>Prior to tutoring, birds that will learn exhibit HVC sequences that are relatively immature and decoupled from vocal output</title><p>Next, we asked whether the properties of the HVC sequences relate to the ability of birds to learn a new song from a tutor. Many of our young isolated birds were eventually tutored at an age around the critical period and we found that half of them learned elements of their tutor song, while the others developed fully isolated songs. We classified birds as learners if their song had an Imitation Score metric (<xref ref-type="bibr" rid="bib42">Mandelblat-Cerf and Fee, 2014</xref>) greater than 0.5. The songs of non-learners remained highly variable and isolate-like even after tutoring (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). In contrast, learner birds developed a new syllable within a day or two after tutoring, and ultimately sang typical adult songs, consisting of stereotyped motifs (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The new syllables appeared to imitate elements of the tutor song, and persist as part of the learned song (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref>–<xref ref-type="fig" rid="fig2s4">4</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Relation between HVC sequence maturity and subsequent song learning.</title><p>(<bold>A</bold>) Example spectrograms for two non-learner birds, prior to tutoring and several weeks later (at least 77dph). (<bold>B</bold>) Example spectrograms for two learners, prior to tutoring, shortly after tutoring, and several weeks later. Red dots mark the new syllable. Red bars mark a stereotyped motif. (<bold>C–E</bold>) Three measures of HVC sequence maturity for learners (pink) and non-learners (gray). Error bars denote standard deviation (*p&lt;0.05, *p&lt;0.01). (<bold>C</bold>) Number of sequences in HVC. (<bold>D</bold>) Fraction of neurons that participate in a sequence. (<bold>E</bold>) Autocorrelation of sequence factor timecourses. (<bold>F</bold>) Age of first tutoring for learners and non-learners. (<bold>G–H</bold>) Example pre-tutoring data from two birds that were brothers. (<bold>G</bold>) A non-learner first tutored at 61 dph. (<bold>H</bold>) A learner first tutored at 64 dph.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Elaborations on tutor match, bird 6938.</title><p>Song spectrograms at different stages of development, and comparison to tutor song spectrogram. Colored bars match elements of the imitation to tutor song syllables.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Elaborations on tutor match, bird 6992.</title><p>Song spectrograms at different stages of development, and comparison to tutor song spectrogram. Colored bars match elements of the imitation to tutor song syllables.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Elaborations on tutor match, bird 6962.</title><p>Song spectrograms at different stages of development, and comparison to tutor song spectrogram. Colored bars match elements of the imitation to tutor song syllables.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Elaborations on tutor match, bird 6922.</title><p>Song spectrograms at different stages of development, and comparison to tutor song spectrogram.Colored bars match elements of the imitation to tutor song syllables.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig2-figsupp4-v1.tif"/></fig></fig-group><p>An analysis of HVC activity revealed that sequences prior to tutoring were systematically less mature/‘crystallized’ in birds that learned than in birds that failed to learn. Learner birds had fewer sequences than non-learners (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, average two sequences in learners, 3.25 sequences in non-learners, p=0.029, Wilcoxon rank sum test). Sequences in learner birds were more weakly correlated to song features (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, average 0.20 s learner, 0.55 s non-learner, p=0.0034, Wilcoxon rank sum test). Sequences in learners had lower autocorrelation, a measure of how repeatably/rhythmically they are produced (<xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>), than non-learners (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, average 0.125 s learner, 0.244 s non-learner, p=0.018, Wilcoxon rank sum test). Three additional measures of sequence maturity, all related to intrinsic sequence properties were calculated. While non-learners also trended higher in these measures, the differences were not significant (Wilcoxon rank sum tests, Neural participation: average 45% learner, 70% non-learner, p=0.2; Reliability: average 69% learner, 74% non-learner, p=1; Coverage: average 51% learner, 71% non-learner, p=0.34). In our dataset, the age of tutoring did not significantly influence whether the bird was a learner or non-learner (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, average 60.5 dph learner, 78.75 dph non-learner, p=0.11, Wilcoxon rank sum test). For example, one of the younger birds in our dataset (61 dph) was a non-learner, and had particularly clear HVC sequences before tutoring (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). This bird’s brother, tutored 3 days later, was a learner, and had sequences that appear far less mature (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). Together, these results suggest that the presence, at the time of tutoring, of robust song-locked sequences, may inhibit learning. In other words, learning may be better supported by more immature sequences that are more independent from the vocal output.</p></sec><sec id="s2-3"><title>Tracking HVC sequences across rapidly learned song changes</title><p>In late-tutored birds that learned, the speed with which new syllables appeared was striking. These birds developed a new syllable within a day or two after tutoring (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>), as has been previously described (<xref ref-type="bibr" rid="bib56">Tchernichovski et al., 2001</xref>; <xref ref-type="bibr" rid="bib33">Lipkind and Tchernichovski, 2011</xref>; <xref ref-type="bibr" rid="bib34">Lipkind et al., 2013</xref>). These new syllables appeared to emerge de-novo, not by syllable differentiation as is common in tutored birds.</p><p>We wondered if these birds, which learned a new syllable rapidly after tutoring, formed a de-novo HVC sequence for this new syllable, or perhaps used a pre-existing sequence. We were able to track neurons in our calcium imaging data throughout the course of tutoring (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, see Methods, <xref ref-type="bibr" rid="bib23">Gu et al., 2023</xref>), enabling us to see what happens to neural activity during rapid changes in the song. We first extracted neural sequences associated with new post-tutoring syllables, then followed these neurons back in time to find that the sequence existed even prior to tutoring (<xref ref-type="fig" rid="fig3">Figure 3B and C</xref>, see Methods). The correlation coefficients between the pre-tutoring and post-tutoring sequences in the four learner birds were <inline-formula><mml:math id="inf13"><mml:mrow><mml:mn>0.20</mml:mn><mml:mo>,</mml:mo><mml:mn>0.38</mml:mn><mml:mo>,</mml:mo><mml:mn>0.27</mml:mn></mml:mrow></mml:math></inline-formula>, and 0.45, respectively. In all four learner birds, the correlation between the pre-tutoring and post-tutoring sequences was significantly higher than expected by a time-shuffled control (p=0.014, p=0.018, p=0.0004, p=0.0002, respectively). Additionally, the correlation between pre- and post- tutoring sequences was significantly higher than a neuron-shuffled control in two birds (p=0.0099, p=0.0032), and trended higher in the remaining two birds (p=0.077, p=0.079, likely influenced by an abundance of near-synchronous neurons, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). Interestingly, the sequences prior to tutoring were relatively uncoupled to vocal output, without a strong correlation to song syllables. Combining data from the four birds that learned a new syllable rapidly after tutoring, neural sequences extracted two days after tutoring appeared to become more song locked after tutoring (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, p=0.0048, Wilcoxon rank sum test). This lack of coupling between HVC sequences and song structure prior to tutoring, and their subsequent incorporation into learned syllables, suggests that, in these late-tutored birds, HVC sequences may exist in a ‘latent’ state.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Tracking HVC sequences as isolated birds rapidly learn a new syllable.</title><p>(<bold>A</bold>) Neurons detected before (left) and after (right) tutoring shown in grayscale (CNMF_E algorithm). Colored contours indicate locations of neurons tracked across five days, from blue to red (<bold>B</bold>) Sequence in HVC, tracked before and after first tutor exposure, through the development of a new syllable. Each of the five panels shows data from a different day, starting one day before tutoring, through three days after tutoring. (Top) On each recording day, cross-correlation of neurons with the sequence that becomes associated with the new syllable. The sequence was extracted by running seqNMF on neural data recorded two days after tutoring, and selecting the factor associated with the new syllable. Neurons are sorted according to participation in this factor. Significant bins are shown in black, non-significant bins in gray (p=0.05, Bonferroni corrected, compared to circularly-shifted control) (Middle). On each recording day, for example, spectrograms at times when the sequence occurs on each day. Red circles indicate putative newly learned syllables. (Bottom) On each recording day, cross-correlation of sequence with acoustic features (amplitude, entropy, pitch goodness, aperiodicity, mean frequency, pitch, frequency modulation, and amplitude modulation) (<bold>C</bold>) Same as B for a different example bird. (<bold>D</bold>) Correlation with song amplitude before (pink) and after (gray) tutoring for all sequences in learner birds extracted data when a new syllable had been learned. (<bold>E</bold>) Similar to B and C, for a different example bird. Here, sequences are extracted from pre-tutoring data, then tracked forward in time. (<bold>F</bold>) Song locking (maximum cross-correlation with song amplitude) before and after tutoring for the pre-tutoring sequences that had weaker song locking. (<bold>G</bold>) Song locking before and after tutoring for the pre-tutoring sequences that started off with stronger song locking.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77262-fig3-v1.tif"/></fig><p>Next, we aimed to control for the possibility that the appearance of sequences becoming progressively more locked to vocal output after tutoring was due to the fact that sequences were extracted from neural data recorded after tutoring. We directly extracted HVC sequences from exclusively pre-tutoring neuronal data and tracked them forward in time until a new syllable appeared. Sequences that were initially relatively ‘latent’ persisted, becoming progressively more correlated with vocal output, ultimately appearing to become locked to a new syllable (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Each of the ‘learner’ birds appeared to have two HVC sequences present prior to tutoring. Of these sequences, the ones that started off less correlated with song amplitude exhibited a significant increase in correlation with song amplitude after tutoring (<xref ref-type="fig" rid="fig3">Figure 3F</xref>, p=0.045, Wilcoxon rank sum test). The sequences that started off more correlated with song amplitude did not significantly change their correlation with song amplitude (<xref ref-type="fig" rid="fig3">Figure 3G</xref>, p=1, Wilcoxon rank sum test). Together, these results are consistent with the view that the emergence of new syllables after tutoring may co-opt existing HVC sequences, including relatively ‘latent’ sequences.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We set out to determine whether the formation of sequences in HVC depends on prior exposure to a tutor song. By observing the neural activity in HVC of isolated birds, we found that HVC network activity can form long repeatable sequences even in birds that had no prior exposure to vocal tutoring. Sequences in isolate HVC exhibit some properties of typical HVC, with many neurons reliably participating in sequences, and sequences being correlated to vocal output. However, sequences in isolated birds were less reliable and less tightly correlated with vocal output than has been described in typical birds, and exhibited abnormal truncations and persistent activity.</p><p>We had previously hypothesized that the experience of hearing a tutor may seed the formation of HVC sequences of the appropriate number and durations (<xref ref-type="bibr" rid="bib39">Mackevicius and Fee, 2018</xref>), but our new data reveal that HVC sequences exist even prior to tutoring. Thus, there must be a way for sequences to form without the prior storage of a tutor memory. In models of Hebbian learning in HVC, sequences can form in networks driven by random inputs rather than patterned inputs (<xref ref-type="bibr" rid="bib19">Fiete et al., 2010</xref>). However, in this case, the distribution of sequence durations no longer matches syllable durations found in typical adult birds, but is instead more consistent with the highly variable and atypically long syllables that occur in birds that have never heard a tutor (isolate song) (<xref ref-type="bibr" rid="bib17">Fehér et al., 2009</xref>; <xref ref-type="bibr" rid="bib52">Price, 1979</xref>). Thus our findings are consistent with the view that sequences can emerge in isolate birds by a combination of simple Hebbian learning mechanisms together with spontaneous activity either within HVC or driven by the inputs to HVC.</p><p>Our discovery of latent sequences suggests a separation between neural processes for building a stable representation of states within a task (i.e. sequential moments in time), and neural processes for associating an action with each state. Thus, sequences may gradually emerge in the maturing HVC network via simple Hebbian processes (<xref ref-type="bibr" rid="bib6">Buonomano, 2005</xref>; <xref ref-type="bibr" rid="bib29">Jun and Jin, 2007</xref>; <xref ref-type="bibr" rid="bib19">Fiete et al., 2010</xref>; <xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>), but may remain relatively decoupled from downstream motor neurons until a memory of the tutor song is learned and reinforcement learning processes begin.</p><p>From a computational perspective, what do latent sequences tell us about how the brain learns? By latent sequences, we mean sequences that are initially only weakly correlated with vocal output, but are subsequently used to produce learned song changes. In reinforcement learning models of song learning, HVC sequences remain relatively stable even as the song changes (<xref ref-type="bibr" rid="bib11">Doya and Sejnowski, 1994</xref>; <xref ref-type="bibr" rid="bib18">Fiete et al., 2007</xref>; <xref ref-type="bibr" rid="bib16">Fee and Goldberg, 2011</xref>; <xref ref-type="bibr" rid="bib5">Brainard and Doupe, 2013</xref>), consistent with our observation of stable sequences. This is in contrast with other models of song learning, like the ‘inverse model’ (<xref ref-type="bibr" rid="bib20">Giret et al., 2014</xref>; <xref ref-type="bibr" rid="bib26">Hanuschkin et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Hahnloser and Ganguli, 2013</xref>). In the inverse model, each motor neuron produces the same vocal output at different times during vocal learning; song changes are caused by pre-motor neurons (e.g. HVC) being activated in a different order. In contrast, we observed relatively stable sequences throughout learned song changes. Our results are consistent with data from the primary motor cortex of macaques operating a brain-computer interface—a fixed repertoire of activity patterns is associated with different movements after learning (<xref ref-type="bibr" rid="bib22">Golub et al., 2018</xref>). Our results are also consistent with the idea that the brain may use pre-existing sequential patterns to rapidly learn from new experiences, for example, the existence of sequences in the hippocampus prior to exposure to new environments (<xref ref-type="bibr" rid="bib59">Villette et al., 2015</xref>; <xref ref-type="bibr" rid="bib15">Farooq et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">McKenzie et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Dragoi, 2020</xref>).</p><p>If the brain is able to build on the latent structure to learn from sparse data, essentially implementing inductive bias, we might expect different forms of latent structure for different tasks. Zebra finches are known to develop typical songs, including typical syllable durations, after being tutored by atypical isolate songs, relying on species-specific ‘priors’ to achieve species-typical syllable durations. The latent sequences we observed tended to last approximately a couple hundred milliseconds—the same as the duration of typical zebra finch syllables. Might other species that sing faster songs (e.g. grasshopper sparrow) or slower songs (e.g. white-throated sparrow) exhibit latent sequences of shorter or longer durations? One might imagine that the speed of latent sequences could be genetically specified by expression levels of ion channels with different time constants within HVC. Alternatively, the duration of latent sequences could be specified by the amount of time it takes for HVC to get feedback from respiratory and/or auditory centers, which may also have their own intrinsic timing or rhythmicity (<xref ref-type="bibr" rid="bib53">Schmidt and Goller, 2016</xref>; <xref ref-type="bibr" rid="bib25">Hamaguchi et al., 2016</xref>; <xref ref-type="bibr" rid="bib1">Araki et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Mackevicius et al., 2020</xref>). Each of these possible sources of latent HVC structure could be tested in further experiments. By whatever mechanism latent sequences arise, they appear to be capable of supporting song learning, at least in the case of delayed tutoring. More generally, the ability of brains to generate complex learned behavior may depend on the intrinsic developmental formation of appropriate latent dynamics in motor and sensory circuits.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"><break/><break/>Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="top">Software, algorithm<break/></td><td align="left" valign="top">seqNMF</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/FeeLab/seqNMF">github.com/FeeLab/seqNMF</ext-link></td><td align="left" valign="top">Sequence detection</td></tr><tr><td align="left" valign="top">Software, algorithm<break/></td><td align="left" valign="top">CNMF_E</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib63">Zhou et al., 2018</xref></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/CNMF_E">github.com/zhoupc/CNMF_E</ext-link></td><td align="left" valign="top">Cell extraction</td></tr><tr><td align="left" valign="top">Software, algorithm<break/><break/></td><td align="left" valign="top">STAT</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib23">Gu et al., 2023</xref></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/shijiegu/STAT">https://github.com/shijiegu/STAT</ext-link></td><td align="left" valign="top">Tracking neurons across days</td></tr><tr><td align="left" valign="top">Software, algorithm<break/><break/></td><td align="left" valign="top">Chronux</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib46">Mitra and Bokil, 2007</xref></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="http://chronux.org/">chronux.org/</ext-link></td><td align="left" valign="top">Spectrogram computation</td></tr><tr><td align="left" valign="top">Software, algorithm<break/></td><td align="left" valign="top">SAP</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib55">Tchernichovski et al., 2000</xref></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="http://soundanalysispro.com">soundanalysispro.com</ext-link></td><td align="left" valign="top">Sound analysis</td></tr><tr><td align="left" valign="top">Software, algorithm<break/></td><td align="left" valign="top">SI</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib42">Mandelblat-Cerf and Fee, 2014</xref></td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0096484">https://doi.org/10.1371/journal.pone.0096484</ext-link></td><td align="left" valign="top">Song imitation</td></tr><tr><td align="left" valign="top">Software, algorithm<break/><break/></td><td align="left" valign="top">MATLAB</td><td align="left" valign="top">MathWorks</td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="http://mathworks.com/products/matlab">mathworks.com/products/matlab</ext-link></td><td align="left" valign="top">Programming language</td></tr><tr><td align="left" valign="top">Biological sample (<italic>Taeniopygia guttata</italic>)<break/></td><td align="left" valign="top">Zebra finches</td><td align="left" valign="top">MIT animal facility</td><td align="left" valign="top"><italic>Taeniopygia guttata</italic></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Strain, strain background<break/>(<italic>adeno-associated virus</italic>)</td><td align="left" valign="top">AAV9.CAG.GCaMP6f.<break/>WPRE.SV40</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib7">Chen et al., 2013</xref></td><td align="left" valign="top">Addgene viral prep # 100836-AAV9, <break/><ext-link ext-link-type="uri" xlink:href="http://n2t.net/addgene:100836">http://n2t.net/addgene:100836</ext-link>,<break/>RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:Addgene_100836">Addgene_100836</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top"><break/>Commercial assay or kit</td><td align="left" valign="top">Miniature microscope</td><td align="left" valign="top">Inscopix</td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.inscopix.com/nvista">https://www.inscopix.com/nvista</ext-link></td><td align="left" valign="top"/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Animal care and use</title><p>For this study, Imaging data were collected in nine male zebra finches (<italic>Taeniopygia guttata</italic>) from the MIT zebra finch breeding facility (Cambridge, MA). Animal care and experiments were carried out in accordance with NIH guidelines, and reviewed and approved by the Massachusetts Institute of Technology Committee on Animal Care (Protocol 0721-064-24: Chronic Recording of Neural Activity in Songbirds).</p><p>In order to control exposure to a tutor song, eight birds were foster-raised by female birds, which do not sing, starting on or before post-hatch day 15 (15 dph). Starting between 35 dph and 50 dph, these birds were housed singly in custom-made sound isolation chambers. An additional bird was tutored by his father, as is typical. After a couple of days of acclimation to the lab environment, birds were anesthetized with isoflurane, and were given a surgery to inject the virus to express the functional indicator GCaMP6f and implant a GRIN (gradient index) lens (see below). Analgesic (Buprinex) was administered 30 min prior to the surgery, and for 3 days postoperatively. After at least a week for virus expression, an Inscopix miniscope baseplate was attached to the existing implant. Birds were acclimated to the miniscope, and once birds started singing with the miniscope (2–7 days), functional calcium signals were recorded for at least three consecutive days. To avoid photobleaching, short files (approximately 10 s) were obtained, typically fewer than 50 files per day. Once some pre-tutoring singing data had been obtained, birds were tutored briefly (5–10 song bouts from a tutor bird) each day for at least 7 days.</p></sec><sec id="s4-2"><title>Expression of functional calcium indicator GCaMP6f</title><p>The calcium indicator GCaMP6f was expressed in HVC by intercranial injection of the viral vector AAV9.CAG.GCaMP6f.WPRE.SV40 (<xref ref-type="bibr" rid="bib7">Chen et al., 2013</xref>) into HVC. In the same surgery, a cranial window was made using a relay GRIN (gradient index) lens (1 mm diameter, 4 mm length, Inscopix) implanted on the surface of the brain, after the dura was removed. After at least one week, in order to allow for sufficient viral expression, recordings were made using the Inscopix nVista miniature fluorescent microscope. It is not known whether this virus is specific to projection neurons in HVC. However, given the dense firing patterns of HVC interneurons, once convolved with the GCaMP6f calcium kernel, HVC interneuron activity would likely look flat, almost indistinguishable from the background. Therefore, in practice, most if not all of the neurons included in our datasets are likely to be projection neurons, not HVC interneurons.</p></sec><sec id="s4-3"><title>Extraction of neuronal activity and background subtraction using CNMF_E</title><p>Neuronal activity traces were extracted from raw fluorescence movies using a constrained non-negative matrix factorization algorithm, CNMF_E, that is specialized for microendoscope data by including a local background model to remove activity from out-of-focus cells (<xref ref-type="bibr" rid="bib63">Zhou et al., 2018</xref>). Custom software (Shijie Gu, Emily Mackevicius, Pengcheng Zhou) was used to extend the CNMF_E algorithm to combine batches of short files (BatchVer) and track individual neurons over the course of multiple days (<xref ref-type="bibr" rid="bib23">Gu et al., 2023</xref>).</p></sec><sec id="s4-4"><title>Unsupervised discovery of neural sequences using seqNMF</title><p>We addressed the challenge of needing to detect neural sequences in HVC without relying on aligning neural activity to the song by developing an unsupervised algorithm, seqNMF (<xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref>). This was necessary because juvenile songs are highly variable and difficult to parse into repeatable syllables, and because we wanted to allow for the possibility that HVC activity might be more stereotyped than the song. Briefly, seqNMF factorizes data into exemplar sequence factors (<inline-formula><mml:math id="inf14"><mml:mi>W</mml:mi></mml:math></inline-formula>’s). Each sequence factor has a corresponding timecourse (<inline-formula><mml:math id="inf15"><mml:mi>H</mml:mi></mml:math></inline-formula>). Convolving each exemplar with its respective timecourse produces an approximate reconstruction of the original data (<inline-formula><mml:math id="inf16"><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>⊛</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>). SeqNMF returns a factorization that minimizes reconstruction error, subject to a penalty term that encourages simpler factorizations. It is possible for seqNMF to extract non-sequential (purely synchronous) patterns of neural activity. SeqNMF measures the extent to which a dataset contains sequential vs. synchronous patterns using a ‘sequenciness’ score, which ranges between 0 and 1. A score of zero indicates that all explanatory power of the factorization is due to synchronous activity, while a score of one indicates that none of the explanatory power is due to synchronous activity. Quantitatively this is calculated by shuffling the timebins in the dataset. In these datasets, both ‘sequenciness’ scores and visual inspection of the factors suggest the presence of temporally extended patterns, which we refer to as sequences.</p></sec><sec id="s4-5"><title>Preprocessing calcium traces prior to running seqNMF</title><p>We performed several preprocessing steps before applying seqNMF to functional calcium traces extracted by CNMF_E. First, we estimated burst times from the raw traces by deconvolving the traces using an AR-2 process. The deconvolution parameters (time constants and noise floor) were estimated for each neuron using the CNMF_E code package (<xref ref-type="bibr" rid="bib63">Zhou et al., 2018</xref>). Some neurons exhibited larger peaks than others, likely due to different expression levels of the calcium indicator. Since seqNMF would prioritize the neurons with the most power, we renormalized by dividing the signal from each neuron by the sum of the maximum value of that row and the <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mn>95</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> percentile of the signal across all neurons. In this way, neurons with larger peaks were given some priority, but not much more than that of neurons with weaker signals.</p></sec><sec id="s4-6"><title>Estimating the number of significant sequences in each dataset</title><p>The number of sequences present in real neuronal datasets can be slightly ambiguous, so we used several methods to arrive at and validate an estimate for the number of significant neural sequences present in each dataset. It is important to note that, since our datasets are short, there may be additional neural sequences in HVC that do not appear, or do not achieve significance, in our datasets.</p><p>Our primary method for estimating the number of sequences in each dataset involves choosing a value for the seqNMF parameter <inline-formula><mml:math id="inf18"><mml:mi>λ</mml:mi></mml:math></inline-formula> that balances reconstruction cost with correlation (redundancy) cost, as described in <xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref>. We swept <inline-formula><mml:math id="inf19"><mml:mi>λ</mml:mi></mml:math></inline-formula> with <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> s to find <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, the cross-over point that balances these cost terms (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A</xref>). Based on analysis of simulated data (<xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref>), where values of <inline-formula><mml:math id="inf23"><mml:mi>λ</mml:mi></mml:math></inline-formula> at or slightly above <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> yielded the correct number of significant sequences, we looked at the distribution of significant sequences at <inline-formula><mml:math id="inf25"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf26"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2B</xref>), and chose as our estimate a number between the peaks of these two distributions. For significance tests, each dataset was split into a training set (75%) and a test set (25%). Sequences were detected in the training dataset, and significance was measured in the test dataset by assessing the overlap of the sequences with the test dataset compared to null (time-shifted) sequences.</p><p>We validated these estimates of the number of significant sequences by testing the consistency of resulting factorizations. Consistency measures the extent to which there is a one-to-one mapping between the factors of two different factorizations. When K matches the number of sequences in a dataset, seqNMF factorizations will be relatively consistent across different random initializations, even at <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib40">Mackevicius et al., 2019</xref>). We ran seqNMF on the entire dataset at the estimated K from 25 different random initial conditions, and confirmed that the sequences were consistent across the different initializations. This can be seen by a large block of consistent factorizations in the consistency matrix (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>). When K is too high for the dataset, inconsistency will arise in seqNMF factorizations if <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This can be seen by a disruption in the consistency, which we tested by computing consistency matrices for K above the estimated K. (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2D</xref>).</p></sec><sec id="s4-7"><title>Selecting a consistent factorization</title><p>For each dataset, we selected the most consistent factorization on which to perform all further analysis. Once we had selected an appropriate number of sequences for each dataset, using the analyses described above, we ran seqNMF 25 times at this value of <inline-formula><mml:math id="inf29"><mml:mi>K</mml:mi></mml:math></inline-formula> from different random initial conditions, and picked the factorization that was most consistent with the other factorizations (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2D</xref>). Factorizations at <inline-formula><mml:math id="inf30"><mml:mi>K</mml:mi></mml:math></inline-formula> chosen by the above methods tended to be more consistent than factorizations at higher <inline-formula><mml:math id="inf31"><mml:mi>K</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2D</xref>).</p></sec><sec id="s4-8"><title>Significance testing for cross-correlation analyses</title><p>Several of our results involve analyzing the temporal relationship between different timecourses (factors and neurons; factors and song acoustic features; factor autocorrelations). These analyses involve testing the significance of the cross-correlation between two time series, compared to null cross-correlation values that could occur if the signals were circularly shifted relative to each other by a random large time lag. Before measuring cross-correlations, we centered each signal to have zero mean. If we are assessing the cross-correlation at lags in the range from −L to L, we want to compare values measured here to null values measured at random lags longer than L. We compute the cross-correlation at each lag <inline-formula><mml:math id="inf32"><mml:mi mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula> in the range <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where T is the length of the time series, by circularly shifting one of the time series by <inline-formula><mml:math id="inf34"><mml:mi mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula> and computing the dot product with the other time series. We then use the cross-correlations at null lags (<inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>&lt;</mml:mo><mml:mo>−</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> or <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>&lt;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) to determine a Bonferroni-corrected significance threshold. The threshold is the <inline-formula><mml:math id="inf37"><mml:mrow><mml:mn>100</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> percentile of the absolute value of these null cross-correlations, where <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> is the number of comparisons (2 L times the number of tests being run), and <inline-formula><mml:math id="inf39"><mml:mi>p</mml:mi></mml:math></inline-formula> is the <inline-formula><mml:math id="inf40"><mml:mi>p</mml:mi></mml:math></inline-formula>-value. Significance is achieved for lags at which the measured cross-correlation exceeds this value.</p></sec><sec id="s4-9"><title>Assessing song locking, the cross-correlation between each factor and acoustic song features</title><p>Several of our results involve quantifying the temporal relationship between sequence timecourses (<inline-formula><mml:math id="inf41"><mml:mi>H</mml:mi></mml:math></inline-formula>’s) and the song. To do this, we measured the cross-correlation of sequences with song acoustics using eight acoustic features common in the songbird literature (<xref ref-type="bibr" rid="bib55">Tchernichovski et al., 2000</xref>): amplitude, entropy, pitch goodness, aperiodicity, mean frequency, pitch, frequency modulation, and amplitude modulation. Each of these acoustic features is measured from the song at 1ms resolution using standard software (Sound Analysis Pro, <ext-link ext-link-type="uri" xlink:href="http://soundanalysispro.com/">http://soundanalysispro.com/</ext-link>, <xref ref-type="bibr" rid="bib55">Tchernichovski et al., 2000</xref>). The seqNMF H’s are upsampled to this resolution, then cross-correlation between each <inline-formula><mml:math id="inf42"><mml:mi>H</mml:mi></mml:math></inline-formula> and each song feature is assessed using the above procedure, with L=1 s, p=0.05, and Bonferroni correction (2000 timebins) × (8 features) × (K sequences). The overall measure of song locking is computed by integrating the number of seconds that a given sequence has a significant correlation with each of the song features.</p></sec><sec id="s4-10"><title>Assessing which neurons participate in each sequence</title><p>Several of our results involve assessing which neurons participate in each sequence. In order to do this, we measure whether there is a significant cross-correlation between each neuron and each factor (with L=0.5 s, p=0.05, and Bonferroni correction (30 timebins) × (N neurons) × (K sequences)). Note that, since seqNMF is run on the neural data, it is guaranteed that some neurons will be correlated with the factors —the primary aim of this test is to assess which neurons are in which sequences.</p></sec><sec id="s4-11"><title>Tracking HVC projection neurons over the course of major song changes</title><p>A core motivation for using calcium imaging methods instead of other methods was the possibility to track HVC projection neurons over the course of major song changes. HVC projection neurons are particularly difficult to record with electrophysiological methods—current methods are unable to record an HVC projection neuron for more than a few hours, and tend to record one, or at most three, projection neurons at a time (<xref ref-type="bibr" rid="bib49">Okubo et al., 2014</xref>; <xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>). Previous studies of song-locked HVC activity throughout the learning process could only track changes in the neural population that occurred at a timescale slower than a week, because population statistics had to be compiled from single-neuron recordings (<xref ref-type="bibr" rid="bib50">Okubo et al., 2015</xref>). This technique misses rapid changes that can happen within a day (<xref ref-type="bibr" rid="bib56">Tchernichovski et al., 2001</xref>), and is unable to assess the stability of HVC sequences.</p><p>Stability of HVC sequences over time can be assessed using calcium imaging, though some challenges remain due to the potential for errors in tracking neurons across days. Single-photon calcium imaging methods have been used to address the stability of HVC sequences in adult birds with stable songs, observing stable song-locked activity in slightly more than half of HVC projection neurons, and unstable song-locked activity in slightly less than half of HVC projection neurons (<xref ref-type="bibr" rid="bib32">Liberti et al., 2016</xref>). This measure is likely an underestimate of the stability of HVC activity, since noise in tracking cell locations across days could lead to perceived instability. Thus, HVC sequences appear relatively stable in birds with stable song, but what about birds whose songs are changing? The potential for errors in tracking neurons across days was one factor in our decision to record in birds undergoing very rapid learning. It was necessary for us to expand upon previous methods for tracking neurons recorded by calcium imaging over time (<xref ref-type="bibr" rid="bib54">Sheintuch et al., 2017</xref>), likely due to the relatively short individual file sizes in our dataset from singing juvenile birds (we recorded many short files each day, when the birds happened to sing, instead of longer continuous files).</p><p>We tracked the activity of populations of HVC neurons over multiple days using Spatial Tracking Across Time (STAT, <xref ref-type="bibr" rid="bib23">Gu et al., 2023</xref>). This method builds off of previous methods (<xref ref-type="bibr" rid="bib54">Sheintuch et al., 2017</xref>), where individual cell pairs’ shape spatial correlation and distance are used to determine the correspondences between cells extracted from different sessions. STAT also considers local neighborhood motion consistency (<xref ref-type="bibr" rid="bib4">Belongie et al., 2002</xref>; <xref ref-type="bibr" rid="bib48">Myronenko and Song, 2010</xref>; <xref ref-type="bibr" rid="bib38">Ma et al., 2016</xref>) in computing the optimal tracking of cells across sessions, and requires less manual supervision. Individual cell identity matchings are iteratively updated with respect to the local motion consistency cost function. Cells that have no good match are excluded, as are cells with the abnormal coefficient of variations (the standard deviation divided by the mean). The coefficient of variation exclusion criteria was designed to detect artifacts (blood vessels erroneously detected by the algorithm as a neuron, which has very different spatial and temporal profiles compared to actual neurons), and fewer than 10% of extracted cells were excluded. Finally, the results of the matching algorithm are checked manually.</p></sec><sec id="s4-12"><title>Tracking sequences extracted on one subset of a dataset to another subset of the dataset</title><p>In order to track a sequence, <inline-formula><mml:math id="inf43"><mml:mi>W</mml:mi></mml:math></inline-formula>, extracted in one subset of a dataset (<italic>X</italic><sub>1</sub>, for example before tutoring) to another subset of the dataset (<italic>X</italic><sub>2</sub>, for example after tutoring), we first mean-subtract <inline-formula><mml:math id="inf44"><mml:mi>W</mml:mi></mml:math></inline-formula> and <italic>X</italic><sub>2</sub> along the time dimension, then estimate <inline-formula><mml:math id="inf45"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mo>⊤</mml:mo></mml:msup><mml:mo>⊛</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. In order to assess whether a neuron significantly participates in <inline-formula><mml:math id="inf46"><mml:mi>W</mml:mi></mml:math></inline-formula> in dataset <italic>X</italic><sub>2</sub>, we bootstrap using control datasets <inline-formula><mml:math id="inf47"><mml:msubsup><mml:mi>X</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, in which data from each neuron is circularly shifted in time by a different random amount. We then ask whether the neuron participates more strongly in the real dataset compared to participation calculated on control datasets (p=0.05 significance threshold, Bonferroni corrected for the number of neurons and the number of time-lags). Specifically, we compare <inline-formula><mml:math id="inf48"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mo>⊤</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf49"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-13"><title>Assessing sequence coverage of song bouts</title><p>Sequence coverage quantifies the observation that sequences in isolated birds appear to pop on and off at somewhat arbitrary moments in bouts, leaving some sections of some bouts with no clear sequences present. First, the moments when each sequence occurs are estimated by computing when <inline-formula><mml:math id="inf50"><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mo>⊤</mml:mo></mml:msup><mml:mo>⊛</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is larger than expected by chance (Bonferroni-corrected 95% percentile of <inline-formula><mml:math id="inf51"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>~</mml:mo></mml:mover><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mo>⊤</mml:mo></mml:msup><mml:mo>⊛</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). Next, the sequence is convolved with the corresponding <inline-formula><mml:math id="inf52"><mml:mi>W</mml:mi></mml:math></inline-formula>. Finally, the total number of seconds when some sequences was present is divided by the total number of seconds in the bout, and multiplied by 100, to get the percent of the bout covered by some sequence. Note that sequence coverage is distinct from previously described measures of burst coverage within a repeatable adult song motif (<xref ref-type="bibr" rid="bib37">Lynch et al., 2016</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Validation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Investigation, Methodology</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing – original draft, Project administration, Writing – review and editing, Formal analysis</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal care and experiments were carried out in accordance with NIH guidelines, and reviewed and approved by the Massachusetts Institute of Technology Committee on Animal Care (Protocol 0721-064-24: Chronic Recording of Neural Activity in Songbirds).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-77262-transrepform1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data and code to generate figures is publically available on the Dryad data-sharing platform, at the following URL: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.j0zpc86km">https://doi.org/10.5061/dryad.j0zpc86km</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Mackevicius</surname><given-names>E</given-names></name><name><surname>Gu</surname><given-names>S</given-names></name><name><surname>Denissenko</surname><given-names>N</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Calcium imaging dataset from the pre-motor area HVC in singing zebra finches before and after tutor exposure</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.j0zpc86km</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by a grant from the Simons Collaboration for the Global Brain, the National Institutes of Health (NIH) [R01 DC009183], and the G Harold and Leila Y Mathers Charitable Foundation. ELM received support through the NDSEG Fellowship program and the Simons Society of Fellows. Special thanks to Andrew Bahle for his comments on earlier versions of the manuscript.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Araki</surname><given-names>M</given-names></name><name><surname>Bandi</surname><given-names>MM</given-names></name><name><surname>Yazaki-Sugiyama</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mind the gap: neural coding of species identity in birdsong prosody</article-title><source>Science</source><volume>354</volume><fpage>1282</fpage><lpage>1287</lpage><pub-id pub-id-type="doi">10.1126/science.aah6799</pub-id><pub-id pub-id-type="pmid">27940872</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Andalman</surname><given-names>AS</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A specialized forebrain circuit for vocal babbling in the juvenile songbird</article-title><source>Science</source><volume>320</volume><fpage>630</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1126/science.1155140</pub-id><pub-id pub-id-type="pmid">18451295</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bear</surname><given-names>MF</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Modulation of visual cortical plasticity by acetylcholine and noradrenaline</article-title><source>Nature</source><volume>320</volume><fpage>172</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1038/320172a0</pub-id><pub-id pub-id-type="pmid">3005879</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Belongie</surname><given-names>S</given-names></name><name><surname>Malik</surname><given-names>J</given-names></name><name><surname>Puzicha</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Shape matching and object recognition using shape contexts</article-title><conf-name>IEEE Transactions on Pattern Analysis and Machine Intelligence</conf-name><fpage>509</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1109/34.993558</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>MS</given-names></name><name><surname>Doupe</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Translating birdsong: songbirds as a model for basic and applied medical research</article-title><source>Annual Review of Neuroscience</source><volume>36</volume><fpage>489</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-060909-152826</pub-id><pub-id pub-id-type="pmid">23750515</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buonomano</surname><given-names>DV</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A learning rule for the emergence of stable dynamics and timing in recurrent networks</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>2275</fpage><lpage>2283</lpage><pub-id pub-id-type="doi">10.1152/jn.01250.2004</pub-id><pub-id pub-id-type="pmid">16160088</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>TW</given-names></name><name><surname>Wardill</surname><given-names>TJ</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Pulver</surname><given-names>SR</given-names></name><name><surname>Renninger</surname><given-names>SL</given-names></name><name><surname>Baohan</surname><given-names>A</given-names></name><name><surname>Schreiter</surname><given-names>ER</given-names></name><name><surname>Kerr</surname><given-names>RA</given-names></name><name><surname>Orger</surname><given-names>MB</given-names></name><name><surname>Jayaraman</surname><given-names>V</given-names></name><name><surname>Looger</surname><given-names>LL</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Kim</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ultrasensitive fluorescent proteins for imaging neuronal activity</article-title><source>Nature</source><volume>499</volume><fpage>295</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1038/nature12354</pub-id><pub-id pub-id-type="pmid">23868258</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chomsky</surname><given-names>N</given-names></name><name><surname>Belletti</surname><given-names>A</given-names></name><name><surname>Rizzi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>On Nature and Language</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511613876</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cynx</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Experimental determination of a unit of song production in the zebra finch (Taeniopygia guttata)</article-title><source>Journal of Comparative Psychology</source><volume>104</volume><fpage>3</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1037/0735-7036.104.1.3</pub-id><pub-id pub-id-type="pmid">2354628</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshpande</surname><given-names>M</given-names></name><name><surname>Pirlepesov</surname><given-names>F</given-names></name><name><surname>Lints</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Rapid encoding of an internal model for imitative learning</article-title><source>Proceedings. Biological Sciences</source><volume>281</volume><elocation-id>20132630</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2013.2630</pub-id><pub-id pub-id-type="pmid">24598418</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Doya</surname><given-names>K</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>A Novel Reinforcement Model of Birdsong Vocalization Learning</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dragoi</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cell assemblies, sequences and temporal coding in the hippocampus</article-title><source>Current Opinion in Neurobiology</source><volume>64</volume><fpage>111</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.03.003</pub-id><pub-id pub-id-type="pmid">32375084</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eales</surname><given-names>LA</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Do zebra finch males that have been raised by another species still tend to select a conspecific song tutor?</article-title><source>Animal Behaviour</source><volume>35</volume><fpage>1347</fpage><lpage>1355</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(87)80007-6</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farley</surname><given-names>BJ</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Jin</surname><given-names>DZ</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Alteration of visual input results in a coordinated reorganization of multiple visual cortex maps</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>10299</fpage><lpage>10310</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2257-07.2007</pub-id><pub-id pub-id-type="pmid">17881536</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farooq</surname><given-names>U</given-names></name><name><surname>Sibille</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>K</given-names></name><name><surname>Dragoi</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Strengthened temporal coordination within pre-existing sequential cell assemblies supports trajectory replay</article-title><source>Neuron</source><volume>103</volume><fpage>719</fpage><lpage>733</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.040</pub-id><pub-id pub-id-type="pmid">31253469</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fee</surname><given-names>MS</given-names></name><name><surname>Goldberg</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A hypothesis for basal ganglia-dependent reinforcement learning in the songbird</article-title><source>Neuroscience</source><volume>198</volume><fpage>152</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2011.09.069</pub-id><pub-id pub-id-type="pmid">22015923</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fehér</surname><given-names>O</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Saar</surname><given-names>S</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name><name><surname>Tchernichovski</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>De novo establishment of wild-type song culture in the zebra finch</article-title><source>Nature</source><volume>459</volume><fpage>564</fpage><lpage>568</lpage><pub-id pub-id-type="doi">10.1038/nature07994</pub-id><pub-id pub-id-type="pmid">19412161</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Model of birdsong learning based on gradient estimation by dynamic perturbation of neural conductances</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>2038</fpage><lpage>2057</lpage><pub-id pub-id-type="doi">10.1152/jn.01311.2006</pub-id><pub-id pub-id-type="pmid">17652414</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>CZH</given-names></name><name><surname>Hahnloser</surname><given-names>RHR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spike-time-dependent plasticity and heterosynaptic competition organize networks to produce long scale-free sequences of neural activity</article-title><source>Neuron</source><volume>65</volume><fpage>563</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.003</pub-id><pub-id pub-id-type="pmid">20188660</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giret</surname><given-names>N</given-names></name><name><surname>Kornfeld</surname><given-names>J</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Hahnloser</surname><given-names>RHR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Evidence for a causal inverse model in an avian cortico-basal ganglia circuit</article-title><source>PNAS</source><volume>111</volume><fpage>6063</fpage><lpage>6068</lpage><pub-id pub-id-type="doi">10.1073/pnas.1317087111</pub-id><pub-id pub-id-type="pmid">24711417</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gobes</surname><given-names>SMH</given-names></name><name><surname>Jennings</surname><given-names>RB</given-names></name><name><surname>Maeda</surname><given-names>RK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The sensitive period for auditory-vocal learning in the zebra finch: consequences of limited-model availability and multiple-tutor paradigms on song imitation</article-title><source>Behavioural Processes</source><volume>163</volume><fpage>5</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2017.07.007</pub-id><pub-id pub-id-type="pmid">28743517</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Sadtler</surname><given-names>PT</given-names></name><name><surname>Oby</surname><given-names>ER</given-names></name><name><surname>Quick</surname><given-names>KM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Chase</surname><given-names>SM</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning by neural reassociation</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>607</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0095-3</pub-id><pub-id pub-id-type="pmid">29531364</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>S</given-names></name><name><surname>Mackevicius</surname><given-names>EL</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name><name><surname>Zhou</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Spatial Tracking across Time (STAT): Tracking Neurons across in-Vivo Imaging Sessions through Optimizing Local Neighborhood Motion Consistency</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.05.13.540658</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hahnloser</surname><given-names>R</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Vocal learning with inverse models Principles of Neural Coding</source><publisher-name>CRC Press</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamaguchi</surname><given-names>K</given-names></name><name><surname>Tanaka</surname><given-names>M</given-names></name><name><surname>Mooney</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A distributed recurrent network contributes to temporally precise vocalizations</article-title><source>Neuron</source><volume>91</volume><fpage>680</fpage><lpage>693</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.019</pub-id><pub-id pub-id-type="pmid">27397518</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanuschkin</surname><given-names>A</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Hahnloser</surname><given-names>RHR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A Hebbian learning rule gives rise to mirror neurons and links them to control theoretic inverse models</article-title><source>Frontiers in Neural Circuits</source><volume>7</volume><elocation-id>106</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2013.00106</pub-id><pub-id pub-id-type="pmid">23801941</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hildyard</surname><given-names>KL</given-names></name><name><surname>Wolfe</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Child neglect: developmental issues and outcomes</article-title><source>Child Abuse &amp; Neglect</source><volume>26</volume><fpage>679</fpage><lpage>695</lpage><pub-id pub-id-type="doi">10.1016/s0145-2134(02)00341-1</pub-id><pub-id pub-id-type="pmid">12201162</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Immelmann</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1969">1969</year><source>Song Development in the Zebra Finch and Other Estrildid Finches</source><publisher-name>Bird Vocalizations</publisher-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JK</given-names></name><name><surname>Jin</surname><given-names>DZ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Development of neural circuitry for precise temporal sequences through spontaneous activity, axon remodeling, and synaptic plasticity</article-title><source>PLOS ONE</source><volume>2</volume><elocation-id>e723</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0000723</pub-id><pub-id pub-id-type="pmid">17684568</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosche</surname><given-names>G</given-names></name><name><surname>Vallentin</surname><given-names>D</given-names></name><name><surname>Long</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Interplay of inhibition and excitation shapes a premotor neural sequence</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>1217</fpage><lpage>1227</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4346-14.2015</pub-id><pub-id pub-id-type="pmid">25609636</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kral</surname><given-names>A</given-names></name><name><surname>Dorman</surname><given-names>MF</given-names></name><name><surname>Wilson</surname><given-names>BS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuronal development of hearing and language: cochlear implants and critical periods</article-title><source>Annual Review of Neuroscience</source><volume>42</volume><fpage>47</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-061513</pub-id><pub-id pub-id-type="pmid">30699049</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liberti</surname><given-names>WA</given-names></name><name><surname>Markowitz</surname><given-names>JE</given-names></name><name><surname>Perkins</surname><given-names>LN</given-names></name><name><surname>Liberti</surname><given-names>DC</given-names></name><name><surname>Leman</surname><given-names>DP</given-names></name><name><surname>Guitchounts</surname><given-names>G</given-names></name><name><surname>Velho</surname><given-names>T</given-names></name><name><surname>Kotton</surname><given-names>DN</given-names></name><name><surname>Lois</surname><given-names>C</given-names></name><name><surname>Gardner</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Unstable neurons underlie a stable learned behavior</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1665</fpage><lpage>1671</lpage><pub-id pub-id-type="doi">10.1038/nn.4405</pub-id><pub-id pub-id-type="pmid">27723744</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lipkind</surname><given-names>D</given-names></name><name><surname>Tchernichovski</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Quantification of developmental birdsong learning from the subsyllabic scale to cultural evolution</article-title><source>PNAS</source><volume>108</volume><fpage>15572</fpage><lpage>15579</lpage><pub-id pub-id-type="doi">10.1073/pnas.1012941108</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lipkind</surname><given-names>D</given-names></name><name><surname>Marcus</surname><given-names>GF</given-names></name><name><surname>Bemis</surname><given-names>DK</given-names></name><name><surname>Sasahara</surname><given-names>K</given-names></name><name><surname>Jacoby</surname><given-names>N</given-names></name><name><surname>Takahasi</surname><given-names>M</given-names></name><name><surname>Suzuki</surname><given-names>K</given-names></name><name><surname>Feher</surname><given-names>O</given-names></name><name><surname>Ravbar</surname><given-names>P</given-names></name><name><surname>Okanoya</surname><given-names>K</given-names></name><name><surname>Tchernichovski</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Stepwise acquisition of vocal combinatorial capacity in songbirds and human infants</article-title><source>Nature</source><volume>498</volume><fpage>104</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/nature12173</pub-id><pub-id pub-id-type="pmid">23719373</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>London</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Developmental song learning as a model to understand neural mechanisms that limit and promote the ability to learn</article-title><source>Behavioural Processes</source><volume>163</volume><fpage>13</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2017.11.008</pub-id><pub-id pub-id-type="pmid">29162376</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>MA</given-names></name><name><surname>Jin</surname><given-names>DZ</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Support for a synaptic chain model of neuronal sequence generation</article-title><source>Nature</source><volume>468</volume><fpage>394</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1038/nature09514</pub-id><pub-id pub-id-type="pmid">20972420</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lynch</surname><given-names>GF</given-names></name><name><surname>Okubo</surname><given-names>TS</given-names></name><name><surname>Hanuschkin</surname><given-names>A</given-names></name><name><surname>Hahnloser</surname><given-names>RH</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rhythmic continuous-time coding in the songbird analog of vocal motor cortex</article-title><source>Neuron</source><volume>90</volume><fpage>877</fpage><lpage>892</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.021</pub-id><pub-id pub-id-type="pmid">27196977</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>J</given-names></name><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Yuille</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Non-Rigid point set registration by preserving global and local structures</article-title><source>IEEE Transactions on Image Processing</source><volume>25</volume><fpage>53</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1109/TIP.2015.2467217</pub-id><pub-id pub-id-type="pmid">26276991</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackevicius</surname><given-names>EL</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Building a state space for song learning</article-title><source>Current Opinion in Neurobiology</source><volume>49</volume><fpage>59</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.12.001</pub-id><pub-id pub-id-type="pmid">29268193</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackevicius</surname><given-names>EL</given-names></name><name><surname>Bahle</surname><given-names>AH</given-names></name><name><surname>Williams</surname><given-names>AH</given-names></name><name><surname>Gu</surname><given-names>S</given-names></name><name><surname>Denisenko</surname><given-names>NI</given-names></name><name><surname>Goldman</surname><given-names>MS</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Unsupervised discovery of temporal sequences in high-dimensional datasets, with applications to neuroscience</article-title><source>eLife</source><volume>8</volume><elocation-id>e38471</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.38471</pub-id><pub-id pub-id-type="pmid">30719973</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackevicius</surname><given-names>EL</given-names></name><name><surname>Happ</surname><given-names>MT</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An avian cortical circuit for chunking tutor song syllables into simple vocal-motor units</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>5029</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-18732-x</pub-id><pub-id pub-id-type="pmid">33024101</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mandelblat-Cerf</surname><given-names>Y</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An automated procedure for evaluating song imitation</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e96484</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0096484</pub-id><pub-id pub-id-type="pmid">24809510</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenzie</surname><given-names>S</given-names></name><name><surname>Huszár</surname><given-names>R</given-names></name><name><surname>English</surname><given-names>DF</given-names></name><name><surname>Kim</surname><given-names>K</given-names></name><name><surname>Christensen</surname><given-names>F</given-names></name><name><surname>Yoon</surname><given-names>E</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Preexisting hippocampal network dynamics constrain optogenetically induced place fields</article-title><source>Neuron</source><volume>109</volume><fpage>1040</fpage><lpage>1054</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.01.011</pub-id><pub-id pub-id-type="pmid">33539763</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mets</surname><given-names>DG</given-names></name><name><surname>Brainard</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Genetic variation interacts with experience to determine interindividual differences in learned song</article-title><source>PNAS</source><volume>115</volume><fpage>421</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1073/pnas.1713031115</pub-id><pub-id pub-id-type="pmid">29279376</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mets</surname><given-names>DG</given-names></name><name><surname>Brainard</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Learning is enhanced by tailoring instruction to individual genetic differences</article-title><source>eLife</source><volume>8</volume><elocation-id>e47216</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.47216</pub-id><pub-id pub-id-type="pmid">31526480</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mitra</surname><given-names>P</given-names></name><name><surname>Bokil</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Observed Brain Dynamics</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195178081.001.0001</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Torres</surname><given-names>I</given-names></name><name><surname>Madrid-Cánovas</surname><given-names>S</given-names></name><name><surname>Blanco-Montañez</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sensitive periods and language in cochlear implant users</article-title><source>Journal of Child Language</source><volume>43</volume><fpage>479</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1017/S0305000915000823</pub-id><pub-id pub-id-type="pmid">26924727</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Myronenko</surname><given-names>A</given-names></name><name><surname>Song</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Point set registration: coherent point drift</article-title><conf-name>IEEE Transactions on Pattern Analysis and Machine Intelligence</conf-name><fpage>2262</fpage><lpage>2275</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2010.46</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okubo</surname><given-names>TS</given-names></name><name><surname>Mackevicius</surname><given-names>EL</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>In vivo recording of single-unit activity during singing in zebra finches</article-title><source>Cold Spring Harbor Protocols</source><volume>2014</volume><fpage>1273</fpage><lpage>1283</lpage><pub-id pub-id-type="doi">10.1101/pdb.prot084624</pub-id><pub-id pub-id-type="pmid">25342072</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okubo</surname><given-names>TS</given-names></name><name><surname>Mackevicius</surname><given-names>EL</given-names></name><name><surname>Payne</surname><given-names>HL</given-names></name><name><surname>Lynch</surname><given-names>GF</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Growth and splitting of neural sequences in songbird vocal development</article-title><source>Nature</source><volume>528</volume><fpage>352</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1038/nature15741</pub-id><pub-id pub-id-type="pmid">26618871</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Picardo</surname><given-names>MA</given-names></name><name><surname>Merel</surname><given-names>J</given-names></name><name><surname>Katlowitz</surname><given-names>KA</given-names></name><name><surname>Vallentin</surname><given-names>D</given-names></name><name><surname>Okobi</surname><given-names>DE</given-names></name><name><surname>Benezra</surname><given-names>SE</given-names></name><name><surname>Clary</surname><given-names>RC</given-names></name><name><surname>Pnevmatikakis</surname><given-names>EA</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Long</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Population-Level representation of a temporal sequence underlying song production in the zebra finch</article-title><source>Neuron</source><volume>90</volume><fpage>866</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.02.016</pub-id><pub-id pub-id-type="pmid">27196976</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname><given-names>PH</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Developmental determinants of structure in zebra finch song</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>93</volume><fpage>260</fpage><lpage>277</lpage><pub-id pub-id-type="doi">10.1037/h0077553</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>MF</given-names></name><name><surname>Goller</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Breathtaking songs: coordinating the neural circuits for breathing and singing</article-title><source>Physiology</source><volume>31</volume><fpage>442</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1152/physiol.00004.2016</pub-id><pub-id pub-id-type="pmid">27708050</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheintuch</surname><given-names>L</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Brande-Eilat</surname><given-names>N</given-names></name><name><surname>Geva</surname><given-names>N</given-names></name><name><surname>Sadeh</surname><given-names>N</given-names></name><name><surname>Pinchasof</surname><given-names>O</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Tracking the same neurons across multiple days in Ca2+ imaging data</article-title><source>Cell Reports</source><volume>21</volume><fpage>1102</fpage><lpage>1115</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.10.013</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tchernichovski</surname><given-names>O</given-names></name><name><surname>Nottebohm</surname><given-names>F</given-names></name><name><surname>Ho</surname><given-names>CE</given-names></name><name><surname>Pesaran</surname><given-names>B</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A procedure for an automated measurement of song similarity</article-title><source>Animal Behaviour</source><volume>59</volume><fpage>1167</fpage><lpage>1176</lpage><pub-id pub-id-type="doi">10.1006/anbe.1999.1416</pub-id><pub-id pub-id-type="pmid">10877896</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tchernichovski</surname><given-names>O</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name><name><surname>Lints</surname><given-names>T</given-names></name><name><surname>Nottebohm</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamics of the vocal imitation process: how a zebra finch learns its song</article-title><source>Science</source><volume>291</volume><fpage>2564</fpage><lpage>2569</lpage><pub-id pub-id-type="doi">10.1126/science.1058522</pub-id><pub-id pub-id-type="pmid">11283361</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tchernichovski</surname><given-names>O</given-names></name><name><surname>Marcus</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Vocal learning beyond imitation: mechanisms of adaptive vocal development in songbirds and human infants</article-title><source>Current Opinion in Neurobiology</source><volume>28</volume><fpage>42</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.06.002</pub-id><pub-id pub-id-type="pmid">25005823</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vallentin</surname><given-names>D</given-names></name><name><surname>Kosche</surname><given-names>G</given-names></name><name><surname>Lipkind</surname><given-names>D</given-names></name><name><surname>Long</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural circuits. Inhibition protects acquired song segments during vocal learning in zebra finches</article-title><source>Science</source><volume>351</volume><fpage>267</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1126/science.aad3023</pub-id><pub-id pub-id-type="pmid">26816377</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Villette</surname><given-names>V</given-names></name><name><surname>Malvache</surname><given-names>A</given-names></name><name><surname>Tressard</surname><given-names>T</given-names></name><name><surname>Dupuy</surname><given-names>N</given-names></name><name><surname>Cossart</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Internally recurring hippocampal sequences as a population template of spatiotemporal information</article-title><source>Neuron</source><volume>88</volume><fpage>357</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.052</pub-id><pub-id pub-id-type="pmid">26494280</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiesel</surname><given-names>TN</given-names></name><name><surname>Hubel</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Single-Cell responses in striate cortex of kittens deprived of vision in one eye</article-title><source>Journal of Neurophysiology</source><volume>26</volume><fpage>1003</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1152/jn.1963.26.6.1003</pub-id><pub-id pub-id-type="pmid">14084161</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>H</given-names></name><name><surname>Kilander</surname><given-names>K</given-names></name><name><surname>Sotanski</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Untutored song, reproductive success and song learning</article-title><source>Animal Behaviour</source><volume>45</volume><fpage>695</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1006/anbe.1993.1084</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ye</surname><given-names>J</given-names></name><name><surname>Gupta</surname><given-names>P</given-names></name><name><surname>Shah</surname><given-names>P</given-names></name><name><surname>Tiwari</surname><given-names>K</given-names></name><name><surname>Gandhi</surname><given-names>T</given-names></name><name><surname>Ganesh</surname><given-names>S</given-names></name><name><surname>Phillips</surname><given-names>F</given-names></name><name><surname>Levi</surname><given-names>D</given-names></name><name><surname>Thorn</surname><given-names>F</given-names></name><name><surname>Diamond</surname><given-names>S</given-names></name><name><surname>Bex</surname><given-names>P</given-names></name><name><surname>Sinha</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Resilience of temporal processing to early and extended visual deprivation</article-title><source>Vision Research</source><volume>186</volume><fpage>80</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2021.05.004</pub-id><pub-id pub-id-type="pmid">34062374</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>P</given-names></name><name><surname>Resendez</surname><given-names>SL</given-names></name><name><surname>Rodriguez-Romaguera</surname><given-names>J</given-names></name><name><surname>Jimenez</surname><given-names>JC</given-names></name><name><surname>Neufeld</surname><given-names>SQ</given-names></name><name><surname>Giovannucci</surname><given-names>A</given-names></name><name><surname>Friedrich</surname><given-names>J</given-names></name><name><surname>Pnevmatikakis</surname><given-names>EA</given-names></name><name><surname>Stuber</surname><given-names>GD</given-names></name><name><surname>Hen</surname><given-names>R</given-names></name><name><surname>Kheirbek</surname><given-names>MA</given-names></name><name><surname>Sabatini</surname><given-names>BL</given-names></name><name><surname>Kass</surname><given-names>RE</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Efficient and accurate extraction of in vivo calcium signals from microendoscopic video data</article-title><source>eLife</source><volume>7</volume><elocation-id>e28728</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.28728</pub-id><pub-id pub-id-type="pmid">29469809</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77262.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Goldberg</surname><given-names>Jesse H</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05bnh6r87</institution-id><institution>Cornell University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.02.18.480996" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.02.18.480996"/></front-stub><body><p>This fundamental work in songbirds shows that stereotyped neural sequences known to drive the correspondingly stereotyped acoustic structures of adult songs can exist very early in development even when songs are variable and before birds have been provided song models by tutors. The evidence is exceptional and includes imaging activity of populations of premotor neurons in singing birds. This paper provides important insights into the mechanistic foundations of how nature and nurture work together to produce learned motor sequences.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77262.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Goldberg</surname><given-names>Jesse H</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05bnh6r87</institution-id><institution>Cornell University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Cohen</surname><given-names>Yarden</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0316ej306</institution-id><institution>Weizmann Institute of Science</institution></institution-wrap><country>Israel</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.02.18.480996">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.02.18.480996v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Self-organization of songbird neural sequences during social isolation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Ronald Calabrese as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Yarden Cohen (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) In the abstract and elsewhere, the authors write that 'experience is not necessary for the formation of sequences.' This statement is a bit of a reach – this paper exclusively shows that tutor exposure is not necessary for chain formation. It's conceivable that the experiences of deafening, muting or the absence of singing WOULD block chain formation. It's also possible that cohabitation with females – who call – could play some rudimentary auditory experience that helps establish chains. Please edit the language of the manuscript to make sure the conclusions match specific experimental results. Comb the manuscript for use of the work 'experience' and ensure that tutor-experience is what's written.</p><p>2) The adequacy of the sequence detection method (seqNMF) and analyses of its outcomes need further explanation and support. This is especially needed when describing results where sequences are truncated, jittery, or otherwise variable (as some of the results indicate). The presentation of results will be strengthened by:</p><p>2.1. A clear presentation of seqNMF's outcomes and fit to data:</p><p>2.1.1. Explaining in the main text and methods what is meant by 'sequences' that the algorithm extracts. It is not clear if these are cells activating one after the other or any robust spatiotemporal pattern. seqNMF allows seeking 'event based' or 'part based' factorization. Please describe which was used in this manuscript.</p><p>2.1.2. How much of the data variability is explained by sequences?</p><p>2.1.3. How specific are neurons' activity to sequences (compared to its activity not in sequences).</p><p>2.2. Control analyses (or citation if shown elsewhere) can show that the atypical properties of sequences are not confounded by seqNMF.</p><p>2.2.1. For example, measures in Figure 1E-K may be compared to sequences extracted from time-shuffled data. (Similar to the 'sequenciness' approach defined by previous work of the authors[3]).</p><p>2.2.2. Alternatively, if at all possible (because data is limited), results could be compared to analyses carried out on held-out data. For example, sequences can be discovered in training set data and used to calculate results as in Figure 1E-K on test set data.</p><p>2.3. Is it possible to compare sequences (the W's) found before and after training? The claim that they persist needs quantitative support.</p><p>3) The tutoring process and its effects need a clearer presentation.</p><p>3.1. The methods are vague about the process of tutoring (specifically, how many days of tutoring each bird received).</p><p>3.2. When describing (in text and in figure panels) the effect of tutoring it is most helpful to show: (3.2.1) the tutors template, (3.2.2) parts of the template that were copied by the tutee. Currently, the manuscript shows newly adopted syllables but doesn't demonstrate that these syllables were copied from the tutor. (3.2.3) The imitation score. These elaborations on tutor match can be put in a supplemental figure.</p><p>4) In all figures the spectrograms are tiny and it is very difficult to see the link between the identified sequences and the acoustic structure of song. Please revise figures so that the reader does not have to simply depend on somewhat abstracted statistical measures of song locking to absorb the result. Please make spectrograms bigger in the figures.</p><p>Also In Figure 1C, the first and second sequences seem to overlap. E.g., for the second sequence (magenta) the units in the upper sequence also participate. I assume that whether the seqNMF algorithm generates these two sequences or merges them is dependent on the parameters? But either way, how do we interpret these sequences: is the conclusion that the same units participate in more than one sequence (in the same order) or that it is the same, but noisy sequence? How often were different there shared sub-sequences between the identified sequences?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77262.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) In the abstract and elsewhere, the authors write that 'experience is not necessary for the formation of sequences.' This statement is a bit of a reach – this paper exclusively shows that tutor exposure is not necessary for chain formation. It's conceivable that the experiences of deafening, muting or the absence of singing WOULD block chain formation. It's also possible that cohabitation with females – who call – could play some rudimentary auditory experience that helps establish chains. Please edit the language of the manuscript to make sure the conclusions match specific experimental results. Comb the manuscript for use of the work 'experience' and ensure that tutor-experience is what's written.</p></disp-quote><p>The reviewer makes an important point. Our results apply to tutor experience specifically, and do not speak to the possible effects of other types of experience on HVC chain formation. We have edited the abstract to use “tutor experience” instead of “experience” when referring to our work. We combed through the manuscript for cases where “experience” is discussed, and changed this to “tutor experience” wherever the discussion referred to our results.</p><disp-quote content-type="editor-comment"><p>2) The adequacy of the sequence detection method (seqNMF) and analyses of its outcomes need further explanation and support. This is especially needed when describing results where sequences are truncated, jittery, or otherwise variable (as some of the results indicate). The presentation of results will be strengthened by:</p><p>2.1. A clear presentation of seqNMF's outcomes and fit to data:</p></disp-quote><p>We apologize for the lack of clarity, and have expanded our discussion of the seqNMF method, as detailed below.</p><disp-quote content-type="editor-comment"><p>2.1.1. Explaining in the main text and methods what is meant by 'sequences' that the algorithm extracts. It is not clear if these are cells activating one after the other or any robust spatiotemporal pattern. seqNMF allows seeking 'event based' or 'part based' factorization. Please describe which was used in this manuscript.</p></disp-quote><p>We added the following paragraph to the main text to provide additional information about the seqNMF algorithm, and what is meant by ‘sequences’:</p><p>The seqNMF algorithm is designed to find patterns in data, and identify the times when each pattern occurs. It is a generalization of non-negative matrix factorization, allowing for non-synchronous patterns of neural activity, for example sequential firing of neurons in a chain. In the context of seqNMF, a sequence is defined as a pattern of activity in a population of neurons that extends for more than one time step. The algorithm allows for an individual neuron to be active at more than one time in a sequence, but in practice neurons in HVC or the hippocampus are typically active only once in a sequence. Each seqNMF factor is represented as an exemplar sequence <bold><italic>W</italic></bold>, and a vector of times when the sequence occurs, <bold><italic>H</italic></bold>. A sequence in the data is factorized as the convolution of a <bold><italic>W</italic></bold> with its corresponding <bold><italic>H</italic></bold>. Data often contain multiple sequences, each represented by different <bold><italic>W</italic></bold>s and <bold><italic>H</italic></bold>s, and the full data matrix is represented as a sum across all different extracted sequences. Using gradient descent, the algorithm automatically finds sequences that best fit the data, while avoiding redundancies between sequences. It allows for explicitly selecting between ‘parts-based’ and ‘events-based’ factorizations, but here we are agnostic to this distinction, selecting the factorization that best fits the data. SeqNMF has been shown to be robust to several forms of neural variability MackeviciusBahle 2018. In addition, it includes a measure of “sequenciness”, which quantifies the extent to which data are better explained by temporally extended sequences than by synchronized activity. This measure ranges from zero (only synchronized activity) to one (only temporally extended sequences, such that shuffling timebins in the data erases all repeatable structure).</p><p>In addition, we added this clarification to the methods:</p><p>It is possible for seqNMF to extract non-sequential (purely synchronous) patterns of neural activity. SeqNMF measures the extent to which a dataset contains sequential vs. synchronous patterns using a “sequenciness” score, which ranges between 0 and 1. A score of zero indicates that all explanatory power of the factorization is due to synchronous activity, while a score of one indicates that none of the explanatory power is due to synchronous activity. Quantitatively this is calculated by shuffling the timebins in the dataset. In these datasets, both “sequenciness” scores and visual inspection of the factors suggest the presence of temporally extended patterns, which we refer to as sequences.</p><disp-quote content-type="editor-comment"><p>2.1.2. How much of the data variability is explained by sequences?</p></disp-quote><p>On average, 45.21%+-7% of neuronal activity was specific to sequences. We calculated this by binarizing the seqNMF reconstruction and binarizing the data, and computing the correlation between these two matrices, then dividing the norm of the correlation by the norm of the data. As in other analyses, W and H are thresholded by 25% of the 99th percentile. We have added this information to the text.</p><disp-quote content-type="editor-comment"><p>2.1.3. How specific are neurons' activity to sequences (compared to its activity not in sequences).</p></disp-quote><p>In order to show that atypical sequences in isolate birds are not confounded by seqNMF, control analyses were performed by constructing time-shuffled datasets, as in the reviewer’s suggestion 2.2.1, see detail below.</p><disp-quote content-type="editor-comment"><p>2.2. Control analyses (or citation if shown elsewhere) can show that the atypical properties of sequences are not confounded by seqNMF.</p></disp-quote><p>In order to show that atypical sequences in isolate birds are not confounded by seqNMF, control analyses were performed by constructing time-shuffled datasets, as in the reviewer’s suggestion 2.2.1, see detail below.</p><disp-quote content-type="editor-comment"><p>2.2.1. For example, measures in Figure 1E-K may be compared to sequences extracted from time-shuffled data. (Similar to the 'sequenciness' approach defined by previous work of the authors[3]).</p></disp-quote><p>We repeated each of the analyses in Figure 1 for time-shuffled data (independent circular shifting of each neuron, as in the “sequenciness” approach). In the summary plots (participating neurons, reliability, song locking, and coverage), we now include a red line indicating the median value obtained on shuffled data. The results of these control analyses are consistent with the view that seqNMF detects sequences in isolated birds substantially more than expected by chance (time-shuffled data), but these sequences appear less robust than in the adult bird.</p><disp-quote content-type="editor-comment"><p>2.2.2. Alternatively, if at all possible (because data is limited), results could be compared to analyses carried out on held-out data. For example, sequences can be discovered in training set data and used to calculate results as in Figure 1E-K on test set data.</p></disp-quote><p>Given the limited amount of data in pre-tutoring birds, we prefer the control analyses suggested by the reviewer in 2.2.1.</p><disp-quote content-type="editor-comment"><p>2.3. Is it possible to compare sequences (the W's) found before and after training? The claim that they persist needs quantitative support.</p></disp-quote><p>We quantified the correlation between the W’s found before and after tutoring, and are including this information in the main text. We performed two control analyses. In one analysis, we shuffled the identity of the neurons within Wpre. In the second analysis, we circularly shifted the time dimension of each of the neurons within Wpre. In all four learner birds, the correlation between the pre-tutoring and post-tutoring sequences was significantly higher than expected by a time-shuffled control (p=0.014, p=0.018, p=0.0004, p=0.0002, respectively). Additionally, the correlation between pre- and post- tutoring sequences was significantly higher than a neuron-shuffled control in two birds (p=0.0099, p=0.0032), and trended higher in the remaining two birds (p=0.077, p=0.079). We believe the weaker effect in these two birds is because many neurons fire at similar (synchronous) latencies in these birds, one of which is shown in Figure 4c. We have included this information in the text.</p><disp-quote content-type="editor-comment"><p>3) The tutoring process and its effects need a clearer presentation.</p><p>3.1. The methods are vague about the process of tutoring (specifically, how many days of tutoring each bird received).</p></disp-quote><p>Each bird received at least 7 sequential days of tutoring, and the data shown in the paper were acquired during this period. We have clarified this information in the text.</p><disp-quote content-type="editor-comment"><p>3.2. When describing (in text and in figure panels) the effect of tutoring it is most helpful to show: (3.2.1) the tutors template, (3.2.2) parts of the template that were copied by the tutee. Currently, the manuscript shows newly adopted syllables but doesn't demonstrate that these syllables were copied from the tutor. (3.2.3) The imitation score. These elaborations on tutor match can be put in a supplemental figure.</p></disp-quote><p>We thank the reviewers for this suggestion, and have added new supplemental figures for each of the learner birds showing the tutor template, the imitation score, and which syllables in the tutor song are imitated. In each case, the new syllables that emerge after tutoring appear to be imitating syllables in the tutor song, and appear to persist, sometimes differentiating into new variants, and ultimately be used in the learned song.</p><disp-quote content-type="editor-comment"><p>4) In all figures the spectrograms are tiny and it is very difficult to see the link between the identified sequences and the acoustic structure of song. Please revise figures so that the reader does not have to simply depend on somewhat abstracted statistical measures of song locking to absorb the result. Please make spectrograms bigger in the figures.</p></disp-quote><p>We have made the spectrograms larger in all of the figures. In addition, we have included supplemental figures showing large spectrograms and corresponding neural data for each bird for a 6-second bout of pre-tutoring singing data.</p><disp-quote content-type="editor-comment"><p>Also In Figure 1C, the first and second sequences seem to overlap. E.g., for the second sequence (magenta) the units in the upper sequence also participate. I assume that whether the seqNMF algorithm generates these two sequences or merges them is dependent on the parameters? But either way, how do we interpret these sequences: is the conclusion that the same units participate in more than one sequence (in the same order) or that it is the same, but noisy sequence? How often were different there shared sub-sequences between the identified sequences?</p></disp-quote><p>In this bird, the algorithm factorizes this feature of the data as two distinct sequences that are sometimes produced at different times, and sometimes produced concurrently. The possibility of overlapping subsequences is very interesting, and is reminiscent of splitting sequences observed in Okubo et al. It’s clear that this happened in this isolate bird, but examining the other birds, it doesn’t seem to happen in other birds (see new supplemental data figures, showing enlarged spectrograms and neural data for each bird).</p></body></sub-article></article>