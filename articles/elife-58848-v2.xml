<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">58848</article-id><article-id pub-id-type="doi">10.7554/eLife.58848</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Short Report</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural population dynamics in motor cortex are different for reach and grasp</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-189393"><name><surname>Suresh</surname><given-names>Aneesha K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1014-9541</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-189394"><name><surname>Goodman</surname><given-names>James M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6055-0600</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-189395"><name><surname>Okorokova</surname><given-names>Elizaveta V</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2719-2706</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-140468"><name><surname>Kaufman</surname><given-names>Matthew</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-19199"><name><surname>Hatsopoulos</surname><given-names>Nicholas G</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-142999"><name><surname>Bensmaia</surname><given-names>Sliman J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4039-9135</contrib-id><email>sliman@uchicago.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Committee on Computational Neuroscience, University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Department of Organismal Biology and Anatomy, University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Grossman Institute for Neuroscience, Quantitative Biology and Human Behavior, University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Santacruz</surname><given-names>Samantha R</given-names></name><role>Reviewing Editor</role><aff><institution>The University of Texas at Austin</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Ivry</surname><given-names>Richard B</given-names></name><role>Senior Editor</role><aff><institution>University of California, Berkeley</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>17</day><month>11</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e58848</elocation-id><history><date date-type="received" iso-8601-date="2020-05-12"><day>12</day><month>05</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-10-27"><day>27</day><month>10</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Suresh et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Suresh et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-58848-v2.pdf"/><abstract><p>Low-dimensional linear dynamics are observed in neuronal population activity in primary motor cortex (M1) when monkeys make reaching movements. This population-level behavior is consistent with a role for M1 as an autonomous pattern generator that drives muscles to give rise to movement. In the present study, we examine whether similar dynamics are also observed during grasping movements, which involve fundamentally different patterns of kinematics and muscle activations. Using a variety of analytical approaches, we show that M1 does not exhibit such dynamics during grasping movements. Rather, the grasp-related neuronal dynamics in M1 are similar to their counterparts in somatosensory cortex, whose activity is driven primarily by afferent inputs rather than by intrinsic dynamics. The basic structure of the neuronal activity underlying hand control is thus fundamentally different from that underlying arm control.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>motor control</kwd><kwd>hand</kwd><kwd>movement</kwd><kwd>rhesus macaque</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NS082865</award-id><principal-award-recipient><name><surname>Hatsopoulos</surname><given-names>Nicholas G</given-names></name><name><surname>Bensmaia</surname><given-names>Sliman J</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NS096952</award-id><principal-award-recipient><name><surname>Suresh</surname><given-names>Aneesha K</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NS045853</award-id><principal-award-recipient><name><surname>Hatsopoulos</surname><given-names>Nicholas G</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NS111982</award-id><principal-award-recipient><name><surname>Hatsopoulos</surname><given-names>Nicholas G</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NS101325</award-id><principal-award-recipient><name><surname>Bensmaia</surname><given-names>Sliman J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The neuronal activity in primary motor cortex does not exhibit smooth low-dimensional dynamics during grasp as it does during reach.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The responses of populations of neurons in primary motor cortex (M1) exhibit rotational dynamics – reflecting a neural oscillation at the population level – when animals make arm movements, including reaching and cycling (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Lara et al., 2018a</xref>; <xref ref-type="bibr" rid="bib38">Russo et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Shenoy et al., 2013</xref>). One interpretation of this population-level behavior is that M1 acts as a pattern generator that drives muscles to give rise to movement. A major question is whether such population dynamics reflect a general principle of M1 function, or whether they underlie some behaviors and effectors but not others. To address this question, we examined the dynamics in the neuronal population activity during grasping movements, which involve a plant (the hand) that serves a different function, comprises more joints, and is characterized by different mechanical properties (<xref ref-type="bibr" rid="bib34">Rathelot and Strick, 2009</xref>). While the hand is endowed with many degrees of freedom, hand kinematics can be largely accounted for within a small subspace (<xref ref-type="bibr" rid="bib16">Ingram et al., 2008</xref>; <xref ref-type="bibr" rid="bib30">Overduin et al., 2015</xref>; <xref ref-type="bibr" rid="bib40">Santello et al., 1998</xref>; <xref ref-type="bibr" rid="bib48">Tresch and Jarc, 2009</xref>) so we might expect to observe low-dimensional neural dynamics during hand movements, not unlike those observed during arm movements.</p><p>To test this, we recorded the neural activity in M1 using chronically implanted electrode arrays as monkeys performed a grasping task, restricting our analyses to responses before object contact (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Animals were required to hold their arms still at the elbow and shoulder joints as a robotic arm presented each object to their contralateral hand. This task – which can be likened to catching a tossed object or grasping an offered one – limits proximal limb movements and isolates grasping movements. For comparison, we also examined the responses of M1 neurons during a center-out reaching task (<xref ref-type="bibr" rid="bib14">Hatsopoulos et al., 2007</xref>). In addition, we compared grasping responses in M1 to their counterparts in somatosensory cortex (SCx), which is primarily driven by afferent input and therefore should not exhibit autonomous dynamics (<xref ref-type="bibr" rid="bib38">Russo et al., 2018</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>First, we used jPCA to search for rotational dynamics in a low-dimensional manifold of M1 population activity (<xref ref-type="fig" rid="fig1">Figure 1</xref>; <xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>). Replicating previous findings, reaching was associated with a variety of different activity patterns at the single-neuron level (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) that were collectively governed by rotational dynamics at the population level (<xref ref-type="fig" rid="fig1">Figure 1C,E</xref>). During grasp, individual M1 neurons similarly exhibited a variety of different response profiles (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), but rotational dynamics were weak or absent at the population level (<xref ref-type="fig" rid="fig1">Figure 1D,E</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>M1 rotational dynamics during reaching and grasping.</title><p>(<bold>A</bold>) Normalized peri-event histograms aligned to movement onset (black square) for four representative neurons during the reaching task (Monkey 4, Dataset 5). Each shade of gray indicates a different reach direction, trial-averaged for each reaching condition (eight total). (<bold>B</bold>) Normalized peri-event histograms aligned to maximum aperture (black square) for four representative neurons during the grasping task (Monkey 2, Dataset 2). Each shade of blue indicates a neuron’s response, trial-averaged for different object groups. (<bold>C</bold>) Rotational dynamics in the population response during reaching for Monkey 4 (Dataset 5) projected onto the first jPCA plane. Different shades of gray denote different reach directions. (<bold>D</bold>) Lack of similar M1 rotational dynamics during grasping. Different shades of blue indicate different object groups, for Monkey 2 (Dataset 2). (<bold>E</bold>) FVE (fraction of variance explained) in the rate of change of neural PCs (dx/dt) explained by the best fitting rotational dynamical system. The difference in FVE for reach and grasp is significant (two-sample two-sided equal-variance t-test, t(16) = −19.44, p=4.67e-13). Error bars denote standard error of the mean and data points represent the outcomes of cross-validation folds (across conditions – see Materials and methods) for each of two monkeys. (<bold>F</bold>) FVE in the rate of change of neural PCs (dx/dt) explained by the best fitting linear dynamical system, not constrained to be rotational. The difference in FVE is highly significant (two-sample two-sided equal-variance t-test, t(16) = −21.37 p=1.57e-14). Error bars denote standard error of the mean and data points represent the outcomes of cross-validation folds for each of two monkeys (fourfold for reaching data, and 5-fold for grasping data). The lack of dynamical structure during grasping relative to reach is further established in a series of control analyses (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Grasping behavior and neurophysiology.</title><p>Related to Materials and methods. (<bold>A</bold>) Time course of grasp task. Start of Movement, Maximum Aperture, and Grasp epochs were inferred based on hand kinematics. Arrows indicate motion of the robot presenting the object or motion of the hand. (<bold>B</bold>) Multi-electrode arrays were used to record neuronal activity. (<bold>C</bold>) Probability density of the range of motion, where each instance is the difference between the maximum and minimum angle of a joint DOF during a single trial. Instances are pooled across joint DOFs, sessions, and animals. (<bold>D</bold>) Probability density of mean joint angular speed, where each instance is the mean speed of a single joint degree of freedom (DOF) during a single trial. (<bold>E</bold>) Performance of a linear discriminant analysis to decode object identity on the basis of hand posture (DOFs). Objects are most discriminable just before object contact (Grasp) but are also discriminable well above chance long before contact is established (for example, at maximum aperture). Trace indicates the mean, error bars the S.E.M. across monkeys. (<bold>F</bold>) Scree plots, for both reach- and grasp-related M1 responses used in the jPCA analysis, indicating the cumulative variance explained by the first <italic>n</italic> principal components of neural activity. Principal components analysis was applied to rate-normalized, trial-averaged, Gaussian-smoothed firing rates. (<bold>G</bold>) Relationship between the mean speed and mean range of motion for each DOF. Neither the mean joint angular speed (two-sample equal-variance t-test [t(202780) = 0.65, p=0.51) nor the joint angular range of motion (t(202780) = 1.8462, p=0.0649]) differs between reach and grasp. Moreover, the two DOFs tracked during reach follow the same trend as joint DOFs during grasp (R<sup>2</sup> = 0.9820). In other words, grasping and reaching movements are associated with overlapping distributions of joint angular speeds and ranges of motion.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig1-figsupp1-v2.tif"/><permissions><copyright-statement>© 2019, Elsevier</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Elsevier</copyright-holder><license><license-p>Panels A-E and G are reproduced from <xref ref-type="bibr" rid="bib12">Goodman et al., 2019</xref>, with permission from Elsevier. It is not covered by the CC-BY 4.0 licence and further reproduction of this panel would need permission from the copyright holder.</license-p></license></permissions></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Control analyses for reaching and grasping.</title><p>Related to <xref ref-type="fig" rid="fig1">Figure 1</xref>. (<bold>A</bold>) For reaching: cross-validated fraction of variance explained (FVE) in the rate of change of neural PCs (d<italic>x</italic>/dt) explained by the linear dynamical system that best fit the data, with data aligned to target presentation (target) or movement onset (movement). (<bold>B</bold>) For grasping: cross-validated FVE in the rate of change of neural PCs (dx/dt) explained by the linear dynamical system that best fits the data, when the data are aligned to a 500 ms window centered on object presentation (present), a 700 ms window centered on movement onset (mov), and a 700 ms window centered on maximum aperture (max aperture). (<bold>C</bold>) Average peak firing rate across all neurons for arm (gray) and hand (blue) responses. Each point indicates the mean peak rate for a single task condition within a single animal: for ‘arm’, this constitutes eight reaching directions across two animals; for ‘hand’, 35 objects across two animals. (<bold>D</bold>) Average neuronal modulation (90th percentile firing rate – 10th percentile firing rate, before normalization) for arm (gray) and hand (blue) responses. Each point denotes the mean modulation across trials and neurons for a single task condition within a single animal. (<bold>E</bold>) Bootstrapped responses (55 neurons) vs. full sample for reaching. (<bold>F</bold>) Cross-validated FVE in the rate of change of neural PCs (dx/dt) explained by the linear dynamical system that best fits the data when the grasping data are clustered into just a few object groups (see methods). For 8 and 7 clusters, cross validation was achieved on a leave-one-out basis. For 35 clusters, the standard fivefold (leave-7-out) cross-validation was used. Difference between 8 clusters and 35 clusters is significant (p=0.0008) while difference between 7 clusters and 35 clusters is not significant (p=0.57). However, for both clustering methods, the difference between hand and arm remains highly significant (eight clusters| p=2.5e-18; seven clusters | p=2.08e-19). (<bold>G</bold>) Cross-validated FVE for rightward arm movements only compared to all arm movements (right and left). For all figures, except where otherwise indicated, bar heights and solid lines represent the mean, shaded regions and error bars represent standard error of the mean, and each data point represents the result of an individual cross-validation fold for each of two monkeys. (<bold>H</bold>) Cross-validated FVE across various smoothing kernels (10 to 50 ms). Difference between arm and hand remains substantial regardless of smoothing. (<bold>I</bold>) Coefficient of variation (CV) of spike counts across trials within condition. Each point denotes the mean CV across each condition for a single neuron, assessed over 100 ms bins around movement onset (at 250 ms). Results indicate that trial-to-trial variability in neuronal responses is stable over the trial and similar for reach (top) and grasp (bottom).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig1-figsupp2-v2.tif"/></fig></fig-group><p>Given the poor fit of rotational dynamics to neural activity during grasp, we next assessed whether activity could be described by a linear dynamical system of any kind. To test for linear dynamics, we fit a regression model using the first 10 principal components of the M1 population activity (<italic>x</italic>(t)) to predict their rates of change (d<italic>x</italic>/dt). We found <italic>x</italic>(t) to be far less predictive of d<italic>x</italic>/dt in grasp than in reach, suggesting much weaker linear dynamics in M1 during grasp (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). We verified that these results were not an artifact of data alignment, movement epoch, peak firing rate, smoothing, population size, or number of behavioral conditions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p><p>The possibility remains that dynamics are present in M1 during grasp, but that they are higher-dimensional or more nonlinear than during reach. Indeed, M1 population activity during a reach-grasp-manipulate task is higher dimensional than is M1 activity during reach alone (<xref ref-type="bibr" rid="bib36">Rouse and Schieber, 2018</xref>). In light of this, we used Latent Factor Analysis via Dynamical Systems (LFADS) to infer and exploit latent dynamics and thereby improve estimation of single-trial firing rates, then applied a decoder to evaluate the level of improvement. Naturally, the benefit of LFADS is only realized if the neural population acts like a dynamical system. Importantly, such dynamics are minimally constrained and can, in principle, be arbitrarily high dimensional and/or highly nonlinear. First, as expected, we found that in both datasets, neural reconstruction of single trials improved with LFADS (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A,B</xref>). However, LFADS yielded a significantly greater improvement in reconstruction accuracy for reach than for grasp (t(311) = 7.07, p=5.11e-12; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1Β</xref>). Second, a standard Kalman filter was used to decode joint angle kinematics from the inferred latent factors (<xref ref-type="fig" rid="fig2">Figure 2</xref>). If latent dynamics in M1 play a key role in the generation of temporal sequences of muscle activations, which in turn give rise to movement, LFADS should substantially improve kinematic decoding. Replicating previous results, we found decoding accuracy to be substantially improved for reaching when processing firing rates using LFADS (<xref ref-type="fig" rid="fig2">Figure 2A,C</xref>) (R<sup>2</sup> = 0.93 and 0.57 with and without LFADS, respectively). In contrast, LFADS offered minimal improvement in accuracy when decoding grasping kinematics in two monkeys (<xref ref-type="fig" rid="fig2">Figure 2B,C</xref>) (R<sup>2</sup> = 0.46 and 0.37), regardless of the latent dimensionality of the model (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C</xref>) or whether external inputs were included (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1D</xref>). These decoding results demonstrate that the strong dynamical structure seen in the M1 population activity during reach is not observed during grasp, even when dimensionality and linearity constraints are relaxed.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Decoding of kinematics based on population activity pre-processed with Gaussian smoothing or with LFADS.</title><p>(<bold>A</bold>) End-point coordinates of center-out reaching with actual kinematics (top) or kinematics reconstructed with neural data preprocessed with Gaussian smoothing (middle) or LFADS (bottom). Coordinates are color-coded according to the eight directions of movement. While conditions are visually separable in both Gaussian and LFADS reconstructions, the later provides a smoother and more reliable estimate. (<bold>B</bold>) Single-trial time-varying angles of five hand joints (black, dashed) from monkey three as it grasped five objects along with their decoded counterparts (Gaussian-smoothed in green, LFADS-inferred in red). Both Gaussian-smoothed and LFADS-inferred firing rates yield similar decoding errors. Here, ‘4mcp flexion’ refers to flexion/extension of the fourth metacarpophalangeal joint; ‘5pip flexion’ - flexion/extension of the fifth proximal interphalangeal joint; and ‘1cmc flexion’ - flexion/extension of the first carpo-metacarpal joint. (<bold>C</bold>) Difference in performance gauged by the coefficient of determination between decoders with LFADS and Gaussian smoothing for reach (gray) and grasp (blue). Each point denotes the mean performance increase across 10-fold cross-validation of all degrees of freedom pooled across monkeys for reach (2 monkeys with 2 DoFs each) and grasp (2 monkeys with 22 and 29 DoFs, respectively). All decoders were fit using a population of 37 M1 neurons. LFADS leads to significantly larger decoder performance improvement for reach than for grasp. Stars indicate significance of a Mann-Whitney-Wilcoxon test for unmatched samples: *** - alpha of 0.001 for one-sided alternative hypothesis.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Validation of LFADS.</title><p>(<bold>A</bold>) Reconstruction of single trials with Gaussian smoothing and LFADS for reach (top row) and grasp (bottom row). Leftmost column shows PSTHs for eight conditions (color-coded) computed using all training trials. Middle and right columns show single-trial PSTHs for test trials color-coded by condition computed with either gaussian smoothing or LFADS. (<bold>B</bold>) Improvement in the neural reconstruction (change in correlation coefficient) with LFADS compared to Gaussian smoothing for reach (gray) and grasp (blue). Red horizontal lines denote the respective means. Stars indicate significance of two-sample, one-sided t-test (α = 0.001). (<bold>C</bold>) Difference in performance between decoders based on LFADS and Gaussian smoothing (delta R<sup>2</sup>) for reach (gray) and grasp (blue) as a function of latent dimensionality (i.e. number of inferred factors) in the LFADS model. Error bars denote the standard error of the mean for all reconstructed joints pooled from across monkeys. All decoders were trained using a population of 37 M1 neurons. Decoder performance increase with LFADS was significantly larger for reach than for grasp with as few as five dimensions. Stars indicate significance of a one-sided Mann-Whitney-Wilcoxon test for unmatched samples (α = 0.001). Differences are significant for dimensionalities greater than 5. (<bold>D</bold>) Comparison of LFADS with (ordinate) and without (abscissa) the assumption of external inputs to the dynamical system of grasp. In LFADS with inputs, we relaxed the assumption of autonomy and allowed two controllers to perturb the internal dynamics. Each point denotes the mean R<sup>2</sup> for each of 22 DoF of Monkey three in Dataset 3 (grasp 1, light blue) and 29 DoF of Monkey one in Dataset 4 (grasp 2, dark blue). Stars indicate significance of paired-sample one-sided Wilcoxon signed rank test (α = 0.001).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig2-figsupp1-v2.tif"/></fig></fig-group><p>As a separate way to examine the neural dynamics in grasping responses, we computed a neural ‘tangling’ metric, which assesses the degree to which network dynamics are governed by a smooth and consistent flow field (<xref ref-type="bibr" rid="bib38">Russo et al., 2018</xref>). In a smooth, autonomous dynamical system, neural trajectories passing through nearby points in state space should have similar derivatives. The tangling metric (<italic>Q</italic>) assesses the degree to which this is the case over a specified (reduced) number of dimensions. During reaching, muscle activity and movement kinematics have been shown to exhibit more tangling than does M1 activity, presumably because the cortical circuits act as a dynamical pattern generator whereas muscles are input-driven (<xref ref-type="bibr" rid="bib38">Russo et al., 2018</xref>). We replicated these results for reaching: neural activity was much less tangled than the corresponding arm kinematics (position, velocity, and acceleration of joint angles) (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), as long as the subspace was large enough (&gt;2D), (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). For grasp, however, M1 activity was as tangled as the corresponding hand kinematics, or even more so (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), over all subspaces (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Next, we compared tangling in the grasp-related activity in M1 to its counterpart in SCx, which, as a sensory area, is expected to exhibit tangled activity (as shown during reaching movements [<xref ref-type="bibr" rid="bib38">Russo et al., 2018</xref>]). Surprisingly, population activity patterns in both M1 and SCx were similarly tangled during grasp (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). In summary, M1 responses during grasp do not exhibit the properties of an autonomous dynamical system, but rather are tangled to a similar degree as are sensory cortical responses (<xref ref-type="fig" rid="fig3">Figure 3D</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Tangling in reach and grasp.</title><p>(<bold>A</bold>) Tangling metric (Q) for population responses in motor cortex vs. Q for kinematics during reaching. Kinematic tangling is higher than neural tangling, consistent with motor cortex acting as a pattern generation during reach. (<bold>B</bold>) Q-M1 population vs. Q-kinematics for grasping. Neural tangling is higher than kinematic tangling, which argues against pattern generation as the dominant mode during grasp. (<bold>C</bold>) Q-M1 population vs. Q-SCx population. Neural tangling is similar in M1 and SCx. For plots A-C, each point represents the max Q value for a (trial-averaged) neural state at a single time point and single task condition for one monkey (Monkey 1, Dataset 1). (<bold>D</bold>) Log of Q-motor/Q-kinematics of the arm during reach (K<sub>A</sub>), Q-motor/Q-kinematics of the hand during grasp (K<sub>H</sub>), and Q-motor/Q-sensory during grasp (N<sub>s</sub>). Each point represents the log-ratio for a single condition and time point (pooled across two monkeys each). Black bars denote the mean log-ratio. The differences between reaching-derived and grasping-derived log-ratios are significant and substantial (two-sample two-sided equal-variance t-test: K<sub>H</sub> | t(2978)=-43, p=1.03e-130; N<sub>s</sub> |t(2978)=-39 p=1.87e-121). Tangling is insensitive to the precise dimensionality, provided it exceeds a minimum dimensionality (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Tangling vs. dimensionality.</title><p>Left panels correspond to Monkey 1 (Dataset 1), right panels correspond to Monkey 2 (Dataset 2). (<bold>A</bold>) Tangling metric (90th percentile of Q, see Methods) vs. number of dimensions used to compute Q for reaching. Q values derived from motor cortical responses are shown in dark gray, Q values derived from kinematics are shown in light gray. Arm kinematics exhibit consistently higher tangling than do the corresponding population responses in motor cortex. (<bold>B</bold>) Tangling metric vs. number of dimensions used to compute Q for grasp. Q values derived from motor cortical responses are shown in blue, Q-values derived from hand kinematics are shown in green. When Q has leveled off for the kinematic and neural data (~20 dimensions), neuronal trajectories in motor cortex exhibit higher tangling than do the corresponding hand kinematic trajectories. (<bold>C</bold>) Tangling metric vs. number of dimensions used to compute Q for reaching in motor and somatosensory cortex. Q-values derived from motor cortical responses are shown in blue, those derived from somatosensory responses are shown in orange. Grasp-related responses in M1 and SCx exhibit similar tangling.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Dimensionality of grasp-related neuronal responses.</title><p>The first monkey (Dataset 1) performed a distinct grasp for nearly every object while the second monkey (Dataset 2) grasped many objects using very similar grasps, as evidenced by the fact that we could classify objects based on pre-contact hand posture with 84% accuracy for the first monkey and 33% accuracy for the second. These differences in the complexity of manual behaviors were reflected in the complexity of the associated neuronal responses. (<bold>A</bold>) Classification of grasped object based on the population response projected on progressively smaller subspaces – removing high-variance principal components first – remained above chance even after dozens of PCs were removed. (<bold>B</bold>) Continuous decoding of kinematics based on the population response projected on progressively smaller subspaces also remained above chance after removal of dozens of PCs. Classification and decoding performance is well above chance with over 20 dimensions removed, indicating that low-variance PCs still carry information about the behavior. Importantly, while the dimensionality of the response is systematically higher for the first monkey than it is for the second, dynamical systems analyses of both data sets yield identical conclusions. Chance performance was computed by randomly shifting spikes within each trial (preserving the spike count) and applying the Kalman filter to the shuffled spike trains.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58848-fig3-figsupp2-v2.tif"/></fig></fig-group></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We find that M1 does not exhibit low-dimensional dynamics during grasp as it does during reach (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>), reach-to-grasp (<xref ref-type="bibr" rid="bib36">Rouse and Schieber, 2018</xref>), or reach-like center-out pointing (<xref ref-type="bibr" rid="bib31">Pandarinath et al., 2015</xref>). The difference between reach- and grasp-related neuronal dynamics seems to stem from the fundamentally different kinematics and functions of these movements, rather than from effector-specific differences, since dynamics are observed for reach-like finger movements. That rotational dynamics are observed in reach-to-grasp likely reflects the reaching component of the behavior, consistent with the observation that movement signals are broadcast widely throughout motor cortex (<xref ref-type="bibr" rid="bib27">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Stavisky et al., 2019</xref>; <xref ref-type="bibr" rid="bib50">Willett et al., 2020</xref>).</p><p>Other factors might also explain the different dynamical profiles in M1 between reach and grasp. One might conjecture that M1 population dynamics are much higher dimensional and/or more nonlinear for grasp than for reach, which might explain our failure to detect dynamics in grasp-related M1 activity. However, both LFADS (<xref ref-type="bibr" rid="bib32">Pandarinath et al., 2018</xref>; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) and the tangling metric (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) can accommodate high-dimensional systems and some degree of nonlinearity in the dynamics. We verified that our failure to observe dynamics did not stem from a failure to adequately characterize a high-dimensional grasp-related response in M1 commensurate with the dimensionality of the movement (See ‘Dimensionality of the neuronal response’ in the Materials and methods, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). We cannot exclude the possibility that dynamics may be observed in a much higher dimensional space than we can resolve with our sample, one whose dimensionality far exceeds that of the movement itself. To test this hypothesis will require large-scale neural recordings obtained during grasping.</p><p>Another possibility is that M1 dynamics are under greater influence from extrinsic inputs for grasp than for reach: inputs can push neuronal activity away from the trajectories dictated by the intrinsic dynamics, thereby giving rise to tangling. M1 receives input from large swaths of the brain that each exhibit their own dynamics, including the supplementary motor area (<xref ref-type="bibr" rid="bib23">Lara et al., 2018b</xref>; <xref ref-type="bibr" rid="bib39">Russo et al., 2020</xref>), premotor and posterior parietal cortices (<xref ref-type="bibr" rid="bib26">Michaels et al., 2018</xref>), and motor thalamus (<xref ref-type="bibr" rid="bib43">Sauerbrei et al., 2020</xref>), in addition to responding to somatosensory and visual inputs (<xref ref-type="bibr" rid="bib46">Suminski et al., 2010</xref>). Our findings are consistent with the hypothesis that grasp involves more inputs to M1 than does reach, or that grasp-related inputs are more disruptive to the intrinsic dynamics in M1 than are their reach-related counterparts (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>Whatever the case may be, the low-dimensional linear dynamics observed in M1 during reaching are not present during grasping, consistent with an emerging view that the cortical circuits that track and control the hand differ from those that track and control the proximal limb (<xref ref-type="bibr" rid="bib12">Goodman et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Rathelot and Strick, 2009</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Behavior and neurophysiological recordings for grasping task</title><p>We recorded single-unit responses in the primary motor and somatosensory cortices (M1 and SCx) of two monkeys (Macaca mulatta) (M1: N<sub>1</sub> = 58, N<sub>2</sub> = 53 | SCx: N<sub>1</sub> = 26 N<sub>2</sub>=28) as they grasped each of 35 objects an average of 10 times per session. We refer to these recordings as Dataset 1 and Dataset 2, which were recorded from Monkey 1 and Monkey 2, respectively. Neuronal recordings were obtained across 6 and 9 sessions, respectively, and are used in the jPCA and tangling analyses. We also recorded simultaneously from populations of neurons in M1 in two monkeys (N<sub>3</sub> = 44, N<sub>4</sub> = 37) during a single session of this same task. These are called, respectively, Dataset 3 and Dataset 4. The first of these (N<sub>3</sub>) was recorded from a third Monkey, Monkey 3; the second population of simultaneously recorded neurons (N<sub>4</sub>) was obtained from the same monkey (Monkey 1) as the first set of sequentially recorded neurons (N<sub>1</sub>). The recordings in Monkey 1 were achieved with different arrays and separated by 3 years. Simultaneously recorded populations were used for the decoding analyses.</p><p>On each trial (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), one of 25 objects was manually placed on the end of an industrial robotic arm (MELFA RV-1A, Mitsubishi Electric, Tokyo, Japan). After a 1–3 s delay, randomly drawn on a trial-by-trial basis, the robot translated the object toward the animal’s stationary hand. The animal was required to maintain its arms in the primate chair for the trial to proceed: if light sensors on the arm rest became unobstructed before the robot began to move, the trial was aborted. We also confirmed that the animal produced minimal proximal limb movement by inspecting videos of the experiments and from the reconstructed kinematics. The object began 12.8 cm from the animal’s hand and followed a linear trajectory toward the hand at a constant speed of 16 cm/s for a duration of 800 ms. As the object approached, the animal shaped its hand to grasp it. Some of the shapes were presented at different orientations, requiring a different grasping strategy, yielding 35 unique ‘objects’. Each object was presented 8–11 times in a given session.</p><p>The timing of start of movement, maximum aperture, and grasp events were inferred on the basis of the recorded kinematics. A subset of trials from each session were manually scored for each of these three events. On the basis of these training data, joint angular kinematic trajectories spanning 200 ms before and after each frame were used as features to train a multi-class linear discriminant classifier to discriminate among these four classes: all three events of interest and ‘no event’. Log likelihood ratio was used to determine which ‘start of movement’, ‘maximum aperture’, and ‘grasp’ times were most probable relative to ‘no event’. Events were sequentially labeled for each trial to enforce the constraint that start of movement precedes maximum aperture, and maximum aperture precedes grasp. The median interval between the start of movement and maximum aperture was 450 ± 85 ms (median ± interquartile range) for Monkey 1 (across both sets of recordings), 240.0 ± 10.0 ms for Monkey 2, and 456 ± 216 ms for Monkey 3. The interval between maximum aperture and grasp was 356 ± 230 ms for Monkey 1, 410 ± 160 ms for Monkey 2, and 274 ± 145 ms for Monkey 3. Total grasp times from start of movement to grasp were 825 ± 280 ms for Monkey 1, 650 ± 170 ms for Monkey 2, and 755 ± 303 ms for Monkey 3.</p><p>Neural recordings were obtained from two monkeys (N<sub>1</sub> and N<sub>2</sub>) using semi-chronic electrode arrays (SC96 arrays, Gray Matter Research, Bozeman, MT) (<xref ref-type="bibr" rid="bib10">Dotson et al., 2017</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Electrodes, which were individually depth-adjustable, were moved to different depths on different sessions to capture new units. Units spanning both M1 and SCx were recorded using these arrays, and SCx data comprise populations from both proprioceptive subdivisions of SCx, namely, Brodmann’s areas 3a and 2. Simultaneous neural recordings were obtained from one monkey (N<sub>3</sub>) using a combination of Utah electrode arrays (UEAs, Blackrock Microsystems, Inc, Salt Lake City, UT) and floating microelectrode arrays (FMAs, Microprobes for Life Science, Gaithersburg, MD) targeting rostral and caudal subdivisions of the hand representation of M1, respectively. In the other monkey (N<sub>4</sub>), simultaneous population recordings were obtained using a single 64-channel Utah array targeting the hand representation of (rostral) M1. Single units from all sessions (treated as distinct units) were extracted using an Offline Sorter (Plexon Inc, Dallas TX). Units were identified based on inter-spike interval distribution and waveform shape and size.</p><p>Hand joint kinematics, namely the angles and angular velocities about all motile axes of rotation in the joints of the wrist and digits, were tracked at a rate of 100 Hz by means of a 14-camera motion tracking system (MX-T series, VICON, Los Angeles, CA). The VICON system tracked the three-dimensional positions of the markers, and time-varying joint angles were computed using inverse kinematics based on a musculoskeletal model of the human arm (<ext-link ext-link-type="uri" xlink:href="https://simtk.org/projects/ulb_project">https://simtk.org/projects/ulb_project</ext-link>) (<xref ref-type="bibr" rid="bib2">Anderson and Pandy, 2001</xref>; <xref ref-type="bibr" rid="bib1">Anderson and Pandy, 1999</xref>; <xref ref-type="bibr" rid="bib6">de Leva, 1996</xref>; <xref ref-type="bibr" rid="bib7">Delp et al., 1990</xref>; <xref ref-type="bibr" rid="bib9">Dempster and Gaughran, 1967</xref>; <xref ref-type="bibr" rid="bib15">Holzbaur et al., 2005</xref>; <xref ref-type="bibr" rid="bib52">Yamaguchi and Zajac, 1989</xref>) implemented in Opensim (<ext-link ext-link-type="uri" xlink:href="https://simtk.org/frs/index.php?group_id=91">https://simtk.org/frs/index.php?group_id=91</ext-link>) (<xref ref-type="bibr" rid="bib8">Delp et al., 2007</xref>) with segments scaled to the sizes of those in a monkey limb using Opensim’s built-in scaling function. Task and kinematic recording methods are reported in an earlier publication (<xref ref-type="bibr" rid="bib12">Goodman et al., 2019</xref>). We used a linear discriminant classifier as detailed in this previous publication to determine whether objects indeed evoked distinct kinematics (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><p>All surgical, behavioral, and experimental procedures conformed to the guidelines of the National Institutes of Health and were approved by the University of Chicago Institutional Animal Care and Use Committee.</p></sec><sec id="s4-2"><title>Behavior and neurophysiological recordings for reaching task</title><p>To compare grasp to reach, we analyzed previously published single- and multi-unit responses from two additional M1 populations (M1: N<sub>5</sub> = 76, N<sub>6</sub> = 107) recorded from two additional monkeys (Monkeys 4 and 5, respectively) operantly trained to move a cursor in a variable delay center out reaching task (<xref ref-type="bibr" rid="bib14">Hatsopoulos et al., 2007</xref>). These recordings are called Dataset 5 and Dataset 6, respectively. The monkey’s arm rested on cushioned arm troughs secured to links of a two-joint exoskeletal robotic arm (KINARM system; BKIN Technologies, Kingston, Ontario, Canada) underneath a projection surface. The shoulder and elbow joint angles were sampled at 500 Hz by the motor encoders of the robotic arm, and the <italic>x</italic> and <italic>y</italic> positions of the hand were computed using the forward kinematic equations. The center-out task involved movements from a center target to one of eight peripherally positioned targets (5 to 7 cm away). Targets were radially defined, spanning a full 360° rotation about the central target in 45° increments. Each trial comprised two epochs: first, an instruction period lasting 1 to 1.5 s, during which the monkey held its hand over the center target to make the peripheral target appear; second, a ‘go’ period, cued by blinking of the peripheral target, which indicated to the monkey that it could begin to move toward the target. Following the ‘go’ cue, movement onset was 324 ± 106 ms (median ± interquartile range) for Monkey 4 in Dataset 5, and 580 ± 482 ms for Monkey 5 in Dataset 6. Total movement duration was 516 ± 336 ms for Monkey 4 in Dataset 5 and 736 ± 545 ms for Monkey 5 in Dataset 6. Single- and multi-unit activities were recorded from each monkey during the course of a single session using an UEA implanted in the upper limb representation of contralateral M1. All surgical, behavioral, and experimental procedures conformed to the guidelines of the National Institutes of Health and were approved by the University of Chicago Institutional Animal Care and Use Committee.</p><p>Information about all grasping and reaching datasets and their associated analyses is provided in Table 1 of <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>.</p></sec><sec id="s4-3"><title>Differences between reach and grasp and their potential implications for population dynamics</title><p>In this section, we discuss differences between the reach and grasp tasks that might have had an impact on the neuronal dynamics.</p><p>First, movements were cued differently in the two tasks. For reaching, targets blinked to cue movement. For grasping, there was no explicit movement cue; rather, the animals could begin preshaping their hand as soon as the robot began to move, although they had to wait for the object to reach the hand to complete their grasp and obtain a reward. Nonetheless, we found that the delay between the beginning of the robot’s approach and hand movement onset (median ± interquartile range: Monkey 1 – 271 ± 100 ms; Monkey 2 – 419 ± 101 ms; numbers not available for Monkey 3) was similar to the delay in the reaching task between the go cue and start of movement. Note, moreover, that the nature of the ‘delay’ period should have little effect on neuronal dynamics. Indeed, self-initiated reaches and those that are executed rapidly with little to no preparation are nonetheless associated with rotational M1 dynamics (<xref ref-type="bibr" rid="bib22">Lara et al., 2018a</xref>).</p><p>Second, the kinematics of reaching and grasping are quite different, and differences in the respective ranges of motion or speeds could mediate the observed differences in neuronal dynamics. However, the ranges of motion and distribution of speeds were similar for reach and grasp (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C–D,G</xref>), suggesting that the observed differences in neuronal dynamics are not trivial consequences of differences in the kinematics. On a related note, grasping movements with no reach (lasting roughly 700 ms) were generally slower than those reported in in the context of reach (lasting roughly 300 ms) (<xref ref-type="bibr" rid="bib3">Bonini et al., 2014</xref>; <xref ref-type="bibr" rid="bib4">Chen et al., 2009</xref>; <xref ref-type="bibr" rid="bib24">Lehmann and Scherberger, 2013</xref>; <xref ref-type="bibr" rid="bib35">Rouse and Schieber, 2015</xref>; <xref ref-type="bibr" rid="bib37">Roy et al., 2000</xref>; <xref ref-type="bibr" rid="bib47">Theverapperuma et al., 2006</xref>), as the animals had to wait for the robot to transport the object to their hand. Note, however, that similar constraints on movement duration and speed during reaching do not affect the presence or nature of M1 rotational dynamics during those movements (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>). As such, speed differences should not lead to qualitatively different M1 population dynamics.</p><p>Third, we considered whether grasping without reaching might simply be too ‘unnatural’ to be controlled by stereotyped M1 dynamics. However, we observed the presence of two hallmarks of grasping behavior: a clearly-defined maximum aperture phase and the presence of hand pre-shaping (<xref ref-type="bibr" rid="bib18">Jeannerod, 1984</xref>; <xref ref-type="bibr" rid="bib17">Jeannerod, 1981</xref>; <xref ref-type="bibr" rid="bib41">Santello et al., 2002</xref>; <xref ref-type="bibr" rid="bib42">Santello and Soechting, 1998</xref>). The latter is evidenced by a gradual improvement in our ability to classify objects based on the kinematics they evoke as the trial proceeded (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref>): Upon start of movement, the hand is in a generic configuration that is independent of the presented object. However, as the trial proceeds, hand kinematics become increasingly object-specific, culminating in a high classification performance just before object contact. Furthermore, grasping kinematics have been previously shown to be robust to different types of reaches (<xref ref-type="bibr" rid="bib49">Wang and Stelmach, 1998</xref>).</p></sec><sec id="s4-4"><title>Data analysis</title><sec id="s4-4-1"><title>Data pre-processing</title><p>For both reach and grasp, neuronal responses were aligned to the start of movement, resampled at 100 Hz so that they would be at the same temporal resolution, averaged across trials, then smoothed by convolution with a Gaussian (25 ms S.D.). For jPCA, we then followed the data pre-processing steps described in <xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>: normalization of individual neuronal firing rates, subtraction of the cross-condition mean peri-event time histogram (PETH) from each neuron’s response in each condition, and applying principal component analysis (PCA) to reduce the dimensionality of the population response. For LFADS and the tangling analyses, only the normalization of neurons’ firing rates was performed. Although the condition-invariant response varies in a meaningful way (<xref ref-type="bibr" rid="bib20">Kaufman et al., 2016</xref>), its inclusion obstructs our ability to use jPCA to visualize neural trajectories whose initial conditions vary, and thus our ability to use jPCA to evaluate claims of dynamical structure. Even when this component is especially large, dynamical structure in the remaining condition-dependent neural activity has been observed (<xref ref-type="bibr" rid="bib36">Rouse and Schieber, 2018</xref>), thus subtraction of even a large condition-independent response should permit the inference of neural dynamics. We used 10 dimensions instead of six (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>) as a compromise between the lower dimensional reach data and the higher dimensional grasp data.</p></sec><sec id="s4-4-2"><title>jPCA</title><p>We applied to the population data (reduced to 10 dimensions by PCA) a published dimensionality reduction method, jPCA (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>), which finds orthonormal basis projections that capture rotational structure in the data. We used a similar number of dimensions for both reach and grasp, as PCA revealed no stark differences in the effective dimensionality of the neural population between the two tasks (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>). With jPCA, the neural state is compared with its derivative, and the strictly rotational dynamical system that explains the largest fraction of variance in that derivative is identified. The delay periods between the presentation/go-cue for each monkey varied, along with the reaction times, so we selected a single time interval (averaging 700 ms) that maximized rotational variance across all of them. For the reach data, data were aligned to the start of movement and the analysis window was centered on this event, whereas for the grasp data, data were aligned to maximum hand aperture, and we analyzed the interval centered on this event. In some cases, the center of this 700 ms window was shifted between −350 ms to +350 ms relative to the alignment event to obtain an estimate of how rotational dynamics change over the course of the trial (e.g. <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). These events were chosen for alignment as they were associated with both the largest peak firing rates and the strongest rotational dynamics. Other alignment events were also tested, to test robustness (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2B</xref>).</p></sec><sec id="s4-4-3"><title>Object clustering</title><p>Each of the 35 objects was presented 10 times per session, which yields a smaller number of trials per condition than were used to assess jPCA during reaching (at least 40). To permit pooling across a larger number of trials when visualizing and quantifying population dynamics with jPCA (<xref ref-type="fig" rid="fig1">Figure 1</xref>), objects in the grasp task were grouped into eight object clusters on the basis of the trial-averaged similarity of hand posture across all 30 joint degrees of freedom 10 ms prior to grasp (i.e. object contact). Objects were hierarchically clustered into eight clusters on the basis of the Ward linkage function (MATLAB <monospace>clusterdata</monospace>). Eight clusters were chosen to match the number of conditions in the reaching task. Cluster sizes were not uniform; the smallest comprised two and the largest nine different objects, with the median cluster comprising four objects.</p><p>As the clustering method just described yielded different cluster sizes, we assessed an alternative clustering procedure (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2F</xref>) that guaranteed objects were divided into seven equally-sized clusters (five objects per cluster). Rather than determining cluster membership on the basis of a linkage threshold, cluster linkages were instead used to sort the objects on the basis of their dendrogram placements (MATLAB dendrogram). Clusters were obtained by grouping the first five objects in this sorted list into a common cluster, then the next five, and so on. This resulted in slightly poorer performance of jPCA (see <italic>Quantification</italic>).</p><p>For completeness, we also assessed jPCA without clustering (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2E</xref>), which also resulted in slightly poorer performance of jPCA and was considerably more difficult to visualize given the large number of conditions.</p></sec><sec id="s4-4-4"><title>Quantification</title><p>In a linear dynamical system, the derivative of the state is a linear function of the state. We wished to assess whether a linear dynamical system could account for the neural activity. To this end, we first produced a de-noised low-dimensional neural state (<italic>X</italic>) by reducing the dimensionality of the neuronal responses to 10 using PCA. Second, we numerically differentiated <italic>X</italic> to estimate the derivative, <inline-formula><mml:math id="inf1"><mml:mover accent="true"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>. Next, we used regression to fit a linear model, predicting the derivative of the neuronal state from the current state: <inline-formula><mml:math id="inf2"><mml:mover accent="true"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mi>X</mml:mi></mml:math></inline-formula>. Finally, we computed the fraction of variance explained (FVE) by this model:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mi>V</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>M</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><italic>M</italic> was constrained to be skew-symmetric (<inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) unless otherwise specified; <inline-formula><mml:math id="inf4"><mml:mfenced close="⟩" open="⟨" separators="|"><mml:mrow><mml:mo>∙</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> indicates the mean of a matrix across samples, but not across dimensions; and <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mfenced close="‖" open="‖" separators="|"><mml:mrow><mml:mo>∙</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> indicates the Frobenius norm of a matrix. Unless otherwise specified, analysis of reaching data from each monkey was fourfold cross-validated, whereas analysis of grasp data was 5-fold cross-validated.</p></sec><sec id="s4-4-5"><title>Control comparisons between arm and hand data</title><p>We performed several controls comparing arm and hand data to ensure that our results were not an artifact of trivial differences in the data or pre-processing steps.</p><p>First, we considered whether alignment of the data to different events might impact results. For the arm data, we aligned each trial to target onset and movement onset (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A</xref>). For the hand data, we aligned each trial to presentation of the object, movement onset, and the time at which the hand reached maximum aperture during grasp (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2B</xref>). Linear dynamics were strongest (although still very weak) when neuronal responses were aligned to maximum aperture, so this alignment is reported throughout the main text.</p><p>Second, we assessed whether rotations might be obscured due to differences in firing rates in the hand vs. arm responses. To this end, we compared peak firing rates for trial-averaged data from the arm and hand after pre-processing (excluding normalization) to directly contrast the inputs to the jPCA analysis given the two effectors/tasks (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>). Peak firing rates were actually higher for the hand than the arm, eliminating the possibility that our failure to observe dynamics during grasp was a consequence of weak responses. We also verified that differences in dynamics could not be attributed to differences in the degree to which neurons were modulated in the two tasks. To this end, we computed the modulation range (90th percentile firing – 10th percentile firing) and found that modulation was similar in reach and grasp (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2D</xref>).</p><p>Third, we assessed whether differences in the sample size might contribute to differences in variance explained (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2E</xref>). To this end, we took five random samples of 55 neurons from the reaching data set – chosen to match the minimum number of neurons in the grasping data – and computed the cross-validated fraction of variance explained by the rotational dynamics. The smaller samples yielded identical fits as the full sample.</p><p>Fourth, we assessed whether the low variance explained by linear dynamics in the hand might be due to poor sampling of the joint motion space (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2G</xref>). To this end, we computed FVE for only rightward reaches, and found that the variance explained for all directions versus only rightward reaches were comparable. Therefore, we expect that our sampling of hand motions would not affect our ability to observe linear dynamics.</p><p>Fifth, we considered whether our smoothing kernel might impact results (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2H</xref>). We compared the FVE for the optimal linear dynamical system across various smooth kernels – from 5 to 40 ms – and found that the difference between hand and arm dynamics remains substantial regardless of kernel width.</p><p>Finally, since our analyses involve averaging across trials, we assessed whether trial-to-trial variability was different for reach and grasp. To this end, we computed for each neuron the coefficient of variation (CV) of spike counts over 100 ms bins around movement onset. We found the trial-to-trial variability to be stable over the trial and similar for reach and grasp (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2I</xref>).</p></sec></sec><sec id="s4-5"><title>Decoding</title><sec id="s4-5-1"><title>Preprocessing</title><p>For decoding, we preprocessed the neural data using one of two methods: smoothing with a Gaussian kernel (σ = 20 ms) or latent factor analysis via dynamical systems (LFADS) (<xref ref-type="bibr" rid="bib32">Pandarinath et al., 2018</xref>). LFADS is a generative model that assumes that observed spiking responses arise from an underlying dynamical system and estimates that system using deep learning. We used the same number of neurons in the reaching and grasping analyses to train the LFADS models and fixed the number of factors in all models to 30, at which performance of both reach and grasp models had levelled off (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C</xref>). We allowed two continuous controllers while training the model, which could potentially capture the influence of external inputs on dynamics (<xref ref-type="bibr" rid="bib32">Pandarinath et al., 2018</xref>), since these had significant positive influence on decoding performance (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1D</xref>). Hyper-parameter tuning was performed as previously described (<xref ref-type="bibr" rid="bib21">Keshtkaran and Pandarinath, 2019</xref>).</p></sec><sec id="s4-5-2"><title>Neural reconstruction</title><p>To compare our ability to reconstruct single-trial responses using Gaussian smoothing and LFADS, we first computed peri-event time histograms (PETHs) within condition using all training trials (excluding one test trial). We then computed the correlation between the firing rates of each test trial (smoothed with a Gaussian kernel or reconstructed with LFADS) with the PETH of the corresponding condition averaged across the training trails (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>). We repeated this procedure with a different trial left out for each condition. We report the difference in correlation coefficient obtained after LFADS processing and Gaussian smoothing (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>).</p></sec><sec id="s4-5-3"><title>Kalman filter</title><p>To predict hand and arm kinematics, we applied the Kalman filter (<xref ref-type="bibr" rid="bib19">Kalman, 1960</xref>), commonly used for kinematic decoding (<xref ref-type="bibr" rid="bib25">Menz et al., 2015</xref>; <xref ref-type="bibr" rid="bib29">Okorokova et al., 2020</xref>; <xref ref-type="bibr" rid="bib51">Wu et al., 2004</xref>). In this approach, kinematic dynamics can be described by a linear relationship between past and future states:<disp-formula id="equ2"><label>(3)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a vector of joint angles at time <inline-formula><mml:math id="inf7"><mml:mi>t</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf8"><mml:mi>A</mml:mi></mml:math></inline-formula> is a state transition matrix, and <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a vector of random numbers drawn from a Gaussian distribution with zero mean and covariance matrix <inline-formula><mml:math id="inf10"><mml:mi>V</mml:mi></mml:math></inline-formula>. The kinematics <inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> can be also explained in terms of the observed neural activity <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ3"><label>(4)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a vector of instantaneous firing rates across a population of M1 neurons at time <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, preprocessed either with Gaussian kernel or LFADS, <italic>B</italic> is an observation model matrix, and <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a random vector drawn from a Gaussian distribution with zero mean and covariance matrix <italic>W</italic>. We tested multiple values of the latency, Δ, and report decoders using the latency that maximized decoder accuracy (150 ms).</p><p>We estimated the matrices <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> using linear regression on each training set, and then used those estimates in the Kalman filter update algorithm to infer the kinematics of each corresponding test set (see <xref ref-type="bibr" rid="bib11">Faragher, 2012</xref>; <xref ref-type="bibr" rid="bib28">Okorokova et al., 2015</xref> for details). Briefly, at each time <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, kinematics were first predicted using the state transition equation (3), then updated with observation information from equation (4). Update of the kinematic prediction was achieved by a weighted average of the two estimates from (3) and (4): the weight of each estimate was inversely proportional to its uncertainty (determined in part by <italic>V</italic> and <italic>W</italic> for the estimates based on <italic>x<sub>t-1</sub></italic> and <italic>z<sub>t-Δ</sub></italic>, respectively), which changed as a function of time and was thus recomputed for every time step.</p><p>To assess decoding performance, we performed 10-fold cross-validation in which we trained the parameters of the filter on a randomly selected 90% of the trials and tested the model using the remaining 10% of trials. Importantly, we trained separate Kalman filters for the two types of neural preprocessing techniques (Gaussian smoothing and LFADS) and then compared their performance on the same trials. Performance was quantified using the coefficient of determination (<inline-formula><mml:math id="inf18"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>) for the held-out trials across test sets.</p></sec><sec id="s4-5-4"><title>Tangling</title><p>We computed tangling of the neural population data (reduced to 20 dimensions by PCA) using a published method (<xref ref-type="bibr" rid="bib38">Russo et al., 2018</xref>). In brief, the tangling metric estimates the extent to which neural population trajectories are inconsistent with what would be expected if they were governed by an autonomous dynamical system, with smaller values indicating consistency with such dynamical structure. Specifically, tangling measures the degree to which similar neural states, either during different movements or at different times for the same movement, are associated with different derivatives. This is done by finding, for each neural state (indexed by <inline-formula><mml:math id="inf19"><mml:mi>t</mml:mi></mml:math></inline-formula>), the maximum value of the tangling metric <inline-formula><mml:math id="inf20"><mml:mi>Q</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> across all other neural states (indexed by <inline-formula><mml:math id="inf21"><mml:mi>t</mml:mi><mml:mi>'</mml:mi></mml:math></inline-formula>):<disp-formula id="equ4"><label>(2)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo form="prefix" movablelimits="true">max</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mfrac><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the neural state at time <italic>t</italic> (a 20-dimensional vector containing the neural responses at that time), <inline-formula><mml:math id="inf23"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula> is the temporal derivative of the neural state (estimated numerically), and <inline-formula><mml:math id="inf24"><mml:mfenced close="‖" open="‖" separators="|"><mml:mrow><mml:mo>∙</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is the Euclidean norm, while <inline-formula><mml:math id="inf25"><mml:mi>ε</mml:mi></mml:math></inline-formula> is a small constant added for robustness to noise (<xref ref-type="bibr" rid="bib38">Russo et al., 2018</xref>). This analysis is not constrained to work solely for neural data; indeed, we also apply this same analysis to trajectories of joint angular kinematics to compare their tangling to that of neural trajectories.</p><p>The neural data were pre-processed using the same alignment, trial averaging, smoothing, and normalization methods described above. Joint angles were collected for both hand and arm data. For this analysis, joint angle velocity and acceleration were computed (six total dimensions for arm, 90 dimensions for hand). For reaching, we analyzed the epoch from 200 ms before to 100 ms after movement onset. For grasping, we analyzed the epoch starting 200 ms before to 100 ms after maximum aperture. Neuronal responses were binned in 10 ms bins to match the sampling rate of the kinematics.</p><p>The tangling metric is partially dependent on the dimensionality of the underlying data. To eliminate the possibility that our results were a trivial consequence of selecting a particular number of principal components, we tested tangling at different dimensionalities and selected the dimensionality at which Q had largely leveled off for both the population neural activity and kinematics (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Namely, we report results using six principal components (the maximum) for reach kinematics and their associated neural responses, and using 20 for kinematics and neuronal responses during grasp.</p></sec><sec id="s4-5-5"><title>Dimensionality of the neuronal response</title><p>One possibility is that our failure to observe autonomous dynamics during grasp stems from a failure to properly characterize the neural manifold, which in principle could be much higher dimensional for grasp than it is for reach. However, the first D dimensions of a manifold can be reliably estimated from fewer than 2*D projections if two conditions hold: the eigenvalue spectrum is not flat, and the samples approximate random projections of the underlying manifold (<xref ref-type="bibr" rid="bib13">Halko et al., 2011</xref>). The scree plot shows that the first condition is met (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>). To evaluate the second condition and determine whether neurons are random projections of the low-dimensional manifold, we applied a Gine-Ajne test (<xref ref-type="bibr" rid="bib33">Prentice, 1978</xref>) to the first 5, 10, and 20 PCs. We found that the null hypothesis of spherical uniformity was not rejected (p&gt;0.5 for all dimensionalities and data sets). While we cannot rule out that the possibility that there exists a small, unrecorded fraction of neurons that span a disjoint manifold subspace from that we measured, the failure to reject spherical uniformity provides evidence that these neurons approximate random projections. To further examine the possibility that dynamics occupy a space that we were unable to resolve with our neuronal sample, we implemented LFADS with a different number of latent factors. We found that, to the extent that decoding performance improved with additional latent factors, it levelled off at ~10 factors (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). If the dynamics were distributed over a high-dimensional manifold, we might expect that performance would increase slowly with the number of latent factors over the entire range afforded by the sample size. This was not the case.</p><p>Yet another possibility we considered is that the neuronal manifold beyond the first few dimensions reflects noise, which would preclude the identification of dynamics embedded in higher order dimensions. To examine this possibility, we assessed our ability to relate the monkeys’ behavior during the grasp task to the neural data over subsets of dimensions. First, we found that the ability to classify objects based on the population response projected on progressively smaller subspaces – removing high-variance principal components first – remained above chance even after dozens of PCs were removed. This suggests that behaviorally relevant neuronal activity was distributed over many dimensions, and that this signal clearly rose above the noise (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A</xref>). For this analysis, we used multiclass linear discriminant analysis based on population responses evoked over a 150 ms window before object contact. Second, we found that the ability to decode kinematics based on the population response projected on progressively smaller subspaces remained above chance after removal of many PCs, consistent with the classification analysis (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B</xref>). For this analysis, we used population responses over an 800 ms window centered on maximum aperture for reaching and movement onset for grasping. Thus, high-order PCs do not simply reflect noise but rather comprise behaviorally relevant signals.</p><p>In summary, then, our sample size is sufficient, in principle, to recover dynamics embedded in a high-dimensional manifold. The weak dynamics in the grasping response that we did recover occupy a low-dimensional manifold, and we were able to resolve the population response for the grasping behavior across a large number of dimensions (40+ principal components).</p></sec></sec><sec id="s4-6"><title>Statistics</title><p>For most of analyses, sample sizes were large and data were distributed approximately normally so we used two-sided t-test. However, for some analyses, the data were right-skewed and the sample size was small, so we used non-parametric tests, either the Wilcoxon signed rank test or the Mann-Whitney-Wilcoxon test depending on whether the samples were matched (for example, comparison of same kinematic DoFs reconstructed with either Gaussian smoothing or LFADS) or not (for example, comparison of kinematic DoFs reconstruction from different datasets).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Sangwook A Lee, Gregg A Tabot and Alexander T Rajan for help with data collection, as well as Mohammad Reza Keshtkaran and Chethan Pandarinath for help with the LFADS implementation. This work was supported by NINDS grants NS082865, NS101325, NS096952, NS045853, and NS111982.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Formal analysis, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Supervision, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Funding acquisition, Investigation, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Supervision, Funding acquisition, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All surgical, behavioral, and experimental procedures conformed to the guidelines of the National Institutes of Health and were approved by the University of Chicago Institutional Animal Care and Use Committee (#72042).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Datasets and related analyses and figures.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-58848-supp1-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The data that support the findings of this study have been deposited in Dryad, accessible at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.xsj3tx9cm">https://doi.org/10.5061/dryad.xsj3tx9cm</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Suresh</surname><given-names>AK</given-names></name><name><surname>Goodman</surname><given-names>JM</given-names></name><name><surname>Okorokova</surname><given-names>EV</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Hatsopoulos</surname><given-names>NG</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Neural population dynamics in motor cortex are different for reach and grasp</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.xsj3tx9cm</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>FC</given-names></name><name><surname>Pandy</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>A dynamic optimization solution for vertical jumping in three dimensions</article-title><source>Computer Methods in Biomechanics and Biomedical Engineering</source><volume>2</volume><fpage>201</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1080/10255849908907988</pub-id><pub-id pub-id-type="pmid">11264828</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>FC</given-names></name><name><surname>Pandy</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamic optimization of human walking</article-title><source>Journal of Biomechanical Engineering</source><volume>123</volume><fpage>381</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1115/1.1392310</pub-id><pub-id pub-id-type="pmid">11601721</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonini</surname> <given-names>L</given-names></name><name><surname>Maranesi</surname> <given-names>M</given-names></name><name><surname>Livi</surname> <given-names>A</given-names></name><name><surname>Fogassi</surname> <given-names>L</given-names></name><name><surname>Rizzolatti</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Space-dependent representation of objects and other's action in monkey ventral premotor grasping neurons</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>4108</fpage><lpage>4119</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4187-13.2014</pub-id><pub-id pub-id-type="pmid">24623789</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Reitzen</surname> <given-names>SD</given-names></name><name><surname>Kohlenstein</surname> <given-names>JB</given-names></name><name><surname>Gardner</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural representation of hand kinematics during prehension in posterior parietal cortex of the macaque monkey</article-title><source>Journal of Neurophysiology</source><volume>102</volume><fpage>3310</fpage><lpage>3328</lpage><pub-id pub-id-type="doi">10.1152/jn.90942.2008</pub-id><pub-id pub-id-type="pmid">19793876</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Foster</surname> <given-names>JD</given-names></name><name><surname>Nuyujukian</surname> <given-names>P</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Leva</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Adjustments to Zatsiorsky-Seluyanov's segment inertia parameters</article-title><source>Journal of Biomechanics</source><volume>29</volume><fpage>1223</fpage><lpage>1230</lpage><pub-id pub-id-type="doi">10.1016/0021-9290(95)00178-6</pub-id><pub-id pub-id-type="pmid">8872282</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delp</surname> <given-names>SL</given-names></name><name><surname>Loan</surname> <given-names>JP</given-names></name><name><surname>Hoy</surname> <given-names>MG</given-names></name><name><surname>Zajac</surname> <given-names>FE</given-names></name><name><surname>Topp</surname> <given-names>EL</given-names></name><name><surname>Rosen</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>An interactive graphics-based model of the lower extremity to study orthopaedic surgical procedures</article-title><source>IEEE Transactions on Biomedical Engineering</source><volume>37</volume><fpage>757</fpage><lpage>767</lpage><pub-id pub-id-type="doi">10.1109/10.102791</pub-id><pub-id pub-id-type="pmid">2210784</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delp</surname> <given-names>SL</given-names></name><name><surname>Anderson</surname> <given-names>FC</given-names></name><name><surname>Arnold</surname> <given-names>AS</given-names></name><name><surname>Loan</surname> <given-names>P</given-names></name><name><surname>Habib</surname> <given-names>A</given-names></name><name><surname>John</surname> <given-names>CT</given-names></name><name><surname>Guendelman</surname> <given-names>E</given-names></name><name><surname>Thelen</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>OpenSim: open-source software to create and analyze Dynamic simulations of movement</article-title><source>IEEE Transactions on Bio-Medical Engineering</source><volume>54</volume><fpage>1940</fpage><lpage>1950</lpage><pub-id pub-id-type="doi">10.1109/TBME.2007.901024</pub-id><pub-id pub-id-type="pmid">18018689</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dempster</surname> <given-names>WT</given-names></name><name><surname>Gaughran</surname> <given-names>GRL</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Properties of body segments based on size and weight</article-title><source>American Journal of Anatomy</source><volume>120</volume><fpage>33</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1002/aja.1001200104</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dotson</surname> <given-names>NM</given-names></name><name><surname>Hoffman</surname> <given-names>SJ</given-names></name><name><surname>Goodell</surname> <given-names>B</given-names></name><name><surname>Gray</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A Large-Scale Semi-Chronic microdrive recording system for Non-Human primates</article-title><source>Neuron</source><volume>96</volume><fpage>769</fpage><lpage>782</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.050</pub-id><pub-id pub-id-type="pmid">29107523</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faragher</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Understanding the basis of the kalman filter via a simple and intuitive derivation [Lecture notes]</article-title><source>IEEE Signal Processing Magazine</source><volume>29</volume><fpage>128</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1109/MSP.2012.2203621</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname> <given-names>JM</given-names></name><name><surname>Tabot</surname> <given-names>GA</given-names></name><name><surname>Lee</surname> <given-names>AS</given-names></name><name><surname>Suresh</surname> <given-names>AK</given-names></name><name><surname>Rajan</surname> <given-names>AT</given-names></name><name><surname>Hatsopoulos</surname> <given-names>NG</given-names></name><name><surname>Bensmaia</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Postural representations of the hand in the primate sensorimotor cortex</article-title><source>Neuron</source><volume>104</volume><fpage>1000</fpage><lpage>1009</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.004</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halko</surname> <given-names>N</given-names></name><name><surname>Martinsson</surname> <given-names>PG</given-names></name><name><surname>Tropp</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Finding structure with randomness: probabilistic algorithms for constructing approximate matrix decompositions</article-title><source>SIAM Review</source><volume>53</volume><fpage>217</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1137/090771806</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hatsopoulos</surname> <given-names>NG</given-names></name><name><surname>Xu</surname> <given-names>Q</given-names></name><name><surname>Amit</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Encoding of movement fragments in the motor cortex</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>5105</fpage><lpage>5114</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3570-06.2007</pub-id><pub-id pub-id-type="pmid">17494696</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holzbaur</surname> <given-names>KR</given-names></name><name><surname>Murray</surname> <given-names>WM</given-names></name><name><surname>Delp</surname> <given-names>SL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A model of the upper extremity for simulating musculoskeletal surgery and analyzing neuromuscular control</article-title><source>Annals of Biomedical Engineering</source><volume>33</volume><fpage>829</fpage><lpage>840</lpage><pub-id pub-id-type="doi">10.1007/s10439-005-3320-7</pub-id><pub-id pub-id-type="pmid">16078622</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ingram</surname> <given-names>JN</given-names></name><name><surname>Körding</surname> <given-names>KP</given-names></name><name><surname>Howard</surname> <given-names>IS</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The statistics of natural hand movements</article-title><source>Experimental Brain Research</source><volume>188</volume><fpage>223</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1007/s00221-008-1355-3</pub-id><pub-id pub-id-type="pmid">18369608</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeannerod</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Intersegmental coordination during reaching at natural visual objects</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0132937</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0132937</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeannerod</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>The timing of natural prehension movements</article-title><source>Journal of Motor Behavior</source><volume>16</volume><fpage>235</fpage><lpage>254</lpage><pub-id pub-id-type="doi">10.1080/00222895.1984.10735319</pub-id><pub-id pub-id-type="pmid">15151851</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalman</surname> <given-names>RE</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>A new approach to linear filtering and prediction problems</article-title><source>Journal of Basic Engineering</source><volume>82</volume><fpage>35</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1115/1.3662552</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Seely</surname> <given-names>JS</given-names></name><name><surname>Sussillo</surname> <given-names>D</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The largest response component in the motor cortex reflects movement timing but not movement type</article-title><source>Eneuro</source><volume>3</volume><elocation-id>ENEURO.0085-16.2016</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0085-16.2016</pub-id><pub-id pub-id-type="pmid">27761519</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Keshtkaran</surname> <given-names>MR</given-names></name><name><surname>Pandarinath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><chapter-title>Enabling hyperparameter optimization in sequential autoencoders for spiking neural data</chapter-title><person-group person-group-type="editor"><name><surname>Wallach</surname> <given-names>H</given-names></name><name><surname>Larochelle</surname> <given-names>H</given-names></name><name><surname>Beygelzimer</surname> <given-names>A</given-names></name><name><surname>d’Alché-Buc</surname> <given-names>F</given-names></name><name><surname>Fox</surname> <given-names>E</given-names></name><name><surname>Garnett</surname> <given-names>R</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><volume>32</volume><publisher-name>Curran Associates, Inc</publisher-name><fpage>15937</fpage><lpage>15947</lpage></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lara</surname> <given-names>AH</given-names></name><name><surname>Elsayed</surname> <given-names>GF</given-names></name><name><surname>Zimnik</surname> <given-names>AJ</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2018">2018a</year><article-title>Conservation of preparatory neural events in monkey motor cortex regardless of how movement is initiated</article-title><source>eLife</source><volume>7</volume><elocation-id>e31826</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.31826</pub-id><pub-id pub-id-type="pmid">30132759</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lara</surname> <given-names>AH</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2018">2018b</year><article-title>Different population dynamics in the supplementary motor area and motor cortex during reaching</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>05146</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05146-z</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lehmann</surname> <given-names>SJ</given-names></name><name><surname>Scherberger</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reach and gaze representations in macaque parietal and premotor grasp Areas</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>7038</fpage><lpage>7049</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5568-12.2013</pub-id><pub-id pub-id-type="pmid">23595761</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menz</surname> <given-names>VK</given-names></name><name><surname>Schaffelhofer</surname> <given-names>S</given-names></name><name><surname>Scherberger</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Representation of continuous hand and arm movements in macaque Areas M1, F5, and AIP: a comparative decoding study</article-title><source>Journal of Neural Engineering</source><volume>12</volume><elocation-id>056016</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2560/12/5/056016</pub-id><pub-id pub-id-type="pmid">26355718</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaels</surname> <given-names>JA</given-names></name><name><surname>Dann</surname> <given-names>B</given-names></name><name><surname>Intveld</surname> <given-names>RW</given-names></name><name><surname>Scherberger</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural dynamics of variable Grasp-Movement preparation in the macaque frontoparietal network</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>5759</fpage><lpage>5773</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2557-17.2018</pub-id><pub-id pub-id-type="pmid">29798892</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname> <given-names>S</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Juavinett</surname> <given-names>AL</given-names></name><name><surname>Gluf</surname> <given-names>S</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okorokova</surname> <given-names>E</given-names></name><name><surname>Lebedev</surname> <given-names>M</given-names></name><name><surname>Linderman</surname> <given-names>M</given-names></name><name><surname>Ossadtchi</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A dynamical model improves reconstruction of handwriting from multichannel electromyographic recordings</article-title><source>Frontiers in Neuroscience</source><volume>9</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.3389/fnins.2015.00389</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okorokova</surname> <given-names>EV</given-names></name><name><surname>Goodman</surname> <given-names>JM</given-names></name><name><surname>Hatsopoulos</surname> <given-names>NG</given-names></name><name><surname>Bensmaia</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Decoding hand kinematics from population responses in sensorimotor cortex during grasping</article-title><source>Journal of Neural Engineering</source><volume>17</volume><elocation-id>046035</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/ab95ea</pub-id><pub-id pub-id-type="pmid">32442987</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Overduin</surname> <given-names>SA</given-names></name><name><surname>d'Avella</surname> <given-names>A</given-names></name><name><surname>Roh</surname> <given-names>J</given-names></name><name><surname>Carmena</surname> <given-names>JM</given-names></name><name><surname>Bizzi</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Representation of muscle synergies in the primate brain</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>12615</fpage><lpage>12624</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4302-14.2015</pub-id><pub-id pub-id-type="pmid">26377453</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pandarinath</surname> <given-names>C</given-names></name><name><surname>Gilja</surname> <given-names>V</given-names></name><name><surname>Blabe</surname> <given-names>CH</given-names></name><name><surname>Nuyujukian</surname> <given-names>P</given-names></name><name><surname>Sarma</surname> <given-names>AA</given-names></name><name><surname>Sorice</surname> <given-names>BL</given-names></name><name><surname>Eskandar</surname> <given-names>EN</given-names></name><name><surname>Hochberg</surname> <given-names>LR</given-names></name><name><surname>Henderson</surname> <given-names>JM</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural population dynamics in human motor cortex during movements in people with ALS</article-title><source>eLife</source><volume>4</volume><elocation-id>e07436</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.07436</pub-id><pub-id pub-id-type="pmid">26099302</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pandarinath</surname> <given-names>C</given-names></name><name><surname>O'Shea</surname> <given-names>DJ</given-names></name><name><surname>Collins</surname> <given-names>J</given-names></name><name><surname>Jozefowicz</surname> <given-names>R</given-names></name><name><surname>Stavisky</surname> <given-names>SD</given-names></name><name><surname>Kao</surname> <given-names>JC</given-names></name><name><surname>Trautmann</surname> <given-names>EM</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Hochberg</surname> <given-names>LR</given-names></name><name><surname>Henderson</surname> <given-names>JM</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Sussillo</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title><source>Nature Methods</source><volume>15</volume><fpage>805</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0109-9</pub-id><pub-id pub-id-type="pmid">30224673</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prentice</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>On invariant tests of uniformity for directions and orientations</article-title><source>The Annals of Statistics</source><volume>6</volume><fpage>169</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1214/aos/1176344075</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rathelot</surname> <given-names>JA</given-names></name><name><surname>Strick</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Subdivisions of primary motor cortex based on cortico-motoneuronal cells</article-title><source>PNAS</source><volume>106</volume><fpage>918</fpage><lpage>923</lpage><pub-id pub-id-type="doi">10.1073/pnas.0808362106</pub-id><pub-id pub-id-type="pmid">19139417</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname> <given-names>AG</given-names></name><name><surname>Schieber</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatiotemporal distribution of location and object effects in reach-to-grasp kinematics</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>3268</fpage><lpage>3282</lpage><pub-id pub-id-type="doi">10.1152/jn.00686.2015</pub-id><pub-id pub-id-type="pmid">26445870</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname> <given-names>AG</given-names></name><name><surname>Schieber</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Condition-Dependent neural dimensions progressively shift during reach to grasp</article-title><source>Cell Reports</source><volume>25</volume><fpage>3158</fpage><lpage>3168</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.11.057</pub-id><pub-id pub-id-type="pmid">30540947</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname> <given-names>AC</given-names></name><name><surname>Paulignan</surname> <given-names>Y</given-names></name><name><surname>Farnè</surname> <given-names>A</given-names></name><name><surname>Jouffrais</surname> <given-names>C</given-names></name><name><surname>Boussaoud</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Hand kinematics during reaching and grasping in the macaque monkey</article-title><source>Behavioural Brain Research</source><volume>117</volume><fpage>75</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(00)00284-9</pub-id><pub-id pub-id-type="pmid">11099760</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russo</surname> <given-names>AA</given-names></name><name><surname>Bittner</surname> <given-names>SR</given-names></name><name><surname>Perkins</surname> <given-names>SM</given-names></name><name><surname>Seely</surname> <given-names>JS</given-names></name><name><surname>London</surname> <given-names>BM</given-names></name><name><surname>Lara</surname> <given-names>AH</given-names></name><name><surname>Miri</surname> <given-names>A</given-names></name><name><surname>Marshall</surname> <given-names>NJ</given-names></name><name><surname>Kohn</surname> <given-names>A</given-names></name><name><surname>Jessell</surname> <given-names>TM</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Motor cortex embeds Muscle-like commands in an untangled population response</article-title><source>Neuron</source><volume>97</volume><fpage>953</fpage><lpage>966</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.004</pub-id><pub-id pub-id-type="pmid">29398358</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russo</surname> <given-names>AA</given-names></name><name><surname>Khajeh</surname> <given-names>R</given-names></name><name><surname>Bittner</surname> <given-names>SR</given-names></name><name><surname>Perkins</surname> <given-names>SM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural trajectories in the supplementary motor area and motor cortex exhibit distinct geometries, compatible with different classes of computation</article-title><source>Neuron</source><volume>107</volume><fpage>745</fpage><lpage>758</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.05.020</pub-id><pub-id pub-id-type="pmid">32516573</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santello</surname> <given-names>M</given-names></name><name><surname>Flanders</surname> <given-names>M</given-names></name><name><surname>Soechting</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Postural hand synergies for tool use</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>10105</fpage><lpage>10115</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-23-10105.1998</pub-id><pub-id pub-id-type="pmid">9822764</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santello</surname> <given-names>M</given-names></name><name><surname>Flanders</surname> <given-names>M</given-names></name><name><surname>Soechting</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Patterns of hand motion during grasping and the influence of sensory guidance</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>1426</fpage><lpage>1435</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-04-01426.2002</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santello</surname> <given-names>M</given-names></name><name><surname>Soechting</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Gradual molding of the hand to object contours</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>1307</fpage><lpage>1320</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.3.1307</pub-id><pub-id pub-id-type="pmid">9497412</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauerbrei</surname> <given-names>BA</given-names></name><name><surname>Guo</surname> <given-names>JZ</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Mischiati</surname> <given-names>M</given-names></name><name><surname>Guo</surname> <given-names>W</given-names></name><name><surname>Kabra</surname> <given-names>M</given-names></name><name><surname>Verma</surname> <given-names>N</given-names></name><name><surname>Mensh</surname> <given-names>B</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name><name><surname>Hantman</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cortical pattern generation during dexterous movement is input-driven</article-title><source>Nature</source><volume>577</volume><fpage>386</fpage><lpage>391</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1869-9</pub-id><pub-id pub-id-type="pmid">31875851</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical control of arm movements: a dynamical systems perspective</article-title><source>Annual Review of Neuroscience</source><volume>36</volume><fpage>337</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150509</pub-id><pub-id pub-id-type="pmid">23725001</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stavisky</surname> <given-names>SD</given-names></name><name><surname>Willett</surname> <given-names>FR</given-names></name><name><surname>Wilson</surname> <given-names>GH</given-names></name><name><surname>Murphy</surname> <given-names>BA</given-names></name><name><surname>Rezaii</surname> <given-names>P</given-names></name><name><surname>Avansino</surname> <given-names>DT</given-names></name><name><surname>Memberg</surname> <given-names>WD</given-names></name><name><surname>Miller</surname> <given-names>JP</given-names></name><name><surname>Kirsch</surname> <given-names>RF</given-names></name><name><surname>Hochberg</surname> <given-names>LR</given-names></name><name><surname>Ajiboye</surname> <given-names>AB</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Henderson</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural ensemble dynamics in dorsal motor cortex during speech in people with paralysis</article-title><source>eLife</source><volume>8</volume><elocation-id>e46015</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.46015</pub-id><pub-id pub-id-type="pmid">31820736</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suminski</surname> <given-names>AJ</given-names></name><name><surname>Tkach</surname> <given-names>DC</given-names></name><name><surname>Fagg</surname> <given-names>AH</given-names></name><name><surname>Hatsopoulos</surname> <given-names>NG</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Incorporating feedback from multiple sensory modalities enhances brain-machine interface control</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>16777</fpage><lpage>16787</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3967-10.2010</pub-id><pub-id pub-id-type="pmid">21159949</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theverapperuma</surname> <given-names>LS</given-names></name><name><surname>Hendrix</surname> <given-names>CM</given-names></name><name><surname>Mason</surname> <given-names>CR</given-names></name><name><surname>Ebner</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Finger movements during reach-to-grasp in the monkey: amplitude scaling of a temporal synergy</article-title><source>Experimental Brain Research</source><volume>169</volume><fpage>433</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1007/s00221-005-0167-y</pub-id><pub-id pub-id-type="pmid">16292639</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tresch</surname> <given-names>MC</given-names></name><name><surname>Jarc</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The case for and against muscle synergies this review comes from a themed issue on motor systems edited by abdel el manira and Krishna Shenoy</article-title><source>Current Opinion in Neurobiology</source><volume>19</volume><fpage>601</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2009.09.002</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>Stelmach</surname> <given-names>GE</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Coordination among the body segments during reach-to-grasp action involving the trunk</article-title><source>Experimental Brain Research</source><volume>123</volume><fpage>346</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1007/s002210050578</pub-id><pub-id pub-id-type="pmid">9860274</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willett</surname> <given-names>FR</given-names></name><name><surname>Deo</surname> <given-names>DR</given-names></name><name><surname>Avansino</surname> <given-names>DT</given-names></name><name><surname>Rezaii</surname> <given-names>P</given-names></name><name><surname>Hochberg</surname> <given-names>LR</given-names></name><name><surname>Henderson</surname> <given-names>JM</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hand knob area of premotor cortex represents the whole body in a compositional way</article-title><source>Cell</source><volume>181</volume><fpage>396</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.02.043</pub-id><pub-id pub-id-type="pmid">32220308</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname> <given-names>W</given-names></name><name><surname>Black</surname> <given-names>MJ</given-names></name><name><surname>Mumford</surname> <given-names>D</given-names></name><name><surname>Gao</surname> <given-names>Y</given-names></name><name><surname>Bienenstock</surname> <given-names>E</given-names></name><name><surname>Donoghue</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Modeling and decoding motor cortical activity using a switching kalman filter</article-title><source>IEEE Transactions on Biomedical Engineering</source><volume>51</volume><fpage>933</fpage><lpage>942</lpage><pub-id pub-id-type="doi">10.1109/TBME.2004.826666</pub-id><pub-id pub-id-type="pmid">15188861</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamaguchi</surname> <given-names>GT</given-names></name><name><surname>Zajac</surname> <given-names>FE</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>A planar model of the knee joint to characterize the knee extensor mechanism</article-title><source>Journal of Biomechanics</source><volume>22</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/0021-9290(89)90179-6</pub-id><pub-id pub-id-type="pmid">2914967</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.58848.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Santacruz</surname><given-names>Samantha R</given-names></name><role>Reviewing Editor</role><aff><institution>The University of Texas at Austin</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Santacruz</surname><given-names>Samantha R</given-names></name><role>Reviewer</role><aff><institution>The University of Texas at Austin</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Capogrosso</surname><given-names>Marco</given-names> </name><role>Reviewer</role><aff><institution>École polytechnique fédérale de Lausanne</institution><country>Switzerland</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>The authors present a short report demonstrating the difference in neural dynamics between grasping and reaching behaviors. This work is broadly interesting to those in the field of motor control and leverages cutting-edge techniques to elucidate neural dynamics associated with the two aforementioned motor behaviors. We are enthusiastic about the suitability of this publication in <italic>eLife</italic>.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Neural population dynamics in motor cortex are different for reach and grasp&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Samantha R Santacruz as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Richard Ivry as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Marco Capogrosso (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, we are asking editors to accept without delay manuscripts, like yours, that they judge can stand as <italic>eLife</italic> papers without additional data, even if they feel that they would make the manuscript stronger. Thus the revisions requested below only address clarity and presentation.</p><p>Summary:</p><p>The authors present a cohesive and elegant short report demonstrating the difference in neural dynamics between grasping and reaching behaviors. The reviewers are enthusiastic about this work and agree that this study is of great interest to the field since increasingly the motor cortex is modelled as a system with strong dynamical properties. However, they find that the manuscript would be greatly strengthened by clarifications in the analyses, statistics, and animals utilized. The manuscript is suitable for publication in <italic>eLife</italic> subject to the revisions detailed below.</p><p>Essential revisions:</p><p>1) Analysis to convince the reader that motor cortical neural activity analyzed is as grasp-modulated as much as it is reach-modulated, which would control for the possibility that neural activity is just more reach-modulated so looks like reach conditions have stronger dynamics. Are the percentage of neurons modulated by the task same in grasp vs. reach (in the PSTH that you analyze)? Since these dynamics questions reflect how well changes (modulation) in firing rate are predicted, it would be important to know that the amount of modulation is comparable. Further, please clarify the point articulated in paragraph three of subsection “Control comparisons between arm and hand data”. Since firing rates are normalized before jPCA, why is analyzing the peak firing rates without normalization a valid way to &quot;directly contrast the inputs to the jPCA analysis&quot;?</p><p>2) Analysis to show that reach and grasp PSTHs are equally representative of individual trials, which would control for the possibility that grasp activity is just more variable trial-to-trial so analyzing the PSTH isn't representative of true dynamics. How reliable is the trial-to-trial neural activity for reach vs. grasp? Ensuring that the PSTH is equally reflective of trial activity is important for fairly comparing these two conditions.</p><p>3) Please report R2 for the neural reconstruction with LFADS for reach vs. grasp in Figure 2. This value would indicate whether using a non-linear dynamics model (LFADS) can accurately predict neural activity even in the case of grasp, which is important to do prior to any of the kinematic decoding.</p><p>4) Clarify the number of animals used for each analysis. It is difficult to understand from the results and reported figures how many animals were used and for which analysis. We suggest using a table to report this information in an accessible format. When performing statistics with data combined across animals, we also suggest using a linear mixed effect model with &quot;animal&quot; as a random effect.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your article &quot;Neural population dynamics in motor cortex are different for reach and grasp&quot; for consideration by <italic>eLife</italic>. Your revised article has been reviewed by two of the original peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Richard Ivry as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require a modest amount of additional new data, as they do with your paper, we are asking that the manuscript be revised to either limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Our expectation is that the authors will eventually carry out the additional experiments and report on how they affect the relevant conclusions either in a preprint on bioRxiv or medRxiv, or if appropriate, as a Research Advance in <italic>eLife</italic>, either of which would be linked to the original paper.</p><p>Summary:</p><p>The authors present a short report demonstrating the difference in neural dynamics between grasping and reaching behaviors. The reviewers remain enthusiastic about this work and the overall interest that it will have to the field, but there remain outstanding concerns regarding the statistics and interpretation of results. Below you will find more detailed comments. The manuscript is suitable for publication in eLife<italic>eLife</italic> if the points detailed below can be addressed.</p><p>Revisions for this paper:</p><p>– Pertaining to Essential Revisions #3: The authors now report an R2 for the NEURAL reconstruction using LFADS for reaching and grasping. The authors have placed this result in the Materials and methods section, rather than in the Results section. Secondly and more importantly, this result is: &quot;The average correlation between measured and reconstructed firing rates was 0.44 +/- 0.022 and 0.48 +/- 0.021 for single trials and 0.73 +/- 0.03 and 0.76 +/- 0.011 when averaged within condition, for reach and grasp respectively&quot;. This suggests that both reach and grasp NEURAL activity are equally explained by LFADS. This result appears to go against the main message of their paper (which to this point has been that there are no discernible dynamics in grasping, but there are in reaching). We would like to see this result reported in the Results section before Figure 2, and would like to see the message of the paper reflect this result (maybe something along the lines of &quot;Grasping dynamics are high dimensional, non-linear, and can't be used for decoding with a linear decoder whereas reaching dynamics are low dimensional, linear, and can be used for decoding&quot;).</p><p>– The R2 result from above also seems to contradict the tangling results in Figure 3 (that Q-M1/Q-kinematics is higher for grasping than reaching). However upon further inspection of Figure 3, it seems like the reaching and grasping Q-kinematics are quite different (mean Q-kinematics seems to be about ~1x10<sup>4</sup> for reaching, ~0.3x10<sup>4</sup> for grasping), whereas it looks like the Q-motor cortex may be similar for both reaching and grasping. Perhaps the kinematics themselves may be driving the significant differences in the Q-ratio while the Q-motor cortex values may be comparable (which would be more consistent with the above result for approx equal R2 from LFADS)? This should be addresses in the revision.</p><p>– Pertaining to essential revisions #2: We appreciate the inclusion of panel I in Figure 1—figure supplement 2 to address this point. The main point of this question was to assess whether trial-to-trial variability affected the estimate of the PSTH and thus the ability of a linear model to capture dynamics from the PSTH. Displaying the coefficient of variation as a bar graph collapses over all temporal differences in trial-to-trial variability. For example, it is consistent within this bar plot that trial-to-trial activity is approx. uniform across the reaching behavior epoch, but for grasp is low at the beginning of the trial then high at the end of the trial for example. This hypothetical difference would make it so that the grasping PSTH is consistent at the beginning and noisy at the end, and could explain why it is harder to estimate grasping PSTH with linear dynamics. If this is the case, it may be that reach and grasp neural dynamics are not very different, just that grasp behavior tends to be more variable so the PSTH is not reflective of the true dynamics that may be ongoing during grasp. Another way to address this concern would be to report R2 of neural activity estimated from fitting dynamics on single trials and showing the same differences as in Figure 1. This gets around the issue of trial-averaging and potential trial-to-trial variability differences. We ask that the authors report this R2 value.</p><p>– There remain some overall concerns with the statistics performed. When performing statistics, data points from different subjects cannot be pooled together. This is because performing tests on pooled data violates the assumption of iid samples because part of the variance in the samples is explained by the fact that data some of the samples are from one animal and some from the other (intra-animal vs inter-animal). In this case manuscript, the authors are comparing 2 monkeys against 2 different monkeys, and everything is pooled together. We ask the authors to clarify and justify their methodology.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.58848.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Analysis to convince the reader that motor cortical neural activity analyzed is as grasp-modulated as much as it is reach-modulated, which would control for the possibility that neural activity is just more reach-modulated so looks like reach conditions have stronger dynamics. Are the percentage of neurons modulated by the task same in grasp vs. reach (in the PSTH that you analyze)? Since these dynamics questions reflect how well changes (modulation) in firing rate are predicted, it would be important to know that the amount of modulation is comparable. Further, please clarify the point articulated in paragraph three of subsection “Control comparisons between arm and hand data”. Since firing rates are normalized before jPCA, why is analyzing the peak firing rates without normalization a valid way to &quot;directly contrast the inputs to the jPCA analysis&quot;?</p></disp-quote><p>Thank you for this comment, we have addressed this point in Figure 1—figure supplement 2, Panel D, and in the relevant passage of the text. The goal was to directly address the reviewer’s question, namely whether firing rates are similar across neuronal populations and tasks. The modulation depths were similar for reach and grasp responses.</p><disp-quote content-type="editor-comment"><p>2) Analysis to show that reach and grasp PSTHs are equally representative of individual trials, which would control for the possibility that grasp activity is just more variable trial-to-trial so analyzing the PSTH isn't representative of true dynamics. How reliable is the trial-to-trial neural activity for reach vs. grasp? Ensuring that the PSTH is equally reflective of trial activity is important for fairly comparing these two conditions.</p></disp-quote><p>We assessed trial-to-trial variability by computing the coefficient of variation of spike counts over a 500-ms window centred on movement onset. The results of this analysis are shown in Figure 1—figure supplement 2, Panel I. Trial-to-trial variability was similar for reach and grasp.</p><disp-quote content-type="editor-comment"><p>3) Please report R2 for the neural reconstruction with LFADS for reach vs. grasp in Figure 2. This value would indicate whether using a non-linear dynamics model (LFADS) can accurately predict neural activity even in the case of grasp, which is important to do prior to any of the kinematic decoding.</p></disp-quote><p>We now report average correlations between firing rates estimated with Gaussian smoothing and those estimated with LFADS. We find that the correlations between the two are similar for reach and grasp in both condition-averaged responses and on a trial-by-trial basis (now reported in the Materials and methods section). This result indicates that the model captured similar amount of variance in reach and grasp datasets, yet this variance was more informative about kinematics for reach than for grasp, as evidenced by the decoding analysis.</p><disp-quote content-type="editor-comment"><p>4) Clarify the number of animals used for each analysis. It is difficult to understand from the results and reported figures how many animals were used and for which analysis. We suggest using a table to report this information in an accessible format. When performing statistics with data combined across animals, we also suggest using a linear mixed effect model with &quot;animal&quot; as a random effect.</p></disp-quote><p>We have added a table to provide the requested information. We used different monkeys in the reach and grasp tasks, so unfortunately our data do not admit the suggested repeated-measures analysis design.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Revisions for this paper:</p><p>– Pertaining to Essential Revisions #3: The authors now report an R2 for the NEURAL reconstruction using LFADS for reaching and grasping. The authors have placed this result in the Materials and methods section, rather than in the Results section. Secondly and more importantly, this result is: &quot;The average correlation between measured and reconstructed firing rates was 0.44 +/- 0.022 and 0.48 +/- 0.021 for single trials and 0.73 +/- 0.03 and 0.76 +/- 0.011 when averaged within condition, for reach and grasp respectively&quot;. This suggests that both reach and grasp NEURAL activity are EQUALLY explained by LFADS. This result appears to go against the main message of their paper (which to this point has been that there are no discernible dynamics in grasping, but there are in reaching). We would like to see this result reported in the Results section before Figure 2, and would like to see the message of the paper reflect this result (maybe something along the lines of &quot;Grasping dynamics are high dimensional, non-linear, and can't be used for decoding with a linear decoder whereas reaching dynamics are low dimensional, linear, and can be used for decoding&quot;).</p></disp-quote><p>We thank the reviewers for this comment. In the first revision, we reported mean correlations between the trial-averaged responses and their smoothed and LFADS-processed counterparts. This was a mistake. What we should have done instead is to compute the correlation between the response obtained on one trial and the smoothed or LFADS-processed response averaged over the other trials. We would then predict that, for reaching, LFADS should yield responses that generalize better because it leverages the latent dynamics to reconstruct the single trial response. This is indeed what we found for the reaching responses and significantly less so for the grasping responses:</p><p>“First, as expected, we found that in both datasets, neural reconstruction of single trials improved with LFADS (0.34 and 0.23 correlation improvement in reach and grasp, correspondingly, Figure 2—figure supplement 1 (A, B)). However, neural reconstruction improvement was on average significantly higher for reach than for grasp (t(311) = 7.07, p = 5.11e-12; Figure 2—figure supplement 1).”</p><disp-quote content-type="editor-comment"><p>– The R2 result from above also seems to contradict the tangling results in Figure 3 (that Q-M1/Q-kinematics is higher for grasping than reaching). However upon further inspection of Figure 3, it seems like the reaching and grasping Q-kinematics are quite different (mean Q-kinematics seems to be about ~1x10<sup>4</sup> for reaching, ~0.3x10<sup>4</sup> for grasping), whereas it looks like the Q-motor cortex may be similar for both reaching and grasping. Perhaps the kinematics themselves may be driving the significant differences in the Q-ratio while the Q-motor cortex values may be comparable (which would be more consistent with the above result for approx equal R2 from LFADS)? This should be addresses in the revision.</p></disp-quote><p>Now that we have done the analysis properly, the contradiction between the LFADS reconstruction and the tangling analysis is resolved. Regarding the raw tangling values, these depend on task, number of conditions, time binning, smoothing, and other factors, and thus fundamentally constitute a relative measure (Russo et al., 2018). The kinematics are matched for the aforementioned factors and thus make a nice comparison.</p><disp-quote content-type="editor-comment"><p>– Pertaining to essential revisions #2: We appreciate the inclusion of panel I in Figure 1—figure supplement 2 to address this point. The main point of this question was to assess whether trial-to-trial variability affected the estimate of the PSTH and thus the ability of a linear model to capture dynamics from the PSTH. Displaying the coefficient of variation as a bar graph collapses over all temporal differences in trial-to-trial variability. For example, it is consistent within this bar plot that trial-to-trial activity is approx. uniform across the reaching behavior epoch, but for grasp is low at the beginning of the trial then high at the end of the trial for example. This hypothetical difference would make it so that the grasping PSTH is consistent at the beginning and noisy at the end, and could explain why it is harder to estimate grasping PSTH with linear dynamics. If this is the case, it may be that reach and grasp neural dynamics are not very different, just that grasp behavior tends to be more variable so the PSTH is not reflective of the true dynamics that may be ongoing during grasp. Another way to address this concern would be to report R2 of neural activity estimated from fitting dynamics on single trials and showing the same differences as in Figure 1. This gets around the issue of trial-averaging and potential trial-to-trial variability differences. We ask that the authors report this R2 value.</p></disp-quote><p>The linear dynamical analysis cannot be applied to single trials because these are too noisy. Indeed, even the much more constrained jPCA cannot be computed from single trials (see Figures 3B,D in Pandarinath et al., 2018). LFADS, on the other hand, is well suited for this purpose. Accordingly, the analysis described above is in the spirit of what is requested here. To address the specific possibility, raised by the reviewer, that the variability may be distributed differently within the trial for reaching and grasping, we recomputed the CV at different epochs during each trial and found these to be homogeneous over the trial and similar for reaching and grasping (see Figure 1—figure supplement 2).</p><disp-quote content-type="editor-comment"><p>– There remain some overall concerns with statistics performed. When performing statistics, data points from different subjects cannot be pooled together. This is because performing tests on pooled data violates the assumption of iid samples because part of the variance in the samples is explained by the fact that data some of the samples are from one animal and some from the other (intra-animal vs inter-animal). In this case manuscript, the authors are comparing 2 monkeys against 2 different monkeys, and everything is pooled together. We ask the authors to clarify and justify their methodology.</p></disp-quote><p>We agree that it would have been preferable to obtain reaching and grasping data from the same animals. However, the two tasks were used in two different studies with different goals and, unfortunately, different animals. Note, however, that the differences between reach and grasp are very strong and persist even if we compare the least favorable pair of animals.</p></body></sub-article></article>