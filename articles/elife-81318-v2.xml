<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">81318</article-id><article-id pub-id-type="doi">10.7554/eLife.81318</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Landmark-based spatial navigation across the human lifespan</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-284027"><name><surname>Bécu</surname><given-names>Marcia</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4564-1023</contrib-id><email>marcia.becu@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-169280"><name><surname>Sheynikhovich</surname><given-names>Denis</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7737-8907</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-285615"><name><surname>Ramanoël</surname><given-names>Stephen</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4735-1097</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-285616"><name><surname>Tatur</surname><given-names>Guillaume</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-285617"><name><surname>Ozier-Lafontaine</surname><given-names>Anthony</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-285618"><name><surname>Authié</surname><given-names>Colas N</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-202065"><name><surname>Sahel</surname><given-names>José-Alain</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-177901"><name><surname>Arleo</surname><given-names>Angelo</given-names></name><email>angelo.arleo@inserm.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02en5vm52</institution-id><institution>Sorbonne Université, INSERM, CNRS, Institut de la Vision</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tvrq624</institution-id><institution>Kavli Institute for Systems Neuroscience, Centre for Neural Computation, The Egil and Pauline Braathen and Fred Kavli Centre for Cortical Microcircuits, NTNU</institution></institution-wrap><addr-line><named-content content-type="city">Trondheim</named-content></addr-line><country>Norway</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0387jng26</institution-id><institution>Max Planck Institute for Human Cognitive and Brain Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/000zhpw23</institution-id><institution>Institut de la Vision, Streetlab</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Ophthalmology, The University of Pittsburgh School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024v1ns19</institution-id><institution>CHNO des Quinze-Vingts, INSERM-DGOS CIC</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02yfw7119</institution-id><institution>Department of Ophthalmology, Fondation Ophtalmologique Rothschild</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ekstrom</surname><given-names>Arne</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03m2x1q45</institution-id><institution>University of Arizona</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Baker</surname><given-names>Chris I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>13</day><month>03</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e81318</elocation-id><history><date date-type="received" iso-8601-date="2022-06-22"><day>22</day><month>06</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-03-11"><day>11</day><month>03</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2020-02-13"><day>13</day><month>02</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.02.12.945808"/></event></pub-history><permissions><copyright-statement>© 2023, Bécu et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Bécu et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-81318-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-81318-figures-v2.pdf"/><abstract><p>Human spatial cognition has been mainly characterized in terms of egocentric (body-centered) and allocentric (world-centered) wayfinding bhavior. It was hypothesized that allocentric spatial coding, as a special high-level cognitive ability, develops later and deteriorates earlier than the egocentric one throughout lifetime. We challenged this hypothesis by testing the use of landmarks versus geometric cues in a cohort of 96 deeply phenotyped participants, who physically navigated an equiangular Y maze, surrounded by landmarks or an anisotropic one. The results show that an apparent allocentric deficit in children and aged navigators is caused specifically by difficulties in using landmarks for navigation while introducing a geometric polarization of space made these participants as efficient allocentric navigators as young adults. This finding suggests that allocentric behavior relies on two dissociable sensory processing systems that are differentially affected by human aging. Whereas landmark processing follows an inverted-U dependence on age, spatial geometry processing is conserved, highlighting its potential in improving navigation performance across the lifespan.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>spatial navigation</kwd><kwd>spatial cognition</kwd><kwd>human aging</kwd><kwd>landmark</kwd><kwd>geometry</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>ANR</institution></institution-wrap></funding-source><award-id>ANR-14-CHIN-0001 ANR-14-CHIN-0002</award-id><principal-award-recipient><name><surname>Arleo</surname><given-names>Angelo</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>ANR</institution></institution-wrap></funding-source><award-id>Labex LifeSenses ANR-10-LABX-65</award-id><principal-award-recipient><name><surname>Sahel</surname><given-names>José-Alain</given-names></name><name><surname>Arleo</surname><given-names>Angelo</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>ANR</institution></institution-wrap></funding-source><award-id>IHU FOReSIGHT grant ANR-18-IAHU-01</award-id><principal-award-recipient><name><surname>Sahel</surname><given-names>José-Alain</given-names></name><name><surname>Arleo</surname><given-names>Angelo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Landmark cues preclude complex and flexible spatial navigation in human development and aging.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Human navigation strategies and the underlying spatial representations have been the subject of an intense debate (<xref ref-type="bibr" rid="bib7">Burgess, 2006</xref>; <xref ref-type="bibr" rid="bib52">Wang and Spelke, 2002</xref>; <xref ref-type="bibr" rid="bib15">Ekstrom et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Burgess, 2008</xref>; <xref ref-type="bibr" rid="bib53">Wang et al., 2006</xref>; <xref ref-type="bibr" rid="bib14">Ekstrom et al., 2014</xref>). Wayfinding behavior has extensively been described in terms of two types of navigation strategies, depending on the spatial reference frame in which multisensory representations are encoded. Egocentric strategies rely on spatial codes anchored on the subject’s body or the use of visual snapshots of the environment (<xref ref-type="bibr" rid="bib51">Waller and Hodgson, 2006</xref>), whereas allocentric strategies are grounded on representations that are independent from the subject’s position and orientation, akin to a topographic map (<xref ref-type="bibr" rid="bib8">Burgess, 2008</xref>). A large body of experimental work has been devoted to the question of how environmental conditions as well as navigators’ individual characteristics influence the strategy preference (<xref ref-type="bibr" rid="bib16">Ekstrom and Isham, 2017</xref>; <xref ref-type="bibr" rid="bib26">Lester et al., 2017</xref>).</p><p>The study of age-related differences in human navigation has added a new temporal dimension to this research domain. It has been extensively proposed that a deterioration of neural structures underlying spatial coding during aging would lead to decreased allocentric navigation capabilities in older participants (<xref ref-type="bibr" rid="bib10">Colombo et al., 2017</xref>; <xref ref-type="bibr" rid="bib55">Wiener et al., 2013</xref>; <xref ref-type="bibr" rid="bib35">Moffat, 2009</xref>; <xref ref-type="bibr" rid="bib31">Lithfous et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Raz et al., 2004</xref>; <xref ref-type="bibr" rid="bib30">Lister and Barnes, 2009</xref>; <xref ref-type="bibr" rid="bib11">Davis and Weisbeck, 2015</xref>; <xref ref-type="bibr" rid="bib13">Driscoll et al., 2005</xref>; <xref ref-type="bibr" rid="bib44">Rodgers et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Ruggiero et al., 2016</xref>; <xref ref-type="bibr" rid="bib18">Harris et al., 2012</xref>; <xref ref-type="bibr" rid="bib33">Mahmood et al., 2009</xref>). However, the majority of experimental paradigms used to assess allocentric navigation in humans were based on the capacity of subjects to use landmarks (<xref ref-type="bibr" rid="bib55">Wiener et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Davis and Weisbeck, 2015</xref>; <xref ref-type="bibr" rid="bib13">Driscoll et al., 2005</xref>; <xref ref-type="bibr" rid="bib44">Rodgers et al., 2012</xref>; <xref ref-type="bibr" rid="bib5">Bohbot et al., 2012</xref>), while making geometric cues uninformative about the goal location or preventing subjects from using them.</p><p>Here, we postulate that lifetime changes in spatial cognition can be understood in terms of modulation of spatial cue processing capabilities. Hence, an alternative explanation consistent with the literature is that the widely accepted hypothesis of age-related allocentric deficit may in fact reflect landmark processing differences. This view on the spatial navigation capabilities as a function of age leads to a strong prediction: making the geometric layout of an experimental space informative (about the subject and the goal locations in space) should attenuate the egocentric bias in aged navigators and restore the putative allocentric impairment. Besides, since a preference for geometry and a bias toward egocentric strategies were both shown in aging (<xref ref-type="bibr" rid="bib4">Bécu et al., 2020</xref>) and human development as well (<xref ref-type="bibr" rid="bib5">Bohbot et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">van der Ham et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Newcombe, 2019</xref>; <xref ref-type="bibr" rid="bib37">Nardini et al., 2006</xref>; <xref ref-type="bibr" rid="bib6">Bullens et al., 2010</xref>), polarization of geometry could also improve allocentric spatial behavior in children.</p><p>We sought to test these hypotheses by employing a Y-maze experimental paradigm, traditionally used to dissociate egocentric and allocentric navigation in rodents (<xref ref-type="bibr" rid="bib25">Lenck-Santini et al., 2001</xref>; <xref ref-type="bibr" rid="bib42">Rinaldi et al., 2020</xref>) and humans (<xref ref-type="bibr" rid="bib44">Rodgers et al., 2012</xref>). We first comparatively assessed spatial orientation and navigation performances of children, young, and older adults physically moving in an immersive virtual reality environment. Natural, active body and head motion during spatial behavior avoided limitations of joystick-operated paradigms, which prevent subjects, in particular older ones, from integrating visual, proprioceptive, and vestibular cues for reorientation and navigation (<xref ref-type="bibr" rid="bib33">Mahmood et al., 2009</xref>; <xref ref-type="bibr" rid="bib1">Adamo et al., 2012</xref>; <xref ref-type="bibr" rid="bib19">Harris and Wolbers, 2012</xref>). Second, we tested participants in a real-world replica of the Y-maze environment, allowing natural visual inputs to support navigation. Here, we report experimental evidence in support of above predictions by showing that anisotropic geometry eliminates differences between young adults, children, and older subjects in terms of allocentric navigation capabilities. We show that age-dependent differences in wayfinding behavior can then be ascribed to differences in coding landmarks versus geometrical spatial cues. Our findings suggest that the bias toward egocentric navigation in both children and older navigators is conditioned by the spatial cues present in the environment, questioning the traditional view of a specific deficit for allocentric strategies per se in development and aging. Overall, these results highlight the need to revisit the classical allocentric–egocentric dichotomy to encompass the role of two dissociable systems (based on landmark or geometry) in governing spatial cognition across the lifespan.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We tested 96 participants (29 children, μ = 10, std = 0.49; 22 young adults, μ = 28, std = 4.28; 28 healthy older adults, μ = 73, std = 3.90) in a Y-maze navigation paradigm adapted to study the relative influence of landmark and geometric cues on spatial navigation (79 participants were tested in immersive virtual conditions, while 17 were tested in the real-world replica, see <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>and <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref> for participant details). The participants were randomly assigned to two groups, and each group was tested in one of two different versions of the Y-maze task. In the classical landmark condition, an equiangular maze was surrounded by three distal landmarks with respect to which any position in the maze could be unambiguously defined (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). In the novel geometry condition, there were no landmarks and the angle between two of the three arms was set to 50°, making any location in the maze uniquely determined by its anisotropic geometric layout (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). The experimental protocol was identical in both conditions and consisted of two phases (see ‘Materials and methods’ for details). All subjects were disoriented with the eyes closed before each trial, and they were placed at the starting location facing the center of the maze (<xref ref-type="video" rid="video1">Video 1</xref>). In the first phase, the subjects learned across multiple trials to navigate from the departure arm (position A, <xref ref-type="fig" rid="fig1">Figure 1c</xref>) to an invisible target area (position C), reaching of which was notified by sound. Four consecutive successful learning trials triggered the start of the second, testing phase, in which no reward signal was given. The testing phase comprised six trials, in which departure positions were selected among the two non-goal arms: three control trials started from same starting position (arm A) as during learning, while three probe trials started from the arm B (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). As the subjects were not notified about changes in starting positions, their behavior during the probe trials reflected the strategy they adopted to self-localize and navigate to the goal. If a subject ended up in the arm A during a probe trial, that is, by making the same body turn at the center of the maze as during learning, his/her behavior during that trial was classified as egocentric. If the subject reoriented in space and inferred the position of the target from either the landmark array (landmark condition) or the geometric layout of the maze (geometry condition) and ended up in the goal arm C, the behavior was classified as allocentric. Note that these behavioral classifications were purely descriptive, and that they were chosen to permit the comparison with previous works. They did not mean to capture the nature of processes or representations underlying the associated behavior (<xref ref-type="bibr" rid="bib14">Ekstrom et al., 2014</xref>; <xref ref-type="bibr" rid="bib54">Wang, 2017</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Immersive Y-maze tasks to assess the relative influence of landmark and geometric spatial cues as a function of age.</title><p>(<bold>a</bold>) Top view of the Y-maze during the classical <italic>landmark condition</italic> (i.e., equiangular Y-maze; arm separation: 120°/120°/120°). Three distinct, distal landmarks (blue square, red circle, green star) cued the environment. (<bold>b</bold>) Top view of the Y-maze during the novel <italic>geometry condition</italic> (i.e., anisotropic geometric layout with no landmarks; arm separation: 50°/155°/155°). As depicted in the figure, the corridors in this condition were 54% longer than in the landmark condition to avoid the participants to see the end of the corridors from the starting locations. (<bold>c</bold>) Example of first-person perspective from the departure location during learning trials (i.e., position A in the maze) in the landmark and geometry condition (left and right, respectively). (<bold>d</bold>) Example of first-person perspective from the departure location during probe trials (i.e., position B in the maze) in the landmark and geometry condition (left and right, respectively). See <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for details on the real-world replica.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Real-world Y-maze implementation.</title><p>(<bold>a</bold>) Dimensions of the Y-maze in meters, as seen from above. Panels are 2.23 m high. A–C differentiate the three corridors (see protocol). Landmarks are 0.45 m<sup>2</sup> pictures hanging from the ceiling at 2.82 m. They are positioned at 2.3 m from the maze center. (<bold>b, c</bold>) Customized Plexiglas panels were used to build the maze, which reflected the visible radiation while allowing infrared light to pass. Custom-made support frames held the IR-pass panels vertically.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig1-figsupp1-v2.tif"/></fig></fig-group><media mimetype="video" mime-subtype="mp4" xlink:href="elife-81318-video1.mp4" id="video1"><label>Video 1.</label><caption><title>Disorientation of a participant in immersive virtual conditions.</title></caption></media><sec id="s2-1"><title>Geometric cues enable allocentric navigation in children and older adults</title><p>We first assessed strategy preference in the virtual reality settings (n = 79). In the landmark condition, we found a significant bias toward egocentric-like responses in children and older adults compared to young adults (<xref ref-type="fig" rid="fig2">Figure 2a</xref>; overall Fisher’s exact test across the three age groups: p&lt;0.01, Cohen’s w = 0.47; children vs. young adults: p&lt;0.01, <italic>φ</italic> = 0.56, odds ratio = 15.80, odds ratio 95% confidence interval (CI) = [1.94:∞], Cohen’s w = 0.48; older adults vs. young adults: p&lt;0.01, odds ratio = 14.75, odds ratio 95% CI = [1.88:∞], Cohen’s w = 0.45). This result is in agreement with previous reports on allocentric deficits in children and older adults (<xref ref-type="bibr" rid="bib26">Lester et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Bullens et al., 2010</xref>), while suggesting that the absence of proprioceptive and vestibular cues that characterize desktop-based virtual reality was not the cause for the egocentric bias in previous studies. In the geometric condition of the Y-maze task, there was no significant difference between the three age groups (<xref ref-type="fig" rid="fig2">Figure 2b</xref>; overall p=0.43; children: p=0.28; older adults: p=0.22). That is, a large majority of children and older adults were able to solve the task allocentrically, similarly to young subjects (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1b–d</xref> for statistical comparisons of each age group between the two experimental conditions). In order to confirm that the experimental condition differentially affected behavior in the three age groups, we evaluated the statistical interaction between age and condition in a logistic regression model of the data (see ‘Materials and methods’). According to this model, the probabilities of making an allocentric response in the landmark condition are 88, 32, and 31% (for young, children, and older participants, respectively), whereas in the geometry condition they are 99, 82, and 82%. The interaction effect is significant (second differences in children vs. young: <italic>Δ</italic> = 0.38, p&lt;0.001; children vs. older: <italic>Δ</italic> = 0.067, n.s.). These findings suggest that the allocentric deficits in children and older adults described so far in the literature are linked to a difference in how arrays of landmarks are used to orient and navigate in space. In order to corroborate the results obtained in immersive virtual reality, we reproduced the landmark condition in a real-world replica of the Y-maze in n = 17 participants (see <xref ref-type="video" rid="video2">Video 2</xref>). We found a majority of egocentric responses in older participants navigating the real-world maze (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a</xref>, p&lt;0.05, odds ratio = 11.11, odds ratio 95% CI = [0.79: ∞], Cohen’s w = 0.41), which suggested that the sensory restrictions that characterize immersive head-mounted display (e.g., reduction of the visual field or image quality) were not responsible for the observed egocentric bias. The data from the real-world replica were not further used in the following analyses, unless otherwise specified.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Proportion of allocentric behavioral responses during probe trials in the three age groups.</title><p>Bar plots indicate the proportion of subjects who made either a majority (i.e., 3/3 or 2/3) or a minority (i.e., 1/3 or 0/3) of allocentric choices during the three probe trials. That is, green corresponds to allocentric responses, whereas yellow indicates egocentric behaviors. (<bold>a</bold>) In the landmark condition (n=42), children and older adults failed to solve the Y-maze task since they mostly adopted an egocentric behavior. By contrast, a significant majority of young adults were able to solve the task allocentrically. (<bold>b</bold>) In the geometry condition (n=37), the three age groups behaved similarly, with children and older adults mostly using an allocentric strategy as young adults. p-Values correspond to pairwise comparisons using Fisher’s exact test across the corresponding age groups and strategy preferences. The source data for this figure is available in the <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>. This figure corresponds to the strategy preference observed in the virtual reality settings. The same data for the real-world replica can be found in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a</xref>.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Proportion of allocentric behavioral responses during probe trials across age groups.</title></caption><media mimetype="application" mime-subtype="zip" xlink:href="elife-81318-fig2-data1-v2.zip"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Proportion of allocentric choices in the three probe trials.</title><p>(<bold>a</bold>) Proportion of subjects behaving allocentrically in the real-world Y-maze during the landmark condition (n = 17 participants: nine young and eight healthy older adults). (<bold>b–d</bold>) Proportion of subjects behaving allocentrically in the virtual Y-maze during landmark vs. geometry condition (n = 79 participants: 29 children, 22 young adults, and 28 healthy older adults). p-Values correspond to pairwise comparisons using Fisher’s exact test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig2-figsupp1-v2.tif"/></fig></fig-group><media mimetype="video" mime-subtype="mp4" xlink:href="elife-81318-video2.mp4" id="video2"><label>Video 2.</label><caption><title>Examples of learning and probe trials in real-world conditions.</title></caption></media></sec><sec id="s2-2"><title>Landmark-based spatial learning is more difficult for children and older adults</title><p>To rule out other sensorimotor or cognitive factors, we comparatively assessed a battery of navigational variables as a function of age, condition and, when possible, interaction of thereof. During learning, subjects could possibly associate the initial view from the starting position with the navigational response (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). If spatial orientation using landmarks is generally more difficult for children and older adults, this difficulty should be reflected already during learning. To test this hypothesis, we compared the number of trials-to-criterion, traveled distance, escape latency, and navigation speed across the three age groups during learning, in both task conditions. Note that to better interpret the escape latency variable, we also analyzed separately the duration of the orientation period (i.e., the time between the start of the trial and the initiation of locomotion) and the duration of the navigation period (i.e., the time to reach the inferred goal location after locomotion started) for each trial (see ‘Materials and methods’). These analyses with age and condition as explanatory factors compared the navigation variables averaged over the first four trials of the learning phase (which were common to all subjects; see also <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> for scatter plots of these data). In the landmark condition, older adults required a higher number of trials than young adults to reach the learning criterion of four consecutive successful trials (<xref ref-type="fig" rid="fig3">Figure 3a</xref> left; older vs. young adults: U = 287.5, p&lt;0.05, n = 27, <italic>r</italic> = 0.49, Bayes factor [BF] = 1.97). We observed a similar tendency in children but the statistics were less conclusive (Mann–Whitney U = 226.5, p=0.065, n = 25, <italic>r</italic> = 0.37, BF = 0.92). In comparison, there was no evidence that children and older adults needed more learning trials to reach to criterion in the geometry condition compared to young adults (<xref ref-type="fig" rid="fig3">Figure 3a</xref> right; children vs. young adults: U = 213.5, p=0.19, n = 26, <italic>r</italic> = 0.25, BF = 0.56; older adults vs. young adults: U = 141.5, p=0.55, n = 23, <italic>r</italic> = 0.12, BF = 0.58). There was a significant main effect of age on navigation variables (traveled distance: F<sub>(73,2)</sub> = 6.6, p&lt;0.01, BF = 1.53, <xref ref-type="fig" rid="fig3">Figure 3b</xref>; escape latency: F<sub>(73,2)</sub> = 8.7, p&lt;0.01, BF = 31, <xref ref-type="fig" rid="fig3">Figure 3c</xref>; orientation duration: F<sub>(73,2)</sub> = 3.6, p&lt;0.05, BF = 2.37, <xref ref-type="fig" rid="fig3">Figure 3d</xref>; navigation duration: F<sub>(73,2)</sub> = 8.73, p&lt;0.001, BF = 19.88, <xref ref-type="fig" rid="fig3">Figure 3e</xref>; walking speed: F<sub>(73,2)</sub> = 3.3, p&lt;0.05, BF = 1.94, <xref ref-type="fig" rid="fig3">Figure 3f</xref>). The condition strongly influenced the distance traveled by the participants (traveled distance: F<sub>(73,1)</sub> = 48.6, p&lt;0.0001, BF = 1.1 × 10<sup>6</sup>) and their walking speed (F<sub>(73,1)</sub> = 27.9, p&lt;0.0001, BF = 4.7 × 10<sup>3</sup>), due to the corridors in the geometry condition being slightly longer than in the landmark condition (see ‘Materials and methods’). The other navigation variables were minimally or not influenced by condition (navigation duration: F<sub>(73,1)</sub> = 4.9, p&lt;0.05, BF = 1.21, escape latency: F<sub>(73,1)</sub> = 1.5, p=0.23, BF = 0.39; orientation duration: F<sub>(73,1)</sub> = 1.7, p=0.20, BF = 0.47). Finally, evidence in favor of an interaction between age and condition was found for the time-related variables like escape latency (F<sub>(73,2)</sub> = 3.2, p&lt;0.05, BF = 1.49; <xref ref-type="fig" rid="fig3">Figure 3c</xref>), navigation duration (F<sub>(73,2)</sub> = 4.1, p&lt;0.05, BF = 2.56; <xref ref-type="fig" rid="fig3">Figure 3e</xref>) but not for walking speed (F<sub>(73,2)</sub> = 2.7, p=0.07, BF = 1.25; <xref ref-type="fig" rid="fig3">Figure 3f</xref>), traveled distance (F<sub>(73,2)</sub> = 1.6, p=0.19, BF = 0.51; <xref ref-type="fig" rid="fig3">Figure 3b</xref>), or orientation duration (F<sub>(73,2)</sub> = 0.32, p=0.72, BF = 0.22; <xref ref-type="fig" rid="fig3">Figure 3d</xref>). Further investigation of the interactions showed evidence of a simple effect of age in the landmark condition (escape latency: F<sub>(73,2)</sub> = 3.1, p=0.052, with Bonferroni correction p=0.10; navigation duration: F<sub>(73,2)</sub> = 11.3, p&lt;0.0001, with Bonferroni correction p&lt;0.001) but not in the geometry condition (escape latency: F<sub>(73,2)</sub> = 0.83, p=0.44, navigation duration: F<sub>(73,2)</sub> = 1.52, p=0.22).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Spatial navigation performance during learning trials across the three age groups in the landmark (n=42, left) and geometry (n=37, right) conditions (<bold>a–f</bold>).</title><p>Colored lines represent median values for the three age groups. Box plots in (<bold>a</bold>) show the median (colored lines), the interquartile range (25th and 75th percentiles, length of the boxes), 1.5× interquartile range (whiskers) and outliers (dots). Error bars represent the standard error of the mean. p-Values in (<bold>a</bold>) shows uncorrected two-samples Mann–Whitney U tests.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Scatter plots of the navigation variables for the first four trials of the learning phase across the three age groups.</title><p>Color code: children (yellow), young (blue), and older (orange) adults.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig3-figsupp1-v2.tif"/></fig></fig-group><p>To summarize, in the landmark condition children and older adults adopted direct paths to the goal as young adults, but it nevertheless took them longer, likely reflecting a lower confidence in taking decision when facing the environment composed of landmarks (see below for the analysis of oculomotor behavior supporting this conclusion). Age differences were mitigated in the geometry condition as indicated by the absence of simple effects. In addition, the rapid convergence of learning curves for children and older adults in the presence of geometry (see <xref ref-type="fig" rid="fig3">Figure 3b, c, e, and f</xref>) suggested that one-trial learning took place in this condition. These results supported the hypothesis that learning to orient using landmarks was more difficult for children and older participants compared to young adults.</p></sec><sec id="s2-3"><title>Age-related navigational differences are not due to a faulty attention to landmarks</title><p>The combined eye- and head-motion recordings provided a mean to analyze gaze dynamics during reorientation and navigation periods, such as to infer the visual information used by the subjects (<xref ref-type="bibr" rid="bib4">Bécu et al., 2020</xref>). We sought to understand to what extent age-related differences in landmark-based behavior could be associated with specific oculomotor patterns. We only compare here the VR-based gaze dynamics of young against older adults (eye movements were not recorded in children, see ‘Materials and methods’). In particular, we investigated whether older subjects’ egocentric bias during testing was due to a lack of attention to landmarks during learning. We identified the visual stimuli fixated by each subject by calculating the intersections between the gaze vector and the elements of environment (i.e., landmarks, sky, maze walls, maze floor, etc.; see ‘Materials and methods’). In the landmark condition, both young and older participants spent a larger proportion of time at visually exploring the sky region (<xref ref-type="fig" rid="fig4">Figure 4a</xref>; U = 986, p&lt;0.0001, <italic>r</italic> = 0.82, n = 50, BF = 3311). While looking at the sky region, they focused their visual attention on the landmark that was located directly in front of their departure position (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). In the geometry condition, conversely, the participants observed mainly the floor region (<xref ref-type="fig" rid="fig4">Figure 4b</xref>; U = 856, p&lt;0.0001, <italic>r</italic> = 0.74, n = 50, BF = 968), focusing on the lower fork area of the Y-maze (<xref ref-type="fig" rid="fig4">Figure 4e</xref>). The average time spent on the sky and floor regions in the two conditions was about 20%, with the remaining 80% of the time devoted to fixating maze walls, independently of the condition (<xref ref-type="fig" rid="fig4">Figure 4c</xref>; U = 718, p=0.57, <italic>r</italic> = 0.08, n = 50, BF = 0.30). Separate analyses for the orientation and navigation periods of the learning trials showed that the sky and the floor were observed mainly during the orientation period, while during navigation the participants looked preferentially at the maze walls (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Importantly, we did not find evidence for an age difference in the time spent gazing at landmarks (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, U = 119, p=0.30, <italic>r</italic> = 0.27, n = 27, BF = 0.55), suggesting that age-related strategy difference during probe trials did not result from a lack of visual attention during learning.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Gaze-mediated exploratory behavior during spatial learning.</title><p>(<bold>a–c</bold>) Gaze dwell-time proportion for sky (<bold>a</bold>), floor (<bold>b</bold>), and wall (<bold>c</bold>) regions of the virtual space as a function of age (young adults n=22, older adults n=28) and experimental condition (landmark n=27, geometry n=23). We found a double dissociation between the time spent at visually exploring sky and floor regions in the landmark and geometry conditions (<bold>a</bold> and <bold>b</bold>, respectively). Neither age nor condition affected the gaze time proportion relative to the walls of the maze (<bold>c</bold>). Data were averaged across the four first trials. Box plots (<bold>a–c</bold>) show the median (colored lines), the interquartile range (25th and 75th percentiles, length of the boxes), 1.5× interquartile range (whiskers) and outliers (dots). (<bold>d</bold>) In the landmark condition, the spatial distribution of the visual focus of attention over the sky region showed that subjects gazed mostly at the landmark facing the departure point. Heatmaps data were pooled across age and the color bar normalization was computed for each group separately. (<bold>e</bold>) In the geometry condition, subjects mostly focused on the fork area of the Y-maze floor. (<bold>fg</bold>) Gaze dwell-time proportion in the sky region of the landmark condition(<bold>d</bold>) and the floor region of the geometry condition (<bold>e</bold>) as a function of learning trials, for young and older allocentric and egocentric subjects. No significant difference existed as either a function of age or strategy preference. Error bars show standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Oculomotor behavior in the learning phase in young and older groups.</title><p>(<bold>a</bold>) Gaze dwell-time proportion for floor and wall regions as well as for the three landmark sectors of the sky region. (<bold>b</bold>) Spatial distribution of visual focus of attention over the sky region of the landmark condition (left) and over the floor region of the geometry condition (right), for young (top, n=22) and older (bottom, n=28) adults. Oculomotor data were averaged (in <bold>a</bold>) and pooled (in b) across the four learning trials. Heatmap color bar normalization in (<bold>b</bold>) was computed for each group separately.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig4-figsupp1-v2.tif"/></fig></fig-group><p>To further support this conclusion, we analyzed within-group oculomotor signatures. We tested whether there existed differences between the gaze patterns of older subjects that adopted different navigation strategies during probe trials (i.e., allocentric vs. egocentric responses; see ‘Materials and methods’ and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for the distribution of subjects across age groups and strategy preferences). We found that during learning in the landmark condition, egocentric and allocentric older participants seemingly spent an equivalent proportion of time gazing at the sky region, and in particular at the landmark in front of their starting arm (<xref ref-type="fig" rid="fig4">Figure 4f</xref>; U = 84, p=0.96, n = 16, BF = 0.44). Similarly, in the geometry condition, we found evidence that egocentric and allocentric older participants gazed at the floor for an equivalent amount of time (<xref ref-type="fig" rid="fig4">Figure 4g</xref>; U = 13, p=0.90, n = 11, BF = 0.54). Moreover, in both conditions, we did not find evidence for different gaze patterns between allocentric young participants and allocentric or egocentric older participants (<xref ref-type="fig" rid="fig4">Figure 4f and g</xref>; landmark condition: U = 181, p=0.13, <italic>r</italic> = −0.30, n = 25, BF = 0.67; geometry condition: U = 122, p=0.56, <italic>r</italic> = −0.12, n = 23, BF = 0.43). Note that because there was only one egocentric young subject, we only considered allocentric young participants for these age-based comparisons. These data reinforced the conclusion that the bias toward egocentric navigation responses in the older population was not caused by a lack of visual attention to landmarks during learning. Nevertheless, a majority of them did not use this information during the probe phase.</p></sec><sec id="s2-4"><title>Older adults use a view-matching strategy when the landmarks are present</title><p>In a subsequent set of analyses, we looked for oculomotor signatures of distinct navigational responses during the probe trials. The rationale was to provide some insights into the dynamical use of spatial cues when the departure arm was different from the one used throughout learning. Gaze dwell-time analyses showed that allocentric navigators spent about 40% of the trial duration exploring the sky region, with no age effect (<xref ref-type="fig" rid="fig5">Figure 5a</xref>; Mann–Whitney U test, young allocentric vs. older allocentric participants: U = 49, p=0.95, n = 15, BF = 0.47). This was about twice the time spent by allocentric participants gazing at the same sky region during learning trials (<xref ref-type="fig" rid="fig4">Figure 4f</xref>; Wilcoxon signed-rank test, young subjects: W = 44, p&lt;0.01, n = 9, BF = 16; older subjects: W = 21, p&lt;0.05, n = 6, BF = 11). These results were in a stark contrast with those with egocentric subjects, for whom there was no difference in the time spent gazing at the sky area during learning and probe trials (<xref ref-type="fig" rid="fig4">Figure 4f</xref> and <xref ref-type="fig" rid="fig5">Figure 5a</xref>; Wilcoxon signed-rank test, older group: W = 32, p=0.69, n = 10, BF = 0.39). These findings suggested that the longer time spent by allocentric subjects at fixating landmarks during probe trials may reflect cognitive processes related to landmark-based spatial orientation. In order to gain more information about these processes, we analyzed the evolution of gaze dwell-times throughout probe trials, during both orientation and navigation periods (by separating the sky area in three sectors corresponding to the circle, square, and start landmarks, <xref ref-type="fig" rid="fig5">Figure 5b</xref>). We found that gazing at the star (located directly in front of the starting position B) at the very beginning of the orientation period (i.e., upon opening of the eyes) was sufficient for allocentric young subjects to navigate to the goal (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, top). They did not focus on other landmarks, indicating a good knowledge of the environment in this age group (see also <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>). Allocentric older navigators had a similar gazing behavior during reorientation, but they also looked at the circle during navigation (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, center and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1b</xref>). Since the circle was directly in front of the departure position during learning, this suggested that allocentric older participants might use a cue-based (i.e., view-matching), rather than map-based, strategy. To verify this hypothesis, we first compared the navigation trajectories of young and older allocentric participants during the first probe trial (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). We observed that allocentric older navigators tended to decrease their walking speed at the center of the maze and they eventually gazed at the red circle, unlike young adults (<xref ref-type="fig" rid="fig6">Figure 6a and b</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1c</xref>). This observation was confirmed by a quantitative analysis showing that when older adults were in the central area of the maze, they spent a longer time gazing at the circle landmark, compared to young ones (U = 45, p=0.054; n = 14, BF = 2), favoring an egocentric view-matching strategy with aging.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Gaze dynamics in the probe trials of the landmark condition.</title><p>(<bold>a</bold>) Gaze dwell-time proportion relative to the sky region for young and older subjects. Independently from age, allocentric navigators explored significantly more the sky region in the probe trials (~40% of the trial) compared to the learning trials (~20% of the trial, see <xref ref-type="fig" rid="fig4">Figure 4f</xref> for a comparison). This result did not hold for older egocentric subjects, who spend ~20% of the trial gazing at the sky, irrespective of the learning or probe phases. Error bars show standard error of the mean. (<bold>b</bold>) For analysis purposes, the sky region was separated in landmark-centered sectors, as indicated by dashed lines. (<bold>c</bold>) Evolution of gaze dwell-times throughout the probe trials, including orientation and navigation periods, as a function of landmark sectors, age, and navigation strategy. The star sector corresponds to the landmark directly in front of the departure position in probe trials, while the circle sector corresponds to the landmark directly in front of the starting position in the learning trials. Allocentric young and older subjects focused on the star upon opening the eyes to reorient in space and plan their goal-oriented trajectories. During navigation, allocentric older adults switched their visual focus of attention onto the red landmark when being at the center of the maze. Egocentric older adults looked at the star during orientation as well as while navigating toward the center of the maze.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Time spent gazing at the three landmarks during the first probe trial of the landmark condition (young adults, n=10 and older adults, n=17).</title><p>(<bold>a</bold>) During the orientation period, (<bold>b</bold>) during the navigation period, and (<bold>c</bold>) during the time spent in the central area of the environment. Box plots show the median (colored lines), the interquartile range (25th and 75th percentiles, length of the boxes), 1.5× interquartile range (whiskers) and outliers (circles). Young and older adults data. P-values from the Mann-Whitney U test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig5-figsupp1-v2.tif"/></fig></fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Trajectories and gaze vector field representations in the first probe trials of the landmark condition in young and older adults.</title><p>Qualitative representations of goal-oriented trajectories color-coded with instantaneous speed (top rows), and gaze vectors (bottom rows) of six representative young (<bold>a</bold>) and older (<bold>b</bold>) allocentric navigators. Older adults tended to slow down at the center of the Y-maze where they eventually gazed at the red circle.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig6-v2.tif"/></fig></sec><sec id="s2-5"><title>The presence of geometry eliminates age-related differences in navigational performances</title><p>We then quantitatively assessed the ‘cost’ of implementing an allocentric strategy by comparing the navigational variables of young vs. older allocentric participants during probe trials (<xref ref-type="fig" rid="fig7">Figure 7a–d</xref>). These analyses were carried out in n = 36 allocentric adults, with two-way ANOVAs with Age and Condition as explaining factors or Mann–Whitney rank-sum tests. Interactions were significant (escape latency: F<sub>(32,1)</sub> = 9.92, p&lt;0.01, BF = 4.5, <xref ref-type="fig" rid="fig7">Figure 7a</xref>; orientation duration: F<sub>(32,1)</sub> = 8.36, p&lt;0.001, BF = 4.36, <xref ref-type="fig" rid="fig7">Figure 7b</xref>; central area: F<sub>(32,1)</sub> = 13.03, p&lt;0.01, BF = 19, <xref ref-type="fig" rid="fig7">Figure 7c</xref>), and simple effects with Bonferroni adjustment supported a different impact of age in the landmark and geometry conditions. In the landmark condition, older allocentric adults were significantly slower to initiate walking upon opening the eyes compared to young allocentric subjects (i.e., the orientation duration was longer, <xref ref-type="fig" rid="fig7">Figure 7b</xref>; F<sub>(32,1)</sub> = 20.13, p&lt;0.001), they traveled a longer goal-directed distance (<xref ref-type="fig" rid="fig7">Figure 7d</xref>; U = 49, p&lt;0.01, n = 15, BF = 2.7), and as a result, they were slower to reach the goal (i.e., larger escape latency, <xref ref-type="fig" rid="fig7">Figure 7a</xref>; F<sub>(32,1)</sub> = 30.4, p&lt;0.0001). Coherent with a view-matching strategy in the presence of landmarks, we found that older allocentric subjects spent a longer time (up to 33 s) in the central area of the maze compared to young participants (<xref ref-type="fig" rid="fig7">Figure 7c</xref>; F<sub>(32,1)</sub> = 21.13, p&lt;0.001). In the geometry condition, there was no age effect on navigation during the probe trials. Older adults were as quick as young ones in using an allocentric strategy in relation to the geometry, to make their decisions and to reach the goal, which argues in favor of similar processes governing spatial behavior in these two age groups in the geometry condition (<xref ref-type="fig" rid="fig7">Figure 7a–d</xref> and <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, escape latency: F<sub>(32,1)</sub> = 0.92, p=0.68, time in the central area: F<sub>(32,1)</sub> = 034, p=1, orientation duration: F<sub>(32,1)</sub> = 0.72, p=0.79, traveled distance: U = 109, p=0.11, n = 21, <italic>r</italic> = −0.35, BF = 0.97).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>The presence of geometric cues eliminated the effect of age on navigation.</title><p>In the landmark condition, older allocentric adults took longer to reach the goal (<bold>a</bold>), were slower at reorienting in space (<bold>b</bold>), spent significantly more time in the central area of the maze (<bold>c</bold>), and their trajectories to the goal were longer compared to young allocentric adults (<bold>d</bold>). In comparison, there was no age difference in the geometry condition. Box plots in show the median (colored lines), the interquartile range (25th and 75th percentiles, length of the boxes), 1.5× interquartile range (whiskers) and outliers (circles). Stars indicate significant simple effect or Mann-Whitney test. These analysis were carried out in n=36 allocentric adults.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Oculomotor behavior and navigation measures in the probe trials of the geometry condition.</title><p>(<bold>a</bold>) Gaze dwell-time proportion over the floor region for young allocentric subjects as well as older allocentric and egocentric navigators (there was no young egocentric subjects in the geometry condition). (<bold>b</bold>) Evolution of gaze dwell-time proportion for wall, floor, and sky regions across probe trials. (<bold>c–f</bold>) Time spent in central area, traveled distance, orientation duration, and escape latency during probe trials. Error bars represent the standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig7-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-6"><title>Gaze dynamics predicts behavioral strategy during probe trials</title><p>Given the clear distinction between egocentric and allocentric subjects in terms of sky vs. floor gaze dwell-times, we sought to assess to what extent eye-movement signatures before the initiation of locomotion could predict future behavioral responses. To do so, we trained a binary classifier (on a single-subject-single-trial basis) with the altitude of the gaze during orientation of the probe trials as the independent predictor variable (see ‘Materials and methods’). This choice was based on the observation of more distinct gaze altitude profiles during the orientation period of both experimental conditions (<xref ref-type="fig" rid="fig8">Figure 8a and b</xref>). We quantified the performance of the classifier by both a 25% hold-out and a leave-one-out validation procedure. We found that gaze altitude patterns during orientation in the landmark condition allowed the future spatial strategy adopted by the subject to be reliably predicted (<xref ref-type="fig" rid="fig8">Figure 8c</xref>; 25% hold-out: p=0.05, 88 and 61% of participants using an allocentric or egocentric strategy were correctly classified, respectively; leave-one-out: 79% of the subjects were correctly classified, n = 26). Expectedly, the gaze altitude also provided a robust predictor of the experimental condition undertaken by the subject (<xref ref-type="fig" rid="fig8">Figure 8d</xref>; 25% hold-out: p=0.0001, 97 and 81% of participants were correctly classified in the geometry and landmark condition, respectively; leave-one-out: 88%, n = 49). Supposedly, the lower predictability found in the landmark group, especially in people using an egocentric strategy, reflects the higher variability in gaze altitude observed in this group (see standard errors in <xref ref-type="fig" rid="fig8">Figure 8a and b</xref>).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Predictive eye-motion statistics.</title><p>(<bold>a, b</bold>) Evolution of gaze altitude throughout probe trials. In both the landmark (<bold>a</bold>) and geometry (<bold>b</bold>) conditions, the gaze altitude during reorientation differed between allocentric and egocentric navigators. Eye level is denoted by 0. Shaded areas represent the between-subject standard error of the mean. (<bold>c</bold>) Distribution of the proportion of correct single-subject-single-trial predictions of the strategy used to solve the landmark condition of the Y-maze, based on the gaze altitude statistics during reorientation. The dashed vertical line indicates chance-level prediction, that is, the area to the left of the dashed line represents the probability (p-value) that less than half of the subjects in the validation set were correctly classified. (<bold>d</bold>) Prediction performance with respect to the experimental condition, that is, landmark vs. geometry, again on the basis of gaze altitude statistics during reorientation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig8-v2.tif"/></fig></sec><sec id="s2-7"><title>Visual and cognitive correlates of age-related behavioral differences</title><p>A subsample of 64 participants (29 young and 35 older adults) enrolled in the study underwent a battery of visual and neurocognitive screenings (see ‘Materials and methods’ and <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). We pooled participants from the VR/real-world experiments and the landmark/geometry conditions to gain statistical power for these visual and cognitive analyses. These tests were not performed in the children group. Among the selected participants, 47 were screened across the complete battery of 19 assessments, while the rest had one or more missing measurements. We exploited these multivariate data to better interpret individual behavioral responses and to avoid potential biases. We first tested whether age and strategy categories corresponded to localized regions of the multivariate feature space. Principal component analysis (PCA) revealed that the participant scores along the first principal axis of the data allowed subjects to be discriminated according to their age (<xref ref-type="fig" rid="fig9">Figure 9a</xref>; young vs. older: t(45) = 6.32, p&lt;0.001) as well as to the strategy preference in the older population (egocentric vs. allocentric: t(30) = 3.11, p&lt;0.01). The age effect was indeed significant in the large majority (74%) of the screening tests (see <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplements 1</xref>–<xref ref-type="fig" rid="fig9s2">2</xref>). We then tested whether the observed strategy differences between experimental conditions (<xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a</xref>) could possibly be associated to differences in visuo-cognitive characteristics of participants (‘Condition effect’), and whether egocentric and allocentric subjects could be distinguished based on their screening test scores (‘Strategy effect’). We performed this analysis only in the older adults because there was no egocentric young adult in the geometry condition. We did not find any differences in the test scores according to the task condition (Condition effect, all p&gt;0.0.5), suggesting no visuo-cognitive sampling bias in the data. We found that egocentric older subjects, compared to allocentric ones, had lower scores in the perspective taking test (<xref ref-type="fig" rid="fig9">Figure 9b</xref>; F(33,1) = 4.34, p&lt;0.05), mental flexibility (B-A difference: F(34,1) = 7.96, p&lt;0.01, B-A ratio: F(34,1) = 9.73, p&lt;0.01; <xref ref-type="fig" rid="fig8">Figure 8c</xref>), and contrast sensitivity, especially at high frequencies (<xref ref-type="fig" rid="fig8">Figure 8d</xref>; two circles per degree, 4 cycles per degree [CPD]: U = 194, p=0.088; 8 CPD: U = 187.5, p=0.0042; 16 CPD: U = 184.5, p=0.0029, with Bonferroni <italic>α</italic> = 0.017, see comparisons for all measures in <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplements 1</xref>–<xref ref-type="fig" rid="fig9s2">2</xref>). The main conclusion from these analyses was that the observed deficits in landmark-based spatial coding were likely to be linked to difficulties in flexibly processing and reasoning about landmarks (possibly related to perspective taking, mental flexibility/rotation), as well as to a lower capacity to perceive fine details. In contrast, visual attention, figure memory, and processing speed differences did not seem to play a role.</p><fig-group><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Visuo-cognitive multivariate analysis of age-related modulation of spatial behavior.</title><p>(<bold>a</bold>) Principal component analysis (PCA) across 19 measures of visual, attentional, mnemonic, and spatial reasoning capabilities (see <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref> for test descriptions). Participants could be discriminated based on their age and, within the older population, their strategy preference. PCA was performed on 47 participants for whom we had the complete visuo-cognitive battery. (<bold>b–d</bold>) Scores of perspective taking, TMT mental flexibility, and contrast sensitivity. Error bars in (<bold>d</bold>) represent the standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig9-v2.tif"/></fig><fig id="fig9s1" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 1.</label><caption><title>Cognitive screening results for adult participants.</title><p>p-Values indicated to the left of the dashed vertical lines correspond to the comparison of the ‘Age effect’ (young vs. older adults, pooled across the two versions), whereas the other p-values concern the ‘Strategy effect’ (allocentric vs. egocentric within the older group of participants). See <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref> for the description of all cognitive tests. We specify the n in each group since some subjects had one or more missing data among all the 19 measurements.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig9-figsupp1-v2.tif"/></fig><fig id="fig9s2" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 2.</label><caption><title>Visual screening results for adult participants.</title><p>p-Values indicated to the left of the dashed vertical lines correspond to the comparison of the ‘Age effect’ (young vs. older adults, pooled across the two versions), whereas the other p-values concern the ‘Strategy effect’ (allocentric vs. egocentric within the older group of participants). See <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref> for the description of all visual tests. We specify the n in each group since some subjects had one or more missing data among all the 19 measurements.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig9-figsupp2-v2.tif"/></fig><fig id="fig9s3" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 3.</label><caption><title>Results from post-experiment self-reported visuo-spatial memory of landmarks.</title><p>(<bold>a</bold>) Recognition of the maze shape (among three possibilities). (<bold>b</bold>) Recall of the landmarks (among six possibilities). (<bold>c, d</bold>) Drawing of a top view map of the maze with the landmark array (<bold>c</bold>: example of a correct map; <bold>d</bold>: example of an incorrect one). (<bold>e</bold>) Quantitative performance of participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-fig9-figsupp3-v2.tif"/></fig></fig-group><p>Finally, we looked for representational errors that could have precluded children and older subjects to use landmarks for orientation. To do so, we tested a subset of participants for their memory of the maze immediately after they completed the landmark condition. We asked 13 children and 7 older adults to (i) recognize the maze shape out of three possibilities (<xref ref-type="fig" rid="fig9s3">Figure 9—figure supplement 3a</xref>), (ii) recognize the landmarks within an ensemble with three distractors (<xref ref-type="fig" rid="fig9s3">Figure 9—figure supplement 3b</xref>), and (iii) draw a top-view map of the maze they experienced (<xref ref-type="fig" rid="fig9s3">Figure 9—figure supplement 3c and d</xref>). We found that a minority of subjects (15%) made errors in recognizing the maze shape and that all subjects had an intact memory of landmarks (<xref ref-type="fig" rid="fig9s3">Figure 9—figure supplement 3e</xref>). In contrast, the association between the remembered landmarks, maze layout, and goal position was problematic as almost half of the subjects (45%) could not place the landmarks in the correct order and even when they did, the landmark array was misaligned either with the maze (45%) or with the goal (65%). Among the 15 subjects who made at least one error on the drawing, 11 (73%) failed to use an allocentric-like strategy in the testing phase. Although performed in a very small sample of subjects, these findings supported our conclusions from the profiling data analyses, in that binding of the landmarks to the cognitive representation of space, rather than the memory of landmarks itself, would underlie the age-related deficits in allocentric-like behavior.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The main finding of this study is that a geometric polarization of the environment removes the egocentric bias in both healthy older adults (&gt;65 yo) and children (~10 yo), and it habilitates their allocentric navigation capabilities. This result provides a strong evidence in support of the hypothesis that age-related allocentric navigation deficits, largely described in the literature (<xref ref-type="bibr" rid="bib10">Colombo et al., 2017</xref>; <xref ref-type="bibr" rid="bib55">Wiener et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Davis and Weisbeck, 2015</xref>; <xref ref-type="bibr" rid="bib13">Driscoll et al., 2005</xref>; <xref ref-type="bibr" rid="bib44">Rodgers et al., 2012</xref>; <xref ref-type="bibr" rid="bib5">Bohbot et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">van der Ham et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Newcombe, 2019</xref>; <xref ref-type="bibr" rid="bib37">Nardini et al., 2006</xref>; <xref ref-type="bibr" rid="bib6">Bullens et al., 2010</xref>), can rather be ascribed to an difficulty in using a landmark array for navigation purpose. By means of a Y-maze paradigm enabling natural, physical displacement of subjects in space, we found that children and older navigators are impaired at exhibiting allocentric behaviors when landmarks are the only environmental spatial cues. However, when geometric information is present and informative about the spatial relations between the goal and the subject’s position in space, children and older adults become as good allocentric navigators as young subjects.</p><p>Through an analysis of locomotor and oculomotor behavior, we showed that learning to orient on the basis of landmark arrays is more difficult than with geometry in children and older adults (independently of the navigation strategy that they put forward in the subsequent probe tests). During learning, all subjects had similar visual exploratory behavior regardless of age (e.g., they all gazed at landmarks for equivalent amount of times). This result suggests that the difficulty in using landmarks for navigation is not merely caused by a lack of visual attention to them. The analysis of neuropsychological and cognitive data as well as post-hoc questionnaires showed that landmark-specific deficits may be linked to difficulties in spatial manipulations of landmark configurations in a navigation-informative way (e.g., mental rotation of a landmark array and inference of self and goal positions in relation to rotated landmarks). These analyses also suggested age-related changes in binding landmark identities to the internal representation of the environment, whereas the memory of landmarks themselves was relatively intact. These conclusions are in line with previous studies showing that estimating and reproducing distances and rotations in a geometrically isotropic environment (i.e., a circular arena) is impaired in older adults (<xref ref-type="bibr" rid="bib33">Mahmood et al., 2009</xref>) and that their performance does not improve when landmarks are provided (<xref ref-type="bibr" rid="bib19">Harris and Wolbers, 2012</xref>). Our data are also in agreement with previous works showing age-related deficits in the retrieval of spatial position (<xref ref-type="bibr" rid="bib20">Jansen et al., 2010</xref>) of landmarks and their temporal order (<xref ref-type="bibr" rid="bib56">Wilkniss et al., 1997</xref>; <xref ref-type="bibr" rid="bib28">Lindenberger and Baltes, 1994</xref>) during route learning. We also show that the observed egocentric bias in aged adults is associated with lower contrast sensitivity to high spatial frequencies. This effect is unlikely to directly cause differences in navigational decisions since landmarks were clearly visible and our participants were screened for normal visual acuity. However, lower visual scores were repeatedly associated with cognitive impairments in large cohort studies (<xref ref-type="bibr" rid="bib28">Lindenberger and Baltes, 1994</xref>; <xref ref-type="bibr" rid="bib43">Roberts and Allen, 2016</xref>; <xref ref-type="bibr" rid="bib36">Naël et al., 2019</xref>), in which impoverished sensory (e.g., visual) input was shown to increase the risk of cognitive decline in aging.</p><p>The differential influence of landmark and geometric cues on human navigation suggests a potential dissociation of the related neural processing pathways. If indeed different subnetworks in the brain mediate the processing of different types of cues (<xref ref-type="bibr" rid="bib40">Ramanoël et al., 2022</xref>), our results suggest that the subnetwork dedicated to geometric processing matures earlier in development and it is preserved better in aging. Construction of geometry-based spatial representations could thus represent the basic mode of spatial learning, with efficient binding of landmark to the representations of space developing during primary school years and deteriorating early in aging. The proposed dissociation between brain systems mediating geometric and landmark processing in the brain is not new, and a number of experimental studies and theoretical models addressed this question (<xref ref-type="bibr" rid="bib9">Cheng, 1986</xref>; <xref ref-type="bibr" rid="bib12">Doeller and Burgess, 2008</xref>; <xref ref-type="bibr" rid="bib48">Sheynikhovich et al., 2009</xref>; <xref ref-type="bibr" rid="bib21">Julian et al., 2015</xref>; <xref ref-type="bibr" rid="bib23">Krupic et al., 2015</xref>; <xref ref-type="bibr" rid="bib22">Julian et al., 2016</xref>). However, the age-related aspect of this dissociation is novel. In a recent modeling work, we have proposed that landmark-geometry dissociation may follow a well-established neurophysiological distinction between the dorsal and ventral visual processing streams (<xref ref-type="bibr" rid="bib27">Li et al., 2020</xref>), substantiating earlier proposals related to the role of these pathways in mediating allocentric and egocentric cue representations (<xref ref-type="bibr" rid="bib7">Burgess, 2006</xref>; <xref ref-type="bibr" rid="bib38">Nau et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Litman et al., 2009</xref>).</p><p>The fact that in the geometry condition of the navigation task all age groups had equivalent performance in terms of behavioral and oculomotor measures suggests that children and older adults may not be as bad navigators as previously thought, provided that anisotropic geometric cues are available. Confirming previous data from a real-world navigation task (<xref ref-type="bibr" rid="bib4">Bécu et al., 2020</xref>), we show that gazing at the floor contributes to the extraction of geometry-related information about the environment. We put forth an important function of geometry for spatial orientation and navigation across the lifespan, permitting fast learning of the environmental layout, efficient inference of self-position, and the relative goal location in space. Altogether, these findings highlight the necessity to rethink the impact of age on spatial cognition and to reframe the classical allocentric–egocentric dichotomy in terms of landmark-geometry spatial processing and coding. It also calls for rethinking navigational aids and environment architectural designs where older adults and children usually evolve. This article suggests that emphasizing geometric cues could favor navigation of these populations and reduce their chance of getting lost.</p><p>A limitation of our results resides in the fact that we remain blind to the exact neural mechanisms that mediate the anchoring of landmarks to the geometry-based representation of space and how they are affected by aging. Our interpretations thus need to be complemented by neuroimaging investigations, possibly with longitudinal follow-up to reduce potential cohort effects. As a first step toward this issue, experiments should aim at differentiating brain areas implicated in geometry vs. landmark processing in humans, and at characterizing, possibly with longitudinal designs, age-related cortical and subcortical changes potentially linked to the preserved use of allocentric strategies in the presence of geometric cues. Finally, given that older age induces a stronger reliance on the external environment in general (<xref ref-type="bibr" rid="bib29">Lindenberger and Mayr, 2014</xref>) and on visual information in particular (<xref ref-type="bibr" rid="bib2">Agathos et al., 2015</xref>; <xref ref-type="bibr" rid="bib3">Alberts et al., 2019</xref>), results stemming from the coupling of behavioral and neuroimaging will provide a novel insight for rehabilitation solutions for spatial navigation in aging.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>A sample of 79 subjects were enrolled in the virtual reality implementation of the study: 29 children (range: 10–11 y, μ = 10, std = 0.49, 17 females, 12 males), 22 young adults (range: 23–37 y, μ = 28, std = 4.28, 13 females, 9 males), and 28 healthy older adults (range: 67–81 y, μ = 73, std = 3.90, 17 females, 11 males). We used a power analysis to estimate this sample size for our three age groups, with an alpha level of 0.05, a target power of 0.8, and an expected effect size of 0.356, as derived from <xref ref-type="bibr" rid="bib44">Rodgers et al., 2012</xref>. Based on these parameters, a minimal sample size of 77 was estimated in order to reach 0.8 power for our design (<xref ref-type="bibr" rid="bib17">Faul et al., 2007</xref>). For the real-world experiment, we enrolled 17 participants: 9 young adults (range: 22–33 y, μ = 27.39, std = 4, 6 females, 3 males) and 8 healthy older adults (range: 66–78 y, μ = 72.40, std = 4, 4 females, 4 males). All young and older adult participants enrolled in either the virtual reality or the real-world experiment were part of the SilverSight cohort study (<xref ref-type="bibr" rid="bib24">Lagrené, 2019</xref>) at the Paris Vision Institute – Quinze-Vingts National Ophthalmology Hospital. The children were recruited in a primary school in the Paris area. All participants were voluntary, and they (or their parents in the case of children) gave an informed consent for inclusion in the study. All screening and experimental procedures were in accordance with the tenets of the Declaration of Helsinki, and they were approved by the Ethical Committee CPP Ile de France V (ID_RCB 2015-A01094-45, no. CPP: 16122 MSB). Adult participants were included in the study based on the following criteria: (i) corrected visual acuity of at least 7/10 and 5/10 in participants younger and older than 70 yo, respectively; (ii) a Mini-Mental State Examination score of 24 or higher; and (iii) no physical inability in terms of locomoting without assistance. The complete list of inclusion/exclusion criteria used for the SilverSight cohort is described in <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref>. The clinical and functional assessment of the adult participants included ophthalmological screening (e.g., optical coherence tomography, fundus photography), functional visual screening (e.g., visual acuity, visual field extent, contrast sensitivity, attentional field of view), otorhinolaryngological examination (e.g., audiogram, vestibular function), cognitive-neuropsychological assessment (e.g., visuo-spatial memory, mental rotation, executive functions), oculomotor evaluation (e.g., ocular fixation, saccadic control), and a static/dynamic balance assessment. A series of questionnaires were also administered to evaluate the quality of vision with respect to mobility and spatial orientation. In this study, a subset of these multivariate tests were used to avoid sampling biases related to inter-individual characteristics variability and to control for co-factors affecting spatial behavior. Participants habitually wearing far-vision lenses were encouraged to keep their glasses on during the experiment.</p></sec><sec id="s4-2"><title>Experimental setup</title><p>Adult participants were all tested in the Streetlab experimental platform at the Vision Institute (see <xref ref-type="video" rid="video1">Videos 1</xref>–<xref ref-type="video" rid="video2">2</xref>). The experiments with children were setup in a school gymnasium. The immersive virtual reality (VR) environment was created using the Unity3D game engine (Unity Technologies), and it was displayed using the HTC VIVE headset equipped with a Tobii Pro VR binocular eye tracker. Participants were equipped with a wireless VR capable backpack system (VR One, MSI). Experiment control and monitoring were performed remotely. This setup allowed the participants to move freely and explore the immersive virtual space. The head position in the real space was tracked at 30 Hz by two laser emitters placed 9 m away from each other and at a height of 3 m enabling an experimental capture area of approximately 4.0 × 4.0 m. The HTC VIVE headset had a nominal field of view of about 110° through two 1080 × 1200 pixels displays, updated at 90 Hz. The pixel density of the display was about 12 pixels/degree. The Tobii eye-tracker recorded eye movements at a rate of 120 Hz. The equipment used with children was the same as for adults, except that no eye-tracking was performed. The real-world maze was built within the Streetlab experimental platform (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The maze walls were made of black Plexiglas acrylic panels that reflected the visible light while allowing infrared (IR) light to pass through. Body movements were recorded by an opto-electronic motion capture system (10 infrared cameras, model T160) at 120 Hz (VICON Motion Systems Inc). During the experiment, participants wore a tight black suit equipped with 39 infrared reflective markers, following the Vicon Plug-In-Gait model. Marker detection and tracking stability (computed as the position tracking error with respect to a reference measurement without the IR panels) indicated a sub-millimeter accuracy. Participant binocular eye movements were tracked at 60 Hz with SMI eye-tracking glasses (SensoriMotor Instruments).</p></sec><sec id="s4-3"><title>Spatial navigation task</title><p>Two versions of the Y-maze tasks were used in the immersive virtual reality study: the classical landmark-based equiangular Y-maze (<xref ref-type="fig" rid="fig1">Figure 1a</xref>) and a new geometrically polarized Y-maze (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Both mazes were composed of three corridors, with homogeneously textured walls. In order for all subjects to have to same visual experience of the maze, the wall size was adjusted individually such as to exceed the height of each subject by 10 cm. In the equiangular landmark condition, all corridors were 66 cm wide and 190 cm long. Three distal landmarks were placed 8 m above the maze walls at a distance of 20 m from the maze center: a green star, a blue square, and a red circle, each subtending a visual angle of 10°, if seen from the maze center. In the geometrically polarized condition, all corridors were 66 cm wide and 230 cm long. No distal landmarks were present in this condition. The corridors were longer in the geometric condition than in the landmark one to prevent the subject from seeing the end of the corridor from the departure location. Overall, the maze size in the geometry condition was 1.54 times bigger than in the landmark condition. No shadows were present in the virtual environment and the sky was homogeneous. Subjects were randomly assigned to either the landmark or geometry condition under the constraint of equal gender distribution. In the real-world component of the study, only the landmark-based equiangular Y-maze was implemented (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></sec><sec id="s4-4"><title>Experimental protocol</title><p>The experiment with the virtual maze (in either the landmark of the geometry condition) lasted approximately 30 min per participant. Prior to the experimental session, the headset and the inter-pupillary distance were adjusted for each participant, and a nine-point eye-tracker calibration with head fixed was carried out. The quality of the calibration was verified by using the same nine-point procedure at the beginning, halfway through, and at the end of the experiment. Whenever the mean angular calibration error exceeded 3°, the adjustment/calibration/verification procedure was repeated. Before every trial, the following disorientation procedure was performed: the subject was asked to keep the eyes closed and to hold the hands of the experimenter, while being passively led around the room for approximately 2 min (<xref ref-type="video" rid="video1">Video 1</xref>). To mask uncontrollable sound sources, a non-informative sound was played in the headphones during the whole experiment. To verify the effectiveness of the disorientation procedure, the subject was asked to point to a conspicuous room cue (i.e., a computer, located near the exit of the experimental room). If the pointing error was less than 90°, the entire disorientation procedure was repeated. At the beginning of each trial, the disoriented subject was placed at the departure location (e.g., position A in <xref ref-type="fig" rid="fig1">Figure 1a</xref>), facing the center of the maze. He/she was instructed not to walk through the virtual walls and not to stand on tiptoes. Before undergoing the two experimental phases (i.e., learning and testing, see below), the subject had to perform three exploration trials (60 s each), starting from each arm of the maze. He/she was explicitly instructed to explore the whole environment. If the subject did not enter one of the arms or did not look up in the direction of the landmarks, he/she was encouraged to do so by the following instruction though the headphones: ‘Make sure to explore the whole environment.’ At the beginning of each trial of the learning phase, the disoriented subject was placed at the departure position A (<xref ref-type="fig" rid="fig1">Figure 1a and b</xref>) and instructed to navigate, as directly as possible, to the goal (dashed C area in <xref ref-type="fig" rid="fig1">Figure 1a and b</xref>; radius: 0.4 m). The learning phase ended after four consecutive successful trials, defined as the trials in which the subject went directly to the goal without entering the arm B. At the beginning of each trial of the second, testing phase, the disoriented subject was placed in one of the two non-goal arms. The following predefined sequence of starting location areas was used: B, A, A, B, A, B. Each testing trial ended when the subject stopped for at least 5 s at the end of one of the three arms. No reward signal was given during testing trials. Once a trial was ended, the image displayed on the headset faded, the subject was instructed to close the eyes and disorientation began. A questionnaire testing the memory of the experimental environment was administered to a subset of subjects (n = 20) tested in the landmark condition. The protocol used for the experiments conducted in the real-world setting was identical (<xref ref-type="video" rid="video2">Video 2</xref>).</p></sec><sec id="s4-5"><title>Data processing</title><sec id="s4-5-1"><title>Navigation measures</title><p>Spatial navigation in the virtual maze was assessed separately in the learning and testing phase. To quantify spatial learning, the following navigation variables were measured based on the subjects’ trajectories obtained from head tracking data: (i) <italic>trials-to-criterion,</italic> defined as the number of trials until the criterion of four consecutive successful trials was reached (see above for the definition of a successful trial); (ii) <italic>traveled distance,</italic> defined as the length (in meters) of a start-to-goal trajectory; (iii) <italic>escape latency,</italic> calculated as the time (in seconds) necessary to reach the goal zone from the departure location. In the experiments, each trial was separated into an initial <italic>orientation</italic> period, during which the subject opened the eyes and self-located in space, and the subsequent <italic>navigation</italic> period, during the subject physically moved throughout the Y-maze. For analysis purposes, the orientation period was taken as the time interval between the start of image projection on the HMD and locomotion initiation, that is, the moment when the subject exited a virtual circle (radius: 0.3 m) around the departure position. The navigation period was calculated as the time between the start of and the end of locomotion (e.g., upon entrance in the goal area during the learning phase). Therefore, the following time-related variables were used for analyses: (4) <italic>orientation-period duration</italic> and (v) <italic>navigation-period duration</italic>, both measured in seconds. In addition, the (vi) <italic>average speed</italic> was measured as the average instantaneous speed along the trajectory during the navigation period. Given that walking speed is correlated with a person’s height (<xref ref-type="bibr" rid="bib47">Samson et al., 2001</xref>), the <italic>normalized speed</italic> (i.e., average speed divided by the height) was used in the statistical comparisons between adults and children. Finally, to assess spatial behavior in the probe trials, (vii) the <italic>time spent in the central area</italic> was calculated as the time (in seconds) spent in the region composed of one third of each of the three arms closest to the center of the maze.</p></sec><sec id="s4-5-2"><title>Navigation strategies</title><p>We defined a subject’s strategy based on which area the subject first entered on probe trials (areas centered around A, B, and C in <xref ref-type="fig" rid="fig1">Figure 1a and b</xref>, with a radius of 0.4 m). A subject was classified as belonging to the <italic>allocentric</italic> category if he or she made a majority of allocentric choices in the three probe trials. Otherwise, the subject was classified as <italic>egocentric</italic>. In the landmark version of the virtual experiment, the preferred strategy of one child and one older participant could not be evaluated as they returned several times to the starting position. Those two subjects were excluded in the behavioral and gaze analyses but they were pooled with the egocentric group for the visual and cognitive analyses.</p></sec><sec id="s4-5-3"><title>Eye tracking</title><p>In order to measure each subject’s gaze vector in the 3D virtual space, head-tracking data were interpolated to synchronize them with the eye-tracker frequency (120 Hz). Once the image was displayed in the HMD, the cyclopean gaze vector was calculated by averaging the data for the left and the right eye. If the signal from one of the eyes was judged too noisy, the recording from the remaining eye was used. The subject’s visual focus of attention was computed as the intersection point of the gaze vector with the surface of the virtual walls, the floor, or the sky region, the latter being defined the virtual sphere (radius: 6 m) around the maze center. The <italic>gaze time proportion</italic> was calculated as the proportion of time that the gaze focused on either the walls, the floor, or the sky region, normalized by the total duration of the period considered (see below). There were missing data (young adults: 22%; older adults: 27%) due to blinks or loss of the pupil tracking. These were not considered when computing the gaze time proportion. Fixations and saccades were not separated for the analyses. For statistical comparisons, the gaze time proportion was computed for each trial and averaged across subjects and/or experimental trials. To visualize the distribution of the gaze foci as a function of trial duration, the gaze time proportion was computed over a window of 1 s sliding across the trial time separated into 50 time bins (orientation period: 15 bins; navigation period: 35 bins). Finally, to visualize the spatial distribution of the gaze foci in a particular experimental condition, they were accumulated from all trials and all subjects considered, for a particular region (e.g., sky, floor), and represented by heatmaps, normalized to have the maximal value of 1.</p></sec><sec id="s4-5-4"><title>Predictive model based on eye-motion statistics</title><p>A generalized linear (logistic) regression model was trained to predict the navigation strategy (i.e., allocentric vs. egocentric) as well as the experimental condition (i.e., landmarks vs. geometry) based on the average altitude of the gaze relative to eye level (in degrees) recorded during the orientation period of probe trials. Gaze altitude was expressed as the elevation (in degrees) of the gaze vector relative to a horizontal plan passing though the eye height. To assess the regression performance, we used two cross-validation procedures. First, 25% hold-out validation, in which the model was trained using 75% of the subjects’ data and then tested on the remaining subjects’ data. The same procedure was repeated 1000 times to estimate the distribution of the proportion of the correct responses. The p-value reported in the figures corresponds to the probability that the prediction was correct for less than half of the subjects. Second, leave-one-out validation, in which the model was trained on all but 1 subject, whose data were used for testing. The procedure was repeated for all subjects, and the number of correctly classified cases was reported. Strategy prediction was assessed only for the landmark condition since there were only two subjects that made egocentric choices in the geometry condition.</p></sec><sec id="s4-5-5"><title>Scoring self-reported outcomes and map drawings</title><p>At the end of the experimental session in the 3D virtual environment, a subset of participants were asked to recall the shape of the maze (out of three choices) as well as of the three landmarks (out of a set of six, with three distractors). They were also asked to sketch a top-view drawing of the maze, indicating the landmark array and the goal location. A binary score (correct/incorrect) was used to quantify performance in recalling the shape of the maze and of the landmarks. Three binary scores were used to evaluate the map sketches. They assessed whether the order of landmarks was correct (independently of their position in space with respect to the maze), whether the placement of landmarks relative to the maze was correct (i.e., if the landmarks were drawn in-between the arms and not at their ends), independently of the landmark order, and whether the goal zone was placed in the correct arm and relative to the landmarks.</p></sec></sec><sec id="s4-6"><title>Statistical analyses</title><p>Student’s <italic>t</italic>-tests and ANOVAs were used for statistical comparisons on continuous data that passed normality and homoscedasticity tests. The normality was verified by the Lilliefors normality test and by the visual inspection of Q-Q plots. Box–Cox transformations were used on this data. ANOVAs were complemented by Bayesian ANOVAs for null testing (<xref ref-type="bibr" rid="bib45">Rouder et al., 2009</xref>) performed with the Bayes Factor package in R. Nonparametric tests were used for ordinal data and when normality could not be achieved. Mann–Whitney U test was used to compare independent groups. When samples were large, we used the z approximation to calculate the Cohen’s r, as an estimation of the effect size with r = z/sqrt(N). We also specify the global n for the two groups compared. Cohen’s guidelines for r are that a large effect is 0.5, a medium effect is 0.3, and a small effect is 0.1. Wilcoxon signed-rank W statistic was used to test whether the difference between pairs of observations differed from a given median (in our case, 0). We complemented nonparametric tests with a Bayesian rank-based testing method described in <xref ref-type="bibr" rid="bib50">van Doorn et al., 2020</xref>. Alpha level for statistical significance was set to 0.05. Corrections for multiple comparisons are described in the text. To assess statistical interactions between age and condition in the Y-maze task, a logistic regression model (generalized linear model with binomial response and logit link) was fit to the data. Interactions in this model were analyzed using marginal effects framework (<xref ref-type="bibr" rid="bib34">Mize, 2019</xref>) implemented by the ‘marginaleffects’ R package. In the text, we report second differences (Δ, the effect of change from landmark to geometry condition on the difference between age groups) and their p-values. Alpha level is 0.05 is used.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Visualization, Methodology</p></fn><fn fn-type="con" id="con4"><p>Data curation, Software, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con5"><p>Data curation, Software, Formal analysis, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con6"><p>Validation, Investigation, Methodology</p></fn><fn fn-type="con" id="con7"><p>Supervision, Funding acquisition, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants were voluntary and they (or their parents in the case of children) gave an informed consent for inclusion in the study. All screening and experimental procedures were in accordance with the tenets of the Declaration of Helsinki, and they were approved by the Ethical Committee CPP Ile de France V (ID_RCB 2015-A01094-45, No. CPP: 16122 MSB).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Number of observations, mean, and standard deviation of age in different age groups.</title></caption><media xlink:href="elife-81318-supp1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Number of observations, mean, and standard deviation of age in different age groups for the experiments in real-world setting.</title></caption><media xlink:href="elife-81318-supp2-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>List of visual and cognitive tests performed by a subset of our adult participants.</title></caption><media xlink:href="elife-81318-supp3-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp4"><label>Supplementary file 4.</label><caption><title>Inclusion/exclusion criteria used for the SilverSight cohort (adult participants).</title></caption><media xlink:href="elife-81318-supp4-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-81318-mdarchecklist1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="sdata1"><label>Source data 1.</label><caption><title>Participants’ demographics.</title></caption><media xlink:href="elife-81318-data1-v2.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data and code used in the analyses are available as an Open Science Framework deposit, accessible at <ext-link ext-link-type="uri" xlink:href="https://osf.io/zhrk4">https://osf.io/zhrk4</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Bécu</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Evolution of landmark-based spatial navigation across the human lifespan</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/zhrk4">zhrk4</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Saddek Mohand-Said of the Clinical Investigation Centre of the Quinze-Vingts Hospital, Paris for medical supervision during clinical screening of participants. We also thank Karine Lagrené, Sonia Combariza, and Jérôme Gillet from the Aging in Vision and Action laboratory at Vision Institute for helping in enrolling/profiling the participants. Finally, the authors wish to thank Emanuel Gutman, Johan Lebrun of the Streetlab team for technical support in setting up the experiments in the Streetlab platform. ANR-Essilor SilverSight Chair grant ANR-14-CHIN-0001, ANR-Essilor SilverSight Chair grant ANR-18-CHIN-0002, LabEx LIFESENSES grant ANR-10-LABX-65, IHU FOReSIGHT grant ANR-18-IAHU-01.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adamo</surname><given-names>DE</given-names></name><name><surname>Briceño</surname><given-names>EM</given-names></name><name><surname>Sindone</surname><given-names>JA</given-names></name><name><surname>Alexander</surname><given-names>NB</given-names></name><name><surname>Moffat</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Age differences in virtual environment and real world path integration</article-title><source>Frontiers in Aging Neuroscience</source><volume>4</volume><elocation-id>26</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2012.00026</pub-id><pub-id pub-id-type="pmid">23055969</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agathos</surname><given-names>CP</given-names></name><name><surname>Bernardin</surname><given-names>D</given-names></name><name><surname>Huchet</surname><given-names>D</given-names></name><name><surname>Scherlen</surname><given-names>AC</given-names></name><name><surname>Assaiante</surname><given-names>C</given-names></name><name><surname>Isableu</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sensorimotor and cognitive factors associated with the age-related increase of visual field dependence: a cross-sectional study</article-title><source>Age</source><volume>37</volume><elocation-id>9805</elocation-id><pub-id pub-id-type="doi">10.1007/s11357-015-9805-x</pub-id><pub-id pub-id-type="pmid">26122710</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alberts</surname><given-names>BBGT</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Medendorp</surname><given-names>WP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Age-Related reweighting of visual and vestibular cues for vertical perception</article-title><source>Journal of Neurophysiology</source><volume>121</volume><fpage>1279</fpage><lpage>1288</lpage><pub-id pub-id-type="doi">10.1152/jn.00481.2018</pub-id><pub-id pub-id-type="pmid">30699005</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bécu</surname><given-names>M</given-names></name><name><surname>Sheynikhovich</surname><given-names>D</given-names></name><name><surname>Tatur</surname><given-names>G</given-names></name><name><surname>Agathos</surname><given-names>CP</given-names></name><name><surname>Bologna</surname><given-names>LL</given-names></name><name><surname>Sahel</surname><given-names>J-A</given-names></name><name><surname>Arleo</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Age-Related preference for geometric spatial cues during real-world navigation</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>88</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0718-z</pub-id><pub-id pub-id-type="pmid">31548677</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohbot</surname><given-names>VD</given-names></name><name><surname>McKenzie</surname><given-names>S</given-names></name><name><surname>Konishi</surname><given-names>K</given-names></name><name><surname>Fouquet</surname><given-names>C</given-names></name><name><surname>Kurdi</surname><given-names>V</given-names></name><name><surname>Schachar</surname><given-names>R</given-names></name><name><surname>Boivin</surname><given-names>M</given-names></name><name><surname>Robaey</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Virtual navigation strategies from childhood to senescence: evidence for changes across the life span</article-title><source>Frontiers in Aging Neuroscience</source><volume>4</volume><elocation-id>28</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2012.00028</pub-id><pub-id pub-id-type="pmid">23162463</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullens</surname><given-names>J</given-names></name><name><surname>Iglói</surname><given-names>K</given-names></name><name><surname>Berthoz</surname><given-names>A</given-names></name><name><surname>Postma</surname><given-names>A</given-names></name><name><surname>Rondi-Reig</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Developmental time course of the acquisition of sequential egocentric and allocentric navigation strategies</article-title><source>Journal of Experimental Child Psychology</source><volume>107</volume><fpage>337</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1016/j.jecp.2010.05.010</pub-id><pub-id pub-id-type="pmid">20598705</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spatial memory: how egocentric and allocentric combine</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>551</fpage><lpage>557</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.10.005</pub-id><pub-id pub-id-type="pmid">17071127</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatial cognition and the brain</article-title><source>Annals of the New York Academy of Sciences</source><volume>1124</volume><fpage>77</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1196/annals.1440.002</pub-id><pub-id pub-id-type="pmid">18400925</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>A purely geometric module in the rat’s spatial representation</article-title><source>Cognition</source><volume>23</volume><fpage>149</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(86)90041-7</pub-id><pub-id pub-id-type="pmid">3742991</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colombo</surname><given-names>D</given-names></name><name><surname>Serino</surname><given-names>S</given-names></name><name><surname>Tuena</surname><given-names>C</given-names></name><name><surname>Pedroli</surname><given-names>E</given-names></name><name><surname>Dakanalis</surname><given-names>A</given-names></name><name><surname>Riva</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Egocentric and allocentric spatial reference frames in aging: a systematic review</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>80</volume><fpage>605</fpage><lpage>621</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2017.07.012</pub-id><pub-id pub-id-type="pmid">28760627</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>RL</given-names></name><name><surname>Weisbeck</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Search strategies used by older adults in a virtual reality place learning task</article-title><source>The Gerontologist</source><volume>55 Suppl 1</volume><fpage>S118</fpage><lpage>S127</lpage><pub-id pub-id-type="doi">10.1093/geront/gnv020</pub-id><pub-id pub-id-type="pmid">26055772</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Distinct error-correcting and incidental learning of location relative to landmarks and boundaries</article-title><source>PNAS</source><volume>105</volume><fpage>5909</fpage><lpage>5914</lpage><pub-id pub-id-type="doi">10.1073/pnas.0711433105</pub-id><pub-id pub-id-type="pmid">18413609</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driscoll</surname><given-names>I</given-names></name><name><surname>Hamilton</surname><given-names>DA</given-names></name><name><surname>Yeo</surname><given-names>RA</given-names></name><name><surname>Brooks</surname><given-names>WM</given-names></name><name><surname>Sutherland</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Virtual navigation in humans: the impact of age, sex, and hormones on place learning</article-title><source>Hormones and Behavior</source><volume>47</volume><fpage>326</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.1016/j.yhbeh.2004.11.013</pub-id><pub-id pub-id-type="pmid">15708762</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Arnold</surname><given-names>A</given-names></name><name><surname>Iaria</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A critical review of the allocentric spatial representation and its neural underpinnings: toward A network-based perspective</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>803</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00803</pub-id><pub-id pub-id-type="pmid">25346679</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Huffman</surname><given-names>DJ</given-names></name><name><surname>Starrett</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Interacting networks of brain regions underlie human spatial navigation: a review and novel synthesis of the literature</article-title><source>Journal of Neurophysiology</source><volume>118</volume><fpage>3328</fpage><lpage>3344</lpage><pub-id pub-id-type="doi">10.1152/jn.00531.2017</pub-id><pub-id pub-id-type="pmid">28931613</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Isham</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Human spatial navigation: representations across dimensions and scales</article-title><source>Current Opinion in Behavioral Sciences</source><volume>17</volume><fpage>84</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.06.005</pub-id><pub-id pub-id-type="pmid">29130062</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faul</surname><given-names>F</given-names></name><name><surname>Erdfelder</surname><given-names>E</given-names></name><name><surname>Lang</surname><given-names>AG</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>G*Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title><source>Behavior Research Methods</source><volume>39</volume><fpage>175</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.3758/bf03193146</pub-id><pub-id pub-id-type="pmid">17695343</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>MA</given-names></name><name><surname>Wiener</surname><given-names>JM</given-names></name><name><surname>Wolbers</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Aging specifically impairs switching to an allocentric navigational strategy</article-title><source>Frontiers in Aging Neuroscience</source><volume>4</volume><elocation-id>29</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2012.00029</pub-id><pub-id pub-id-type="pmid">23125833</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>MA</given-names></name><name><surname>Wolbers</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Ageing effects on path integration and landmark navigation</article-title><source>Hippocampus</source><volume>22</volume><fpage>1770</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1002/hipo.22011</pub-id><pub-id pub-id-type="pmid">22431367</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jansen</surname><given-names>P</given-names></name><name><surname>Schmelter</surname><given-names>A</given-names></name><name><surname>Heil</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spatial knowledge acquisition in younger and elderly adults: a study in a virtual environment</article-title><source>Experimental Psychology</source><volume>57</volume><fpage>54</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1027/1618-3169/a000007</pub-id><pub-id pub-id-type="pmid">20178963</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Julian</surname><given-names>JB</given-names></name><name><surname>Keinath</surname><given-names>AT</given-names></name><name><surname>Muzzio</surname><given-names>IA</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Place recognition and heading retrieval are mediated by dissociable cognitive systems in mice</article-title><source>PNAS</source><volume>112</volume><fpage>6503</fpage><lpage>6508</lpage><pub-id pub-id-type="doi">10.1073/pnas.1424194112</pub-id><pub-id pub-id-type="pmid">25941390</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Julian</surname><given-names>JB</given-names></name><name><surname>Ryan</surname><given-names>J</given-names></name><name><surname>Hamilton</surname><given-names>RH</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The occipital place area is causally involved in representing environmental boundaries during navigation</article-title><source>Current Biology</source><volume>26</volume><fpage>1104</fpage><lpage>1109</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.02.066</pub-id><pub-id pub-id-type="pmid">27020742</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cell symmetry is shaped by environmental geometry</article-title><source>Nature</source><volume>518</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature14153</pub-id><pub-id pub-id-type="pmid">25673417</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lagrené</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Healthy and pathological visual aging in a french follow-up cohort study</article-title><source>Investig. Opthalmology Vis. Sci</source><volume>60</volume><elocation-id>5915</elocation-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lenck-Santini</surname><given-names>PP</given-names></name><name><surname>Save</surname><given-names>E</given-names></name><name><surname>Poucet</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Place-cell firing does not depend on the direction of turn in a Y-maze alternation task</article-title><source>The European Journal of Neuroscience</source><volume>13</volume><fpage>1055</fpage><lpage>1058</lpage><pub-id pub-id-type="doi">10.1046/j.0953-816x.2001.01481.x</pub-id><pub-id pub-id-type="pmid">11264680</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lester</surname><given-names>AW</given-names></name><name><surname>Moffat</surname><given-names>SD</given-names></name><name><surname>Wiener</surname><given-names>JM</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>Wolbers</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The aging navigational system</article-title><source>Neuron</source><volume>95</volume><fpage>1019</fpage><lpage>1035</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.037</pub-id><pub-id pub-id-type="pmid">28858613</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Arleo</surname><given-names>A</given-names></name><name><surname>Sheynikhovich</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Panoramic Visual Representation in the Dorsal Visual Pathway and Its Role in Reorientation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/827667</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>Baltes</surname><given-names>PB</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Sensory functioning and intelligence in old age: a strong connection</article-title><source>Psychology and Aging</source><volume>9</volume><fpage>339</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1037//0882-7974.9.3.339</pub-id><pub-id pub-id-type="pmid">7999320</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>Mayr</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cognitive aging: is there a dark side to environmental support?</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>7</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.10.006</pub-id><pub-id pub-id-type="pmid">24210962</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lister</surname><given-names>JP</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neurobiological changes in the hippocampus during normative aging</article-title><source>Archives of Neurology</source><volume>66</volume><fpage>829</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1001/archneurol.2009.125</pub-id><pub-id pub-id-type="pmid">19597084</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lithfous</surname><given-names>S</given-names></name><name><surname>Dufour</surname><given-names>A</given-names></name><name><surname>Després</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial navigation in normal aging and the prodromal stage of Alzheimer’s disease: insights from imaging and behavioral studies</article-title><source>Ageing Research Reviews</source><volume>12</volume><fpage>201</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1016/j.arr.2012.04.007</pub-id><pub-id pub-id-type="pmid">22771718</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litman</surname><given-names>L</given-names></name><name><surname>Awipi</surname><given-names>T</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Category-specificity in the human medial temporal lobe cortex</article-title><source>Hippocampus</source><volume>19</volume><fpage>308</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1002/hipo.20515</pub-id><pub-id pub-id-type="pmid">18988234</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahmood</surname><given-names>O</given-names></name><name><surname>Adamo</surname><given-names>D</given-names></name><name><surname>Briceno</surname><given-names>E</given-names></name><name><surname>Moffat</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Age differences in visual path integration</article-title><source>Behavioural Brain Research</source><volume>205</volume><fpage>88</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2009.08.001</pub-id><pub-id pub-id-type="pmid">19665496</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mize</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Best practices for estimating, interpreting, and presenting nonlinear interaction effects</article-title><source>Sociological Science</source><volume>6</volume><fpage>81</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.15195/v6.a4</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moffat</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Aging and spatial navigation: what do we know and where do we go?</article-title><source>Neuropsychology Review</source><volume>19</volume><fpage>478</fpage><lpage>489</lpage><pub-id pub-id-type="doi">10.1007/s11065-009-9120-3</pub-id><pub-id pub-id-type="pmid">19936933</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naël</surname><given-names>V</given-names></name><name><surname>Pérès</surname><given-names>K</given-names></name><name><surname>Dartigues</surname><given-names>J-F</given-names></name><name><surname>Letenneur</surname><given-names>L</given-names></name><name><surname>Amieva</surname><given-names>H</given-names></name><name><surname>Arleo</surname><given-names>A</given-names></name><name><surname>Scherlen</surname><given-names>A-C</given-names></name><name><surname>Tzourio</surname><given-names>C</given-names></name><name><surname>Berr</surname><given-names>C</given-names></name><name><surname>Carrière</surname><given-names>I</given-names></name><name><surname>Delcourt</surname><given-names>C</given-names></name><name><surname>Helmer</surname><given-names>C</given-names></name><collab>Sense-Cog consortium</collab></person-group><year iso-8601-date="2019">2019</year><article-title>Vision loss and 12-year risk of dementia in older adults: the 3C cohort study</article-title><source>European Journal of Epidemiology</source><volume>34</volume><fpage>141</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1007/s10654-018-00478-y</pub-id><pub-id pub-id-type="pmid">30610413</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nardini</surname><given-names>M</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Breckenridge</surname><given-names>K</given-names></name><name><surname>Atkinson</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Differential developmental trajectories for egocentric, environmental and intrinsic frames of reference in spatial memory</article-title><source>Cognition</source><volume>101</volume><fpage>153</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2005.09.005</pub-id><pub-id pub-id-type="pmid">16359653</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nau</surname><given-names>M</given-names></name><name><surname>Julian</surname><given-names>JB</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How the brain’s navigation system shapes our visual experience</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>810</fpage><lpage>825</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.06.008</pub-id><pub-id pub-id-type="pmid">30031670</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newcombe</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Navigation and the developing brain</article-title><source>The Journal of Experimental Biology</source><volume>222</volume><elocation-id>jeb186460</elocation-id><pub-id pub-id-type="doi">10.1242/jeb.186460</pub-id><pub-id pub-id-type="pmid">30728229</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramanoël</surname><given-names>S</given-names></name><name><surname>Durteste</surname><given-names>M</given-names></name><name><surname>Bizeul</surname><given-names>A</given-names></name><name><surname>Ozier-Lafontaine</surname><given-names>A</given-names></name><name><surname>Bécu</surname><given-names>M</given-names></name><name><surname>Sahel</surname><given-names>J-A</given-names></name><name><surname>Habas</surname><given-names>C</given-names></name><name><surname>Arleo</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Selective neural coding of object, feature, and geometry spatial cues in humans</article-title><source>Human Brain Mapping</source><volume>43</volume><fpage>5281</fpage><lpage>5295</lpage><pub-id pub-id-type="doi">10.1002/hbm.26002</pub-id><pub-id pub-id-type="pmid">35776524</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raz</surname><given-names>N</given-names></name><name><surname>Rodrigue</surname><given-names>KM</given-names></name><name><surname>Head</surname><given-names>D</given-names></name><name><surname>Kennedy</surname><given-names>KM</given-names></name><name><surname>Acker</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Differential aging of the medial temporal lobe: a study of a five-year change</article-title><source>Neurology</source><volume>62</volume><fpage>433</fpage><lpage>438</lpage><pub-id pub-id-type="doi">10.1212/01.wnl.0000106466.09835.46</pub-id><pub-id pub-id-type="pmid">14872026</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rinaldi</surname><given-names>A</given-names></name><name><surname>De Leonibus</surname><given-names>E</given-names></name><name><surname>Cifra</surname><given-names>A</given-names></name><name><surname>Torromino</surname><given-names>G</given-names></name><name><surname>Minicocci</surname><given-names>E</given-names></name><name><surname>De Sanctis</surname><given-names>E</given-names></name><name><surname>López-Pedrajas</surname><given-names>RM</given-names></name><name><surname>Oliverio</surname><given-names>A</given-names></name><name><surname>Mele</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Flexible use of allocentric and egocentric spatial memories activates differential neural networks in mice</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>11338</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-68025-y</pub-id><pub-id pub-id-type="pmid">32647258</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberts</surname><given-names>KL</given-names></name><name><surname>Allen</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Perception and cognition in the ageing brain: a brief review of the short- and long-term links between perceptual and cognitive decline</article-title><source>Frontiers in Aging Neuroscience</source><volume>8</volume><elocation-id>39</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2016.00039</pub-id><pub-id pub-id-type="pmid">26973514</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodgers</surname><given-names>MK</given-names></name><name><surname>Sindone</surname><given-names>JA</given-names></name><name><surname>Moffat</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Effects of age on navigation strategy</article-title><source>Neurobiology of Aging</source><volume>33</volume><elocation-id>202</elocation-id><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2010.07.021</pub-id><pub-id pub-id-type="pmid">20832911</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>JN</given-names></name><name><surname>Speckman</surname><given-names>PL</given-names></name><name><surname>Sun</surname><given-names>D</given-names></name><name><surname>Morey</surname><given-names>RD</given-names></name><name><surname>Iverson</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Bayesian T tests for accepting and rejecting the null hypothesis</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>16</volume><fpage>225</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.3758/PBR.16.2.225</pub-id><pub-id pub-id-type="pmid">19293088</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruggiero</surname><given-names>G</given-names></name><name><surname>D’Errico</surname><given-names>O</given-names></name><name><surname>Iachini</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Development of egocentric and allocentric spatial representations from childhood to elderly age</article-title><source>Psychological Research</source><volume>80</volume><fpage>259</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1007/s00426-015-0658-9</pub-id><pub-id pub-id-type="pmid">25805435</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samson</surname><given-names>MM</given-names></name><name><surname>Crowe</surname><given-names>A</given-names></name><name><surname>de Vreede</surname><given-names>PL</given-names></name><name><surname>Dessens</surname><given-names>JAG</given-names></name><name><surname>Duursma</surname><given-names>SA</given-names></name><name><surname>Verhaar</surname><given-names>HJJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Differences in gait parameters at a preferred walking speed in healthy subjects due to age, height and body weight</article-title><source>Aging Clinical and Experimental Research</source><volume>13</volume><fpage>16</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1007/BF03351489</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheynikhovich</surname><given-names>D</given-names></name><name><surname>Chavarriaga</surname><given-names>R</given-names></name><name><surname>Strösslin</surname><given-names>T</given-names></name><name><surname>Arleo</surname><given-names>A</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Is there a geometric module for spatial orientation? insights from a rodent navigation model</article-title><source>Psychological Review</source><volume>116</volume><fpage>540</fpage><lpage>566</lpage><pub-id pub-id-type="doi">10.1037/a0016170</pub-id><pub-id pub-id-type="pmid">19618986</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Ham</surname><given-names>IJM</given-names></name><name><surname>Claessen</surname><given-names>MHG</given-names></name><name><surname>Evers</surname><given-names>AWM</given-names></name><name><surname>van der Kuil</surname><given-names>MNA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Large-Scale assessment of human navigation ability across the lifespan</article-title><source>Scientific Reports</source><volume>10</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41598-020-60302-0</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Doorn</surname><given-names>J</given-names></name><name><surname>Ly</surname><given-names>A</given-names></name><name><surname>Marsman</surname><given-names>M</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Bayesian rank-based hypothesis testing for the rank sum test, the signed rank test, and spearman’s ρ</article-title><source>Journal of Applied Statistics</source><volume>47</volume><fpage>2984</fpage><lpage>3006</lpage><pub-id pub-id-type="doi">10.1080/02664763.2019.1709053</pub-id><pub-id pub-id-type="pmid">35707708</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waller</surname><given-names>D</given-names></name><name><surname>Hodgson</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Transient and enduring spatial representations under disorientation and self-rotation</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>32</volume><fpage>867</fpage><lpage>882</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.32.4.867</pub-id><pub-id pub-id-type="pmid">16822154</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>R</given-names></name><name><surname>Spelke</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Human spatial representation: insights from animals</article-title><source>Trends in Cognitive Sciences</source><volume>6</volume><elocation-id>376</elocation-id><pub-id pub-id-type="doi">10.1016/s1364-6613(02)01961-7</pub-id><pub-id pub-id-type="pmid">12200179</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>RF</given-names></name><name><surname>Crowell</surname><given-names>JA</given-names></name><name><surname>Simons</surname><given-names>DJ</given-names></name><name><surname>Irwin</surname><given-names>DE</given-names></name><name><surname>Kramer</surname><given-names>AF</given-names></name><name><surname>Ambinder</surname><given-names>MS</given-names></name><name><surname>Thomas</surname><given-names>LE</given-names></name><name><surname>Gosney</surname><given-names>JL</given-names></name><name><surname>Levinthal</surname><given-names>BR</given-names></name><name><surname>Hsieh</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spatial updating relies on an egocentric representation of space: effects of the number of objects</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>13</volume><fpage>281</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.3758/bf03193844</pub-id><pub-id pub-id-type="pmid">16892995</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatial updating and common misinterpretations of spatial reference frames</article-title><source>Spatial Cognition &amp; Computation</source><volume>17</volume><fpage>222</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1080/13875868.2017.1304394</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiener</surname><given-names>JM</given-names></name><name><surname>de Condappa</surname><given-names>O</given-names></name><name><surname>Harris</surname><given-names>MA</given-names></name><name><surname>Wolbers</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Maladaptive bias for extrahippocampal navigation strategies in aging humans</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>6012</fpage><lpage>6017</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0717-12.2013</pub-id><pub-id pub-id-type="pmid">23554482</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilkniss</surname><given-names>SM</given-names></name><name><surname>Jones</surname><given-names>MG</given-names></name><name><surname>Korol</surname><given-names>DL</given-names></name><name><surname>Gold</surname><given-names>PE</given-names></name><name><surname>Manning</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Age-Related differences in an ecologically based study of route learning</article-title><source>Psychology and Aging</source><volume>12</volume><fpage>372</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1037//0882-7974.12.2.372</pub-id><pub-id pub-id-type="pmid">9189997</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81318.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ekstrom</surname><given-names>Arne</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03m2x1q45</institution-id><institution>University of Arizona</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2020.02.12.945808" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2020.02.12.945808"/></front-stub><body><p>The findings in the article show that when provided with geometric cues, rather than landmark cues, older adults and children no longer show selective difficulty with learning spatial layouts allocentrically. This important and compelling finding challenges decades of work suggesting that older adults have a selective allocentric navigation deficit. Instead, the findings suggest that older adults may have perceptual issues related to processing and integrating landmarks.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81318.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ekstrom</surname><given-names>Arne</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03m2x1q45</institution-id><institution>University of Arizona</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.02.12.945808">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.02.12.945808v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Evolution of landmark-based spatial navigation across the human lifespan&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Chris Baker as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>As editor, I have also carefully reviewed the paper and the reviewer comments. Overall, I think the paper makes a novel and important point potentially worthy of publication. Specifically, the manuscript nicely converges on the idea that past literature arguing for allocentric spatial deficits in older adults is flawed. Instead, the results in the current paper make the point that such differences in fact arise from differences in visual landmark processing in older adults and not due to a deficit in allocentric representation per se. I believe that the basic results supporting this idea are robust and the experimental design sound and well-reasoned in terms of addressing the core issue of landmark vs. geometrical processing differences and their relationship to allocentric vs. egocentric processing.</p><p>Nonetheless, both reviewers, particularly reviewer #1, identified serious statistical and analytic choices that limit the impact of the paper. As such, I am rejecting the current version of the paper and asking you to consider carefully revising your manuscript based on the feedback below.</p><p>The major issues I see here are statistical and in terms of the presentation. Perhaps most important, a null difference, particularly in a small sample, is not evidence of a lack of a difference. Bayes null testing, where possible, should be used (Rouder et al. 2009), and all null statements should be treated with greater caution. In addition, if statements are made about differences in one condition but not another, interaction effects should be tested for and identified as significant; otherwise, there could simply be differences in variance that are not accounted for (Nieuwenhuis et al. 2011). The areas involving eye tracking and neuropsychological tests were somewhat hard to follow and the number of subjects in these subsamples difficult to determine. One possibility could involve increasing the sample size for the neuropsychological correlations/PCA as it is currently significantly under-powered. Statistical power should be reported when possible to ensure that these effects can be considered robust. Lastly, the choice of the Mann-Whitney U test, while justified with non-parametric data, should be handled more carefully. In the very least, correction for multiple comparisons should be applied and/or non-parametric tests used that allow for testing of interaction effects. For categorical data (maze choice), the authors could consider a multinomial logistic regression. Also, where possible, if the data are continuous and fit the correct parametric assumptions, ANOVAs should be applied.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>I have several comments to the authors:</p><p>1. One difference between the mazes is that the geometry condition maze is 54% longer than the landmark condition maze. I don't think this can cause the observed effects, but this should be mentioned in the limitations section and not just hidden in the methods. It might also be mentioned in Figure 3 legend as this affects its interpretation (e.g. larger walking distances in the geometry compared to landmarks maze in all groups.)</p><p>2. The potential dissociation between geometry-based and landmark-based processing is a strength of this study – although this has been discussed in the literature, people still think on &quot;allocentric mapping&quot; as one system where the cognitive map is anchored to either geometry or landmarks. The study design very elegantly dissociates these elements, and I think this is important and can be emphasized more strongly (even in the abstract). Also, with regards to previous literature, besides the influential Doeller and Burgess 2008 paper on dissociation between geometric and landmark-based navigation that is cited, the studies by Julian et al. PNAS 2015 (dissociation between feature/landmark-based context retrieval and geometry-based heading retrieval), Krupic et al. Nature 2015 (geometry-based coding irrespective of distal cue location), and Julian et al. Curr Biol 2016 (impairment in geometry-based location coding without impairment in landmark-based location coding) might be relevant.</p><p>3. The Results section is very long and detailed, and requires substantial reader attention to go through all of it and understand the findings. Subheadings to the different sections detailing the main effects could be very beneficial for readability and to enable getting a grasp of the findings without reading all sections fully.</p><p>4. The authors sometimes refer to the maze as a &quot;radial maze&quot; and sometimes as a &quot;Y maze&quot;. I think Y-maze is more appropriate here and should be used consistently (including in the abstract) to avoid confusion.</p><p>5. The authors sometimes use the term &quot;landmark processing&quot; which might be confusing – since the problem doesn't seem to be with processing the landmarks (i.e. noticing/attending to them and being able to recognize them), but with using them to navigate. I would change the terminology to &quot;using landmarks during navigation&quot; or something similar.</p><p>6. The age (mean+-SD) should be stated at the start of the results as this is a very important issue and shouldn't be mentioned only in the methods.</p><p>7. Figure 5 is unclear without reference to the text: In panel A, there is no marking of the average gaze time to the sky in the learning trials. (2) In panel B, the original and probe starting locations are not marked. (3) In panel C, the color scale emphasizes the learning effect but makes it difficult to see what participants focus on during navigation – it might be better to separate the learning and navigation phases, and modify the scale of the navigation period graph to better emphasize the effects.</p><p>8. The authors may optionally wish to speculate on the potential impact of their study in real life – how navigational aids or environments can be designed to alleviate the problems faced by older adults or children during navigation.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>1. The authors report significant main effects of age across several outcome measures in the landmark condition. Most notably, children and older adults are more likely to engage in an 'egocentric' strategy during probe trials. Similar age effects are largely absent in the geometric condition; children, young adults, and older adults are equally likely to engage in an 'allocentric' strategy during probe trials and generally do not differ across any of the other outcome measures. It isn't clear, however, whether the authors performed any analyses necessary to identify a significant age group x condition interaction, which is necessary to determine whether the availability of geometric cues truly moderates the effect of age on navigation. To put it another way, simply showing a significant main effect of age in one condition and a null effect in the other does not in itself indicate that the magnitude of the age differences were moderated by the respective conditions. Given the data presented in Figure 2, I suspect this will be the case (with sufficient power, at least), but the results of formal interaction analyses should be reported.</p><p>2. The authors do a deep dive into the eye tracking analyses, which is informative but often difficult to follow. The results often switch back and forth between describing results of between-condition comparisons (i.e., landmark vs geometric) and within-landmark comparisons (i.e. allocentric vs. egocentric). It also wasn't always clear whether data from the VR (landmark and geometric) and real-world (landmark only) conditions were collapsed when describing the principal analyses. This seems particularly relevant when considering the use of different systems to obtain eye tracking data. Were any measures taken to compare the reliability and/or precision of gaze data measured by the respective systems?</p><p>3. During the orientation phase on probe trials in the landmark condition, young and older allocentric navigators tended to orient towards the star. During the subsequent navigation phase, older allocentric navigators showed a greater tendency to orient towards the red circle, which the authors suggest may reflect a cue-based view matching strategy. By contrast, young adults continue to orient towards the star during navigation, which is interpreted as reflecting a cognitive map-based strategy. Curiously, older egocentric navigators exhibit viewing patterns similar to that observed in younger allocentric navigators. These results appear to be purely based on a qualitative interpretation of the heatmaps presented in Figure 5C. Were there any formal statistics on gaze dwell-time to confirm these ostensive age differences in the evolution of viewing patterns? The authors do report quantitative age differences in orientation latencies, amount of time spent in the central maze area, and escape latencies to support these interpretations, but the link between these measures seems highly speculative.</p><p>4. The authors performed a classifier analysis to determine whether gaze altitude during orientation (that is, viewing the floor or sky) could predict subsequent navigation strategies. How was altitude quantified? Was it based on mean angle/degrees computed across the entire orientation epoch? Likewise, Figure 7A and 7B suggest that there was substantially more variability in gaze altitude during the orientation phase in the landmark condition compared to the geometric condition (both between- and, perhaps more importantly, within-groups). Can the authors discuss what this difference in gaze variability between conditions might mean in terms of interpreting the classifier analysis, and whether it represents a potential confound?</p><p>5. A subset of participants completed a battery of 19 visual and neurocognitive tests. Among older adults, those that showed a bias for egocentric navigation also tended to perform worse on tests of perspective taking, mental flexibility, and contrast sensitivity. Did the authors correct for multiple comparisons? Several of these effects do not appear to be particularly strong, and since these tests were only performed in a subset of participants, the broader implications of these results are difficult to determine.</p><p>6. In Supplementary Figure 4, the authors note that trial-to-criterion, travelled distance, and escape latency did not differ between the landmark and geometric conditions in young adults. The authors argue that this speaks to the comparable levels of difficulty between the two conditions. Can the authors elaborate on this? I don't follow the rationale that null effects in young adults is a sensitive measure of task complexity experienced by children and/or older adults.</p><p>7. Line 410: What was the rationale for adopting different visual acuity inclusion criteria for young (7/10) and older (5/10) adults?</p><p>8. Why were neuropsychological, visual acuity, and post-task questionnaires only collected in a subset of participants?</p><p>Some other issues the editor (Ekstrom) noted:</p><p>1) &quot;Egocentric strategies rely on spatial codes anchored on the subject's body, whereas allocentric strategies are grounded on representations that are independent from the subject's position and orientation, akin to a topographic map (4).&quot;</p><p>It should be noted that egocentric processing also can involve (and often does involve) visual snapshots of the environment, see for example (Waller and Hodgson 2006).</p><p>2) &quot;The study of age-related changes in human navigation has added a new temporal dimension to this research domain by investigating the evolution of spatial learning and wayfinding behavior across the lifespan.&quot;</p><p>As this is a cross-sectional study (old vs. young vs. children) and not longitudinal, it seems difficult to rule out cohort effects. Perhaps instead phrase as age-related differences.</p><p>3) &quot;Hence, an alternative explanation consistent with the literature is that the widely-accepted hypothesis of age-related allocentric deficit may in fact reflect a landmark-processing impairment.&quot;</p><p>It is unclear if what is being looked at is a &quot;deficit&quot; or a difference in processing/strategy.</p><p>4) &quot;We sought to test these hypotheses by employing a radial-maze experimental paradigm, traditionally used to dissociate egocentric and allocentric navigation in rodents (27,28) and humans (15).&quot;</p><p>From the way things are written, it is difficult to tell which findings came from the real-world maze and the virtual maze. This should be made clearer upfront and at all points in the results, this distinction should be clearer.</p><p>5) &quot;We sought to test these hypotheses by employing a radial-maze experimental paradigm, traditionally used to dissociate egocentric and allocentric navigation in rodents (27,28) and humans (15).</p><p>The sample size varies somewhat throughout the manuscript. It should be made clear throughout exactly what the N is in each comparison.</p><p>6) &quot;Older adults required a higher number of trials than young adults to reach the learning criterion of 4 consecutive successful trials (Figure 3A; older vs. young adults: U=287.5, p&lt;0.05).</p><p>It is unclear what test is being conducted here and what the degrees of freedom are.</p><p>7) &quot;A subset of the participants in the virtual experiment underwent a complete battery of visual and neurocognitive screenings, resulting in 19 measurements per subject</p><p>How many subjects were tested here?</p><p>References</p><p>Nieuwenhuis S, Forstmann BU, Wagenmakers EJ. 2011. Erroneous analyses of interactions in neuroscience: a problem of significance. Nature neuroscience 14: 1105-7</p><p>Rouder JN, Speckman PL, Sun DC, Morey RD, Iverson G. 2009. Bayesian t tests for accepting and rejecting the null hypothesis. Psychon B Rev 16: 225-37</p><p>Waller D, Hodgson E. 2006. Transient and enduring spatial representations under disorientation and self-rotation. J Exp Psychol Learn Mem Cogn 32: 867-82</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81318.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>As editor, I have also carefully reviewed the paper and the reviewer comments. Overall, I think the paper makes a novel and important point potentially worthy of publication. Specifically, the manuscript nicely converges on the idea that past literature arguing for allocentric spatial deficits in older adults is flawed. Instead, the results in the current paper make the point that such differences in fact arise from differences in visual landmark processing in older adults and not due to a deficit in allocentric representation per se. I believe that the basic results supporting this idea are robust and the experimental design sound and well-reasoned in terms of addressing the core issue of landmark vs. geometrical processing differences and their relationship to allocentric vs. egocentric processing.</p><p>Nonetheless, both reviewers, particularly reviewer #1, identified serious statistical and analytic choices that limit the impact of the paper. As such, I am rejecting the current version of the paper and asking you to consider carefully revising your manuscript based on the feedback below.</p><p>The major issues I see here are statistical and in terms of the presentation. Perhaps most important, a null difference, particularly in a small sample, is not evidence of a lack of a difference. Bayes null testing, where possible, should be used (Rouder et al. 2009), and all null statements should be treated with greater caution. In addition, if statements are made about differences in one condition but not another, interaction effects should be tested for and identified as significant; otherwise, there could simply be differences in variance that are not accounted for (Nieuwenhuis et al. 2011). The areas involving eye tracking and neuropsychological tests were somewhat hard to follow and the number of subjects in these subsamples difficult to determine. One possibility could involve increasing the sample size for the neuropsychological correlations/PCA as it is currently significantly under-powered. Statistical power should be reported when possible to ensure that these effects can be considered robust. Lastly, the choice of the Mann-Whitney U test, while justified with non-parametric data, should be handled more carefully. In the very least, correction for multiple comparisons should be applied and/or non-parametric tests used that allow for testing of interaction effects. For categorical data (maze choice), the authors could consider a multinomial logistic regression. Also, where possible, if the data are continuous and fit the correct parametric assumptions, ANOVAs should be applied.</p></disp-quote><p>General comment from the authors:</p><p>We have revised the paper by taking into consideration the comments of the editor and reviewers, notably in terms of statistics. Specifically, we did the following:</p><p>– We have replaced Mann-Whitney U test by two-ways ANOVAs in order to assess main effects and interactions, when normality could be achieved with a boxcox transformation. This led to a substantial change in the result section. Our main conclusions from the previous version of the paper are maintained, while some have been downplayed.</p><p>– We have added Bayes factor to classical p-value ANOVAs presentation for a better readout of the effect strength favoring the alternative or the null hypothesis.</p><p>– We have added interaction analysis using a binomial logistic regression model for the categorical data in Figure 2, as suggested by the editors. The interactions in this model were analyzed using marginal effects framework (implemented in the “marginaleffects” package in R).</p><p>– We have collected additional cognitive and visual data and pooled participants from the virtual and real experiments in order to increase the statistical power of the principal component analysis (PCA).</p><p>– We have added headings to the Results section to improve readability thereof.</p><p>– Non-parametric testing has been maintained in the case of non-normal data. It was the case when comparing gazing time proportion (e.g., time spent gazing at landmarks or the floor, in Figure 4) or in comparison with small samples (e.g., analysis comparing older adults using allocentric vs. egocentric strategies in Figure 5). We backed up the classical tests with a non-parametric approach from van Doorn et al. (see added reference) in order for the reader to understand how data support either the null hypothesis or its alternative.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>I have several comments to the authors:</p><p>1. One difference between the mazes is that the geometry condition maze is 54% longer than the landmark condition maze. I don't think this can cause the observed effects, but this should be mentioned in the limitations section and not just hidden in the methods. It might also be mentioned in Figure 3 legend as this affects its interpretation (e.g. larger walking distances in the geometry compared to landmarks maze in all groups.)</p></disp-quote><p>We agree that this information, also rendered on Figure 1B, should have been stated clearly. We now do so in both the caption of Figure 1B and in the Results section, line 166, to explain why participants travelled longer distances in the geometric maze.</p><disp-quote content-type="editor-comment"><p>2. The potential dissociation between geometry-based and landmark-based processing is a strength of this study – although this has been discussed in the literature, people still think on &quot;allocentric mapping&quot; as one system where the cognitive map is anchored to either geometry or landmarks. The study design very elegantly dissociates these elements, and I think this is important and can be emphasized more strongly (even in the abstract). Also, with regards to previous literature, besides the influential Doeller and Burgess 2008 paper on dissociation between geometric and landmark-based navigation that is cited, the studies by Julian et al. PNAS 2015 (dissociation between feature/landmark-based context retrieval and geometry-based heading retrieval), Krupic et al. Nature 2015 (geometry-based coding irrespective of distal cue location), and Julian et al. Curr Biol 2016 (impairment in geometry-based location coding without impairment in landmark-based location coding) might be relevant.</p></disp-quote><p>We agree with the reviewer on the interpretation of two dissociable systems. This point has been strengthened in the revised abstract. We also thank the reviewer for the references, which were cited in the dedicated discussion paragraph.</p><disp-quote content-type="editor-comment"><p>3. The Results section is very long and detailed, and requires substantial reader attention to go through all of it and understand the findings. Subheadings to the different sections detailing the main effects could be very beneficial for readability and to enable getting a grasp of the findings without reading all sections fully.</p></disp-quote><p>We have added subheadings to facilitate reading.</p><disp-quote content-type="editor-comment"><p>4. The authors sometimes refer to the maze as a &quot;radial maze&quot; and sometimes as a &quot;Y maze&quot;. I think Y-maze is more appropriate here and should be used consistently (including in the abstract) to avoid confusion.</p></disp-quote><p>We have updated the text accordingly.</p><disp-quote content-type="editor-comment"><p>5. The authors sometimes use the term &quot;landmark processing&quot; which might be confusing – since the problem doesn't seem to be with processing the landmarks (i.e. noticing/attending to them and being able to recognize them), but with using them to navigate. I would change the terminology to &quot;using landmarks during navigation&quot; or something similar.</p></disp-quote><p>This is an interesting language issue raised by the reviewer. In our definition, visuo-spatial processing pertains to the ability to perceive, manipulate, and think about visual patterns in space, including the ability to determine where objects are in space relative to oneself and others. Yet, we agree that “landmark/spatial cues processing” might be misleading in the sense that it relates to both lower-level skills (perceiving) and higher-level skills (spatial reasoning and positioning). We have revised the text to clarity to what extent accounting for the processing of landmarks in a navigation context is key to explain age-related differences (e.g., lines 386 and 409).</p><disp-quote content-type="editor-comment"><p>6. The age (mean+-SD) should be stated at the start of the results as this is a very important issue and shouldn't be mentioned only in the methods.</p></disp-quote><p>We have updated the text accordingly (line 78).</p><disp-quote content-type="editor-comment"><p>7. Figure 5 is unclear without reference to the text: In panel A, there is no marking of the average gaze time to the sky in the learning trials. (2) In panel B, the original and probe starting locations are not marked. (3) In panel C, the color scale emphasizes the learning effect but makes it difficult to see what participants focus on during navigation – it might be better to separate the learning and navigation phases, and modify the scale of the navigation period graph to better emphasize the effects.</p></disp-quote><p>Figure 5 is dedicated to probe trials only, which is now indicated more clearly by subheadings. This is why we choose to not show this data for the learning trials (which can be seen on Figure 4F). We nevertheless think that comparing learning (4F) and probe (5A) trials is interesting as it shows how people that use an allocentric strategy adapt their behavior to the new starting location. We have modified the caption of Figure 5A in order to better explain this point and the link to the preceding figure (Figure 4). We have also modified Figure 5B to indicate the starting location of the probe trials only, to strengthen the fact that this figure is about probe trials, and to avoid confusion with preceding (Figure 4).</p><p>Concerning the panel C (heatmaps), the variable represented here is the proportion of time participants gazed at different elements of the environment during a given time window. We average this across subjects, without any normalization so the data are directly readable (i.e., a data of 0.5 means that on average participant spent 50% time gazing at the element on a given time window). We think that the use of a normalization or different colormap for the two periods would have removed this direct relation.</p><p>We nevertheless agree that the navigation period was less readable, since participants did not gaze at landmark so much as in the orientation period. We have now used a different the colormap (a more discretized one) to increase the readability of the gaze behavior map during the navigation period.</p><disp-quote content-type="editor-comment"><p>8. The authors may optionally wish to speculate on the potential impact of their study in real life – how navigational aids or environments can be designed to alleviate the problems faced by older adults or children during navigation.</p></disp-quote><p>We thank the reviewer for the suggestion. We have added this interesting point (lines 427-430).</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>1. The authors report significant main effects of age across several outcome measures in the landmark condition. Most notably, children and older adults are more likely to engage in an 'egocentric' strategy during probe trials. Similar age effects are largely absent in the geometric condition; children, young adults, and older adults are equally likely to engage in an 'allocentric' strategy during probe trials and generally do not differ across any of the other outcome measures. It isn't clear, however, whether the authors performed any analyses necessary to identify a significant age group x condition interaction, which is necessary to determine whether the availability of geometric cues truly moderates the effect of age on navigation. To put it another way, simply showing a significant main effect of age in one condition and a null effect in the other does not in itself indicate that the magnitude of the age differences were moderated by the respective conditions. Given the data presented in Figure 2, I suspect this will be the case (with sufficient power, at least), but the results of formal interaction analyses should be reported.</p></disp-quote><p>We are thankful to the reviewer for pointing out this important flaw in our statistical analyses. To correct it, we have fit a logistic regression model to the data as suggested by the editors. We used marginal effects framework (Mize et al. 2019, now cited in the manuscript), implemented in the R package <italic>marginaleffects</italic>, in order to assess the statistical significance of interactions in this model. We now report the results of this analysis on page 9 of the revised manuscript, confirming a significant interaction between age and condition in our data. A description of this analysis has been added to the Methods (p. 41).</p><disp-quote content-type="editor-comment"><p>2. The authors do a deep dive into the eye tracking analyses, which is informative but often difficult to follow. The results often switch back and forth between describing results of between-condition comparisons (i.e., landmark vs geometric) and within-landmark comparisons (i.e. allocentric vs. egocentric). It also wasn't always clear whether data from the VR (landmark and geometric) and real-world (landmark only) conditions were collapsed when describing the principal analyses. This seems particularly relevant when considering the use of different systems to obtain eye tracking data. Were any measures taken to compare the reliability and/or precision of gaze data measured by the respective systems?</p></disp-quote><p>We understand that the section devoted to eye movements was particularly long and difficult to follow. We have added subheadings to the Result section, in the form of a compact sentence specifying the main subsection message. We believe that this will significantly facilitate the reading of the section.</p><p>We have indeed recorded eye movements in the real-world experiment, but the data presented in this manuscript come only from the VR-based eye-tracker. Under no circumstance have we collapsed the data from the two eye-trackers. We have clarified this in lines 136 and 198. Although we have found gaze patterns in real-world condition to be coherent with the results in VR (see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> showing gazing time proportion in the real-world replica of the landmark condition), we think that such VR/real-world comparison is beyond the scope of the paper and it would add the already cluttered result section.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81318-sa2-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>3. During the orientation phase on probe trials in the landmark condition, young and older allocentric navigators tended to orient towards the star. During the subsequent navigation phase, older allocentric navigators showed a greater tendency to orient towards the red circle, which the authors suggest may reflect a cue-based view matching strategy. By contrast, young adults continue to orient towards the star during navigation, which is interpreted as reflecting a cognitive map-based strategy. Curiously, older egocentric navigators exhibit viewing patterns similar to that observed in younger allocentric navigators. These results appear to be purely based on a qualitative interpretation of the heatmaps presented in Figure 5C. Were there any formal statistics on gaze dwell-time to confirm these ostensive age differences in the evolution of viewing patterns? The authors do report quantitative age differences in orientation latencies, amount of time spent in the central maze area, and escape latencies to support these interpretations, but the link between these measures seems highly speculative.</p></disp-quote><p>We have performed the statistical analysis of the time proportion of gazing at the different landmarks during the first probe trial (more precisely, across different periods of the first probe trial). It has appeared that older allocentric navigators spend higher amount of time gazing at the circle than their younger counterparts (see the median in the new Supplementary Figure 5C). Because the statistical comparison of these data did not reach the level of significance, the revised text mentions that the data point in the direction of a view-matching in older adults. We have also downplayed our interpretation of a view-matching strategy in older adults.</p><disp-quote content-type="editor-comment"><p>4. The authors performed a classifier analysis to determine whether gaze altitude during orientation (that is, viewing the floor or sky) could predict subsequent navigation strategies. How was altitude quantified? Was it based on mean angle/degrees computed across the entire orientation epoch? Likewise, Figure 7A and 7B suggest that there was substantially more variability in gaze altitude during the orientation phase in the landmark condition compared to the geometric condition (both between- and, perhaps more importantly, within-groups). Can the authors discuss what this difference in gaze variability between conditions might mean in terms of interpreting the classifier analysis, and whether it represents a potential confound?</p></disp-quote><p>Gaze altitude was expressed as the elevation (in degrees) of the gaze vector relative to the horizontal plan passing though the eye height. Therefore, zero corresponded to participant eye height, and values were either positive or negative when the participant gazed upwards or downwards, respectively. The performance of the classifier was assessed on altitude data averaged over the orientation epoch. We have added a more detailed explanation of how these data were calculated in the revised manuscript (line 596).</p><p>When predicting the condition each participant was assigned to, the classification performance was 88% (on average over 1000 iterations). The average performance was 97% in the geometry group and 81% in the landmark group.</p><p>When predicting the strategy in the landmark group, the classifier performance was 79%, with 88% and 61% correct classification for allocentric and egocentric navigators.</p><p>We think the lower predictability in the landmark group, and specifically for older adults egocentric subgroup, is likely to reflect the higher gaze altitude variability observed. We have now pointed out this possibility in lines 323-330.</p><disp-quote content-type="editor-comment"><p>5. A subset of participants completed a battery of 19 visual and neurocognitive tests. Among older adults, those that showed a bias for egocentric navigation also tended to perform worse on tests of perspective taking, mental flexibility, and contrast sensitivity. Did the authors correct for multiple comparisons? Several of these effects do not appear to be particularly strong, and since these tests were only performed in a subset of participants, the broader implications of these results are difficult to determine.</p></disp-quote><p>The complete set of 19 measurements was not conducted for all participants included in the study at the moment of the navigation experiments. In response to the concern of the editor and reviewers, we have now added as many subjects as possible for these visual and cognitive analyses. In addition to this, we have also pooled the visuo-cognitive data from participants that underwent the virtual and real-world experiments, reaching a sample of 64 for this second version of the manuscript. With this larger sample we have performed more sophisticated statistical analysis, and we have substantially modified Figure 8. We have specified in the revised text when correction for multiple comparison was applied.</p><p>Unfortunately, we were unable to get the screening data from all participants. This is due to the fact that some participants drop out the SilverSight cohort before finishing the 19 measurements, which were performed during different visits to the lab. Drop-out occurred for several reasons that are usual for aging cohort study populations (e.g., relocation, unwillingness to further participate, death).</p><disp-quote content-type="editor-comment"><p>6. In Supplementary Figure 4, the authors note that trial-to-criterion, travelled distance, and escape latency did not differ between the landmark and geometric conditions in young adults. The authors argue that this speaks to the comparable levels of difficulty between the two conditions. Can the authors elaborate on this? I don't follow the rationale that null effects in young adults is a sensitive measure of task complexity experienced by children and/or older adults.</p></disp-quote><p>We agree with the Reviewer on the fact that a similar learning criterion does not rule out the possibility that attentional demands may vary between the two conditions, and that an absence of performance difference in one age group does not allow to infer about task complexity in the other age groups. As a consequence, we have removed this over-interpretation (as well as the associated figure) from the revised version of the manuscript.</p><disp-quote content-type="editor-comment"><p>7. Line 410: What was the rationale for adopting different visual acuity inclusion criteria for young (7/10) and older (5/10) adults?</p></disp-quote><p>Our study used participants from the Silversight cohort, which was created in 2015 by our laboratory Aging in Vision and Action at the Institute of Vision, in collaboration with the Clinical Investigation Center at the Quinze-Vingts National Ophthalmological Hospital, Paris. The SilverSight cohort counts &lt;inline-graphic mimetype=&quot;image&quot; mime-subtype=&quot;png&quot; xlink:href=&quot;media/image1.png&quot; /&gt;350 participants older than 18 years of age and without any pathology or deficit that could interfere with the visual, cognitive, hearing and vestibular functions. The entire cohort population underwent (and follow-ups are regularly done) an ophthalmological screening (conducted by medical doctors at CIC), a functional visual screening (conducted by orthoptists), an otorhinolaryngological examination (conducted by ENT specialists), and a static/dynamic balance assessment (conducted by podiatrists and posture specialists). Visual acuity naturally decreases with advancing age, even in the absence of pathology so the 5/10 criterion for visual acuity reflects this physiological process. All subjects were corrected to normal when performing our experiment (not necessarily with the best correction possible, but with the correction they usually wear when walking in an outdoor environment).</p><disp-quote content-type="editor-comment"><p>8. Why were neuropsychological, visual acuity, and post-task questionnaires only collected in a subset of participants?</p></disp-quote><p>For cognitive and visual measures, please our response in point 5 above.</p><p>Concerning the post-task questionnaire, we realized that getting the participant internal representation of space (by asking them to draw a map of the environment) could be interesting for our study after debriefing with the first old subjects enrolled. One of them, for instance, mentioned his/her (wrong) impression that landmarks were changed during the learning phase. We came up with a short questionnaire to evaluate this point, but we could only get a subset of participants. We started the enrollment of young adults before older adults and children, which explains why we have few post-task questionnaires in young adults. We think that post-task questionnaire data (small sample) and navigational/gaze/cognitive data (larger sample) all point in the direction of a landmark-specific deficit in older adults.</p><disp-quote content-type="editor-comment"><p>Some other issues the editor (Ekstrom) noted:</p><p>1) &quot;Egocentric strategies rely on spatial codes anchored on the subject's body, whereas allocentric strategies are grounded on representations that are independent from the subject's position and orientation, akin to a topographic map (4).&quot;</p><p>It should be noted that egocentric processing also can involve (and often does involve) visual snapshots of the environment, see for example (Waller and Hodgson 2006).</p></disp-quote><p>We thank the Editor. We have added this reference, which perfectly fits with some results of the paper.</p><disp-quote content-type="editor-comment"><p>2) &quot;The study of age-related changes in human navigation has added a new temporal dimension to this research domain by investigating the evolution of spatial learning and wayfinding behavior across the lifespan.&quot;</p><p>As this is a cross-sectional study (old vs. young vs. children) and not longitudinal, it seems difficult to rule out cohort effects. Perhaps instead phrase as age-related differences.</p></disp-quote><p>We agree that the use of terminology like “evolution” can be misleading. We have corrected every instance in the text (title/abstract/introduction). In the Discussion section, we have mentioned the need for longitudinal confirmation of the results observed here (lines 430-433).</p><disp-quote content-type="editor-comment"><p>3) &quot;Hence, an alternative explanation consistent with the literature is that the widely-accepted hypothesis of age-related allocentric deficit may in fact reflect a landmark-processing impairment.&quot;</p><p>It is unclear if what is being looked at is a &quot;deficit&quot; or a difference in processing/strategy.</p></disp-quote><p>Map drawing analyses, and to some extent gaze analyses, showed that landmark locations were incorrectly encoded by older adults. This, we believe, might be one of the reasons older subjects choose a different strategy during the probe trials.</p><p>We used the words ‘deficit’ and ‘impairment’ to describe older adults’ behavioral difficulties, as compared to young adults, in line with existing aging literature. We can indeed agree that older adults’ egocentric preference can be detrimental in real life situations, where they must be able to take detours and/or plan complex navigational paths.</p><p>When referring to our own results, we have preferred the term ‘strategy preference’ or ‘bias towards egocentric strategies’.</p><disp-quote content-type="editor-comment"><p>4) &quot;We sought to test these hypotheses by employing a radial-maze experimental paradigm, traditionally used to dissociate egocentric and allocentric navigation in rodents (27,28) and humans (15).&quot;</p><p>From the way things are written, it is difficult to tell which findings came from the real-world maze and the virtual maze. This should be made clearer upfront and at all points in the results, this distinction should be clearer.</p></disp-quote><p>We understand the confusion, and we have clarified upfront how we used the data from each experiment. Please, see line 136 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>5) &quot;We sought to test these hypotheses by employing a radial-maze experimental paradigm, traditionally used to dissociate egocentric and allocentric navigation in rodents (27,28) and humans (15).</p><p>The sample size varies somewhat throughout the manuscript. It should be made clear throughout exactly what the N is in each comparison.</p></disp-quote><p>We have tried to specify the n in each analysis and to explain in the text why n varies. See for instance lines 131, 136, and 198 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>6) &quot;Older adults required a higher number of trials than young adults to reach the learning criterion of 4 consecutive successful trials (Figure 3A; older vs. young adults: U=287.5, p&lt;0.05).</p><p>It is unclear what test is being conducted here and what the degrees of freedom are.</p></disp-quote><p>Two samples non-parametric comparison were done with the Mann-Whitney U test. The U test has no degree of freedom but we have additionally provided an effect size estimation (r), the sample size, and non-parametric Bayes factor for a better read out of these statistical tests.</p><disp-quote content-type="editor-comment"><p>7) &quot;A subset of the participants in the virtual experiment underwent a complete battery of visual and neurocognitive screenings, resulting in 19 measurements per subject</p><p>How many subjects were tested here?</p></disp-quote><p>Please, see the response to Reviewer 2 point 5 on this matter. We could get cognitive data from 64 participants, although only 47 of them had the complete 19 measurements used for the principal component analysis (PCA). With more subjects, our interpretation from the previous version are maintained.</p></body></sub-article></article>