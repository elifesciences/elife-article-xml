<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">81681</article-id><article-id pub-id-type="doi">10.7554/eLife.81681</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Early language exposure affects neural mechanisms of semantic representations</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-243863"><name><surname>Wang</surname><given-names>Xiaosha</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2133-8161</contrib-id><email>wangxiaosha@bnu.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-297568"><name><surname>Wang</surname><given-names>Bijun</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-48064"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0522-3372</contrib-id><email>ybi@bnu.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>State Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG/McGovern Institute for Brain Research, Beijing Normal University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/029819q61</institution-id><institution>Chinese Institute for Brain Research</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peelle</surname><given-names>Jonathan Erik</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04t5xt781</institution-id><institution>Northeastern University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Donders Institute for Brain, Cognition and Behaviour</institution><country>Netherlands</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>10</day><month>05</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e81681</elocation-id><history><date date-type="received" iso-8601-date="2022-07-07"><day>07</day><month>07</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-05-04"><day>04</day><month>05</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-11-07"><day>07</day><month>11</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.11.06.515336"/></event></pub-history><permissions><copyright-statement>© 2023, Wang et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Wang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-81681-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-81681-figures-v2.pdf"/><abstract><p>One signature of the human brain is its ability to derive knowledge from language inputs, in addition to nonlinguistic sensory channels such as vision and touch. How does human language experience modulate the mechanism by which semantic knowledge is stored in the human brain? We investigated this question using a unique human model with varying amounts and qualities of early language exposure: early deaf adults who were born to hearing parents and had reduced early exposure and delayed acquisition of any natural human language (speech or sign), with early deaf adults who acquired sign language from birth as the control group that matches on nonlinguistic sensory experiences. Neural responses in a semantic judgment task with 90 written words that were familiar to both groups were measured using fMRI. The deaf group with reduced early language exposure, compared with the deaf control group, showed reduced semantic sensitivity, in both multivariate pattern (semantic structure encoding) and univariate (abstractness effect) analyses, in the left dorsal anterior temporal lobe (dATL). These results provide positive, causal evidence that language experience drives the neural semantic representation in the dATL, highlighting the roles of language in forming human neural semantic structures beyond nonverbal sensory experiences.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>Humans are the only known species where much of knowledge learning happens symbolically through language, in addition to information received directly from the senses. For example, humans can learn about the color of some rose flowers from the popular expression “roses are red” without needing to see any red roses – allowing them to accumulate knowledge beyond the constraints of their own senses.</p><p>Recent work suggests that a region of the brain known as the dorsal anterior temporal lobe represents knowledge acquired from language instead of sensory experiences. However, these studies were based on volunteers deprived of sensory experiences rather than those with reduced language exposure. Therefore, it was not clear whether this brain structure represents knowledge derived specifically from language and the importance of language in shaping non-sensory knowledge.</p><p>To address this question, Wang et al. studied the brain activity of deaf adult volunteers in a word meaning judgement task. Volunteers were either born deaf or lost their hearing as toddlers, and all primarily used Chinese Sign Language for communication. One group of volunteers had been exposed to sign language from birth, giving them similar exposure to language as hearing individuals. The other group had less exposure to language in their early years and only learned sign language later in childhood.</p><p>The task included 90 written words that were familiar to the volunteers. They included a mixture of object words – related to material objects – such as “shoulder” and “hammer” and abstract words – which are not linked to physical objects – such as “cause” and “violence”. The volunteers were shown each word in turn and asked to think about the word’s meaning. Brain scans revealed that the left dorsal anterior temporal lobes of the volunteers with reduced early language exposure were less sensitive to the meaning of the words compared with those of the other volunteers.</p><p>The findings demonstrate that the dorsal anterior temporal lobe specifically supports meaning derived from a person’s experience of language as opposed to sensory experience, providing a new angle to understand the mechanism of knowledge representations. Increased understanding of how language supports knowledge will help to uncover the human-specific ways of representing and creating knowledge in the brain.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>dorsal anterior temporal lobe</kwd><kwd>fMRI</kwd><kwd>knowledge</kwd><kwd>language</kwd><kwd>semantics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>STI2030-Major Project 2021ZD0204100</institution></institution-wrap></funding-source><award-id>2021ZD0204104</award-id><principal-award-recipient><name><surname>Bi</surname><given-names>Yanchao</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31925020</award-id><principal-award-recipient><name><surname>Bi</surname><given-names>Yanchao</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>82021004</award-id><principal-award-recipient><name><surname>Bi</surname><given-names>Yanchao</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32171052</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Xiaosha</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31700943</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Xiaosha</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100005240</institution-id><institution>Changjiang Scholar Program of Chinese Ministry of Education</institution></institution-wrap></funding-source><award-id>Professorship Award T2016031</award-id><principal-award-recipient><name><surname>Bi</surname><given-names>Yanchao</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Impoverished access to natural human language during early childhood reduces semantic structure encoding in the left dorsal anterior temporal lobe, which provides positive evidence for the role of language in forming specific neural semantic representations in the human brain.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Humans are believed to be the only species in the animal kingdom where knowledge learning can be achieved symbolically, mostly through language (‘roses are red’), in addition to sensory channels (visually perceiving roses in color red) (<xref ref-type="bibr" rid="bib30">Gelman and Roberts, 2017</xref>; <xref ref-type="bibr" rid="bib54">Perszyk and Waxman, 2018</xref>). A common view shared by the modern neurocognitive theories of semantics is that semantic knowledge, even those acquired through language, is ultimately grounded in (nonlinguistic) sensory/motor experiences, encoded in the distributed brain areas encompassing high-level sensorimotor areas, and potential hub regions that bind such sensory-derived representations (<xref ref-type="bibr" rid="bib2">Barsalou, 2016</xref>; <xref ref-type="bibr" rid="bib5">Binder et al., 2009</xref>; <xref ref-type="bibr" rid="bib26">Fernandino et al., 2022</xref>; <xref ref-type="bibr" rid="bib57">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Martin, 2016</xref>). However, language experiences may contribute to semantic development beyond sensory experiences by facilitating or modulating categorizations by the nature of labeling (i.e. words) to the sensory experiences, and/or by constructing semantic relations based on various types of word relations (<xref ref-type="bibr" rid="bib30">Gelman and Roberts, 2017</xref>; <xref ref-type="bibr" rid="bib54">Perszyk and Waxman, 2018</xref>; <xref ref-type="bibr" rid="bib69">Unger and Fisher, 2021</xref>). Are such cognitive contributions manifested by modulating the neural representations of the sensory-derived semantic spaces, or by also formulating neural representations that specialize in representing knowledge derived from language experience (i.e. not nonlinguistic sensory experience)?</p><p>Neural representations of fully nonsensory, language-derived knowledge have only recently been inferred based on studies with sensory-deprived individuals (<xref ref-type="bibr" rid="bib10">Bottini et al., 2020</xref>; <xref ref-type="bibr" rid="bib62">Striem-Amit et al., 2018</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2020</xref>, see <xref ref-type="bibr" rid="bib4">Bi, 2021</xref>, for a review). Congenitally blind individuals, who cannot acquire visual-specific knowledge (e.g. color) through sensory experiences, can nevertheless acquire semantic structures about such knowledge behaviorally similar to those in the sighted, presumably derived from language. Such nonsensory semantic structures in the blind (and also sighted) are represented in the dorsal anterior temporal lobe (dATL), with sighted individuals additionally representing the highly similar knowledge structure (presumably derived from sensory experience) in the visual cortex (<xref ref-type="bibr" rid="bib73">Wang et al., 2020</xref>). This dATL cluster is distinct from the central ‘amodal’ semantic hub proposed to bind together multiple sensory attributes, which is located in the more ventral-medial territory of the ATL (<xref ref-type="bibr" rid="bib57">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Patterson et al., 2007</xref>; see discussions in <xref ref-type="bibr" rid="bib62">Striem-Amit et al., 2018</xref>). The left dATL is also more strongly activated by abstract than concrete words in typically developed individuals (<xref ref-type="bibr" rid="bib5">Binder et al., 2009</xref>; <xref ref-type="bibr" rid="bib11">Bucur and Papagno, 2021</xref>; <xref ref-type="bibr" rid="bib70">Wang et al., 2010</xref>; <xref ref-type="bibr" rid="bib72">Wang et al., 2019</xref>). It was thus proposed that this area represents knowledge derived from language, in addition to those from sensory experiences in various perceptual (association) regions (<xref ref-type="bibr" rid="bib4">Bi, 2021</xref>). These lines of evidence, while highly suggestive, are based on manipulating sensory experience by examining individuals deprived of a sensory modality or by contrasting concepts with rich sensory experiences versus those without, rather than the positive manipulation of language experience. Thus, the positive evidence for the necessity of language experiences for the neural semantic representation here is still lacking.</p><p>Here, we address this issue in a special human model that varies in early language exposure: individuals who were born profoundly deaf in hearing families and had limited natural language exposure (speech or sign) during early childhood (<xref ref-type="bibr" rid="bib31">Goldin-Meadow and Feldman, 1977</xref>; <xref ref-type="bibr" rid="bib45">Mayberry et al., 2002</xref>). These individuals often acquired their first language (sign language) around school age, which is much later than the age of first language (L1) acquisition in typically developed children or in native deaf signers who were born in deaf families and acquired sign language from birth. Previous research has shown that such early language exposure limitation led to long-lasting effects on various aspects of language processing. Behaviorally, these delayed deaf signers, even during adulthood with many years of sign language usage, have lower proficiency in phonological, morphological, and syntactic processing of sign language (<xref ref-type="bibr" rid="bib9">Bogliotti et al., 2020</xref>; <xref ref-type="bibr" rid="bib12">Caselli et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Cheng and Mayberry, 2021</xref>; <xref ref-type="bibr" rid="bib39">Lieberman et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Mayberry et al., 2002</xref>; <xref ref-type="bibr" rid="bib44">Mayberry and Fischer, 1989</xref>; <xref ref-type="bibr" rid="bib49">Newport, 1990</xref>; <xref ref-type="bibr" rid="bib65">Tomaszewski et al., 2022</xref>). Neurally, brain functional imaging studies have reported decreased activation magnitude in the left inferior frontal and posterior temporal regions in tasks of sign sentence judgments (<xref ref-type="bibr" rid="bib46">Mayberry et al., 2011</xref>; <xref ref-type="bibr" rid="bib60">Richardson et al., 2020</xref>; <xref ref-type="bibr" rid="bib67">Twomey et al., 2020</xref>). Anatomical alterations in regions typically recruited in language tasks – reduced cortical volume in the left inferior frontal region, reduced cortical thickness in the left posterior middle temporal region, and reduced fractional anisotropy values in the left arcuate fasciculus – were also reported in signers with delayed L1 acquisition (<xref ref-type="bibr" rid="bib16">Cheng et al., 2023</xref>; <xref ref-type="bibr" rid="bib14">Cheng et al., 2019</xref>).</p><p>Despite these documented effects of delayed L1 acquisition on phonology, morphology, and syntax (<xref ref-type="bibr" rid="bib20">Curtiss, 1977</xref>; <xref ref-type="bibr" rid="bib38">Lenneberg, 1967</xref>; <xref ref-type="bibr" rid="bib40">Lillo-Martin and Henner, 2021</xref>; <xref ref-type="bibr" rid="bib48">Mayberry and Kluender, 2018</xref>), studies have reported little effects on semantic behaviors, including semantic interference effects in the picture-sign paradigm (<xref ref-type="bibr" rid="bib3">Baus et al., 2008</xref>), scalar implicature (<xref ref-type="bibr" rid="bib21">Davidson and Mayberry, 2015</xref>), or accuracy scores of several written word semantic tasks (e.g. synonym judgment) (<xref ref-type="bibr" rid="bib17">Choubsaz and Gheitury, 2017</xref>). However, as shown by the color knowledge in the congenitally blind studies (e.g. <xref ref-type="bibr" rid="bib73">Wang et al., 2020</xref>), similar semantic behaviors may arise from (partly) different neural representations. Semantic processing is supported by a multifaceted cognitive system and a complex neural network entailing distributed brain regions (<xref ref-type="bibr" rid="bib4">Bi, 2021</xref>; <xref ref-type="bibr" rid="bib6">Binder and Desai, 2011</xref>; <xref ref-type="bibr" rid="bib57">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Martin, 2016</xref>), and thus focal neural changes may not necessarily lead to semantic behavioral changes. Neurally, neurophysiological signatures assumed to reflect semantic processes showed incongruent effects across studies: N400 effects in the semantic violation of written sentences were not affected (<xref ref-type="bibr" rid="bib61">Skotara et al., 2012</xref>), whereas M400 in the picture-sign matching task showed atypical activation patterns (reduced recruitment of the left fronto-temporal regions and involvement of the right parietal and occipital regions) (<xref ref-type="bibr" rid="bib25">Ferjan Ramirez et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Ferjan Ramirez et al., 2014</xref>; <xref ref-type="bibr" rid="bib47">Mayberry et al., 2018</xref>). It remains to be tested whether and where delayed L1 acquisition affects how semantics are neurally represented, using imaging techniques with higher spatial resolutions.</p><p>In this study, by a rare opportunity of manipulation of early language exposure offered by nature, we aim to test the neural system representing the language-derived semantic representations, beyond the sensory-derived semantic representations (<xref ref-type="bibr" rid="bib4">Bi, 2021</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2020</xref>). With fMRI experiments on semantic processing of familiar words, we compared the neural semantic structures between congenitally deaf signers with delayed sign language acquisition (delayed deaf signers) and congenitally deaf signers with native sign language acquisition (native deaf signers), that is, two groups that are matched on their nonlinguistic sensory experiences but varied in early language experience. Significant group differences would provide positive evidence for the role of language experience in the formation of the identified neural semantic structures.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Participants’ background information and task fMRI design</title><p>We recruited two adult groups of congenitally or early deaf participants, including 16 native deaf signers and 23 delayed deaf signers (<xref ref-type="table" rid="table1">Table 1</xref>; <xref ref-type="supplementary-material" rid="table1sdata1">Table 1—source data 1</xref>). Native signers were born in deaf families; delayed signers were born in hearing families and became exposed to Chinese sign language (CSL) between the ages of 4 and 10 (mean ± standard deviation [SD]: 6.91±1.62 years of age). Note that in China the nation-wide hearing screening for newborns or during early infancy started in 2009 and our participants were born before 2000. The family signing environment was confirmed by the subjective ratings of parental CSL proficiency: Native signers rated their parents to have much more proficient CSL skills than delayed signers did on a 7-point scale (Welch’s <italic>t</italic><sub>31.7</sub> = 13.54, p=1.10 × 10<sup>–14</sup>; each participant provided CSL ratings for both parents and the maximum score was used for group comparison). All deaf participants received formal education in special education programs since elementary school. The two deaf groups were matched on demographic variables (gender, age, years of education, ps &gt; 0.15) and subjective social status (<xref ref-type="bibr" rid="bib1">Adler et al., 2000</xref>) during childhood (p = 0.54). While the two groups significantly differed in the education levels of their parents (<xref ref-type="table" rid="table1">Table 1</xref>; ps &lt; 0.053), the direction was in favor of delayed signers as their hearing parents received more formal education than the deaf parents of native signers. In terms of language skills, the two deaf groups were matched on self-reported proficiency of CSL comprehension, production, and lipreading skills (ps &gt; 0.34), and on the reading disability risk measured by the Adult Reading History Questionnaire (ARHQ, <xref ref-type="bibr" rid="bib37">Lefly and Pennington, 2000</xref>) (p = 0.22). Written word processing was further evaluated in two reaction-time tasks (i.e. visual lexical decision and word-triplet semantic judgment) and no significant group differences were found (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). In summary, the native and delayed deaf groups were carefully matched on a wide range of demographic and later language performances (sign, lipreading, and written). Thus, different early language exposure is a strong candidate to account for the neural group differences reported below.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Background demographic and language information of native and delayed signers.</title><p><supplementary-material id="table1sdata1"><label>Table 1—source data 1.</label><caption><title>Background demographic and language information of native and delayed signers.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-81681-table1-data1-v2.xlsx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="left" valign="top">Native(n=16)</th><th align="left" valign="top">Delayed(n=23)</th><th align="left" valign="top">Welch’s <italic>t</italic></th><th align="left" valign="top">p-Value</th><th align="left" valign="top">Hedges' <italic>g</italic></th></tr></thead><tbody><tr><td align="left" valign="top"> AoA of CSL (years of age)</td><td align="char" char="plusmn" valign="top">0±0</td><td align="char" char="plusmn" valign="top">6.91±1.62</td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top"> Parental CSL proficiency (1–7 scale)<xref ref-type="table-fn" rid="table1fn1">*</xref> <sup><xref ref-type="table-fn" rid="table1fn4">§</xref></sup></td><td align="char" char="plusmn" valign="top">6.81±0.54</td><td align="char" char="plusmn" valign="top">2.74±1.29</td><td align="char" char="." valign="top">13.54</td><td align="char" char="." valign="top">&lt;0.001</td><td align="char" char="." valign="top">4.04</td></tr><tr><td align="left" valign="top"> <italic>Demographic information</italic></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top"> Gender</td><td align="char" char="." valign="top">11 M, 5 F</td><td align="char" char="." valign="top">12 M, 11 F</td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top"> Age (years)</td><td align="char" char="plusmn" valign="top">28.50±7.13</td><td align="char" char="plusmn" valign="top">27.09±5.87</td><td align="char" char="." valign="top">0.65</td><td align="char" char="." valign="top">0.52</td><td align="char" char="." valign="top">0.21</td></tr><tr><td align="left" valign="top"> Education (years)</td><td align="char" char="plusmn" valign="top">14.13±2.31</td><td align="char" char="plusmn" valign="top">15.09±1.41</td><td align="char" char="." valign="top">–1.49</td><td align="char" char="." valign="top">0.15</td><td align="char" char="." valign="top">–0.49</td></tr><tr><td align="left" valign="top"> McArthur Scale of Subjective Social Status, childhood (1–10 scale)<xref ref-type="table-fn" rid="table1fn2"><sup>†</sup></xref></td><td align="char" char="plusmn" valign="top">3.88±2.58</td><td align="char" char="plusmn" valign="top">4.35±1.97</td><td align="char" char="." valign="top">–0.62</td><td align="char" char="." valign="top">0.54</td><td align="char" char="." valign="top">–0.20</td></tr><tr><td align="left" valign="top"> Father’s education (years) <xref ref-type="table-fn" rid="table1fn4"><sup>§</sup></xref></td><td align="char" char="plusmn" valign="top">7.19±3.04</td><td align="char" char="plusmn" valign="top">10.39±2.84</td><td align="char" char="." valign="top">–3.33</td><td align="char" char="." valign="top">0.002</td><td align="char" char="." valign="top">–1.07</td></tr><tr><td align="left" valign="top"> Mother’s education (years)</td><td align="char" char="plusmn" valign="top">6.56±3.14</td><td align="char" char="plusmn" valign="top">8.52±2.73</td><td align="char" char="." valign="top">–2.02</td><td align="char" char="." valign="top">0.053</td><td align="char" char="." valign="top">–0.65</td></tr><tr><td align="left" valign="top"> <italic>Language information</italic></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top"> CSL comprehension (1–7 scale)<xref ref-type="table-fn" rid="table1fn1">*</xref></td><td align="char" char="plusmn" valign="top">6.06±0.93</td><td align="char" char="plusmn" valign="top">6.17±0.89</td><td align="char" char="." valign="top">–0.38</td><td align="char" char="." valign="top">0.71</td><td align="char" char="." valign="top">–0.12</td></tr><tr><td align="left" valign="top"> CSL production (1–7 scale)<xref ref-type="table-fn" rid="table1fn1">*</xref></td><td align="char" char="plusmn" valign="top">5.75±1.00</td><td align="char" char="plusmn" valign="top">5.87±1.10</td><td align="char" char="." valign="top">–0.35</td><td align="char" char="." valign="top">0.73</td><td align="char" char="." valign="top">–0.11</td></tr><tr><td align="left" valign="top"> Lipreading of acquaintances (1–7 scale)<xref ref-type="table-fn" rid="table1fn1">*</xref></td><td align="char" char="plusmn" valign="top">2.81±1.11</td><td align="char" char="plusmn" valign="top">3.17±1.19</td><td align="char" char="." valign="top">–0.97</td><td align="char" char="." valign="top">0.34</td><td align="char" char="." valign="top">–0.31</td></tr><tr><td align="left" valign="top"> Lipreading of strangers (1–7 scale)<xref ref-type="table-fn" rid="table1fn1">*</xref></td><td align="char" char="plusmn" valign="top">1.88±0.81</td><td align="char" char="plusmn" valign="top">1.87±0.97</td><td align="char" char="." valign="top">0.02</td><td align="char" char="." valign="top">0.99</td><td align="char" char="." valign="top">0.01</td></tr><tr><td align="left" valign="top"> Adult Reading History Questionnaire (ARHQ, 1–5 scale)<xref ref-type="table-fn" rid="table1fn3"><sup>‡</sup></xref></td><td align="char" char="plusmn" valign="top">2.59±0.68</td><td align="char" char="plusmn" valign="top">2.84±0.52</td><td align="char" char="." valign="top">–1.25</td><td align="char" char="." valign="top">0.22</td><td align="char" char="." valign="top">–0.41</td></tr><tr><td align="left" valign="top"> ARHQ, Item 26, self-rated reading speed (1–5 scale)<xref ref-type="table-fn" rid="table1fn3"><sup>‡</sup></xref></td><td align="char" char="plusmn" valign="top">2.38±1.36</td><td align="char" char="plusmn" valign="top">3.13±1.01</td><td align="char" char="." valign="top">–1.89</td><td align="char" char="." valign="top">0.07</td><td align="char" char="." valign="top">–0.62</td></tr><tr><td align="left" valign="top"> ARHQ, Item 29, self-rated writing skills (1–5 scale)<sup><xref ref-type="table-fn" rid="table1fn3">‡</xref> <xref ref-type="table-fn" rid="table1fn4">§</xref></sup></td><td align="char" char="plusmn" valign="top">2.25±1.00</td><td align="char" char="plusmn" valign="top">3.17±0.94</td><td align="char" char="." valign="top">–2.91</td><td align="char" char="." valign="top">0.007</td><td align="char" char="." valign="top">–0.93</td></tr><tr><td align="left" valign="top"> ARHQ, Item 40, self-rated reading comprehension (1–5 scale)<xref ref-type="table-fn" rid="table1fn3"><sup>‡</sup></xref></td><td align="char" char="plusmn" valign="top">2.44±0.81</td><td align="char" char="plusmn" valign="top">2.70±0.97</td><td align="char" char="." valign="top">–0.90</td><td align="char" char="." valign="top">0.38</td><td align="char" char="." valign="top">–0.28</td></tr></tbody></table><table-wrap-foot><fn id="table1fn1"><label>*</label><p>Higher scores indicate higher proficiency.</p></fn><fn id="table1fn2"><label>†</label><p>Higher scores indicate higher social status; from <xref ref-type="bibr" rid="bib1">Adler et al., 2000</xref>.</p></fn><fn id="table1fn3"><label>‡</label><p>Higher scores indicate a higher risk of reading disability; from <xref ref-type="bibr" rid="bib37">Lefly and Pennington, 2000</xref>.</p></fn><fn id="table1fn4"><label>§</label><p>p &lt; 0.01, significant differences between the two deaf groups.</p></fn></table-wrap-foot></table-wrap><p>The stimuli of task fMRI were 90 written words that were highly familiar to both groups, including 40 concrete/object words varying in sensory and motor properties (animals, face/body parts, artifacts) and 50 abstract/nonobject words varying in social and emotional contents. These words were grouped into 10 categories based on the group-averaged semantic multi-arrangement performances in an independent group of 32 hearing participants (see Materials and methods, <xref ref-type="fig" rid="fig1">Figure 1a</xref>, and <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>). Both deaf groups judged these words to be highly familiar (7-point familiarity ratings from 8 native signers: 6.72±0.17; 13 delayed signers: 6.86±0.15; 7 being most familiar) and yielded similar word-relational structures in a 1 hr semantic distance judgment task, in which each participant (16 native and 21 delayed signers) produced a 90 × 90 semantic representational distance matrix (RDM). The group-averaged semantic RDMs of the two deaf groups were strongly correlated (Spearman’s rho = 0.71, n = 4005; <xref ref-type="fig" rid="fig1">Figure 1a</xref>). At the individual level, correlations with the benchmark (the group-averaged RDM of hearing participants) did not significantly differ between the two deaf groups (Welch’s <italic>t</italic><sub>31.3</sub> = –0.37, p = 0.71; <xref ref-type="supplementary-material" rid="fig1sdata2">Figure 1—source data 2</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The word stimuli, task fMRI procedure, and regions of interest (ROIs) in this study.</title><p>(<bold>a</bold>) Word stimuli in the task fMRI. Ninety words were used, including 40 concrete/object words and 50 abstract/nonobject words, which were grouped into fine-grained categories based on k-means clustering of the group-averaged semantic space of 32 hearing participants. The left panel shows the group-averaged semantic representational matrices (RDM) in hearing participants, native signers, and delayed signers. The right panel shows the Spearman’s rho between each deaf participant’s semantic RDM and the group-averaged semantic RDM in hearing participants. n = 16 in the native group; n = 21 in the delayed group. Error bars indicate 1 s.e.m. n.s., not significant, p &gt; 0.05, Welch’s <italic>t</italic>-test. (<bold>b</bold>) Task fMRI procedure. During scanning, participants were asked to think about each of 90 target word meanings (displayed in black, e.g. ‘panda’, ‘reason’) and to determine whether occasional words displayed in red (catch trials, e.g. ‘justification’) were semantically related to the previous word. There were 90 target word trials (each word appeared once) and 14 catch trials in each run. (<bold>c</bold>) Semantic ROIs were functionally identified by contrasting abstract/nonobject words with concrete/object words in 33 hearing participants at the threshold of voxel-level p &lt; 0.001, cluster-level FWE-corrected p &lt; 0.05. dATL, dorsal anterior temporal lobe; IFG, inferior frontal gyrus; pMTG, posterior middle temporal gyrus. L, left hemisphere; R, right hemisphere.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Ninety words in the fMRI task, grouped into 10 semantic clusters based on k-means clustering of the group-mean hearing semantic space.</title></caption><media mimetype="application" mime-subtype="docx" xlink:href="elife-81681-fig1-data1-v2.docx"/></supplementary-material></p><p><supplementary-material id="fig1sdata2"><label>Figure 1—source data 2.</label><caption><title>Spearman’s rho between each deaf participant’s semantic representational distance matrix (RDM) and the group-averaged semantic RDM in hearing participants.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-81681-fig1-data2-v2.xlsx"/></supplementary-material></p><p><supplementary-material id="fig1sdata3"><label>Figure 1—source data 3.</label><caption><title>Details of semantic regions of interest (ROIs), including cluster location, extent, peak t values, and Montreal Neurological Institute (MNI) coordinates.</title></caption><media mimetype="application" mime-subtype="docx" xlink:href="elife-81681-fig1-data3-v2.docx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Written word processing performances of the two deaf groups in two reaction-time tasks.</title><p>(<bold>a</bold>) Lexical decision task, in which participants were asked to decide whether a two-Chinese-character written stimulus denoted a real word or a pseudoword via button press. In each trial, a fixation point was presented for 800 ms, followed by a Chinese stimulus (font SONG, size 40). The stimulus disappeared upon the response and the next trial started 1 s later. The stimuli were 100 two-character Chinese nouns (word frequency, range: 0–1491 per million; <xref ref-type="bibr" rid="bib63">Sun et al., 1997</xref>; number of strokes: range: 8–25) and 100 two-character pseudowords created by pseudo-randomly combining two characters of 100 real words. Bar plots show the d-prime and reaction time of real-word trials. d-Prime was calculated using the Signal Detection Theory Calculator (version 1.2) provided by <xref ref-type="bibr" rid="bib29">Gaetano, 2017</xref>. (<bold>b</bold>) Word-triplet semantic judgment task, in which participants were presented with three 2-character Chinese words and asked to decide which of the two choice words (bottom) was more semantically related to the probe word (top) via button press. In each trial, a fixation point was presented for 500 ms, followed by three Chinese words (font SONG, size 40), with the probe word presented at the top and two choice words arranged horizontally at the bottom. The stimuli disappeared upon the response and the next trial started 1 s later. The stimuli were 80 triplets of two-character Chinese words (word frequency, range: 0–2340 per million; total number of strokes, range: 6–31), with all but four primarily used as nouns. Bar plots show overall accuracy and reaction time of correct trials. n = 16 in the native group; n = 22 in the delayed group. Error bars indicate 1 s.e.m. n.s., not significant, p &gt; 0.05, Welch’s <italic>t</italic>-test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Representational similarity analysis (RSA) and univariate results in other regions of interest (ROIs) (except for the left dATL, inferior frontal gyrus [IFG], and pMTG) in the two deaf groups.</title><p>dATL, dorsal anterior temporal lobe; pMTG, posterior middle temporal gyrus; SFGmed, superior frontal gyrus, medial; PCG, posterior cingulate gyrus; PCUN, precuneus. n.s., not significant, p &gt; 0.05; *, p &lt; 0.05. n = 16 in the native group; n = 23 in the delayed group. In (a), RSA results were assessed using one-sample <italic>t</italic>-tests (one-tailed) for each group; group differences were examined using two-tailed Welch’s <italic>t</italic>-tests. In (b), beta values of the two word types were compared using one-tailed paired <italic>t</italic>-tests for each group; group effects were assessed using two-way analysis of variance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig1-figsupp2-v2.tif"/></fig></fig-group><p>In the MRI scanner, participants were asked to think about the meaning of each of the 90 words (condition-rich fMRI design; <xref ref-type="bibr" rid="bib35">Kriegeskorte et al., 2008</xref>) and to decide whether a word in red (catch trials) was semantically related to its previous word (i.e. oddball one-back semantic judgment, <xref ref-type="fig" rid="fig1">Figure 1b</xref>). We first examined the two-deaf-group differences in brain regions preferring abstract/nonobject words to concrete/object words, which have been proposed to relate to verbal semantic processing (<xref ref-type="bibr" rid="bib5">Binder et al., 2009</xref>; <xref ref-type="bibr" rid="bib70">Wang et al., 2010</xref>). These regions were functionally localized by contrasting abstract/nonobject words (e.g. <italic>reason</italic>) to concrete/object words (e.g. <italic>panda</italic>) in an independent group of 33 hearing participants (voxel-level p&lt;0.001, cluster-level FWE-corrected p&lt;0.05). This contrast in the hearing group resulted in regions in the frontal and temporal cortices that were well aligned with the literature (<xref ref-type="fig" rid="fig1">Figure 1c</xref>; <xref ref-type="supplementary-material" rid="fig1sdata3">Figure 1—source data 3</xref>). In particular, the left dATL, the left inferior frontal gyrus (IFG), and the left posterior middle temporal gyrus (pMTG) were most consistently reported in the meta-analyses (<xref ref-type="bibr" rid="bib5">Binder et al., 2009</xref>; <xref ref-type="bibr" rid="bib11">Bucur and Papagno, 2021</xref>; <xref ref-type="bibr" rid="bib70">Wang et al., 2010</xref>) and were taken as our primary regions of interest (ROIs). Results for the other clusters are shown in <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref> (no significant group differences). We then carried out whole-brain analyses to explore the two-deaf-group differences beyond these semantic ROIs. We focused on two neural semantic effects: (1) representational similarity analysis (RSA) of word meaning by correlating 90 words’ neural RDMs with semantic RDMs (i.e. semantically related words have similar neural patterns) and (2) the univariate semantic abstractness effects.</p></sec><sec id="s2-2"><title>Semantic structure representation: dATL alteration in delayed signers</title><p>We first examined whether early-life language exposure affects neural representations of the semantic space using RSA (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, <xref ref-type="bibr" rid="bib35">Kriegeskorte et al., 2008</xref>). We estimated the multivoxel activation pattern for each target word and, in a given ROI, calculated the correlation distance (1-Pearson correlation) of the multivoxel activation patterns between each word pair to build a 90 × 90 neural RDM. As a sanity check, we first carried out whole-brain searchlight RSA of visual similarity of written words, by computing Spearman’s rank correlation between the pixelwise dissimilarity of the 90 words and neural RDMs, and observed significant encoding of written word visual similarity in the early visual cortex in both native and delayed signers at the threshold of voxel-level p &lt; 0.001, cluster-level FWE-corrected p &lt; 0.05 (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). To quantify the semantic information encoded in the neural RDMs, in each deaf subject, we computed Spearman’s partial correlation between the neural RDMs and the 10-category benchmark semantic RDM (i.e. those of the hearing group), while controlling for the stimulus low-level visual and phonological RDMs (see Materials and methods). Note that we opted for the categorical structural similarity based on the clustering analyses to boost signal and to allow for better generalization across items (i.e. along the categorical structure). This approach may lose the important graded space especially for the abstract items, and we carried out a validation analysis using the continuous semantic distances specifically focused on the abstract items (see below).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Effects of early language exposure on neural representations of semantic knowledge.</title><p>(<bold>a</bold>) Representational similarity analysis (RSA) procedure. For each participant, a neural representational distance matrix (RDM) was computed as the correlation distance of multivoxel activity patterns (in a given regions of interest [ROI]) for each pair of words and then correlated with the hearing-group-level semantic category RDM to quantify semantic information encoded in the neural RDM. (<bold>b</bold>) ROI-level RSA results. Error bars indicate 1 s.e.m. n.s., not significant, p &gt; 0.05; *, p &lt; 0.05; **, p &lt; 0.01; ***, p &lt; 0.001. ROI results were assessed using one-sample t-tests (one-tailed) for each group; group differences were examined using two-tailed Welch’s t-tests. dATL, dorsal anterior temporal lobe; pMTG, posterior middle temporal gyrus; IFG, inferior frontal gyrus. (<bold>c</bold>) Whole-brain searchlight RSA results. The statistical maps were thresholded at voxel-level p &lt; 0.001, cluster size &gt; 10 voxels. Brain results were visualized using the ‘Maximum Voxel’ mapping algorithm in BrainNet Viewer to illustrate small clusters. Clusters in black lines survived the cluster-level FWE-corrected p &lt; 0.05. L, left hemisphere; R, right hemisphere. n = 16 in the native group; n = 23 in the delayed group.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Region of interest (ROI)-level representational similarity analysis (RSA) results in the two deaf groups.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-81681-fig2-data1-v2.xlsx"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><label>Figure 2—source data 2.</label><caption><title>Cluster details of the whole-brain searchlight representational similarity analysis (RSA) results.</title></caption><media mimetype="application" mime-subtype="docx" xlink:href="elife-81681-fig2-data2-v2.docx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Whole-brain representational similarity analysis (RSA) results of pixelwise similarity of visual words in the two deaf groups.</title><p>The neural effects were thresholded at voxel-level p &lt; 0.001, cluster-level FWE-corrected p &lt; 0.05. L, left hemisphere. n = 16 in the native group; n = 23 in the delayed group.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig2-figsupp1-v2.tif"/></fig></fig-group><p>ROI-level RSA was carried out in the left dATL, pMTG, and IFG. As shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>, the three ROIs significantly encoded the semantic space in native signers (<italic>t</italic><sub>15</sub> &gt; 3.04, one-tailed ps &lt; 0.004, Cohen’s d &gt; 0.76). In delayed signers, the left dATL and pMTG also significantly encoded the semantic space (<italic>t</italic><sub>22</sub> &gt; 2.07, one-tailed ps &lt; 0.025, Cohen’s d &gt; 0.43) and the left IFG showed a similar, nonsignificant, trend (<italic>t</italic><sub>22</sub> = 1.31, one-tailed p = 0.10, Cohen’s d = 0.27). Critically, group differences were observed in the left dATL (Welch’s <italic>t</italic><sub>36.7</sub> = 3.15, two-tailed p=0.003, Hedges’ <italic>g</italic> = 0.98), not in the left pMTG or IFG (ps &gt; 0.26). Note that we did not observe a significant group-by-ROI interaction in the two-way ANOVA (<italic>F</italic><sub>(2,74)</sub> = 1.59, p = 0.21).</p><p>We then carried out whole-brain searchlight RSA (<xref ref-type="bibr" rid="bib34">Kriegeskorte et al., 2006</xref>) to explore group differences in semantic encoding beyond the semantic ROIs defined above (<xref ref-type="fig" rid="fig2">Figure 2c</xref>; <xref ref-type="supplementary-material" rid="fig2sdata2">Figure 2—source data 2</xref>). At the threshold of voxel-level p &lt; 0.001, cluster-level FWE-corrected p &lt; 0.05, in native signers, the semantic encoding was observed in the left dATL, IFG, pMTG, along with adjacent parietal and occipital areas, dorsomedial prefrontal cortex, and frontal orbital cortex. In delayed signers, no brain regions survived the whole-brain correction; at a more lenient threshold of voxel p &lt; 0.001, cluster size &gt;10 voxels, semantic encoding could be observed in the left dATL, IFG, and clusters scattered in the left inferior parietal and occipital regions. Of course, such a thresholded map does not indicate true negatives in the delayed singer group. The whole-brain contrast between the two deaf groups peaked at the left dATL at the threshold of voxel p &lt; 0.001, which was also the largest cluster (peak MNI coordinates: –60, 6,–20, peak t = 5.87, 162 voxels), converging well with the ROI results in that native signers showed stronger semantic encoding than delayed signers in the left dATL ROI. While this cluster was not large enough to survive the whole-brain correction (cluster FWE-corrected p = 0.22), the top 10 voxels survived the voxel-level correction of FWE-corrected p &lt; 0.05. No areas were found to show significantly increased semantic information in delayed signers compared with native signers at the conventional threshold. Together, group differences were not apparent outside the ROIs analyzed in the previous section.</p><p>To further validate the reduced semantic encoding in the left dATL, we carried out the following analyses: (1) Types of semantic distance measures: While semantic categories for concrete/object words are robust and well documented, the semantic categorization within the abstract/nonobject words is much fuzzier and remains controversial (<xref ref-type="bibr" rid="bib13">Catricalà et al., 2014</xref>; <xref ref-type="bibr" rid="bib74">Wang and Bi, 2021</xref>). The behavioral semantic RDM in <xref ref-type="fig" rid="fig1">Figure 1a</xref> indeed shows gradations in dissimilarity for abstract/nonobject words. We thus checked the two groups’ semantic RDMs using the continuous behavioral measures and further examined whether group differences in the left dATL were affected by the types of semantic distance (categorical vs. continuous) being used for abstract/nonobject words. The two deaf groups showed comparable similarities to the hearing benchmark (by correlating each deaf subject’s RDM with the group-averaged RDM of hearing subjects, Welch’s <italic>t</italic><sub>23.0</sub> = –0.12, two-tailed p = 0.90). RSA was performed by correlating each deaf subject’s neural RDM in the left dATL with these two types of semantic RDMs. Significant group differences were observed (<xref ref-type="fig" rid="fig3">Figure 3</xref>; <xref ref-type="supplementary-material" rid="fig3sdata1">Figure 3—source data 1</xref>), for both the categorical RDM (Welch’s <italic>t</italic><sub>31.0</sub> = 3.06, two-tailed p = 0.005, Hedges’ <italic>g</italic> = 0.98) and the continuous behavioral semantic RDM (Welch’s <italic>t</italic><sub>37.0</sub> = 2.47, two-tailed p = 0.018, Hedges’ <italic>g</italic> = 0.76), with significant semantic encoding in the dATL observed in both analyses for native signers (one-tailed ps &lt; 0.003) and neither for delayed signers (one-tailed ps &gt; 0.42). These results indicate that the reduced dATL encoding of abstract/nonobject word meanings induced by delayed L1 acquisition was reliable across different semantic distance measures. (2) Types of ROIs: To validate whether the dATL semantic reduction in delayed signers depends on particular ATL definitions and to explore potential group differences in other language-sensitive regions beyond the ROIs we localized, we performed the RSA in a commonly used language mask (contrasting intact sentences with nonword lists) (<xref ref-type="bibr" rid="bib23">Fedorenko et al., 2010</xref>). As shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>, again we observed significant group differences in the ATL (Welch’s <italic>t</italic><sub>33.1</sub> = 3.71, two-tailed p = 7.53 × 10<sup>–4</sup>, Hedges’ <italic>g</italic> = 1.18), which also survived the Bonferroni correction. Other language-sensitive regions did not reach significance, with the tendency for the same direction of semantic encoding reduction (ps &gt; 0.065, uncorrected). Two-way ANOVA showed a significant main effect of group (<italic>F</italic><sub>(1, 37)</sub> = 6.80, p=0.013) and no significant ROI-by-group interaction (<italic>F</italic><sub>(5, 185)</sub> = 0.823, p=0.535), indicating that delayed L1 acquisition resulted in widespread reduced semantic representations in the language regions, with the effects in the ATL consistently robust.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Effects of early language exposure on neural representations of abstract/nonobject words in the left dorsal anterior temporal lobe (dATL).</title><p>The two representational distance matrices (RDMs) at the top illustrate the categorical and the continuous behavioral semantic RDMs of 50 abstract/nonobject words constructed in an independent group of hearing individuals. The bar plots at the bottom show the Fisher-transformed Spearman’s correlations between the neural and semantic RDMs for each deaf subject. Error bars indicate 1 s.e.m. *, p &lt; 0.05; **, p &lt; 0.01; ***, p &lt; 0.001. RSA results were assessed using one-sample <italic>t</italic>-tests (one-tailed) for each group; group differences were examined using two-tailed Welch’s <italic>t</italic>-tests. n = 16 in the native group; n = 23 in the delayed group.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Representational similarity analysis (RSA) results for the abstract/nonobject words in the two deaf groups.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-81681-fig3-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig3-v2.tif"/></fig><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Effects of early language exposure on neural representations of semantic knowledge in language-sensitive regions.</title><p>The left panel shows the language-sensitive regions of interest (ROIs) (<xref ref-type="bibr" rid="bib23">Fedorenko et al., 2010</xref>) and the black lines indicate the three ROIs we functionally localized. Bar plots show the Fisher-transformed Spearman’s correlations between the neural and the semantic category RDMs for each deaf subject. Error bars indicate 1 s.e.m. n.s., not significant, p &gt; 0.05; *, p &lt; 0.05; **, p &lt; 0.01; ***, p &lt; 0.001. RSA results were assessed using one-sample <italic>t</italic>-tests (one-tailed) for each group; group differences were examined using two-tailed Welch’s <italic>t</italic>-tests. ATL, anterior temporal lobe; pMTG, posterior middle temporal gyrus; AG, angular gyrus; IFGorb, the orbital part of the inferior frontal gyrus; IFG, inferior frontal gyrus; MFG, middle frontal gyrus. n = 16 in the native group; n = 23 in the delayed group.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Representational similarity analysis (RSA) results in language-sensitive regions of interest (ROIs) in the two deaf groups.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-81681-fig4-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig4-v2.tif"/></fig></sec><sec id="s2-3"><title>Univariate semantic abstractness effects: dATL alteration in delayed signers</title><p>We then examined how early language exposure might alter the neural semantic abstractness effects by comparing regional activation strength to abstract/nonobject and concrete/object words in the two deaf groups. While the abstractness effect has often been used to reflect linguistic processes (e.g. <xref ref-type="bibr" rid="bib70">Wang et al., 2010</xref>), ‘abstractness’ is not a single dimension and relates to both linguistic and nonlinguistic (e.g. emotion) cognitive processes (<xref ref-type="bibr" rid="bib8">Binder et al., 2016</xref>; <xref ref-type="bibr" rid="bib66">Troche et al., 2014</xref>; <xref ref-type="bibr" rid="bib71">Wang et al., 2018</xref>). The reasoning here is that if a brain region’s abstractness effect is affected by early language exposure, this would constitute further evidence that the abstractness computed by this brain region is indeed associated with language processes.</p><p>At the ROI level (<xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>), all three ROIs (the left dATL, IFG, and pMTG) exhibited significant abstractness preference in both deaf groups (<xref ref-type="fig" rid="fig5">Figure 5a</xref>; native group: paired <italic>t</italic>s &gt; 3.72, df = 15, one-tailed ps &lt;0.001, Cohen’s <italic>d</italic>s &gt; 0.93; delayed group: paired <italic>t</italic>s &gt; 2.13, df = 22, one-tailed ps &lt; 0.02, Cohen’s <italic>d</italic>s&gt;0.44), further indicating the robustness of semantic abstractness preference in these ROIs. We then carried out two-way ANOVA to examine group effects in each of these ROIs, with word type (concrete/object, abstract/nonobject) as a within-subject factor and group (native, delayed) as a between-subject factor. The group × word type interaction reached statistical significance only in the left dATL (<italic>F</italic><sub>(1,37)</sub> = 4.91, p = 0.033), not in the left pMTG or IFG (ps &gt; 0.30). In the left dATL native signers exhibited greater semantic abstractness effects than delayed signers. The main effects of group were not significant in any of the three ROIs (ps &gt; 0.057). We then compared group differences across the three ROIs using two-way ANOVA on the semantic abstractness effects (calculated by subtracting the concrete/object activation from the abstract/nonobject activation strength). NThere were no significant group-by-ROI interaction (<italic>F</italic><sub>(2,74)</sub> = 0.50, p = 0.61).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Effects of early language exposure on the univariate semantic abstractness effects in group-level-defined semantic regions of interest (ROIs) (<bold>a</bold>) and individual functional ROIs (fROIs) (<bold>b</bold>).</title><p>Boxplots show beta values to abstract/nonobject words and concrete/object words in the three ROIs (the left dorsal anterior temporal lobe [dATL], posterior middle temporal region [pMTG], and inferior frontal gyrus [IFG]). n.s., not significant, p &gt; 0.05; *, p &lt; 0.05; **, p &lt; 0.01; ***, p &lt; 0.001. Beta values of the two word types were compared using one-tailed paired <italic>t</italic>-tests for each group; group effects were assessed using two-way analysis of variance. n=16 in the native group; n = 23 in the delayed group.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Raw beta values to abstract/nonobject words and concrete/object words in group-level-defined semantic regions of interest (ROIs) and individual functional ROIs (fROIs) in the two deaf groups.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-81681-fig5-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Whole-brain univariate results of semantic abstractness in native and delayed signers.</title><p>The statistical maps were thresholded at voxel-level p &lt; 0.001, cluster sizes &gt; 10 voxels, and visualized using the ‘Maximum Voxel’ mapping algorithm in BrainNet Viewer to illustrate small clusters. Clusters labeled with an asterisk survived the threshold of voxel-level p &lt; 0.001, cluster-level FWE-corrected p &lt; 0.05 (left dorsal anterior temporal lobe [dATL] in native signers, peak Montreal Neurological Institute [MNI] coordinates: –58, 4, -8, peak t = 7.27, 209 voxels). L, left hemisphere; R, right hemisphere. n = 16 in the native group; n = 23 in the delayed group.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81681-fig5-figsupp1-v2.tif"/></fig></fig-group><p>Considering inter-subject variations in activation locations, we further carried out the individualized functional ROI (fROI) analysis for validation (<xref ref-type="bibr" rid="bib18">Cohen et al., 2019</xref>; <xref ref-type="bibr" rid="bib58">Ratan Murty et al., 2020</xref>) (see Materials and methods). Using each of the ROIs defined in the hearing group as anatomical constraints, we identified the top 50 selective voxels in each deaf participant using one-half of the fMRI data and computed regional activation strength to abstract and concrete words in these voxels in the held-out data (i.e. via an odd-even run cross-validation process). As shown in <xref ref-type="fig" rid="fig5">Figure 5b</xref>, the group × word type interaction was again observed in the left dATL (<italic>F</italic><sub>(1,37)</sub> = 6.20, p = 0.017), not in the pMTG or IFG (ps &gt; 0.58). Main effects of group were not found (ps &gt; 0.18).</p><p>We performed a whole-brain analysis of the semantic abstractness effects in the two deaf groups (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). For native signers, at the threshold of voxel-level p &lt; 0.001, cluster-level FWE-corrected p &lt; 0.05, semantic abstractness reached significance in the left dATL (peak MNI coordinates: –58, 4,–8, peak t = 7.27, 209 voxels). For delayed signers, no regions survived the whole-brain threshold; at a lenient threshold of voxel p &lt; 0.001, cluster size &gt;10 voxels, abstractness could be observed in the left pMTG and dATL, which are consistent with the ROI results above. The whole-brain between-group comparisons of the semantic abstractness effects did not yield any areas surviving the conventional whole-brain correction threshold.</p></sec><sec id="s2-4"><title>Controlling for the written language performances for dATL semantic reduction in delayed signers</title><p>Delayed L1 acquisition may associate with language proficiency changes in multiple aspects (see <xref ref-type="table" rid="table1">Table 1</xref>). It is possible that the dATL semantic computation is not associated with delayed L1 acquisition per se, but with subjects’ written language performance, a key source of semantic knowledge accumulation. Our two groups of deaf signers did not significantly differ in their performances in two word-reading tasks (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), which was consistent with the self-rated reading comprehension ability in the ARHQ (Welch’s <italic>t</italic><sub>35.6</sub> = –0.90, p = 0.375, Hedges’ <italic>g</italic> = –0.28, <xref ref-type="table" rid="table1">Table 1</xref>). However, delayed signers did report significantly lower writing ability (Welch’s <italic>t</italic><sub>31.0</sub> = –2.91, p = 0.007, Hedges’ <italic>g</italic> = –0.93) and a tendency of lower reading speeds (Welch’s <italic>t</italic><sub>26.2</sub> = –1.89, p = 0.07, Hedges’ <italic>g</italic> = –0.62) in the ARHQ than native signers (<xref ref-type="table" rid="table1">Table 1</xref>). We then carried out mediation analyses (using the <italic>mediation</italic> package in R) to examine whether writing or reading speed mediated the group differences in neural semantic effects in the left dATL. For both the multivariate RSA and univariate abstractness effects, the direct effects of group remained largely significant (ps &lt; 0.074), whereas the mediation effects did not approach statistical significance (ps &gt; 0.52), based on 5000 times bootstrapping resampling. That is, the reduced dATL semantic effects induced by delayed L1 acquisition were not fully attributable to written language processes.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>By comparing fMRI BOLD responses to the word semantic structures between native and delayed early deaf signers, we aimed to examine how early-life language exposure affects the semantic neural representations. Our results demonstrated that semantic information in the left dATL was significantly reduced in delayed signers compared with native signers in both multivariate (representation of rich semantic space) and univariate (preference to abstract/nonobject words) analyses. That is, early-life language acquisition – critical to language system neurodevelopment – is necessary for the left dATL to exhibit the typical semantic organization in adulthood. These results provide the first positive evidence for the effect of language experience on driving the semantic functional development of a particular brain region.</p><p>Two types of specificity are to be clarified – anatomical specificity and information specificity. First, is this group effect specific to the dATL, relative to other brain regions? We do not have evidence for such a strong region specificity. We did not observe a significant group-by-ROI interaction in either the RSA or the univariate analyses. That is, the group differences were not significantly stronger in the dATL than in the other semantic regions being analyzed (IFG and pMTG). We are thus not claiming that the dATL is the only region that derives semantic representation from language experience, but choose to focus the following discussion on this region because of the robust positive effects here. Second, is the dATL semantic representation specifically derived from language experience and not other (nonlinguistic) sensory experiences? The manipulation of the current study – the two groups of deaf signers – varies on the language exposure while matching on the sensory experiences (see below), and thus did not test the presence or absence of sensory-derived semantic representations. Inferences could be drawn in combination with the previous studies that focused on the manipulation of sensory experiences by studying visual knowledge in congenitally blind subjects. There, it was reported that the blind and sighted had comparable semantic information encoding in the RSA (<xref ref-type="bibr" rid="bib73">Wang et al., 2020</xref>). In terms of univariate effects (abstractness or color concept adaptation), deprivation of sensory experiences did not reduce, but actually tended to enhance the effects here (<xref ref-type="bibr" rid="bib10">Bottini et al., 2020</xref>; <xref ref-type="bibr" rid="bib62">Striem-Amit et al., 2018</xref>). That is, evidence from congenitally blind studies does not support the additional sensory-derived semantic encoding here. While drawing negative conclusions is always difficult, we reason that it is parsimonious, based on available data, to propose that the dATL’s contribution to semantic encoding is specific to language, and not sensory-derived representations.</p><p>What kind of variables best account for the observed group differences in the dATL? The two deaf groups were matched on sensory experiences (both similarly profoundly deaf), a wide range of nonlinguistic environmental variables including the socioeconomic status (except for parents’ education backgrounds, which were better for the delayed signer group), the length and level of formal education, through which largely comparable sign language and word reading skills were achieved. The salient difference was the early-life language experience (before 6.9 years of age – the mean age of acquisition in our delayed signer group). Notably, deaf children with limited access to natural language often spontaneously develop homesign systems, which share some aspects with natural language (<xref ref-type="bibr" rid="bib32">Goldin-Meadow, 2003</xref>). For instance, they could use homesigns to produce generic utterances in a similar manner to typically developed children (<xref ref-type="bibr" rid="bib33">Goldin-Meadow et al., 2005</xref>). Notably, routine nation-wide neonate hearing screening in China did not start until 2009, years after the early childhood of our participants (born before 2000), and some hearing parents may nonetheless try to give deaf children additional aids of exposure to signs (via preschool special education programs) or speech (via hearing aids). Critically, our positive results of the robust group differences in the dATL suggest that early homesign/aid measures and later formal education for sign and written language experiences are insufficient for typical dATL neurodevelopment; the full-fledged language experience during early infancy and childhood (before school age) plays a necessary role in this process. A further variable to consider is that a lack of early language exposure may lead to alterations beyond the language system, affecting non-language cognitive domains such as working memory or theory of mind in children (<xref ref-type="bibr" rid="bib42">Marshall et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Richardson et al., 2020</xref>). While we cannot rule out the effects of these potential intermediate cognitive processes, the positive evidence of these variables in dATL functionality is lacking. The most direct manipulation and parsimonious account for the dATL effects is language-related.</p><p>The effects of language experience in shaping the semantic representation in the dATL observed here are corroborated by several previous lines of indirect evidence for the relevance of language in its functionality. It shows a functional preference for abstract words, which are less salient in sensory attributes than concrete words and are assumed to entail more language processes such as context diversity (e.g. <xref ref-type="bibr" rid="bib5">Binder et al., 2009</xref>; <xref ref-type="bibr" rid="bib11">Bucur and Papagno, 2021</xref>; <xref ref-type="bibr" rid="bib70">Wang et al., 2010</xref>). In congenitally blind individuals, it encodes visual knowledge such as color and the activity strength is negatively modulated by perceptibility (<xref ref-type="bibr" rid="bib10">Bottini et al., 2020</xref>; <xref ref-type="bibr" rid="bib62">Striem-Amit et al., 2018</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2020</xref>). It is sensitive to semantic composition, such as in two-word phrases or sentences (<xref ref-type="bibr" rid="bib51">Pallier et al., 2011</xref>; <xref ref-type="bibr" rid="bib56">Pylkkänen, 2019</xref>). This region is functionally and structurally connected with other language-sensitive regions (<xref ref-type="bibr" rid="bib22">Fan et al., 2014</xref>; <xref ref-type="bibr" rid="bib27">Friederici et al., 2017</xref>; <xref ref-type="bibr" rid="bib57">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib52">Pascual et al., 2015</xref>; <xref ref-type="bibr" rid="bib72">Wang et al., 2019</xref>). Finally, a recent neurodevelopmental study shows that the early-life resting-state functional connectivity patterns of the left temporal pole significantly predict performances in tasks entailing semantic processes, not in tasks of phonological skills or rapid automatized naming, at about 6.5 years of age (<xref ref-type="bibr" rid="bib76">Yu et al., 2021</xref>). These lines of findings are often correlational evidence for the language effect on their own. Together with the positive evidence of early language experience in developing typical semantic representation in the dATL reported here, the parsimonious proposal accounting for them together would be that the dATL represents knowledge derived from language (e.g. from higher-order word relations). Without early language exposure, the semantic structure representation and the abstractness preference here are reduced.</p><p>Together, this package of findings extends beyond the majority of the neurocognitive semantic theories, which mainly focus on the representing, binding, and controlling of knowledge derived from nonlinguistic multisensory experiences (<xref ref-type="bibr" rid="bib7">Binder, 2016</xref>; <xref ref-type="bibr" rid="bib57">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Martin, 2016</xref>; but see <xref ref-type="bibr" rid="bib41">Mahon and Caramazza, 2008</xref>). The recently developed dual-neural-coding framework for semantic knowledge (<xref ref-type="bibr" rid="bib4">Bi, 2021</xref>), which explicitly proposes that the human brain has developed regions (the dATL) for language-derived semantic representations, in addition to the sensory-derived knowledge representations, naturally accommodates these observations. Language, as a symbolic system, allows us to convey and manipulate meanings free from sensorimotor experiences and plays a key role in knowledge transmission and accumulation across individuals and generations (<xref ref-type="bibr" rid="bib30">Gelman and Roberts, 2017</xref>). The existence of the language-derived knowledge neural system may lay the foundation for the efficient storage and manipulation of semantic knowledge, particularly abstract knowledge without tangible and consistent sensorimotor referents (<xref ref-type="bibr" rid="bib4">Bi, 2021</xref>).</p><p>The current results also have implications for the role of early language exposure in neurodevelopment more generally. Previous studies have reported that delayed L1 acquisition associates with reduced cortical volume in the left inferior frontal region, reduced cortical thickness in the left posterior middle temporal region, and the reduced fractional anisotropy values in the left arcuate fasciculus that structurally connects the two regions, and not ATL or its related white matter tracts (<xref ref-type="bibr" rid="bib16">Cheng et al., 2023</xref>; <xref ref-type="bibr" rid="bib14">Cheng et al., 2019</xref>). Our findings of semantic functional alterations in the dATL are thus not easily attributable to broad anatomical changes associated with late L1 acquisition. Notably, different from phonological and syntactic processes, where both visible behavioral underdevelopment (e.g. <xref ref-type="bibr" rid="bib12">Caselli et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Cheng and Mayberry, 2021</xref>; <xref ref-type="bibr" rid="bib45">Mayberry et al., 2002</xref>) and brain functional changes (<xref ref-type="bibr" rid="bib46">Mayberry et al., 2011</xref>; <xref ref-type="bibr" rid="bib60">Richardson et al., 2020</xref>; <xref ref-type="bibr" rid="bib67">Twomey et al., 2020</xref>) were observed, for semantics we only observed brain functional changes in the dATL but no visible behavioral effects. Consistent with the literature where deaf delayed signers did not show differences to controls in semantic interference effects in the picture-sign paradigm (<xref ref-type="bibr" rid="bib3">Baus et al., 2008</xref>), scalar implicature (<xref ref-type="bibr" rid="bib21">Davidson and Mayberry, 2015</xref>), or N400 measures (<xref ref-type="bibr" rid="bib61">Skotara et al., 2012</xref>), we did not observe visible differences in terms of semantic distance structures (<xref ref-type="fig" rid="fig1">Figure 1a</xref>) or reaction time of lexical decision and word-triplet semantic judgment (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). As reasoned in the Introduction, this seeming neuro-behavior discrepancy might be related to the multifaceted, distributed nature of the cognitive and neural basis of semantics more broadly. The general semantic behavioral tasks we employed could be achieved with representations derived from multiple types of experiences, supported by highly distributed neural systems (e.g. <xref ref-type="bibr" rid="bib4">Bi, 2021</xref>; <xref ref-type="bibr" rid="bib6">Binder and Desai, 2011</xref>; <xref ref-type="bibr" rid="bib57">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Martin, 2016</xref>), including those not affected by delayed L1 acquisition in regions beyond the dATL. This finding invites future studies to specify the exact developmental mechanisms in the left dATL (<xref ref-type="bibr" rid="bib28">Fu et al., 2023</xref>; <xref ref-type="bibr" rid="bib69">Unger and Fisher, 2021</xref>) and to uncover semantic behavioral consequences related to the functionality of this area.</p><p>To conclude, by manipulation of early language experience by nature we were able to positively identify a human brain region – dATL – robustly supporting word meanings derived from language experience, in contrast to those grounding nonlinguistic, sensory experiences. These findings highlight the role of language in forming specific neural semantic representations in the human brain, and raise new questions about the ontogenetic mechanisms of this intriguing neural structure.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Thirty-nine congenitally or early deaf adults and 33 hearing college students (15 males, mean age 21.97 ± 2.58 years, range: 18–28 years, all native Mandarin Chinese speakers) were recruited for the fMRI study. All except for one delayed deaf signer and one hearing participant participated in the behavioral semantic distance judgment task. The behavioral data of one delayed signer were excluded from data analysis due to technical errors. The behavioral and neural data of 21 out of the 33 hearing college students overlapped with a previous study (<xref ref-type="bibr" rid="bib74">Wang and Bi, 2021</xref>) that examined the intersubject variability of semantics in typically developed populations.</p><p>The deaf participants included two groups (<xref ref-type="table" rid="table1">Table 1</xref>). Native signers (n = 16; 11 males) had deaf parents and were exposed to CSL soon after birth. Delayed (nonnative) signers (n = 23; 12 males) were born in hearing families and learned CSL after they were enrolled in special education schools (range: 4–10 years of age). All deaf participants completed a background questionnaire, in which they reported their hearing loss conditions, history of language acquisition, and educational background. They were also asked to rate sign language abilities of their family members and to rate their own sign and lipreading abilities using a 7-point scale: 1 = none at all, 7 = very proficient. All deaf participants then finished the Chinese version of the ARHQ (a self-report screening tool for the risk of reading disability in adults, <xref ref-type="bibr" rid="bib37">Lefly and Pennington, 2000</xref>), the MacArthur Scale of subjective social status (<xref ref-type="bibr" rid="bib1">Adler et al., 2000</xref>) during childhood, and reported the educational years of their parents. For hearing loss conditions, all deaf participants reported being severely or profoundly deaf from birth, except for one native signer and three delayed signers who reported becoming deaf before the age of 2 due to medication side effects. Hearing thresholds in decibels (dB) were available in 23 deaf participants (native: 11/16; delayed: 12/23) and confirmed severe to profound hearing loss (range: 85–120 dB). One native signer and four delayed signers were using hearing aids at the time of testing; others either had never used hearing aids (six native signers and five delayed signers) or had used hearing aids for some time (nine native signers and fourteen delayed signers; years of use: 0.5–20 years). Speech comprehension was reported to be very poor, even with the use of hearing aids.</p><p>All participants had normal or corrected-to-normal vision. All participants were right-handed, except for three native signers (one was ambidextrous and two were left-handed) (measured by the Edinburgh inventory, <xref ref-type="bibr" rid="bib50">Oldfield, 1971</xref>). All participants gave written informed consent and received monetary compensation for participation. The study was approved by the Human Subject Review Committee at Peking University (2017-09-01), China, in accordance with the Declaration of Helsinki.</p></sec><sec id="s4-2"><title>Word stimuli in task fMRI</title><p>The stimuli for fMRI scanning were 90 written words, including 40 concrete/object words and 50 abstract/nonobject words without explicit external referents. Concrete/object words varied in sensory and motor attributes and included 10 animals (e.g. <italic>panda</italic>), 10 face or body parts (e.g. <italic>shoulder</italic>), 10 tools (e.g. <italic>hammer</italic>), and 10 common large household objects (e.g. <italic>microwave</italic>). Abstract/nonobject words varied in social and emotional associations (e.g. <italic>cause</italic>, <italic>violence</italic>). A 7-point familiarity rating, with 7 being the most familiar, was collected from 21 out of 39 deaf signers and an independent group of 26 hearing college students. All words were highly familiar to deaf participants (8 native signers: 6.72 ± 0.17; 13 delayed signers: 6.86 ± 0.15). All words were disyllabic except for five object words (‘cat’ and ‘bed’ are monosyllabic and ‘giraffe’, ‘microwave’, and ‘washing machine’ are trisyllabic in Chinese). All words were primarily used as nouns except for 10 words denoting emotional states (nine were primarily used as adjectives and one as a verb). The concrete and abstract words were matched on the number of strokes (a measure of visual complexity for Chinese words; 17.23 ± 5.80 vs 16.14 ± 3.98; <italic>t</italic><sub>88</sub> = 1.05, p = 0.30). While concrete/object words were less frequent in a Mandarin Chinese corpus (<xref ref-type="bibr" rid="bib63">Sun et al., 1997</xref>) than abstract/nonobject words (log word frequency: 1.05±0.73 vs 1.62 ± 0.68; <italic>t</italic><sub>88</sub> = –3.83, p &lt; 0.001), the former were rated as more subjectively familiar than the latter in either hearing (6.79 ± 0.16 vs 6.22 ± 0.26; <italic>t</italic><sub>88</sub> = 12.05, p &lt; 0.001) or deaf (6.85 ± 0.07 vs 6.77 ± 0.13; <italic>t</italic><sub>88</sub> = 3.41, p &lt; 0.001) participants.</p></sec><sec id="s4-3"><title>Behavioral semantic distance judgment task</title><p>To examine participants’ understanding of the 90 words used in the task fMRI, we asked them to judge semantic distance among these words by arranging them spatially close together or far apart in a circular arena on a computer screen via mouse drag-and-drop operations (<xref ref-type="bibr" rid="bib36">Kriegeskorte and Mur, 2012</xref>). The task lasted for 1 hr and produced a 90 × 90 semantic distance matrix for each participant. We correlated each deaf participant’s semantic RDM with the hearing group-averaged semantic RDM using Spearman’s rank correlation, Fisher-<italic>z</italic>-transformed the correlation coefficients, and compared the two deaf groups to assess the similarity between their semantic structures.</p><p>Considering the multidimensional and flexible nature of semantic distance among various concrete and abstract words (<xref ref-type="bibr" rid="bib8">Binder et al., 2016</xref>; <xref ref-type="bibr" rid="bib19">Conca et al., 2021</xref>), we focused on the categorical structure of 90 words to boost signal and to allow for better generalization across items (i.e. along the categorical structure). The categorical RDM was obtained by performing a k-means clustering analysis on the group-averaged 90 × 90 semantic RDM of hearing participants (the factoextra package, <ext-link ext-link-type="uri" xlink:href="http://www.sthda.com/english/rpkgs/factoextra">http://www.sthda.com/english/rpkgs/factoextra</ext-link>, RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_016692">SCR_016692</ext-link>; in the R programming environment, version 4.0.0; <xref ref-type="bibr" rid="bib59">R Development Core Team, 2020</xref>). The optimal number of clusters was determined based on gap statistic (<xref ref-type="bibr" rid="bib64">Tibshirani et al., 2001</xref>), which revealed 10 semantic categories (<xref ref-type="fig" rid="fig1">Figure 1a</xref>).</p></sec><sec id="s4-4"><title>Task fMRI procedure</title><p>In the MRI scanner, participants were instructed to look at each of the 90 target words, think about their meanings, and perform an oddball one-back semantic judgment task. In this oddball task, participants were asked to judge whether occasional words in red (catch trials) were semantically related to the previous word by pressing the corresponding buttons with the right index or middle finger.</p><p>Each participant performed 10 runs (360 s per run) of task fMRI scanning, except for one native signer who finished eight runs and withdrew due to discomfort. Each run consisted of 90 2.5-s-long target word trials and 14 2.5-s-long catch trials. Each trial started with a 0.8 s word stimulus (black color, SONG font, 2.6 visual degrees in height) at the center of a gray background, followed by 1.7 s fixation. Thirty 2.5-s-long null trials (fixation only) were randomly inserted among target and catch trials, with the interval between two words ranging from 1.7 to 11.7 s. Each target word appeared once in each run, and the order was pseudo-randomized for each run in each participant. Each run began with a 12 s fixation period and ended with a 13 s rest period during which participants received a written cue that the current run was about to end. Stimulus presentation was controlled by E-prime 2 (Psychology Software Tools, Inc, Pittsburgh, PA, USA). The 140 catch trials were created by first pairing each of the 90 target words with a probe word and then pseudo-randomly selecting 50 out of 90 target words (21 concrete/object words and 29 abstract/nonobject words) to pair with another 50 probe words. Participants performed this task attentively, with overall miss rates lower than 22.1% (median: 1.4%).</p></sec><sec id="s4-5"><title>Image acquisition</title><p>All functional and structural MRI data were collected using a Siemens Prisma 3T Scanner with a 64-channel head-neck coil at the Center for MRI Research, Peking University. Functional data were acquired with a simultaneous multi-slice echoplanar imaging sequence supplied by Siemens (62 axial slices, repetition time [TR]=2000 ms, echo time [TE]=30 ms, multi-band factor = 2, flip angle [FA]=90°, field of view [FOV]=224 mm × 224 mm, matrix size = 112 × 112, slice thickness = 2 mm, gap = 0.2 mm, and voxel size = 2 mm × 2 mm × 2.2 mm). A high-resolution 3D T1-weighted anatomical scan was acquired using the magnetization-prepared rapid acquisition gradient echo sequence (192 sagittal slices, TR = 2530 ms, TE = 2.98 ms, inversion time = 1100 ms, FA = 7°, FOV = 224 mm × 256 mm, matrix size = 224 × 256, interpolated to 448 × 512, slice thickness = 1 mm, and voxel size = 0.5 mm × 0.5 mm × 1 mm).</p></sec><sec id="s4-6"><title>Image preprocessing</title><p>Functional images were preprocessed using SPM12 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm12/">http://www.fil.ion.ucl.ac.uk/spm12/</ext-link>; RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_007037">SCR_007037</ext-link>). For each participant, the first four volumes of each functional run were discarded for signal equilibrium. The remaining images were corrected for slice timing and head motion and then spatially normalized to Montreal Neurological Institute (MNI) space via unified segmentation (resampling into 2 mm × 2 mm × 2 mm voxel size). All participants had head motion less than 1.97 mm/1.95°, except for one hearing participant showing excessive head motion in 2 runs (&gt;2 mm/2°); we thus analyzed the remaining 8 runs of fMRI data for this participant. We also estimated each participant’s framewise displacement (FD) from translations and rotations (<xref ref-type="bibr" rid="bib55">Power et al., 2012</xref>); the two deaf groups exhibited comparable FD during scanning (native: 0.12±0.04; delayed: 0.11±0.04; Welch’s <italic>t</italic><sub>29.1</sub> = 0.77, p = 0.45). Spatial smoothing was applied with a Gaussian kernel of 6 mm full width at half maximum (FWHM) for univariate analysis and 2 mm FWHM for RSA.</p></sec><sec id="s4-7"><title>ROI definition</title><p>A GLM was built to localize semantic abstractness in the brain, that is, brain regions showing stronger activations to abstract/nonobject words than to concrete/object words, in hearing participants. These regions were considered as candidates supporting knowledge derived from language. For spatially smoothed functional images, the GLM included three regressors (i.e. abstract/nonobject words, concrete/object words, and catch trials) for each run, each convolved with the canonical hemodynamic response function (HRF). The GLM also included six head motion parameters and a global mean predictor of each run. The high-pass filter was set at 128 s. The contrast (i.e. abstract &gt; concrete) was computed for each participant.</p><p>The beta-weight images of abstract &gt; concrete in hearing participants were submitted to one-sample <italic>t</italic>-tests. A conventional cluster-extent-based inference threshold (voxel-level p &lt; 0.001, cluster-level FWE-corrected p &lt; 0.05) was adopted and we stated explicitly when other thresholds were applied. At the conventional threshold, six clusters were found (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). As the largest cluster extended from the left dATL to the left IFG, we separated the dATL (808 voxels) and IFG (411 voxels) into two ROIs based on the automated anatomical labeling (AAL) atlas (<xref ref-type="bibr" rid="bib68">Tzourio-Mazoyer et al., 2002</xref>). To have the cluster sizes comparable across ROIs, we increased voxel-level threshold to p &lt; 0.0001 and obtained a smaller dATL cluster (488 voxels), based on which the ROI-level results were reported; the results were largely similar across different sizes of the dATL ROI.</p></sec><sec id="s4-8"><title>Representational similarity analysis</title><sec id="s4-8-1"><title>GLM</title><p>The preprocessed functional images were analyzed using a GLM to create a <italic>t</italic>-statistic image for each word (<xref ref-type="bibr" rid="bib35">Kriegeskorte et al., 2008</xref>). For each participant, a GLM was built with the concatenated time series across all the scanning runs, including 90 regressors corresponding to each word and one regressor for catch trials, convolved with a canonical HRF. Additionally, six head motion parameters and a global mean predictor were included for each run. A high-pass filter cutoff was set as 128 s. The resulting <italic>t</italic>-maps for each word versus baseline were used to create neural RDMs.</p></sec><sec id="s4-8-2"><title>ROI-level RSA</title><p>For each ROI in each participant, we extracted the activity patterns to each word from its whole-brain <italic>t</italic>-statistic images and calculated a neural 90 × 90 RDM based on the Pearson distance between activation patterns for each pair of words. Semantic information encoded in this ROI was quantified by computing Spearman’s rank correlation between the neural RDM and the 10-category benchmark semantic RDM. Partial correlations were used to control for two stimulus low-level property RDMs: (1) The low-level visual similarity RDM was computed by Pearson’s correlation distance between the binary silhouette images of each word pair. (2) The word phonological RDM: Despite that our task did not require explicit phonological retrieval, there might be automatic phonological activation. We thus constructed the phonological RDM by calculating one minus the proportion of shared sub-syllabic units (onsets or rhyme) between each word pair. The resulting correlation coefficients between neural and semantic RDMs were Fisher-<italic>z</italic>-transformed and compared with zero using one-sample <italic>t</italic>-tests (one-tailed) to test whether the ROI significantly encoded the semantic structure. Group differences in semantic encoding were assessed using two-tailed Welch’s <italic>t</italic>-tests for each ROI.</p></sec><sec id="s4-8-3"><title>Whole-brain searchlight RSA</title><p>To explore the potential differences between native and delayed signers in the neural semantic representations beyond the semantic ROIs identified above, we carried out whole-brain searchlight RSA. For each voxel in the AAL mask, we extracted the multivoxel activity patterns of 90 words within a sphere (radius = 8 mm) centered at that voxel. A neural 90 × 90 RDM was computed based on Pearson distance and was correlated with the semantic benchmark RDM while controlling for the two low-level RDMs of visual and phonological similarity of word stimuli, which produced a correlation coefficient for this voxel. By moving the searchlight center through the AAL mask, we obtained a correlation map for each participant. This map was Fisher-<italic>z</italic>-transformed and then spatially smoothed using a 6 mm FWHM Gaussian kernel. The correlation maps of native and delayed groups were then compared using a two-sample <italic>t</italic>-test.</p></sec></sec><sec id="s4-9"><title>Univariate semantic abstractness analysis</title><sec id="s4-9-1"><title>GLM</title><p>The neural semantic abstractness effects were computed using the same GLMs in the ‘ROI definition’ section. For each deaf participant, we computed the following three contrasts for ROI and whole-brain group comparisons using all the runs: abstract &gt; concrete, abstract words &gt; baseline, concrete words &gt; baseline.</p></sec><sec id="s4-9-2"><title>ROI analysis</title><p>For each ROI, we extracted the averaged beta values of abstract words &gt; baseline and concrete words &gt; baseline, from each deaf participant, and compared these beta values of the two word types using one-tailed paired <italic>t</italic>-tests to test for the semantic abstractness effects in each deaf group. Two-way ANOVA was then adopted to examine group effects, with word type (concrete/object, abstract/nonobject) as a within-subject factor and group (native, delayed) as a between-subject factor.</p></sec><sec id="s4-9-3"><title>fROI analysis</title><p>We also carried out individualized fROI analyses (<xref ref-type="bibr" rid="bib18">Cohen et al., 2019</xref>; <xref ref-type="bibr" rid="bib58">Ratan Murty et al., 2020</xref>), which examined semantic selectivity in individually defined functional voxels, with the fROI localization and selectivity calculation using independent datasets. Specifically, we estimated each deaf participant’s whole-brain beta and <italic>t</italic> maps for the contrast between abstract/nonobject and concrete/object words in odd and even runs. The semantic ROIs defined above in hearing participants were taken as anatomical constraints. In each hearing-group-ROI, for each deaf participant, we localized his/her top 50 selective voxels (i.e. voxels with the highest <italic>t</italic> values to the contrast) in the odd runs, extracted the mean beta values of these voxels to abstract and concrete words, respectively, in the even runs. This procedure was repeated with fROI defined in the even runs and beta values calculated in the odd runs. The beta values were averaged across two iterations for each ROI in each participant and compared between the two deaf groups using the abovementioned statistical analyses. We also repeated the fROI analyses at the fROI size of 100 voxels and obtained very similar results.</p></sec><sec id="s4-9-4"><title>Whole-brain analysis</title><p>The whole-brain semantic abstractness effects were examined by one-sample <italic>t</italic>-tests on the whole-brain beta-weight images of abstract &gt; concrete in each group. For the whole-brain group comparison of the semantic abstractness effects, the abstract &gt; concrete beta-weight maps of the two deaf groups were submitted to a two-sample <italic>t</italic>-test.</p></sec></sec><sec id="s4-10"><title>Brain visualization</title><p>The brain results were projected onto the MNI brain surface for visualization using BrainNet Viewer (version 1.7; <ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/projects/bnv/">https://www.nitrc.org/projects/bnv/</ext-link>; RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_009446">SCR_009446</ext-link>; <xref ref-type="bibr" rid="bib75">Xia et al., 2013</xref>) with the default ‘interpolated’ mapping algorithm, unless stated explicitly otherwise. Regional labels were derived based on the AAL template in xjview (by Xu Cui, <ext-link ext-link-type="uri" xlink:href="http://www.alivelearn.net/xjview/">http://www.alivelearn.net/xjview/</ext-link>; RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_008642">SCR_008642</ext-link>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Senior Editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Methodology, Project administration</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants gave written informed consent and received monetary compensation for participation. The study was approved by the Human Subject Review Committee at Peking University (2017-09-01), China, in accordance with the Declaration of Helsinki.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-81681-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Source data files have been provided for Table 1 and all the figures. Additional behavioral and neural data have been made available on OSF at the link <ext-link ext-link-type="uri" xlink:href="https://osf.io/wz6q9/">https://osf.io/wz6q9/</ext-link>. The whole-brain unthresholded statistical maps have also been made available on NeuroVault at the link <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/13705/">https://neurovault.org/collections/13705/</ext-link>. Deidentified Nifti files are not shared openly because of ethics constraints, but are available from the corresponding authors upon reasonable request.</p><p>The following datasets were generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Early language exposure affects neural mechanisms of semantic representations</data-title><source>Open Science Framework</source><pub-id pub-id-type="doi">10.17605/OSF.IO/WZ6Q9</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset2"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Early language exposure affects neural mechanisms of semantic representations</data-title><source>NeuroVault</source><pub-id pub-id-type="accession" xlink:href="https://neurovault.org/collections/13705/">13705</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Dr. Xi Yu for helpful discussions on earlier drafts of the manuscript. We thank Ms. Yun Hao, Anran Deng, and Wei Liang for their assistance in data collection. This work was supported by STI2030-Major Project 2021ZD0204100 (2021ZD0204104), the National Natural Science Foundation of China (31925020 and 82021004 to YB, 32171052 and 31700943 to XW), and Changjiang Scholar Professorship Award (T2016031 to YB). The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adler</surname><given-names>NE</given-names></name><name><surname>Epel</surname><given-names>ES</given-names></name><name><surname>Castellazzo</surname><given-names>G</given-names></name><name><surname>Ickovics</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Relationship of subjective and objective social status with psychological and physiological functioning: preliminary data in healthy white women</article-title><source>Health Psychology</source><volume>19</volume><fpage>586</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1037//0278-6133.19.6.586</pub-id><pub-id pub-id-type="pmid">11129362</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barsalou</surname><given-names>LW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>On staying grounded and avoiding quixotic dead ends</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>1122</fpage><lpage>1142</lpage><pub-id pub-id-type="doi">10.3758/s13423-016-1028-3</pub-id><pub-id pub-id-type="pmid">27112560</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baus</surname><given-names>C</given-names></name><name><surname>Gutiérrez-Sigut</surname><given-names>E</given-names></name><name><surname>Quer</surname><given-names>J</given-names></name><name><surname>Carreiras</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Lexical access in Catalan signed language (Lsc) production</article-title><source>Cognition</source><volume>108</volume><fpage>856</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2008.05.012</pub-id><pub-id pub-id-type="pmid">18656181</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dual coding of knowledge in the human brain</article-title><source>Trends in Cognitive Sciences</source><volume>25</volume><fpage>883</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2021.07.006</pub-id><pub-id pub-id-type="pmid">34509366</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name><name><surname>Graves</surname><given-names>WW</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>2767</fpage><lpage>2796</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp055</pub-id><pub-id pub-id-type="pmid">19329570</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neurobiology of semantic memory</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>527</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.10.001</pub-id><pub-id pub-id-type="pmid">22001867</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>In defense of abstract conceptual representations</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>1096</fpage><lpage>1108</lpage><pub-id pub-id-type="doi">10.3758/s13423-015-0909-1</pub-id><pub-id pub-id-type="pmid">27294428</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name><name><surname>Humphries</surname><given-names>CJ</given-names></name><name><surname>Fernandino</surname><given-names>L</given-names></name><name><surname>Simons</surname><given-names>SB</given-names></name><name><surname>Aguilar</surname><given-names>M</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Toward a brain-based componential semantic representation</article-title><source>Cognitive Neuropsychology</source><volume>33</volume><fpage>130</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1080/02643294.2016.1147426</pub-id><pub-id pub-id-type="pmid">27310469</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogliotti</surname><given-names>C</given-names></name><name><surname>Aksen</surname><given-names>H</given-names></name><name><surname>Isel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Language experience in LSF development: behavioral evidence from a sentence repetition task</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0236729</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0236729</pub-id><pub-id pub-id-type="pmid">33201887</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bottini</surname><given-names>R</given-names></name><name><surname>Ferraro</surname><given-names>S</given-names></name><name><surname>Nigri</surname><given-names>A</given-names></name><name><surname>Cuccarini</surname><given-names>V</given-names></name><name><surname>Bruzzone</surname><given-names>MG</given-names></name><name><surname>Collignon</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain regions involved in conceptual retrieval in sighted and blind people</article-title><source>Journal of Cognitive Neuroscience</source><volume>32</volume><fpage>1009</fpage><lpage>1025</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01538</pub-id><pub-id pub-id-type="pmid">32013684</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bucur</surname><given-names>M</given-names></name><name><surname>Papagno</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>An ale meta-analytical review of the neural correlates of Abstract and concrete words</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>15727</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-94506-9</pub-id><pub-id pub-id-type="pmid">34344915</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caselli</surname><given-names>NK</given-names></name><name><surname>Emmorey</surname><given-names>K</given-names></name><name><surname>Cohen-Goldberg</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The signed mental lexicon: effects of phonological neighborhood density, iconicity, and childhood language experience</article-title><source>Journal of Memory and Language</source><volume>121</volume><elocation-id>104282</elocation-id><pub-id pub-id-type="doi">10.1016/j.jml.2021.104282</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Catricalà</surname><given-names>E</given-names></name><name><surname>Della Rosa</surname><given-names>PA</given-names></name><name><surname>Plebani</surname><given-names>V</given-names></name><name><surname>Vigliocco</surname><given-names>G</given-names></name><name><surname>Cappa</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Abstract and concrete categories? Evidences from neurodegenerative diseases</article-title><source>Neuropsychologia</source><volume>64</volume><fpage>271</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.09.041</pub-id><pub-id pub-id-type="pmid">25281886</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>Q</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Mayberry</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Effects of early language deprivation on brain connectivity: language pathways in deaf native and late first-language learners of American sign language</article-title><source>Frontiers in Human Neuroscience</source><volume>13</volume><elocation-id>320</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2019.00320</pub-id><pub-id pub-id-type="pmid">31607879</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>Q</given-names></name><name><surname>Mayberry</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>When event knowledge overrides word order in sentence comprehension: learning a first language after childhood</article-title><source>Developmental Science</source><volume>24</volume><elocation-id>e13073</elocation-id><pub-id pub-id-type="doi">10.1111/desc.13073</pub-id><pub-id pub-id-type="pmid">33296520</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>Q</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Klein</surname><given-names>D</given-names></name><name><surname>Chen</surname><given-names>JK</given-names></name><name><surname>Mayberry</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Restricted language access during childhood affects adult brain structure in selective language regions</article-title><source>PNAS</source><volume>120</volume><elocation-id>e2215423120</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2215423120</pub-id><pub-id pub-id-type="pmid">36745780</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choubsaz</surname><given-names>Y</given-names></name><name><surname>Gheitury</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Is semantics affected by missing a critical period? Evidence from the Persian deaf</article-title><source>Journal of Psycholinguistic Research</source><volume>46</volume><fpage>77</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1007/s10936-016-9421-7</pub-id><pub-id pub-id-type="pmid">27007472</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MA</given-names></name><name><surname>Dilks</surname><given-names>DD</given-names></name><name><surname>Koldewyn</surname><given-names>K</given-names></name><name><surname>Weigelt</surname><given-names>S</given-names></name><name><surname>Feather</surname><given-names>J</given-names></name><name><surname>Kell</surname><given-names>AJ</given-names></name><name><surname>Keil</surname><given-names>B</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Wald</surname><given-names>L</given-names></name><name><surname>Saxe</surname><given-names>R</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Representational similarity precedes category selectivity in the developing ventral visual pathway</article-title><source>NeuroImage</source><volume>197</volume><fpage>565</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.05.010</pub-id><pub-id pub-id-type="pmid">31077844</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conca</surname><given-names>F</given-names></name><name><surname>Borsa</surname><given-names>VM</given-names></name><name><surname>Cappa</surname><given-names>SF</given-names></name><name><surname>Catricalà</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The multidimensionality of abstract concepts: a systematic review</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>127</volume><fpage>474</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2021.05.004</pub-id><pub-id pub-id-type="pmid">33979574</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Curtiss</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1977">1977</year><source>Genie: A Psycholinguistic Study of A Modern-Day Wild Child</source><publisher-loc>New York</publisher-loc><publisher-name>Academic press</publisher-name></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>K</given-names></name><name><surname>Mayberry</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Do adults show an effect of delayed first language acquisition when calculating scalar implicatures?</article-title><source>Language Acquisition</source><volume>22</volume><fpage>329</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1080/10489223.2014.962140</pub-id><pub-id pub-id-type="pmid">26997850</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Han</surname><given-names>W</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name><name><surname>Jiang</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Connectivity-based parcellation of the human temporal pole using diffusion tensor imaging</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>3365</fpage><lpage>3378</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht196</pub-id><pub-id pub-id-type="pmid">23926116</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Hsieh</surname><given-names>PJ</given-names></name><name><surname>Nieto-Castañón</surname><given-names>A</given-names></name><name><surname>Whitfield-Gabrieli</surname><given-names>S</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>New method for fMRI investigations of language: defining rois functionally in individual subjects</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>1177</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1152/jn.00032.2010</pub-id><pub-id pub-id-type="pmid">20410363</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferjan Ramirez</surname><given-names>N</given-names></name><name><surname>Leonard</surname><given-names>MK</given-names></name><name><surname>Torres</surname><given-names>C</given-names></name><name><surname>Hatrak</surname><given-names>M</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Mayberry</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural language processing in adolescent first-language learners</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>2772</fpage><lpage>2783</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht137</pub-id><pub-id pub-id-type="pmid">23696277</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferjan Ramirez</surname><given-names>N</given-names></name><name><surname>Leonard</surname><given-names>MK</given-names></name><name><surname>Davenport</surname><given-names>TS</given-names></name><name><surname>Torres</surname><given-names>C</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Mayberry</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural language processing in adolescent first-language learners: longitudinal case studies in American sign language</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>1015</fpage><lpage>1026</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu273</pub-id><pub-id pub-id-type="pmid">25410427</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandino</surname><given-names>L</given-names></name><name><surname>Tong</surname><given-names>JQ</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name><name><surname>Humphries</surname><given-names>CJ</given-names></name><name><surname>Binder</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Decoding the information structure underlying the neural representation of concepts</article-title><source>PNAS</source><volume>119</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1073/pnas.2108091119</pub-id><pub-id pub-id-type="pmid">35115397</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friederici</surname><given-names>AD</given-names></name><name><surname>Chomsky</surname><given-names>N</given-names></name><name><surname>Berwick</surname><given-names>RC</given-names></name><name><surname>Moro</surname><given-names>A</given-names></name><name><surname>Bolhuis</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Language, mind and brain</article-title><source>Nature Human Behaviour</source><volume>1</volume><fpage>713</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1038/s41562-017-0184-4</pub-id><pub-id pub-id-type="pmid">31024099</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Wei</surname><given-names>T</given-names></name><name><surname>Liao</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Different computational relations in language are captured by distinct brain systems</article-title><source>Cerebral Cortex</source><volume>33</volume><fpage>997</fpage><lpage>1013</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhac117</pub-id><pub-id pub-id-type="pmid">35332914</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Gaetano</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Signal detection theory calculator 1.2</article-title><ext-link ext-link-type="uri" xlink:href="https://www.researchgate.net/profile/Justin_Gaetano2">https://www.researchgate.net/profile/Justin_Gaetano2</ext-link><date-in-citation iso-8601-date="2021-12-23">December 23, 2021</date-in-citation></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>SA</given-names></name><name><surname>Roberts</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>How language shapes the cultural inheritance of categories</article-title><source>PNAS</source><volume>114</volume><fpage>7900</fpage><lpage>7907</lpage><pub-id pub-id-type="doi">10.1073/pnas.1621073114</pub-id><pub-id pub-id-type="pmid">28739931</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldin-Meadow</surname><given-names>S</given-names></name><name><surname>Feldman</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>The development of language-like communication without a language model</article-title><source>Science</source><volume>197</volume><fpage>401</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1126/science.877567</pub-id><pub-id pub-id-type="pmid">877567</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goldin-Meadow</surname><given-names>S.</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>The Resilience of Language: What gesture creation in deaf children can tell us about how all children learn language</source><publisher-loc>New York</publisher-loc><publisher-name>Psychology Press</publisher-name></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldin-Meadow</surname><given-names>S</given-names></name><name><surname>Gelman</surname><given-names>SA</given-names></name><name><surname>Mylander</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Expressing generic concepts with and without a language model</article-title><source>Cognition</source><volume>96</volume><fpage>109</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2004.07.003</pub-id><pub-id pub-id-type="pmid">15925572</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Bandettini</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Information-based functional brain mapping</article-title><source>PNAS</source><volume>103</volume><fpage>3863</fpage><lpage>3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.0600244103</pub-id><pub-id pub-id-type="pmid">16537458</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Mur</surname><given-names>M</given-names></name><name><surname>Bandettini</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis-connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Mur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Inverse MDS: inferring dissimilarity structure from multiple item arrangements</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>245</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00245</pub-id><pub-id pub-id-type="pmid">22848204</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lefly</surname><given-names>DL</given-names></name><name><surname>Pennington</surname><given-names>BF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Reliability and validity of the adult reading history questionnaire</article-title><source>Journal of Learning Disabilities</source><volume>33</volume><fpage>286</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1177/002221940003300306</pub-id><pub-id pub-id-type="pmid">15505966</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lenneberg</surname><given-names>EH</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>The biological foundations of language</article-title><source>Hospital Practice</source><volume>2</volume><fpage>59</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1080/21548331.1967.11707799</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lieberman</surname><given-names>AM</given-names></name><name><surname>Borovsky</surname><given-names>A</given-names></name><name><surname>Hatrak</surname><given-names>M</given-names></name><name><surname>Mayberry</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Real-time processing of ASL signs: delayed first language acquisition affects organization of the mental lexicon</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>41</volume><fpage>1130</fpage><lpage>1139</lpage><pub-id pub-id-type="doi">10.1037/xlm0000088</pub-id><pub-id pub-id-type="pmid">25528091</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillo-Martin</surname><given-names>D</given-names></name><name><surname>Henner</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Acquisition of sign languages</article-title><source>Annual Review of Linguistics</source><volume>7</volume><fpage>395</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.1146/annurev-linguistics-043020-092357</pub-id><pub-id pub-id-type="pmid">34746335</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahon</surname><given-names>BZ</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A critical look at the embodied cognition hypothesis and a new proposal for grounding conceptual content</article-title><source>Journal of Physiology, Paris</source><volume>102</volume><fpage>59</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2008.03.004</pub-id><pub-id pub-id-type="pmid">18448316</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshall</surname><given-names>C</given-names></name><name><surname>Jones</surname><given-names>A</given-names></name><name><surname>Denmark</surname><given-names>T</given-names></name><name><surname>Mason</surname><given-names>K</given-names></name><name><surname>Atkinson</surname><given-names>J</given-names></name><name><surname>Botting</surname><given-names>N</given-names></name><name><surname>Morgan</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deaf children’s non-verbal working memory is impacted by their language experience</article-title><source>Frontiers in Psychology</source><volume>6</volume><elocation-id>527</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2015.00527</pub-id><pub-id pub-id-type="pmid">25999875</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>GRAPES-grounding representations in action, perception, and emotion systems: how object properties and categories are represented in the human brain</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>979</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.3758/s13423-015-0842-3</pub-id><pub-id pub-id-type="pmid">25968087</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayberry</surname><given-names>RI</given-names></name><name><surname>Fischer</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Looking through phonological shape to lexical meaning: the bottleneck of non-native sign language processing</article-title><source>Memory &amp; Cognition</source><volume>17</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.3758/bf03202635</pub-id><pub-id pub-id-type="pmid">2811671</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayberry</surname><given-names>RI</given-names></name><name><surname>Lock</surname><given-names>E</given-names></name><name><surname>Kazmi</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Linguistic ability and early language exposure</article-title><source>Nature</source><volume>417</volume><elocation-id>38</elocation-id><pub-id pub-id-type="doi">10.1038/417038a</pub-id><pub-id pub-id-type="pmid">11986658</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayberry</surname><given-names>RI</given-names></name><name><surname>Chen</surname><given-names>JK</given-names></name><name><surname>Witcher</surname><given-names>P</given-names></name><name><surname>Klein</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Age of acquisition effects on the functional organization of language in the adult brain</article-title><source>Brain and Language</source><volume>119</volume><fpage>16</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2011.05.007</pub-id><pub-id pub-id-type="pmid">21705060</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayberry</surname><given-names>RI</given-names></name><name><surname>Davenport</surname><given-names>T</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neurolinguistic processing when the brain matures without language</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>99</volume><fpage>390</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2017.12.011</pub-id><pub-id pub-id-type="pmid">29406150</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayberry</surname><given-names>RI</given-names></name><name><surname>Kluender</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Rethinking the critical period for language: new insights into an old question from American sign language</article-title><source>Bilingualism</source><volume>21</volume><fpage>938</fpage><lpage>944</lpage><pub-id pub-id-type="doi">10.1017/S1366728918000585</pub-id><pub-id pub-id-type="pmid">31662701</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Maturational constraints on language development</article-title><source>Cognitive Science</source><volume>14</volume><fpage>11</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog1401_2</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldfield</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>The assessment and analysis of handedness: the Edinburgh inventory</article-title><source>Neuropsychologia</source><volume>9</volume><fpage>97</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(71)90067-4</pub-id><pub-id pub-id-type="pmid">5146491</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pallier</surname><given-names>C</given-names></name><name><surname>Devauchelle</surname><given-names>AD</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical representation of the constituent structure of sentences</article-title><source>PNAS</source><volume>108</volume><fpage>2522</fpage><lpage>2527</lpage><pub-id pub-id-type="doi">10.1073/pnas.1018711108</pub-id><pub-id pub-id-type="pmid">21224415</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascual</surname><given-names>B</given-names></name><name><surname>Masdeu</surname><given-names>JC</given-names></name><name><surname>Hollenbeck</surname><given-names>M</given-names></name><name><surname>Makris</surname><given-names>N</given-names></name><name><surname>Insausti</surname><given-names>R</given-names></name><name><surname>Ding</surname><given-names>SL</given-names></name><name><surname>Dickerson</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Large-scale brain networks of the human left temporal pole: a functional connectivity MRI study</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>680</fpage><lpage>702</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht260</pub-id><pub-id pub-id-type="pmid">24068551</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Nestor</surname><given-names>PJ</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Where do you know what you know? The representation of semantic knowledge in the human brain</article-title><source>Nature Reviews. Neuroscience</source><volume>8</volume><fpage>976</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1038/nrn2277</pub-id><pub-id pub-id-type="pmid">18026167</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perszyk</surname><given-names>DR</given-names></name><name><surname>Waxman</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Linking language and cognition in infancy</article-title><source>Annual Review of Psychology</source><volume>69</volume><fpage>231</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-122216-011701</pub-id><pub-id pub-id-type="pmid">28877000</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Barnes</surname><given-names>KA</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion</article-title><source>NeuroImage</source><volume>59</volume><fpage>2142</fpage><lpage>2154</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.018</pub-id><pub-id pub-id-type="pmid">22019881</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pylkkänen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The neural basis of combinatory SYNTAX and semantics</article-title><source>Science</source><volume>366</volume><fpage>62</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1126/science.aax0050</pub-id><pub-id pub-id-type="pmid">31604303</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ralph</surname><given-names>MAL</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The neural and computational bases of semantic cognition</article-title><source>Nature Reviews. Neuroscience</source><volume>18</volume><fpage>42</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.150</pub-id><pub-id pub-id-type="pmid">27881854</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratan Murty</surname><given-names>NA</given-names></name><name><surname>Teng</surname><given-names>S</given-names></name><name><surname>Beeler</surname><given-names>D</given-names></name><name><surname>Mynick</surname><given-names>A</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Visual experience is not necessary for the development of face-selectivity in the lateral fusiform gyrus</article-title><source>PNAS</source><volume>117</volume><fpage>23011</fpage><lpage>23020</lpage><pub-id pub-id-type="doi">10.1073/pnas.2004607117</pub-id><pub-id pub-id-type="pmid">32839334</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="software"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group><year iso-8601-date="2020">2020</year><data-title>R: A language and environment for statistical computing</data-title><version designator="4.0.0">4.0.0</version><publisher-name>R Foundation for Statistical Computing</publisher-name><publisher-loc>Vienna, Austria</publisher-loc><ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/">https://www.r-project.org/</ext-link></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>H</given-names></name><name><surname>Koster-Hale</surname><given-names>J</given-names></name><name><surname>Caselli</surname><given-names>N</given-names></name><name><surname>Magid</surname><given-names>R</given-names></name><name><surname>Benedict</surname><given-names>R</given-names></name><name><surname>Olson</surname><given-names>H</given-names></name><name><surname>Pyers</surname><given-names>J</given-names></name><name><surname>Saxe</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Reduced neural selectivity for mental states in deaf children with delayed exposure to sign language</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3246</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17004-y</pub-id><pub-id pub-id-type="pmid">32591503</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skotara</surname><given-names>N</given-names></name><name><surname>Salden</surname><given-names>U</given-names></name><name><surname>Kügow</surname><given-names>M</given-names></name><name><surname>Hänel-Faulhaber</surname><given-names>B</given-names></name><name><surname>Röder</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The influence of language deprivation in early childhood on L2 processing: an Erp comparison of deaf native signers and deaf signers with a delayed language acquisition</article-title><source>BMC Neuroscience</source><volume>13</volume><elocation-id>44</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2202-13-44</pub-id><pub-id pub-id-type="pmid">22554360</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Striem-Amit</surname><given-names>E</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural representation of visual concepts in people born blind</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>5250</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-07574-3</pub-id><pub-id pub-id-type="pmid">30531889</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Sun</surname><given-names>D</given-names></name><name><surname>Li</surname><given-names>D</given-names></name><name><surname>Xing</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1997">1997</year><chapter-title>Introduction to language corpus system of modern Chinese study</chapter-title><person-group person-group-type="editor"><name><surname>Hu</surname><given-names>MY</given-names></name></person-group><source>Paper Collection for the Fifth World Chinese Teaching Symposium</source><publisher-loc>Beijing</publisher-loc><publisher-name>Peking University Publishers</publisher-name><fpage>459</fpage><lpage>466</lpage></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Walther</surname><given-names>G</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Estimating the number of clusters in a data set via the gap statistic</article-title><source>Journal of the Royal Statistical Society Series B</source><volume>63</volume><fpage>411</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1111/1467-9868.00293</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomaszewski</surname><given-names>P</given-names></name><name><surname>Krzysztofiak</surname><given-names>P</given-names></name><name><surname>Morford</surname><given-names>JP</given-names></name><name><surname>Eźlakowski</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Effects of age-of-acquisition on proficiency in Polish sign language: insights to the critical period hypothesis</article-title><source>Frontiers in Psychology</source><volume>13</volume><elocation-id>896339</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2022.896339</pub-id><pub-id pub-id-type="pmid">35693522</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Troche</surname><given-names>J</given-names></name><name><surname>Crutch</surname><given-names>S</given-names></name><name><surname>Reilly</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Clustering, hierarchical organization, and the topography of abstract and concrete nouns</article-title><source>Frontiers in Psychology</source><volume>5</volume><elocation-id>360</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00360</pub-id><pub-id pub-id-type="pmid">24808876</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Twomey</surname><given-names>T</given-names></name><name><surname>Price</surname><given-names>CJ</given-names></name><name><surname>Waters</surname><given-names>D</given-names></name><name><surname>MacSweeney</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The impact of early language exposure on the neural system supporting language in deaf and hearing adults</article-title><source>NeuroImage</source><volume>209</volume><elocation-id>116411</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116411</pub-id><pub-id pub-id-type="pmid">31857205</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N</given-names></name><name><surname>Landeau</surname><given-names>B</given-names></name><name><surname>Papathanassiou</surname><given-names>D</given-names></name><name><surname>Crivello</surname><given-names>F</given-names></name><name><surname>Etard</surname><given-names>O</given-names></name><name><surname>Delcroix</surname><given-names>N</given-names></name><name><surname>Mazoyer</surname><given-names>B</given-names></name><name><surname>Joliot</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title><source>NeuroImage</source><volume>15</volume><fpage>273</fpage><lpage>289</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id><pub-id pub-id-type="pmid">11771995</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unger</surname><given-names>L</given-names></name><name><surname>Fisher</surname><given-names>AV</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The emergence of richly organized semantic knowledge from simple statistics: a synthetic review</article-title><source>Developmental Review</source><volume>60</volume><elocation-id>100949</elocation-id><pub-id pub-id-type="doi">10.1016/j.dr.2021.100949</pub-id><pub-id pub-id-type="pmid">33840880</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Conder</surname><given-names>JA</given-names></name><name><surname>Blitzer</surname><given-names>DN</given-names></name><name><surname>Shinkareva</surname><given-names>SV</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neural representation of abstract and concrete concepts: a meta-analysis of neuroimaging studies</article-title><source>Human Brain Mapping</source><volume>31</volume><fpage>1459</fpage><lpage>1468</lpage><pub-id pub-id-type="doi">10.1002/hbm.20950</pub-id><pub-id pub-id-type="pmid">20108224</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wu</surname><given-names>W</given-names></name><name><surname>Ling</surname><given-names>Z</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Men</surname><given-names>W</given-names></name><name><surname>Gao</surname><given-names>JH</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Organizational principles of abstract words in the human brain</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>4305</fpage><lpage>4318</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx283</pub-id><pub-id pub-id-type="pmid">29186345</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Close yet independent: dissociation of social from valence and abstract semantic dimensions in the left anterior temporal lobe</article-title><source>Human Brain Mapping</source><volume>40</volume><fpage>4759</fpage><lpage>4776</lpage><pub-id pub-id-type="doi">10.1002/hbm.24735</pub-id><pub-id pub-id-type="pmid">31379052</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Men</surname><given-names>W</given-names></name><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Two forms of knowledge representations in the human brain</article-title><source>Neuron</source><volume>107</volume><fpage>383</fpage><lpage>393</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.04.010</pub-id><pub-id pub-id-type="pmid">32386524</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Idiosyncratic tower of Babel: individual differences in word-meaning representation increase as word abstractness increases</article-title><source>Psychological Science</source><volume>32</volume><fpage>1617</fpage><lpage>1635</lpage><pub-id pub-id-type="doi">10.1177/09567976211003877</pub-id><pub-id pub-id-type="pmid">34546824</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>He</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>BrainNet viewer: a network visualization tool for human brain connectomics</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e68910</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0068910</pub-id><pub-id pub-id-type="pmid">23861951</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Ferradal</surname><given-names>SL</given-names></name><name><surname>Sliva</surname><given-names>DD</given-names></name><name><surname>Dunstan</surname><given-names>J</given-names></name><name><surname>Carruthers</surname><given-names>C</given-names></name><name><surname>Sanfilippo</surname><given-names>J</given-names></name><name><surname>Zuk</surname><given-names>J</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Boyd</surname><given-names>E</given-names></name><name><surname>Gagoski</surname><given-names>B</given-names></name><name><surname>Ou</surname><given-names>Y</given-names></name><name><surname>Grant</surname><given-names>PE</given-names></name><name><surname>Gaab</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Functional connectivity in infancy and Toddlerhood predicts long-term language and Preliteracy outcomes</article-title><source>Cerebral Cortex</source><volume>4</volume><elocation-id>bhab230</elocation-id><pub-id pub-id-type="doi">10.1093/cercor/bhab230</pub-id><pub-id pub-id-type="pmid">34347052</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81681.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peelle</surname><given-names>Jonathan Erik</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04t5xt781</institution-id><institution>Northeastern University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.11.06.515336" link-type="continued-by" xlink:href="https://sciety.org/articles/10.1101/2022.11.06.515336"/></front-stub><body><p>This study provides important evidence regarding the development of concept representations, using functional brain imaging to compare concept structure in people with different amounts of language experience. The analyses, which are overall solid, suggest that concept representations differ as a function of childhood language experience.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81681.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peelle</surname><given-names>Jonathan Erik</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04t5xt781</institution-id><institution>Northeastern University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Reilly</surname><given-names>Jamie</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00kx1jb78</institution-id><institution>Temple University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Fairhall</surname><given-names>Scott Laurence</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05trd4x28</institution-id><institution>University of Trento</institution></institution-wrap><country>Italy</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/10.1101/2022.11.06.515336">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.11.06.515336v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Early-life language deprivation affects specific neural mechanisms of semantic representations&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Floris de Lange as the Senior Editor. The following individuals involved in the review of your submission have agreed to reveal their identity: Jamie Reilly (Reviewer #2); Scott Laurence Fairhall (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Expanding on the discussion of critical periods for language development, particularly with respect to lexical-semantic and semantic acquisition (as opposed to phonology and syntax).</p><p>2) Explicitly evaluating whether the dATL differs in pattern from other ROIs, which would be necessary to say strongly that the dATL is &quot;specifically&quot; or &quot;uniquely&quot; sensitive.</p><p>3) Addressing what seems to be a mismatch between the behavioral results (no group differences) and brain results (significant group differences).</p><p>4) Before resubmitting please revisit the language regarding the language-deprived group carefully to ensure the logic is clear and not stigmatizing. There was some disagreement among reviewers during a discussion over this issue so I just ask you to ensure the issue is handled thoughtfully.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>– Please share the deidentified Nifti files on OpenNeuro, or if this is not permitted by ethics constraints, include the reason in the manuscript.</p><p>– Please consider sharing results maps on NeuroVault rather than OSF to aid discoverability (and NeuroVault comes with a viewer that facilitates viewing unthresholded maps).</p><p>– Many of the paragraphs are quite long (spanning a page or more). I would suggest considering breaking some of these into smaller paragraphs, with informative topic sentences, to enhance readability.</p><p>– Without cytoarchitectonic information, including the Brodmann area may not be well justified. A helpful discussion on this can be found in Devlin and Poldrack (2007), In praise of tedious anatomy.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>My critique was not focused on the viability data but more on how to better frame assumptions and predictions. The data are very promising and interesting. I felt that a clear set of front-ended predictions would be very helpful, as would elaborating on the role of language deprivation.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>The study is well-written, the work is well-motivated and the analysis is consistent with the field. I have a few specific comments below.</p><p>Comment 1</p><p>The authors make some strong claims and it may be worth being a little more precise about exactly what is being claimed. For instance, if we break down the authors concluding sentence from the abstract &quot;These results provide positive, causal evidence that the neural semantic representation in dATL is specifically supported by language, as a unique mechanism of representing (abstract) semantic space, beyond the sensory-derived semantic representations distributed in the other cortical regions.&quot;</p><p>By 'specifically', do the authors mean that dATL is a solely language-based representation (and sensory-derived conceptual representation plays no role, even in the sighted), do they mean the dATL specifically (and not other brain regions) is involved in language-derived conceptual representation. Does 'supported', mean a supportive/auxiliary role, or does this mean that language is the basis upon which representations are formed? Does 'unique' imply that the dATL alone is language-derived, that it is alone in being language derived and independent of sensory-derived representations, that is the unique representation of truly abstract knowledge?</p><p>I would encourage the authors to, as much as possible, clearly lay out their claims, as this is of genuine interest (rather than just 'softening the language').</p><p>Comment 2</p><p>I do get the sense that the authors are proposing that dATL may be purely language-derived representation not grounded in or in any derived from sensory experience. It seems possible that this can be the case, as shown in the congenitally blind population, but this does not indicate that it is always the case. It is very possible that in the absence of sensory experience, dATL representations can continue to form, but it is simultaneously possible that when this sensory experience is present, more grounded processes also contribute. Are the authors arguing that the present result shows that this is not the case? Please clarify.</p><p>Comment 3</p><p>The main empirical emphasis of this work and the authors' general thesis is the specificity or particular 'peak' importance of the dATL. The group difference in the RSA and in the univariate analysis of the abstract&gt;concrete effect in dATL do indeed support the importance of dATL. However, the failure of these effects to reach significance in the other abstract&gt;concrete ROIs (pMTG, IFG) does not indicate that these effects are different between dATL and (e.g.) pMTG.</p><p>Ideally, ROI by group interactions would be performed on the ROI data in Figure 2B and Figure 3A to show that dATL is statistically different from the other ROIs. I appreciate that this level of statistical vigour is often not met in our field but considering the importance and interesting nature of the authors' claims, I feel it would strongly improve the quality of the results here.</p><p>If the ROI by effect interactions are not significant, then a clear caution about over-interpreting the absence of effects of pMTG and IFG could be included in the discussion.</p><p>Comment 4</p><p>Similarly, the searchlight analysis (lines 220-229) reports the presence of effects in native signers and the absence of effects in later signers (while there are no significant differences between the groups). This may also encourage the reader to over-interpret the absence of effects. The inclusion of the searchlight is clearly motivated, in that it shows that group differences are not apparent outside the ROIs analysed in the previous section. It would be good if the authors could emphasise more strongly the absence of effects outside of the ROIs and caution against the over-interpretation of the absence of effects in delayed signers given the absence of significant differences between delayed and native signers.</p><p>Comment 5</p><p>Relating to comment 4, if we are to take the descriptive route, it seems there is comparable evidence implicating the left AG/TPJ in language-derived representations in native but not delayed signers (Figure 3C). Might a (post hoc) ROI analysis indicate comparable effects of delayed language acquisition in this region? How would the potential generalisability of this effect impact the authors' beliefs about dATL?</p><p>Comment 6</p><p>Delayed language acquisition could have potentially wide-reaching effects on cortical development. I appreciate that participants were matched on some criteria (e.g. self-report sign proficiency, lexical decision) but do the authors have reason to be sure that reported imaging differences are not a non-specific result of broad cortical changes? One supportive data point I can think of is the difference between dATL and IFG but perhaps there is information in the literature. It would be good if the authors could lay these out.</p><p>Comment 7</p><p>Do the authors think that language-derived knowledge is related to all domains dATL? For instance, in congenitally blind individuals, do the authors think distinctions between a mountain range versus a city skyline would be present in dATL rather than PPA or RSA?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81681.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Expanding on the discussion of critical periods for language development, particularly with respect to lexical-semantic and semantic acquisition (as opposed to phonology and syntax).</p></disp-quote><p>We appreciate the suggestion and have revised our manuscript thoroughly in light of this comment. First, we now avoid the vague term “critical period”, which may be taken to refer to critical period for different, specific cognitive and/or neural development in the literature. Instead, we now made explicit throughout the specific processes being discussed (phonology, syntax, semantics). The behavioral and neural effects of early language experience (delayed language acquisition) on phonology, syntax, and semantics are now elaborated, discussed separately and explicitly in both the Introduction and Discussion (see more detailed responses below, Reviewer 2 – Comment 1).</p><disp-quote content-type="editor-comment"><p>2) Explicitly evaluating whether the dATL differs in pattern from other ROIs, which would be necessary to say strongly that the dATL is &quot;specifically&quot; or &quot;uniquely&quot; sensitive.</p></disp-quote><p>We added two-way ANOVA analyses, with ROIs as the within-subject factor and group as the between-subject factor. The ROI-by-group interaction did not reach significance for either the RSA semantic encoding effect or the univariate abstractness effect (pages 9 and 12). We have revised the statistical reports and discussions accordingly, adding a paragraph explicitly stating that there is no evidence for a strong anatomical specificity (Discussion paragraph 2, page 14). Please see also below (Reviewer 3 – Comment 3) for more detailed responses.</p><disp-quote content-type="editor-comment"><p>3) Addressing what seems to be a mismatch between the behavioral results (no group differences) and brain results (significant group differences).</p></disp-quote><p>We have added explicit discussions addressing this issue (page 18):</p><p>“Consistent with the literature where deaf delayed signers did not show differences to controls in semantic interference effects in the picture-sign paradigm (Baus et al., 2008), scalar implicature (Davidson and Mayberry, 2015) or N400 measures (Skotara et al., 2012), we did not observe visible differences in terms of semantic distance structures (Figure 1a) or reaction time of lexical decision and word-triplet semantic judgment (Supplementary file 1). As reasoned in the Introduction, this seeming neuro-behavior discrepancy might be related to the multifaceted, distributed nature of the cognitive and neural basis of semantics more broadly. The general semantic behavioral tasks we employed could be achieved with representations derived from multiple types of experiences, supported by highly distributed neural systems (e.g., Bi, 2021; Binder and Desai, 2011; Lambon Ralph et al., 2017; Martin, 2016), including those not affected by delayed L1 acquisition in regions beyond dATL. This finding invites future studies to specify the exact developmental mechanisms in the left dATL (Fu et al., 2022; Unger and Fisher, 2021) and to uncover semantic behavioral consequences related to the functionality of this area.”</p><p>Also in the Introduction, the potential differences between behavioral and neural profiles for semantics are laid out, motivating the importance of looking at semantic neural representations (Intro paragraph 4, page 4).</p><disp-quote content-type="editor-comment"><p>4) Before resubmitting please revisit the language regarding the language-deprived group carefully to ensure the logic is clear and not stigmatizing. There was some disagreement among reviewers during a discussion over this issue so I just ask you to ensure the issue is handled thoughtfully.</p></disp-quote><p>Thank you for this kind reminder. With references to related studies in the literature, we removed the term “language deprivation” and used the terms “subjects with varying amounts of early language exposure” or “delayed L1 acquisition” to more precisely describe our experimental manipulation throughout the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>– Please share the deidentified Nifti files on OpenNeuro, or if this is not permitted by ethics constraints, include the reason in the manuscript.</p></disp-quote><p>Added in the manuscript “Deidentified Nifti files are not shared openly because of ethics constraints, but are available from the corresponding authors upon reasonable request.” (page 28)</p><disp-quote content-type="editor-comment"><p>– Please consider sharing results maps on NeuroVault rather than OSF to aid discoverability (and NeuroVault comes with a viewer that facilitates viewing unthresholded maps).</p></disp-quote><p>Done. “The whole-brain unthresholded statistical maps have also been made available on NeuroVault at the link <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/13705/">https://neurovault.org/collections/13705/</ext-link>.” (page 28)</p><disp-quote content-type="editor-comment"><p>– Many of the paragraphs are quite long (spanning a page or more). I would suggest considering breaking some of these into smaller paragraphs, with informative topic sentences, to enhance readability.</p></disp-quote><p>Done.</p><disp-quote content-type="editor-comment"><p>– Without cytoarchitectonic information, including the Brodmann area may not be well justified. A helpful discussion on this can be found in Devlin and Poldrack (2007), In praise of tedious anatomy.</p></disp-quote><p>Thank you. We have removed the information of Brodmann areas from the Results section.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>My critique was not focused on the viability data but more on how to better frame assumptions and predictions. The data are very promising and interesting. I felt that a clear set of front-ended predictions would be very helpful, as would elaborating on the role of language deprivation.</p></disp-quote><p>Thank you for your constructive comments on our study. Following your and other reviewers’ suggestions, we have thoroughly revised the Introduction section. The major revisions include: (1) to elaborate on the previous findings of delayed L1 acquisition on the behavioral and neural effects of semantic knowledge; (2) to be more explicit about our focus and predictions on the effects of delayed L1 acquisition on the neural representations of semantics (pages 2, 4-5).</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>The study is well-written, the work is well-motivated and the analysis is consistent with the field. I have a few specific comments below.</p></disp-quote><p>We appreciate the positive evaluations and the constructive comments.</p><disp-quote content-type="editor-comment"><p>Comment 1</p><p>The authors make some strong claims and it may be worth being a little more precise about exactly what is being claimed. For instance, if we break down the authors concluding sentence from the abstract &quot;These results provide positive, causal evidence that the neural semantic representation in dATL is specifically supported by language, as a unique mechanism of representing (abstract) semantic space, beyond the sensory-derived semantic representations distributed in the other cortical regions.&quot;</p><p>By 'specifically', do the authors mean that dATL is a solely language-based representation (and sensory-derived conceptual representation plays no role, even in the sighted), do they mean the dATL specifically (and not other brain regions) is involved in language-derived conceptual representation. Does 'supported', mean a supportive/auxiliary role, or does this mean that language is the basis upon which representations are formed? Does 'unique' imply that the dATL alone is language-derived, that it is alone in being language derived and independent of sensory-derived representations, that is the unique representation of truly abstract knowledge?</p><p>I would encourage the authors to, as much as possible, clearly lay out their claims, as this is of genuine interest (rather than just 'softening the language').</p></disp-quote><p>We appreciate this comment very much. We have made the following revisions to explicitly address these important issues.</p><p>We added a full paragraph in the Discussion to clarify the specificity regarding the anatomical regions (i.e., relative to other brain regions) and the information contents (i.e., relative to semantic structures derived from nonlinguistic experiences) (page 14): “Two types of specificity are to be clarified – anatomical specificity and information specificity. First, is this group effect specific to the dATL, relative to other brain regions? We do not have evidence for such a strong region-specificity. We did not observe a significant group-by-ROI interaction in either the RSA or the univariate analyses. That is, the group differences were not significantly stronger in the dATL than in the other semantic regions being analyzed (IFG and pMTG). We are thus not claiming that the dATL is the only region that derives semantic representation from language experience, but choose to focus the following discussion on this region because of the robust positive effects here. Second, is the dATL semantic representation specifically derived from language experience and not other (nonlinguistic) sensory experiences?.…” (see also response to comment 2 below).</p><p>We have also revised the Introduction to more explicitly explain the potential cognitive contribution of language to semantic knowledge and the rationale behind our study (page 2): “Language experiences may contribute to semantic development beyond sensory experiences by facilitating or modulating categorizations by the nature of labelling (i.e., words) to the sensory experiences, and/or by constructing semantic relations based on various types of word relations (Gelman and Roberts, 2017; Perszyk and Waxman, 2018; Unger and Fisher, 2021). Are such cognitive contributions manifested by modulating the neural representations of the sensory-derived semantic spaces, or by also formulating neural representations that specialize to represent knowledge derived from language experience (i.e., not nonlinguistic sensory experience)?”; (page 6): “We aim to test the neural system representing the language-derived semantic representations, beyond the sensory-derived semantic representations (Bi, 2021; Wang et al., 2020).”</p><p>We have also carefully updated the wording in other parts of the manuscript to make the relevant statements more precise.</p><disp-quote content-type="editor-comment"><p>Comment 2</p><p>I do get the sense that the authors are proposing that dATL may be purely language-derived representation not grounded in or in any derived from sensory experience. It seems possible that this can be the case, as shown in the congenitally blind population, but this does not indicate that it is always the case. It is very possible that in the absence of sensory experience, dATL representations can continue to form, but it is simultaneously possible that when this sensory experience is present, more grounded processes also contribute. Are the authors arguing that the present result shows that this is not the case? Please clarify.</p></disp-quote><p>We appreciate this suggestion to clarify the discussion of this important issue. We have added explicit discussions as follows (page 14-15): “Is the dATL semantic representation specifically derived from language experience and not other (nonlinguistic) sensory experiences? The manipulation of the current study--the two groups of deaf signers--varies on the language exposure while matching on the sensory experiences (see below), and thus did not test the presence or absence of sensory-derived semantic representations. Inferences could be drawn in combination with the previous studies that focused on the manipulation of sensory experiences by studying visual knowledge in congenitally blind subjects. There, it was reported that the blind and sighted had comparable semantic information encoding in the RSA analyses (Wang et al., 2020); in terms of univariate effects (abstractness or color concept adaptation), deprivation of sensory experiences did not reduce, but actually tended to enhance the effects here (Bottini et al., 2020; Striem-Amit et al., 2018). That is, evidence from congenitally blind studies does not support the additional sensory-derived semantic encoding here. While drawing negative conclusions is always difficult, we reason that it is parsimonious, based on available data, to propose that dATL’s contribution to semantic encoding is specific to language, and not sensory-derived representations.”</p><disp-quote content-type="editor-comment"><p>Comment 3</p><p>The main empirical emphasis of this work and the authors' general thesis is the specificity or particular 'peak' importance of the dATL. The group difference in the RSA and in the univariate analysis of the abstract&gt;concrete effect in dATL do indeed support the importance of dATL. However, the failure of these effects to reach significance in the other abstract&gt;concrete ROIs (pMTG, IFG) does not indicate that these effects are different between dATL and (e.g.) pMTG.</p><p>Ideally, ROI by group interactions would be performed on the ROI data in Figure 2B and Figure 3A to show that dATL is statistically different from the other ROIs. I appreciate that this level of statistical vigour is often not met in our field but considering the importance and interesting nature of the authors' claims, I feel it would strongly improve the quality of the results here.</p><p>If the ROI by effect interactions are not significant, then a clear caution about over-interpreting the absence of effects of pMTG and IFG could be included in the discussion.</p></disp-quote><p>We appreciate this comment very much. We added two-way ANOVA, with ROIs as the within-subject factor and group as the between-subject factor. The ROI-by-group interaction did not reach significance for either RSA (<italic>F<sub>(2,74)</sub></italic> = 1.59, <italic>p</italic> = 0.21) or univariate abstractness (<italic>F<sub>(2,74)</sub></italic> = 0.50, <italic>p</italic> = 0.61) effects (pages 9 and 12). We have revised the statistical description and relevant discussions accordingly, making sure to not claim for true negatives in pMTG/IFG or that the dATL is “anatomically specific”, being the only region that derives semantic representation from language experience.</p><p>Explicit clarifications included “We do not have evidence for such a strong region-specificity. We did not observe a significant group-by-ROI interaction in either the RSA or the univariate analyses. That is, the group difference was not significantly stronger in dATL than in the other semantic regions being analyzed (IFG and pMTG). We are thus not claiming that the dATL is the only region that derives semantic representation from language experience, but choose to focus the following discussion on this region because of the robust positive effects here.” (page 14)”</p><disp-quote content-type="editor-comment"><p>Comment 4</p><p>Similarly, the searchlight analysis (lines 220-229) reports the presence of effects in native signers and the absence of effects in later signers (while there are no significant differences between the groups). This may also encourage the reader to over-interpret the absence of effects. The inclusion of the searchlight is clearly motivated, in that it shows that group differences are not apparent outside the ROIs analysed in the previous section. It would be good if the authors could emphasise more strongly the absence of effects outside of the ROIs and caution against the over-interpretation of the absence of effects in delayed signers given the absence of significant differences between delayed and native signers.</p></disp-quote><p>Thank you for this helpful advice. Following this suggestion, we added, after the report of the whole-brain map results: “Of course, such a thresholded map does not indicate true negatives in the delayed singer group”, which was followed by the emphasis on the group difference tests, summarized by the implications of the whole brain searchlight analyses “Together, group differences are not apparent outside the ROIs analyzed in the previous section.” (pages 9-10)</p><disp-quote content-type="editor-comment"><p>Comment 5</p><p>Relating to comment 4, if we are to take the descriptive route, it seems there is comparable evidence implicating the left AG/TPJ in language-derived representations in native but not delayed signers (Figure 3C). Might a (post hoc) ROI analysis indicate comparable effects of delayed language acquisition in this region? How would the potential generalisability of this effect impact the authors' beliefs about dATL?</p></disp-quote><p>Following this comment, we carried out RSA in an additional set of language ROIs that included both ATL and AG/TPJ (Fedorenko et al., 2010) to further validate the effects in the ATL and to examine the potential group differences in the AG/TPJ (pages 10-11): “(2) Types of ROIs: To validate whether the dATL semantic reduction in delayed signers depends on particular ATL definitions and to explore potential group differences in other language-sensitive regions beyond the ROIs we localized, we performed the RSA in a commonly used language mask (contrasting intact sentences with nonword lists) (Fedorenko et al., 2010). As shown in Figure 4, again we observed significant group differences in the ATL (Welch’s <italic>t</italic><sub>33.1</sub> = 3.71, two-tailed <italic>p</italic> = 7.53 x 10<sup>-4</sup>, Hedges’ g = 1.18), which also survived the Bonferroni correction. Other language-sensitive regions did not achieve significance, with the tendency for the same direction of semantic encoding reduction (<italic>p</italic>s &gt;.065, uncorrected). Two-way ANOVA showed a significant main effect of group (<italic>F<sub>(1, 37)</sub></italic> = 6.80, <italic>p</italic> = .013) and no significant ROI-by-group interaction (<italic>F<sub>(5, 185)</sub></italic> = 0.823, <italic>p</italic> = .535), indicating that delayed L1 acquisition resulted in widespread reduced semantic representations in the language regions, with the effects in the ATL consistently robust.” These results led us to explicitly acknowledge that we do not have evidence or claim for the strong region-specificity in the dATL.</p><disp-quote content-type="editor-comment"><p>Comment 6</p><p>Delayed language acquisition could have potentially wide-reaching effects on cortical development. I appreciate that participants were matched on some criteria (e.g. self-report sign proficiency, lexical decision) but do the authors have reason to be sure that reported imaging differences are not a non-specific result of broad cortical changes? One supportive data point I can think of is the difference between dATL and IFG but perhaps there is information in the literature. It would be good if the authors could lay these out.</p></disp-quote><p>Thank you for the helpful suggestion. Indeed, previous studies have reported that delayed L1 acquisition associates with anatomical alterations. We have now reviewed such findings and considered our results in light of those observations in the Introduction: “Anatomical alterations in regions typically recruited in language tasks – reduced cortical volume in the left inferior frontal region, reduced cortical thickness in the left posterior middle temporal region, and reduced fractional anisotropy values in the left arcuate fasciculus – were also reported in signers with delayed L1 acquisition (Cheng et al., 2023, 2019).” (page 4)</p><p>And the Discussion: “The current results also have implications for the role of early language exposure in neurodevelopment more generally. Previous studies have reported delayed L1 acquisition associates with reduced cortical volume in the left inferior frontal region, reduced cortical thickness in the left posterior middle temporal region, and the reduced fractional anisotropy values in the left arcuate fasciculus that structurally connects the two regions, and not ATL or its related white matter tracts (Cheng et al., 2023, 2019). Our findings of semantic functional alterations in dATL are thus not easily attributable to broad anatomical changes associated with late L1 acquisition.” (page 17)</p><disp-quote content-type="editor-comment"><p>Comment 7</p><p>Do the authors think that language-derived knowledge is related to all domains dATL? For instance, in congenitally blind individuals, do the authors think distinctions between a mountain range versus a city skyline would be present in dATL rather than PPA or RSA?</p></disp-quote><p>We appreciate the opportunity to clarify our positions. The general response to the hypothesized representation in dATL is shown in response to Comment 1. For the specific example here, a mountain range versus a city skyline may differ not only in language relational patterns, but also in nonvisual sensory aspects. Although congenitally blind individuals could not directly perceive such targets, they may still learn that a city skyline is comprised of more rectilinear or rectangular lines, and a mountain range may have more curved lines, or other types of compositional properties, from direct or indirect language descriptions. Such componential shape knowledge may be derived from sensory experiences (e.g., tactile), which could be represented in PPA/RSC. Thus it is difficult to make strong predictions about the absence of sensory-derived representations and we restricted our discussion to the main manipulation here (effects of language experience).</p></body></sub-article></article>