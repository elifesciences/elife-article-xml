<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">19460</article-id><article-id pub-id-type="doi">10.7554/eLife.19460</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Divisive suppression explains high-precision firing and contrast adaptation in retinal ganglion cells</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-32485"><name><surname>Cui</surname><given-names>Yuwei</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-50546"><name><surname>Wang</surname><given-names>Yanbin V</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-50547"><name><surname>Park</surname><given-names>Silvia J H</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-17156"><name><surname>Demb</surname><given-names>Jonathan B</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-50013"><name><surname>Butts</surname><given-names>Daniel A</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0158-5317</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Biology</institution>, <institution>University of Maryland</institution>, <addr-line><named-content content-type="city">College Park</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Program in Neuroscience and Cognitive Science</institution>, <institution>University of Maryland</institution>, <addr-line><named-content content-type="city">College Park</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Ophthalmology and Visual Science</institution>, <institution>Yale University</institution>, <addr-line><named-content content-type="city">New Haven</named-content></addr-line>, <country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Cellular and Molecular Physiology</institution>, <institution>Yale University</institution>, <addr-line><named-content content-type="city">New Haven</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallant</surname><given-names>Jack L</given-names></name><role>Reviewing editor</role><aff id="aff5"><institution>University of California, Berkeley</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>jonathan.demb@yale.edu</email> (JBD);</corresp><corresp id="cor2"><email>dab@umd.edu</email> (DAB)</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>14</day><month>11</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e19460</elocation-id><history><date date-type="received"><day>08</day><month>07</month><year>2016</year></date><date date-type="accepted"><day>19</day><month>10</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Cui et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Cui et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-19460-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.19460.001</object-id><p>Visual processing depends on specific computations implemented by complex neural circuits. Here, we present a circuit-inspired model of retinal ganglion cell computation, targeted to explain their temporal dynamics and adaptation to contrast. To localize the sources of such processing, we used recordings at the levels of synaptic input and spiking output in the in vitro mouse retina. We found that an ON-Alpha ganglion cell's excitatory synaptic inputs were described by a divisive interaction between excitation and delayed suppression, which explained nonlinear processing that was already present in ganglion cell inputs. Ganglion cell output was further shaped by spike generation mechanisms. The full model accurately predicted spike responses with unprecedented millisecond precision, and accurately described contrast adaptation of the spike train. These results demonstrate how circuit and cell-intrinsic mechanisms interact for ganglion cell function and, more generally, illustrate the power of circuit-inspired modeling of sensory processing.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.001">http://dx.doi.org/10.7554/eLife.19460.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.19460.002</object-id><title>eLife digest</title><p>Visual processing begins in the retina, a layer of light-sensitive tissue at the back of the eye. The retina itself is made up of three layers of excitatory neurons. The first comprises cells called photoreceptors, which absorb light and convert it into electrical signals. The photoreceptors transmit these signals to the next layer, the bipolar cells, which in turn pass them on to the final layer, the retinal ganglion cells. The latter are responsible for sending the signals on to the brain. Other cells in the retina inhibit the excitatory neurons and thereby regulate their signals.</p><p>While the basic structure of the retina has been described in detail, we know relatively little about how retinal ganglion cells represent information from visual scenes. Existing models of vision fail to explain several aspects of retinal ganglion cell activity. These include the exquisite timing of ganglion cell responses, and the fact that retinal ganglion cells adjust their responses to suit different visual conditions. In the phenomenon known as contrast adaptation, for example, ganglion cells become more sensitive during small variations in contrast (differences in color and brightness) and less sensitive during high variations in contrast.</p><p>To understand how ganglion cells process visual stimuli, Cui et al. recorded the inputs and outputs of individual ganglion cells in samples of tissue from the mouse retina. By feeding these data into a computer model, Cui et al. were able to identify the mathematical calculations that take place at each stage of the retinal circuit. The findings suggest that a key element shaping the response of ganglion cells is the interaction between two visual processing pathways at the level of the bipolar cells. The resulting model can predict the responses of ganglion cells to specific inputs from bipolar cells with millisecond precision.</p><p>Future studies should extend the model to more complex visual stimuli. The approach could also be adapted to study different types of ganglion cells in order to obtain a more complete picture of the workings of the retina.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.002">http://dx.doi.org/10.7554/eLife.19460.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>computation</kwd><kwd>precision</kwd><kwd>adaptation</kwd><kwd>normalization</kwd><kwd>retinal circuitry</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>IIS-1350990</award-id><principal-award-recipient><name><surname>Cui</surname><given-names>Yuwei</given-names></name><name><surname>Butts</surname><given-names>Daniel A</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>EY021372</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Yanbin V</given-names></name><name><surname>Park</surname><given-names>Silvia J H</given-names></name><name><surname>Demb</surname><given-names>Jonathan B</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>EY014454</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Yanbin V</given-names></name><name><surname>Park</surname><given-names>Silvia J H</given-names></name><name><surname>Demb</surname><given-names>Jonathan B</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001818</institution-id><institution>Research to Prevent Blindness</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Wang</surname><given-names>Yanbin V</given-names></name><name><surname>Park</surname><given-names>Silvia J H</given-names></name><name><surname>Demb</surname><given-names>Jonathan B</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The convergence of two visual pathways at the level of retinal bipolar cells accounts for key features of ganglion cell responses.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Neural computations in the retina are generated by complex circuits that drive the responses of ~30 distinct ganglion cell types (<xref ref-type="bibr" rid="bib6">Baden et al., 2016</xref>; <xref ref-type="bibr" rid="bib25">Demb and Singer, 2015</xref>; <xref ref-type="bibr" rid="bib66">Sanes and Masland, 2015</xref>). Despite the complexity of retinal circuitry, many aspects of the responses of ganglion cells to visual stimuli can be predicted with a straightforward Linear-Nonlinear (LN) cascade model (<xref ref-type="bibr" rid="bib71">Shapley, 2009</xref>). In this model, a linear receptive field filters the stimulus, and a nonlinear function shapes the output by implementing the spike threshold and response saturation (<xref ref-type="bibr" rid="bib4">Baccus and Meister, 2002</xref>; <xref ref-type="bibr" rid="bib24">Chichilnisky, 2001</xref>; <xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>). However, many aspects of ganglion cell firing deviate from LN model predictions. For example, the LN model does not capture the effects of contrast adaptation, which includes a reduced gain (i.e., filter amplitude) at high contrast (<xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib53">Meister and Berry, 1999</xref>; <xref ref-type="bibr" rid="bib72">Shapley and Victor, 1978</xref>). The LN model also does not predict firing at high temporal resolution (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib16">Butts et al., 2016</xref>, <xref ref-type="bibr" rid="bib19">2007</xref>; <xref ref-type="bibr" rid="bib40">Keat et al., 2001</xref>; <xref ref-type="bibr" rid="bib59">Passaglia and Troy, 2004</xref>; <xref ref-type="bibr" rid="bib81">Uzzell and Chichilnisky, 2004</xref>), and yet precise firing likely represents an essential element of downstream visual processing (<xref ref-type="bibr" rid="bib15">Bruno and Sakmann, 2006</xref>; <xref ref-type="bibr" rid="bib35">Havenith et al., 2011</xref>; <xref ref-type="bibr" rid="bib41">Kelly et al., 2014</xref>; <xref ref-type="bibr" rid="bib83">Wang et al., 2010a</xref>).</p><p>To improve on the LN model, several nonlinear approaches have been proposed. The first approach describes the nonlinear function between stimulus and response as a mathematical expansion, extending from the linear receptive field (<xref ref-type="bibr" rid="bib24">Chichilnisky, 2001</xref>) to 'second-order' quadratic terms, using either spike-triggered covariance (<xref ref-type="bibr" rid="bib28">Fairhall et al., 2006</xref>; <xref ref-type="bibr" rid="bib46">Liu and Gollisch, 2015</xref>; <xref ref-type="bibr" rid="bib33">Samengo and Gollisch, 2013</xref>; <xref ref-type="bibr" rid="bib82">Vaingankar et al., 2012</xref>) or maximally informative dimension analyses (<xref ref-type="bibr" rid="bib74">Sharpee et al., 2004</xref>). Such expansion terms better predict the spike train, but they are difficult to interpret functionally and with respect to the underlying circuitry (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>; <xref ref-type="bibr" rid="bib52">McFarland et al., 2013</xref>). The second approach targets specific aspects of the response, such as spike-refractoriness (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib40">Keat et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>; <xref ref-type="bibr" rid="bib60">Pillow et al., 2005</xref>), gain changes associated with contrast adaptation (<xref ref-type="bibr" rid="bib11">Bonin et al., 2005</xref>; <xref ref-type="bibr" rid="bib50">Mante et al., 2008</xref>; <xref ref-type="bibr" rid="bib53">Meister and Berry, 1999</xref>; <xref ref-type="bibr" rid="bib72">Shapley and Victor, 1978</xref>), the interplay of excitation and inhibition (<xref ref-type="bibr" rid="bib16">Butts et al., 2016</xref>, <xref ref-type="bibr" rid="bib18">2011</xref>), and rectification of synaptic release, associated with nonlinear spatial processing (<xref ref-type="bibr" rid="bib32">Freeman et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Gollisch, 2013</xref>; <xref ref-type="bibr" rid="bib68">Schwartz and Rieke, 2011</xref>). However, each of these models primarily focuses on one type of nonlinear computation and does not generalize to explain a range of response properties.</p><p>Here we derive a novel nonlinear modeling framework inspired by retinal circuitry. The model is constrained by recordings at two stages of processing: excitatory synaptic input and spike output, recorded in mouse retinal ganglion cells. We focused on ON-Alpha ganglion cells because they comprise a major input to lateral geniculate nucleus (LGN) and superior colliculus, and because they could be targeted routinely, in vitro, based on their large soma size. Furthermore, their spiking response to contrast modulation is mediated predominantly by synaptic excitation (<xref ref-type="bibr" rid="bib54">Murphy and Rieke, 2006</xref>). We devised a tractable model of excitatory currents that incorporates a nonlinear structure based on realistic circuit elements. In particular, we allowed for divisive suppression acting on a ganglion cell’s excitatory inputs to capture the computations implemented by presynaptic inhibition (<xref ref-type="bibr" rid="bib26">Eggers and Lukasiewicz, 2011</xref>; <xref ref-type="bibr" rid="bib31">Franke et al., 2016</xref>) and synaptic depression (<xref ref-type="bibr" rid="bib38">Jarsky et al., 2011</xref>; <xref ref-type="bibr" rid="bib56">Ozuysal and Baccus, 2012</xref>) at bipolar cell terminals. Ganglion cell firing, further shaped by spike generation mechanisms, could be predicted by the model with millisecond precision. Our study establishes a unified model of nonlinear processing within ganglion cells that accurately captures both the generation of precise firing events and fast contrast adaptation. Similar circuit-inspired modeling could be applied widely in other sensory systems.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We recorded spikes from ON-Alpha ganglion cells in the in vitro mouse retina while presenting a temporally modulated (&lt;30 Hz), 1-mm spot centered on the neuron’s receptive field (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>top</italic>). Every 10 s the contrast level switched between high and low. In high contrast, the stimulus evoked spike responses that were precisely timed from trial to trial (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>left</italic>), consistent with previous work performed both in vitro and in vivo (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib16">Butts et al., 2016</xref>; <xref ref-type="bibr" rid="bib19">Butts et al., 2007</xref>; <xref ref-type="bibr" rid="bib59">Passaglia and Troy, 2004</xref>; <xref ref-type="bibr" rid="bib62">Reinagel and Reid, 2000</xref>; <xref ref-type="bibr" rid="bib81">Uzzell and Chichilnisky, 2004</xref>). Such precision was not clearly present at low contrast (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>right</italic>).<fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.003</object-id><label>Figure 1.</label><caption><title>Precision of ganglion cell spike trains arises at the level of synaptic inputs.</title><p>(<bold>A</bold>) Spike rasters of an ON-Alpha cell to 10 repeated presentations of a temporally modulated noise stimulus (<italic>top</italic>) at two contrast levels. The response was parsed into separate 'events' (labeled by different colors). The PSTH (<italic>bottom</italic>) is compared with predictions of the LN model (blue, red), which fits better at low contrast. (<bold>B</bold>) The LN model (schematic: <italic>left</italic>) was fit separately at each contrast, with the effects of adaptation isolated to the linear filters (<italic>top</italic>), which share the same nonlinearity (<italic>bottom</italic>). Nonlinearities are shown relative to the distributions of the filtered stimulus at high (shaded blue) and low (shaded red) contrasts. (<bold>C</bold>) Temporal properties of the observed spike trains, compared with predictions of the LN model without or with a spike-history term (LN and LN+RP). <italic>Left</italic>: SD of the timing of the first spike in each event. <italic>Right</italic>: Event duration, measured by the SD of all spikes in the event (*p&lt;10<sup>–6</sup>, 59 events). LN and LN+RP models do not reproduce the spike precision at high contrast (HC), but the LN+RP model is adequate at low contrast (LC). (<bold>D</bold>) Excitatory synaptic current from the neuron in (<bold>A</bold>–<bold>C</bold>) compared with the LN model predictions. Gray area indicates SD across trials, demonstrating minimal variability. (<bold>E</bold>) LN model fits to the current data. The temporal filters (<italic>top</italic>) change less with contrast compared to spike filters (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Note here there is also a tonic offset between contrasts (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), captured in the vertical shift of the nonlinearity (<italic>bottom right</italic>). (<bold>F</bold>). The precision of the current response was measured using the coherence between the response on individual trials and either the observed trial-averaged response (black) or LN predictions (blue, red). Gray area shows SEM across trials (<italic>left</italic>) and SD across the population (<italic>right</italic>). The LN model fails to capture high frequency response components at HC, but agrees well with the data at LC, suggesting the precision observed in ganglion cell spike trains arises at the level of synaptic inputs.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.003">http://dx.doi.org/10.7554/eLife.19460.003</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig1-v1"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19460.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Measurement of slow contrast adaptation.</title><p>(<bold>A</bold>) The stimulus (<italic>top</italic>) and unprocessed recording of synaptic current (<italic>bottom</italic>) from an example neuron over the course of a 20 s trial consisting of 10 s high contrast (<italic>left</italic>) followed by 10 s low contrast (<italic>right</italic>). (<bold>B</bold>) Average (<italic>left</italic>) and standard deviation (<italic>right</italic>) of the membrane current over the 20 s trial for the example neuron (<italic>top</italic>) and averaged across the population (<italic>bottom</italic>). Each point is the average and standard deviation over a sliding 1 s window: each measurement was then averaged over the 10 trials. This demonstrated a tonic shift in membrane current offset (<italic>left</italic>) and gain (<italic>right</italic>) with contrast. The last three seconds of every trial represent the repeated section of the stimulus (red shaded area); the fluctuations in response to the repeated stimuli are a result of not averaging over different stimuli across the 10 trials. (<bold>C</bold>) To depict the scale of the change in mean current with contrast compared with the standard deviation (from <bold>B</bold>), the mean is represented on the same scale with the standard deviation (from <bold>B</bold>, <italic>right</italic>) with error bars extending from the averages (from <bold>B</bold>, <italic>left</italic>). The change in mean current over time was small relative to the fluctuations in synaptic current driven by the stimulus, explaining why the models did not need to incorporate mechanisms of slow contrast adaptation. The tonic shift in offset is also evident in the LN model analysis (below). (<bold>D</bold>) Average firing rate over the 20 s trial for an example neuron (<italic>top</italic>) and across the population (<italic>bottom</italic>). Each point represents the average firing rate over a sliding 1 s window across the 10 trials. The error bars in the bottom panel represent the standard deviation across the population. (<bold>E</bold>) We also tested for slower adaptation using LN analysis (e.g., <xref ref-type="bibr" rid="bib23">Chander and Chichilnisky, 2001</xref>; see Materials and methods) based on data from the first three seconds (<italic>left</italic>) compared with the last three seconds (<italic>right</italic>) of each 7 s period of unique responses within a 10 s trial (excluding the final 3 s period of a repeated stimulus). The LN analyses for the example cell is shown. (<bold>F</bold>) Change of contrast gain (<italic>left</italic>) and biphasic index (<italic>right</italic>) across contrasts measured on the first 3 s (<italic>x-axis</italic>) and on the last 3 s (<italic>y-axis</italic>) of each trial across neurons (<italic>n</italic> = 13). We observed no difference on a cell-by-cell basis. (<bold>G</bold>) Comparison of the change in average synaptic current between contrast, comparing the first 3- and last 3 s periods, demonstrating no difference between the two periods.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.004">http://dx.doi.org/10.7554/eLife.19460.004</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig1-figsupp1-v1"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19460.005</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Stability of recording.</title><p>To test the stability of the recording, we calculated the standard deviation of intracellular synaptic current responses (<italic>top</italic>) and average current (<italic>bottom</italic>) over the 10 trials of each experiment (box plots show data aggregated across cells, <italic>n </italic>= 13). Recordings were stable across trials.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.005">http://dx.doi.org/10.7554/eLife.19460.005</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig1-figsupp2-v1"/></fig></fig-group></p><p>We first used a linear-nonlinear (LN) cascade model (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) (<xref ref-type="bibr" rid="bib24">Chichilnisky, 2001</xref>; <xref ref-type="bibr" rid="bib37">Hunter and Korenberg, 1986</xref>) to predict the observed responses. The 'L' (linear) step of the cascade processes the stimulus with a linear 'receptive field' <bold>k</bold>, whose output reflects the degree that the stimulus <bold>s</bold>(<italic>t</italic>) matches <bold>k</bold>. The 'N' (nonlinear) step acts on the output of the receptive field, <bold>k·s</bold>(<italic>t</italic>), which is scaled by a nonlinear function that could include the effects of spike threshold and response saturation. Both the linear receptive field and the nonlinearity are fit to the data in order to better predict the firing rate. The resulting receptive field had a biphasic shape at both contrasts, representing the sensitivity of the neuron to dark-to-light transitions (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Furthermore, the filter had a smaller amplitude at high contrast, a signature of contrast adaptation (<xref ref-type="bibr" rid="bib4">Baccus and Meister, 2002</xref>; <xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib87">Zaghloul et al., 2005</xref>).</p><p>Despite capturing the coarse temporal features of the response, the LN model could not capture fine temporal features at high contrast (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib47">Liu et al., 2001</xref>). To precisely compare time scales of the observed data with model predictions, we performed 'event analysis', which divides the spike train into firing events separated by silence (<xref ref-type="bibr" rid="bib17">Butts et al., 2010</xref>; <xref ref-type="bibr" rid="bib44">Kumbhani et al., 2007</xref>). Based on this analysis, the LN model failed to predict either the SD of the first-spike in each event or the overall event duration in high contrast, but was largely successful in low contrast (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p><p>To improve on the LN model prediction, we included a refractory period (RP) following each spike (<xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>), which has previously been suggested as a mechanism for precise firing in ganglion cells (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib40">Keat et al., 2001</xref>) (see Materials and methods). However, while the resulting LN+RP model could predict the temporal properties of the spike train at low contrast, it failed at high contrast (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Thus, spike-refractoriness alone could not explain the precision at high contrast, and consequently could not predict how the response changes from low to high contrast.</p><sec id="s2-1"><title>Nonlinear processing distributed across two stages of retinal processing</title><p>Because some degree of contrast adaptation is already present in a ganglion cell’s excitatory synaptic inputs (<xref ref-type="bibr" rid="bib7">Beaudoin et al., 2007</xref>; <xref ref-type="bibr" rid="bib8">Beaudoin et al., 2008</xref>; <xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>), we hypothesized that we might uncover the source of the nonlinear processing by directly modeling the synaptic input currents. We therefore made whole-cell patch clamp recordings on the same neurons we recorded spike responses from, and performed a similar LN analysis on excitatory synaptic currents (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). The LN model of the currents (<xref ref-type="fig" rid="fig1">Figure 1E</xref>) – like that of the spike response – accurately predicted the observed response at low contrast, but performed relatively poorly at high contrast (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). To compare the precision of the LN model to the observed data, we measured the coherence between the trial-averaged response or model prediction and the responses on individual trials (see Methods); this measure captures the consistency of the response across repeats across time scales. At low contrast, the coherence of the excitatory current matched that of the LN model prediction, whereas at high contrast the coherence of the current extended to finer time scales (i.e., higher frequencies) and hence exceeded the precision predicted by the LN model (<xref ref-type="fig" rid="fig1">Figure 1F</xref>).</p><p>Contrast adaptation was measured in the synaptic currents by comparing LN models at each contrast level (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). The linear filter for the current responses had a larger amplitude (i.e., higher gain) in low contrast compared with high contrast (<xref ref-type="bibr" rid="bib7">Beaudoin et al., 2007</xref>; <xref ref-type="bibr" rid="bib8">Beaudoin et al., 2008</xref>; <xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>). This adaptation occurred rapidly after the contrast switch and showed a barely discernable slow component that has been observed in other ganglion cell types (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>; [<xref ref-type="bibr" rid="bib4">Baccus and Meister, 2002</xref>; <xref ref-type="bibr" rid="bib49">Manookin and Demb, 2006</xref>]). To compare the contrast-dependent gain change in the currents and spikes, we define contrast gain as the ratio between the standard deviation of the filter in low contrast over that in high contrast. The contrast gain was significantly larger for spikes (1.61 ± 0.23) than for currents (1.10 ± 0.14; p&lt;10<sup>−6</sup>, <italic>unpaired two-sample t-test</italic>, spikes: <italic>n </italic>= 11, current: <italic>n </italic>= 13) (<xref ref-type="bibr" rid="bib87">Zaghloul et al., 2005</xref>); in cases where both currents and spikes were recorded in the same cell, the contrast gain was larger for spikes by 30.1% ± 12.0% (<italic>n </italic>= 3). These observations suggest that both contrast adaptation and temporal precision in ON-Alpha ganglion cell spike responses are generated in large part by retinal circuitry upstream of the ganglion cell, but that further transformation occurs between currents and spikes (<xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>).</p></sec><sec id="s2-2"><title>The nonlinear computation underlying synaptic inputs to ganglion cells</title><p>In constructing a nonlinear description of the computation present in excitatory synaptic currents, we sought to emulate elements of the retinal circuit that shape these currents (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Excitatory synaptic inputs to ganglion cells come from bipolar cells, and bipolar cell voltage responses to our stimuli are well described by an LN model (<xref ref-type="bibr" rid="bib4">Baccus and Meister, 2002</xref>; <xref ref-type="bibr" rid="bib63">Rieke, 2001</xref>). This suggests that mechanisms responsible for the nonlinear behavior of the postsynaptic excitatory current are localized to the bipolar-ganglion cell synapses. Possible sources of such nonlinear behavior include presynaptic inhibition from amacrine cells, which can directly gate glutamate release from bipolar cell terminals (<xref ref-type="bibr" rid="bib26">Eggers and Lukasiewicz, 2011</xref>; <xref ref-type="bibr" rid="bib27">Euler et al., 2014</xref>; <xref ref-type="bibr" rid="bib31">Franke et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Schubert et al., 2008</xref>; <xref ref-type="bibr" rid="bib88">Zaghloul et al., 2007</xref>), and synaptic depression at bipolar terminals caused by vesicle depletion (<xref ref-type="bibr" rid="bib38">Jarsky et al., 2011</xref>; <xref ref-type="bibr" rid="bib51">Markram et al., 1998</xref>; <xref ref-type="bibr" rid="bib56">Ozuysal and Baccus, 2012</xref>).<fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.006</object-id><label>Figure 2.</label><caption><title>The divisive suppression (DivS) model of synaptic currents.</title><p>(<bold>A</bold>) Schematic of retinal circuitry. The vertical excitatory pathway, cones → bipolar cells → ganglion cell, can be modulated at the bipolar cell synapse by amacrine cell-mediated inhibition of bipolar cell release or by synaptic depression. We model both processes by divisive suppression (<italic>bottom</italic>), where an LN model, representing the collective influence of amacrine cell inhibition and synaptic depression, multiplicatively modulates excitatory inputs from bipolar cells to the ganglion cell. (<bold>B</bold>) The excitatory (green) and suppressive (cyan) temporal filters of the DivS model for an example ON-Alpha cell. (<bold>C</bold>) Divisive suppression is delayed relative to excitation, demonstrated by the distributions of latencies measured for each pair of filters (mean delay = 10.9 ± 2.2 ms, p&lt;0.0005, <italic>n </italic>= 13). (<bold>D</bold>) Excitatory (<italic>left</italic>) and suppressive nonlinearities (<italic>right</italic>) for the DivS model. The solid line indicates model fits for the example cell, and the gray lines are from other cells in the population, demonstrating their consistent form. The distribution of the filtered stimulus is also shown as the shaded area for HC (blue) and LC (red). The suppressive nonlinearity (<italic>right</italic>) falls below one for stimuli that match the kernel or are opposite, implying that divisive suppression is ON-OFF. (<bold>E</bold>) To validate the form of the DivS model, we compared its performance to alternative models, including a more general model where the form of the nonlinearity is not assumed (2-D, see below), a model where excitatory and suppressive terms interact additively (AddS) instead of divisively, and a covariance (COV) model similar to spike triggered covariance (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). The DivS model performed significantly better than the LN, AddS and COV models (**p&lt;0.0005, <italic>n </italic>= 13), and matched the performance of the 2-D model. (<bold>F</bold>) We used a 2-dimensional nonlinearity to capture any more general interaction between excitatory and suppressive filters, shown with schematic (<italic>left</italic>), and the resulting fits (<italic>middle</italic>). Consistent with the model performance (<bold>E</bold>), the form of this 2-D nonlinearity could be reproduced by the DivS model (<italic>right</italic>). (<bold>G</bold>) Accuracy of the ability of the DivS, AddS, and COV models to reproduce the 2-D nonlinearity across neurons (**p&lt;0.0005, <italic>n </italic>= 13).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.006">http://dx.doi.org/10.7554/eLife.19460.006</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig2-v1"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19460.007</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Comparison to covariance-based models.</title><p>(<bold>A</bold>–<bold>F</bold>) Covariance-based analysis of synaptic currents for the same example cell as in <xref ref-type="fig" rid="fig1">Figure 1.</xref> Covariance analysis follows the intuition of spike-triggered covariance (STC), but uses continuous current input rather than spikes (see Materials and methods). (<bold>A</bold>) <italic>Left:</italic> Cross-correlation between the stimulus and current response (the equivalent of a spike-triggered average) for high contrast (HC, blue) and low contrast (LC, red) stimuli. Filters are scaled to have the same standard deviation, for comparisons of shape. <italic>Middle:</italic> The eigenvalue spectrum for the response-triggered covariance matrix in HC, revealing two significant eigenvalues (color-coded). <italic>Right:</italic> The corresponding eigenvectors. (<bold>B</bold>) The locations of the cross-correlations in HC (blue, <italic>left</italic>) and LC (red, <italic>right</italic>) within the 2-D subspace spanned by the two significant eigenvectors for all neurons (<italic>n</italic> = 13). Because they are all close to the unit circle, both HC and LC cross-correlations were largely contained in the covariance (COV) subspace, consistent with previously reported results for spikes (<xref ref-type="bibr" rid="bib46">Liu and Gollisch, 2015</xref>). (<bold>C</bold>) Model performance for the LN, DivS, and COV models (<italic>n</italic> = 13), reproduced from <xref ref-type="fig" rid="fig2">Figure 2E</xref>. This demonstrates that the COV filters coupled to a 2-D nonlinearity (described below) can nearly match the performance of the DivS model. (<bold>D</bold>) <italic>Left:</italic> The excitatory (green) and suppressive (cyan) filters of the DivS model, plotted in comparison to the filters identified by covariance analysis (dashed lines). <italic>Middle:</italic> The DivS model filters shared the same 2-D subspace as the covariance filters, as shown by comparing the filters to optimal linear combinations of the COV filters (black dashed), following previous work based on spikes (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>). <italic>Right</italic>: The DivS filters projected into the COV filters subspace across neurons, using the same analysis as in (B). Their proximity to the unit circle shows they are almost completely in the covariance subspace for all neurons, again consistent with previous work with spikes (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>). (<bold>E</bold>) <italic>Left:</italic> The 2-D nonlinearity associated with the COV filters, for the example neuron considered. <italic>Right:</italic> The best 2-D nonlinearity reconstructed from 1-D nonlinearities operating on the COV filters. Unlike the 2-D nonlinearity associated with the DivS filters (<xref ref-type="fig" rid="fig2">Figure 2F</xref>), this nonlinearity could not be represented as the product of two 1-D nonlinearities. (<bold>F</bold>) The separability of 2-D nonlinearities for the COV and DivS models, measured as the ability of the 1-D nonlinearities to reproduce the measured 2-D nonlinearity (<italic>R<sup>2</sup></italic>) across neurons (**p&lt;0.0005, <italic>n</italic> = 13). (<bold>G</bold>–<bold>H</bold>) STC analysis applied to an example neuron for which there was enough spiking data. (<bold>G</bold>) The spike-triggered average (<italic>left</italic>), eigenvalue spectrum (<italic>middle</italic>), and significant STC filters (<italic>right</italic>). (<sc><bold>H</bold></sc>) As with the analyses of current responses above, the DivS filters (green, cyan) did not match those identified by STC (<italic>left</italic>, dashed), but were largely contained in the subspace spanned by the STC filters (<italic>right</italic>), as shown by comparing to their projections into the STC subspace (dashed black). Note that there was not enough data to estimate 2-D nonlinearities for the spiking data, and so no comparison of STC model performances could be made.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.007">http://dx.doi.org/10.7554/eLife.19460.007</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig2-figsupp1-v1"/></fig></fig-group></p><p>To capture the computations that could be performed by such suppressive mechanisms, we constructed a 'divisive suppression' (DivS) model (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, <italic>bottom left</italic>). Terms simulating bipolar cell excitation and suppression are each described by a separate LN model, with a multiplicative interaction between their outputs such that the suppression impacts bipolar cell release (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Note that the divisive gain control matches earlier models of both presynaptic inhibition (<xref ref-type="bibr" rid="bib55">Olsen and Wilson, 2008</xref>) and synaptic depression (<xref ref-type="bibr" rid="bib51">Markram et al., 1998</xref>). The suppressive term drops below one when the stimulus matches the suppressive filter, causing a proportional decrease in excitation of the ganglion cell. If the suppression does not contribute to the response, its nonlinearity would simply maintain a value of one, and the DivS model reduces to the LN model. The DivS model construction can be tractably fit to data using recent advances in statistical modeling (<xref ref-type="bibr" rid="bib3">Ahrens et al., 2008b</xref>; <xref ref-type="bibr" rid="bib52">McFarland et al., 2013</xref>).</p><p>The DivS model fits were highly consistent across the population, with similarly shaped excitatory and suppressive filters across cells (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). For each cell, the suppressive filter was delayed relative to the excitatory filter (10.9 ± 2.2 ms, p&lt;0.0005, <italic>n</italic> = 13, <xref ref-type="fig" rid="fig2">Figure 2C</xref>). The excitatory nonlinearity was approximately linear over the range of stimuli (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <italic>left</italic>), whereas the suppressive nonlinearity decreased below one when the stimulus either matched or was opposite to the suppressive filter (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <italic>right</italic>), resulting in ‘ON-OFF’ selectivity to both light increments and decrements.</p><p>The DivS model outperformed the LN model in predicting the observed currents (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). Furthermore, it performed as well or better than models with other nonlinear interactions between the two filters. We first tested a more general form of nonlinear interaction by directly estimating a two-dimensional nonlinear function based on the filters derived from the DivS model. This 2-D nonlinearity maps each combination of the excitatory and suppressive filter outputs to a predicted current (<xref ref-type="fig" rid="fig2">Figure 2F</xref>; see Materials and methods). While this 2-D model contains many more parameters than the DivS model, it did not perform significantly better (<xref ref-type="fig" rid="fig2">Figure 2E</xref>); indeed, the estimated 2-D nonlinearities for each neuron were well approximated by the separable mathematical form of the DivS model (<italic>R</italic><sup>2</sup> for 2-D nonlinearity reconstruction = 0.94 ± 0.02; <xref ref-type="fig" rid="fig2">Figure 2G</xref>). We also tested an additive suppression (AddS) model, where suppression interacts with excitation additively (see Materials and methods). The AddS model had significantly worse predictive power than the DivS model (p&lt;0.0005, <italic>n</italic> = 13; <xref ref-type="fig" rid="fig2">Figure 2E</xref>) and less resemblance to the corresponding 2-D nonlinearities compared to the DivS model (p&lt;0.0005, <italic>n</italic> = 13; <xref ref-type="fig" rid="fig2">Figure 2G</xref>).</p><p>Finally, we compared the DivS model to a form of spike-triggered covariance (<xref ref-type="bibr" rid="bib28">Fairhall et al., 2006</xref>; <xref ref-type="bibr" rid="bib46">Liu and Gollisch, 2015</xref>; <xref ref-type="bibr" rid="bib33">Samengo and Gollisch, 2013</xref>) adapted to the continuous nature of the synaptic currents (see Materials and methods). This covariance analysis generated different filters than the DivS model (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), although both sets of filters were within the same subspace (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>; <xref ref-type="bibr" rid="bib52">McFarland et al., 2013</xref>), meaning that the covariance-based filters could be derived as a linear combination of the DivS filters and vice versa. Because the filters shared the same subspace, the 2-D nonlinear mapping that converts the filter output to a predicted current had roughly the same performance as the 2-D model based on the DivS filters (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). However, because the covariance model used a different pair of filters (and in particular the DivS filters are not orthogonal), its 2-D mapping differed substantially from that of the DivS model. Consequently, the 2-D mapping for the STC analysis, unlike the DivS analysis, could not be decomposed into two 1-D components (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). Thus, despite the ability of covariance analysis to nearly match the DivS model in terms of model performance (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), it could not reveal the divisive interaction between excitation and suppression.</p><p>The DivS model therefore provides a parsimonious description of the nonlinear computation at the bipolar-ganglion cell synapse and yields interpretable model components, suggesting an interaction between tuned excitatory and suppressive elements. As we demonstrate below, the correspondingly straightforward divisive interaction detected by the DivS model on the ganglion cell synaptic input is essential in deriving the most accurate model of ganglion cell output, which combines this divisive interaction with subsequent nonlinear components related to spike generation.</p></sec><sec id="s2-3"><title>Divisive suppression explains contrast adaptation in synaptic currents</title><p>In addition to nearly perfect predictions of excitatory current at high contrast (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="fig" rid="fig3">Figure 3C</xref>), the DivS model also predicted the time course of the synaptic currents at low contrast. Indeed, using a single set of parameters, the model was similarly accurate in both contrast conditions (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), and outperformed an LN model that used separate filters fit to each contrast level (e.g., <xref ref-type="fig" rid="fig1">Figure 1E</xref>). The DivS model thus implicitly adapts to contrast with no associated changes in parameters.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.008</object-id><label>Figure 3.</label><caption><title>DivS model explains temporal precision and contrast adaptation in synaptic currents.</title><p>(<bold>A</bold>) The predictive power of models across contrasts. The DivS model is fit to both contrasts using a single set of parameters, and outperforms LN models fit separately to either high or low contrast (LN-H and LN-L). As expected, the LN model fit for both contrasts (LN-HL) performs worse than separately fit LN models, because the LN-HL model cannot capture the filter changes without changes in model parameters. (<bold>B</bold>) Average coherence between model predictions and recorded synaptic currents on individual trials (<italic>n</italic> = 13), shown for high contrast (HC) and low contrast (LC). The DivS model prediction performs almost identically to the trial-averaged response. (<bold>C</bold>) DivS model explains precision and contrast adaptation through the interplay of excitation and suppression. <italic>Top</italic>: comparison of predictions of synaptic current response of the LN model and the DivS model for the cell in <xref ref-type="fig" rid="fig1">Figure 1.</xref> <italic>second row</italic>: normalized output of the excitatory and delayed suppressive filter. <italic>3rd row</italic>: suppressive modulation obtained by passing the filtered output through the suppressive nonlinearity (<italic>middle inset</italic>). <italic>Bottom</italic>: excitatory output of the DivS model before and after the suppressive modulation. In LC, the suppressive term (<italic>third row</italic>) does not deviate much from unity, and consequently the DivS model output resembles the excitatory input. (<bold>D</bold>) Comparison of the measured (<italic>left</italic>) and DivS model predicted (<italic>right</italic>) LN models across contrast. (<bold>E</bold>) The LN analysis applied to the DivS model predictions captures changes of both contrast gain (<italic>left: R</italic> = 0.96, p&lt;10<sup>–6</sup>) and biphasic index (<italic>right: R</italic> = 0.86, p&lt;0.0005) of the temporal filters across contrasts. (<bold>F</bold>) The DivS models predict the changes in tonic offset without any additional parameter shifts (<italic>R</italic> = 0.90, p&lt;10<sup>–4</sup>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.008">http://dx.doi.org/10.7554/eLife.19460.008</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig3-v1"/></fig></p><p>The adaptation of the DivS model arises from the scaling of the divisive term with contrast. The fine temporal features in the synaptic currents observed at high contrast (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, <italic>left</italic>) arise from the product of the output of the excitatory LN component and the output of the suppressive LN component. Because suppression is delayed relative to the excitation and has both ON and OFF selectivity, suppression increases at both positive and negative peaks of the suppressive filter output (<xref ref-type="fig" rid="fig3">Figure 3C</xref> <italic>inset</italic>). This divisive suppression makes the DivS model output more transient compared to its excitatory component output alone; the difference between the two predictions is pronounced surrounding the times of peak excitation. At low contrast (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, <italic>right</italic>), both excitatory and suppressive filter outputs are proportionately scaled down. Because the suppression is divisive and close to one, the DivS model becomes dominated by the excitatory term and closely matches the LN model, as well as the measured excitatory current.</p><p>The close match between data and DivS predictions across contrast levels suggests that the DivS model should exhibit contrast adaptation, as measured by the LN model filters (<italic>e.g.</italic>, <xref ref-type="fig" rid="fig1">Figure 1E</xref>). Indeed, using LN analysis to describe the DivS-model-predicted currents across contrast shows that the changes in filtering properties predicted by the DivS model were tightly correlated with those from the measured data (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), including changes in contrast gain and biphasic index (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Furthermore, a small tonic offset of the synaptic currents across contrast levels (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), which resulted in a vertical shift in the nonlinearity of the LN model (<xref ref-type="fig" rid="fig1">Figure 1E</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), was captured by the DivS model without any parameter changes (<xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p></sec><sec id="s2-4"><title>Divisive suppression largely originates from the surround region of the receptive field</title><p>The mathematical form of the DivS model (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) is consistent with two pre-synaptic mechanisms that shape temporal processing: synaptic depression (<xref ref-type="bibr" rid="bib38">Jarsky et al., 2011</xref>; <xref ref-type="bibr" rid="bib56">Ozuysal and Baccus, 2012</xref>) and presynaptic inhibition (<xref ref-type="bibr" rid="bib26">Eggers and Lukasiewicz, 2011</xref>; <xref ref-type="bibr" rid="bib67">Schubert et al., 2008</xref>). Indeed, a model of ganglion cells that explicitly implements synaptic depression, the linear-nonlinear-kinetic model (LNK model) (<xref ref-type="bibr" rid="bib56">Ozuysal and Baccus, 2012</xref>) can also predict the temporal features of ganglion cell intracellular recordings across contrast. The LNK model fits a single LN filter (analogous to the excitatory <bold>k</bold><italic><sub>E</sub></italic> and <italic>f<sub>E</sub></italic>(.) of the DivS model; <xref ref-type="fig" rid="fig2">Figure 2A</xref>), with additional terms that simulate use-dependent depletion of output (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). This depletion depends on the previous output of the model (recovering over one or more time scales), and divisively modulates the output of the LN filter. For our data, the LNK model captured excitatory currents in response to the temporally modulated spot (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), also outperforming the LN model (p&lt;0.0005, <italic>n</italic> = 13), although not with the level of performance as the DivS model (p&lt;0.0005, <italic>n</italic> = 13). Furthermore, when data were generated de novo by an LNK model simulation, the resulting DivS model fit showed a delayed suppressive term, whose output well approximated the effect of synaptic depression in the LNK model (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.009</object-id><label>Figure 4.</label><caption><title>Probing the mechanism of divisive suppression with center-surround stimuli.</title><p>(<bold>A</bold>) For the large spot stimulus, the Linear-Nonlinear-Kinetic (LNK) model nearly matches the performance of the DivS model, and outperforms the LN model. (<bold>B</bold>) To distinguish between different sources of divisive suppression, we presented a spot-annulus stimulus (<italic>left</italic>), where each region is independently modulated. Model filters can be extended to this stimulus using a separate temporal kernel for center and surround, shown for the LN and LNK model filters (<italic>right</italic>), which are very similar. (<bold>C</bold>) After the linear filter, the LNK model applies a nonlinearity (<italic>left</italic>), whose output drives the transition between resting and activated states (<italic>middle</italic>), which is further governed by kinetics parameters as shown. Critical kinetics parameters for LNK models differed between the large-spot and spot-annulus stimulus (<italic>right</italic>), with the spot-annulus model very quickly transitioning from Inactive back to Active states, minimizing the effects of synaptic depression. (<bold>D</bold>) The performance of the spatiotemporal LNK model is only slightly better than that of the LN model, and neither captures the details of the modulation in synaptic current, compared with the DivS model. (<bold>E</bold>) The spatiotemporal DivS model shown for an example neuron exhibits different spatial footprints for excitation and suppression, with excitation largely driven by the spot and suppression by the annulus. This divisive suppression cannot be explained exclusively by synaptic depression, which predicts overlapping sources of suppression and excitation (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>). (<bold>F</bold>) The contribution of the center component in the DivS model for excitation (<italic>left</italic>) and suppression (<italic>right</italic>). Excitation was stronger in the center than in the surround (center contribution&gt;0.5, p=0.016, <italic>n</italic> = 7) and suppression was weaker in the center (center contribution&lt;0.5, p=0.016, <italic>n</italic> = 7) for every neuron. (<bold>G</bold>) The DivS model captured temporal transients in the current response to spot-annulus stimuli better than the LN and LNK models.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.009">http://dx.doi.org/10.7554/eLife.19460.009</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig4-v1"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19460.010</object-id><label>Figure 4—figure supplement 1.</label><caption><title>DivS model localizes the suppressive components of LNK model and reproduces its simulated response.</title><p>We simulated LNK models resembling the example neurons considered in <xref ref-type="fig" rid="fig4">Figure 4.</xref> (<bold>A</bold>–<bold>D</bold>) LNK simulation in response to a temporally modulated spot. (<bold>A</bold>) The LNK model components consist of a temporal filter <bold>k</bold> (<italic>left</italic>) and static nonlinearity <italic>f</italic>(∙) (<italic>middle</italic>), whose output <italic>u</italic>(<italic>t</italic>)=<italic>f</italic>[<bold>k</bold>∙<bold>s</bold>(<italic>t</italic>)] governs the transition rate between the resting (R) and active (A) states. The current output is proportional to active state occupation, and other constants govern the transition to inactive (I) state and back to resting state. The parameters for this LNK simulation were derived from an LNK fit to an example neuron (see Materials and methods). (<bold>B</bold>) A DivS model was fit to the LNK model simulated response, with components labeled as in <xref ref-type="fig" rid="fig2">Figure 2.</xref> The temporal filter of suppression (cyan) is delayed relative to the excitation (<italic>left</italic>) and only results in suppression for ON stimuli, as expected given its relationship to synaptic depression. (<bold>C</bold>) Model performance (<italic>R</italic><sup>2</sup>) for the LN model and DivS model across all neurons demonstrates that the DivS model could reproduce LNK simulations with greater than 90% accuracy, across simulations of all LNK models of recorded neurons (<italic>n </italic>= 13). (<bold>D</bold>) Simulated response of the LNK model in (A) in response to a temporal modulated spot stimulus (<italic>top</italic>). <italic>2nd row</italic>: The output of the LNK simulation (black) could be reproduced better by a DivS model (red) fit to the simulated data, as compared to the LN model (blue). <italic>3rd row</italic>: The occupation of each internal state determined the current output in addition to the output of the LN component of the model. <italic>4th row</italic>: The dynamics of the divisive suppression of the DivS model (cyan) roughly matched the occupation of the resting state of the LNK model (<italic>3rd row</italic>, green): the resting state occupancy (and availability for transition to the active state and resulting current output in the LNK model) was low at the same times there is suppression in the DivS model. (<bold>E</bold>–<bold>G</bold>) LNK simulation in response to the spot-annulus stimulus. (<bold>E</bold>) LNK components are labeled identically as in (<bold>A</bold>), but now the filter <bold>k</bold> consists of separate components for the spot (<italic>left</italic>, solid) and annulus (dashed) regions of the stimulus. The temporal filter and nonlinearity were derived from the example cell in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, but the kinetics parameters of the temporally modulated stimulus (<bold>A</bold>) were used in place of those derived for the spot-annulus stimuli, because the latter parameters did not result in nonlinear effects. (<bold>F</bold>) A DivS model fitted to the LNK model simulated response, with components labeled as in <xref ref-type="fig" rid="fig2">Figure 2</xref>, resulting in the expected delayed ON suppression (as with the temporally modulated spot simulations in <bold>B</bold>). (<bold>G</bold>) Simulated response using the LNK model with the spot-annulus stimulus, again with the divisive suppression of the DivS model (<italic>4th row</italic>, cyan) capturing the occupancy of resting state of the LNK model (<italic>3rd row</italic>, green).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.010">http://dx.doi.org/10.7554/eLife.19460.010</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig4-figsupp1-v1"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.19460.011</object-id><label>Figure 4—figure supplement 2.</label><caption><title>DivS model descriptions of extended LNK models.</title><p>Here we consider additional model structures involving synaptic depression. The simulations here incorporate nonlinear rectified subunits, and were limited to two components corresponding to those independently modulated in the stimulus: spot and annulus. (<bold>A–D</bold>) First we considered an extended LNK model with independent stimulus processing of the spot and annulus stimuli, and a shared synaptic depression stage. (<bold>A</bold>) Model schematic, showing that the separate 'center' and 'surround' components (corresponding to spot and annulus stimuli) are each rectified before being combined, and fed into the LNK model for synaptic depression, using the same kinetic parameters considered for simulations in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. Simulated data were generated for a range of models of this form, where the weight for the ‘spot’ component <italic>w<sub>spot</sub></italic> was fixed and the annulus component weight <italic>w<sub>annu</sub></italic> was varied. (<bold>B</bold>) The DivS model components fit to an example simulated response of the extended LNK model (with <italic>w<sub>spot</sub> </italic>= <italic>w<sub>annu</sub></italic>). As with simpler circuits (e.g., <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), suppression was delayed relative to excitation. Note that the DivS model was limited to only a single rectified component to match the form used to describe experiments described in <xref ref-type="fig" rid="fig4">Figure 4</xref>. (<bold>C</bold>) The performance of the LN (red) and DivS (purple) models across simulations with different annulus component weights. The DivS model performance was significantly better than that of the LN model over a wide range of parameters (each point corresponds to the results of simulation with different choice of <italic>w<sub>annu</sub></italic>), suggesting a large portion of the synaptic depression effect was captured by the DivS model. Note, however, that the DivS model has a more difficult time explaining this [simulated] data than the data from real ON-Alpha ganglion cells (i.e., <xref ref-type="fig" rid="fig4">Figure 4D</xref>). (<bold>D</bold>) For all simulations, the 'spatial profile' of suppression matched that of excitation, as measured by the 'center fraction', which was given by the norm of the center component of the filter divided by the norm of the full filter. [The center fraction is one for no surround component, and zero for no center component.] (<bold>E</bold>–<bold>H</bold>) We next considered an extended LNK model with both independent stimulus processing and independent kinetics. (<bold>E</bold>) Model schematic, showing the separate center and surround components each with independent synaptic depression — again with the same kinetic parameters previously considered. (<bold>F</bold>) The DivS model components fit to an example simulated response of the extended LNK model (with <italic>w<sub>spot</sub> </italic>= <italic>w<sub>annu</sub></italic>). (<bold>G</bold>) Performance of DivS model and LN model on simulated LNK model response. (<bold>H</bold>) Tight correlation of the center fractions of excitation versus divisive suppression of the DivS model components (as in panel <bold>D</bold>). This and related simulations (i.e., with additional center-surround filtering prior to the rectification stage) involving synaptic depression never yielded a case where DivS excitation was largely from the center and suppression was largely from the surround, which was observed in the real ON-Alpha cell data (e.g., <xref ref-type="fig" rid="fig4">Figure 4E</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.011">http://dx.doi.org/10.7554/eLife.19460.011</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig4-figsupp2-v1"/></fig></fig-group></p><p>The DivS and LNK models, however, yielded distinct predictions to a more complex stimulus where a central spot and surrounding annulus were modulated independently (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). The models described above were extended to this stimulus by including two temporal filters, one for the center and one for the surround. As expected from the center-surround structure of ganglion cell receptive fields, an LN model fit to this condition demonstrated strong ON-excitation from the center, and a weaker OFF component from the surround (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p><p>The 'spatial' LNK model’s filter resembled that of the LN model (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Consistent with this resemblance to the LN Model, the spatial LNK model had rate constants that minimized the time that the model dwelled in the inactivated state (i.e., was 'suppressed') (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). These rate constants were significantly different from those of the LNK model fit to the single temporally modulated spot. Correspondingly, the LNK model in the spot-annulus condition exhibited little performance improvement over the LN model (predictive power improvement 1.8% ± 1.3%, p=0.016, <italic>n = 7</italic>; <xref ref-type="fig" rid="fig4">Figure 4D</xref>).</p><p>By comparison, the DivS model significantly outperformed the LN model with an improvement of 8.6% ± 3.3% (p=0.016; <italic>n </italic>= 7), and was 6.7 ± 2.8% better than the LNK model (p=0.016; <italic>n </italic>= 7). The suppressive term of the DivS model showed a very distinct spatial profile relative to excitation, with a greater drive from the annulus region, while excitation was mostly driven by the spot region (<xref ref-type="fig" rid="fig4">Figure 4E,F</xref>). The suppressive filter processing the spot region was typically slower than the annulus filter: the peak latency for the suppressive filter was 129 ± 16 ms within the spot region compared to 120 ± 15 ms within the annulus region (faster by 9.7 ± 4.3 ms; p=0.0156, <italic>n </italic>= 7).</p><p>The strong suppression in the surround detected by the DivS model could not be explained by the LNK model, which cannot flexibly fit an explicit suppressive filter. Indeed, suppression in the LNK model arises from excitation, and thus the two components share the same spatial profile (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>). This can be demonstrated not only with simulations of the LNK model, but also more complex models with separate synaptic depression terms in center and surround (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). In all cases, application of the DivS model to data generated by these synaptic-depression-based simulations revealed that the suppressive term roughly matched the spatial profile of excitation, which is inconsistent with the observed data (<xref ref-type="fig" rid="fig4">Figure 4F</xref>). While these analyses do not eliminate the possibility that synaptic depression plays a role in shaping the ganglion cell response (and contributing to the suppression detected by the DivS model), the strength of surround suppression detected by the DivS model suggests that synaptic depression alone cannot fully describe our results.</p></sec><sec id="s2-5"><title>Nonlinear mechanisms underlying the spike output of ganglion cells</title><p>With an accurate model for excitatory synaptic currents established, we returned to modeling the spike output of ON-Alpha cells. Following previous likelihood-based models of ganglion cell spikes, we added a spike-history term, which implements absolute and relative refractory periods (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>; <xref ref-type="bibr" rid="bib52">McFarland et al., 2013</xref>; <xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>; <xref ref-type="bibr" rid="bib60">Pillow et al., 2005</xref>). The output of this spike-history term is added to the output of the DivS model for the synaptic currents, and this sum is further processed by a spiking nonlinearity (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) to yield the final predicted firing rate. Using a standard likelihood-based framework, all terms of the model – including the excitatory and suppressive LN models that comprised the prediction of synaptic currents – can then be tractably fit using spike data alone. But it is important to note that this model architecture was only made clear via the analyses of synaptic currents described above.<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.012</object-id><label>Figure 5.</label><caption><title>The extended divisive suppression model explains ganglion cell spike trains with high precision.</title><p>(<bold>A</bold>) Model schematic for the divisive suppression model of spiking, which extends DivS model for the current data by adding an additional suppressive term for spike-history (refractoriness), with the resulting sum passed through a rectifying spiking nonlinearity. (<bold>B</bold>–<bold>E</bold>) The model components for the same example neuron considered in <xref ref-type="fig" rid="fig1">Figures 1</xref>–<xref ref-type="fig" rid="fig3">3</xref>. (<bold>B</bold>) The excitatory and suppressive filters. (<bold>C</bold>). The excitatory and suppressive nonlinearities. The filters and nonlinearities were similar to the DivS model fit from current data (shown in <xref ref-type="fig" rid="fig2">Figure 2B</xref>). (<bold>D</bold>) The spike-history term, demonstrating an absolute and relative refractory period. (<bold>E</bold>) The spiking nonlinearity, relative to the distribution of generating signals (shaded). (<bold>F</bold>). The predictive power of different models applied to the spike data in HC and LC. The DivS model performs better than other models (HC: p&lt;0.001; LC: p&lt;0.002, <italic>n </italic>= 11), including the LN model, the LN model with spike history term (LN+RP), and a divisive suppression model lacking spike refractoriness (DivS-RP). Only a single set of parameters was used to fit the DivS model for both contrasts, whereas all other models shown used different parameters fit to each contrast.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.012">http://dx.doi.org/10.7554/eLife.19460.012</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig5-v1"/></fig></p><p>When fit using spiking data alone, the resulting excitatory and suppressive filters and nonlinearities closely resembled those found when fitting the model to the synaptic currents recorded from the same neurons (e.g., <xref ref-type="fig" rid="fig2">Figure 2B,D</xref>). Suppression was consistently delayed relative to excitation (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), and exhibited both ON and OFF selectivity (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). The spike-history term was suppressive and had two distinct components, a strong absolute refractory period that lasted 1–2 ms and a second relative refractory period that lasted more than 15 ms (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>; <xref ref-type="bibr" rid="bib40">Keat et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>; <xref ref-type="bibr" rid="bib60">Pillow et al., 2005</xref>).</p><p>The resulting model successfully captured over 90% of the predictable variance in the firing rate for all neurons in the study (<xref ref-type="fig" rid="fig5">Figure 5F</xref>, median = 91.5% ± 1.0%; <italic>n </italic>= 11), representing the best model performance reported in the literature for ganglion cell spike trains considered at millisecond resolution. By comparison, the standard LN model had a median predictive power of 62.8% ± 1.9% (<italic>n </italic>= 11); which modestly increased to 68.8% ± 1.9% upon inclusion of a spike-history term (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). This suggests that ganglion cell spikes are strongly shaped by the nonlinear computations present at their synaptic input, and that the precise timing of ganglion cell spiking involves the interplay of divisive suppression with spike-generating mechanisms.</p></sec><sec id="s2-6"><title>Precision of spike trains arises from complementary mechanisms of divisive suppression and spike refractoriness</title><p>To evaluate the relative contributions of divisive suppression and spike refractoriness to predicting firing, we simulated spike trains using different combinations of model components (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). We found that the parameters of the divisive suppression components could not fit without including a spike-history term, suggesting that each component predicts complementary forms of suppression. We could generate a DivS model without a spike-history term, however, by first determining the full model (with spike-history term), and then removing the spike-history term and refitting (see Materials and methods), resulting in the DivS–RP model. This allowed for direct comparisons between models with a selective deletion of either divisive suppression or spike refractoriness (<xref ref-type="fig" rid="fig6">Figure 6A</xref>).<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.013</object-id><label>Figure 6.</label><caption><title>Spike patterning is shaped by a combination of nonlinear mechanisms.</title><p>(<bold>A</bold>) <italic>Top</italic>: Spike rasters recorded over ten repeats for an example cell (black) compared with simulated spikes from four models: LN, LN model with spike-history term (LN+RP), the DivS model without spike-history (DivS-RP), and the full DivS model (DivS). Colors in the raster label separate spike events across trials (see Materials and methods). <italic>Bottom</italic>: The PSTHs for each model demonstrate that suppressive terms are important in shaping the envelope of firing (DivS prediction is shaded). (<bold>B</bold>–<bold>E</bold>) Using event labels, spike statistics across repeats were compiled to gauge the impact of different model components. (<bold>B</bold>) The temporal properties of events compared with model predictions, across contrast (same as <xref ref-type="fig" rid="fig1">Figure 1</xref>, with DivS-based models added). Both spike-history and divisive suppression contribute to reproduce the temporal scales across contrast. (<bold>C</bold>) The Fano factor for each event is a measure of reliability, which increased (i.e., Fano factor decreased) for models with a spike-history term.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.013">http://dx.doi.org/10.7554/eLife.19460.013</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig6-v1"/></fig></p><p>Event analyses on the resulting simulated spike trains, compared with the observed data, demonstrate that both divisive suppression (derived from the current analyses above) and spike refractoriness were necessary to explain the precision and reliability of ganglion cell spike trains. By comparing the two models without DivS (LN and LN+RP) to those with DivS (DivS and DivS–RP), it is clear that divisive suppression is necessary to predict the correct envelope of the firing rate (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Note, however, that DivS had little impact in the low contrast condition, which lacked fine-time-scale features of the spike response.</p><p>By comparison, the spike-history term had little effect on the envelope of firing (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, <italic>bottom</italic>), and contributed little to the fine time scales in the ganglion cell spike train at high contrast (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Instead, the spike-history term had the largest effect on accurate predictions of event reliability, as reflected in the event Fano factor (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). By comparison, both models without the spike-history term had much greater variability in spike counts within each event. The presence of the suppression contributed by the spike-history term following each event allows the predicted firing rate to be much higher (and more reliable) during a given event, resulting in reliable patterns of firing within each event (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) (<xref ref-type="bibr" rid="bib60">Pillow et al., 2005</xref>).</p><p>We conclude that a two-stage computation present in the spike-DivS model, with both divisive suppression and spike refractoriness, is necessary to explain the detailed spike patterning on ON-Alpha ganglion cells.</p></sec><sec id="s2-7"><title>Enhancement of contrast adaptation via spike refractoriness in ganglion cell output</title><p>In addition to accurate reproduction of precise spike outputs of ganglion cells, the DivS model also captured the effects of contrast adaptation observed in the ganglion cell spike trains. For both contrast conditions, the simulated spike trains, which are predicted for both contrasts using a single set of parameters, were almost indistinguishable from the data (<xref ref-type="fig" rid="fig7">Figure 7A</xref>, <italic>top</italic>). As with the performance of the models of excitatory current (<xref ref-type="fig" rid="fig3">Figure 3</xref>), the DivS model outperformed LN models that were separately fit for each contrast level (<xref ref-type="fig" rid="fig5">Figure 5F</xref>).<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.014</object-id><label>Figure 7.</label><caption><title>Contrast adaptation in the spike output depends on both divisive suppression and spike refractoriness.</title><p>(<bold>A</bold>) The full spike-DivS model accurately captured contrast adaptation. <italic>Top</italic>: observed PSTH and predicted firing rates of the DivS model at HC and LC. (<bold>B</bold>) The DivS model predicted the changes in LN filter shape and magnitude with contrast for an example cell. Predicted changes are shown for each model, demonstrating that the full effects of contrast adaptation require both divisive suppression and spike-history terms. (<bold>C</bold>) Measured and predicted contrast gain (<italic>top</italic>) and changes of biphasic index (<italic>bottom</italic>). The DivS model accurately predicted a contrast gain and changes biphasic index across contrast across cells (contrast gain: slope of regression = 0.75, <italic>R </italic>= 0.85, p&lt;0.001; biphasic index: slope of regression = 0.87, <italic>R </italic>= 0.87, p&lt;0.001). DivS model without the spike history term underestimated contrast adaptation (contrast gain: slope of regression = 0.53, <italic>R </italic>= 0.51, p = 0.10; biphasic index: slope of regression = 0.49, <italic>R </italic>= 0.73, p&lt;0.05), and the LN+RP model failed to predict adaptation altogether (contrast gain: slope of regression = 0.06, <italic>R </italic>= 0.28, p = 0.41; biphasic index: slope of regression = −0.07, <italic>R </italic>= −0.18, <italic>p </italic>= 0.60). (<bold>D</bold>) The suppressive effect from the spike-history term was amplified at HC, due to the increased precision of the spike train. Dashed lines show the onset of HC spike events, which predict the largest difference in the magnitudes of the suppression between contrasts.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.014">http://dx.doi.org/10.7554/eLife.19460.014</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-19460-fig7-v1"/></fig></p><p>The ability to correctly predict the effects of contrast adaptation depended on both the divisive suppression and spike-refractoriness of the spike-DivS model. This is shown for an example neuron by using LN filters of the simulated output of each model at high and low contrasts (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). In this case, only the DivS model (which includes a spike-history term) shows adaptation similar to that observed by the LN filters fit to the data. We quantified this by identifying the most prominent feature of adaptation of the LN filters, the change in filter amplitude (i.e., contrast gain). Across the population, the DivS correctly predicted the magnitude of this change (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, <italic>top</italic>), as well as the changes in biphasic index across contrasts (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, <italic>bottom</italic>), and outperformed models with either the divisive suppression or spike-history terms missing.</p><p>As expected, spike refractoriness imparted by the spike-history term contributed to the stronger effects of contrast adaptation observed in spikes relative to synaptic inputs (<xref ref-type="bibr" rid="bib7">Beaudoin et al., 2007</xref>; <xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>, <xref ref-type="bibr" rid="bib43">2003</xref>; <xref ref-type="bibr" rid="bib63">Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib87">Zaghloul et al., 2005</xref>). Specifically, at high contrast, spikes concentrate into relatively smaller time windows, leading to a consistently timed effect of spike refractoriness (<xref ref-type="fig" rid="fig7">Figure 7D</xref>). As a result, despite similar numbers of spikes at the two contrasts, the effect of the spike-history term has a bigger impact at high contrast.</p><p>Thus, fast contrast adaptation – and more generally the temporal shaping of ON-Alpha ganglion cell spike trains – depends on nonlinear mechanisms at two stages of processing within the retinal circuit. Both aspects of nonlinear processing originate at the level of ganglion cell synaptic inputs, shaped by divisive suppression, and become amplified by spike-refractoriness to generate the array of nonlinear properties evident in the spike train output.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we derived a retina-circuit-inspired model for ganglion cell computation using recordings of both the synaptic inputs and spike outputs of the ON-Alpha ganglion cell. Data were used to fit model parameters and evaluate different hypotheses of how the retinal circuit processed visual stimuli. The resulting model explained both high precision firing and contrast adaptation with unprecedented accuracy. Precise timing was already present in the excitatory synaptic inputs, and can be explained by divisive suppression, which likely depends on a combination of mechanisms: presynaptic inhibition of bipolar terminals from amacrine cells and synaptic depression at bipolar cell synapses. The interplay between nonlinear mechanisms, including divisive suppression, spike refractoriness and spiking nonlinearity, accurately captured the detailed structure in the spike response across contrast levels.</p><p>Divisive suppression was implemented by multiplying two LN models together (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). One LN model controls the gain of a second LN model; the gain is equal to or less than one and so represents division. While divisive gain terms have been previously suggested in the retina – particularly in reference to early models of contrast adaptation (<xref ref-type="bibr" rid="bib50">Mante et al., 2008</xref>; <xref ref-type="bibr" rid="bib53">Meister and Berry, 1999</xref>; <xref ref-type="bibr" rid="bib72">Shapley and Victor, 1978</xref>), critical novel elements of the present DivS model include the ability to fit the nonlinearities of both LN terms by themselves, as well as their tractability in describing data at high time resolution. The presence of nonlinearities that are fit to data in the context of multiplicative interactions distinguishes this model from multi-linear models (i.e., two linear terms multiplying) (<xref ref-type="bibr" rid="bib2">Ahrens et al., 2008a</xref>; <xref ref-type="bibr" rid="bib86">Williamson et al., 2016</xref>), as well as more generalized LN models such as those associated with spike-triggered covariance (<xref ref-type="bibr" rid="bib28">Fairhall et al., 2006</xref>; <xref ref-type="bibr" rid="bib33">Samengo and Gollisch, 2013</xref>; <xref ref-type="bibr" rid="bib70">Schwartz et al., 2006</xref>). Furthermore the model form allows for inclusion of spike-history terms as well as spiking nonlinearities, and can be tractably fit to both synaptic currents and spikes at high temporal resolution (~1 ms).</p><p>An eventual goal of our approach is to characterize the nonlinear computation performed on arbitrarily complex spatiotemporal stimuli. Here, we focused on temporal stimuli, which drive well-characterized nonlinearities in ganglion cell processing including temporal precision (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib19">Butts et al., 2007</xref>; <xref ref-type="bibr" rid="bib40">Keat et al., 2001</xref>; <xref ref-type="bibr" rid="bib59">Passaglia and Troy, 2004</xref>; <xref ref-type="bibr" rid="bib81">Uzzell and Chichilnisky, 2004</xref>) and contrast adaptation (<xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib53">Meister and Berry, 1999</xref>; <xref ref-type="bibr" rid="bib72">Shapley and Victor, 1978</xref>) but do not require a large number of additional parameters to specify spatial tuning. By comparison, studies that focused on characterizing nonlinearities in spatial processing (<xref ref-type="bibr" rid="bib32">Freeman et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Gollisch, 2013</xref>; <xref ref-type="bibr" rid="bib68">Schwartz and Rieke, 2011</xref>) have not modeled responses at high temporal resolution. Ultimately, it will be important to combine these two approaches, to capture nonlinear processing within spatial ‘subunits’ of the ganglion cell receptive field, and thereby predict responses at both high temporal and spatial resolutions to arbitrary stimuli. Such an approach would require a large number of model parameters and consequently a larger amount of data than collected here. Our intracellular experiments were useful for deriving model architecture – discerning the different time courses of excitation, suppression, and spike refractoriness – but ultimate tests of full spatiotemporal models will likely require prolonged, stable recordings of spike trains, perhaps using a multielectrode array.</p><sec id="s3-1"><title>Generation of temporal precision in the retina</title><p>One important nonlinear response property of early sensory neurons is high temporal precision. Temporal precision of spike responses has been observed in the retinal pathway with both noise stimuli (<xref ref-type="bibr" rid="bib10">Berry et al., 1997</xref>; <xref ref-type="bibr" rid="bib62">Reinagel and Reid, 2000</xref>) and natural movies (<xref ref-type="bibr" rid="bib19">Butts et al., 2007</xref>). The precise spike timing suggests a role for temporal coding in the nervous system (<xref ref-type="bibr" rid="bib10">Berry et al., 1997</xref>), or alternatively simply suggests that analog processing in the retina must be oversampled in order to preserve information about the stimulus (<xref ref-type="bibr" rid="bib19">Butts et al., 2007</xref>). Temporal precision also plays an important role in downstream processing of information provided by ganglion cells (<xref ref-type="bibr" rid="bib77">Stanley et al., 2012</xref>; <xref ref-type="bibr" rid="bib80">Usrey et al., 2000</xref>).</p><p>The generation of temporal precision involves nonlinear mechanisms within the retina, which may include both spike-refractoriness within ganglion cells (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>; <xref ref-type="bibr" rid="bib40">Keat et al., 2001</xref>; <xref ref-type="bibr" rid="bib60">Pillow et al., 2005</xref>) and the interplay of excitation and inhibition (<xref ref-type="bibr" rid="bib5">Baccus, 2007</xref>; <xref ref-type="bibr" rid="bib16">Butts et al., 2016</xref>; <xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>). Such distinct mechanisms contributing to ganglion cell computation are difficult to distinguish using recordings of the spike outputs alone, which naturally reflect the total effects of all upstream mechanisms. By recording at two stages of the ganglion cell processing, we demonstrated that high temporal precision has already presented in the synaptic current inputs at high contrast, and temporal precision of both current inputs and spike outputs can be accurately explained by the DivS model.</p><p>The DivS model explained fast changes in the response through the interplay of excitation and suppression. For both the spike and current models, suppression is consistently delayed relative to excitation. The same suppression mechanism also likely underlies high temporal precision of LGN responses, which can be captured by a model with delayed suppression (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>). Indeed, recordings of both LGN neurons and their major ganglion cell inputs suggest that precision of LGN responses is inherited from the retina and enhanced across the retinogeniculate synapse (<xref ref-type="bibr" rid="bib16">Butts et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Carandini et al., 2007</xref>; <xref ref-type="bibr" rid="bib22">Casti et al., 2008</xref>; <xref ref-type="bibr" rid="bib61">Rathbun et al., 2010</xref>; <xref ref-type="bibr" rid="bib84">Wang et al., 2010b</xref>). Therefore, our results demonstrate that the temporal precision in the early visual system likely originates from nonlinear processing in the inputs to retinal ganglion cells. Note that the full spiking-DivS model did not incorporate any form of direct synaptic inhibition onto the ON-Alpha cell, consistent with findings that the impact of such inhibition is relatively weak and that excitation dominates the spike response in the stimulus regime that we studied (<xref ref-type="bibr" rid="bib45">Kuo et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Murphy and Rieke, 2006</xref>).</p><p>Our results show that the contribution of spike-history term to precision – as measured by the time scale of events and first-spike jitter – seems minor, consistent with earlier studies in the LGN (<xref ref-type="bibr" rid="bib16">Butts et al., 2016</xref>; <xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>). Nevertheless, the spike-history term does play an important role in spike patterning within the event (<xref ref-type="bibr" rid="bib60">Pillow et al., 2005</xref>) and the resulting neuronal reliability (<xref ref-type="bibr" rid="bib9">Berry and Meister, 1998</xref>). In fact, we could not fit the divisive suppression term robustly without the spike-history term in place, suggesting that both nonlinear mechanisms are important to explain the ganglion cell firing.</p></sec><sec id="s3-2"><title>Contrast adaptation relies on both divisive suppression and spike refractoriness</title><p>Here we modeled contrast adaptation at the level of synaptic currents and spikes from the same ganglion cell. We found contrast adaptation in synaptic inputs to ganglion cells, consistent with previous studies (<xref ref-type="bibr" rid="bib7">Beaudoin et al., 2007</xref>; <xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib63">Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib87">Zaghloul et al., 2005</xref>). Such adaptation could be explained by divisive suppression, which takes a mathematical form similar to previously proposed gain control models (<xref ref-type="bibr" rid="bib36">Heeger, 1992</xref>; <xref ref-type="bibr" rid="bib73">Shapley and Victor, 1979</xref>). Because the suppressive nonlinearity has a very different shape than the excitatory nonlinearity, divisive suppression has a relatively strong effect at high contrast and results in a decrease in measured gain. Moreover, the same divisive suppression mechanism may also explain nonlinear spatial summation properties of ganglion cells (<xref ref-type="bibr" rid="bib73">Shapley and Victor, 1979</xref>), because suppression generally has broader spatial profiles than excitation.</p><p>Contrast adaptation is amplified in the spike outputs mostly due to spike refractoriness and changes of temporal precision across contrast. At high contrast, the response had higher precision and occurred within shorter event windows (<xref ref-type="bibr" rid="bib17">Butts et al., 2010</xref>). As a result, the accumulated effect of spike refractoriness was stronger within each response event. Note that the effect of the spike-history term was highly dependent on the ability of the model to predict fine temporal precision at high contrast, which largely originates from the divisive suppression term as discussed earlier. Therefore, the two nonlinear properties of retinal processing, contrast adaptation and temporal precision, are tightly related and can be simultaneously explained by the DivS model.</p></sec><sec id="s3-3"><title>Circuits and mechanisms underlying the divisive suppression</title><p>Divisive suppression has been observed in the invertebrate olfactory system (<xref ref-type="bibr" rid="bib55">Olsen and Wilson, 2008</xref>), the lateral geniculate nucleus (<xref ref-type="bibr" rid="bib11">Bonin et al., 2005</xref>), the primary visual cortex (<xref ref-type="bibr" rid="bib36">Heeger, 1992</xref>), and higher visual areas such as area MT (<xref ref-type="bibr" rid="bib75">Simoncelli and Heeger, 1998</xref>). A number of biophysical and cellular mechanisms for divisive suppression have been proposed, including shunting inhibition (<xref ref-type="bibr" rid="bib1">Abbott et al., 1997</xref>; <xref ref-type="bibr" rid="bib20">Carandini et al., 1997</xref>; <xref ref-type="bibr" rid="bib34">Hao et al., 2009</xref>), synaptic depression (<xref ref-type="bibr" rid="bib1">Abbott et al., 1997</xref>), presynaptic inhibition (<xref ref-type="bibr" rid="bib55">Olsen and Wilson, 2008</xref>; <xref ref-type="bibr" rid="bib89">Zhang et al., 2015</xref>) and fluctuation in membrane potential due to ongoing activity (<xref ref-type="bibr" rid="bib29">Finn et al., 2007</xref>).</p><p>We evaluated different mechanistic explanations of the divisive suppression identified in this study. Divisive suppression underlying synaptic inputs to ganglion cells cannot be attributed to fluctuations in membrane potential or shunting inhibition since we recorded synaptic currents under voltage-clamp conditions that minimize inhibitory inputs. Although synaptic depression could also explain fast transient responses and contrast adaptation (<xref ref-type="bibr" rid="bib56">Ozuysal and Baccus, 2012</xref>), synaptic depression will generally result in excitation and suppression that have the same spatial profiles (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>), whereas we show that excitation and suppression have distinct spatial profiles (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Therefore, the divisive suppression in our model likely depends partly on presynaptic inhibition from amacrine cells, which can extend their suppressive influence laterally (<xref ref-type="bibr" rid="bib27">Euler et al., 2014</xref>; <xref ref-type="bibr" rid="bib31">Franke et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Schubert et al., 2008</xref>). This was somewhat surprising, because earlier studies had shown that contrast adaptation persisted in the presence of inhibitory receptor antagonists, suggesting that adaptation depended primarily on mechanisms intrinsic to the bipolar cell (e.g., synaptic depression), independent of synaptic inhibition (<xref ref-type="bibr" rid="bib7">Beaudoin et al., 2007</xref>; <xref ref-type="bibr" rid="bib14">Brown and Masland, 2001</xref>; <xref ref-type="bibr" rid="bib63">Rieke, 2001</xref>). Indeed, synaptic depression was likely the primary mechanism for adaptation in conditions with inhibition blocked, but the present results suggest that lateral inhibitory mechanisms also play a role in generating adaptation under conditions with inhibition intact, at least for some retinal circuits.</p><p>Models for contrast adaptation based on synaptic depression rely on a change in the average level of synaptic activity with contrast. This condition is met for synapses with lower rates of tonic release (<xref ref-type="bibr" rid="bib38">Jarsky et al., 2011</xref>). However, the ON-Alpha cell receives a relatively high rate of tonic release from presynaptic type 6 bipolar cells (<xref ref-type="bibr" rid="bib12">Borghuis et al., 2013</xref>; <xref ref-type="bibr" rid="bib69">Schwartz et al., 2012</xref>). Consequently, the average excitatory synaptic input would change less during contrast modulation compared to a ganglion cell that received a lower rate of glutamate release. An inhibitory mechanism for contrast adaptation thus may play a relatively prominent role for retinal circuits, such as the ON-Alpha cell, driven by high rates of glutamate release.</p><p>Detailed anatomical studies suggest that each ganglion cell type receives inputs from a unique combination of bipolar and amacrine cell types, contributing to a unique visual computation (<xref ref-type="bibr" rid="bib6">Baden et al., 2016</xref>). By focusing on a single cell type, the ON-Alpha cell, we identified a particular computation consistent across cells. We expect that other ganglion cell types will perform different computations, and likewise have different roles in visual processing. This could include additional contrast-dependent mechanisms, including slow forms of adaptation (<xref ref-type="bibr" rid="bib4">Baccus and Meister, 2002</xref>; <xref ref-type="bibr" rid="bib49">Manookin and Demb, 2006</xref>), sensitization (<xref ref-type="bibr" rid="bib39">Kastner and Baccus, 2014</xref>) and complex changes in filtering (<xref ref-type="bibr" rid="bib46">Liu and Gollisch, 2015</xref>). Thus, further applications of the approach described here will uncover a rich diversity of computation constructed by retinal circuitry to format information for downstream visual processing.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Neural recordings</title><p>Data were recorded from ON-Alpha ganglion cells from the in vitro mouse retina using the procedures described previously (<xref ref-type="bibr" rid="bib12">Borghuis et al., 2013</xref>; <xref ref-type="bibr" rid="bib85">Wang et al., 2011</xref>). Spikes were recorded in the loose-patch configuration using a patch pipette filled with Ames medium, and synaptic currents were recorded using a second pipette filled with intracellular solution (in mM): 110 Cs-methanesulfonate; 5 TEA-Cl, 10 HEPES, 10 BAPTA, 3 NaCl, 2 QX-314-Cl, 4 ATP-Mg, 0.4 GTP-Na<sub>2</sub>, and 10 phosphocreatine-Tris<sub>2</sub> (pH 7.3, 280 mOsm). Lucifer yellow was also included in the pipette solution to label the cell using a previously described protocol (<xref ref-type="bibr" rid="bib48">Manookin et al., 2008</xref>). The targeted cell was voltage clamped at <italic>E<sub>Cl</sub> </italic>(−67 mV) to record excitatory currents after correcting for the liquid junction potential (−9 mV). Cells in the ganglion cell layer with large somas (20–25 μm diameter) were targeted. Cells were confirmed to be ON-Alpha cells based on previously established criteria (<xref ref-type="bibr" rid="bib12">Borghuis et al., 2013</xref>): (1) an ON response; (2) high rate of spontaneous firing; and a high rate of spontaneous excitatory synaptic input; (3) a low input resistance (~40–70 MΩ). In some cases, we imaged the morphology of recorded cells and confirmed (4) a relatively wide dendritic tree (300–400 μm diameter) and (5) stratification on the vitreal side of the nearby ON cholinergic (starburst) amacrine cell processes.</p><p>We made recordings from 27 ON-Alpha cells total, each in one or more of the experimental conditions described. Of the 15 cells recorded in cell-attached configuration (spike recordings), 4 cells were excluded where low reliability across trials indicated an unstable recording, as indicated by much higher spike event Fano Factors (&gt;0.2, see below).</p><p>All procedures were conducted in accordance with National Institutes of Health guidelines under protocols approved by the Yale University Animal Care and Use Committee.</p></sec><sec id="s4-2"><title>Visual stimulation</title><p>The temporally modulated spot stimulus was described previously (<xref ref-type="bibr" rid="bib85">Wang et al., 2011</xref>). The retina was stimulated by UV LEDs (peak, 370 nm; NSHU-550B; Nichia America) to drive cone photoreceptors in the ventral retina. UV LEDs were diffused and windowed by an aperture in the microscope’s fluorescence port, with intensity controlled by <italic>pClamp 9</italic> software via a custom non-inverting voltage-to-current converter using operational amplifiers (TCA0372; ON Semiconductor). The stimulus was projected through a 4X objective lens (NA, 0.13). The stimulus was a flickering spot (1-mm diameter), with intensity generated from low pass Gaussian noise with a 30 Hz cutoff frequency. We used a contrast-switching paradigm (<xref ref-type="bibr" rid="bib4">Baccus and Meister, 2002</xref>; <xref ref-type="bibr" rid="bib42">Kim and Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib87">Zaghloul et al., 2005</xref>), in which the temporal contrast alternately stepped up or down every 10 s. The contrast of the stimulus is defined by the SD of the Gaussian noise and was either 0.3 times (high contrast) or 0.1 times (low contrast) the mean. Note that this is only a three-fold difference in contrast versus the seven-fold difference considered in <xref ref-type="bibr" rid="bib56">Ozuysal and Baccus (2012)</xref>, but sufficient to see clear contrast effects. The stimulus comprised 10 cycles of 10 s for each contrast. The first 7 s were unique in each cycle (used for fitting model parameters), and the last 3 s were repeated across cycles (used for cross-validation of model performance).</p><p>The center-surround stimuli (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) were generated in <italic>Matlab</italic> (Mathworks, Natick) using the <italic>Psychophysics Toolbox</italic> (<xref ref-type="bibr" rid="bib13">Brainard, 1997</xref>) and presented with a video projector (M109s DLP; Dell, or identical HP Notebook Companion; HP), modified to project UV light (single LED NC4U134A, peak wavelength 385 nm; Nichia) as previously described (<xref ref-type="bibr" rid="bib12">Borghuis et al., 2013</xref>). The center and surround stimuli were independently modulated with Gaussian noise (60-Hz update rate). A spot covered the receptive field center (e.g., 0.3 mm), and an annulus extended into the surround (e.g., inner/outer diameters of 0.35/1.0 mm). We recorded 7 ON-Alpha cells in this condition. For a subset of the recordings (<italic>n</italic>=5), we explored a range of inner/outer diameters, and selected the diameters that maximized the difference between the spatial footprints of excitatory and suppressive terms of the DivS model (see below).</p><p>The mean luminance of the stimulus was calculated to evoke ~4×10<sup>4</sup> photoisomerizations cone<sup>−1</sup> sec<sup>−1</sup>, under the assumption of a 1 μm<sup>2</sup> cone collecting area. For all methods of stimulation, the gamma curve was corrected to linearize output, and stimuli were centered on the cell body and focused on the photoreceptors. We verified that the relatively short stimulus presentation did not result in significant bleaching, as the response (and model parameters) had no consistent trends from the beginning of the experiment to the end (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>–<xref ref-type="fig" rid="fig1s2">2</xref>).</p></sec><sec id="s4-3"><title>Statistical modeling of the synaptic current response</title><p>We modeled the synaptic current response of neurons using the traditional linear-nonlinear (LN) cascade model (<xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>; <xref ref-type="bibr" rid="bib79">Truccolo et al., 2005</xref>), the Linear-Nonlinear-Kinetic model (<xref ref-type="bibr" rid="bib56">Ozuysal and Baccus, 2012</xref>), a 2-D nonlinear model (‘2-D’), and the Divisive Suppression model (‘DivS’) introduced in this paper.</p><p>In all cases (with the exception of the LN analyses of contrast adaptation effects described below), we optimized model parameters to minimize the mean-squared error (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) between the model-predicted and observed currents:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To limit the number of model parameters in the minimization of <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, we represented temporal filters by linear coefficients weighting a family of orthonormalized basis functions (<xref ref-type="bibr" rid="bib40">Keat et al., 2001</xref>):<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ζ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>π</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>=200 ms.</p><sec id="s4-3-1"><title>LN model</title><p>The LN model transforms the stimulus <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to the synaptic current response <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> using a linear filter <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and nonlinearity <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> such that:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a baseline offset. The filter <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was represented as a set of coefficients weighting the basis functions of <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>, and the nonlinearities were represented as coefficients weighting tent basis functions as previously described (<xref ref-type="bibr" rid="bib3">Ahrens et al., 2008b</xref>; <xref ref-type="bibr" rid="bib52">McFarland et al., 2013</xref>).</p></sec><sec id="s4-3-2"><title>2-D model</title><p>We generalized the LN model by incorporating a second filtered input, such that:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a two-dimensional nonlinearity, and <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denote the excitatory and suppressive filters respectively.</p><p>The 2-D nonlinearity was represented using piecewise planar surfaces and could be estimated non-parametrically for a given choice of filters (<xref ref-type="bibr" rid="bib78">Toriello and Velma, 2012</xref>). Specifically, we divided the 2-D space into a set of uniform squares, and then subdivided each square into two triangles. Each basis function was defined as a hexagonal pyramid function centered at one of the vertices, and the 2-D nonlinearity function was expressed as a combination of these bases:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the basis centered at the <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> grid vertex, and <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the corresponding weight coefficient, which was optimized by minimizing <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for a given choice of filters.</p><p>The coefficients for the filters and nonlinearities were optimized using block-coordinate descent: for a given choice of nonlinearity <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> the filters were optimized, and vice versa. In doing so, we introduced an additional constraint on the nonlinearity due to a degeneracy in the combined optimization of stimulus filters and 2-D nonlinearity. Specifically, one can choose a linear combination of the two stimulus filters and achieve the same model performance by refitting the 2-D nonlinearity. To alleviate this problem, we constrained the 2-D nonlinearity to be monotonically increasing along the first dimension, i.e.,<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi>F</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>≥</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∀</mml:mi><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-3-3"><title>DivS model</title><p>We derived the DivS model as a decomposition of the 2-D nonlinearity into two one-dimensional LN models that interact multiplicatively:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mtext> </mml:mtext><mml:mo>×</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We constrained the excitatory nonlinearity <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> to be monotonically increasing, and constrained the second nonlinearity <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> to be suppressive by bounding it between zero and one, with the value for zero input constrained to be one. We optimized the filters and the nonlinearities through block-coordinate descent until a minimum MSE was found. Because this optimization problem is in general non-convex (i.e., not guaranteed to have a single global minimum), we used standard approaches (<xref ref-type="bibr" rid="bib52">McFarland et al., 2013</xref>) such as testing a range of initialization and block-coordinate descent procedures to ensure that global optima were found.</p></sec><sec id="s4-3-4"><title><bold>Covariance</bold> model of currents and spikes</title><p>We performed covariance analyses on both synaptic current responses and spike trains. Spike-triggered covariance analyses followed established methods (<xref ref-type="bibr" rid="bib28">Fairhall et al., 2006</xref>; <xref ref-type="bibr" rid="bib46">Liu and Gollisch, 2015</xref>; <xref ref-type="bibr" rid="bib33">Samengo and Gollisch, 2013</xref>; <xref ref-type="bibr" rid="bib70">Schwartz et al., 2006</xref>). Briefly, for spike-triggered covariance analysis, we collected the stimulus sequence <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> that preceded each spike time <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where the lag <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> covers 200 time bins at 1 ms resolution. The spike-triggered average was calculated as the average over all spikes <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the covariance matrix was calculated as <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. We then subtracted the ‘prior’ covariance matrix (averaged over all times instead of just spike times) from <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and diagonalized the resulting ‘covariance-difference’ matrix to obtain its eigenvalues and corresponding eigenvectors.</p><p>This procedure was extended to perform the same analysis on synaptic currents, similar to past applications (<xref ref-type="bibr" rid="bib30">Fournier et al., 2014</xref>). For current-based covariance analysis, we calculated the cross-correlation between stimulus and synaptic current response (analogous to the spike-triggered average) <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the current-based covariance matrix was given by <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. We again subtracted an average covariance matrix (unweighted by the current) and calculated eigenvalues and eigenvectors for the result.</p><p>We generated response predictions of the current-based covariance model using the two eigenvectors with the largest magnitude, and applied the methods for fitting a two-dimensional nonlinearity described above. The performance of the resulting model is reported in <xref ref-type="fig" rid="fig2">Figure 2E</xref>, and example fits are shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. To be applied to spike trains, such methods require much more data, and we could not generate firing rate predictions of the spike-based model with reasonable accuracy given the limited data to estimate a two-dimensional nonlinearity, consistent with previous applications of spike-triggered covariance to retina data (e.g., [<xref ref-type="bibr" rid="bib46">Liu and Gollisch, 2015</xref>]). Note that simply estimating separate one-dimensional nonlinearities for each filter (e.g., [<xref ref-type="bibr" rid="bib76">Sincich et al., 2009</xref>]), results in significantly worse predictive performance (e.g., [<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>]), due to the non-separability of the resulting nonlinear structure, as well as the inability for such analyses to factor in spike refractoriness.</p></sec><sec id="s4-3-5"><title>LNK Model</title><p>We explicitly followed the methods of <xref ref-type="bibr" rid="bib56">Ozuysal and Baccus (2012)</xref> in fitting the linear-nonlinear-kinetic (LNK) model to the temporally modulated spot data (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). This model involves the estimation of an LN model in combination with a first-order kinetics model that governs the dynamics of signaling elements in resting state (R), active state (A) and inactivated states (I). Note that we have omitted the fourth state of the original LNK model that explains slow adaptation, because it did not improve model performance due to the small magnitude of slow adaptation we observed (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The kinetics rate constants reflect how fast the signaling elements transition between states. Model parameters are fitted to the data using constrained optimization. We adapted this model to fit the spot-annulus data by extending the linear filter of the LN model into separate temporal filters for center and surround processing (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Note that parameters for more complex forms of the LNK model (e.g., those considered in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>) cannot be tractably fit to data, and we chose the parameters of these models and simulate their output, as described in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>.</p></sec></sec><sec id="s4-4"><title>Statistical modeling of the spike response</title><p>We applied several statistical models to describe the spike response of ganglion cells. We first considered the generalized linear model (GLM) (<xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>; <xref ref-type="bibr" rid="bib79">Truccolo et al., 2005</xref>). We assumed that spike responses are generated by an inhomogeneous Poisson process with an instantaneous rate. The GLM makes prediction of the instantaneous firing rate of the neuron <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> based on both the stimulus <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and the recent history of the spike train <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a linear receptive field, <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the spike-history term and <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the spiking threshold.</p><p>Note that for fitting the model parameters of the GLM (as well as those of other models with a spike-history term <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), we used the observed spikes for predicting firing rates (i.e., <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> was derived from the observed spike train). However, to generate cross-validated predictions, we did not use the observed spikes, and instead calculated <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> iteratively as the history of a simulated spike train that was generated using a Poisson process (see <xref ref-type="bibr" rid="bib18">Butts et al. 2011</xref> for more details).</p><p>The parameters of the GLM are all linear functions inside the spiking nonlinearity <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The LN model consists of only the linear receptive field and the spiking threshold; the full GLM further includes the spike-history term (denoted as LN+RP in figures). The spiking nonlinearity had a fixed functional form <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, satisfying conditions for efficient optimization (<xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>). The choice of this particular parametric form of spiking nonlinearity was verified with standard non-parametric estimation of the spiking nonlinearity (<xref ref-type="fig" rid="fig1">Figure 1B,E</xref>) (<xref ref-type="bibr" rid="bib24">Chichilnisky, 2001</xref>). The model parameters were estimated using maximum likelihood optimization. The log-likelihood (<inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) of the model parameters that predict a firing rate <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> given the observed neural response <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is (<xref ref-type="bibr" rid="bib58">Paninski, 2004</xref>):<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The optimal model parameters could then be determined using gradient-descent based optimization of <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Although this formulation of the model assumes probabilistic generation of spikes, this fitting procedure was able to capture the parameters of the equivalent integrate-and-fire neuron, and thus was not impacted by the form of noise related to spike generation (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>; <xref ref-type="bibr" rid="bib57">Paninski et al., 2007</xref>).</p><p>To capture nonlinear properties of the spike response, we extended the Nonlinear Input Model (NIM) (<xref ref-type="bibr" rid="bib52">McFarland et al., 2013</xref>) to include multiplicative interactions. The predicted firing rate of the NIM is given as:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ζ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where each <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ζ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> represents a component of [potentially nonlinear] upstream processing. The original formulation of the NIM assumed this upstream processing had the form of an LN model (making the NIM an LNLN cascade). However, based on knowledge of nonlinear processing in the synaptic current response, here we assumed that the upstream components <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ζ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> take the form of a DivS model:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ζ</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mtext> </mml:mtext><mml:mo>×</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Similar to parameter estimation of the DivS models of synaptic current response, we alternately estimated the filters and nonlinearities until they converged. The set of constraints on excitatory and suppressive nonlinearities was the same as with DivS model of synaptic currents.</p></sec><sec id="s4-5"><title>Quantification of contrast adaptation with LN analysis</title><p>We performed a more traditional LN model analysis to gauge the adaptation to contrast of both the observed data as well as the predictions of nonlinear models, following (<xref ref-type="bibr" rid="bib23">Chander and Chichilnisky, 2001</xref>; <xref ref-type="bibr" rid="bib4">Baccus and Meister, 2002</xref>). We first separately performed LN analysis for each contrast level, establishing the filter by reverse correlation and then using the filter output at each contrast to separately estimate each nonlinearity. The nonlinearities were then aligned by simultaneously estimating a scaling factor for the x-axis and an offset for the y-axis to minimize the mean squared deviation between them. The associated scaling factor was incorporated into the linear filters such that contrast gain was attributable entirely to changes in the linear filter (<xref ref-type="bibr" rid="bib23">Chander and Chichilnisky, 2001</xref>). While the offset parameter was not used in (<xref ref-type="bibr" rid="bib23">Chander and Chichilnisky, 2001</xref>), we found it was necessary to fully describe the changes in the nonlinearities associated with the synaptic current (but not spiking) data (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). This additional offset is shown in the comparison between the two nonlinearities across contrast (e.g., <xref ref-type="fig" rid="fig1">Figure 1E</xref>).</p><p>Once the linear filters at both contrasts were obtained, we calculated contrast gain as the ratio of standard deviations of the filters at low and high contrast conditions. To make more detailed comparisons about the filter shape, we also calculated a biphasic index, based on the ratio of the most negative to the most positive amplitude of the LN filter <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, i.e., <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-6"><title>Evaluation of model performance</title><p>We fit all models on the 7 s segments of unique stimuli within each 10 s block, and cross-validated model performance on the 3 s repeat trials. We calculated the predictive power, or percent of explainable variance (<xref ref-type="bibr" rid="bib64">Sahani and Linden, 2003</xref>), to quantify how well the model captured the trial-averaged response for both intracellular and extracellular recordings. This metric is based on the fraction of explained variance (<italic>R<sup>2</sup></italic>) but corrects for noise-related bias due to a limited number of trials. For validation of spike-based models, we simulated individual instances of spike trains using a non-homogeneous Poisson process, and the model predictions were based on measuring a PSTH to 500 simulated repeats in response to the cross-validation stimulus. All measures of model performance compared predicted to measured responses using 1 ms bins, which was necessary to measure how accurately the different models captured temporal precision (<xref ref-type="bibr" rid="bib18">Butts et al., 2011</xref>, <xref ref-type="bibr" rid="bib19">2007</xref>).</p></sec><sec id="s4-7"><title>Coherence analysis of synaptic current response</title><p>The general model performance metrics such as predictive power and cross-validated likelihood do not reveal which aspects of the response are not captured by the model. We thus devised a new coherence-based metric to quantify how well the model performs across temporal frequencies. The coherence between the model predicted current response <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and the recorded current response on the <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> trial <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is (<xref ref-type="bibr" rid="bib19">Butts et al., 2007</xref>):<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>γ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>ω</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mtext>C</mml:mtext><mml:mrow><mml:mtext>obs</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mover><mml:mrow><mml:mtext>C</mml:mtext><mml:mtext>(</mml:mtext><mml:mi>ω</mml:mi><mml:mtext>)</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mtext>C</mml:mtext><mml:mrow><mml:mtext>obs</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>ω</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext>C</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>ω</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> are the Fourier transforms of <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> respectively, and the bar denotes complex conjugate. We used angular frequency <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ω</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> instead of <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to be consistent with common conventions. The coherence measure on individual trials was averaged across repeats for each cell.</p><p>Because the observed response on each trial contains noise, a coherence of one throughout the frequency is not a realistic target. To correct for this bias, we calculated the coherence between the trial-averaged current response (i.e., the ideal predictor of response) and the recorded current on each trial. This noise corrected coherence metric represents an upper bound of coherence that can be achieved by any stimulus-processing model. It also reflects the consistency of current response at each frequency. For example, in the low contrast condition, the response contained little high frequency components (<xref ref-type="fig" rid="fig7">Figure 7A–B</xref>), and consequently the measured coherence was close to zero above 30 Hz.</p></sec><sec id="s4-8"><title>Event analysis of spike trains</title><p>We modified a previously established method to identify short firing episodes (events) in the spike train (<xref ref-type="bibr" rid="bib10">Berry et al., 1997</xref>; <xref ref-type="bibr" rid="bib17">Butts et al., 2010</xref>; <xref ref-type="bibr" rid="bib44">Kumbhani et al., 2007</xref>). Specifically, events were first defined in the peristimulus time histogram (PSTH) as times of firing interspersed with periods of silence lasting ≥ 8 ms. Each resulting event was further analyzed by fitting the PSTH with a two-component Gaussian mixture model. An event was broken into two events if the differences of means of the two Gaussian components exceed two times the sum of standard deviations. Event boundaries were defined as the midpoint between neighboring event centers and were used when assigning event labels to simulated spikes. Events were excluded from further analysis if no spike was observed on more than 50% of the trials during the event window. This criterion excluded spontaneous spikes that occurred on few trials. Event analysis was first performed on responses at high contrast. Events at low contrast were defined using the event boundaries obtained from high contrast data. These particular methods were chosen because they gave the most reasonable results with regards to visual inspection, but the results presented here do not qualitatively depend on the precise methods.</p><p>Once the events were parsed, we measured several properties associated with each event relating to their precision and reliability (<xref ref-type="fig" rid="fig1">Figures 1</xref>,<xref ref-type="fig" rid="fig6">6</xref>). First, we measured the jitter in the timing of the first-spike, using the SD of the first spike of the event on each trial. Then, the event time scale was estimated as the SD of all spike times in each event, which is related to the duration of each event. Finally, the event Fano factor measured the ratio between the variance of spike count and the mean spike count in each event.</p></sec><sec id="s4-9"><title>Statistical tests</title><p>All statistical tests performed in the manuscript were non-parametric Wilcoxon signed rank tests, unless otherwise stated. All significant comparisons were also significant using t-tests.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by NSF IIS-1350990 (YC, DAB) and NIH EY021372 and EY014454 and an unrestricted grant from Research to Prevent Blindness to the Department of Ophthalmology &amp; Visual Science at Yale University (YVW, SJHW, JBD).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>YC, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>YVW, Analysis and interpretation of data, Acquisition of Data</p></fn><fn fn-type="con" id="con3"><p>SJHP, Acquisition of data</p></fn><fn fn-type="con" id="con4"><p>JBD, Conception and design, Acquisition of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con5"><p>DAB, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All experimental procedures were conducted in accordance with the recommendations in the Guide for Care and Use of Laboratory Animals of the National Institutes of Health. All of the procedures involving animals were approved by an institutional animal care and use committee (IACUC) protocol (#11431) at Yale University.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Varela</surname><given-names>JA</given-names></name><name><surname>Sen</surname><given-names>K</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Synaptic depression and cortical gain control</article-title><source>Science</source><volume>275</volume><fpage>220</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1126/science.275.5297.221</pub-id><pub-id pub-id-type="pmid">8985017</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahrens</surname><given-names>MB</given-names></name><name><surname>Linden</surname><given-names>JF</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008a</year><article-title>Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>1929</fpage><lpage>1942</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3377-07.2008</pub-id><pub-id pub-id-type="pmid">18287509</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahrens</surname><given-names>MB</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008b</year><article-title>Inferring input nonlinearities in neural encoding models</article-title><source>Network: Computation in Neural Systems</source><volume>19</volume><fpage>35</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1080/09548980701813936</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baccus</surname><given-names>SA</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Fast and slow contrast adaptation in retinal circuitry</article-title><source>Neuron</source><volume>36</volume><fpage>909</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01050-4</pub-id><pub-id pub-id-type="pmid">12467594</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baccus</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Timing and computation in inner retinal circuitry</article-title><source>Annual Review of Physiology</source><volume>69</volume><fpage>271</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1146/annurev.physiol.69.120205.124451</pub-id><pub-id pub-id-type="pmid">17059359</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baden</surname><given-names>T</given-names></name><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Franke</surname><given-names>K</given-names></name><name><surname>Román Rosón</surname><given-names>M</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Euler</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The functional diversity of retinal ganglion cells in the mouse</article-title><source>Nature</source><volume>529</volume><fpage>345</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1038/nature16468</pub-id><pub-id pub-id-type="pmid">26735013</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaudoin</surname><given-names>DL</given-names></name><name><surname>Borghuis</surname><given-names>BG</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Cellular basis for contrast gain control over the receptive field center of mammalian retinal ganglion cells</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>2636</fpage><lpage>2645</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4610-06.2007</pub-id><pub-id pub-id-type="pmid">17344401</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaudoin</surname><given-names>DL</given-names></name><name><surname>Manookin</surname><given-names>MB</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Distinct expressions of contrast gain control in parallel synaptic pathways converging on a retinal ganglion cell</article-title><source>The Journal of Physiology</source><volume>586</volume><fpage>5487</fpage><lpage>5502</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2008.156224</pub-id><pub-id pub-id-type="pmid">18832424</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berry</surname><given-names>MJ</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Refractoriness and neural precision</article-title><source>Journal of Neuroscience </source><volume>18</volume><fpage>2200</fpage><lpage>2211</lpage><pub-id pub-id-type="pmid">9482804</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berry</surname><given-names>MJ</given-names></name><name><surname>Warland</surname><given-names>DK</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The structure and precision of retinal spike trains</article-title><source>PNAS</source><volume>94</volume><fpage>5411</fpage><lpage>5416</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.10.5411</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The suppressive field of neurons in lateral geniculate nucleus</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>10844</fpage><lpage>10856</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3562-05.2005</pub-id><pub-id pub-id-type="pmid">16306397</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borghuis</surname><given-names>BG</given-names></name><name><surname>Marvin</surname><given-names>JS</given-names></name><name><surname>Looger</surname><given-names>LL</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Two-photon imaging of nonlinear glutamate release dynamics at bipolar cell synapses in the mouse retina</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>10972</fpage><lpage>10985</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1241-13.2013</pub-id><pub-id pub-id-type="pmid">23825403</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>SP</given-names></name><name><surname>Masland</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Spatial scale and cellular substrate of contrast adaptation by retinal ganglion cells</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>44</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1038/82888</pub-id><pub-id pub-id-type="pmid">11135644</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruno</surname><given-names>RM</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cortex is driven by weak but synchronously active thalamocortical synapses</article-title><source>Science</source><volume>312</volume><fpage>1622</fpage><lpage>1627</lpage><pub-id pub-id-type="doi">10.1126/science.1124593</pub-id><pub-id pub-id-type="pmid">16778049</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Cui</surname><given-names>Y</given-names></name><name><surname>Casti</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Nonlinear computations shaping temporal processing of precortical vision</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>1344</fpage><lpage>1357</lpage><pub-id pub-id-type="doi">10.1152/jn.00878.2015</pub-id><pub-id pub-id-type="pmid">27334959</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Desbordes</surname><given-names>G</given-names></name><name><surname>Weng</surname><given-names>C</given-names></name><name><surname>Jin</surname><given-names>J</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The episodic nature of spike trains in the early visual pathway</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>3371</fpage><lpage>3387</lpage><pub-id pub-id-type="doi">10.1152/jn.00078.2010</pub-id><pub-id pub-id-type="pmid">20926615</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Weng</surname><given-names>C</given-names></name><name><surname>Jin</surname><given-names>J</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Temporal precision in the visual pathway through the interplay of excitation and stimulus-driven suppression</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>11313</fpage><lpage>11327</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0434-11.2011</pub-id><pub-id pub-id-type="pmid">21813691</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Weng</surname><given-names>C</given-names></name><name><surname>Jin</surname><given-names>J</given-names></name><name><surname>Yeh</surname><given-names>CI</given-names></name><name><surname>Lesica</surname><given-names>NA</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Temporal precision in the neural code and the timescales of natural vision</article-title><source>Nature</source><volume>449</volume><fpage>92</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1038/nature06105</pub-id><pub-id pub-id-type="pmid">17805296</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title><source>Journal of Neuroscience</source><volume>17</volume><fpage>8621</fpage><lpage>8644</lpage><pub-id pub-id-type="pmid">9334433</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Horton</surname><given-names>JC</given-names></name><name><surname>Sincich</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Thalamic filtering of retinal spike trains by postsynaptic summation</article-title><source>Journal of Vision</source><volume>7</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1167/7.14.20</pub-id><pub-id pub-id-type="pmid">18217815</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casti</surname><given-names>A</given-names></name><name><surname>Hayot</surname><given-names>F</given-names></name><name><surname>Xiao</surname><given-names>Y</given-names></name><name><surname>Kaplan</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A simple model of retina-LGN transmission</article-title><source>Journal of Computational Neuroscience</source><volume>24</volume><fpage>235</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1007/s10827-007-0053-7</pub-id><pub-id pub-id-type="pmid">17763931</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chander</surname><given-names>D</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Adaptation to temporal contrast in primate and salamander retina</article-title><source>Journal of Neuroscience </source><volume>21</volume><fpage>9904</fpage><lpage>9916</lpage><pub-id pub-id-type="pmid">11739598</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A simple white noise analysis of neuronal light responses</article-title><source>Network: Computation in Neural Systems</source><volume>12</volume><fpage>199</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1080/713663221</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demb</surname><given-names>JB</given-names></name><name><surname>Singer</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional circuitry of the retina</article-title><source>Annual Review of Vision Science</source><volume>1</volume><fpage>263</fpage><lpage>289</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035334</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eggers</surname><given-names>ED</given-names></name><name><surname>Lukasiewicz</surname><given-names>PD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multiple pathways of inhibition shape bipolar cell responses in the retina</article-title><source>Visual Neuroscience</source><volume>28</volume><fpage>95</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1017/S0952523810000209</pub-id><pub-id pub-id-type="pmid">20932357</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Euler</surname><given-names>T</given-names></name><name><surname>Haverkamp</surname><given-names>S</given-names></name><name><surname>Schubert</surname><given-names>T</given-names></name><name><surname>Baden</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Retinal bipolar cells: elementary building blocks of vision</article-title><source>Nature Reviews Neuroscience</source><volume>15</volume><fpage>507</fpage><lpage>519</lpage><pub-id pub-id-type="doi">10.1038/nrn3783</pub-id><pub-id pub-id-type="pmid">25158357</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhall</surname><given-names>AL</given-names></name><name><surname>Burlingame</surname><given-names>CA</given-names></name><name><surname>Narasimhan</surname><given-names>R</given-names></name><name><surname>Harris</surname><given-names>RA</given-names></name><name><surname>Puchalla</surname><given-names>JL</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Selectivity for multiple stimulus features in retinal ganglion cells</article-title><source>Journal of Neurophysiology</source><volume>96</volume><fpage>2724</fpage><lpage>2738</lpage><pub-id pub-id-type="doi">10.1152/jn.00995.2005</pub-id><pub-id pub-id-type="pmid">16914609</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>IM</given-names></name><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Ferster</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The emergence of contrast-invariant orientation tuning in simple cells of cat visual cortex</article-title><source>Neuron</source><volume>54</volume><fpage>137</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.02.029</pub-id><pub-id pub-id-type="pmid">17408583</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fournier</surname><given-names>J</given-names></name><name><surname>Monier</surname><given-names>C</given-names></name><name><surname>Levy</surname><given-names>M</given-names></name><name><surname>Marre</surname><given-names>O</given-names></name><name><surname>Sári</surname><given-names>K</given-names></name><name><surname>Kisvárday</surname><given-names>ZF</given-names></name><name><surname>Frégnac</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hidden complexity of synaptic receptive fields in cat V1</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>5515</fpage><lpage>5528</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0474-13.2014</pub-id><pub-id pub-id-type="pmid">24741042</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franke</surname><given-names>K</given-names></name><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Schubert</surname><given-names>T</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Euler</surname><given-names>T</given-names></name><name><surname>Baden</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Balanced excitation and inhibition decorrelates visual feature representation in the mammalian inner retina</article-title><source>Biorxiv</source><pub-id pub-id-type="doi">10.1101/040642</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>J</given-names></name><name><surname>Field</surname><given-names>GD</given-names></name><name><surname>Li</surname><given-names>PH</given-names></name><name><surname>Greschner</surname><given-names>M</given-names></name><name><surname>Gunning</surname><given-names>DE</given-names></name><name><surname>Mathieson</surname><given-names>K</given-names></name><name><surname>Sher</surname><given-names>A</given-names></name><name><surname>Litke</surname><given-names>AM</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Field</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>GD</given-names></name><name><surname>Sher</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mapping nonlinear receptive field structure in primate retina at single cone resolution</article-title><source>eLife</source><volume>4</volume><elocation-id>e05241</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05241</pub-id><pub-id pub-id-type="pmid">26517879</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gollisch</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Features and functions of nonlinear spatial integration by retinal ganglion cells</article-title><source>Journal of Physiology-Paris</source><volume>107</volume><fpage>338</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2012.12.001</pub-id><pub-id pub-id-type="pmid">23262113</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hao</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>X.-d.</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name><name><surname>Poo</surname><given-names>M.-m.</given-names></name><name><surname>Zhang</surname><given-names>X.-h.</given-names></name><name><surname>Wang</surname><given-names>XD</given-names></name><name><surname>Poo</surname><given-names>MM</given-names></name><name><surname>Zhang</surname><given-names>XH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>An arithmetic rule for spatial summation of excitatory and inhibitory inputs in pyramidal neurons</article-title><source>PNAS</source><volume>106</volume><fpage>21906</fpage><lpage>21911</lpage><pub-id pub-id-type="doi">10.1073/pnas.0912022106</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Havenith</surname><given-names>MN</given-names></name><name><surname>Yu</surname><given-names>S</given-names></name><name><surname>Biederlack</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>NH</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Nikolić</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Synchrony makes neurons fire in sequence, and stimulus properties determine who is ahead</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>8570</fpage><lpage>8584</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2817-10.2011</pub-id><pub-id pub-id-type="pmid">21653861</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Normalization of cell responses in cat striate cortex</article-title><source>Visual Neuroscience</source><volume>9</volume><fpage>181</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1017/S0952523800009640</pub-id><pub-id pub-id-type="pmid">1504027</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname> <given-names>IW</given-names></name><name><surname>Korenberg</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>The identification of nonlinear biological systems: Wiener and hammerstein cascade models</article-title><source>Biological Cybernetics</source><volume>55</volume><fpage>135</fpage><lpage>144</lpage><pub-id pub-id-type="pmid">3801534</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarsky</surname><given-names>T</given-names></name><name><surname>Cembrowski</surname><given-names>M</given-names></name><name><surname>Logan</surname><given-names>SM</given-names></name><name><surname>Kath</surname><given-names>WL</given-names></name><name><surname>Riecke</surname><given-names>H</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name><name><surname>Singer</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A synaptic mechanism for retinal adaptation to luminance and contrast</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>11003</fpage><lpage>11015</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2631-11.2011</pub-id><pub-id pub-id-type="pmid">21795549</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>DB</given-names></name><name><surname>Baccus</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Insights from the retina into the diverse and general computations of adaptation, detection, and prediction</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>63</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.11.012</pub-id><pub-id pub-id-type="pmid">24709602</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keat</surname><given-names>J</given-names></name><name><surname>Reinagel</surname><given-names>P</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Predicting every spike: a model for the responses of visual neurons</article-title><source>Neuron</source><volume>30</volume><fpage>803</fpage><lpage>817</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00322-1</pub-id><pub-id pub-id-type="pmid">11430813</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>ST</given-names></name><name><surname>Kremkow</surname><given-names>J</given-names></name><name><surname>Jin</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The role of thalamic population synchrony in the emergence of cortical feature selectivity</article-title><source>PLoS Computational Biology</source><volume>10</volume><elocation-id>e1003418</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003418</pub-id><pub-id pub-id-type="pmid">24415930</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>KJ</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporal contrast adaptation in the input and output signals of salamander retinal ganglion cells</article-title><source>Journal of Neuroscience </source><volume>21</volume><fpage>287</fpage><lpage>299</lpage><pub-id pub-id-type="pmid">11150346</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>KJ</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Slow Na+ inactivation and variance adaptation in salamander retinal ganglion cells</article-title><source>Journal of Neuroscience </source><volume>23</volume><fpage>1506</fpage><lpage>1516</lpage><pub-id pub-id-type="pmid">12598639</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumbhani</surname><given-names>RD</given-names></name><name><surname>Nolt</surname><given-names>MJ</given-names></name><name><surname>Palmer</surname><given-names>LA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Precision, reliability, and information-theoretic analysis of visual thalamocortical neurons</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>2647</fpage><lpage>2663</lpage><pub-id pub-id-type="doi">10.1152/jn.00900.2006</pub-id><pub-id pub-id-type="pmid">17581854</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuo</surname><given-names>SP</given-names></name><name><surname>Schwartz</surname><given-names>GW</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Nonlinear spatiotemporal integration by electrical and chemical synapses in the retina</article-title><source>Neuron</source><volume>90</volume><fpage>320</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.012</pub-id><pub-id pub-id-type="pmid">27068789</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>JK</given-names></name><name><surname>Gollisch</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spike-tiggered covariance analysis reveals phenomenological diversity of contrast adaptation in the retina</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004425</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004425</pub-id><pub-id pub-id-type="pmid">26230927</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>RC</given-names></name><name><surname>Tzonev</surname><given-names>S</given-names></name><name><surname>Rebrik</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Variability and information in a neural code of the cat lateral geniculate nucleus</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>2789</fpage><lpage>2806</lpage><pub-id pub-id-type="pmid">11731537</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manookin</surname><given-names>MB</given-names></name><name><surname>Beaudoin</surname><given-names>DL</given-names></name><name><surname>Ernst</surname><given-names>ZR</given-names></name><name><surname>Flagel</surname><given-names>LJ</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Disinhibition combines with excitation to extend the operating range of the OFF visual pathway in daylight</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>4136</fpage><lpage>4150</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4274-07.2008</pub-id><pub-id pub-id-type="pmid">18417693</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manookin</surname><given-names>MB</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Presynaptic mechanism for slow contrast adaptation in mammalian retinal ganglion cells</article-title><source>Neuron</source><volume>50</volume><fpage>453</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.03.039</pub-id><pub-id pub-id-type="pmid">16675399</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Functional mechanisms shaping lateral geniculate responses to artificial and natural stimuli</article-title><source>Neuron</source><volume>58</volume><fpage>625</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.03.011</pub-id><pub-id pub-id-type="pmid">18498742</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Differential signaling via the same axon of neocortical pyramidal neurons</article-title><source>PNAS</source><volume>95</volume><fpage>5323</fpage><lpage>5328</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.9.5323</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFarland</surname><given-names>JM</given-names></name><name><surname>Cui</surname><given-names>Y</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inferring nonlinear neuronal computation based on physiologically plausible inputs</article-title><source>PLoS Computational Biology</source><volume>9</volume><elocation-id>e1003143</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003143</pub-id><pub-id pub-id-type="pmid">23874185</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meister</surname><given-names>M</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The neural code of the retina</article-title><source>Neuron</source><volume>22</volume><fpage>435</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80700-X</pub-id><pub-id pub-id-type="pmid">10197525</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>GJ</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Network variability limits stimulus-evoked spike timing precision in retinal ganglion cells</article-title><source>Neuron</source><volume>52</volume><fpage>511</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.09.014</pub-id><pub-id pub-id-type="pmid">17088216</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname><given-names>SR</given-names></name><name><surname>Wilson</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Lateral presynaptic inhibition mediates gain control in an olfactory circuit</article-title><source>Nature</source><volume>452</volume><fpage>956</fpage><lpage>960</lpage><pub-id pub-id-type="doi">10.1038/nature06864</pub-id><pub-id pub-id-type="pmid">18344978</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozuysal</surname><given-names>Y</given-names></name><name><surname>Baccus</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Linking the computational structure of variance adaptation to biophysical mechanisms</article-title><source>Neuron</source><volume>73</volume><fpage>1002</fpage><lpage>1015</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.029</pub-id><pub-id pub-id-type="pmid">22405209</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Pillow</surname><given-names>J</given-names></name><name><surname>Lewi</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Statistical models for neural encoding, decoding, and optimal stimulus design</article-title><source>Progress in Brain Research</source><volume>165</volume><fpage>493</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(06)65031-0</pub-id><pub-id pub-id-type="pmid">17925266</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Maximum likelihood estimation of cascade point-process neural encoding models</article-title><source>Network: Computation in Neural Systems</source><volume>15</volume><fpage>243</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1088/0954-898X_15_4_002</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Passaglia</surname><given-names>CL</given-names></name><name><surname>Troy</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Information transmission rates of cat retinal ganglion cells</article-title><source>Journal of Neurophysiology</source><volume>91</volume><fpage>1217</fpage><lpage>1229</lpage><pub-id pub-id-type="doi">10.1152/jn.00796.2003</pub-id><pub-id pub-id-type="pmid">14602836</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Uzzell</surname><given-names>VJ</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Prediction and decoding of retinal ganglion cell responses with a probabilistic spiking model</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>11003</fpage><lpage>11013</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3305-05.2005</pub-id><pub-id pub-id-type="pmid">16306413</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rathbun</surname><given-names>DL</given-names></name><name><surname>Warland</surname><given-names>DK</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spike timing and information transmission at retinogeniculate synapses</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>13558</fpage><lpage>13566</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0909-10.2010</pub-id><pub-id pub-id-type="pmid">20943897</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinagel</surname><given-names>P</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Temporal coding of visual information in the thalamus</article-title><source>Journal of Neuroscience</source><volume>20</volume><fpage>5392</fpage><lpage>5400</lpage><pub-id pub-id-type="pmid">10884324</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporal contrast adaptation in salamander bipolar cells</article-title><source>Journal of Neuroscience</source><volume>21</volume><fpage>9445</fpage><lpage>9454</lpage><pub-id pub-id-type="pmid">11717378</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Linden</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><chapter-title>How linear are auditory cortical responses?</chapter-title><person-group person-group-type="editor"><name><surname>Thrun</surname> <given-names>S</given-names></name><name><surname>Obermayer</surname> <given-names>K</given-names></name><name><surname>Becker</surname> <given-names>S</given-names></name><name><surname>Thrun</surname> <given-names>S</given-names></name><name><surname>Obermayer</surname> <given-names>K</given-names></name></person-group><source>In Advances in Neural Information Processing Systems</source><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT</publisher-name></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samengo</surname><given-names>I</given-names></name><name><surname>Gollisch</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spike-triggered covariance: geometric proof, symmetry properties, and extension beyond Gaussian stimuli</article-title><source>Journal of Computational Neuroscience</source><volume>34</volume><fpage>137</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1007/s10827-012-0411-y</pub-id><pub-id pub-id-type="pmid">22798148</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanes</surname><given-names>JR</given-names></name><name><surname>Masland</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The types of retinal ganglion cells: current status and implications for neuronal classification</article-title><source>Annual Review of Neuroscience</source><volume>38</volume><fpage>221</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071714-034120</pub-id><pub-id pub-id-type="pmid">25897874</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schubert</surname><given-names>T</given-names></name><name><surname>Kerschensteiner</surname><given-names>D</given-names></name><name><surname>Eggers</surname><given-names>ED</given-names></name><name><surname>Misgeld</surname><given-names>T</given-names></name><name><surname>Kerschensteiner</surname><given-names>M</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name><name><surname>Lukasiewicz</surname><given-names>PD</given-names></name><name><surname>Wong</surname><given-names>RO</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Development of presynaptic inhibition onto retinal bipolar cell axon terminals is subclass-specific</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>304</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1152/jn.90202.2008</pub-id><pub-id pub-id-type="pmid">18436633</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>G</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perspectives on: information and coding in mammalian sensory physiology: nonlinear spatial encoding by retinal ganglion cells: when 1 + 1 ≠ 2</article-title><source>The Journal of General Physiology</source><volume>138</volume><fpage>283</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1085/jgp.201110629</pub-id><pub-id pub-id-type="pmid">21875977</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>GW</given-names></name><name><surname>Okawa</surname><given-names>H</given-names></name><name><surname>Dunn</surname><given-names>FA</given-names></name><name><surname>Morgan</surname><given-names>JL</given-names></name><name><surname>Kerschensteiner</surname><given-names>D</given-names></name><name><surname>Wong</surname><given-names>RO</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The spatial structure of a nonlinear receptive field</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1572</fpage><lpage>1580</lpage><pub-id pub-id-type="doi">10.1038/nn.3225</pub-id><pub-id pub-id-type="pmid">23001060</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>O</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Rust</surname><given-names>NC</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spike-triggered neural characterization</article-title><source>Journal of Vision</source><volume>6</volume><fpage>484</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1167/6.4.13</pub-id><pub-id pub-id-type="pmid">16889482</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shapley</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Linear and nonlinear systems analysis of the visual system: why does it seem so linear? A review dedicated to the memory of Henk Spekreijse</article-title><source>Vision Research</source><volume>49</volume><fpage>907</fpage><lpage>921</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.09.026</pub-id><pub-id pub-id-type="pmid">18940193</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shapley</surname><given-names>RM</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>The effect of contrast on the transfer properties of cat retinal ganglion cells</article-title><source>The Journal of Physiology</source><volume>285</volume><fpage>275</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1978.sp012571</pub-id><pub-id pub-id-type="pmid">745079</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shapley</surname><given-names>RM</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Nonlinear spatial summation and the contrast gain control of cat retinal ganglion cells</article-title><source>The Journal of Physiology</source><volume>290</volume><fpage>141</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1979.sp012765</pub-id><pub-id pub-id-type="pmid">469742</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharpee</surname><given-names>T</given-names></name><name><surname>Rust</surname><given-names>NC</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Analyzing neural responses to natural signals: maximally informative dimensions</article-title><source>Neural Computation</source><volume>16</volume><fpage>223</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1162/089976604322742010</pub-id><pub-id pub-id-type="pmid">15006095</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A model of neuronal responses in visual area MT</article-title><source>Vision Research</source><volume>38</volume><fpage>743</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(97)00183-1</pub-id><pub-id pub-id-type="pmid">9604103</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sincich</surname><given-names>LC</given-names></name><name><surname>Horton</surname><given-names>JC</given-names></name><name><surname>Sharpee</surname><given-names>TO</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Preserving information in neural transmission</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>6207</fpage><lpage>6216</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3701-08.2009</pub-id><pub-id pub-id-type="pmid">19439598</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanley</surname><given-names>GB</given-names></name><name><surname>Jin</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Desbordes</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Black</surname><given-names>MJ</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Visual orientation and directional selectivity through thalamic synchrony</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>9073</fpage><lpage>9088</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4968-11.2012</pub-id><pub-id pub-id-type="pmid">22745507</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toriello</surname><given-names>A</given-names></name><name><surname>Vielma</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Fitting piecewise linear continuous functions</article-title><source>European Journal of Operational Research</source><volume>219</volume><fpage>86</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1016/j.ejor.2011.12.030</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Truccolo</surname><given-names>W</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Fellows</surname><given-names>MR</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name><name><surname>Brown</surname><given-names>EN</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A point process framework for relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects</article-title><source>Journal of Neurophysiology</source><volume>93</volume><fpage>1074</fpage><lpage>1089</lpage><pub-id pub-id-type="doi">10.1152/jn.00697.2004</pub-id><pub-id pub-id-type="pmid">15356183</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Synaptic interactions between thalamic inputs to simple cells in cat visual cortex</article-title><source>Journal of Neuroscience</source><volume>20</volume><fpage>5461</fpage><lpage>5467</lpage><pub-id pub-id-type="pmid">10884329</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uzzell</surname><given-names>VJ</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Precision of spike trains in primate retinal ganglion cells</article-title><source>Journal of Neurophysiology</source><volume>92</volume><fpage>780</fpage><lpage>789</lpage><pub-id pub-id-type="doi">10.1152/jn.01171.2003</pub-id><pub-id pub-id-type="pmid">15277596</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaingankar</surname><given-names>V</given-names></name><name><surname>Soto-Sanchez</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Sommer</surname><given-names>FT</given-names></name><name><surname>Hirsch</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neurons in the thalamic reticular nucleus are selective for diverse and complex visual features</article-title><source>Frontiers in Integrative Neuroscience</source><volume>6</volume><elocation-id>118</elocation-id><pub-id pub-id-type="doi">10.3389/fnint.2012.00118</pub-id><pub-id pub-id-type="pmid">23269915</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Webber</surname><given-names>RM</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2010">2010a</year><article-title>Thalamic synchrony and the adaptive gating of information flow to cortex</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1534</fpage><lpage>1541</lpage><pub-id pub-id-type="doi">10.1038/nn.2670</pub-id><pub-id pub-id-type="pmid">21102447</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Hirsch</surname><given-names>JA</given-names></name><name><surname>Sommer</surname><given-names>FT</given-names></name></person-group><year iso-8601-date="2010">2010b</year><article-title>Recoding of sensory information across the retinothalamic synapse</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>13567</fpage><lpage>13577</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0910-10.2010</pub-id><pub-id pub-id-type="pmid">20943898</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>YV</given-names></name><name><surname>Weick</surname><given-names>M</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spectral and temporal sensitivity of cone-mediated responses in mouse retinal ganglion cells</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>7670</fpage><lpage>7681</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0629-11.2011</pub-id><pub-id pub-id-type="pmid">21613480</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williamson</surname><given-names>RS</given-names></name><name><surname>Ahrens</surname><given-names>MB</given-names></name><name><surname>Linden</surname><given-names>JF</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Input-specific gain modulation by local sensory context shapes cortical and thalamic responses to complex sounds</article-title><source>Neuron</source><volume>91</volume><fpage>467</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.041</pub-id><pub-id pub-id-type="pmid">27346532</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaghloul</surname><given-names>KA</given-names></name><name><surname>Boahen</surname><given-names>K</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Contrast adaptation in subthreshold and spiking responses of mammalian Y-type retinal ganglion cells</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>860</fpage><lpage>868</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2782-04.2005</pub-id><pub-id pub-id-type="pmid">15673666</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaghloul</surname><given-names>KA</given-names></name><name><surname>Manookin</surname><given-names>MB</given-names></name><name><surname>Borghuis</surname><given-names>BG</given-names></name><name><surname>Boahen</surname><given-names>K</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Functional circuitry for peripheral suppression in Mammalian Y-type retinal ganglion cells</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>4327</fpage><lpage>4340</lpage><pub-id pub-id-type="doi">10.1152/jn.01091.2006</pub-id><pub-id pub-id-type="pmid">17460102</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Rasch</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Circuit motifs for contrast-adaptive differentiation in early sensory systems: the role of presynaptic inhibition and short-term plasticity</article-title><source>PLoS One</source><volume>10</volume><elocation-id>e0118125</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0118125</pub-id><pub-id pub-id-type="pmid">25723493</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.19460.016</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallant</surname><given-names>Jack L</given-names></name><role>Reviewing editor</role><aff id="aff6"><institution>University of California, Berkeley</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>[Editors’ note: a previous version of this study was rejected after peer review, but the authors submitted for reconsideration. The first decision letter after peer review is shown below.]</p><p>Thank you for submitting your work entitled &quot;Divisive suppression explains high-precision firing and contrast adaptation in retinal ganglion cells&quot; for consideration by <italic>eLife</italic>. Please accept our apologies for the long delay in returning these reviews to you. We had a difficult time finding qualified reviewers for your paper and then one of the initial reviewers had to bow out at a late date.</p><p>Your article has been reviewed by two peer reviewers. The process was overseen by a Reviewing Editor and by Timothy Behrens, the Senior Editor. Our decision was reached after consultation between the reviewers, the Reviewing Editor and the Senior Editor.</p><p>Based on these discussions and the individual reviews below, we regret to inform you that this submission will not be considered further for publication in <italic>eLife</italic>. However, the reviewers and Editors thought that your study was interesting and worthwhile, and after discussion amongst the Editors it was decided that we would be happy to consider a revised paper, which would be considered as a new submission. Based on extensive discussions with the reviewers, the Reviewing Editor believes that a resubmission would be considered if you were to revise the paper in one of three ways: (1) undertake pharmacological studies as suggested by one reviewer, and therefore try to tie the model more closely to specific neural mechanisms; (2) use a wider range of stimuli, such as stimuli that include naturalistic slow temporal fluctuations (e.g., 1/f), and then modify the model as necessary to account for a broader range of phenomena; (3) try to get a better sense of which elements of the model are critical under what situations, but testing an even wider range of competing models and model variants. We thank you for sending your work for review and we hope you will either revise this work and resubmit it, or barring that you will wish to submit to <italic>eLife</italic> again in the future.</p><p>Reviewer #1:</p><p>This paper studies the responses of mouse α retinal ganglion cells responding to flickering white noise at two different contrast, and fits the response with a computational model. The model is an abstract model consisting of two pathways, with one influencing the other, which is one of a general class of known models with multiple pathways followed by a nonlinear static (time-independent) interaction. It is shown that the model accurately captures the response and some properties of contrast adaptation. An argument is made why the model can be interpreted to show that inhibition underlies contrast adaptation. Other aspects of the model such as the source of precise firing are discussed. Currently the claim of the role of inhibition is not well supported, and the result that a more simple model of a known type fits the data for one type of ganglion cell is interesting, but mainly to the community of people that fit models of the retina.</p><p>Major points</p><p>1) A central claim of the paper is that the model indicates that adaptation comes from inhibitory suppression. This claim is in conflict with other studies, including one from the Demb lab (Brown &amp; Masland, Manookin &amp; Demb 2006). The current evidence for this claim is not sufficient, and a pharmacological experiment blocking inhibition has to be done for this claim to be supported. If it turns out that blocking inhibition abolishes adaptation and changes the response of the model in the expected way, then this should be the main focus of the paper, and the model should be used to support this main claim. In doing this experiment, the primary concern will be that without inhibition, the retina is put in a different state, where adaptation does not occur, even though inhibition is not really involved. For example, without inhibition, neurons will depolarizes and synapses may be depressed even at low contrast. So care must be taken to avoid this issue. In particular, the expectation is that the excitatory direction changes little, but the suppressive direction disappears. Because the low contrast is 10% (which is still fairly strong) it may be useful to use a lower contrast.</p><p>2) The authors interpret the 'suppressive' direction to mean inhibition, but the alternative interpretation that the authors wish to argue against is that feedback at excitatory synapses produces an apparent suppression when fit with the DivS model. It is quite suspicious that the suppressive direction (temporal filter) in <xref ref-type="fig" rid="fig2">Figure 2B</xref> looks exactly like a delayed version of the excitatory temporal filter. This seems to imply that the suppressive direction might indeed be from negative feedback – though admittedly such negative feedback could from synaptic depression or inhibition. The results presented are consistent with the current model of synaptic depression (not inhibition) underlying adaptation, except for <xref ref-type="fig" rid="fig4">Figure 4</xref>, which relies on a questionable assumption (discussed below). That's why the pharmacological test is critical.</p><p>3) As the sole support of the claim that the suppressive component of the model comes from inhibition, a spatial stimulus is used in <xref ref-type="fig" rid="fig4">Figure 4</xref>. This brings a new level of complexity is not properly addressed. When space is considered, we know that bipolar cells have a receptive field center and surround with different temporal filters. Bipolar cells form nonlinear subunits, each with a threshold (Schwartz et al., 2012 for mouse α cells). Each of these small subunits show local adaptation (Brown &amp; Masland, 2001) and then there is global adaptation in the ganglion cell from spike generation (Zaghloul et al. 2005). The logic the authors use is the suppressive direction should be the same as the excitatory direction if inhibition is not involved. It is not clear whether this is true when the more complex system is considered. The 'excitatory' and 'suppressive' directions are just the two directions in stimulus space that influence the response, and the suppressive direction will be influenced by feedback at bipolar cell synapses and in the ganglion cells. The surround time course is more delayed, and may match the delayed suppression from negative feedback more closely. Thus it is not clear whether the simple DivS model will mix inputs in unexpected ways. The fact that the suppressive and excitatory directions are different is not conclusive without further consideration of the known sites of nonlinearities and adaptation.</p><p>4) Because the model has no slow dynamics, it cannot capture contrast adaptation that lasts over several seconds, which has been the sole subject of some studies of contrast adaptation (Manookin &amp; Demb, 2006). The entire 20 s stretch of recording should be shown of the data, so it can be properly evaluated what aspects of the response cannot be fit by the model. Furthermore, the claims about the accuracy of the model should be qualified in terms of the aspects of adaptation that it does not capture.</p><p>5) Class of model. If in fact there are only two stimulus directions that are important as is claimed, than the DivS model is equivalent to a model that can be created using standard Spike-Triggered Covariance (STC) analysis (Fairhall et al., 2006), which can equivalently be done with continuous currents. So it should be pointed out that this model is not a new type of model, but an example of a known type of model. In (Fairhall, 2006) there are multiple types of ganglion cells reported with different types of responses in the two-D feature space, yet contrast adaptation is widespread among ganglion cells, so it is likely that the interpretations of the current paper won't apply generally. It is ok to study one type of cell, but the fact that the model presented is one of a known class of models should be made clear.</p><p>6) The LNK model is not convex, and more detail should be given as to how this was optimized. Were the methods of (Ozuysal &amp; Baccus, 2012) used? For example, mean squared error was not used as an error metric. If the method of fitting was suboptimal, then the interpretation of the comparison between models is not clear. Also, more detail needs to be given for the spatial LNK model. Because there are two different spatial regions, each one should have independent adaptation, and each spatial region should have a center-surround linear receptive field. This would be a new type of model, so it's not clear whether this model can be properly optimized.</p><p>7) For the spiking DivS model, does the model really take the observed spike train as an input (not just as a constraint to fit data)? Shoudn't a model that takes the response as an input be able to produce the response? (It seems like cheating.) In fact, some studies that use the spike history in the way have shown that using the spike history is either the most important predictor of the response, or that the spike history alone can be used to predict the response (Kraus et al., 2015, Figure S4; Trucculo, et al., 2010). If this is really what was done, this approach differs from other models which use a spike-history term such as a generalized linear model (GLM) (Pillow et al., 2008) but that generate its own spikes rather than taking the actual response as an input. This needs to be made more clear, and also justified as to why this is useful. This approach may be useful for understanding the source of precision as the authors do, but it doesn't seem impressive that this model can fit the data if it really takes the actual response as an input.</p><p>8) <xref ref-type="fig" rid="fig6">Figure 6</xref>, it is not clear where the noise comes from in the model, as there is no noise source. Is it all from the spike-history term, i.e. the actual data? It's not clear how we can evaluate different models using this approach, because the noise is not appropriate for each model. A better approach would be to model noise sources and put them in each different model, like an LNP model.</p><p>Reviewer #2:</p><p>This paper shows how a novel model can predict the retinal ganglion cell responses to full field flicker at different contrasts. Standard approaches, like LN models, fail to generalize across contrasts, while this model does generalize with a single set of parameters to predict responses to high and low contrasts.</p><p>The key novelty of this model is to include both excitatory and inhibitory subunits, that are multiplied together to predict the ganglion cell membrane potential. Further non-linear processing allows to predict the spiking response. The model has been carefully fitted to both intracellular and extracellular recordings. The agreement between the model prediction and the data is impressive.</p><p>Overall this is a very nice work. Contrast adaptation is ubiquitous in the visual system. Such a model could have a broad impact on the field of sensory systems.</p><p>Major comment:</p><p>My only concern is about novelty: as noticed by the authors, another model, the LNK by Ozuysal and Baccus, has already shown its ability to predict ganglion cell responses at different contrasts. The performance of the current model is better than the LNK, but not by much for full field stimuli. The only stimulus where there is a significant difference, if I understood well, was the one composed of a center spot and an annulus stimulating the surround. There the model performed better, but the difference is rather small (around 7%).</p><p>The model is conceptually novel, but relatively similar to previous works by Sahani and colleagues.</p><p>So I think a more thorough comparison between the LNK model and this one would be welcomed. With such a small difference, one would like to be sure that the authors gave the LNK model its best chance of success. Here the methods do not include a text about how this model was fitted. More generally, more details would be welcomed about how the two models were fitted in the case of the compound stimulus (centered spot +annulus).</p><p>[Editors’ note: what now follows is the decision letter after the authors submitted for further consideration.]</p><p>Thank you for resubmitting your work entitled &quot;Divisive suppression explains high-precision firing and contrast adaptation in retinal ganglion cells&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Timothy Behrens (Senior editor), a Reviewing editor, and two reviewers.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance. As you will see Reviewer 1 was very positive, but Reviewer 2 had several remaining concerns. In an extensive consultation session between both reviewers and the Reviewing Editor, it was decided that the best course of action would be for us to return this to you for further revision to meet the concerns of Reviewer 2.</p><p>1) The biggest remaining issue that must be addressed in revision concerns issue #1 raised by Reviewer #2, the use of raw data in prediction. This issue was also brought up in the initial reviews. All the discussants are concerned there is a serious danger of over-fitting here, and they did not consider the responses to the initial reviews on this matter to be sufficient. Reviewer 1 makes some good suggestions about how to deal with this issue, but you might also be able to approach it another way.</p><p>2) Please try to address the slow contrast adaptation issue as suggested by Reviewer 1. If it cannot be addressed then the manuscript should be revised to make it clear that this mechanism is not covered by the model.</p><p>3) Please respond to the dynamics/LNK issue with appropriate revisions (preferably including the requested comparisons).</p><p>4) The presentation regarding the Spike Triggered Covariance model and its relationship to the DivS model needs to be clarified.</p><p>5) Please revise the text concerning divisive suppression to address Reviewer #1's concerns.</p><p>As the discussants see it, you can meet these concerns in one of two ways:</p><p>Option 1: Revise and retract some of the claims so that the claims are more consistent with what is actually shown in the existing manuscript.</p><p>Option 2: Run the model again, but using a spike history filter generated from synthetic spikes rather than using the raw data in the model prediction as was done in the most recent revision.</p><p>The discussants agreed that either of these two options would be fine and that they would leave it up to you to decide which course of action you would like to pursue.</p><p>In either case we appreciate your submitting this excellent manuscript to <italic>eLife</italic> and we hope that these remaining revisions will not be too onerous for you to accomplish quickly.</p><p>Reviewer #1:</p><p>As far as I am concerned the authors replied well to the points I raised. It is clear that this study shows a novel model that can predict better ganglion cells responses. The quantitative improvement compared to previous approaches can be small, but the framework seems a bit more general. It is also stated clearly that this model by itself does not lead to novel insights about the mechanisms behind contrast adaptation as different mechanisms can explain these results.</p><p>Reviewer #2:</p><p>The paper has improved from the previous version, but a number of issues remain that were raised in the first review. The main positive points are that it captures contrast adaptation in a particular cell type with a simple model, and that it raises a new potential mechanism for adaptation using one pathway modulating another, which is different from the accepted explanation of synaptic depression. It can be made suitable for publication, but a number of things must be done.</p><p>1) Spike history. For the spiking DivS model, the authors use the raw data as an input to the model when predicting the data. This seemed to be the case in the last review, although it was baffling to me and surprised both reviewers. Insufficient justification has been given for this procedure, and I can't conceive of any justification for it. The arguments given by the authors for this procedure are not persuasive, and as stated in the last review, this seems like cheating to get the model to predict more accurately.</p><p>Some arguments given by the authors as to why it is ok to use the data to predict the data:</p><p>“First, as detailed in the methods, we constrain the spike history term to be negative, meaning it cannot be used to predict future spikes, but rather only influences temporal patterning on short time scales due to refractoriness.”</p><p>If the spike history term is negative, thus causing silences, it helps the model predict future silences, which the same thing as changing the prediction of future spikes.</p><p>And <xref ref-type="fig" rid="fig5">Figure 5F</xref> shows the authors' claim that it cannot be used to predict future spikes isn't correct. With the spike history coming from the data, the beginning of bursts become more sharp, meaning the spike history is long enough for the data spikes in one burst to influence onset of spiking in the model's next burst. The decreased jitter in the statistics for the first spike in a burst confirms this.</p><p>Furthermore, the spike history goes out at least to 40 ms, and the full duration isn't shown or stated. The fact that it is small at 40 ms doesn't matter, because at long timescales the integration over multiple spikes will produce a large cumulative effect.</p><p>“Second, as we demonstrate, using a spike history term with an LN model (the LN+RP model in later figures) has poor performance in high contrast (<xref ref-type="fig" rid="fig5">Figure 5F</xref>), and also cannot explain contrast adaptation effects (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), and thus the spike-history term is only effective at explaining these effects in tandem with divisive suppression in a two-stage computation, which is a major point of this work. “</p><p>This just means that this inappropriate use of the data in the model is not sufficient alone to predict the response, but it is necessary. It is nonetheless using the data to predict the data.</p><p>“In these figures, we explicitly compare the spiking DivS model with the LN+RP model (without DivS) to show that DivS is necessary, and furthermore show that the DivS-RP model (without spike history) also cannot explain the response to high precision and contrast adaptation, demonstrating that it is the interplay of spike-history effects with the DivS computation that uniquely explain the ganglion cell response and its adaptation to contrast. As described above, the use of spike history is well vetted by much published work in modeling the retina, but the DivS model goes well beyond this to show it alone is not sufficient to explain ganglion cell firing, and must be combined with computations present at the input to ganglion cells. “</p><p>The use of spike history in a feedback loop as part of the model is acceptable of course, but using the data spikes in the model's prediction is not. It is not well vetted to use this procedure to draw conclusions about the model performance, and as mentioned in the previous review references exist to show that it can greatly improve a model prediction (Kraus et al., 2015, Figure S4; Trucculo, et al., 2010), which shows why it is not an acceptable procedure.</p><p>The following statements and conclusions are currently unsupported, and need to be supported by a model using a spike history feedback filter, and not spike history from the raw data. It's fine to take these conclusions about millisecond precision and full adaptation in the spiking model out of the paper, the paper could stand without them.</p><p>Abstract. &quot;The full model accurately predicted spike responses with unprecedented millisecond precision, and accurately described contrast adaption of the spike train.&quot;</p><p>Introduction. &quot;Ganglion cell firing, further shaped by spike generation mechanisms, could be predicted to millisecond precision.&quot;</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref>–<xref ref-type="fig" rid="fig6">6</xref> indicate that without the raw data (Div – RP model), predictions are no better than an LN model. Claims about precision should be removed unless a full spiking model with feedback spike history (without the raw data) is implemented.</p><p>Subsection “Contrast adaptation relies on both divisive suppression and spike refractoriness” &quot;Therefore, the two nonlinear properties of retinal processing, contrast adaptation and temporal precision, are tightly related mechanistically and can be simultaneously explained by the divisive suppression model.&quot;</p><p>Contrast adaptation in spiking for the Div – RP model is improved over an LN model, so that claim can be kept, although full adaptation is not captured.</p><p>2) Lack of slow contrast adaptation. There is currently insufficient evidence addressing the lack of slow contrast adaptation, and in fact the authors perform an analysis that would obscure evidence of slow adaptation. Unfortunately, the authors have resisted my request to show the raw data from a 20 s segment of the recording, which would show the change to both high and low contrast and the full 10 s recording at each contrast. It's ok if there is some slow adaptation, but they have to show whether it's there or not.</p><p>Slow adaptation is revealed only in the change in the average membrane potential (Manookin &amp; Demb, 2006). Gain and temporal filtering do not adapt slowly (Baccus &amp; Meister, 2003), but statistics for gain and temporal filtering are the focus of the supplemental figure. The only evidence that might have been in the figure is the vertical position of the nonlinearity, which would show the change in average membrane potential. But surprisingly, in the methods it states, citing (Chander &amp; Chichilnisky, 2001) &quot;The resulting nonlinearities were then aligned by introducing a scaling factor for the x-axis and an offset for the y-axis.&quot; This y-axis offset would remove the evidence of slow adaptation. This offset was not used in (Chander &amp; Chichilnisky, 2001) and should not be used here.</p><p>To be clear, three things must be done to address whether there is slow adaptation. 1) A full raw trace must be shown. 2) Nonlinearities must be shown without manipulation of the y-axis offset. 3) Because (Manookin &amp; Demb, 2006) shows that most slow adaptation decays by 1.5 s, they should show the membrane potential averaged over trials and binned in increments of no larger than 1 s across the full 20 s.</p><p>3) LNK model. The authors are trying to claim that a model of synaptic depression can't reproduce the effect that there is greater suppression is in one spatial location than another. It is good that the authors have tried to compare the DivS model with different types of LNK models having two pathways, but in order to rule out a possibility (localized suppression from a depression model), they have to show that they have sufficiently tried to make that possibility work.</p><p>The authors resisted my previous suggestion in the first round of review to consider that bipolar cells have center-surround receptive fields and that more than one bipolar cell feeds into a ganglion cell. This implies that for two pathways, one from the center and one from an annulus, each tested pathway should have an input from both central and peripheral regions. The DivS models was allowed to have two pathways, each with a different weighting from the center and surround, but the LNK model does not have such a mixture for each pathway. A model should be tested where each of the two pathways of the LNK model have a weighting of center and surround. To be clear, one pathway should represent bipolar cells in the center, and should have a stronger weighting from the center than the annulus. The other pathway should represent bipolar cells whose receptive field center is under the annulus region, and should have a stronger weighting from the annulus than the central spot. This fits most with known circuitry, because bipolar cells have center-surround linear receptive fields. This test will probably work as the authors predict, but the current comparisons are not adequate for their claim.</p><p>The previously published LNK model used a 4-state kinetic model, the current version of the paper now shows that a 3-state model was used here. This means that the simpler model chosen here can't reproduce all of the dynamics of the previous model. This difference needs to be clearly pointed out and justified in the main text. This issue also fits with showing whether that there is not slow adaptation, because it may be that the reason that the LNK model slightly underperforms the DivS model is that they chose a model with more simplified dynamics, yet the cell has both fast and slow dynamics.</p><p>4) Comparison to Spike Triggered Covariance. There is some confusion in the presentation about what STC analysis reveals, and the relationship to the DivS model.</p><p>“We added <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> to fully describe an STC analysis and added modeling data to <xref ref-type="fig" rid="fig2">Figure 2</xref>. As explained &gt;above, we more clearly demonstrate a number of key differences of the DivS &gt;model over the STC model, most notably the presence of divisive suppression. &gt;We now make clear the caveat that other cell types could require additional &gt;components to capture important features of the response in the Discussion.”</p><p>The following is a summary of the relationship, and it is basically in agreement with what is stated in the legend of <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>: STC analysis produces orthogonal vectors that define the stimulus subspace that drives the cell's response. It does not speak to the subsequent nonlinear mapping of that subspace to the response. In this case, if there is a two-dimensional subspace that defines the response, the filters of the DivS models must occupy the same subspace two STC eigenvectors. Thus this subspace can be found by a standard STC analysis not requiring a optimization procedure.</p><p>For the choice of nonlinear mapping of the subspace to the response, either there can be an n-D nonlinearity (2-D in this case), which would be the optimal solution, or a more simplified nonlinearity can be found. This is what the DivS model does, to simplify the 2-D nonlinearity to a product of 1-D nonlinear functions.</p><p>The reason I requested this detailed comparison was simply to avoid the mistaken conclusion that the DivS model is really a new class of model. It finds a reduced dimensional subspace just as STC does, and in fact such a standard technique can be used. The DivS model then does provide a set of constraints to reduce the complexity of the subsequent nonlinearity, reducing a 2-D nonlinearity to 1-D functions.</p><p>Even though the <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> legend basically agrees with these statements, there are several statements and analyses in the paper that indicate a confusion:</p><p>Subsection “The nonlinear computation underlying synaptic inputs to ganglion cells”. However, the 2-D mapping between STC filter output and the synaptic current differed substantially from the same mapping for the DivS model (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>This isn't possible if things were done correctly (and it seems to conflict with the <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> legend), the STC subspace should be the same as the DivS subspace, and the 2-D nonlinearity from the STC subspace should be the same as the mapping from subspace to response for the DivS model. I think this is just a problem of how something is being stated, but it should be corrected/clarified.</p><p>There is one potential difference between a full-2D nonlinearity from an STC subspace and the DivS model, and that is that the full 2-D nonlinearity may overfit, and thus the DivS model may impose a regularization that allows a better model of a test data set. If this is true, this is an interesting point to make, and it seems to be more relevant with the spiking model, because the authors say that can't fit the 2-D nonlinearity for spiking data (they can of course, but it must not be accurate).</p><p>In the same section, Thus, despite the ability of covariance analysis to nearly match the DivS model in &gt; terms of model performance (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), it could not uncover the divisive interaction between &gt; excitation and suppression (<xref ref-type="fig" rid="fig2">Figure 2G</xref>).</p><p>That's not the point of STC analysis, it only acts to find the relevant subspace. A second step would define the nonlinear mapping from subspace to response, either preserving the full 2-D nonlinearity, which would be the optimal solution, or simplifying the 2-D nonlinearity to a more biological combination of 1-D pathways.</p><p>It seems what the analysis of <xref ref-type="fig" rid="fig2">Figure 2E</xref> has done was to use the eigenvectors as filters for subsequent 1-D nonlinearities. That doesn't make any sense, the ideal 1-D nonlinearities have to lie in the 2-D subspace, but the 1-D nonlinearities don't have to be the eigenvectors, or even be orthogonal. This is not part of a standard STC analysis, and there is no reason to suspect that this would work.</p><p>The point of my request to state the relationship between the DivS model and STC analysis was not to pit STC analysis against the DivS model, because they should yield equivalent results as the stimulus subspace, and that's as far as STC analysis goes. It was so say that STC analysis will find the equivalent subspace as the DivS model, and that the DivS model provides a way to simplify the nonlinear mapping.</p><p>Discussion section, paragraph two. The presence of nonlinearities that are fit to data in the context of multiplicative &gt;interactions distinguishes this model from multi-linear models (two linear terms multiplying) &gt;(Ahrens et al., 2008a; Williamson et al., 2016), as well as more generalized LN models such as &gt;those associated with spike- triggered covariance.</p><p>This isn't clear, STC only identifies the subspace, and then multiplicative interactions can be identified within that subspace.</p><p>5) Circuit mechanisms underlying divisive suppression.</p><p>It is appropriate to discuss the possibility that inhibition does play a role in adaptation, but the authors have to mention the previous literature that says that inhibition isn't needed for contrast adaptation (Brown &amp; Masland, 2001; Manookin &amp; Demb, 2006). This is in their favor to do so, because they point out that their model suggests an unexpected mechanism for contrast adaptation.</p><p>There is another point that the author's may wish to mention that supports their argument. As they mention, On-α cells are more linear with a high spontaneous firing rate. Depression models rely on there being a change in the average level of synapse activation with contrast. With a linear cell, the average input to the synapse doesn't change much with contrast, and thus a change in the level of depression may not occur. Thus, inhibition from a modulatory pathway may be needed to create contrast adaptation for a more linear cell.</p><p>6) Meaning of Divisive Suppression. The authors use the term divisive suppression to apply both to one pathway modulating another (the usual term), and to any change in gain as might occur from synaptic depression. This second use is strange, if that's true, then the finding of divisive suppression isn't new, they have just called gain control something else.</p><p>The potential new concept is that the effect is better modeled by one pathway modulating the other. This is actually an old concept, (Victor) and has since been replaced by one where a second pathway is not necessary, namely synaptic depression. But the new result would be that the older concept of modulation works better, especially when one considers the spatial stimulus. To make this comparison and state this conclusion, it makes more sense to restrict 'divisive suppression' to mean modulation, and thus the question becomes one of Suppression vs. Depression, rather than saying depression is one type of suppression.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.19460.017</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the author responses to the first round of peer review follow.]</p><p><italic>Based on these discussions and the individual reviews below, we regret to inform you that this submission will not be considered further for publication in eLife. However, the reviewers and Editors thought that your study was interesting and worthwhile, and after discussion amongst the Editors it was decided that we would be happy to consider a revised paper, which would be considered as a new submission. Based on extensive discussions with the reviewers, the Reviewing Editor believes that a resubmission would be considered if you were to revise the paper in one of three ways: (1) undertake pharmacological studies as suggested by one reviewer, and therefore try to tie the model more closely to specific neural mechanisms; (2) use a wider range of stimuli, such as stimuli that include naturalistic slow temporal fluctuations (e.g., 1/f), and then modify the model as necessary to account for a broader range of phenomena; (3) try to get a better sense of which elements of the model are critical under what situations, but testing an even wider range of competing models and model variants. We thank you for sending your work for review and we hope you will either revise this work and resubmit it, or barring that you will wish to submit to eLife again in the future.</italic> </p><p>We appreciate the opportunity to resubmit our manuscript to <italic>eLife</italic>. According to our previous decision letter, the Editors recommended choosing one of three directions to expand our study: (1) pharmacology; (2) additional stimuli; (3) computation. We chose option 3: to test a wider range of competing computational models and model variants to clarify which elements of our DivS model are critical for capturing ganglion cell responses, with high temporal precision, at the levels of both synaptic currents and spikes.</p><p>A) The main advance of our paper is the identification of divisive suppression as a critical computation in retinal ganglion cells. We discovered a computational architecture that accurately captures the response properties in synaptic current. We expanded this description to capture spikes at millisecond resolution. In the process, we show that computational mechanisms identified in the synaptic current inputs contribute to high temporal precision in the spikes as well as to contrast adaptation. In the revision of the manuscript, we try to make clear the computational advance in our study and how our approach could inspire similar analyses in other parts of the brain.</p><p>B) We chose not to expand our study with additional pharmacological experiments at this time (editors’ option 1, above). Our <xref ref-type="fig" rid="fig4">Figure 4</xref> shows that a component of divisive suppression primarily originates in surround regions of the receptive field, whereas excitation primarily originates within the center region. The incomplete overlap between excitation and suppression is a novel finding, which we clarified through further material and revisions (see point E below). However, we realize that this observation does not rule out a combination of mechanisms for suppression, including both synaptic depression and a circuit mechanism for lateral inhibition. We now make this clear in the manuscript. We have a longer-term interest in delving further into the synaptic mechanism, but have chosen to keep the focus in this manuscript on the computation. Pharmacological experiments are not straightforward, because (i) blocking all [GABAergic + glycinergic] inhibition results in severe changes in mouse retinal function (Toychiev et al., 2013; our unpublished observations) and (ii) blocking receptors can alter the release of glutamate, which can in turn affect synaptic depression as well other effects on network function. We do hope the modeling approach presented in this manuscript can be used in tandem with such pharmacology to analyze underlying synaptic mechanisms in future studies. In this manuscript, we have therefore focused on the computational description of suppression and tempered the conclusions regarding specific synaptic mechanisms.</p><p>C) We added “covariance” analysis similar to spike-triggered covariance (STC) that can be applied to synaptic currents (i.e., continuous, event-free data). Further, we derived methods to make predictions with this analysis (using a 2-D nonlinearity that can be fit to data as part of the covariance model) – not commonly done with STC – allowing for direct comparisons to other models considered in the manuscript. Our analysis shows that covariance analysis can identify the feature space that drives the ganglion cell response (consistent with previous STC analyses of spikes), but it does not identify the critical divisive interaction identified by the DivS model. Likewise, while the covariance model coupled with a 2-D nonlinearity can generate nearly as good predictions of synaptic currents, the number of parameters it requires, as well as its inability to fit simultaneously with spike-refractoriness, make it unable to be used for accurate predictions of spikes. By comparison our spike responses (~1 minute of unique data at each contrast) could routinely be fit by the DivS model, yielding unprecedented accuracy of any spike-based model of sensory neurons. We believe that our new analysis (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) makes a valid and important comparison between STC and DivS models, and shows the advantages of the DivS model. This is coupled with comparisons in the revised manuscript to other modeling approaches, underscoring the uniqueness of the DivS model and its ability to identify the computations performed by the retinal circuit.</p><p>D) We have analyzed the stability of responses during each contrast half-cycle and examined possible effects of slow adaptation (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Our findings clearly show (i) highly stable responses and (ii) no sign of slow contrast adaptation. Notably, an earlier study of slow contrast adaptation (Manookin and Demb, 2006) focused on OFF Α ganglion cells in guinea pig, whereas here we focus on ON Α ganglion cells in mouse. We would have to modify the DivS model to account for slow contrast adaptation in other cell types in the future: such slow mechanisms likely act in tandem with those identified in this study.</p><p>E) We demonstrate that the DivS model captures the form of synaptic depression implemented in the standard version of the LNK model (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We have expanded this analysis to look at more complex forms of the LNK model that include both center and surround components (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). There are many possible variations of the LNK model, and we considered two reasonable cases where nonlinear center and surround components sum before applying synaptic depression vs. separate center and surround LNK models sum following depression. In both cases, we find that the DivS model can capture the effects of depression, and thus encompass mechanisms described by the LNK model. Furthermore, we show that in all such models, the excitation and suppression are always matched in their relative strengths in center vs. surround; whereas the recorded ganglion cell responses (<xref ref-type="fig" rid="fig4">Figure 4</xref>) analyzed with the DivS model show dissociation between strong excitation in the center and relatively strong suppression in the surround.</p><p>Collectively, the data and analysis in <xref ref-type="fig" rid="fig4">Figure 4</xref> and the new analysis of the LNK model validate our conclusion that suppression has a wider spatial footprint than excitation. This pattern is consistent with a component of suppression that originates in a circuit mechanism (and is inconsistent with the LNK model), demonstrating the novelty of this result. As noted above, however, we cannot rule out a contribution from synaptic depression over the central region, and have clarified this point in the revised manuscript.</p><p><italic>Reviewer #1:</italic> </p><p><italic>This paper studies the responses of mouse α retinal ganglion cells responding to flickering white noise at two different contrast, and fits the response with a computational model. The model is an abstract model consisting of two pathways, with one influencing the other, which is one of a general class of known models with multiple pathways followed by a nonlinear static (time-independent) interaction. It is shown that the model accurately captures the response and some properties of contrast adaptation. An argument is made why the model can be interpreted to show that inhibition underlies contrast adaptation. Other aspects of the model such as the source of precise firing are discussed. Currently the claim of the role of inhibition is not well supported, and the result that a more simple model of a known type fits the data for one type of ganglion cell is interesting, but mainly to the community of people that fit models of the retina.</italic> </p><p>We appreciate these thoughtful comments. As noted above (see Author Points A, B, and E), we hope that we now make the point more clearly that our study’s main achievement is demonstrating how “divisive suppression” is a crucial component of retinal computation, and how it is part of a two-stage computation, which altogether can almost perfectly explain ON-Alpha responses — both their high temporal precision, and their adaptation to contrast. We now give a more balanced description of the underlying mechanism for divisive suppression, which is probably a combination of a circuit mechanism and synaptic depression. However, the precise mechanistic source of divisive suppression is not the main purpose of this work, and most of the novel results relate to identifying computations in the synaptic input, compared with those within the ganglion cell spike output, and demonstrate how precision and contrast adaptation might be simply explained in this description.</p><p>We have taken the reviewer’s comments to heart in this light, but rather than addressing the mechanism with more targeted experiments — which is not central to our main results — we instead rewrote many sections of the manuscript (as described below) to emphasize the achievements of this work more clearly. Furthermore, we added new modeling results to show that the divisive mechanism could explicitly capture synaptic depression, and thus offers a broader framework with which to consider ganglion cell computation (and the means to characterize it).</p><p><italic>Major points</italic> </p><p><italic>1) A central claim of the paper is that the model indicates that adaptation comes from inhibitory suppression. This claim is in conflict with other studies, including one from the Demb lab (Brown &amp; Masland, Manookin &amp; Demb 2006).</italic> </p><p>See Author points B and D above; we give a more balanced description of the mechanism. Furthermore, we now demonstrate a lack of slow adaptation in our recordings of mouse ON-Alpha cells (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><p><italic>The current evidence for this claim is not sufficient, and a pharmacological experiment blocking inhibition has to be done for this claim to be supported. If it turns out that blocking inhibition abolishes adaptation and changes the response of the model in the expected way, then this should be the main focus of the paper, and the model should be used to support this main claim. In doing this experiment, the primary concern will be that without inhibition, the retina is put in a different state, where adaptation does not occur, even though inhibition is not really involved. For example, without inhibition, neurons will depolarizes and synapses may be depressed even at low contrast. So care must be taken to avoid this issue. In particular, the expectation is that the excitatory direction changes little, but the suppressive direction disappears. Because the low contrast is 10% (which is still fairly strong) it may be useful to use a lower contrast.</italic> </p><p>See Author point B above. We agree that this experiment could be complicated and feel that our paper should remain focused on the advances in the computational description. We now give a more balanced description of likely mechanisms for divisive suppression, which does not rule out a contribution from synaptic depression.</p><p><italic>2) The authors interpret the 'suppressive' direction to mean inhibition, but the alternative interpretation that the authors wish to argue against is that feedback at excitatory synapses produces an apparent suppression when fit with the DivS model. It is quite suspicious that the suppressive direction (temporal filter) in <xref ref-type="fig" rid="fig2">Figure 2B</xref> looks exactly like a delayed version of the excitatory temporal filter. This seems to imply that the suppressive direction might indeed be from negative feedback – though admittedly such negative feedback could from synaptic depression or inhibition. The results presented are consistent with the current model of synaptic depression (not inhibition) underlying adaptation, except for <xref ref-type="fig" rid="fig4">Figure 4</xref>, which relies on a questionable assumption (discussed below). That's why the pharmacological test is critical.</italic> </p><p>See Author points B and E above. We now show that synaptic depression, as implemented by the LNK model, does indeed yield the delayed suppressive filter that otherwise resembles the excitation filter (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>). However, the result from <xref ref-type="fig" rid="fig4">Figure 4</xref> shows that excitation and suppression do not have the same spatial footprint, which cannot be explained by the mechanism implemented by the LNK model. This provides evidence for a contribution from an alternate circuit mechanism to divisive suppression, although we cannot rule out additional contributions from synaptic depression to stimuli presented in the center (i.e., that overlaps the region of excitation). We now make this clear in the manuscript.</p><p><italic>3) As the sole support of the claim that the suppressive component of the model comes from inhibition, a spatial stimulus is used in <xref ref-type="fig" rid="fig4">Figure 4</xref>. This brings a new level of complexity is not properly addressed. When space is considered, we know that bipolar cells have a receptive field center and surround with different temporal filters. Bipolar cells form nonlinear subunits, each with a threshold (Schwartz et al., 2012 for mouse α cells). Each of these small subunits show local adaptation (Brown &amp; Masland, 2001) and then there is global adaptation in the ganglion cell from spike generation (Zaghloul et al. 2005). The logic the authors use is the suppressive direction should be the same as the excitatory direction if inhibition is not involved. It is not clear whether this is true when the more complex system is considered. The 'excitatory' and 'suppressive' directions are just the two directions in stimulus space that influence the response, and the suppressive direction will be influenced by feedback at bipolar cell synapses and in the ganglion cells. The surround time course is more delayed, and may match the delayed suppression from negative feedback more closely. Thus it is not clear whether the simple DivS model will mix inputs in unexpected ways. The fact that the suppressive and excitatory directions are different is not conclusive without further consideration of the known sites of nonlinearities and adaptation.</italic> </p><p>The complexity of the retinal circuit when spatial stimuli are involved was the main motivation for the design of the stimulus in <xref ref-type="fig" rid="fig4">Figure 4</xref>, which only introduces two spatial components (center and annulus) to limit the number of possible interactions between nonlinear components. We believe this experiment (and resulting analysis) is novel both because (1) the experimental data can distinguish between our model of divisive suppression and *existing* models of ganglion cell processing (including the LNK model of synaptic depression) that can be fit to data, and (2) it reveals that new mechanisms must be present, in the sense that existing models cannot explain the data. Furthermore, the DivS model can explain the response of this more challenging stimulus nearly perfectly (&gt;90% explainable variance at millisecond resolution) without needing to consider all these additional complexities, suggesting the simple divisive mechanism presented in this manuscript is sufficient to capture such complexities. To our knowledge this level of precision has not even been tested in any other study to date, much less reproduced using a simple two-pathway model.</p><p>Furthermore, we have now performed a number of additional simulations (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>) to investigate several more complex models involving rectification and the application of synaptic depression in various combinations. The conclusions of this are two-fold: (1) in all these simulations, the source of divisive suppression still strongly correlates with that of excitation, as identified by the DivS model, which is not the case for the observed data; (2) the DivS model can still predict the response as generated by these more complex mechanisms relatively accurately, although it describes the observed ganglion cell responses with much better performance compared with data generated through these more complex models. Other modeling approaches, including the LNK model as well as covariance-based models, cannot currently scale to capture the multiple interactions in this complex model, due to the lack of convexity (which the reviewer refers to below in point 6 for the LNK model) and the dependence on response-weighted averaging for covariance-based models. Thus, these supplemental figures also demonstrate the unique ability of the DivS model to characterize these more complex interactions.</p><p>We recognize that we cannot eliminate all alternative explanations, and have clarified the purpose of the experiment and analyses considered in <xref ref-type="fig" rid="fig4">Figure 4</xref> (see Author Points B and E above). We hope to have clarified that this material is useful for distinguishing between different models, and clarified the general utility of the DivS model in characterizing retinal computation, regardless of mechanism.</p><p><italic>4) Because the model has no slow dynamics, it cannot capture contrast adaptation that lasts over several seconds, which has been the sole subject of some studies of contrast adaptation (Manookin &amp; Demb, 2006). The entire 20 s stretch of recording should be shown of the data, so it can be properly evaluated what aspects of the response cannot be fit by the model. Furthermore, the claims about the accuracy of the model should be qualified in terms of the aspects of adaptation that it does not capture.</italic> </p><p>The sections of the data and model predictions that currently are shown (<xref ref-type="fig" rid="fig3">Figures 3C</xref>, <xref ref-type="fig" rid="fig4">4G</xref>, <xref ref-type="fig" rid="fig6">6A</xref>, <xref ref-type="fig" rid="fig7">7A</xref>) are zoomed to demonstrate the high-temporal resolution that the model fits, and we have thus added measurements demonstrating the lack of slow dynamics in the recordings (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>; see Author Point D above). Furthermore, we now mention several components of adaptation present in other ganglion cells that could be addressed in future work, in the last paragraph of the Discussion.</p><p><italic>5) Class of model. If in fact there are only two stimulus directions that are important as is claimed, than the DivS model is equivalent to a model that can be created using standard Spike-Triggered Covariance (STC) analysis (Fairhall et al., 2006), which can equivalently be done with continuous currents. So it should be pointed out that this model is not a new type of model, but an example of a known type of model. In (Fairhall, 2006) there are multiple types of ganglion cells reported with different types of responses in the two-D feature space, yet contrast adaptation is widespread among ganglion cells, so it is likely that the interpretations of the current paper won't apply generally. It is ok to study one type of cell, but the fact that the model presented is one of a known class of models should be made clear.</italic> </p><p>See Author point C. above. We added <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> to fully describe an STC analysis and added modeling data to <xref ref-type="fig" rid="fig2">Figure 2</xref>. As explained above, we more clearly demonstrate a number of key differences of the DivS model over the STC model, most notably the presence of divisive suppression. We now make clear the caveat that other cell types could require additional components to capture important features of the response in the Discussion</p><p><italic>6) The LNK model is not convex, and more detail should be given as to how this was optimized. Were the methods of (Ozuysal &amp; Baccus, 2012) used? For example, mean squared error was not used as an error metric. If the method of fitting was suboptimal, then the interpretation of the comparison between models is not clear. Also, more detail needs to be given for the spatial LNK model. Because there are two different spatial regions, each one should have independent adaptation, and each spatial region should have a center-surround linear receptive field. This would be a new type of model, so it's not clear whether this model can be properly optimized.</italic> </p><p>We apologize for omitting in the previous manuscript how the LNK model was fit, and now include an additional section of the Methods describing this (lines 559-568). In brief, we explicitly followed the methods of Ozuysal &amp; Baccus, although we needed to use different model initializations due to the much faster time courses of the neurons in our study. When fit to temporally modulated spot data, the LNK model is quite successful (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), validating our fitting approach. We extended the LNK model to the center-annulus stimulus (as now described in the Methods), and have added additional detail about this extension in added figure panels (<xref ref-type="fig" rid="fig4">Figure 4B and C</xref>), as well as in two supplemental figures (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref>, <xref ref-type="fig" rid="fig4s2">2</xref>) comparing several LNK-based simulations to the DivS results. This hopefully further clarifies the relationships between these models.</p><p>The difficulty in fitting the LNK model is indeed a main limitation for its applicability more generally, and we have now made clear in the revised manuscript that the DivS model is a much more tractable alternative. For fitting the LNK model, while we are convinced that we have achieved optimal results for the examples considered here (following established methods), to our knowledge the LNK model will be limited to fitting relatively simple data. By comparison, the DivS model is relatively well-behaved (including requiring a fraction of the fitting time), and is much more flexible in describing both simulated data generated by more complex combinations of nonlinearities (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>) as well as actual ganglion cell recordings (<xref ref-type="fig" rid="fig4">Figure 4</xref>). We thus have rewritten sections of the manuscript to highlight the flexibility and applicability of this modeling approach, rather than focusing on mechanistic differences (as in the previous manuscript).</p><p><italic>7) For the spiking DivS model, does the model really take the observed spike train as an input (not just as a constraint to fit data)? Shoudn't a model that takes the response as an input be able to produce the response? (It seems like cheating.) In fact, some studies that use the spike history in the way have shown that using the spike history is either the most important predictor of the response, or that the spike history alone can be used to predict the response (Kraus et al., 2015, Figure S4; Trucculo, et al., 2010).</italic> </p><p>We are glad for this thoughtful concern, as it is potentially a subtle problem in previous studies using the spike history term, where this term is allowed to be positive. When it is positive, previous spikes can be used to predict the next spikes, and (as in the studies listed above), one can do quite well in using the spike-history term to predict future spikes, especially if spikes are correlated over long time scales. This is not as much of a concern in the retina, where time correlations are short (and there is much previous literature validating this approach in the retina, particularly from Paninski and Pillow).</p><p>However, we can eliminate this as a concern in this study for several reasons. First, as detailed in the methods, we constrain the spike history term to be negative, meaning it cannot be used to predict future spikes, but rather only influences temporal patterning on short time scales due to refractoriness. Second, as we demonstrate, using a spike history term with an LN model (the LN+RP model in later figures) has poor performance in high contrast (<xref ref-type="fig" rid="fig5">Figure 5F</xref>), and also cannot explain contrast adaptation effects (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), and thus the spike-history term is only effective at explaining these effects in tandem with divisive suppression in a two-stage computation, which is a major point of this work.</p><p><italic>If this is really what was done, this approach differs from other models which use a spike-history term such as a generalized linear model (GLM) (Pillow et al., 2008) but that generate its own spikes rather than taking the actual response as an input. This needs to be made more clear, and also justified as to why this is useful. This approach may be useful for understanding the source of precision as the authors do, but it doesn't seem impressive that this model can fit the data if it really takes the actual response as an input.</italic> </p><p>We hope that the clarification above explains how the model is more impressive given that it uses spike-history as a suppressive term that only has effects at a short time scale. Furthermore, the larger point of these figures on the spiking DivS model (<xref ref-type="fig" rid="fig6">Figures 6</xref>–<xref ref-type="fig" rid="fig8">8</xref>) is not that the spike-history term explains the spike response – quite the opposite. In these figures, we explicitly compare the spiking DivS model with the LN+RP model (without DivS) to show that DivS is necessary, and furthermore show that the DivS-RP model (without spike history) also cannot explain the response to high precision and contrast adaptation, demonstrating that it is the interplay of spike-history effects with the DivS computation that uniquely explain the ganglion cell response and its adaptation to contrast. As described above, the use of spike-history is well vetted by much published work in modeling the retina, but the DivS model goes well beyond this to show it alone is not sufficient to explain ganglion cell firing, and must be combined with computations present at the input to ganglion cells.</p><p><italic>8) <xref ref-type="fig" rid="fig6">Figure 6</xref>, it is not clear where the noise comes from in the model, as there is no noise source. Is it all from the spike-history term, i.e. the actual data? It's not clear how we can evaluate different models using this approach, because the noise is not appropriate for each model. A better approach would be to model noise sources and put them in each different model, like an LNP model.</italic> </p><p>We apologize for omitting this from the previous version of the manuscript, and have added a sentence describing this detail in the Methods (lines 621-623). We used a non-homogeneous Poisson process to generate spikes from predicted firing rates. This is standard practice in most models of the retina and other visual neurons, and initial work comparing inhomogeneous Poisson processes to more realistic (but less tractable) integrate-and-fire processes (e.g., Pillow et al., 2005) has shown they yield equivalent models (see Paninski, Pillow, and Lewi chapter (2007): “Statistical models for neural encoding, decoding, and optimal stimulus design”). In other words, while there is still great debate on the actual noise sources underlying the lack of reproducibility of spike trains from trial-to-trial (see for example our recent paper McFarland et al., 2016), previous work particular to the retina has shown that our assumptions have no discernible effect on estimation of the model components.</p><p><italic>Reviewer #2:</italic> </p><p> <italic>[…]</italic></p><p><italic>Major comment:</italic> </p><p><italic>My only concern is about novelty: as noticed by the authors, another model, the LNK by Ozuysal and Baccus, has already shown its ability to predict ganglion cell responses at different contrasts. The performance of the current model is better than the LNK, but not by much for full field stimuli. The only stimulus where there is a significant difference, if I understood well, was the one composed of a center spot and an annulus stimulating the surround. There the model performed better, but the difference is rather small (around 7%).</italic> </p><p>To address this and the Reviewer 1’s comments, we have rewritten the manuscript to emphasize that the DivS model is a different – and in fact more general – explanation for retinal processing, such that divisive suppression appears to be a central component of ganglion cell computation (see Author Point E above). In <xref ref-type="fig" rid="fig4">Figure 4</xref>, the reason that the differences between models are smaller was because the LN model itself performs very well in the center-annulus stimulus, and one of the key points of this figure is the LNK model (i.e., adding synaptic depression), does no better than the LN model, meaning that this explanation itself cannot explain the results. In contrast, the DivS model outperforms both, showing that these added nonlinearities are present in the retinal computation. We hope that by making this more explicit in <xref ref-type="fig" rid="fig4">Figure 4</xref> (as well as accompanying <xref ref-type="fig" rid="fig4s1">Figures 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>), and recasting the main points of our manuscript (including greatly elaborating the distinctions between the LNK and DivS model), that the novelty of the results (and the approach in general) is clear.</p><p><italic>The model is conceptually novel, but relatively similar to previous works by Sahani and colleagues.</italic> </p><p>Sahani et al. have pioneered the multi-linear model, which is two linear terms that multiply one another. Such a model is conceptually distinct from the DivS model, which involves the multiplicative interactions of LN components – the important distinction being the nonlinearities, and the means to estimate them. Indeed, multiplication between model components is a well-worn idea (such as “gain terms”) and present in some form in many previous models, and the novelty of the Sahani model (e.g., Ahrens et al., 2008a; Williamson et al., 2016) was the statistical application of multiplicative linear terms. Such a model is not sufficient to explain the interactions we see (as the nonlinear suppression is critical), and the novelty of the model is to introduce such multiplicative interactions between nonlinear terms in a tractable context that can be fit to both intracellular and extracellular data. We agree that clarifying the novelty of our modeling approach in the context of previous work, and in addition to adding supplemental figures addressing STC and the LNK models (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>), we have added to the Discussion in this regard, most notably on lines 342-351):</p><p>“While divisive gain terms have been previously suggested in the retina – particularly in reference to early models of contrast adaptation (Mante et al., 2008; Meister and Berry, 1999; Shapley and Victor, 1978) – critical novel elements of the present DivS model include the ability to fit the nonlinearities of both LN terms by themselves, as well as their tractability in describing data at high time resolution. The presence of nonlinearities that are fit to data in the context of multiplicative interactions distinguishes this model from multi-linear models (two linear terms multiplying) (Ahrens et al., 2008a; Williamson et al., 2016), as well as more generalized LN models such as those associated with spike-triggered covariance (Fairhall et al., 2006; Samengo and Gollisch, 2013; Schwartz et al., 2006). Furthermore the model form allows for inclusion of spike-history terms as well as spiking nonlinearities, and can be tractably fit to both synaptic currents and spikes at high time resolution (~1 ms).”</p><p><italic>So I think a more thorough comparison between the LNK model and this one would be welcomed. With such a small difference, one would like to be sure that the authors gave the LNK model its best chance of success. Here the methods do not include a text about how this model was fitted. More generally, more details would be welcomed about how the two models were fitted in the case of the compound stimulus (centered spot +annulus).</italic> </p><p>We apologize for this omission of methods, and further agree (also with Reviewer #1) that the manuscript would benefit from much more elaboration about the LNK model, and its relationship with the DivS model (see Author Point E above). We have also added a section in the Methods (lines 559-568), panels in <xref ref-type="fig" rid="fig4">Figure 4</xref>, and two supplemental figures (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>) offering further detail about the relationships between the models, and especially how the DivS model is an advance.</p><p>[Editors' note: the author responses to the re-review follow.]</p><p><italic>[…]</italic></p><p><italic>Reviewer #2:</italic> </p><p><italic>The paper has improved from the previous version, but a number of issues remain that were raised in the first review. The main positive points are that it captures contrast adaptation in a particular cell type with a simple model, and that it raises a new potential mechanism for adaptation using one pathway modulating another, which is different from the accepted explanation of synaptic depression. It can be made suitable for publication, but a number of things must be done.</italic> </p><p>We are grateful for the additional suggestions and hope to have addressed the remaining issues completely in the revision, as described below.</p><p><italic>1) Spike history. For the spiking DivS model, the authors use the raw data as an input to the model when predicting the data. This seemed to be the case in the last review, although it was baffling to me and surprised both reviewers. Insufficient justification has been given for this procedure, and I can't conceive of any justification for it. The arguments given by the authors for this procedure are not persuasive, and as stated in the last review, this seems like cheating to get the model to predict more accurately.</italic> </p><p>There is apparently a misunderstanding that we did not clear up in the last round of review. Our model predictions of the spiking data do not use the observed spike trains themselves. This was described in the Methods section in the previous draft:</p><p>“Note that for validation of spike-based models, we simulated individual instances of spike trains using a non-homogeneous Poisson process, and the model predictions were based on many repeats for which we generated a PSTH.”</p><p>In other words, all model performance measures reported in previous versions (and the current version) of the manuscript used simulated spikes, and not actual recorded spikes, to generate model predictions. This includes all reported results about the spike-based models (including the GLM) in <xref ref-type="fig" rid="fig5">Figures 5F</xref>, <xref ref-type="fig" rid="fig6">6,</xref> and <xref ref-type="fig" rid="fig7">7</xref> (and the associated text).</p><p>We regret that we may have confused the issue in the last rebuttal by arguing that it is theoretically possible to use previously observed spikes to validate model performance. Clearly there is a debate in the field about this issue. In this rebuttal, we do not seek to resolve this issue, because in the manuscript we have generated spikes without taking into account the recorded spikes, consistent with the Reviewer’s recommendation.</p><p>As a result, our manuscript follows the following recommendation from the editor’s letter:</p><p>“Option 2: Run the model again, but using a spike history filter generated from synthetic spikes rather than using the raw data in the model prediction as was done in the most recent revision.”</p><p>We are sorry it was not clear that we had already done this in previous versions of the manuscript. To make this point absolutely clear in this revision, we have updated the descriptions of all the methods to accentuate this point. We have updated the specific labels in the relevant modeling diagram (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><p>Thus, we will not argue further the validity of using past observed spikes to evaluate model performance (below), although look forward to spirited debate in the future to ultimately resolve this issue (outside of the context of this review process).</p><p><italic>Some arguments given by the authors as to why it is ok to use the data to predict the data:</italic> </p><p><italic>“First, as detailed in the methods, we constrain the spike history term to be negative, meaning it cannot be used to predict future spikes, but rather only influences temporal patterning on short time scales due to refractoriness.”</italic> </p><p><italic>If the spike history term is negative, thus causing silences, it helps the model predict future silences, which the same thing as changing the prediction of future spikes.</italic> </p><p><italic>And <xref ref-type="fig" rid="fig5">Figure 5F</xref> shows the authors' claim that it cannot be used to predict future spikes isn't correct. With the spike history coming from the data, the beginning of bursts become more sharp, meaning the spike history is long enough for the data spikes in one burst to influence onset of spiking in the model's next burst. The decreased jitter in the statistics for the first spike in a burst confirms this.</italic> </p><p><italic>Furthermore, the spike history goes out at least to 40 ms, and the full duration isn't shown or stated. The fact that it is small at 40 ms doesn't matter, because at long timescales the integration over multiple spikes will produce a large cumulative effect.</italic> </p><p><italic>“Second, as we demonstrate, using a spike history term with an LN model (the LN+RP model in later figures) has poor performance in high contrast (<xref ref-type="fig" rid="fig5">Figure 5F</xref>), and also cannot explain contrast adaptation effects (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), and thus the spike-history term is only effective at explaining these effects in tandem with divisive suppression in a two-stage computation, which is a major point of this work. “</italic></p><p><italic>This just means that this inappropriate use of the data in the model is not sufficient alone to predict the response, but it is necessary. It is nonetheless using the data to predict the data.</italic> </p><p><italic>“In these figures, we explicitly compare the spiking DivS model with the LN+RP model (without DivS) to show that DivS is necessary, and furthermore show that the DivS-RP model (without spike history) also cannot explain the response to high precision and contrast adaptation, demonstrating that it is the interplay of spike-history effects with the DivS computation that uniquely explain the ganglion cell response and its adaptation to contrast. As described above, the use of spike history is well vetted by much published work in modeling the retina, but the DivS model goes well beyond this to show it alone is not sufficient to explain ganglion cell firing, and must be combined with computations present at the input to ganglion cells. “</italic></p><p><italic>The use of spike history in a feedback loop as part of the model is acceptable of course, but using the data spikes in the model's prediction is not. It is not well vetted to use this procedure to draw conclusions about the model performance, and as mentioned in the previous review references exist to show that it can greatly improve a model prediction (Kraus et al., 2015, Figure S4; Trucculo, et al., 2010), which shows why it is not an acceptable procedure.</italic> </p><p><italic>The following statements and conclusions are currently unsupported, and need to be supported by a model using a spike history feedback filter, and not spike history from the raw data. It's fine to take these conclusions about millisecond precision and full adaptation in the spiking model out of the paper, the paper could stand without them.</italic> </p><p>We hope that it is now clear that we did exactly what is suggested above for the spiking-model predictions: spikes were generated using a Poisson process, which was iterated forward in time. The spike history for this simulated spike train depended solely on these past simulated spikes. We apologize for any confusion regarding these methods, and hope that the issue has been clarified.</p><p><italic>Abstract. &quot;The full model accurately predicted spike responses with unprecedented millisecond precision, and accurately described contrast adaption of the spike train.&quot;</italic> </p><p><italic>Introduction. &quot;Ganglion cell firing, further shaped by spike generation mechanisms, could be predicted to millisecond precision.&quot;</italic> </p><p>As a result, we expect that it is not necessary to change these above sentences, as the simulated spike train did actually capture the true spike train to millisecond precision (without using the raw data).</p><p><italic><xref ref-type="fig" rid="fig5">Figure 5</xref>–<xref ref-type="fig" rid="fig6">6</xref> indicate that without the raw data (Div – RP model), predictions are no better than an LN model. Claims about precision should be removed unless a full spiking model with feedback spike history (without the raw data) is implemented.</italic> </p><p>We have clarified <xref ref-type="fig" rid="fig5">Figure 5A</xref> to demonstrate that the model does not use the observed spike train to make model predictions, and changed the label from “Observed spike train” to “Spike history”. <xref ref-type="fig" rid="fig6">Figure 6</xref> is meant to demonstrate the contribution of spike history to explaining the full spike response. Given that we have now clarified that all measures are based on simulated spikes (and do not use the observed spike trains in any way), we believe <xref ref-type="fig" rid="fig6">Figure 6</xref> is appropriately stating the results as stands.</p><p><italic>Subsection “Contrast adaptation relies on both divisive suppression and spike refractoriness” &quot;Therefore, the two nonlinear properties of retinal processing, contrast adaptation and temporal precision, are tightly related mechanistically and can be simultaneously explained by the divisive suppression model.&quot;</italic> </p><p><italic>Contrast adaptation in spiking for the Div – RP model is improved over an LN model, so that claim can be kept, although full adaptation is not captured.</italic> </p><p>We believe that the clarifications to the methods also make changing these above sentences unnecessary.</p><p><italic>2) Lack of slow contrast adaptation. There is currently insufficient evidence addressing the lack of slow contrast adaptation, and in fact the authors perform an analysis that would obscure evidence of slow adaptation. Unfortunately, the authors have resisted my request to show the raw data from a 20 s segment of the recording, which would show the change to both high and low contrast and the full 10 s recording at each contrast. It's ok if there is some slow adaptation, but they have to show whether it's there or not.</italic> </p><p>We apologize for not initially taking the suggestion of the reviewer, and had meant to satisfy the request with what was shown in the previous <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. We now show the requested panels in a modified version of this Figure, which is now divided into two supplemental figures associated with <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p><p>Specifically, we now show a single 20-second segment of the stimulus and synaptic current for an example ON-Α cell (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). We then further analyze this by presenting the mean and standard deviation of the synaptic current within 1-sec windows for this example cell, and also show this quantity averaged over the recorded population (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). There is very little discernable drift in the average synaptic current relative to variation in current driven by the stimulus (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). For completeness, we also show the same analysis for the spikes (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>).</p><p>Consistent with the reviewer’s statement above, we would like to stress that the purpose of this supplemental figure is not to argue whether ON-Α cells have slow contrast adaptation. Rather, it is an explanation for why our model — which has no slow adaptation mechanisms present – is able to fit this data with unprecedented accuracy. We hope this supplemental figure makes clear that the magnitude of this slow adaptation — if it exists at all — is very small relative to the stimulus-driven variations in current (i.e., compare changes in mean with the standard deviation of the current, shown by the error bars in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>).</p><p>Furthermore, as Reviewer #1 also noted, we agree that our revision needed to make clear that the divisive suppression model can explain fast contrast adaptation, but does not address slow adaptation, which is largely absent in this experimental context. We have thus made this point explicit in the revised manuscript, both in response to Reviewer #1’s comment (see above), as well as adding additional Discussion.</p><p><italic>Slow adaptation is revealed only in the change in the average membrane potential (Manookin &amp; Demb, 2006). Gain and temporal filtering do not adapt slowly (Baccus &amp; Meister, 2003), but statistics for gain and temporal filtering are the focus of the supplemental figure. The only evidence that might have been in the figure is the vertical position of the nonlinearity, which would show the change in average membrane potential.</italic> </p><p>We agree — we left out the most important aspect to resolve this issue in the original <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, and have now corrected this omission. We believe that the updated supplemental figure now has exactly what was requested, including directly addressing the vertical position of the nonlinearity between the first and last 3 seconds of each trial (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E,F</xref>), which is predicted by the DivS model (as shown in a new <xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p><p>Furthermore, these observations of little-to-no slow contrast adaptation are not inconsistent with Manookin and Demb (2006). Despite the different species and stimulation protocols, the one example of an ON-Α cell shown in <xref ref-type="fig" rid="fig5">Figure 5J</xref> (Manookin and Demb 2006) also exhibited a much smaller and shorter after-hyperpolarization relative to OFF-Α cells, which were the focus of that study.</p><p><italic>But surprisingly, in the methods it states, citing (Chander &amp; Chichilnisky, 2001) &quot;The resulting nonlinearities were then aligned by introducing a scaling factor for the x-axis and an offset for the y-axis.&quot; This y-axis offset would remove the evidence of slow adaptation. This offset was not used in (Chander &amp; Chichilnisky, 2001) and should not be used here.</italic> </p><p>Chander &amp; Chichilnisky (2001) developed this analysis to introduce the gain into the filter of the LN model itself based on spiking data, which does not have much of an offset to account for (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>). However, as <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref> shows, the current data has a consistent offset in the y-axis of the nonlinearity. Also, subsequent work addressed the importance of distinguishing between gain and offset (see for example Lesica and Stanley, Network, 2006). As a result, we introduced an offset parameter when aligning the nonlinearities across contrast, so that we could accurately perform the scaling to match the slopes of the nonlinearities (and then scale the corresponding filters accordingly).</p><p>Nevertheless, we agree with the reviewer that the offset adjustment should not be overlooked. In fact, we had not paid much attention to it until creating the new version of <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, because the DivS model requires no offset adjustment to fit the contrast changes. Thus, this line of questioning has revealed an extra element of the data we believe is worth reporting. First, we now explicitly demonstrate the offset in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>: both in the raw and average traces, as well as the LN model fits to the currents. [The offset is now also included in the LN models shown in <xref ref-type="fig" rid="fig1">Figure 1E</xref>.] Second, we now report these offsets in this supplemental figure. Finally, we now demonstrate that the DivS model predicts this offset difference between high and low contrast without any parameter adjustment (<xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p><p><italic>To be clear, three things must be done to address whether there is slow adaptation. 1) A full raw trace must be shown. 2) Nonlinearities must be shown without manipulation of the y-axis offset. 3) Because (Manookin &amp; Demb, 2006) shows that most slow adaptation decays by 1.5 s, they should show the membrane potential averaged over trials and binned in increments of no larger than 1 s across the full 20 s.</italic> </p><p>As described above, we have explicitly performed (1) and (3) in the revision, and for (2) have now demonstrated explicitly the offset shift in the LN model, which can be reproduced by the DivS model.</p><p><italic>3) LNK model. The authors are trying to claim that a model of synaptic depression can't reproduce the effect that there is greater suppression is in one spatial location than another. It is good that the authors have tried to compare the DivS model with different types of LNK models having two pathways, but in order to rule out a possibility (localized suppression from a depression model), they have to show that they have sufficiently tried to make that possibility work.</italic> </p><p><italic>The authors resisted my previous suggestion in the first round of review to consider that bipolar cells have center-surround receptive fields and that more than one bipolar cell feeds into a ganglion cell. This implies that for two pathways, one from the center and one from an annulus, each tested pathway should have an input from both central and peripheral regions. The DivS models was allowed to have two pathways, each with a different weighting from the center and surround, but the LNK model does not have such a mixture for each pathway. A model should be tested where each of the two pathways of the LNK model have a weighting of center and surround. To be clear, one pathway should represent bipolar cells in the center, and should have a stronger weighting from the center than the annulus. The other pathway should represent bipolar cells whose receptive field center is under the annulus region, and should have a stronger weighting from the annulus than the central spot.</italic> </p><p>In our original submission, we had argued that models with suppression generated by synaptic depression will have suppression with the same spatial footprint as excitation. The models considered in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> were meant to implement the reviewer’s previous suggestion, by exploring the range of reasonable models where one or multiple components of synaptic depression were embedded in a more complex nonlinear circuit. As explained below, we believe the additional models suggested by the reviewer above are already encompassed by these previous examples, but for completeness have also implemented the reviewer’s suggestion explicitly in this rebuttal. To clarify this for the reader, we have also added an explanation of this in the figure legend for <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>.</p><p>In fact, the models in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> encompass the extreme cases of the Reviewer’s suggestion, and as a result are expected to evince the strongest differences from models considered in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. Specifically, these models are all trying to test alternative situations where the ‘spatial footprint’ of suppression (as measured by the DivS model) could be different than that of excitation as a result of synaptic depression alone. <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> considered the case where there were two completely separate processes of synaptic depression: one in center and one in surround. It seems that the model the Reviewer suggests is where the difference in spatial footprint between these two processes is less extreme, since one process (dominated by the center) will have some input from the surround, and vice versa. Such a model would have effects in between the models considered in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> (where the two processes have completely separate footprints) and where the two processes have the same footprints. However, this latter model reduces to the model in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1E</xref>, since in this case the two processes would generate the same output.</p><p>Because we tested both “extremes” of the model suggested by the Reviewer – and both yield a result where the spatial footprint of the suppression matches that of excitation – we would not expect intermediate models to behave differently. To test this (following the suggestion of the reviewer), we have generated the models to the specification of the reviewer, and demonstrate this in <xref ref-type="fig" rid="fig8">Author response image 1</xref>:<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.19460.015</object-id><label>Author response image 1.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.19460.015">http://dx.doi.org/10.7554/eLife.19460.015</ext-link></p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-19460-resp-fig1-v1"/></fig></p><p>Here, we parametrically vary the relative weight of the center/surround components, to effectively move between the two extremes already in the supplementals (i.e., <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1E</xref> and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). All panels here are analogous to those shown in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, although with the updated model (at left). As expected, the DivS model still reveals a suppressive term matching that of excitation (lower right), unlike the DivS model fit to data (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Rather than include these additional modeling results as yet another supplemental figure and risk confusing the reader (versus the more motivated models already in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>), we instead have elected to reference these observations in the caption of <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>.</p><p><italic>This fits most with known circuitry, because bipolar cells have center-surround linear receptive fields. This test will probably work as the authors predict, but the current comparisons are not adequate for their claim.</italic> </p><p>Although bipolar cells do have center-surround receptive fields and individual ganglion cells could receive inputs from multiple bipolar cells, bipolar cells that are in the surround generally do not provide excitatory input to ganglion cells. Nevertheless, we view these models as “extreme” in order to illustrate the logical argument that the footprint of suppression generated by synaptic depression will recapitulate the footprint of excitation, and thus consider them in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>.</p><p><italic>The previously published LNK model used a 4-state kinetic model, the current version of the paper now shows that a 3-state model was used here. This means that the simpler model chosen here can't reproduce all of the dynamics of the previous model. This difference needs to be clearly pointed out and justified in the main text. This issue also fits with showing whether that there is not slow adaptation, because it may be that the reason that the LNK model slightly underperforms the DivS model is that they chose a model with more simplified dynamics, yet the cell has both fast and slow dynamics.</italic></p><p>As we have demonstrated in the new <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, there is very little slow contrast adaptation in the present recordings, and as a result (1) the dynamics of the LNK model corresponding to the slow inactivation state are not useful; (2) the DivS model, which has no slow contrast adaptation, can accurately fit this data. After testing the LNK model with 4 components, we reduced it to 3-components in the text, and now make this clear in the Materials and methods section.</p><p><italic>4) Comparison to Spike Triggered Covariance. There is some confusion in the presentation about what STC analysis reveals, and the relationship to the DivS model.</italic> </p><p><italic>“We added <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> to fully describe an STC analysis and added modeling data to <xref ref-type="fig" rid="fig2">Figure 2</xref>. As explained &gt;above, we more clearly demonstrate a number of key differences of the DivS &gt;model over the STC model, most notably the presence of divisive suppression. &gt;We now make clear the caveat that other cell types could require additional &gt;components to capture important features of the response in the Discussion.”</italic> </p><p><italic>The following is a summary of the relationship, and it is basically in agreement with what is stated in the legend of <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>: STC analysis produces orthogonal vectors that define the stimulus subspace that drives the cell's response. It does not speak to the subsequent nonlinear mapping of that subspace to the response. In this case, if there is a two-dimensional subspace that defines the response, the filters of the DivS models must occupy the same subspace two STC eigenvectors. Thus this subspace can be found by a standard STC analysis not requiring a optimization procedure.</italic> </p><p><italic>For the choice of nonlinear mapping of the subspace to the response, either there can be an n-D nonlinearity (2-D in this case), which would be the optimal solution, or a more simplified nonlinearity can be found. This is what the DivS model does, to simplify the 2-D nonlinearity to a product of 1-D nonlinear functions.</italic> </p><p>We agree with everything stated above. An important omitted element in the above (as we describe further below) is that directions of the filters themselves (within the subspace) are meaningful in the DivS model (and not orthogonal). The multiplicative form of the DivS model is what determines these filters, and allows the divisive form of interaction between them to be detected.</p><p><italic>The reason I requested this detailed comparison was simply to avoid the mistaken conclusion that the DivS model is really a new class of model. It finds a reduced dimensional subspace just as STC does, and in fact such a standard technique can be used. The DivS model then does provide a set of constraints to reduce the complexity of the subsequent nonlinearity, reducing a 2-D nonlinearity to 1-D functions.</italic> </p><p>It seems that we agree on the facts, but not the semantics, as to what is defined as a “new class of model”. The STC model is an LN model, where the ‘N’ can be a multi-dimensional nonlinearity, and in practice usually cannot be fit. The DivS model for synaptic currents is an LNxLN model, and for spikes has an additional (LNxLN)LN form. These are by definition distinct mathematical forms, and in addition require different methods to estimate their parameters. Because the DivS model has different mathematical form with completely different means to estimate, it seems a reasonable bar to highlight this distinction from STC. Importantly, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> demonstrates that STC cannot reveal the underlying LNxLN model. It furthermore cannot take into account the spike history (which we show in later figures to be necessary to understand the spike response), and thus cannot replicate the form of the spiking DivS model either.</p><p>While we believe this classifies the DivS model as a different class of model than the STC model, we certainly agree they have some similarities (as well as differences), which are explored in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. In previous work (Butts et al., 2011; McFarland et al., 2013), we have perfromed additional analysis of STC-based solutions relative to other modeling forms, including its probabilistic cousin that we have been referring to as a GQM (generalized quadratic model; presented initially in Park and Pillow, NIPS, 2011). We routinely use such models to achieve independent estimates of the filters spanning the stimulus subspace, and its use in this manuscript is not intended to show any disrespect to STC. Rather, its presentation illustrates how the DivS model is distinct, and how it is necessary to reveal the main results presented in this manuscript: namely the divisive interactions underlying ganglion cell computation. We also use <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> to demonstrate that STC correctly identifies the filter subspace (consistent with our previous work, but now applied to current recordings rather than spikes), and thus remains a useful analysis tool.</p><p><italic>Even though the <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> legend basically agrees with these statements, there are several statements and analyses in the paper that indicate a confusion:</italic> </p><p><italic>Subsection “The nonlinear computation underlying synaptic inputs to ganglion cells”. However, the 2-D mapping between STC filter output and the synaptic current differed substantially from the same mapping for the DivS model</italic> (<italic><xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref></italic>).</p><p><italic>This isn't possible if things were done correctly (and it seems to conflict with the <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> legend), the STC subspace should be the same as the DivS subspace, and the 2-D nonlinearity from the STC subspace should be the same as the mapping from subspace to response for the DivS model. I think this is just a problem of how something is being stated, but it should be corrected/clarified.</italic> </p><p>This are glad for this careful description, and see where the misunderstanding is, and how to clarify. Specifically, we demonstrated in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> that the covariance-model (COV) subspace is the same as the DivS subspace, which is explicitly stated there (and in the reviewer’s comments above). However, the 2-D nonlinearities using the DivS filters (<xref ref-type="fig" rid="fig2">Figure 2F</xref>) versus the COV filters (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) are not simply rotations of each other (as implied by the reviewers comments) because the DivS filters are not orthogonal. The specific DivS filters lead the DivS 2-D nonlinearity to be multiplicatively “separable”, whereas such a multiplicative interaction is not clear in the COV 2-D. In the revised manuscript, we have rewritten the section describing these differences, and in particular include this explanation explicitly within the section (The nonlinear computation underlying synaptic inputs to ganglion cells).</p><p><italic>There is one potential difference between a full-2D nonlinearity from an STC subspace and the DivS model, and that is that the full 2-D nonlinearity may overfit, and thus the DivS model may impose a regularization that allows a better model of a test data set. If this is true, this is an interesting point to make, and it seems to be more relevant with the spiking model, because the authors say that can't fit the 2-D nonlinearity for spiking data (they can of course, but it must not be accurate).</italic> </p><p>We agree with this point: namely the many fewer parameters of the DivS model allows it to be tractably fit to much less data. There is enough data to fit the full 2-D models to currents (both based on the DivS and STC filters; <xref ref-type="fig" rid="fig2">Figure 2</xref>), and the model performance of each (<xref ref-type="fig" rid="fig2">Figure 2E</xref>) is only slightly hurt by overfitting. There are in fact two barriers to fitting the STC to spiking data: one being the number of parameters, as the reviewer suggests. The second – which prevents STC from discovering the full computational structure of ganglion cell responses – is its inability to simultaneously fit spike-history terms. With enough spike data, the methods we present here might still be able to measure a 2-D nonlinearity, but such a nonlinearity would mix the divisive and spike-history effects together. Thus, the overarching point is that the STC model could not reveal the structure of computation we report in this paper.</p><p><italic>In the same section, Thus, despite the ability of covariance analysis to nearly match the DivS model in &gt; terms of model performance (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), it could not uncover the divisive interaction between &gt; excitation and suppression</italic> (<italic><xref ref-type="fig" rid="fig2">Figure 2G</xref></italic>).</p><p><italic>That's not the point of STC analysis, it only acts to find the relevant subspace. A second step would define the nonlinear mapping from subspace to response, either preserving the full 2-D nonlinearity, which would be the optimal solution, or simplifying the 2-D nonlinearity to a more biological combination of 1-D pathways.</italic> </p><p>The purpose of this sentence was not to comment on STC analyses, but rather to stress the insight gained by using the DivS model, which discovers a much simpler structure than a full 2-D nonlinearity.</p><p><italic>It seems what the analysis of <xref ref-type="fig" rid="fig2">Figure 2E</xref> has done was to use the eigenvectors as filters for subsequent 1-D nonlinearities. That doesn't make any sense, the ideal 1-D nonlinearities have to lie in the 2-D subspace, but the 1-D nonlinearities don't have to be the eigenvectors, or even be orthogonal. This is not part of a standard STC analysis, and there is no reason to suspect that this would work.</italic> </p><p>We used the full 2-D nonlinear mapping to estimate model performance, as described in the Materials and methods section.</p><p>We also realized that this section in the methods was separated from the descriptions of other models of synaptic currents (since it described models of spikes as well). We have moved this methods section to reside with the other model descriptions.</p><p><italic>The point of my request to state the relationship between the DivS model and STC analysis was not to pit STC analysis against the DivS model, because they should yield equivalent results as the stimulus subspace, and that's as far as STC analysis goes. It was so say that STC analysis will find the equivalent subspace as the DivS model, and that the DivS model provides a way to simplify the nonlinear mapping.</italic> </p><p>We had previously added this section about STC as requested in the first round of review in order to demonstrate what is novel about the DivS model: in being able to identify an underlying divisive interaction in synaptic input. We realize the critical difference between the two methods in relation to their different 2-D nonlinearities did not previously come across clearly, and hope to fixed this in the revision (as described above). In doing so, we expect the reasons for including STC (in addition to responding to the requests following the first round of review) are clear.</p><p><italic>Discussion section, paragraph two. The presence of nonlinearities that are fit to data in the context of multiplicative &gt;interactions distinguishes this model from multi-linear models (two linear terms multiplying) &gt;(Ahrens et al., 2008a; Williamson et al., 2016), as well as more generalized LN models such as &gt;those associated with spike- triggered covariance.</italic> </p><p><italic>This isn't clear, STC only identifies the subspace, and then multiplicative interactions can be identified within that subspace.</italic> </p><p>We hope that we have clarified above that the multiplicative interactions revealed by the DivS model are evident in the 2-D nonlinearity in the STC model, due to the non-orthogonality of the DivS filters (even though these filters share the same subspace as STC). There are no current methods to analyze 2-D nonlinearities other than low-rank approximations (which we perform here) – and in fact most applications of STC do not even go as far as estimating the 2-D nonlinearity. Whether or not methods could be developed to search for divisive interactions using STC, the overarching focus of the manuscript is that there are divisive interactions governing ganglion cell computation, and a means to discover them using the DivS model.</p><p><italic>5) Circuit mechanisms underlying divisive suppression.</italic> </p><p><italic>It is appropriate to discuss the possibility that inhibition does play a role in adaptation, but the authors have to mention the previous literature that says that inhibition isn't needed for contrast adaptation (Brown &amp; Masland, 2001; Manookin &amp; Demb, 2006). This is in their favor to do so, because they point out that their model suggests an unexpected mechanism for contrast adaptation.</italic> </p><p>We thank the reviewer for pointing this out. We agree, and have incorporated this point into the Discussion section.</p><p><italic>There is another point that the author's may wish to mention that supports their argument. As they mention, On-α cells are more linear with a high spontaneous firing rate. Depression models rely on there being a change in the average level of synapse activation with contrast. With a linear cell, the average input to the synapse doesn't change much with contrast, and thus a change in the level of depression may not occur. Thus, inhibition from a modulatory pathway may be needed to create contrast adaptation for a more linear cell.</italic> </p><p>We agree, and have incorporated this point into the Discussion section.</p><p><italic>6) Meaning of Divisive Suppression. The authors use the term divisive suppression to apply both to one pathway modulating another (the usual term), and to any change in gain as might occur from synaptic depression. This second use is strange, if that's true, then the finding of divisive suppression isn't new, they have just called gain control something else.</italic> </p><p><italic>The potential new concept is that the effect is better modeled by one pathway modulating the other. This is actually an old concept, (Victor) and has since been replaced by one where a second pathway is not necessary, namely synaptic depression. But the new result would be that the older concept of modulation works better, especially when one considers the spatial stimulus. To make this comparison and state this conclusion, it makes more sense to restrict 'divisive suppression' to mean modulation, and thus the question becomes one of Suppression vs. Depression, rather than saying depression is one type of suppression.</italic> </p><p>We have not meant to claim that the idea of one pathway modulating another is a novel idea (even as a multiplicative/divisive interaction). This is the basis of most general models of gain control, as well as cortical models of “divisive normalization” (e.g., Carandini and Heeger, 2015). In fact, a divisive gain driven by presynaptic inhibition has been seen in the olfactory system of flies (Olsen and Wilson, 2008. Likewise, a canonical model of synaptic depression models it as a divisive gain (Markram et al., 1998). We include both possibilities in describing formulation of the DivS model (subsection “The nonlinear computation underlying synaptic inputs to ganglion cells”), and further address the relationship to other types of divisive suppression in the Discussion (subsection “Circuits and mechanisms underlying the divisive suppression”). The novelty of our work, in this respect, is revealing how such divisive suppression participates in shaping the ganglion cell response through computations within the retinal circuit.</p></body></sub-article></article>