<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">87962</article-id><article-id pub-id-type="doi">10.7554/eLife.87962</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87962.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Short Report</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A distributed brain response predicting the facial expression of acute nociceptive pain</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Picard</surname><given-names>Marie-Eve</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0001-2412-7829</contrib-id><email>marie-eve.picard.2@umontreal.ca</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Kunz</surname><given-names>Miriam</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Jen-I</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Coll</surname><given-names>Michel-Pierre</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1475-5522</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Vachon-Presseau</surname><given-names>Etienne</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8681-3154</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wager</surname><given-names>Tor D</given-names></name><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Rainville</surname><given-names>Pierre</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9801-757X</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0161xgx34</institution-id><institution>Department of Psychology, Université de Montréal</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/031z68d90</institution-id><institution>Centre de recherche de l’institut universitaire de gériatrie de Montréal</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03p14d497</institution-id><institution>Department of medical psychology and sociology, Medical faculty, University of Augsburg</institution></institution-wrap><addr-line><named-content content-type="city">Augsburg</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04sjchr03</institution-id><institution>School of Psychology, Université Laval</institution></institution-wrap><addr-line><named-content content-type="city">Quebec</named-content></addr-line><country>Canada</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>Faculty of Dentistry, McGill University</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>Department of Anesthesia, McGill University</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>Alan Edwards Centre for Research on Pain, McGill University</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/049s0rh22</institution-id><institution>Department of Psychological and Brain Sciences, Dartmouth College</institution></institution-wrap><addr-line><named-content content-type="city">Hanover</named-content></addr-line><country>United States</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0161xgx34</institution-id><institution>Stomatology Department, Faculté de médecine dentaire, Université de Montréal</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Biurrun Manresa</surname><given-names>José</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01wgfva68</institution-id><institution>National Scientific and Technical Research Council (CONICET), National University of Entre Ríos (UNER)</institution></institution-wrap><country>Argentina</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zgy1s35</institution-id><institution>University Medical Center Hamburg-Eppendorf</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>11</day><month>11</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP87962</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-06-22"><day>22</day><month>06</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-07-28"><day>28</day><month>07</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.26.550504"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-10-04"><day>04</day><month>10</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87962.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-08-29"><day>29</day><month>08</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87962.2"/></event></pub-history><permissions><copyright-statement>© 2023, Picard et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Picard et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-87962-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-87962-figures-v1.pdf"/><abstract><p>Pain is a private experience observable through various verbal and non-verbal behavioural manifestations, each of which may relate to different pain-related functions. Despite the importance of understanding the cerebral mechanisms underlying those manifestations, there is currently limited knowledge of the neural correlates of the facial expression of pain. In this functional magnetic resonance imaging (fMRI) study, noxious heat stimulation was applied in healthy volunteers and we tested if previously published brain signatures of pain were sensitive to pain expression. We then applied a multivariate pattern analysis to the fMRI data to predict the facial expression of pain. Results revealed the inability of previously developed pain neurosignatures to predict the facial expression of pain. We thus propose a facial expression of pain signature (FEPS) conveying distinctive information about the brain response to nociceptive stimulations with minimal or no overlap with other pain-relevant brain signatures associated with nociception, pain ratings, thermal pain aversiveness, or pain valuation. The FEPS may provide a distinctive functional characterization of the distributed cerebral response to nociceptive pain associated with the socio-communicative role of non-verbal pain expression. This underscores the complexity of pain phenomenology by reinforcing the view that neurosignatures conceived as biomarkers must be interpreted in relation to the specific pain manifestation(s) predicted and their underlying function(s). Future studies should explore other pain-relevant manifestations and assess the specificity of the FEPS against simulated pain expressions and other types of aversive or emotional states.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>pain</kwd><kwd>non-verbal communication</kwd><kwd>facial expression</kwd><kwd>neuroimaging</kwd><kwd>brain signature</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003151</institution-id><institution>Fonds de recherche du Québec – Nature et technologies</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Picard</surname><given-names>Marie-Eve</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100019217</institution-id><institution>Institut de Valorisation des Données</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Picard</surname><given-names>Marie-Eve</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN-2018-06799</award-id><principal-award-recipient><name><surname>Rainville</surname><given-names>Pierre</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 DA035484</award-id><principal-award-recipient><name><surname>Wager</surname><given-names>Tor D</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Facial expression provides a complementary channel to communicate pain experiences and reflects the activation of brain mechanisms partly distinct from those associated with subjective self-reports of pain.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Theories of pain communication highlight the diversity in pain manifestations, which occur through multiple channels: verbal reports, vocal complaints, changes of postures, and facial expressions. From an evolutionary perspective, several manifestations of pain appear to be preserved across vertebrate phyla and reflect various functional roles to preserve the integrity of the organism (<xref ref-type="bibr" rid="bib35">Sneddon, 2019</xref>). Withdrawal behaviour allows the individual to move away from the noxious source, while facial expressions in social species convey information about the presence of a potential threat and an appeal for assistance (<xref ref-type="bibr" rid="bib14">Hadjistavropoulos et al., 2011</xref>). Functionally distinct manifestations imply at least partly segregated neurophysiological processing (<xref ref-type="bibr" rid="bib34">Sliwa et al., 2022</xref>). Previous fMRI studies investigating the neural correlates of acute pain have suggested that spontaneous or induced fluctuations in pain facial expression partly reflect changes in activity within the cortical targets of the spino-thalamo-cortical pathways. <xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref> found a positive association between facial responses to pain and the activity in the posterior insula, the primary somatosensory area, and the anterior cingulate cortex. These fluctuations are, however, independent of changes in stimulus intensity and are inversely related to activity in prefrontal regions (<xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Vachon-Presseau et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Kunz et al., 2020</xref>). This suggests that pain facial expression may reflect the integration of activity across distributed brain networks processing ascending nociceptive signals, determining action policy, and gating efferent facial motor outputs (see <xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref> and <xref ref-type="bibr" rid="bib21">Kunz et al., 2020</xref> for further discussion).</p><p>The interest in developing pain neuro markers has led researchers to use multivariate pattern analysis to investigate the distributed brain mechanisms underlying the experience of pain evoked by acute nociceptive stimuli. However, fMRI studies have revealed not one but several brain signatures of acute experimental pain that may reflect the diversity and complexity of pain-related function. The neurological pain signature (NPS; <xref ref-type="bibr" rid="bib39">Wager et al., 2013</xref>) was developed to predict changes in pain induced by variations in stimulus intensity and captured by subjective reports, reflecting primarily the cerebral contributions to acute nociceptive pain (<xref ref-type="bibr" rid="bib16">Krishnan et al., 2016</xref>; <xref ref-type="bibr" rid="bib39">Wager et al., 2013</xref>). To account for spontaneous fluctuations in the perception of pain intensity, the stimulus-independent intensity of pain signature (SIIPS-1) was trained on noxious thermal trials after statistically removing the effects of the stimulus intensity and the NPS response (<xref ref-type="bibr" rid="bib40">Woo et al., 2017</xref>). More recently, the affective dimension of pain has received more attention, resulting in a multivariate pattern predictive of negative affect ratings to thermal pain, referred to here as the thermal pain aversive signature (TPAS; <xref ref-type="bibr" rid="bib4">Čeko et al., 2022</xref>). Finally, a signature was elaborated to characterise the neuronal representations associated with the valuation of pain (PVP) in the context of a decision task involving a cost-benefit analysis of future pain against a monetary reward (<xref ref-type="bibr" rid="bib6">Coll et al., 2022</xref>). Taken together, those signatures have contributed to improve our understanding of the neurobiological mechanisms of pain, as reflected in self-report or explicit decision-making.</p><p>Facial expression has been used as a reliable behavioural measure of pain across different mammal species (<xref ref-type="bibr" rid="bib8">Dalla Costa et al., 2014</xref>; <xref ref-type="bibr" rid="bib7">Craig, 1992</xref>; <xref ref-type="bibr" rid="bib11">Evangelista et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Langford et al., 2010</xref>; <xref ref-type="bibr" rid="bib36">Sotocinal et al., 2011</xref>), but few studies have investigated the brain mechanisms associated with the spontaneous non-verbal communication of pain in humans (<xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>; <xref ref-type="bibr" rid="bib21">Kunz et al., 2020</xref>). As an automatic behavioral manifestation, pain facial expression is considered to be an indicator of activity in nociceptive systems, and to reflect perceptual and affective-evaluative processes. Here, we assessed the association between pain facial expression and the available pain-relevant brain signatures and we applied multivariate analysis with machine learning techniques to develop a predictive brain activation model of the facial responses to pain.</p></sec><sec id="s2" sec-type="results|discussion"><title>Results and discussion</title><p>The facial action coding system (FACS; <xref ref-type="bibr" rid="bib10">Ekman and Friesen, 1978</xref>) was used to quantify the facial expression of pain in healthy participants while brain responses evoked by brief moderately painful heat stimulation were recorded using fMRI. For each trial, the intensity and the frequency of pain-related action units were scored and combined into a FACS composite score (Materials and methods). The association with the NPS, the SIIPS-1, the PVP, and the TPAS was assessed across the whole brain using the correlation between the FACS scores and the dot product computed between each signature and the activation maps for each individual trial.</p><p>Pain facial expression was not significantly associated with NPS expression (<italic>pearson-r</italic>=.06; p=0.20; 95% CI = [–0.03, 0.14]), TPAS expression (<italic>pearson-r</italic>=0.05; p=0.26; 95% CI = [–0.04, 0.14]), PVP expression (<italic>pearson-r</italic>=0.02; p=0.67) and SIIPS-1 expression (<italic>pearson-r</italic>=0.07; p=0.10; 95% CI = [–0.01, 0.16]). These low values indicate that the available pain-relevant brain signatures show poor sensitivity to the facial expression of pain. This motivated the development of a new multivariate brain pattern to predict pain expression.</p><p>We used a multivariate approach at the voxel level across the whole brain to develop the FEPS (see Materials and methods). A LASSO principal component regression was applied to predict the FACS composite scores from the trial-by-trial fMRI activation maps. The FEPS was able to predict the FACS composite scores with a performance significantly above chance level (averaged cross-validated prediction across 10 folds: <italic>pearson-r</italic>=0.54 ± 0.10 (95% CI = [0.39; 0.64]); R<sup>2</sup>=0.22 ± 0.08 (95% CI = [–0.09; 0.33]); RMSE = 0.99 ± 0.08 (95% CI = [0.88; 1.10]); p&lt;0.001 compared to a permuted distribution; <xref ref-type="fig" rid="fig1">Figure 1-AB</xref>). These results indicate that we were able to develop a multivariate brain pattern accounting for some variance in the facial responses related to pain.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Facial expression of pain signature (FEPS): a brain signature of the facial expression of pain.</title><p>(A) Relationship between the actual and the predicted facial action coding system (FACS) composite scores for each cross-validation fold. (<bold>B</bold>) Distribution of the Pearson’s r scores across the cross-validation folds. (<bold>C</bold>) Predictive weight map of pain expression thresholded at FDR <italic>corrected q</italic>&lt;0.05 using bootstrap tests performed with 5000 samples (with replacement). The thresholded map is shown for visualization and interpretation purposes only, although the prediction was made using voxel weights across the whole brain. MNI coordinates of the clusters with the related z-score can be found in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1A and B</xref>. The colour bar represents the z-scored regression weights reflecting the positive and negative association with the magnitude of the FACS composite score of pain expression.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87962-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Behavioral scores across trials.</title><p>(<bold>A</bold>) Fluctuations in the log-transformed facial action coding system (FACS) composite scores across trials in the two runs (shaded areas represent the standard deviation). There was no significant effect of trials and runs (<italic>p</italic>’s&gt;0.8; see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1D</xref>). (<bold>B</bold>) Distribution of the log-transformed FACS composite scores (each point represents one trial). (<bold>C</bold>) Fluctuations in the pain intensity ratings across trials between runs. There was no significant effect of trials and runs (<italic>p</italic>’s&gt;0.15; see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1E</xref>). (<bold>D</bold>) Distribution of the pain intensity ratings.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87962-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Predictive performance of the M1-based model.</title><p>(<bold>A</bold>) Relationship between the actual and the predicted facial action coding system (FACS) composite scores for each cross-validation fold (k=10) using only the activity from the primary motor cortex as defined by the Oxford-Harvard Cortical Atlas (<xref ref-type="bibr" rid="bib3">Caviness et al., 1996</xref>). (<bold>B</bold>) Distribution of the Pearson-r scores across the 10 cross-validation folds (Pearson-r=0.28 ± 0.14 (95% CI = [0.17; 0.49]); R<sup>2</sup>=–0.02 ± 0.12 (95% CI = [–0.41; 0.16]); RMSE = 1.13 ± 0.11 (95% CI = [0.99; 1.23]); p=0.01).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87962-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Facial expression of pain signature (FEPS) pattern expression and pain facial expression.</title><p>(<bold>A</bold>) FEPS pattern expression scores significantly predict the log-transformed facial action coding system (FACS) scores. Each point represents a trial in the pain condition (n=533). (<bold>B</bold>) Distribution of the FEPS pattern expression scores in the warm (nonpainful) condition and in the pain condition, separating the trials with and without pain facial expression. The FEPS pattern expression was computed using the dot product between the FEPS weights and the trial-by-trial activation maps (n=1069). The whiskers on the box plots extend to either 1.5 times the interquartile range or to the farthest point within that range. Statistical results are reported in the main text.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87962-fig1-figsupp3-v1.tif"/></fig></fig-group><p>The distributed pattern of activity predicting pain expression was projected back on the brain to examine the spatial distribution of higher weights contributing to the prediction (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Positive weight clusters were found in the primary motor cortex (M1; bilateral), the frontal pole, the right posterior parietal cortex, and the dorsal part of the parietal operculum, adjacent to the secondary somatosensory cortex (S2) (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1A</xref>). These regions are, respectively, associated with motor control, reward and affective value, attentional processes, and nociceptive pain processing (<xref ref-type="bibr" rid="bib28">Price, 2000</xref>; <xref ref-type="bibr" rid="bib31">Rushworth et al., 2011</xref>; <xref ref-type="bibr" rid="bib32">Shackman et al., 2011</xref>). Regions showing negative weights included the dorsolateral PFC (dlPFC), the ventrolateral PFC (vlPFC), the mid-cingulate cortex (MCC), the subgenual ACC, the ventral part of the parietal operculum, the precuneus, and the vmPFC (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1B</xref>). Negative weights imply that increased activity in those regions is associated with decreased facial response, consistent with a role in the inhibition of pain expression (<xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>). The contribution of the dlPFC and the vlPFC to the model’s prediction aligns with the role of these regions in inhibitory control and cognitive regulation, respectively (<xref ref-type="bibr" rid="bib13">Goldin et al., 2008</xref>).</p><p>A supplementary analysis was conducted to evaluate whether the activity pattern in the primary motor cortex (M1) alone could be sufficient for predicting facial expressions. The choice of this particular region was informed by prior research indicating that M1 presented the strongest correlation with the facial expression of pain (<xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>). If the facial expression of pain primarily reflected a motor component without providing substantial insights into the pain experience, then the activity of the motor cortex alone should have been equally effective as the activity of the whole brain in predicting the FACS scores. This M1 model did lead to a significant prediction of pain facial expression (see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>), but the whole brain model was significantly better (<italic>t</italic>(532) = 2.73, p=0.003).</p><p>These results are consistent with the distributed nature of brain activity associated with the production and regulation of pain facial expression reflecting in part the ascending nociceptive response and the ensuing affective processes, as well as top-down socio-affective regulation underlying the implementation of learned display rules (<xref ref-type="bibr" rid="bib15">Karmann et al., 2016</xref>).</p><p>This study was not designed to assess the specificity of the FEPS against other aversive states but the warm stimulation condition allowed us to compare the FEPS response to a painful vs a non-painful thermal stimulation. The FEPS expression score was computed on the activation maps of the warm trials and compared to the pain trials, with and without pain facial expression (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3B</xref>). The results indicated higher expression scores in the painful condition than in the warm condition (Pain - Warm contrast: EMM = 0.24 ± 0.02, <italic>t</italic>(1034)=10.33, p&lt;0.0001, 95% CI = [0.20, 0.29], Cohen’s <italic>d</italic>=0.63). Given the intra-individual and inter-individual variability in facial responses to pain, we repeated this comparison, stratifying the trials within the pain condition based on FACS scores: null FACS scores (FACS = 0) and non-null FACS scores (FACS &gt;0). The FEPS scores were larger in the pain condition where facial responses were displayed, compared to both the pain condition without facial expression and the warm condition (Pain<sub>FACS&gt;0</sub> - Pain<sub>FACS=0</sub> contrast: EMM = 0.58 ± 0.03, <italic>t</italic>(1065)=17.19, p&lt;0.0001, 95% CI = [0.50, 0.66], Cohen’s <italic>d</italic>=1.69; Pain<sub>FACS=0</sub> - Warm contrast: EMM = –0.06 ± 0.03, <italic>t</italic>(1057)=–2.24, p=0.07, 95% CI = [–0.13, 0.003], Cohen’s <italic>d</italic>=–0.18; Pain<sub>FACS&gt;0</sub> - Warm contrast: EMM = 0.52 ± 0.03, <italic>t</italic>(1055)=19.64, p&lt;0.0001, 95% CI = [0.46, 0.58], Cohen’s <italic>d</italic>=1.52). Note that the comparison of Pain<sub>FACS&gt;0</sub> vs Pain<sub>FACS=0</sub> is redundant with the regression approach used as the primary analysis model (<xref ref-type="fig" rid="fig1">Figure 1</xref>) and should not be considered as additional evidence. The observation that the Pain<sub>FACS=0</sub> trials did not differ significantly from the Warm trials and that both conditions showed a mean score close to 0 (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3B</xref>) indicate that the FEPS does not respond to innocuous thermal stimuli and only responds to noxious heat when a facial expression is produced.</p><p>Several regions identified in the FEPS have also been reported in other pain-related brain signatures. Regions predictive of pain facial expression and pain intensity (NPS and SIIPS-1) include S2, the vmPFC, and the precuneus. The vlPFC is a region that does not receive direct spino-thalamo-cortical nociceptive afferents, and was reported both in the FEPS and in the SIIPS-1. Overlap between the FEPS and the PVP (pain value pattern) includes regions associated with reward and affect (i.e. OFC). Finally, the primary motor cortex, and S2 were also reported as contributing regions in the TPAS. The spatial comparison showing some common regions across these pain-relevant signatures suggests possible shared features with the FEPS.</p><p>We computed the cosine similarity between the FEPS and other pain-related brain signatures to further examine the shared and specific representations between those predictive patterns (see Materials and methods). Cosine similarity ranging from 0.00 to 0.10 was found between the FEPS and the other pain-related brain signatures reflecting the overall low similarity between the signatures at the whole-brain level (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The highest similarity value with the FEPS was found for the SIIPS-1, consistent with the notion that the facial expression of pain may reflect, at least partly, changes in brain responses associated with spontaneous fluctuations in pain experience captured by pain ratings. Similarity with the FEPS was further assessed across different cortical networks (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The significant positive similarity with the SIIPS-1 at the frontoparietal level and in the default-mode network may suggest common mechanisms in self-representation, prediction, and emotional regulation of the pain experience that would be reflected in both facial expression and subjective reports (<xref ref-type="bibr" rid="bib24">Pan et al., 2018</xref>). Recruitment of the frontoparietal network may also be involved in the conscious representation of the pain context, making nociceptive information available for integration into decision-making processes (<xref ref-type="bibr" rid="bib6">Coll et al., 2022</xref>; <xref ref-type="bibr" rid="bib1">Bastuji et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Del Cul et al., 2007</xref>; <xref ref-type="bibr" rid="bib42">Zheng et al., 2020</xref>). The similarity between the FEPS and the SIIPS-1 in the somatomotor network indicates potential overlaps between the sensory aspect of the pain experience captured by the facial expression and the pain intensity ratings. This is consistent with our previous report showing that changes in pain facial expression by the cognitive modulation of perceived pain intensity are correlated to changes in the nociceptive response of the somatosensory cortex (<xref ref-type="bibr" rid="bib21">Kunz et al., 2020</xref>). Finally, the convergent similarities in the limbic network with the PVP is consistent with a key role of affective pain processing influencing facial expression, and perceived pain value (<xref ref-type="bibr" rid="bib12">Garcia-Larrea and Peyron, 2013</xref>; <xref ref-type="bibr" rid="bib30">Roy et al., 2009</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Spatial similarity between the facial expression of pain signature (FEPS) and other pain-related signatures.</title><p>(<bold>A</bold>) Pattern similarity between the FEPS and other pain-related brain signatures using the weights of the full brain patterns. Pattern similarities were computed at the voxel level using the cosine similarity; a value of 1 reflects proportional patterns; a value of 0 reflects orthogonal patterns; a value of –1 reflects patterns of opposite directions. The left panel shows the similarity matrix, and the right panel shows only the significant similarities between the pain-related signatures (*p&lt;0.05; **p&lt;0.01; ***<italic>p</italic>&lt;0.001). (<bold>B</bold>) Deconstructing the pattern similarity with regards to seven cortical networks as defined in the Yeo atlas<ext-link ext-link-type="uri" xlink:href="https://www.zotero.org/google-docs/?broken=qzK4gf">24</ext-link>: Visual Network (VN); Somatomotor Network (SMN); Dorsal Attention Network (DAN); Ventral Attention Network (VAN); Limbic Network (LN); Frontoparietal Network (FPN); Default Mode Network (DMN). Null distributions computed using permutation tests are shown, and the actual similarity values are represented by the vertical bar. Significant similarity values were found in the FPN (similarity = 0.20; p=0.002), the SMN (similarity = 0.21; p=0.02), and the DMN (similarity = 0.15; p=0.04) for the SIIPS-1, in the LN (similarity = 0.26; p=0.001), and DMN (similarity = 0.13; p=0.03) for the pain value pattern (PVP).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87962-fig2-v1.tif"/></fig><p>In research and clinical practice, verbal reports of perceived pain intensity are considered to be the gold standard for measuring pain. Other measures that are often weakly correlated with those subjective reports, like facial expressions of pain, are often considered a less valid metric of the experience of pain even though they provide important complementary information on pain-related processes (<xref ref-type="bibr" rid="bib14">Hadjistavropoulos et al., 2011</xref>). The FEPS was able to predict the magnitude of the facial expression of pain above the chance level. Regions that contribute to the prediction include motor and pain-related areas associated with both sensory and affective processing of pain. Although it shares, to some extent, similar representations with other pain-relevant signatures within various cerebral networks, the FEPS is distinctive from these other signatures. Results of this study provide unique evidence of the complementary information provided by facial expression on pain-related brain processes. Future studies must provide a more comprehensive account of diverse pain manifestations and their related function to better capture the pain phenomenon in its entirety.</p><sec id="s2-1"><title>Limitations</title><p>We recognize that our study has several limitations. First, given our limited sample size, further research will be necessary to verify the generalizability of the FEPS across other samples, but also across diverse experimental conditions (e.g. electrical, mechanical, and chemical pain) and populations (e.g. young vs old, chronic pain). Conducting future generalizability studies is crucial to ensure that the FEPS is a valid signature and is not only a result of model overfitting.</p><p>Even though the model developed from the entire brain activity could predict pain facial expression scores (FACS scores) beyond chance levels, it is important to highlight its inability to accurately predict the higher facial expression scores. This observation may be explained by the positive asymmetry in the distribution of facial expression scores, despite the log transformation applied to mitigate the observed skewness in the behavioral data. It is possible that the brain signature of pain facial expression might not adequately capture the heterogeneity of facial expressiveness in the population, especially for highly expressive individuals (<xref ref-type="bibr" rid="bib18">Kunz et al., 2008</xref>). To address this limitation in the generalizability of the model, it could be re-trained with more observations associated with high FACS scores, thereby improving the extraction of predictive features associated with a greater level of facial expressivity. It is also possible that non-linear models might provide a better prediction and/or that the higher pain expressiveness might engage additional brain mechanisms not captured here.</p><p>The whole-brain model also overestimated the lowest facial responses with the intercept of the regression lines being systematically greater than 0 (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>). This means that even when no facial expression was detected, there was still some brain activation matching the FEPS. Again, this may reflect a limitation of the linear model applied here. It is also possible that the FACS method might miss subtle movements of the face and/or that the FEPS captures meaningful variability in the pain-related brain activity below the threshold of facial expression.</p><p>It is also essential to assess the specificity of the FEPS in future studies. This involves examining whether the FEPS responds specifically to facial expressions of pain rather than broadly reflecting any facial movements including simulated facial expressions of pain and facial expression of emotions. Despite the similarities between facial expressions of pain and those associated with negative emotions, it is possible to behaviorally distinguish them. This suggests the potential to identify distinct brain patterns predictive of different facial responses (<xref ref-type="bibr" rid="bib33">Simon et al., 2008</xref>). However, to our knowledge, there are no available brain imaging datasets to assess the specificity of the FEPS in that context.</p><p>Due to our limited sample size, we were not able to analyze each pain-related facial action unit separately or to explore different combinations. This could be valuable, especially considering the reported differences in the association between diverse pain-related action units and the sensory and affective components of pain (<xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>; <xref ref-type="bibr" rid="bib21">Kunz et al., 2020</xref>).</p><p>Despite the limitations of this study, the evidence provided by our findings highlights the importance of facial expression as a complementary source of information to assess central nociceptive processes and acute pain. These results should be regarded as a benchmark for future research on non-verbal pain-related manifestations and may provide a foundation for the assessment of brain mechanisms underlying non-verbal communication across domains.</p></sec></sec><sec id="s3" sec-type="materials|methods"><title>Materials and methods</title><sec id="s3-1"><title>Participants</title><p>Secondary analyses of brain imaging data acquired in 34 healthy participants were performed in this study (18 women, 16 men; age mean ± SD = 23.4±2.5 years)(<xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>). No participants reported having a history of neurological or psychiatric disease, nor chronic pain. Participants reported not using alcohol nor analgesics for at least 24 hr before the experimental session. All participants provided written informed consent and received monetary compensation for their participation. The information about the video recording of the face was indicated in the consent form but this was not emphasized and it was not mentioned at the time of data acquisition. All procedures were approved by the ethics committee of the Centre de recherche de l’institut universitaire de gériatrie de Montréal.</p></sec><sec id="s3-2"><title>Study design</title><sec id="s3-2-1"><title>Pre-experimental session</title><p>Participants were submitted to a pre-experimental session to assess the range of thermal pain sensitivity using a magnitude estimation procedure. All participants included in this study had normal thermal pain sensitivity (see <xref ref-type="bibr" rid="bib18">Kunz et al., 2008</xref> for more details regarding the procedure; <xref ref-type="bibr" rid="bib29">Rainville et al., 1992</xref>). The degree of facial expressiveness was also evaluated (low/nonexpressive (n=13): facial responses in 20% or less of painful trials; expressive (n=21): facial responses in more than 20% of painful trials; <xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>). Our sample was representative of the interindividual variability in facial expressivity of pain as reported in the literature (<xref ref-type="bibr" rid="bib17">Kunz et al., 2006</xref>; <xref ref-type="bibr" rid="bib18">Kunz et al., 2008</xref>) and data from all participants were used in the present study.</p></sec><sec id="s3-2-2"><title>Thermal stimuli</title><p>Thermal stimulations were induced using a Medoc TSA-2001 thermosensory stimulator with an MRI-compatible 3×3 cm<sup>2</sup> contact probe (Medoc), positioned at the level of the lower left leg. Thermal stimuli lasted 9 s (2 s ramp up, 5 s plateau at targeted temperature, 2 s <italic>ramp down</italic>) and were followed by an interstimulus interval of 18–25 s. The experiment was programmed using E-prime software (Psychology Software Tools, Pittsburgh, Pennsylvania, United States). A baseline temperature of 38 °C was applied between stimuli for all participants. The target temperatures were determined individually before the MRI scans to induce a warm non-painful sensation in the control condition, and a moderate to strong self-reported pain intensity (targeting 75-80/100 on the pain scale, where 50/100 corresponds to the pain threshold; temperature (mean ± SD)=47.8 ± 0.90 °C). Participants were not aware that the warm and painful temperatures remained constant across trials. The order of the control condition and experimental condition was pseudorandomized. There were eight trials for each experimental condition per run, for a total of 16 trials per condition and a total of 544 trials per condition across all participants (34 participants × 16 pain trials). After each stimulus, participants rated the warm or pain sensation by moving a cursor with an MRI-compatible response key on a computerized visual analog scale.</p></sec><sec id="s3-2-3"><title>Facial expression</title><p>The facial expression of the participants was recorded using an MRI-compatible camera (MRC Systems) mounted onto the head coil of the MRI scanner. To be able to quantify facial expressions that occurred during the stimulation, a signal was sent from the stimulator to the sound card to automatically mark the onset of each stimulus on the video recording. Two certified FACS coders evaluated the video recordings to rate the frequency, and intensity (on a 5-point scale) of pain-related action units (AUs; AU4, AU6-7, AU9-10, and AU43) for each trial (see <xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref> for details about the AUs selection). In the frequency count, an AU was considered as occurring either for the first time or if it was already present, an intensity increase of 2 points was recorded as a new occurrence. Additionally, if there was a distinct interruption followed by a reappearance of the AU for a given time window, it was also added to the frequency count. From the frequency and intensity scores, a composite score (FACS composite score) was computed by taking the product between the mean AU frequency and mean AU intensity values, reflecting pain expression for each trial. A logarithmic transformation was applied in order to normalize the FACS composite scores (<inline-formula><mml:math id="inf1"><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>F</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>S</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>; skewness = 0.75, kurtosis = –0.84). The transformed FACS composite scores during the painful trials were used as the predictive variable. All results were reported based on the log-transformed scores. To examine whether the facial expression could be confounded with the pain reports, we predicted the trial-by-trial FACS composite scores from the pain ratings using a mixed effect model with the participants as a random effect, and allowing random slopes. Pain ratings were not associated to facial responses (R<sup>2</sup><sub>GLMM(m)</sub>=0.008, R<sup>2</sup><sub>GLMM(c)</sub>=0.74, <italic>β</italic>=0.10 ± 0.07, 95% CI = [–0.01; 0.21], <italic>t</italic>(32.57)=1.82, p=0.07, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1C</xref>). Even if the likelihood and the strength of facial expression of pain generally increase with pain ratings in response to the increase of stimulus intensity, this result is not surprising in the present context where the stimulus intensity is held constant, and spontaneous fluctuations in both facial expression and subjective ratings are observed (see <xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref> and <xref ref-type="bibr" rid="bib20">Kunz et al., 2018</xref> for a discussion on those results).</p><p>To test for a possible habituation or sensitization effect on the facial expressivity throughout the experiment, a mixed effect model was conducted with the trials, the runs, and the interaction between the trials and the runs considered as fixed effects, and the participants as random effects. No evidence of such habituation or sensitization on the log-transformed FACS scores were found in the results (R<sup>2</sup><sub>GLMM(m)</sub>=0.00; R<sup>2</sup><sub>GLMM(c)</sub>=0.71; trial: <italic>β</italic>=–0.002 ± 0.02, 95% CI = [–0.03; 0.03], <italic>t</italic>(496.01)=–0.12, p=0.90; run: <italic>β</italic>=0.02 ± 0.22, 95% CI = [–0.22; 0.25], <italic>t</italic>(496.16)=0.15, p=0.88; trial × run: <italic>β</italic>=0.001 ± 0.02, 95% CI = [–0.05; 0.05], <italic>t</italic>(496.05)=0.05, p=0.96; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref> and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1D</xref>). The same analysis conducted on the pain intensity ratings led to the same conclusions (R<sup>2</sup><sub>GLMM(m)</sub>=0.01; R<sup>2</sup><sub>GLMM(c)</sub>=0.49; Trials: <italic>β</italic>=0.01 ± 0.21, 95% CI = [–0.40; 0.42], <italic>t</italic>(496.13)=0.04, <italic>P</italic>=0.97; Runs: <italic>β</italic>=1.98 ± 1.47, 95% CI = [–0.91; 4.87], <italic>t</italic>(496.47)=1.35, p=0.18; Trials × Runs: <italic>β</italic>=–0.03 ± 0.29, 95% CI = [–0.61; 0.54], <italic>t</italic>(496.21)=–0.12, p=0.91; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref> and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1E</xref>).</p></sec><sec id="s3-2-4"><title>Anatomical and functional acquisition</title><p>MRI images were acquired using a 12-channel head coil 3T Siemens TRIO scanner. T1-weighted structural data were collected using a MP-RAGE sequence (TR = 2300 ms, TE = 2.91 ms, flip angle = 9°, FOV = 256 mm, matrix size = 240 × 256, voxel size = 1 × 1 × 1.2 mm, 170 whole-brain volumes). Functional data were acquired using an EPI T2*-weighted sequence (TR = 3000 ms, TE = 30 ms, flip angle = 90°, FOV = 220 × 220 mm<sup>2</sup>, voxel size = 3.44 × 3.44 × 3.40 mm, 40 interleaved axial slices).</p></sec><sec id="s3-2-5"><title>Preprocessing of fMRI data</title><p>The fMRI data were preprocessed using SPM8 (Statistical Parametric Mapping, Version 8; Wellcome Department of Imaging Neuroscience, London, United Kingdom) on MATLAB 7.4 (The MathWorks Inc, Natick, Massachusetts, United States). Preprocessing steps included a slice-timing correction, a correction for head movements, and co-registration between functional and anatomical images for each participant. Functional images were normalized into the MNI space. A spatial smoothing procedure (6 mm FWHM Gaussian kernel) and a high pass filter (128 s) were also applied.</p><p>BOLD signal was modeled using a canonical hemodynamic response function. First-level analyses were computed using the GLM to obtain a pain activation map for each trial using SPM8. Additionally, the six movement parameters and averaged signals from the white matter and the cerebrospinal fluid were included as nuisance regressors. Eleven trials were discarded due to excessive movements in the painful condition, and eight trials were excluded in the warm condition, resulting in a total of 533 and 536 activation maps for the pai and the warm conditions, respectively. The activation maps of individual painful trials were used to develop theFEPS.</p></sec></sec><sec id="s3-3"><title>Analyses</title><sec id="s3-3-1"><title>Association between the facial expression of pain and pain-related brain signatures</title><p>The dot product between the neurologic pain signature (NPS; <xref ref-type="bibr" rid="bib39">Wager et al., 2013</xref>), the stimulus intensity independent pain signature-1 (SIIPS-1; <xref ref-type="bibr" rid="bib40">Woo et al., 2017</xref>), the predictive value of pain (PVP; <xref ref-type="bibr" rid="bib6">Coll et al., 2022</xref>), the Thermal Pain Aversive Signature (TPAS; <xref ref-type="bibr" rid="bib4">Čeko et al., 2022</xref>), and the trial-by-trial activation maps was computed to derive a measure of similarity (pattern expression) between the unthresholded signatures and the activation maps. These scalar values were then correlated with the FACS composite scores to assess the association between the facial expression of pain and the NPS, the SIIPS-1, the PVP, and the TPAS, separately. Pearson-r correlation coefficients and p-values are reported.</p></sec><sec id="s3-3-2"><title>Multivariate pattern analysis</title><p>We applied a least absolute shrinkage and selection operator principal component regression (LASSO-PCR) with a 10-fold cross-validation procedure for multivariate pattern analysis (<xref ref-type="bibr" rid="bib38">Wager et al., 2011</xref>) using scikit-learn implementation (<xref ref-type="bibr" rid="bib25">Pedregosa et al., 2011</xref>). The algorithm was trained on ∼70% of the data and tested on the remaining ∼30%, and the LASSO alpha hyperparameter was set at 1.0. The analyses were performed using the trial-by-trial activation maps as input to the model and the participants as a grouping factor (i.e. data from a given participant could only be either in the training set or the testing set for a given cross-validation fold). This procedure was used to predict FACS composite scores from activation maps. The performance of each regression model was evaluated using Pearson’s correlation coefficient (<italic>pearson-r</italic>), coefficient of determination (R<sup>2</sup>; computed using scikit-learn), and root mean square error (RMSE). The scikit-learn’s implementation of the coefficient of determination was used, allowing negative values if the model showed worse performance compared to an unfitted model (i.e. a horizontal line). The averaged performance metrics across folds are reported for each analysis. To test if the models performed significantly above chance, permutation tests were computed using 5000 iterations, leading to a p-value corresponding to the probability that the R<sup>2</sup> between the observed and predicted FACS scores would be obtained by chance. A bootstrap resampling procedure was also performed to evaluate the stability of the voxel contribution to the model performance, and to derive confidence intervals for the performance metrics. This procedure consists of randomly sampling 5000 times the dataset with replacement. The resulting samples contain the same number of observations as the dataset. The LASSO-PCR procedure as described above is then applied on each sample. Z-scores and p-values are calculated on the overall regression coefficients.</p><p>This analysis procedure was first applied at the whole brain level. It was repeated using a spatial mask including only the precentral region bilaterally. This mask was derived from the Oxford-Harvard Cortical Atlas (<xref ref-type="bibr" rid="bib3">Caviness et al., 1996</xref>). This secondary analysis was conducted to verify if the pattern of activity within the primary motor cortex (M1) might be sufficient to predict facial expression. The performance between the model based on the primary motor cortex activity and the whole-brain model was compared using a corrected resampled t-test (<xref ref-type="bibr" rid="bib23">Nadeau and Bengio, 1999</xref>). To ensure that the whole brain model prediction of the facial responses was not confounded with the pain ratings, we predicted the facial composite scores from the FEPS pattern expression scores (i.e. the dot product between the trial-by-trial activation maps and the unthresholded FEPS signature), and included the trial-by-trial pain ratings using a mixed effect model including the participants as a random effect, and allowing the slopes to vary. Variance in the facial composite scores was significantly explained by the FEPS pattern expression scores (R<sup>2</sup><sub>GLMM(m)</sub>=0.40; R<sup>2</sup><sub>GLMM(c)</sub>=0.69; FEPS scores: <italic>β</italic>=0.62 ± 0.04, 95% CI = [0.54; 0.70], <italic>t</italic>(431.79)=14.8, p&lt;0.001; pain ratings: <italic>β</italic>=0.02 ± 0.05, 95% CI = [–0.07; 0.11], <italic>t</italic>(30.34)=0.48, p=0.68; FEPS scores × pain ratings: <italic>β</italic>=–0.09 ± 0.04, 95% CI = [–0.17; –0.01], <italic>t</italic>(194.89)=–2.25, p=0.03; see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1F</xref>; also see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3A</xref> for the scatterplot and the regression line between the log-transformed scores and the FEPS pattern expression scores across all data points). These results confirm the prediction of the facial response by the FEPS scores even when pain ratings are included as a predictors in the model. However, a small but significant negative interaction between the FEPS scores and the pain ratings was found. This possible moderator effect indicates that, for a constant stimulus, the positive slope between the FEPS scores and the facial responses is slightly reduced when pain ratings are higher. This may reflect a saturation effect across the two output channels (i.e. verbal reports and facial expressions).</p></sec><sec id="s3-3-3"><title>Response of the FEPS to pain and warm</title><p>To test if the FEPS was more activated during the painful condition compared to the warm conditions, the FEPS expression scores were further computed on the warm trials. A linear mixed model was performed to examine the relation between the FEPS scores and the experimental conditions (Warm and Pain), considering those conditions as a fixed categorical effect and the participants as a random effect. Contrasts on the estimated marginal means (least-squares means) were conducted to assess the statistical significance of the difference between the FEPS expression scores on the warm trials and the painful trials. Given that there are also trials where the FACS scores were equal to zero in the painful condition, the same analyses were repeated, this time separating the FEPS expression scores based on whether FACS scores were greater or equal to 0 in the painful condition. The estimated marginal means (EMM) contrast between experimental conditions were reported with the associated <italic>t</italic>-value and <italic>p</italic>-value (corrected for multiple comparisons using the Tukey method).</p></sec><sec id="s3-3-4"><title>Spatial similarity across the FEPS and pain-related brain signatures</title><p>Similarity between the FEPS and other pain-related brain signatures was assessed using the cosine similarity computed across all voxels (<inline-formula><mml:math id="inf2"><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mo>⋅</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>X</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>Y</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:math></inline-formula>). This metric was computed on the unthresholded NPS, SIIPS-1, PVP, and TPAS maps. To further explore the cortical similarities between the FEPS and other pain-related brain signatures, we also computed the cosine similarity across different cortical networks (i.e. visual, somatomotor, dorsal attention, ventral attention, limbic, frontoparietal, and default mode) (<xref ref-type="bibr" rid="bib41">Yeo et al., 2011</xref>). Permutation tests (n=1000) using generative null models preserving the spatial autocorrelation of a target brain map were used to assess the significance of the similarity between the brain signatures (<xref ref-type="bibr" rid="bib2">Burt et al., 2020</xref>). p-values were calculated from the generated null distributions as the fraction of permuted samples where the absolute cosine similarity was equal, or larger than the cosine similarity obtained on the original signatures.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s4"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Methodology</p></fn><fn fn-type="con" id="con4"><p>Software, Validation, Visualization</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Validation, Methodology</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Funding acquisition, Validation</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All participants provided written informed consent and received monetary compensation for their participation. The information about the video recording of the face was indicated in the consent form but this was not emphasized and it was not mentioned at the time of data acquisition. All procedures were approved by the ethics committee of the Centre de recherche de l'institut universitaire de gériatrie de Montréal (Comité d'éthique de la recherche vieillissement-neuroimagerie - R9; reference number CMER-RNQ 14-15-003).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s5"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Supplementary tables.</title><p>(<bold>A</bold>) Peak regions with positive weights contributing to the prediction of the facial expression scores. (<bold>B</bold>) Peak regions with negative weights contributing to the prediction of the facial expression scores. (<bold>C</bold>) Mixed-effect model results for the effect of pain ratings on the logarithmic transformed facial action coding system (FACS) scores. (<bold>D</bold>) Mixed-effect model results for the effect of runs and trials on the logarithmic transformed FACS scores. (<bold>E</bold>) Mixed-effect model results for the effect of runs and trials on the pain ratings. (<bold>F</bold>) Mixed-effect model results for the effect of the facial expression of pain signature (FEPS) expression scores and the pain ratings on the logarithmic transformed FACS scores.</p></caption><media xlink:href="elife-87962-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-87962-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s6"><title>Data availability</title><p>This report is based on the secondary analysis of data previously acquired for another study in our laboratory (see <xref ref-type="bibr" rid="bib19">Kunz et al., 2011</xref>). In that previous study, participants did not provide informed consent for the sharing of individual data. Unthresholded and thresholded FEPS patterns are available on Neurovault (Compact Identifiers: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/neurovault.collection:13924">https://identifiers.org/neurovault.collection:13924</ext-link>). The SIIPS-1, the PVP and the TPAS are available on Github (<ext-link ext-link-type="uri" xlink:href="https://github.com/canlab/Neuroimaging_Pattern_Masks">https://github.com/canlab/Neuroimaging_Pattern_Masks</ext-link>, <xref ref-type="bibr" rid="bib26">Petre and Wager, 2024</xref>). We have had access to the NPS through TDW. To have access to it contact Tor.D.Wager@Dartmouth.edu. All the related information can also be found on this website <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/dartmouth.edu/canlab-brainpatterns/multivariate-brain-signatures/2013-nps">https://sites.google.com/dartmouth.edu/canlab-brainpatterns/multivariate-brain-signatures/2013-nps</ext-link>. Furthermore, all custom Python and R scripts used to produce the analyses are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/me-pic/picard_feps_2023">https://github.com/me-pic/picard_feps_2023</ext-link> (copy archived at <xref ref-type="bibr" rid="bib27">Picard, 2024</xref>) under the Apache-2.0 license. The code used for the bootstrap analyses was adapted from <ext-link ext-link-type="uri" xlink:href="https://github.com/mpcoll/coll_painvalue_2021">https://github.com/mpcoll/coll_painvalue_2021</ext-link> (<xref ref-type="bibr" rid="bib5">Coll, 2022</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We wish to thank André Cyr and Carollyn Hurst from the Unité de Neuroimagerie Fonctionnelle for their help with the data acquisition, and Andréanne Proulx, François Paugman, and Pierre Bellec for their insights on the analyses as part of BrainHack School. We also want to acknowledge Compute Canada for the computational resources allocated to conduct the analyses.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastuji</surname><given-names>H</given-names></name><name><surname>Frot</surname><given-names>M</given-names></name><name><surname>Perchet</surname><given-names>C</given-names></name><name><surname>Magnin</surname><given-names>M</given-names></name><name><surname>Garcia-Larrea</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pain networks from the inside: Spatiotemporal analysis of brain responses leading from nociception to conscious perception</article-title><source>Human Brain Mapping</source><volume>37</volume><fpage>4301</fpage><lpage>4315</lpage><pub-id pub-id-type="doi">10.1002/hbm.23310</pub-id><pub-id pub-id-type="pmid">27391083</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burt</surname><given-names>JB</given-names></name><name><surname>Helmer</surname><given-names>M</given-names></name><name><surname>Shinn</surname><given-names>M</given-names></name><name><surname>Anticevic</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Generative modeling of brain maps with spatial autocorrelation</article-title><source>NeuroImage</source><volume>220</volume><elocation-id>117038</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117038</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caviness</surname><given-names>VS</given-names><suffix>Jr</suffix></name><name><surname>Meyer</surname><given-names>J</given-names></name><name><surname>Makris</surname><given-names>N</given-names></name><name><surname>Kennedy</surname><given-names>DN</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>MRI-based topographic parcellation of human neocortex: an anatomically specified method with estimate of reliability</article-title><source>Journal of Cognitive Neuroscience</source><volume>8</volume><fpage>566</fpage><lpage>587</lpage><pub-id pub-id-type="doi">10.1162/jocn.1996.8.6.566</pub-id><pub-id pub-id-type="pmid">23961985</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Čeko</surname><given-names>M</given-names></name><name><surname>Kragel</surname><given-names>PA</given-names></name><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>López-Solà</surname><given-names>M</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Common and stimulus-type-specific brain representations of negative affect</article-title><source>Nature Neuroscience</source><volume>25</volume><fpage>760</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1038/s41593-022-01082-w</pub-id><pub-id pub-id-type="pmid">35637370</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Coll</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Code for Coll et al., The neural signature of the decision value of future pain</data-title><version designator="e9c09e0">e9c09e0</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/mpcoll/coll_painvalue_2021">https://github.com/mpcoll/coll_painvalue_2021</ext-link></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coll</surname><given-names>MP</given-names></name><name><surname>Slimani</surname><given-names>H</given-names></name><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name><name><surname>Vachon-Presseau</surname><given-names>É</given-names></name><name><surname>Roy</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The neural signature of the decision value of future pain</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2119931119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2119931119</pub-id><pub-id pub-id-type="pmid">35658082</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craig</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The facial expression of pain Better than a thousand words?</article-title><source>APS Journal</source><volume>1</volume><fpage>153</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1016/1058-9139(92)90001-S</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalla Costa</surname><given-names>E</given-names></name><name><surname>Minero</surname><given-names>M</given-names></name><name><surname>Lebelt</surname><given-names>D</given-names></name><name><surname>Stucke</surname><given-names>D</given-names></name><name><surname>Canali</surname><given-names>E</given-names></name><name><surname>Leach</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Development of the Horse Grimace Scale (HGS) as a pain assessment tool in horses undergoing routine castration</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e92281</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0092281</pub-id><pub-id pub-id-type="pmid">24647606</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Del Cul</surname><given-names>A</given-names></name><name><surname>Baillet</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Brain dynamics underlying the nonlinear threshold for access to consciousness</article-title><source>PLOS Biology</source><volume>5</volume><elocation-id>e260</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0050260</pub-id><pub-id pub-id-type="pmid">17896866</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>P</given-names></name><name><surname>Friesen</surname><given-names>WV</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>Facial Action Coding System</source><publisher-name>Consulting Psychologists Press</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evangelista</surname><given-names>MC</given-names></name><name><surname>Watanabe</surname><given-names>R</given-names></name><name><surname>Leung</surname><given-names>VSY</given-names></name><name><surname>Monteiro</surname><given-names>BP</given-names></name><name><surname>O’Toole</surname><given-names>E</given-names></name><name><surname>Pang</surname><given-names>DSJ</given-names></name><name><surname>Steagall</surname><given-names>PV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Facial expressions of pain in cats: the development and validation of a Feline Grimace Scale</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>19128</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-55693-8</pub-id><pub-id pub-id-type="pmid">31836868</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia-Larrea</surname><given-names>L</given-names></name><name><surname>Peyron</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Pain matrices and neuropathic pain matrices: a review</article-title><source>Pain</source><volume>154 Suppl 1</volume><fpage>S29</fpage><lpage>S43</lpage><pub-id pub-id-type="doi">10.1016/j.pain.2013.09.001</pub-id><pub-id pub-id-type="pmid">24021862</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldin</surname><given-names>PR</given-names></name><name><surname>McRae</surname><given-names>K</given-names></name><name><surname>Ramel</surname><given-names>W</given-names></name><name><surname>Gross</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The neural bases of emotion regulation: reappraisal and suppression of negative emotion</article-title><source>Biological Psychiatry</source><volume>63</volume><fpage>577</fpage><lpage>586</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2007.05.031</pub-id><pub-id pub-id-type="pmid">17888411</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hadjistavropoulos</surname><given-names>T</given-names></name><name><surname>Craig</surname><given-names>KD</given-names></name><name><surname>Duck</surname><given-names>S</given-names></name><name><surname>Cano</surname><given-names>A</given-names></name><name><surname>Goubert</surname><given-names>L</given-names></name><name><surname>Jackson</surname><given-names>PL</given-names></name><name><surname>Mogil</surname><given-names>JS</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name><name><surname>Sullivan</surname><given-names>MJL</given-names></name><name><surname>Williams</surname><given-names>AC</given-names></name><name><surname>Vervoort</surname><given-names>T</given-names></name><name><surname>Fitzgerald</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A biopsychosocial formulation of pain communication</article-title><source>Psychological Bulletin</source><volume>137</volume><fpage>910</fpage><lpage>939</lpage><pub-id pub-id-type="doi">10.1037/a0023876</pub-id><pub-id pub-id-type="pmid">21639605</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karmann</surname><given-names>AJ</given-names></name><name><surname>Maihöfner</surname><given-names>C</given-names></name><name><surname>Lautenbacher</surname><given-names>S</given-names></name><name><surname>Sperling</surname><given-names>W</given-names></name><name><surname>Kornhuber</surname><given-names>J</given-names></name><name><surname>Kunz</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The role of prefrontal inhibition in regulating facial expressions of pain: a repetitive transcranial magnetic stimulation study</article-title><source>The Journal of Pain</source><volume>17</volume><fpage>383</fpage><lpage>391</lpage><pub-id pub-id-type="doi">10.1016/j.jpain.2015.12.002</pub-id><pub-id pub-id-type="pmid">26705973</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishnan</surname><given-names>A</given-names></name><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Chang</surname><given-names>LJ</given-names></name><name><surname>Ruzic</surname><given-names>L</given-names></name><name><surname>Gu</surname><given-names>X</given-names></name><name><surname>López-Solà</surname><given-names>M</given-names></name><name><surname>Jackson</surname><given-names>PL</given-names></name><name><surname>Pujol</surname><given-names>J</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Somatic and vicarious pain are represented by dissociable multivariate brain patterns</article-title><source>eLife</source><volume>5</volume><elocation-id>e15166</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.15166</pub-id><pub-id pub-id-type="pmid">27296895</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Gruber</surname><given-names>A</given-names></name><name><surname>Lautenbacher</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Sex differences in facial encoding of pain</article-title><source>The Journal of Pain</source><volume>7</volume><fpage>915</fpage><lpage>928</lpage><pub-id pub-id-type="doi">10.1016/j.jpain.2006.04.012</pub-id><pub-id pub-id-type="pmid">17157778</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Chatelle</surname><given-names>C</given-names></name><name><surname>Lautenbacher</surname><given-names>S</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The relation between catastrophizing and facial responsiveness to pain</article-title><source>Pain</source><volume>140</volume><fpage>127</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.pain.2008.07.019</pub-id><pub-id pub-id-type="pmid">18783885</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>JI</given-names></name><name><surname>Lautenbacher</surname><given-names>S</given-names></name><name><surname>Vachon-Presseau</surname><given-names>E</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cerebral regulation of facial expressions of pain</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>8730</fpage><lpage>8738</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0217-11.2011</pub-id><pub-id pub-id-type="pmid">21677157</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Karos</surname><given-names>K</given-names></name><name><surname>Vervoort</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title>When, how, and why do we express pain</chapter-title><person-group person-group-type="editor"><name><surname>Vervoort</surname><given-names>Tine</given-names></name><name><surname>Karos</surname><given-names>Kai</given-names></name><name><surname>Trost</surname><given-names>Zina</given-names></name><name><surname>Prkachin</surname><given-names>Kenneth M</given-names></name></person-group><source>In Social and Interpersonal Dynamics in Pain: We Don’t Suffer Alone</source><publisher-loc>Cham</publisher-loc><publisher-name>Springer International Publishing</publisher-name><fpage>101</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-78340-6_6</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>JI</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Keeping an eye on pain expression in primary somatosensory cortex</article-title><source>NeuroImage</source><volume>1</volume><elocation-id>116885</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116885</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langford</surname><given-names>DJ</given-names></name><name><surname>Bailey</surname><given-names>AL</given-names></name><name><surname>Chanda</surname><given-names>ML</given-names></name><name><surname>Clarke</surname><given-names>SE</given-names></name><name><surname>Drummond</surname><given-names>TE</given-names></name><name><surname>Echols</surname><given-names>S</given-names></name><name><surname>Glick</surname><given-names>S</given-names></name><name><surname>Ingrao</surname><given-names>J</given-names></name><name><surname>Klassen-Ross</surname><given-names>T</given-names></name><name><surname>Lacroix-Fralish</surname><given-names>ML</given-names></name><name><surname>Matsumiya</surname><given-names>L</given-names></name><name><surname>Sorge</surname><given-names>RE</given-names></name><name><surname>Sotocinal</surname><given-names>SG</given-names></name><name><surname>Tabaka</surname><given-names>JM</given-names></name><name><surname>Wong</surname><given-names>D</given-names></name><name><surname>van den Maagdenberg</surname><given-names>A</given-names></name><name><surname>Ferrari</surname><given-names>MD</given-names></name><name><surname>Craig</surname><given-names>KD</given-names></name><name><surname>Mogil</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Coding of facial expressions of pain in the laboratory mouse</article-title><source>Nature Methods</source><volume>7</volume><fpage>447</fpage><lpage>449</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1455</pub-id><pub-id pub-id-type="pmid">20453868</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Nadeau</surname><given-names>C</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Inference for the generalization error</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>J</given-names></name><name><surname>Zhan</surname><given-names>L</given-names></name><name><surname>Hu</surname><given-names>C</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Gu</surname><given-names>L</given-names></name><name><surname>Zhong</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>Q</given-names></name><name><surname>Xie</surname><given-names>X</given-names></name><name><surname>Chen</surname><given-names>Q</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>M</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emotion regulation and complex brain networks: association between expressive suppression and efficiency in the fronto-parietal network and default-mode network</article-title><source>Frontiers in Human Neuroscience</source><volume>12</volume><elocation-id>70</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2018.00070</pub-id><pub-id pub-id-type="pmid">29662443</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: Machine learning in python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Petre</surname><given-names>B</given-names></name><name><surname>Wager</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Neuroimaging_Pattern_Masks</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/canlab/Neuroimaging_Pattern_Masks">https://github.com/canlab/Neuroimaging_Pattern_Masks</ext-link></element-citation></ref><ref id="bib27"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Picard</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Code for Picard et al., A distributed brain response predicting the facial expression of acute nociceptive pain</data-title><version designator="swh:1:rev:d852c113504d29b5c11fb17112cde64a423a56f5">swh:1:rev:d852c113504d29b5c11fb17112cde64a423a56f5</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:6c9be199aaa1f4dbdb40db170abe3eae35cc8fc4;origin=https://github.com/me-pic/picard_feps_2023;visit=swh:1:snp:238c8d85c0e7d79f33be09982d20208d036a7772;anchor=swh:1:rev:d852c113504d29b5c11fb17112cde64a423a56f5">https://archive.softwareheritage.org/swh:1:dir:6c9be199aaa1f4dbdb40db170abe3eae35cc8fc4;origin=https://github.com/me-pic/picard_feps_2023;visit=swh:1:snp:238c8d85c0e7d79f33be09982d20208d036a7772;anchor=swh:1:rev:d852c113504d29b5c11fb17112cde64a423a56f5</ext-link></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Psychological and neural mechanisms of the affective dimension of pain</article-title><source>Science</source><volume>288</volume><fpage>1769</fpage><lpage>1772</lpage><pub-id pub-id-type="doi">10.1126/science.288.5472.1769</pub-id><pub-id pub-id-type="pmid">10846154</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rainville</surname><given-names>P</given-names></name><name><surname>Feine</surname><given-names>JS</given-names></name><name><surname>Bushnell</surname><given-names>MC</given-names></name><name><surname>Duncan</surname><given-names>GH</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>A psychophysical comparison of sensory and affective responses to four modalities of experimental pain</article-title><source>Somatosensory &amp; Motor Research</source><volume>9</volume><fpage>265</fpage><lpage>277</lpage><pub-id pub-id-type="doi">10.3109/08990229209144776</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>M</given-names></name><name><surname>Piche</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>JI</given-names></name><name><surname>Peretz</surname><given-names>I</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Cerebral and spinal modulation of pain by emotions</article-title><source>Nature Precedings</source><volume>February</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.1038/npre.2009.2885.1</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname><given-names>MFS</given-names></name><name><surname>Noonan</surname><given-names>MP</given-names></name><name><surname>Boorman</surname><given-names>ED</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Frontal cortex and reward-guided learning and decision-making</article-title><source>Neuron</source><volume>70</volume><fpage>1054</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.014</pub-id><pub-id pub-id-type="pmid">21689594</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shackman</surname><given-names>AJ</given-names></name><name><surname>Salomons</surname><given-names>TV</given-names></name><name><surname>Slagter</surname><given-names>HA</given-names></name><name><surname>Fox</surname><given-names>AS</given-names></name><name><surname>Winter</surname><given-names>JJ</given-names></name><name><surname>Davidson</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The integration of negative affect, pain and cognitive control in the cingulate cortex</article-title><source>Nature Reviews. Neuroscience</source><volume>12</volume><fpage>154</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1038/nrn2994</pub-id><pub-id pub-id-type="pmid">21331082</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>D</given-names></name><name><surname>Craig</surname><given-names>KD</given-names></name><name><surname>Gosselin</surname><given-names>F</given-names></name><name><surname>Belin</surname><given-names>P</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Recognition and discrimination of prototypical dynamic expressions of pain and emotions</article-title><source>Pain</source><volume>135</volume><fpage>55</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.pain.2007.05.008</pub-id><pub-id pub-id-type="pmid">17583430</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sliwa</surname><given-names>J</given-names></name><name><surname>Mallet</surname><given-names>M</given-names></name><name><surname>Christiaens</surname><given-names>M</given-names></name><name><surname>Takahashi</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neural basis of multi-sensory communication in primates</article-title><source>Ethology Ecology &amp; Evolution</source><volume>34</volume><fpage>322</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1080/03949370.2021.2024266</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sneddon</surname><given-names>LU</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Evolution of nociception and pain: evidence from fish models</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>374</volume><elocation-id>20190290</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2019.0290</pub-id><pub-id pub-id-type="pmid">31544617</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sotocinal</surname><given-names>SG</given-names></name><name><surname>Sorge</surname><given-names>RE</given-names></name><name><surname>Zaloum</surname><given-names>A</given-names></name><name><surname>Tuttle</surname><given-names>AH</given-names></name><name><surname>Martin</surname><given-names>LJ</given-names></name><name><surname>Wieskopf</surname><given-names>JS</given-names></name><name><surname>Mapplebeck</surname><given-names>JCS</given-names></name><name><surname>Wei</surname><given-names>P</given-names></name><name><surname>Zhan</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>McDougall</surname><given-names>JJ</given-names></name><name><surname>King</surname><given-names>OD</given-names></name><name><surname>Mogil</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The Rat Grimace Scale: a partially automated method for quantifying pain in the laboratory rat via facial expressions</article-title><source>Molecular Pain</source><volume>7</volume><elocation-id>55</elocation-id><pub-id pub-id-type="doi">10.1186/1744-8069-7-55</pub-id><pub-id pub-id-type="pmid">21801409</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vachon-Presseau</surname><given-names>E</given-names></name><name><surname>Roy</surname><given-names>M</given-names></name><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Martel</surname><given-names>MO</given-names></name><name><surname>Sullivan</surname><given-names>MJ</given-names></name><name><surname>Jackson</surname><given-names>PL</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multiple faces of pain: effects of chronic pain on the brain regulation of facial expression</article-title><source>Pain</source><volume>157</volume><fpage>1819</fpage><lpage>1830</lpage><pub-id pub-id-type="doi">10.1097/j.pain.0000000000000587</pub-id><pub-id pub-id-type="pmid">27411160</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Atlas</surname><given-names>LY</given-names></name><name><surname>Leotti</surname><given-names>LA</given-names></name><name><surname>Rilling</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Predicting individual differences in placebo analgesia: contributions of brain activity during anticipation and pain experience</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>439</fpage><lpage>452</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3420-10.2011</pub-id><pub-id pub-id-type="pmid">21228154</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Atlas</surname><given-names>LY</given-names></name><name><surname>Lindquist</surname><given-names>MA</given-names></name><name><surname>Roy</surname><given-names>M</given-names></name><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Kross</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>An fMRI-based neurologic signature of physical pain</article-title><source>The New England Journal of Medicine</source><volume>368</volume><fpage>1388</fpage><lpage>1397</lpage><pub-id pub-id-type="doi">10.1056/NEJMoa1204471</pub-id><pub-id pub-id-type="pmid">23574118</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Schmidt</surname><given-names>L</given-names></name><name><surname>Krishnan</surname><given-names>A</given-names></name><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Roy</surname><given-names>M</given-names></name><name><surname>Lindquist</surname><given-names>MA</given-names></name><name><surname>Atlas</surname><given-names>LY</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Quantifying cerebral contributions to pain beyond nociception</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>14211</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms14211</pub-id><pub-id pub-id-type="pmid">28195170</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Sabuncu</surname><given-names>MR</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Hollinshead</surname><given-names>M</given-names></name><name><surname>Roffman</surname><given-names>JL</given-names></name><name><surname>Smoller</surname><given-names>JW</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><pub-id pub-id-type="pmid">21653723</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>W</given-names></name><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Yao</surname><given-names>Z</given-names></name><name><surname>Goldstein</surname><given-names>P</given-names></name><name><surname>Atlas</surname><given-names>LY</given-names></name><name><surname>Roy</surname><given-names>M</given-names></name><name><surname>Schmidt</surname><given-names>L</given-names></name><name><surname>Krishnan</surname><given-names>A</given-names></name><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Hu</surname><given-names>B</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pain-evoked reorganization in functional brain networks</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>2804</fpage><lpage>2822</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz276</pub-id><pub-id pub-id-type="pmid">31813959</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87962.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Biurrun Manresa</surname><given-names>José</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>National Scientific and Technical Research Council (CONICET), National University of Entre Ríos (UNER)</institution><country>Argentina</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>Picard et al. propose a Facial Expression Pain Signature (FEPS) derived from functional magnetic resonance imaging (fMRI) data to predict facial expressions associated with painful heat stimulation. This <bold>important</bold> work advances our understanding of the brain mechanisms associated with facial expressions of pain. It provides <bold>solid</bold> evidence that facial expressions of pain contain information that is complementary to other pain-related brain processes. The work will be of broad interest to researchers from varied fields ranging from neurosciences to psychology and affective sciences.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87962.3.sa1</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary.</p><p>The objective of this study was to further our understanding of the brain mechanisms associated with facial expressions of pain. To achieve this, participants' facial expressions and brain activity were recorded while they received noxious heat stimulation. The authors then used a decoding approach to predict facial expressions from functional magnetic resonance imaging (fMRI) data. They found a distinctive brain signature for pain facial expressions (FEPS). This signature had minimal overlap with brain signatures reflecting other components of pain phenomenology, such as signatures reflecting subjective pain intensity or negative effects.</p><p>Strength.</p><p>The authors used a rigorous approach involving multivariate brain decoding to predict the occurrence and intensity of pain facial expressions during noxious heat stimulation. The analyses are solid and well-conducted. This is an important study of fundamental and clinical relevance.</p><p>Weakness.</p><p>Despite those major strengths, the main weakness of the study is that the design and analyses do not allow us to know if the FEPS is really specific to pain expressions. Based on the analysis, it is possible to conclude that this brain signature is present when a participant is in a state of pain and displays a facial expression. However, it is possible that it would also be present when a participant experiences (another) negative state and displays (another) facial expression. It will be important, in future work, to investigate the specificity of this brain signature.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87962.3.sa2</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In this manuscript, Picard et al. propose a Facial Expression Pain Signature (FEPS) as a distinctive marker of pain processing in the brain. Specifically, they attempt to use functional magnetic resonance imaging (fMRI) data to predict facial expressions associated with painful heat stimulation.</p><p>The main strengths of the manuscript are that it is built on an extensive foundation of work from the research group, and that experience can be observed in the analysis of fMRI data and the development of the machine learning model. Additionally, it provides a comparative account of the similarities of the FEPS with other proposed pain signatures. The main weaknesses of the manuscript are the absence of a proper control condition to assess the specificity of the facial pain expressions, as well as several limitations in the experimental setup.</p><p>I believe that the authors partially succeed in their aims, as described in the introduction, which are to assess the association between pain facial expression and existing pain-relevant brain signatures, and to develop a predictive brain activation model of the facial responses to painful thermal stimulation. However, they list several limitations in the study that should be addressed in future research in order to establish whether FEPS truly conveys distinctive information about the brain response to nociceptive stimuli.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87962.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Picard</surname><given-names>Marie-Eve</given-names></name><role specific-use="author">Author</role><aff><institution>University of Montreal</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Kunz</surname><given-names>Miriam</given-names></name><role specific-use="author">Author</role><aff><institution>Augsburg University</institution><addr-line><named-content content-type="city">Augsburg</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Jen-I</given-names></name><role specific-use="author">Author</role><aff><institution>Université de Montréal</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Coll</surname><given-names>Michel-Pierre</given-names></name><role specific-use="author">Author</role><aff><institution>Université Laval</institution><addr-line><named-content content-type="city">Quebec City</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Vachon-Presseau</surname><given-names>Etienne</given-names></name><role specific-use="author">Author</role><aff><institution>McGill University</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Wager</surname><given-names>Tor</given-names></name><role specific-use="author">Author</role><aff><institution>1Institute of Cognitive Science, University of Colorado Boulder</institution><addr-line><named-content content-type="city">Boulder</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Rainville</surname><given-names>Pierre</given-names></name><role specific-use="author">Author</role><aff><institution>Université de Montréal</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><p>Summary of the changes</p><p>Changes in the manuscript were made to clarify some ambiguities raised by the reviewers and to improve the report following their recommendations. A summary of the main changes is listed below:</p><p>- The title was changed to better reflect the results of this study - Re-training the model on log transformed FACS scores.</p><p>- Testing the specificity of the FEPS to facial expression of pain within this experimental setup by comparing it to the activation maps obtained from the Warm stimulation condition.</p><p>- Testing for sensitization/habituation of the behavioral measures (FACS scores and pain ratings).</p><p>- Adding a section in the discussion to better address the limitations of this study and provide potential directions for future studies.</p><p>Other changes target areas where the original manuscript may have been ambiguous or lacked precision. To address these concerns, additional details have been incorporated, and certain terms have been revised to ensure a more precise and transparent presentation of the information.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Picard et al. report a novel neural signature of facial expressions of pain. In other words, they provide evidence that a specific set of brain activations, as measured by means of functional magnetic resonance imaging (fMRI), can tell us when someone is expressing pain via a concerted activation of distinctive facial muscles. They demonstrate that this signature provides a better characterization of this pain behaviour when compared with other signatures of pain reported by past research. The Facial Expression of Pain Signature (FEPS) thus enriches this collection and, if further validated, may allow scientists to identify the neural structures subserving important non-verbal pain behaviour. I have, however, some reservations about the strength of the evidence, relating to insufficient characterization of the underlying processes involved.</p></disp-quote><p>We are thankful for the summary of our work. We are hopeful that the modifications made in the latest version effectively address these concerns. The changes are outlined in the summary above, and detailed in the following point-by-point response.</p><disp-quote content-type="editor-comment"><p>Strengths:</p><p>The study relies on a robust machine-learning approach, able to capitalise on the multivariate nature of the fMRI data, an approach pioneered in the field of pain by one of the authors (Dr. Tor Wager). This paper extends Wager's and other colleagues' work attempting to identify specific combinations of brain structures subserving different aspects of the pain experience while examining the extent of similarity/dissimilarity with the other signatures. In doing so, the study provides further methodological insight into fine-grained network characterization that may inspire future work beyond this specific field.</p></disp-quote><p>We are thankful for the positive comments.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>The main weakness concerns the lack of a targeted experimental design aimed to dissect the shared variance explained by activations both specific to facial expressions and to pain reports. In particular, I believe that two elements would have significantly increased the robustness of the findings:</p><p>(1) Control conditions for both the facial expressions and the sensory input. An efficient signature should not be predictive of neutral and emotional facial expressions (e.g., disgust) other than pain expressions, as well as it should not be predictive of sensations originating from innocuous warm stimulation or other unpleasant but non-painful stimulation.</p></disp-quote><p>We do recognize the lack of specificity testing for the FEPS, especially towards negative emotional facial expressions. This would be relevant to test given the behavioural overlap between the facial expressions of pain and disgust, fear, anger, and sadness <ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083277">(Kunz</ext-link> <ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083277">et</ext-link> <ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083277">al.,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083277">2013</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/facial-expression-of-pain-an-evolutionary-account/F32F82D2FB5D9AF8980B16239B7EB994">Williams,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/facial-expression-of-pain-an-evolutionary-account/F32F82D2FB5D9AF8980B16239B7EB994">2003</ext-link>). The experimental design used in this study did not include other negative states. However, we fully support the necessity of collecting data throughout those conditions, and we believe that the present study highlights the importance of such a demonstration. Future research should involve recording facial expressions while exposing participants to stimuli that elicit a range of negative emotions but, to our knowledge, such combination of fMRI and behavioural data is currently unavailable. As raised by the reviewer, this approach would allow us to assess the specificity of the FEPS to the facial expression evoked by pain compared to different affective states. We would like to emphasise that specificity and generalizability testing is a massive amount of work, requiring multiple studies to address comprehensively. A Limitations paragraph addressing this research direction has been added to the Discussion. A conclusion was added to the abstract as follows: “Future studies should explore other pain-relevant manifestations and assess the specificity of the FEPS against other types of aversive or emotional states.”</p><disp-quote content-type="editor-comment"><p>(2) Graded intensity of the sensory stimulation: different intensities of the thermal stimulation would have caused a graded facial expression (from neutral to pain) and graded verbal reports (from no pain to strong pain), thus offering a sensitive characterisation of the signal associated with this condition (and the warm control condition).</p><p>However, these conditions are missing from the current design, and therefore we cannot make a strong conclusion about the generalisability of the signature (regardless of whether it can predict better than other signatures - which may/may not suffer from similar or other methodological issues - another potential interesting scientific question!). The authors seem to work on the assumption that the trials where warm stimulation was delivered are of no use. I beg to disagree. As per my previous comment, warm trials (and associated neutral expressions) could be incorporated into the statistical model to increase the classification sensitivity and precision of the FEPS decoding.</p></disp-quote><p>The experience of pain can fluctuate for a fixed intensity or after controlling statistically for the intensity of the stimulation (Woo et al., 2017). Consistent with this, the current study focused on spontaneous facial expression in response to noxious thermal stimuli delivered at a constant intensity that produced moderate to strong pain in every participant. As the reviewer points out, this does not allow us to characterise and compare the stimulus-response function of facial expression and pain ratings. The advantage of the approach adopted is to maximise the number of trials where facial expression is more likely to occur, while ensuring that changes in facial expression and pain ratings are not confounded with changes in stimulus intensity. The manuscript has been revised to clarify that point. However, we do agree that it would be interesting to conduct more studies focusing on facial expression in response to a range of stimulus intensities. This discussion has been added to the Limitations paragraph.</p><p>Furthermore, following the reviewer’s suggestion, we performed complementary analyses on the warm trials in the proposed revisions. The dot product (FEPS scores) between the FEPS and the activation maps associated with the warm condition was computed. A linear mixed model was conducted to investigate the association between FEPS scores and the experimental condition (warm vs pain). The trials in the pain condition were divided into two conditions: null FACS scores (painful trials with no facial response; FACS scores = 0) and non-null FACS scores (painful trials with a facial response; FACS &gt; 0). The details of this analysis have been added to the manuscript (see Response of the FEPS to pain and warm section in the Methods; lines 427 to 439) as well as the corresponding results (see Results and Discussion; lines 138 to 158). The FEPS scores were larger in the pain condition where a facial response was expressed, compared to both the pain condition without facial expression and the warm condition. These results confirmed the sensitivity of the FEPS to facial expression of pain.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>The objective of this study was to further our understanding of the brain mechanisms associated with facial expressions of pain. To achieve this, participants' facial expressions and brain activity were recorded while they received noxious heat stimulation. The authors then used a decoding approach to predict facial expressions from functional magnetic resonance imaging (fMRI) data. They found a distinctive brain signature for pain facial expressions. This signature had minimal overlap with brain signatures reflecting other components of pain phenomenology, such as signatures reflecting subjective pain intensity or negative effects.</p></disp-quote><p>We appreciate this concise and accurate summary of our study.</p><disp-quote content-type="editor-comment"><p>Strength:</p><p>The manuscript is clearly written. The authors used a rigorous approach involving multivariate brain decoding to predict the occurrence and intensity of pain facial expressions during noxious heat stimulation. The analyses seem solid and well-conducted. I think that this is an important study of fundamental and clinical relevance.</p><p>Weaknesses:</p><p>Despite those major strengths, I felt that the authors did not suffciently explain their own interpretation of the significance of the findings. What does it mean, according to them, that the brain signature associated with facial expressions of pain shows a minimal overlap with other pain-related brain signatures?</p></disp-quote><p>We express our sincere gratitude for the valuable insights and constructive comments on the strengths and weaknesses of the current study. We thank reviewer 2 for the encouragement to reinforce our interpretation of the significance of the findings, while acknowledging the limitations raised by the three reviewers.</p><disp-quote content-type="editor-comment"><p>A few questions also arose during my reading.</p><p>Question 1: Is the FEPS really specific to pain expressions? Is it possible that the signature includes a facial expression signal that would be shared with facial expressions of other emotions, especially since it involves socio-affective regulation processes? Perhaps this question should be discussed as a limit of the study?</p></disp-quote><p>We acknowledge this limitation as outlined in response to Reviewer #1. We have incorporated a Limitations paragraph to provide a more in-depth discussion of this limitation and to explore potential future avenues (lines 225 to 268). Again, please note that the demonstration of specificity is an incremental process that requires a systematic comparison with other conditions where facial expressions are produced without pain. A concluding sentence was added to the abstract to encourage specificity testing in future studies. as indicated above.</p><disp-quote content-type="editor-comment"><p>Question 2: All AUs are combined together in a composite score for the regression. Given that the authors have other work showing that different AUs may be associated with different components of pain (affective vs. sensory), is it possible that combining all AUs together has decreased the correlation with other pain signatures? Or that the FEPS actually reflects multiple independent signatures?</p></disp-quote><p>The question raised is consistent with the work of Kunz, Lautenbacher, LeBlanc and Rainville (2012), and Kunz, Chen and Rainville (2020). In the current study, the pain-relevant action units were combined in order to increase the number of trials where a facial response to pain was expressed, thus enhancing the robustness of our analyses. Given the limited sample size, our current dataset is unfortunately insufficient to perform such analysis as there would not be enough trials to look at the action units separately or in subgroups. While the approach of combining the different AUs has proven to be valid and useful, we recognize the value of investigating potential independent signatures associated with the different AUs within the FEPS, and examining whether those signatures can lead to more similar patterns compared to previously developed pain signatures. This discussion has been included in the Limitations paragraph in the Discussion (lines 225 to 268).</p><disp-quote content-type="editor-comment"><p>Question 3: Is facial expressivity constant throughout the experiment? Is it possible that the expressivity changes between the beginning and the end of the experiment? For instance, if there is a habituation, or if the participant is less surprised by the pain, or in contrast if they get tired by the end of the experiment and do not inhibit their expression as much as they did at the beginning. If facial expressivity changes, this could perhaps affect the correlation with the pain ratings and/or with the brain signatures; perhaps time (trial number) could be added as one of the variables in the model to address this question.</p></disp-quote><p>The concern raised by the reviewer is legitimate. We conducted a mixed-effects model to assess the impact of successive trials and runs on facial expressivity. Results indicate that the FACS scores did not change significantly throughout the experiment, suggesting no notable effect of habituation or sensitization on the facial expressivity in our study. Details about the analysis and the results have been added to the Facial Expression section in the Methods (lines 335 to 346).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>In this manuscript, Picard et al. propose a Facial Expression Pain Signature (FEPS) as a distinctive marker of pain processing in the brain. Specifically, they attempt to use functional magnetic resonance imaging (fMRI) data to predict facial expressions associated with painful heat stimulation. The main strengths of the manuscript are that it is built on an extensive foundation of work from the research group, and that experience can be observed in the analysis of fMRI data and the development of the machine learning model. Additionally, it provides a comparative account of the similarities of the FEPS with other proposed pain signatures. The main weaknesses of the manuscript are the absence of a proper control condition to assess the specificity of the facial pain expressions, a few relevant omissions in the methodology regarding the original analysis of the data and its purpose, and a biased interpretation of the results.</p><p>I believe that the authors partially succeed in their aims, as described in the introduction, which are to assess the association between pain facial expression and existing pain-relevant brain signatures, and to develop a predictive brain activation model of the facial responses to painful thermal stimulation. However, I believe that there is a clear difference between those aims and the claim of the title, and that the interpretation of the results needs to be more rigorous.</p></disp-quote><p>We wish to express our appreciation for the insightful and constructive critique provided. The limitation pertaining to the absence of specificity testing had been addressed in response to Reviewer #1, and it has been incorporated into the manuscript (lines 251 to 258).</p><p>The commentary made by Reviewer #3 has drawn our attention to a critical concern, namely the potential misalignment between the study findings and our original title. Consequently, we have changed the title to “A distributed brain response predicting the facial expression of acute nociceptive pain”. We also revised the interpretation of the results in the discussion section and we have added a section on limitations.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the Authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>I hope the following comments will be useful to improve the manuscript.</p><p>Abstract</p><p>I felt the abstract could be more clear in terms of experimental or scientific questions, hypotheses/expectations, and findings. I also feel the abstract should briefly support the conclusive claim (&quot;is better than...&quot;: how better? Or according to what criterion? This may be more relevant than the final conclusive general sentence that does not specifically address the significance of the findings).</p></disp-quote><p>The abstract was revised to reinforce the functional perspective adopted to interpret brain activity produced by noxious stimuli and predicting various pain-relevant manifestations. We also mention explicitly the other pain-relevant signatures against which the FEPS is compared in this report, and we added a concluding sentence highlighting the importance of assessing the specificity of the FEPS in future studies.</p><disp-quote content-type="editor-comment"><p>Introduction - background and rationale</p><p>I would postpone the discussion around pain signature and anticipate the one about the brain mechanisms of facial expressions of pain. This will allow you to reinforce the logical flow of rationale, literature gap/question, why the problem is important, and study aims. Only then go for a review of relevant literature on signatures before providing a more specific final paragraph about the study-specific questions, expectations, and implementation. At the moment this is limited to a single very descriptive short paragraph at the end of the intro.</p></disp-quote><p>The introduction was structured to guide the readers through a comprehensive understanding of different pain neurosignatures. The introduction aimed to establish a robust rationale for the subsequent analyses detailed in the results section. Indeed, the presentation of that literature ensured that the discussion around pain signatures is contextualised within a broader continuous framework. We acknowledge the reviewer’s comment on the limited description of the brain mechanisms of facial expression of pain. However, this was addressed in several previous reports of our laboratory (Kunz et al. 2011; Vachon-Presseau et al. 2016; Kunz, Chen, and Rainville 2020). We have added some more details about the brain mechanisms of facial expression, and highlighted those references in the first paragraph of the introduction.</p><disp-quote content-type="editor-comment"><p>Methods and Results</p><p>(1) Was there any indication of power based on the previous work or the other signature papers? If yes, how that would inform the present analysis?</p></disp-quote><p>The NPS was trained on 20 participants that experienced 12 trials at each of four different intensities. The assessment of the effect sizes was performed on the Neurological Pain Signature in <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S1053811921011150">Han</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S1053811921011150">et</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S1053811921011150">al. (2022)</ext-link>. That study revealed a moderate effect size for predicting between-subject pain reports, and a large one for predicting within-subject pain reports. We trained our model on 34 participants that underwent 16 trials. We expected our results to show a smaller effect size as the current experimental design only allowed us to examine spontaneous changes in the facial expression, as noted in the comments made by Reviewer #1. However, the best way to calculate the unbiased effect size of the results presented in the current study would be to test the unchanged model on new independent datasets (see <ext-link ext-link-type="uri" xlink:href="https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2597706">Reddan,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2597706">Lindquist,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2597706">and</ext-link> <ext-link ext-link-type="uri" xlink:href="https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2597706">Wager,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2597706">2017</ext-link>). Unfortunately, such datasets do not currently exist.</p><disp-quote content-type="editor-comment"><p>(2) I would clarify to the reader what is meant by normal range of thermal pain and why is this relevant. Also, I did not find data about this assessment nor about the assessment of facial expressiveness (or reference to where it can be found).</p></disp-quote><p>We changed this formulation to “All participants included in this study had normal thermal pain sensitivity” and we added a few references. By targeting a healthy population with normal thermal pain sensitivity, our study sought to identify a predictive brain pattern related to facial expression evoked by typical responses to pain that could eventually be generalised to other individuals from the same population. Details about the assessment of facial expressiveness have been added in the appropriate section in the Methods.</p><disp-quote content-type="editor-comment"><p>(3) That pain ratings are only weakly associated with facial responses is, in its own right, an interesting finding, as a naïve reader would expect the two to be highly positively correlated. I'd suggest discussing this aspect (in reference to previous research) as it is interesting on both theoretical and empirical grounds.</p></disp-quote><p>The likelihood and the strength of pain facial expression generally increase with pain ratings in response to acute noxious stimuli of increasing physical intensities, thereby leading to a positive association between the two responses that is driven by the stimulus. However, the poor correlation or the dissociation between facial pain expression and pain rating is a very well known phenomenon that can be demonstrated easily using experimental methods where the stimulus intensity is held constant and spontaneous fluctuations are observed in both facial expression and pain ratings. This result was not discussed in the current manuscript as it was already addressed in the work of Kunz et al. (2011) and Kunz, Karos and Vervoot (2018). We added the references to these studies in the revised manuscript (lines 330 to 334).</p><disp-quote content-type="editor-comment"><p>(4) It may be worth having CIs throughout the whole set of analyses.</p></disp-quote><p>Thanks for the suggestions, this was an oversight. The confidence intervals have been added in the manuscript where applicable.</p><disp-quote content-type="editor-comment"><p>(5) I would clarify if there are two measures of the brain signature: dot-product and activation map. Relatedly, I cannot find where the authors explained what &quot;FEPS pattern expression scores&quot;. Can the authors please clarify?</p></disp-quote><p>The clarification has been added in the manuscript (lines 413 to 414).</p><disp-quote content-type="editor-comment"><p>(6) There seems to be the assumption that the relationship between pain-relevant brain signatures and facial expressions of pain would be parametric and linear. However, this might not hold true. Did the authors test these assumptions?</p></disp-quote><p>We indeed decided to use a linear regression technique (i.e. LASSO regression) to model the association between the brain activity and the facial expression of pain. The algorithm choice was mainly based on the simplicity and the interpretability of that approach, and our limited number of observations. The choice was also coherent with previous studies in the domain (e.g. Wager et al., 2011; Wager et al., 2013; Krishnan et al. 2016; Woo et al., 2017). Using a linear model, we were able to predict above chance level the facial expression evoked by pain using the fMRI activation. However, it is legitimate to think that more complex non linear models can better capture the brain patterns predictive of that behavioural manifestation of pain.</p><disp-quote content-type="editor-comment"><p>(7) Did the authors assess whether the FACS were better to be transformed/normalised? More generally, I would report any data assessment/transformation that has not been reported.</p></disp-quote><p>Thank you for this highly relevant suggestion. FACS scores were indeed not normally distributed and the analyses were conducted again to predict the log transformed FACS scores. This transformation was effective to normalize the distribution (skewness = 0.75, kurtosis = -0.84). The predictive model was confirmed on transformed data.</p><disp-quote content-type="editor-comment"><p>(8) Page 12: I am not clear on whether all the signatures are included in the same model (like a multiple regression) or if separate regressions are calculated per signature. The authors seem to imply that several regressions have been computed (possibly one per comparison with each signature?).</p></disp-quote><p>The correlation between the FACS scores and the pain-related signatures was computed separately for each signature. This information has been clarified.</p><disp-quote content-type="editor-comment"><p>(9) MVPA: See my main comment about warm trials and experimental/statistical design. For example, the LASSO regression model for the pain trials could be compared with a model using warm trials besides (or instead of) the unfitted model. Otherwise, add the warm trials as another predictor or within the subject level in a dummy fixed factor comprising pain and warm trials.</p></disp-quote><p>The inclusion of warm trials in the model training would be inconsistent with the goal of the main analysis to predict the facial expression of pain when a noxious pain stimulus is presented. Secondary analyses were conducted to compare the response of the FEPS to the warm trials compared to noxious pain trials. The dot product between the FEPS and the activation maps (FEPS scores) associated with the warm condition was computed. A linear mixed model was conducted to investigate the association between FEPS scores and the experimental condition (warm vs pain). Additional contrasts compared the warm trials with the pain trials with and without pain facial expression. The details of this analysis have been added to the manuscript (see Response of the FEPS to pain and warm in the Methods) as well as the corresponding results (see Results and Discussion).</p><disp-quote content-type="editor-comment"><p>(10) I would clarify for the reader why the separate M1 analysis has been run. Although obvious, I feel the reader would benefit from the specific hypothesis about this control analysis being spelled out together with the other statistical hypotheses within the statistical design in a more streamlined manner.</p></disp-quote><p>We extended the discussion on the rationale of that analysis and its interpretation taking into account the most recent results using the log transformed FACS scores (lines 125 to 133).</p><disp-quote content-type="editor-comment"><p>(11) The mixed model aimed to assess the relationship between pain ratings FEPS scores and facial scores is a crucial finding. I believe it speaks to the importance of a more complete design, which I already highlighted. I have a couple of technical questions: did the authors assess random slopes too? And, what was the strategy used to determine the random effects structure?</p></disp-quote><p>The linear mixed model considered the participants as a random effect, with random intercepts, considering the grouping structure in our data (i.e., each participant completed multiple trials). The reported results in the original manuscript were considering fixed slopes. However, following the reviewer’s comment, we re-computed the mixed linear models allowing the slopes to vary according to the intensity ratings. The results were changed in the manuscript to represent the output of those models.</p><disp-quote content-type="editor-comment"><p>(12) The text from lines 63 to 67 could go in the methods.</p></disp-quote><p>We decided to include those lines within the Result and Discussion section to give the reader more specification about the FACS scores, as this term is subsequently referenced in the following part of the Results and Discussion section. We are concerned that putting this information only in the Methods section would disrupt the reading.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>p. 4-5. When you report the positive weight clusters, you follow up with a sentence specifying which cognitive processes those brain regions are typically associated with. However, when you report the negative weight clusters, you do not specify the cognitive processes typically associated with those brain areas. I think that providing that information would be helpful to the readers.</p></disp-quote><p>Thanks for noticing this omission. The information has been added in the most recent version of the manuscript (lines 119 to 121).</p><disp-quote content-type="editor-comment"><p>p. 9. You specify that the degree of expressiveness of participants was evaluated. How did you evaluate expressiveness? Did you use this variable in your analyses? Were participants excluded based on their degree of expressiveness?</p></disp-quote><p>Details about the assessment of facial expressiveness have been added in the appropriate section in the Methods (lines 285 to 289).</p><disp-quote content-type="editor-comment"><p>p. 10. You explain that two certified FACS-coders evaluated the video recordings to rate the frequency of AUs. Could you please provide more details about the frequency measure? I think that there are different ways in which this could have been done. For instance, were the videos decomposed into frames, and then the frequency measured by summing the number of frames in which the AU occurred? Or was it &quot;expression-based&quot;, so one occurrence of an AU (frequency of 1) would correspond to the whole period between its activation onset and offset? Both ways have pros and cons. For example, if the frequency represents the number of frames, then it controls for the total duration of the AU activation within a trial (pro); but if there were multiple activations/deactivations of the AU within one trial, this will not be controlled for (con). And vice-versa with the second way of calculating frequency.</p></disp-quote><p>Details about the frequency scores have been added to the manuscript (lines 315 to 319).</p><disp-quote content-type="editor-comment"><p>p. 11. When you explained how you calculated the association between the facial expression of pain and pain-related brain signatures, I felt that there was some information missing. Did you use the thresholded maps (available in the published articles), or did you somehow have access to the complete, voxel-by-voxel, raw regression coefficient maps?</p></disp-quote><p>The unthresholded maps were used. The information has been clarified in the latest version of the manuscript, as well as the details about the availability of the maps (see Data Availability section at the end of the manuscript).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>Format</p><p>The authors will notice that many observations about the manuscript are related to missing information and a lack of graphical representations. I believe the topic and the content of the manuscript are too complex to condense into a short report.</p><p>Title</p><p>The claim of the title is simply not substantiated by the content of the manuscript. Demonstrating that the FEPS is a distinctive (i.e., specific) marker of pain processing requires a substantially different experimental design, with more rigorous controls and a broader set of painful stimulations. The manuscript would benefit from a more accurate title.</p><p>We agree that the title could better align with our findings. We modified the title accordingly : “A distributed brain response predicting the facial expression of acute nociceptive pain”.</p><p>Abstract</p><p>I find it puzzling that the authors claim that there is limited knowledge of the neural correlates of facial expression of pain given what they describe in the first paragraph of the introduction. Besides, they propose to reanalyze a dataset that has been extensively described in Kunz et al. (2011), which is unlikely to provide any new significant information.</p></disp-quote><p>We respectfully disagree with that comment. We considered that three articles (i.e., Kunz et al., 2011; Vachon-presseau et al., 2016; Kunz, Chen and Rainville, 2020) on the topic do constitute limited knowledge, especially if we compare it to the very large body of literature on the neural correlates associated with pain ratings. Except for these three studies, all the other citations pertain to behavioral studies on facial expression of pain, and do not examine the brain activity related to it. Furthermore, we believe that the complementary nature of the analyses performed in Kunz et al. (2011) and in this manuscript offers new insights into our understanding of facial expression in the context of pain. Indeed, the multivariate approach used in this study addresses some limitations present in Kunz et al. (2011) univariate analyses, mainly that it provides a quantifiable way to compare the similarity between different predictive patterns <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">(Reddan</ext-link> <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">and</ext-link> <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">Wager,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">2017</ext-link>). We submit that the assessment of the FEPS against several other pain-relevant signatures provides new and important information.</p><disp-quote content-type="editor-comment"><p>Furthermore, the abstract does not clearly state the aim, and the first line of the results does not match what the authors claim in the preceding line. The take-home message (last sentence) introduces the concept of a biomarker, which, as stated before, cannot be validated with the current data/experimental design. To put it in plain words, a given facial expression (or a composite score derived from a combination of expressions) cannot be a specific biomarker for pain, because a person can always mimic the same expression without feeling pain. Whether a given facial expression can be predicted from brain activity is a different issue, and whether that prediction can differentiate between painful and non-painful origins of the facial expression is another different issue. Unfortunately, neither of those issues can be tested with the current data/experimental design. The abstract would improve if the authors would circumscribe to what they actually tested, which is accurately described in the last sentence of the Introduction.</p></disp-quote><p>The abstract was revised accordingly. The term ‘biomarker’ was used in accordance with preceding studies in the field (see <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">Reddan</ext-link> <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">and</ext-link> <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">Wager,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s12264-017-0150-1">2017</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41591-020-1142-7#Abs1">Lee</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41591-020-1142-7#Abs1">et</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41591-020-1142-7#Abs1">al.,</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41591-020-1142-7#Abs1">2021</ext-link>). Please note that we applied the same reasoning to fluctuations in pain expression as previous studies have applied to pain ratings. Of course, we can not dismiss the possibility of someone mimicking facial expressions. Similar reasoning applies to subjective reports, as individuals can intentionally overestimate their pain experience conveyed through verbal reports. This is another case of specificity testing that cannot be addressed in the present study (see new conclusion of the abstract and discussion of limitations). The challenge of pain assessment is a classical problem within both the scientific and the clinical literature. Here, we suggest that the consideration of multiple manifestations of pain is necessary to address this challenge and will provide a more comprehensive portrait of pain-related brain function.</p><disp-quote content-type="editor-comment"><p>Introduction</p><p>I believe that the Introduction would benefit from a strict definition of what is a marker/biomarker/neuromarkers (all those terms are used in the manuscript) and what are its desirable features (validity, reliability, specificity, etc.). I also believe that the Introduction (and the rest of the text) would benefit from a critical assessment of the term &quot;signature&quot;. The Introduction describes four existing &quot;signatures&quot;, all of them differing in the experimental condition in which acute nociceptive pain is studied, and proposes a fifth one. Keeping with the analogy, I'm wondering whether they should be called (pain) &quot;signatures&quot; if there is a different one for each experimental acute pain condition, and they are so dissimilar between them when they are tested on the same condition (this dataset).</p></disp-quote><p>The last part of that comment raises fundamental methodological potential limitations that should be addressed in more depth in another article. That point goes beyond the scope of a research article. Regarding the stability aspect of the signatures, most of the signatures have not been studied extensively. It is thus difficult to currently assess their reliability. However, Han et al. (2022) showed high within-individual test-retest reliability for the NPS across eight different studies. Given that pain is a multidimensional experience, it is not surprising to find different patterns of activation predictive of different aspects or dimensions of the pain experience (see Čeko et al., 2022 for a similar discussion applied to negative affect).</p><disp-quote content-type="editor-comment"><p>The authors state that &quot;As an automatic behavioral manifestation, pain facial expression might be an indicator of activity in nociceptive systems, perceptual and evaluative processes, or general negative affect.&quot; Doesn't it reflect all three of them? (and instead of or?) Why &quot;might&quot;?</p></disp-quote><p>The original sentence has been modified as follows: “As an automatic behavioral manifestation, pain facial expression is considered to be an indicator of activity in nociceptive systems, and to reflect perceptual and affective-evaluative processes” (lines 65 to 67).</p><disp-quote content-type="editor-comment"><p>Methods</p><p>The pain scale should be described. Kunz et al. used a 0-100 scale, where 50 was the pain threshold. This is crucial to interpret the 75-80/100 score for the painful thermal intensity.</p></disp-quote><p>The description of the pain scale has been added to the manuscript (lines 299 to 300).</p><disp-quote content-type="editor-comment"><p>Ratings for warm and painful temperatures should be reported (ideally plotted with individual-trial/subject data). In the same line of reasoning, FACS scores should be reported as well (ideally plotted with individual-trial/subject data). It would be interesting to explore the across-trial variability of pain ratings and FACS scores. That is, do people keep giving the same ratings and making the same facial expression after 16 trials? How much variability is between trials and between subjects?</p></disp-quote><p>The point raised in that comment was already addressed in response to a comment made by Reviewer #1 (also see the new Figures S2 and S4; see also lines 335 to 346).</p><disp-quote content-type="editor-comment"><p>How come only painful trials are analyzed? What if the FEPS signature was the same for warm and painful stimulation, thus reflecting the settings (fMRI experiment, stimulation, etc.) rather than the brain response to the stimuli?</p></disp-quote><p>The point raised in that comment was already addressed in response to a comment made by Reviewer #1. There was no pain expression in the warm trials and the FEPS shows no response to warm trials. This is now illustrated in the new Figure S4B (see also lines 138 to 158).</p><disp-quote content-type="editor-comment"><p>The authors propose to predict the trial-by-trial FACS composite score from the pain ratings using a LMM. However, it is interesting that they aim for an almost constant within- and between-subject pain score (75-80/100) as stated in the Methods. This should theoretically render the linear model invalid since its first (and main) assumption would be that FACS should vary linearly with the pain score. Even if patients were not aware that the temperatures were constant across trials, the variation in pain scores should be explained by random noise for a constant stimulation intensity.</p></disp-quote><p>Reviewer #3 raises an important point that we need to clarify. Contrary to the expectation that FACS responses should be strongly correlated to pain ratings, we posited that these response channels depend at least in part on separate brain networks that may be differentially sensitive to a variety of modulatory mechanisms (attention, emotion, expectancy, motor priming, social context, etc.). This implies that part of the variance in FACS is independent from pain ratings. We, therefore, consider what Reviewer #3 refers to as random noise to be relevant and meaningful fluctuations reflecting endogenous processes influencing one’s experience of pain and differentially affecting various output responses.</p><disp-quote content-type="editor-comment"><p>I noticed that fMRI data was analyzed with SPM5 in the original paper (Kunz et al., 2011) and with SPM8 in this manuscript. Was fMRI data re-processed for this manuscript? Were there any differences between the original analysis and this one that might induce changes in the interpretation of results?</p></disp-quote><p>The data were indeed re-processed using SPM8, which was the most recent version available when we started the analyses reported here. We used trial-by-trial activation maps for MVPA, which differs from what was used in the previous study (contrast maps at the level of the conditions, not the trials). We have no reason to believe that the different versions will change the message of this manuscript since those versions do not differ significantly in terms of the fMRI preprocessing pipeline (see SPM8 release notes; <ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm8/">https://www.fil.ion.ucl.ac.uk/spm/software/spm8/</ext-link>). Furthermore, the aim of this present study is not to compare the different analysis parameters implemented in SPM5 vs SPM8.</p><disp-quote content-type="editor-comment"><p>What is the rationale for including PVP in the comparison among signatures? The experimental settings in which it was devised are distant from those described here.</p></disp-quote><p>The inclusion of the PVP was aimed at enhancing our comparative analysis with the FEPS, as we sought to investigate the potential functional meaning of the FEPS. The PVP was developed to capture the aversive value of pain, a dimension that is conceptually proximal to the interpretation of the facial expression as a manifestation of the affective response to nociceptive pain.</p><disp-quote content-type="editor-comment"><p>The LASSO-PCR approach is, in my opinion, not a procedure for (brain) decoding in this context. It is accurately described in the section title as a method for multivariate pattern analysis, or as a variable selection and regularization method for a prediction model. Here, brain activity in specific areas related to pain processing can hardly be described as &quot;encoded&quot;, and the method just helps select those activations relevant for explaining a certain outcome (in this case, facial expressions).</p></disp-quote><p>We understand the point made by reviewer #3. The term brain decoding was changed for multivariate pattern analysis in the latest version of the manuscript.</p><disp-quote content-type="editor-comment"><p>Details are missing with regards to the dataset split into training, validation, and testing.</p></disp-quote><p>Details about the training and testing procedure were added in the manuscript (lines 383 to 385).</p><disp-quote content-type="editor-comment"><p>This might just be ignorance from me, so I apologize in advance, but what are &quot;contrast&quot; fMRI images? They are mentioned three times in the text but not really described. Are they the &quot;Pain &gt; Warm&quot; contrasts from the original paper?</p></disp-quote><p>We apologize for any confusion caused by the use of the term “contrast images” which suggests a direct comparison between two experimental conditions. We have replaced “contrast images” with “activation maps” to provide a more accurate description of the nature of the data used in the multivariate pattern analysis (lines 388 to 389).</p><disp-quote content-type="editor-comment"><p>In the &quot;Facial expression&quot; section, the authors run an LMM to test the association between pain ratings (response variable) and facial responses (explanatory variable). If I understand correctly, in the &quot;Multivariate pattern analysis&quot; section they test the association between facial composite scores (response variable) and pain ratings (explanatory variable), but they obtain different results.</p></disp-quote><p>The analyses were recomputed on the log transformed data, as mentioned previously in the response to reviewers 1-2. The first model (in the “Facial expression” section) used the log transformed FACS scores as a dependent variable, the pain ratings as the fixed effect, and the participants as the random effect. The results of that analysis suggested that the transformed facial expression scores were not significantly associated with the pain ratings (p = .07). The second model uses both the FEPS pattern expression scores and pain ratings as fixed effects to predict facial responses. This analysis showed the significant contribution of the FEPS to the prediction of FACS scores (p &lt; .001) and no significant effect of the pain ratings. However, a significant interaction was found (p = .03) suggesting that the prediction of the pain facial expression by the FEPS may vary with pain ratings (i.e. moderator effect). Those results have been clarified in the “Multivariate pattern analysis” section in the Methods (lines 416 to 426).</p><disp-quote content-type="editor-comment"><p>In this same section, what are &quot;FEPS pattern expression scores&quot;? They are used three times in the text, but I could not find their description.</p></disp-quote><p>The FEPS pattern expression scores correspond to the dot product between the trial-by-trial activation maps and the unthresholded FEPS signature. This information has been added to the manuscript (lines 413 to 414).</p><disp-quote content-type="editor-comment"><p>It would not be far-fetched to hypothesize that FACS scores could be predicted using solely activity from the motor cortex. The authors attempted to do this, but only with information from M1. Why did they not use the entire motor cortex, or better, regions of the motor cortex directly linked with the AUs described in the manuscript?</p></disp-quote><p>The selection of the primary motor area (M1) was based on the results found in Kunz et al. (2011). In this study, M1 showed the strongest correlation with facial expression of pain. There are numerous possibilities of combinations of multiple brain regions considering a variety of criteria based on distributed networks involved in motor, affective, or pain-related processes. We limited our exploration to the region with the strongest hypothesis due to practical feasibility concerns.</p><disp-quote content-type="editor-comment"><p>Results and Discussion</p><p>As a general recommendation, results should present individual data whenever possible. For example, the association between signatures and facial expression should be plotted using scatterplots.</p></disp-quote><p>We have added figures showing individual data when it was applicable (Figure S2; Figure S4).</p><disp-quote content-type="editor-comment"><p>The authors state that the LASSO-PCR model accounts for the facial responses to pain. I believe this is an overstatement, considering:</p><p>- A Pearson's r of 0.49 is usually considered low/weak correlation (moderate at best). In the same line, an R2 of 0.17 means that only 17% of the variance is explained by the model.</p></disp-quote><p>More nuanced interpretation of the results has been added to the discussion. A section has been added to highlight the limitations of the study.</p><disp-quote content-type="editor-comment"><p>- Figure 1 needs to display individual subject data and the ideal regression line.</p></disp-quote><p>The model was trained using a k-fold cross-validation procedure. The regression lines thus represent the model’s prediction for each one of the 10 folds (i.e. each fold is trained and tested on a different subset of the data). A scatter plot including the ideal regression line computed across all trials and subjects was added in supplementary material to illustrate the relation between the FACS scores and the FEPS pattern expression scores (Figure S4).</p><disp-quote content-type="editor-comment"><p>- Looking at Figure 1, it is clear that the model has an intercept different from zero. This means that when the FACS score was zero (i.e., volunteers did not make any distinguishable facial expression), the model predicted a score larger than zero. This is not discussed in the manuscript, and in simple terms, it means that there are brain activation patterns when no discernible facial expression is being made by the volunteers. In the original paper by Kunz et al., two groups of subjects were categorized, and one of them was a facially low- or non-expressive group (n=13). This fact is not even mentioned in the manuscript.</p></disp-quote><p>The categorization in the previous report (Kunz et al., 2012) was based on a pre-experimental session. All subjects were included in the current analysis. This is now indicated in the Methods (lines 287 to 289).</p><disp-quote content-type="editor-comment"><p>- On the other end of the range in Figure 1, differences between the FACS scores near the maximum range (40) are underestimated by 23 to 33 points! I guess that the RMSE is smaller (6-7 points), because many FACS scores are concentrated on the low end of the scale.</p></disp-quote><p>This is a very interesting comment. A section discussing the limits of the model to predict the lower and higher FACS scores has been added in the manuscript (lines 232 to 250).</p><disp-quote content-type="editor-comment"><p>It is of course acceptable to interpret the low similarity between signatures as a sign that each signature describes a different mechanism related to pain processing. However, I believe that a complete discussion should contemplate other competing hypotheses. Considering that all signatures were developed using a similar painful thermal stimulation protocol, it is reasonable to expect larger similarities between signatures. The fact that they are so dissimilar could be a reflection of model overfit, i.e., all these signatures are just fitted to these particular experimental protocols and data, and do not generalize to brain mechanisms of pain processing.</p></disp-quote><p>We appreciate the pertinent observation. We have included a limitations section in which we discussed, among other considerations, the possible overfitting of models and the necessity of pursuing generalizability studies (lines 225 to 268).</p></body></sub-article></article>