<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">12830</article-id><article-id pub-id-type="doi">10.7554/eLife.12830</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Perception as a closed-loop convergence process</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-5243"><name><surname>Ahissar</surname><given-names>Ehud</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1223-9767</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="other" rid="par-5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-46224"><name><surname>Assa</surname><given-names>Eldad</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Neurobiology</institution>, <institution>Weizmann Institute of Science</institution>, <addr-line><named-content content-type="city">Rehovot</named-content></addr-line>, <country>Israel</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kleinfeld</surname><given-names>David</given-names></name><role>Reviewing editor</role><aff id="aff2"><institution>University of California, San Diego</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>ehud.ahissar@weizmann.ac.il</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>09</day><month>05</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e12830</elocation-id><history><date date-type="received"><day>04</day><month>11</month><year>2015</year></date><date date-type="accepted"><day>08</day><month>05</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Ahissar et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Ahissar et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-12830-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.12830.001</object-id><p>Perception of external objects involves sensory acquisition via the relevant sensory organs. A widely-accepted assumption is that the sensory organ is the first station in a serial chain of processing circuits leading to an internal circuit in which a percept emerges. This open-loop scheme, in which the interaction between the sensory organ and the environment is not affected by its concurrent downstream neuronal processing, is strongly challenged by behavioral and anatomical data. We present here a hypothesis in which the perception of external objects is a closed-loop dynamical process encompassing loops that integrate the organism and its environment and converging towards organism-environment steady-states. We discuss the consistency of closed-loop perception (CLP) with empirical data and show that it can be synthesized in a robotic setup. Testable predictions are proposed for empirical distinction between open and closed loop schemes of perception.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.001">http://dx.doi.org/10.7554/eLife.12830.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.12830.002</object-id><title>eLife digest</title><p>How do we perceive the world around us? Today the dominant view in brain research is that sensory information flows from the environment to our eyes, fingers and other sense organs. The input then continues on to the brain, which generates a percept. This process is referred to as “open-loop perception” because information flows through the system predominantly in one direction: from the environment, to the sense organs, to the brain.</p><p>Open-loop perception struggles to account for a number of key phenomena. The first is that sensation is an active process. Our eyes and hands constantly move as we interact with the world, and these movements are controlled by the brain. According to Ahissar and Assa, a more accurate view of perception is that the brain triggers the movement of the sense organs, and thereby alters the sensory information that these organs receive. This information is relayed to the brain, triggering further movement of the sense organs and causing the cycle to repeat. Perception is therefore a “closed loop”: information flows between the environment, sense organs and brain in a continuous loop with no clear beginning or end.</p><p>Closed-loop perception appears more consistent with anatomy and with the fact that perception is typically an incremental process. Repeated encounters with an object enable a brain to refine its previous impressions of that object. This can be achieved more easily with a ‘circular’ closed-loop system than with a linear open-loop one. Ahissar and Assa show that closed-loop perception can explain many of the phenomena that open-loop perception struggles to account for. This is largely because closed-loop perception considers motion to be an essential part of perception, and not an artifact that must be corrected for.</p><p>The open- and closed-loop hypotheses should now be compared systematically. One approach would be to construct an artificial perceiver (or robot) based on each hypothesis and examine its behavior. Another would be to perform experiments in which the two hypotheses make opposing predictions. Paralyzing a sensory organ without affecting the flow of sensory information, for example, would impair perception according to the closed-loop hypothesis, but would have no effect according to the open-loop hypothesis.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.002">http://dx.doi.org/10.7554/eLife.12830.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>hypothesis</kwd><kwd>dynamic perception</kwd><kwd>direct perception</kwd><kwd>embodied cognition</kwd><kwd>invariant representation</kwd><kwd>active sensing</kwd><kwd>eye movements</kwd><kwd>whisking</kwd><kwd>predictions</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd><kwd>Mouse</kwd><kwd>Rat</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003977</institution-id><institution>Israel Science Foundation</institution></institution-wrap></funding-source><award-id>1127/14</award-id><principal-award-recipient><name><surname>Ahissar</surname><given-names>Ehud</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001742</institution-id><institution>United States-Israel Binational Science Foundation</institution></institution-wrap></funding-source><award-id>2011432</award-id><principal-award-recipient><name><surname>Ahissar</surname><given-names>Ehud</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution>The NSF-BSF Brain Research EAGER program</institution></institution-wrap></funding-source><award-id>2014906</award-id><principal-award-recipient><name><surname>Ahissar</surname><given-names>Ehud</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution>The Minerva Foundation funded by the Federal German Ministry for Education and Rsearch</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Ahissar</surname><given-names>Ehud</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution>The Israel Ministry of Defense</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Ahissar</surname><given-names>Ehud</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Perception is proposed to be a dynamic motor-sensory closed-loop process in which information flows through the environment and the brain in continuous loops, converging towards steady-state percepts.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Until the midst of the 20<sup>th</sup> century psychologists and psychophysicists viewed perception as a primarily active process: perception is what emerges when an organism equipped with a brain interacts with its environment (<xref ref-type="bibr" rid="bib87">James, 1890</xref>; <xref ref-type="bibr" rid="bib104">Koffka, 1935</xref>; <xref ref-type="bibr" rid="bib114">Mach, 1959</xref>; <xref ref-type="bibr" rid="bib122">Merleau-Ponty, 1962</xref>; <xref ref-type="bibr" rid="bib173">Uexkull, 1926</xref>). Indeed, behavioral studies revealed that although mammals can perceive events or objects while being passive, most of the time mammalian individuals seek for objects and perceive the world via active body and sensor movements (<xref ref-type="bibr" rid="bib2">Ahissar and Arieli, 2001</xref>; <xref ref-type="bibr" rid="bib48">Diamond et al., 2008</xref>; <xref ref-type="bibr" rid="bib56">Findlay and Gilchrist, 2003</xref>; <xref ref-type="bibr" rid="bib75">Halpern, 1983</xref>; <xref ref-type="bibr" rid="bib99">Kleinfeld et al., 2006</xref>; <xref ref-type="bibr" rid="bib105">Konig and Luksch, 1998</xref>; <xref ref-type="bibr" rid="bib109">Land, 2006</xref>; <xref ref-type="bibr" rid="bib111">Lederman and Klatzky, 1987</xref>; <xref ref-type="bibr" rid="bib126">Najemnik and Geisler, 2005</xref>; <xref ref-type="bibr" rid="bib157">Rucci et al., 2007</xref>; <xref ref-type="bibr" rid="bib161">Schroeder et al., 2010</xref>). Investigating perception at the neuronal level, however, proved to be extremely challenging and neuroscientists have adopted a series of reductionist methods in which various components of the process have been eliminated. One critical such component has been sensor motion – neuroscientists have been investing enormous efforts in precluding sensor movements as these movements, naturally, interfere with systematic characterizations of neuronal responses. This passive paradigm indeed yielded invaluable descriptions of neuronal circuits and pathways that can convey sensory information and suggested how these pathways might process sensory information. Crucially, however, passive paradigms cannot reveal how sensory information is actually processed during active perception (<xref ref-type="bibr" rid="bib2">Ahissar and Arieli, 2001</xref>; <xref ref-type="bibr" rid="bib52">Ennis et al., 2014</xref>; <xref ref-type="bibr" rid="bib117">Maravall and Diamond, 2014</xref>). For that, a unified analysis of the motor and sensory components engaging brains with their environments is required.</p><p>Experimental data are usually examined in light of, and reflect on, implicit or explicit hypotheses. One salient outcome of the passive reductionist approach has been the over emphasis of open-loop schemes of perception. The elimination of motor components from the experimental scheme yielded a parallel elimination of motor variables from the corresponding theoretical schemes, leaving models of perception as sensory-only open-loop schemes (e.g., <xref ref-type="bibr" rid="bib36">Connor and Johnson, 1992</xref>; <xref ref-type="bibr" rid="bib51">Edelman, 1993</xref>; <xref ref-type="bibr" rid="bib118">Marr, 1982</xref>; <xref ref-type="bibr" rid="bib141">Poggio and Serre, 2013</xref>). In agreement with previous suggestions (<xref ref-type="bibr" rid="bib2">Ahissar and Arieli, 2001</xref>; <xref ref-type="bibr" rid="bib45">Dewey, 1896</xref>; <xref ref-type="bibr" rid="bib58">Freeman, 2001</xref>; <xref ref-type="bibr" rid="bib96">Kelso, 1997</xref>; <xref ref-type="bibr" rid="bib145">Port and Van Gelder, 1995</xref>), we claim that such a reductionist paradigm should ultimately fail to elucidate neural mechanisms of natural perception. This is not to say that any reduction would fail, but to emphasize that an appropriate reductionist paradigm should leave the motor-object-sensory interactions intact. The current paper describes an attempt to bring the motor variables back to the theoretical modeling of perception, by proposing a motor-sensory closed-loop scheme for the perception of the external environment. The paper makes use of ideas previously developed in various dynamic theories (<xref ref-type="bibr" rid="bib10">Ahissar and Vaadia, 1990</xref>; <xref ref-type="bibr" rid="bib13">Ashby, 1952</xref>; <xref ref-type="bibr" rid="bib96">Kelso, 1997</xref>; <xref ref-type="bibr" rid="bib136">O'Regan and Noe, 2001</xref>; <xref ref-type="bibr" rid="bib145">Port and Van Gelder, 1995</xref>; <xref ref-type="bibr" rid="bib147">Powers, 1973</xref>; <xref ref-type="bibr" rid="bib182">Wiener, 1949</xref>) and, in general, refers to the perception of external objects as a process of acquiring information about presently-existing external objects, whether consciously or not. The paper addresses perceptual acquisition - mechanisms of perceptual reports and their interactions with perceptual acquisition are not addressed here. It is noted, however, that a comprehensive understanding of perception depends on the understanding of report mechanisms as well. For simplicity, the term “brain” is often used in this article in an extended form that includes the sensory organs and their affiliated nerves and muscles.</p><sec id="s1-1"><title>The open loop perception (OLP) doctrine</title><p>Closed loops are systems in which every signal eventually affects its source; open loops are systems in which signals cannot affect their sources. Clearly, brains contain closed-loops at all levels, some of which have been implicated in relation to perceptual processing (<xref ref-type="bibr" rid="bib5">Ahissar and Kleinfeld, 2003</xref>; <xref ref-type="bibr" rid="bib51">Edelman, 1993</xref>; <xref ref-type="bibr" rid="bib119">Martin, 2002</xref>; <xref ref-type="bibr" rid="bib143">Pollen, 1999</xref>). Yet, whether perceptual acquisition is considered an open-loop or closed-loop process does not depend on the existence of closed loops within the chain of processing, but on whether the entire chain of processing is closed (as a loop) or open. Thus, a perceptual process that starts at the sensory organ and ends somewhere in the brain, whether containing local loops or not, is termed here an open-loop perceptual (OLP) process (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), whereas a perceptual process that includes the sensory organ but has no starting nor ending point, is termed a closed-loop perceptual (CLP) process (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.12830.003</object-id><label>Figure 1.</label><caption><title>Possible perceptual schemes.</title><p>(<bold>A</bold>) An open-loop scheme (in the motor-sensory sense) – perception begins with an interaction (uni- or bi-directional) between the object and the sensory organ (an eye in this illustration) and ends somewhere in the brain where a relevant neuronal representation (NR) is formed. (<bold>B</bold>) A closed-loop scheme (in the motor-sensory sense) – perception is a circular process, with no starting or ending points, which contains the sensory organ.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.003">http://dx.doi.org/10.7554/eLife.12830.003</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-12830-fig1-v2.tif"/></fig></p><p>The OLP doctrine holds that external objects and features are perceived in an open-loop manner, in the motor-sensory sense (<xref ref-type="bibr" rid="bib15">Baars, 2002</xref>; <xref ref-type="bibr" rid="bib42">Dehaene et al., 1998</xref>; <xref ref-type="bibr" rid="bib82">Hochstein and Ahissar, 2002</xref>; <xref ref-type="bibr" rid="bib155">Riesenhuber and Poggio, 2000</xref>; <xref ref-type="bibr" rid="bib172">Tononi and Koch, 2008</xref>; <xref ref-type="bibr" rid="bib175">Ullman, 2007</xref>). Thus, for example, an apple activates retinal receptors, which in turn initiate a stream of activations in the brain, some of which may depend on internal loops, i.e., loops that do not include the sensory organ. An activity pattern that is repeatedly evoked in a given neuronal network in response to a presentation of the apple, and/or when such an apple is perceived, is often termed a neuronal correlate or neuronal representation (NR) of that apple. NRs are representations that are not necessarily consistent or unique, i.e., they may appear in only some of the cases in which the apple is presented or perceived, and may appear also when other objects are presented or perceived. If a specific NR is evoked in a given brain for each and every perceived appearance of the apple, is invariant to changes in internal and environmental conditions, and is unique to the apple, it can be termed “the” invariant representation (IvR) of the apple in that specific brain. Assuming OLP, IvRs should be invariant to the acquisition mode. Visual IvRs of the apple, for example, should be the same in passive and active acquisition modes, i.e., when the eye is stationary and the object moves or flashes (passive mode) and when the object is stationary and the eye moves (active mode).</p><p>The search of NRs that are also IvRs, during the last 6–7 decades, yielded several key findings. Among those is the characterization of NRs of various external features along the relevant sensory streams. For example, NRs of brief presentations of visual elements, such as dots and bars, were characterized among retinal, thalamic and cortical neurons (<xref ref-type="bibr" rid="bib77">Hartline, 1938</xref>; <xref ref-type="bibr" rid="bib85">Hubel and Wiesel, 1962</xref>). NRs of more complex visual patterns were characterized in various cortical areas (<xref ref-type="bibr" rid="bib38">Creutzfeldt and Nothdurft, 1978</xref>; <xref ref-type="bibr" rid="bib62">Fujita et al., 1992</xref>; <xref ref-type="bibr" rid="bib121">McMahon et al., 2014</xref>). Crucially, however, although partial invariance had been demonstrated for portions of the proposed NRs in some of the cases, none of these NRs was shown so far to be “the” IvR of a specific external object or feature, namely an NR that is (at least substantially) invariant to changes in the most relevant conditions of perception. Moreover, none of these studies provides information that can discriminate between OLP and alternative hypotheses. Consider, for example, studies exhibiting single neurons that increase their firing rate significantly and selectively for a given object (e.g., a face) out of several presented objects, and for several variations of that object (<xref ref-type="bibr" rid="bib121">McMahon et al., 2014</xref>; <xref ref-type="bibr" rid="bib150">Quiroga et al., 2005</xref>; <xref ref-type="bibr" rid="bib177">Viskontas et al., 2009</xref>). The critical factor here is that such a neuron cannot be considered as describing the IvR of that object, neither as describing a reliable projection of the IvR. Based on combinatorial considerations and response variations the assumption in such cases is that the elevated firing rate of such a neuron is a (tiny) component of the relevant NR, and not the NR itself. The question is, then, would the assumed NR be invariant to a sufficiently large portion of all relevant variations of object presentation and context. Given that these neurons are not completely invariant even to the limited sample of variations presented to them (as is evident from the substantial trial-by-trial variability of their responses) and their tiny contribution to the actual NR, it is impossible to infer the level of invariance of the actual NR out of the firing patterns measured from these neurons.</p><p>Studying the passive mode of sensation also revealed various forms of internal transformations between NRs, such as, for example, transformation from NRs of static dots to NRs of static bars (<xref ref-type="bibr" rid="bib84">Hubel, 1996</xref>; <xref ref-type="bibr" rid="bib154">Reid, 2001</xref>), from temporal-code based NRs to rate-code based NRs (<xref ref-type="bibr" rid="bib9">Ahissar et al., 2000</xref>) or from rate-code based NRs to temporal-code based NRs (<xref ref-type="bibr" rid="bib34">Cleland, 2010</xref>). Clearly, these mechanisms can function within both OLP and CLP schemes of perception. Passive-mode experiments were also instrumental in describing the minimal exposure times required for generating meaningful perceptual reports. Across a large set of stimuli it was found that, depending on practice, exposure times as short as a few tens of milliseconds already allow a categorization of the presented stimulus, at least in a binary manner. As will be shown below, these findings are consistent with both OLP and CLP schemes.</p></sec><sec id="s1-2"><title>Challenges to the OLP doctrine</title><p>As described above, the OLP doctrine allowed an invaluable characterization of various components of the perceptual systems of mammals, using a set of reductionist steps. In order to verify that these specific reductions of the perceptual process are scientifically valid, one has to reconstruct perception by combining back the individual identified components. Succeeding in doing so will not only validate the specific reductionist approaches used, but, more importantly, show that OLP can be considered as a valid (i.e., self-consistent) theory of perception. At this stage we can ask whether OLP is consistent with the data collected so far. We describe here several major findings that appear to be inconsistent with OLP and thus significantly challenge the validity of OLP as a mechanism for natural perception in mammals.</p><sec id="s1-2-1"><title>Sensation is normally active</title><p>Mammalian sensory organs usually acquire information via movements (<xref ref-type="bibr" rid="bib2">Ahissar and Arieli, 2001</xref>; <xref ref-type="bibr" rid="bib31">Chapin and Woodward, 1982</xref>; <xref ref-type="bibr" rid="bib48">Diamond et al., 2008</xref>; <xref ref-type="bibr" rid="bib99">Kleinfeld et al., 2006</xref>; <xref ref-type="bibr" rid="bib105">Konig and Luksch, 1998</xref>; <xref ref-type="bibr" rid="bib109">Land, 2006</xref>; <xref ref-type="bibr" rid="bib111">Lederman and Klatzky, 1987</xref>; <xref ref-type="bibr" rid="bib148">Prescott et al., 2011</xref>; <xref ref-type="bibr" rid="bib157">Rucci et al., 2007</xref>; <xref ref-type="bibr" rid="bib161">Schroeder et al., 2010</xref>). The strategies employed by sensory systems are often similar. Visual and tactile systems, for example, employ movements of sensory organs that contain two-dimensional arrays of receptors. The movements serve several functions. Larger movements (e.g., ocular saccades and head or arm movements) quickly move the array of receptors from one region of interest to another. Smaller (and slower) movements (e.g., fixational drifts and finger or vibrissal scanning) scan the region of interest at fine resolution (<xref ref-type="bibr" rid="bib2">Ahissar and Arieli, 2001</xref>). This move-dwell-move pattern is typical for perceptual exploration across a large range of temporal scales, from minutes to less than a second (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Olfaction and taste are probably as active as touch and vision (<xref ref-type="bibr" rid="bib75">Halpern, 1983</xref>; <xref ref-type="bibr" rid="bib97">Kepecs et al., 2006</xref>; <xref ref-type="bibr" rid="bib109">Mainland and Sobel, 2006</xref>; <xref ref-type="bibr" rid="bib181">Welker, 1964</xref>). The extent of action in hearing is less clear - while cochlear amplification is considered active (<xref ref-type="bibr" rid="bib41">Dallas, 1992</xref>; <xref ref-type="bibr" rid="bib132">Nin et al., 2012</xref>), whether auditory sensation is typically obtained via sensor activation is still not known (see <italic>Perceptual systems are organized as motor-sensory-motor (MSM) loops</italic> and <italic>Contrasting OLP and CLP – discriminatory testable predictions</italic> below). Cross-modal effects between body and sensor movements, which are not discussed in this paper, are likely to play a significant role in perception as well (<xref ref-type="bibr" rid="bib14">Ayaz et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Fonio et al., 2016</xref>; <xref ref-type="bibr" rid="bib71">Grion et al., 2016</xref>; <xref ref-type="bibr" rid="bib95">Keller et al., 2012</xref>; <xref ref-type="bibr" rid="bib125">Moore et al., 2013</xref>; <xref ref-type="bibr" rid="bib129">Niell and Stryker, 2010</xref>). During sensor scanning, activations of individual (e.g., photo- or mechano-) receptors are functions of the interactions between the moving sensor and the physical features of external objects (<xref ref-type="bibr" rid="bib3">Ahissar and Arieli, 2012</xref>; <xref ref-type="bibr" rid="bib10">Ahissar and Vaadia, 1990</xref>; <xref ref-type="bibr" rid="bib16">Bagdasarian et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Boubenec et al., 2012</xref>; <xref ref-type="bibr" rid="bib61">Friston, 2010</xref>; <xref ref-type="bibr" rid="bib2">Gamzu and Ahissar, 2001</xref>; <xref ref-type="bibr" rid="bib64">Gibson, 1962</xref>; <xref ref-type="bibr" rid="bib81">Hires et al., 2013</xref>; <xref ref-type="bibr" rid="bib83">Horev et al., 2011</xref>; <xref ref-type="bibr" rid="bib88">Jarvilehto, 1999</xref>; <xref ref-type="bibr" rid="bib107">Kuang et al., 2012</xref>; <xref ref-type="bibr" rid="bib109">Mainland and Sobel, 2006</xref>; <xref ref-type="bibr" rid="bib136">O'Regan and Noe, 2001</xref>; <xref ref-type="bibr" rid="bib139">Pammer et al., 2013</xref>; <xref ref-type="bibr" rid="bib151">Quist and Hartmann, 2012</xref>; <xref ref-type="bibr" rid="bib152">Quist et al., 2014</xref>; <xref ref-type="bibr" rid="bib158">Rucci and Victor, 2015</xref>; <xref ref-type="bibr" rid="bib159">Saig et al., 2012</xref>; <xref ref-type="bibr" rid="bib160">Saraf-Sinik et al., 2015</xref>; <xref ref-type="bibr" rid="bib164">Smear et al., 2011</xref>). These dependencies are termed here in general motor-sensory contingencies (MS-contingencies); they form one class of the sensorimotor contingencies described by O’Regan and Noe (<xref ref-type="bibr" rid="bib136">O'Regan and Noe, 2001</xref>).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.12830.004</object-id><label>Figure 2.</label><caption><title>Active sensing.</title><p>(<bold>A</bold>) Ocular scanning of a scene.The trajectory of a human subject’s gaze (of one eye) during free viewing of an image presented on a computer screen is depicted. “Drift” points to the slow eye movements scanning a region of interest during a fixational pause. “Saccade” points to a rapid saccadic eye movement moving the gaze from one fixational pause to another. Section duration: 60 s; sampling: 240 Hz. Courtesy of Moshe Fried and Amos Arieli. (<bold>B</bold>) Manual scanning of a surface. The trajectory of a human subject’s hand, while palpating a virtual surface with a varying density of elevated dots (black), is depicted. The surface was mimicked via a tactile computer mouse system (VTPlayer; VirTouch, Jerusalem) whose two 4x4 pin arrays, which were touched constantly with the index and middle fingers of the right hand, reflected the spatial details of the virtual surface according to mouse location. Section duration: 152 s; sampling: 125 Hz. Courtesy of Avraham Saig and Amos Arieli. (<bold>C</bold>) Facial scanning of an arena. The trajectory of the snout of a rat, exploring an arena using sniffing and touch, is depicted. Section duration: 828 s; sampling: 25 Hz. Courtesy of Ben Mitchinson, Chris J. Martin, Robyn A. Grant and Tony. J. Prescott; see (<xref ref-type="bibr" rid="bib124">Mitchinson et al., 2007</xref>). (<bold>D</bold>) Local vibrissal scanning. The trajectory of a point near the middle of whisker C1 of a rat, exploring a region of an arena, is depicted. All whiskers except row C were trimmed on both sides of the snout. Section duration: 1.5 s; sampling: 500 Hz. Courtesy of Tess Oram, Noy Barak and Dudi Deutsch. (<bold>E</bold>) Sensory granularity. Left, a sample of retinal photoreceptors array of the human foveal area (from <xref ref-type="bibr" rid="bib40">Curcio et al., 1987</xref>). Middle, a schematic illustration of the organization of one type of mechanoreceptor (rapidly adapting) under the skin of the human fingertip. Right, whiskers array: left, the array of whiskers across the right snout of a rat, courtesy of Sebastian Haidarliu; right, a schematic illustration of a whisker’s follicle containing hundreds of mechanoreceptors, courtesy of Satomi Ebara.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.004">http://dx.doi.org/10.7554/eLife.12830.004</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-12830-fig2-v2.tif"/></fig></p><p>The fact that mammalian sensation is active significantly challenges the OLP doctrine. First, it turns out that the common reductionist approach in which stimuli are flashed on passive sensory organs cannot be extended back to natural conditions. This is because in such experiments no information is obtained about the dependency of sensory signals on natural active interactions with the object, interactions that cannot be mimicked with passive sensors. In vibrissal touch, for example, a crucial sensory variable is the whisker curvature (<xref ref-type="bibr" rid="bib16">Bagdasarian et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Boubenec et al., 2012</xref>; <xref ref-type="bibr" rid="bib151">Quist and Hartmann, 2012</xref>), which cannot be physically mimicked with only external forces (<xref ref-type="bibr" rid="bib16">Bagdasarian et al., 2013</xref>). In vision, while the conditions accompanying an ocular drift can be mimicked, in principle, by drifting the entire visual field, the conditions accompanying ocular saccades cannot be mimicked with passive eyes. Ocular saccades are accompanied by peri-saccadic suppression during which, unlike with flashed stimuli, activity along the visual sensory pathway is significantly suppressed (<xref ref-type="bibr" rid="bib76">Hamker et al., 2011</xref>). Also, saccades are always ending with additional eye movements, such as overshoots, corrections and drifts, which are lacking in passive-eye experiments. In general, it seems that the conditions introduced when stimuli are flashed on passive sensors mimic a small set of naturally-occurring states such as lightning at night or a sudden wind blowing over the rat’s whiskers. It is thus not surprising that, when compared, the characteristics of NRs revealed with passive sensors are substantially different from those revealed with active sensors (e.g., <xref ref-type="bibr" rid="bib91">Kagan et al., 2002</xref>).</p><p>OLP assumes that the presentation of an object retrieves the NR that represents it, i.e., its neuronal IvR. When this assumption was tested computationally at the presence of simulated eye movements it was found that such a retrieval is possible with a very simple environment (one stimulus) and a limited number of possible NRs (two), in which case the knowledge of the statistics of sensor motion (e.g., eye movements) can provide unique, unambiguous solutions (<xref ref-type="bibr" rid="bib140">Pitkow et al., 2007</xref>). However, it is not clear if a similar mechanism can work with more crowded environments, even when the movement trajectory of the eye is tracked by the perceiver (<xref ref-type="bibr" rid="bib28">Burak et al., 2010</xref>). The major challenge with IvR retrieval in OLP, even when the sensor trajectory is known (e.g., <xref ref-type="bibr" rid="bib7">Ahissar et al., 2015a</xref>), is the instability of the sensory input. With spike-based representations and finite firing rates this instability is devastating – by the time required to construct a reliable representation the sensor may have already moved away and provide new inputs. With representations of fine visual details it had been shown that this is indeed the case (<xref ref-type="bibr" rid="bib3">Ahissar and Arieli, 2012</xref>).</p><p>The realization that the visual system codes external objects differently in passive and active modes sets another major challenge to OLP. This difference can be attributed to the fact that while a passive eye that is stimulated by a flashed image can only use spatial coding to represent the image, a moving eye can use both spatial and temporal coding schemes. In fact, the temporal code appears to be much more accurate, and of higher spatial resolution, than the spatial code (<xref ref-type="bibr" rid="bib3">Ahissar and Arieli, 2012</xref>; <xref ref-type="bibr" rid="bib17">Berry et al., 1997</xref>; <xref ref-type="bibr" rid="bib153">Reich et al., 1997</xref>). Thus an OLP theory assuming that the same IvR is retrieved with or without sensor motion must also assume that perception is based on the less accurate spatially-coded information and ignores (or corrects for) the more accurate temporally-coded information - clearly an inefficient strategy. As we will see below (in <italic>Contrasting OLP and CLP – discriminatory testable predictions</italic>), a more efficient OLP scheme, which is based on active sensing and can exploit its advantages, is also possible.</p></sec><sec id="s1-2-2"><title>Sensory signals convey ambiguous information</title><p>Sensory signals may often be ambiguous if processed without the motor signals that yielded them. One example is the curvature signal generated at the base of a whisker upon its contact with an object. The same curvature can be generated when contacting objects at different locations, an ambiguity that is resolved if the angle by which the whisker is rotated is taken into account (<xref ref-type="bibr" rid="bib16">Bagdasarian et al., 2013</xref>) (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Similarly, temporal delays between two whiskers or two photoreceptors code spatial offsets ambiguously if sensor velocity is not considered (<xref ref-type="bibr" rid="bib2">Ahissar and Arieli, 2001</xref>, <xref ref-type="bibr" rid="bib3">2012</xref>; <xref ref-type="bibr" rid="bib100">Knutsen and Ahissar, 2009</xref>). Consistently, in vivo recordings from the primate retina ruled out pure sensory processing, such as lateral inhibition, as a basis for edge detection while supporting motor-sensory processes involving eye movements (<xref ref-type="bibr" rid="bib52">Ennis et al., 2014</xref>). These pieces of evidence join a substantial list of evidence for the ambiguity of sensory signals and the unambiguity of MS-contingencies (<xref ref-type="bibr" rid="bib20">Bompas and O'Regan, 2006</xref>; <xref ref-type="bibr" rid="bib136">O'Regan and Noe, 2001</xref>). For vision this is further supported by a series of experiments and analyses indicating that retinal information depends on the nature and trajectory of miniature eye movements (<xref ref-type="bibr" rid="bib4">Ahissar et al., 2014</xref>; <xref ref-type="bibr" rid="bib102">Ko et al., 2010</xref>; <xref ref-type="bibr" rid="bib107">Kuang et al., 2012</xref>; <xref ref-type="bibr" rid="bib137">Olveczky et al., 2003</xref>; <xref ref-type="bibr" rid="bib157">Rucci et al., 2007</xref>; <xref ref-type="bibr" rid="bib166">Snodderly et al., 2001</xref>).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.12830.005</object-id><label>Figure 3.</label><caption><title>An example of MS-Contingency in vibrissal touch.</title><p>A schematic illustration of morphological coding of object location (<xref ref-type="bibr" rid="bib16">Bagdasarian et al., 2013</xref>) is depicted. The motor-sensory phase plane describes the combinations of values of a motor (θ<sub>p</sub>: push angle, maximal change in whisker angle from contact onset) and sensory (k, whisker base curvature) variables when a whisker actively contacts an object at various locations. The locations are defined by their coordinates in the horizontal plane (inset): three azimuth coordinates (L<sub>θ</sub> = [p1, p2, p3]) and three radial coordinates (L<sub>r</sub> = [60%, 75%, 90%] of whisker length) are depicted and coded by colors. Note that neither of the two variables provide unambiguous coding of object location by itself; for example, k around .02 mm<sup>-1</sup> codes for both ~[p2, 60%] and ~[p1, 90%]. In contrast, the contingency between the motor and sensory variables provides unique coding of both L<sub>r</sub> and L<sub>θ</sub> (see equations).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.005">http://dx.doi.org/10.7554/eLife.12830.005</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-12830-fig3-v2.tif"/></fig></p><p>Note that this challenge cannot be alleviated by adding efference copy information to open-loop perceptual processing – efference copies are not accurate enough to account for perceptual accuracy (<xref ref-type="bibr" rid="bib7">Ahissar et al., 2015a</xref>; <xref ref-type="bibr" rid="bib140">Pitkow et al., 2007</xref>; <xref ref-type="bibr" rid="bib163">Simony et al., 2008</xref>). For example, perception of object location in rats (<xref ref-type="bibr" rid="bib100">Knutsen and Ahissar, 2009</xref>) depends on the details of the motor trajectory at a resolution corresponding to movements induced by individual motor spikes (<xref ref-type="bibr" rid="bib79">Herfst and Brecht, 2008</xref>; <xref ref-type="bibr" rid="bib163">Simony et al., 2008</xref>), a resolution that is likely not available in internal efference copies (<xref ref-type="bibr" rid="bib54">Fee et al., 1997</xref>; <xref ref-type="bibr" rid="bib80">Hill et al., 2011</xref>). Similarly, the accuracy of visual efference copies is two orders of magnitude lower than the size of fine eye movements (<xref ref-type="bibr" rid="bib140">Pitkow et al., 2007</xref>).</p></sec><sec id="s1-2-3"><title>Perceptual systems are organized as motor-sensory-motor (MSM) loops</title><p>Sensory organs (eyes, hands, whiskers) are associated with muscles whose activations move the sensory organ and induce sensory signals (<xref ref-type="bibr" rid="bib163">Simony et al., 2008</xref>). The neuronal motor and sensory systems that are associated with a given sensory organ are connected via an intricate system of loops that does not allow an isolated operation of either (see illustration of the vibrissal system in <xref ref-type="fig" rid="fig4">Figure 4A</xref>). When motor efferents of a specific sensory organ are activated, sensory signals are inevitably generated (<xref ref-type="bibr" rid="bib78">Hentschke et al., 2006</xref>; <xref ref-type="bibr" rid="bib88">Jarvilehto, 1999</xref>; <xref ref-type="bibr" rid="bib90">Johansson and Flanagan, 2009</xref>; <xref ref-type="bibr" rid="bib95">Keller et al., 2012</xref>; <xref ref-type="bibr" rid="bib146">Poulet and Petersen, 2008</xref>) and when sensory signals are generated, motor efferents to the same sensory organ are naturally affected (<xref ref-type="bibr" rid="bib21">Bonneh et al., 2013</xref>; <xref ref-type="bibr" rid="bib65">Gilad et al., 2014</xref>; <xref ref-type="bibr" rid="bib102">Ko et al., 2010</xref>; <xref ref-type="bibr" rid="bib109">Mainland and Sobel, 2006</xref>; <xref ref-type="bibr" rid="bib128">Nguyen and Kleinfeld, 2005</xref>). One needs to anesthetize the brain, eliminate specific pathways, or prevent the movements of the relevant sensory organs in order to ‘open’ this motor-to-sensory-to-motor loop.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.12830.006</object-id><label>Figure 4.</label><caption><title>Anatomy and perceptual schemes of a sensory modality.</title><p>(<bold>A</bold>) Closed-loop motor-sensory-motor (MSM) connections of the vibrissal system.A schematic diagram of the most relevant connections, through which sensory activities feed motor circuits at various levels, is depicted; efference copies are not explicitly depicted. Oval circles indicate brain regions [BPN, brainstem premotor nuclei (arbitrarily divided into two oval circles); BG, basal ganglia; Cer, cerebellum; FN, facial nucleus; MCx, motor cortex; POm, posteromedial thalamic nucleus; RN, red nucleus; SC, superior colliculus; SI, primary somatosensory cortex; SII, secondary somatosensory cortex; TG, trigeminal ganglion; TN, trigeminal brainstem nuclei; VL, ventrolateral thalamic nucleus; VPM, ventroposteromedial thalamic nucleus; ZI, zona incerta]. Black curves connecting brain regions indicate anatomical connections. Arrows indicate the direction of information flow between brain regions. Connections not labeled with arrows are reciprocal (for more details see <xref ref-type="bibr" rid="bib23">Bosman et al., 2011</xref>; <xref ref-type="bibr" rid="bib48">Diamond et al., 2008</xref>; <xref ref-type="bibr" rid="bib99">Kleinfeld et al., 2006</xref>). Three examples of individual MSM-loops are illustrated by green (a brainstem loop), blue (a thalamic loop) and red (a cortical loop); the primary efferents (FN to muscles) and afferents (follicle to TN) may or may not be common to different pathways. Modified from (<xref ref-type="bibr" rid="bib6">Ahissar and Knutsen, 2008</xref>; <xref ref-type="bibr" rid="bib8">Ahissar et al., 2015b</xref>). Inset, top view of the head and whiskers of a rat performing a bilateral localization task. (<bold>B</bold>) An MSM-loop (left) activates and senses the same organ. Sensory-motor arcs (right), which sense one organ and activate another, are not discussed in this paper. (<bold>C</bold>) Inclusion in an MSM-loop. Re-afferent loops (green) are always closed and thus can be considered as constantly ‘perceiving’ their organs. Ex-afferent loops (magenta) are normally open (dotted). An ex-afferent loop is closed (solid) only when the sensory organ interacts with the object (right); neither object presence alone (left) nor sensor movement alone (middle) close the loop.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.006">http://dx.doi.org/10.7554/eLife.12830.006</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-12830-fig4-v2.tif"/></fig></p><p>Brain loops that include the relevant sensory organ for a given perception (<xref ref-type="bibr" rid="bib3">Ahissar and Arieli, 2012</xref>; <xref ref-type="bibr" rid="bib5">Ahissar and Kleinfeld, 2003</xref>; <xref ref-type="bibr" rid="bib10">Ahissar and Vaadia, 1990</xref>; <xref ref-type="bibr" rid="bib48">Diamond et al., 2008</xref>; <xref ref-type="bibr" rid="bib99">Kleinfeld et al., 2006</xref>; <xref ref-type="bibr" rid="bib159">Saig et al., 2012</xref>) are termed here motor-sensory-motor loops, or briefly <italic>MSM-loops</italic>. For example, vibrissal MSM-loops include loops running via brainstem stations, thalamic stations and cortical stations, all sharing the same sensory organ (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; colored arcs). Finger-touch MSM-loops include loops that are similar to those of the vibrissal system, running through homologous stations (<xref ref-type="bibr" rid="bib8">Ahissar et al., 2015b</xref>). Existing anatomical descriptions of Visual MSM-loops are less detailed, although it is known that they also follow a multi-pathway architecture (<xref ref-type="bibr" rid="bib19">Bishop, 1959</xref>; <xref ref-type="bibr" rid="bib29">Casagrande, 1994</xref>; <xref ref-type="bibr" rid="bib47">Diamond, 1983</xref>; <xref ref-type="bibr" rid="bib110">Lappe et al., 1999</xref>; <xref ref-type="bibr" rid="bib127">Nassi and Callaway, 2009</xref>; <xref ref-type="bibr" rid="bib180">Wang et al., 2007</xref>), with sensory information feeding back onto oculomotor pathways at virtually all brain levels (<xref ref-type="bibr" rid="bib46">Dhande and Huberman, 2014</xref>; <xref ref-type="bibr" rid="bib60">Fries et al., 1985</xref>; <xref ref-type="bibr" rid="bib72">Guillery, 2005</xref>; <xref ref-type="bibr" rid="bib73">Guillery and Sherman, 2002</xref>; <xref ref-type="bibr" rid="bib106">Krauzlis and Lisberger, 1991</xref>; <xref ref-type="bibr" rid="bib116">Malik et al., 2015</xref>). Likewise, sniffing and tasting are likely to be controlled via modality specific MSM-loops as well (<xref ref-type="bibr" rid="bib93">Kareken et al., 2004</xref>; <xref ref-type="bibr" rid="bib98">Kepecs et al., 2007</xref>; <xref ref-type="bibr" rid="bib125">Moore et al., 2013</xref>). As for the auditory system, relevant MSM-loops are likely those whose motor efferents activate the outer hair cells in the cochlea, which in turn change the tuning of the basilar membrane (<xref ref-type="bibr" rid="bib74">Guinan, 1996</xref>; <xref ref-type="bibr" rid="bib89">Jennings and Strickland, 2012</xref>), those which activate the muscles of the middle ear (<xref ref-type="bibr" rid="bib103">Kobler et al., 1992</xref>) and those which control the direction of the pinnae. MSM-loops that control head movements can be shared by all cranial senses.</p><p>Throughout this paper, when we refer to MSM-loops we refer both to their anatomy and function. We use the term”motor-sensory-motor” instead of the common term “sensory-motor” in order to emphasize the fact that the loops that we refer to are those controlling a single sensory organ, and in which the flow of information is from the sensory organ to itself, via the brain. These loops should be distinguished from multi-modal sensory-motor loops, which include sensory-motor arcs that link different modalities (e.g., eye – hand or eye – whisker; <xref ref-type="fig" rid="fig4">Figure 4B</xref>) – these inter-modal loops and arcs are not addressed here.</p><p>The closed-loop architecture of the perceptual systems challenges the OLP doctrine. How would an open-loop mechanism emerge, and how would it function, in such a closed-loop system? In natural conditions every sensory activity will affect the movement of the sensory organ and evoke new sensory activations, assuming that the external object does not disappear after its first interaction with the brain. As loop cycle times are typically shorter than the typical perceptual epoch (e.g., <xref ref-type="bibr" rid="bib44">Deutsch et al., 2012</xref>), a sequence of such sensory activations is typically expected within each perceptual epoch (i.e., a period of continuous engagement with the object). How would this sequence of activations be ignored? And, more importantly perhaps, why would it be ignored? Moreover, it is known that increased stimulus exposure durations increase perceptual accuracy and confidence (<xref ref-type="bibr" rid="bib138">Packer and Williams, 1992</xref>; <xref ref-type="bibr" rid="bib159">Saig et al., 2012</xref>); if this is achieved in an open-loop manner, then it would mean that the brain does use those additional sensory signals, and “corrects for” the motion that evoked them using efference copy signals. Unfortunately, as mentioned above (in <italic>Sensory signals convey ambiguous information</italic>), efference copy signals are not accurate enough to account for fine perception.</p></sec><sec id="s1-2-4"><title>Perception can be masked “backwardly”</title><p>Although the loops are anatomically closed, they can be opened functionally. For example, projecting a flash of an image on the retina or skin, for a duration that is shorter than the duration of the minimal MSM-loop cycle, does not allow closure of the loop. When such a ‘virtual knife’ is used, the system is forced to function in an open-loop mode, regardless of its architecture. According to the OLP doctrine, this reductionist step does not interfere with the fundamental process underlying perception and thus the natural perceptual process can be reconstructed from such individual open-loop processes. However, backward masking, a robust perceptual phenomenon, challenges this assumption. The presentation of a second object within tens of milliseconds after the presentation of a target object prevents or impairs the perception of this target object (<xref ref-type="bibr" rid="bib53">Enns and Di Lollo, 2000</xref>). Such “backward in time” effect can occur in some open loop scenarios, for example if perception would depend on the integration of two processes, one fast and one slow, such that the fast process activated by the mask would interfere with the slow process activated by the target (<xref ref-type="bibr" rid="bib25">Breitmeyer and Ogmen, 2000</xref>). Experimental data, however, were found to be inconsistent with such open loop schemes, while supporting a dependency of perception on closed loop (“re-entrant”) mechanisms, in which the stimulus is repetitively sampled (<xref ref-type="bibr" rid="bib53">Enns and Di Lollo, 2000</xref>). The dependency on repetitive sampling strongly challenges the assumption that the ‘virtual knife’ does not interfere with the natural process of perception. Backward masking indicates that flashed stimuli allow, at best, an examination of the first step of a perceptual process, as explained below (see <italic>CLP propositions</italic>).</p></sec><sec id="s1-2-5"><title>Perception involves motor-sensory convergence</title><p>Perception takes time – typical perceptual epochs last hundreds of milliseconds. The first wave of sensory-driven neuronal activity typically reaches most of the relevant cortical areas within ~100 milliseconds, and quick saccadic reports on the crude category of the perceived item can be generated as fast as 150 milliseconds after stimulus onset (<xref ref-type="bibr" rid="bib184">Wu et al., 2014</xref>). Yet, the identification of more delicate categories and the perception of item details take typically hundreds of milliseconds from first sensor-object encounter, a period during which perceptual acuity continuously improves (<xref ref-type="bibr" rid="bib123">Micheyl et al., 2012</xref>; <xref ref-type="bibr" rid="bib138">Packer and Williams, 1992</xref>; <xref ref-type="bibr" rid="bib159">Saig et al., 2012</xref>). Consistently, scalp EEG recordings reveal that perceptual thresholds are correlated with neuronal activities that are recorded after the first transient neuronal response (<xref ref-type="bibr" rid="bib30">Censor et al., 2009</xref>).</p><p>Careful analyses of rodent and human behavior during tactile perception reveal signatures of a converging process. Object features, such as location and texture, are perceived via a sequence of sensor-object interactions whose motor and sensory variables show a pattern of convergence towards asymptotic values (<xref ref-type="bibr" rid="bib32">Chen et al., 2015</xref>; <xref ref-type="bibr" rid="bib83">Horev et al., 2011</xref>; <xref ref-type="bibr" rid="bib101">Knutsen et al., 2006</xref>; <xref ref-type="bibr" rid="bib120">McDermott et al., 2013</xref>; <xref ref-type="bibr" rid="bib159">Saig et al., 2012</xref>; <xref ref-type="bibr" rid="bib160">Saraf-Sinik et al., 2015</xref>; <xref ref-type="bibr" rid="bib178">Voigts et al., 2015</xref>). This behavior is consistent with previous descriptions of perception as a dynamic process (<xref ref-type="bibr" rid="bib10">Ahissar and Vaadia, 1990</xref>; <xref ref-type="bibr" rid="bib13">Ashby, 1952</xref>; <xref ref-type="bibr" rid="bib96">Kelso, 1997</xref>; <xref ref-type="bibr" rid="bib136">O'Regan and Noe, 2001</xref>; <xref ref-type="bibr" rid="bib145">Port and Van Gelder, 1995</xref>; <xref ref-type="bibr" rid="bib147">Powers, 1973</xref>; <xref ref-type="bibr" rid="bib182">Wiener, 1949</xref>), but not with an open-loop one. Converging dynamics, i.e., dynamics during which the state of the entire system gradually approaches a steady state, are hallmarks of closed-loops – an open-loop system does not converge as a whole. Thus, while the OLP doctrine could accept neuronal convergence in local circuits, it cannot account for perceptually-relevant MSM converging dynamics.</p></sec></sec></sec><sec id="s2"><title>Hypothesis and Results</title><sec id="s2-1"><title>The closed-loop perception (CLP) hypothesis</title><p>Here we propose a closed-loop scheme of perceptual acquisition, and suggest to refer to it as a possible alternative to the OLP doctrine. Within the scope of this paper we describe the acquisition of information about the organism’s immediate environment and do not address the interactions between perceptual acquisition and perceptual report. The CLP scheme is consistent with the same data challenging OLP, primarily because it considers sensor motion as an integral part of perception rather than as a factor that needs to be corrected for. We propose to continue comparing the two alternative schemes on equal grounds against accumulating data, and for aiding such a comparison we list potentially discriminative experiments towards the end of this article.</p><sec id="s2-1-1"><title>The CLP hypothesis is based on the following assumptions</title><list id="L1" list-type="roman-lower"><list-item><p>Sensation is normally active. Sensory organs obtain information about external objects via active interactions with the physical attributes of the object.</p></list-item><list-item><p>MSM-loops are fundamental units of mammalian perception. These loops, as every closed loop, can approach lag-less, steady states. During steady-states all changes in the loop are fully predictable and the loop functions as one unit, with no beginning or end and with no causal order; changes in one component of the loop cannot be considered as lagging or leading changes in any other component of the loop.</p></list-item><list-item><p>There are two basic types of MSM-loops (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, left). The first uses proprioceptive (re-afferent; <xref ref-type="fig" rid="fig4">Figure 4C</xref>, green) signals to monitor sensor state. Such loops are always closed; that is, information about the sensor state is always conveyed back to the rest of the loop. Importantly, these loops can also sense external features in a rough way (<xref ref-type="bibr" rid="bib18">Berryman et al., 2006</xref>), probably via sensing significant deviations between intended and actual sensor kinematics. The other type uses sensory signals to directly monitor features of external objects (ex-afferent; <xref ref-type="fig" rid="fig4">Figure 4C</xref>, magenta). The receptors of “ex-afferent loops”, i.e., loops that contain ex-afferents, do not respond to sensor movement per-se, but to sensor interactions with external objects. These loops remain open if no object exists in the external field scanned by the sensor. They will be closed (i.e., meaningful neuronal activity will flow along the loop) only through interactions of the sensory organ with specific external features to which their receptors are responsive. For example, whisker contacts with external objects activate a family of vibrissal mechanoreceptors that otherwise would remain silent (&quot;Touch cells&quot;) (<xref ref-type="bibr" rid="bib100">Knutsen and Ahissar, 2009</xref>; <xref ref-type="bibr" rid="bib169">Szwed et al., 2003</xref>) - the loops containing these neurons will be closed only through the interaction of whiskers with an external object present in the field of whisking (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Similarly, most photoreceptors are activated by luminance changes and thus would remain silent when the eye rotates against a uniform background. Visual ex-afferent MSM-loops are thus likely to be closed only via the existence of specific optical features in the visual field.</p></list-item></list></sec><sec id="s2-1-2"><title>CLP propositions</title><p>The following set of propositions is consistent with our assumptions and defines a hypothesis for perception.</p><list id="L2" list-type="roman-upper"><list-item><p><italic>Perception (of external feature(s)) ≡ a process of inclusion in MSM-loop(s)</italic>. During this process the entire MSM-loop, including its muscles, receptors and neurons, and with the external feature being included, converges towards a steady-state. Had the loop, with the external feature included, reached steady-state, that feature could be considered as been “directly perceived” by the loop, with no mediation and no delay. However, as such a steady-state is an idealized state in which nothing new is perceived, MSM-loops never reach the absolute steady-states. Rather, they rove dynamically between being perturbed (by external or internal processes) and approaching steady-states.</p></list-item></list><p>Our hypothesis thus asserts that a given percept is associated with a given steady-state of the motor-sensory-neuronal variables space. This steady-state can be referred to as the IvR of the relevant feature or object. The steady-states can be of various types: a fixed point in the motor-sensory-neuronal space, a closed trajectory within this space (limit-cycle) or a chaotic attractor. We name these attractors <italic>perceptual attractors</italic> (<xref ref-type="bibr" rid="bib58">Freeman, 2001</xref>; <xref ref-type="bibr" rid="bib96">Kelso, 1997</xref>; <xref ref-type="bibr" rid="bib145">Port and Van Gelder, 1995</xref>) since perceiving according to our hypothesis is equivalent to converging towards one such specific attractor in the relevant motor-sensory-neuronal space. A crucial aspect of such an attractor is that the dynamics leading to it encompass the entire relevant MSM-loop and thus depend on the function transferring sensor motion into receptors activation; this transfer function describes the perceived object or feature via its physical interactions with sensor motion. Thus, ‘memories’ stored in such perceptual attractors are stored in brain-world interactions, rather than in brain internal representations (see also <xref ref-type="bibr" rid="bib49">Dreyfus, 2002</xref>; <xref ref-type="bibr" rid="bib122">Merleau-Ponty, 1962</xref>; <xref ref-type="bibr" rid="bib135">O'Regan, 1992</xref>).</p><p>During the dynamic convergence process the state of the entire MSM-loop (with the external feature included) gradually approaches a steady-state. This can be illustrated by the dynamics of an internal variable, termed here “perceptual confidence” (<italic>C<sub>j</sub></italic>, where <italic>j</italic> indicates the perceived feature), whose maximal value is obtained at steady-state (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). <italic>C<sub>j</sub></italic> starts to build up upon the first interaction with the object and gradually increases towards the steady-state asymptote as additional interactions occur (see thalamo-cortical correlates of such a process in <xref ref-type="fig" rid="fig6">Figure 6</xref> of <xref ref-type="bibr" rid="bib186">Yu et al., 2015</xref>). This convergence process allows for partial perception (e.g., binary classification) to occur even with very brief presentations of external stimuli (<xref ref-type="bibr" rid="bib176">VanRullen and Thorpe, 2001</xref>) (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, red mark).</p><p>According to CLP, thus, artificially flashed stimuli initiate a perceptual process, and provide some perceptual information, but do not allow further accumulation of perceptual information as would normally occur with natural stationary objects (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). CLP thus predicts that, although the percepts evoked by flashed stimuli can be robust, they would typically include significantly less information than the information actively acquired from continuously-present objects during typical perceptual epochs. Within the CLP scheme, psychophysical data obtained with flashed stimuli are valuable for assessing the degree of convergence that can be reached upon a single interaction with the object, and its reportable resolution.</p><p>We leave the details of the generation of the confidence signal, <italic>C<sub>j</sub></italic>, outside the scope of this article. Yet, for the sake of clarity, we outline here one possible mechanism, which is based on internal models (<xref ref-type="bibr" rid="bib11">Anderson et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Gordon and Ahissar, 2012</xref>; <xref ref-type="bibr" rid="bib94">Kawato, 1999</xref>; <xref ref-type="bibr" rid="bib108">Lalazar and Vaadia, 2008</xref>; <xref ref-type="bibr" rid="bib130">Nijhawan and Kirschfeld, 2003</xref>; <xref ref-type="bibr" rid="bib183">Wolpert et al., 1998</xref>). Internal models implement simulations of the interactions of the brain with the external world, simulations that are tightly coupled to the actual interactions. A continuous comparison of the predictions of internal models with the signals resulting from the actual interactions can provide a measure of the deviation of the actual convergence process from an expected one - the closer the actual and simulated processes the higher the confidence. If internal models are also continuously updated along with the developing history of the organism, as usually assumed, they can provide a close estimation of <italic>C<sub>j</sub></italic>. Internal models are often hypothesized to be implemented via cerebro-cerebellar, basal-ganglia, or thalamo-cortical loops; in principle, internal models affiliated with different MSM-loops can be implemented via different brain areas or circuits. Furthermore, the internal models are likely active players in the operation of the MSM-loop and its convergence dynamics, which is consistent with reports of neuronal signals that are involved in both perceptual processing and perceptual confidence (<xref ref-type="bibr" rid="bib55">Fetsch et al., 2014</xref>).</p><p>The converging process is expected to end by another external perturbation, by reaching a certain level of <italic>C<sub>j</sub></italic> (as in bounded evidence accumulation, <xref ref-type="bibr" rid="bib162">Shadlen and Kiani, 2013</xref>), by the passage of a certain time interval or by an overriding or coordinated operation of another MSM-loop. The guiding principle of brain-object disengagement, when controlled by the brain, is likely to be based on information gain – when subsequent interactions are expected to provide relatively little relevant information, the brain would typically detach from the perceived feature or object and orient its MSM-loops towards other features or objects (<xref ref-type="bibr" rid="bib39">Creutzig et al., 2009</xref>; <xref ref-type="bibr" rid="bib83">Horev et al., 2011</xref>; <xref ref-type="bibr" rid="bib113">Little and Sommer, 2013</xref>; <xref ref-type="bibr" rid="bib142">Polani, 2009</xref>; <xref ref-type="bibr" rid="bib159">Saig et al., 2012</xref>). In principle, modeling of loop disengagement can follow the modeling of decision making dynamics (<xref ref-type="bibr" rid="bib67">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib162">Shadlen and Kiani, 2013</xref>) and dynamic perception (<xref ref-type="bibr" rid="bib96">Kelso, 1997</xref>), targeted to entire MSM-loops rather than to local circuits and assuming active, self-induced sampling of evidence.</p><list continued-from="L2" id="L3" list-type="roman-upper"><list-item><p><italic>Perception of an external object ≡ a coordinated process of inclusion in a collection of MSM-loops.</italic> An individual MSM-loop is assumed here to typically perceive an individual feature. An ‘object’ is a certain set of such features, proposed here to be a set that is delineated by a coordinated convergence process. As the dynamics of such multiple-loop convergence are beyond the scope of this article, we would only mention that they should depend on two major processes. One is a binding process in which the loops share information - one candidate vehicle for inter-loop binding is a link established by fast frequency oscillations (<xref ref-type="bibr" rid="bib59">Fries et al., 2007</xref>; <xref ref-type="bibr" rid="bib171">Tallon-Baudry and Bertrand, 1999</xref>), as they allow several inter-loop iterations per each motor-sensory-motor iteration. The second is a selection process (<xref ref-type="bibr" rid="bib86">Humphries et al., 2007</xref>; <xref ref-type="bibr" rid="bib149">Prescott et al., 2006</xref>) that determines the control over the sensory organ. This selection process is not unique to ‘within object’ loops – it should operate constantly, as naturally more than one MSM-loop is expected to be functional at any given time. We consider two, not mutually exclusive, major schemes of control selection. In one, every loop controls a sub-set of the muscle units attached to the sensory organ (e.g., <xref ref-type="bibr" rid="bib170">Takatoh et al., 2013</xref>). In the other, there is a dynamic selection of the MSM-loop(s) that control sensor-object interactions at any given moment. This process can be implemented by a variety of architectures, including subsumption-like (<xref ref-type="bibr" rid="bib26">Brooks, 1986</xref>), hierarchical curiosity (<xref ref-type="bibr" rid="bib3">Gordon and Ahissar, 2012</xref>; <xref ref-type="bibr" rid="bib69">Gordon et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">Gordon et al., 2014</xref>) and others (<xref ref-type="bibr" rid="bib12">Arkin, 1998</xref>). The binding between the loops is expected to break at the end of the perceptual epoch, upon the disengagement of one or more of the loops from their external features.</p></list-item></list><p>Hierarchical dynamics of MSM-loops can be illustrated by considering a visual scanning of an object or a scene or a tactile scanning of a surface (<xref ref-type="fig" rid="fig2">Figure 2</xref>). For example, when looking at an object or a scene the eyes saccade through a sequence of fixation areas, following a trajectory that is often termed “scanpath” (<xref ref-type="bibr" rid="bib102">Ko et al., 2010</xref>; <xref ref-type="bibr" rid="bib133">Noton and Stark, 1971</xref>; <xref ref-type="bibr" rid="bib179">Walker-Smith et al., 1977</xref>; <xref ref-type="bibr" rid="bib185">Yarbus, 1967</xref>), and drift around within each fixation area for several hundreds of milliseconds (<xref ref-type="bibr" rid="bib4">Ahissar et al., 2014</xref>; <xref ref-type="bibr" rid="bib157">Rucci et al., 2007</xref>; <xref ref-type="bibr" rid="bib167">Steinman and Levinson, 1990</xref>). The scanpath trajectory, which moves the visual gaze from one region of interest to another, is considered in our scheme to be part of converging dynamics in one level of MSM-loops, and the local drift scanning trajectories, which acquire local visual details (<xref ref-type="bibr" rid="bib52">Ennis et al., 2014</xref>), are considered to be parts of converging dynamics of MSM-loops at lower levels (<xref ref-type="bibr" rid="bib4">Ahissar et al., 2014</xref>). Moving on from a given fixation area depends on the <italic>C<sub>j</sub>s </italic>obtained at that area by the lower loops, on the perceptual dynamics of the scanpath loop, on variables of still higher loops depending on the context, task and brain state and on changes in the external object or scene.</p><list continued-from="L3" id="L4" list-type="roman-upper"><list-item><p><italic>Perceptual time is determined by the MSM-loop’s cycle time</italic>. Physical time is unlikely to have a neuronal metric, or ‘yardstick,’ enabling its direct measurement. In contrast, a yardstick that is available for each MSM-loop is its own cycle time, which can be sensed by each of its components. Durations of external events can be measured by the counts of such ‘ticks’ (<xref ref-type="bibr" rid="bib1">Ahissar, 1998</xref>). In this case, the resolution of perceptual time is the loop cycle time; events occurring within one cycle are considered simultaneous (<xref ref-type="bibr" rid="bib144">Poppel, 2004</xref>). A possible relationship between physical and perceptual times can be described using a helix metaphor (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). The helix should be considered flexible in its ‘perceptual axis’, being affected by the state of the perceiving loop. As changes in the loop’s cycle time can also be sensed by neurons (<xref ref-type="bibr" rid="bib1">Ahissar, 1998</xref>; <xref ref-type="bibr" rid="bib10">Ahissar and Vaadia, 1990</xref>; <xref ref-type="bibr" rid="bib27">Buonomano and Merzenich, 1995</xref>), online calibration between perceptual and physical time is possible to some extent. The assessment of physical time by an MSM-loop is predicted here to depend on the loop cycle time, which of course can change according to the perceptual scenario.</p></list-item></list></sec><sec id="s2-1-3"><title>Corollaries of the CLP hypothesis</title><p>Major corollaries of the CLP propositions are:</p><list id="L5" list-type="roman-lower"><list-item><p>An individual MSM-loop is the elemental unit of perception, namely is both necessary and sufficient for perception (of at least one external feature) to emerge in natural conditions. Thus, any reductionist study of perception must include at least one MSM-loop.</p></list-item><list-item><p>Nested MSM-loops can present different dynamics simultaneously. A higher-order loop can perceive (i.e., include) a scene at (close to) a steady-state, while lower-order loops dynamically rove along their perturbed – steady-state axis. Thus, an environment (e.g., a room) can be perceived in (close to) a “direct” manner by higher loops for the entire period in which its details are sequentially scanned by lower-order loops.</p></list-item><list-item><p>Perception is a continuous dynamic and interactive process and not a momentary event (<xref ref-type="bibr" rid="bib33">Cleeremans and Sarrazin, 2007</xref>; <xref ref-type="bibr" rid="bib50">Edelman and Tononi, 2001</xref>); during the perceptual process, a percept gradually emerges.</p></list-item><list-item><p>Perception is associated with changes in brain dynamics rather than with the construction of invariant internal representations. Given that sensor movements are never identical, and in fact vary significantly between perceptual epochs even when objects and contexts are constant (e.g., <xref ref-type="bibr" rid="bib101">Knutsen et al., 2006</xref>; <xref ref-type="bibr" rid="bib160">Saraf-Sinik et al., 2015</xref>), what remain invariant are the relationships between the variables of the entire MSM-loop(s)(see also <xref ref-type="bibr" rid="bib122">Merleau-Ponty, 1962</xref>; <xref ref-type="bibr" rid="bib136">O'Regan and Noe, 2001</xref>). Individual neuronal variables anywhere in the brain are unlikely to remain invariant (<xref ref-type="bibr" rid="bib156">Rokni et al., 2007</xref>).</p></list-item><list-item><p>Perceptual time is determined by the dynamics of the relevant MSM-loops and thus depends on the perceived environment. Also, within one loop cycle period, changes in external features and internal processes occur at different physical times but at the same perceptual time.</p></list-item><list-item><p>Perception is not necessarily conscious. The brain can perceive external features by loops that are not accessible, at that moment, to conscious report. Thus, conscious perception is defined here as one category of perception.</p></list-item></list><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.12830.007</object-id><label>Figure 5.</label><caption><title>CLP dynamics.</title><p>(<bold>A</bold>) The dynamics of perception of an individual feature by an individual MSM-loop follows a convergence pattern.The loop starts converging towards its steady-state (in which state perception is complete and “direct”) upon the first interaction with the object, whether active or passive (e.g., a flashed stimulus). The confidence of perceiving feature <italic>j (C<sub>j</sub></italic>) gradually increases during convergence. The loop may quit the process when <italic>C<sub>j</sub></italic> becomes larger than a certain internal threshold (<italic>C<sub>d</sub></italic>) or upon an internal or external perturbation. (<bold>B</bold>) The relationships between physical and perceptual time during CLP convergence are presented via a spiral metaphor, in which the physical time can be measured along the spiral, and the perceptual time can be measured across the spiral, e.g., by counting the number of activations of a given point along the loop. A steady-state can be reached at some point along the process.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.007">http://dx.doi.org/10.7554/eLife.12830.007</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-12830-fig5-v2.tif"/></fig></sec></sec><sec id="s2-2"><title>CLP mathematical framework and models</title><p>One natural choice of a mathematical framework for CLP is the framework of dynamical systems (<xref ref-type="bibr" rid="bib96">Kelso, 1997</xref>; <xref ref-type="bibr" rid="bib145">Port and Van Gelder, 1995</xref>). Within this framework each MSM-loop is modeled as a dynamical system that includes motor, sensory and neuronal variables, as well as the differential equations which describe their relations. The following is a general mathematical description of such a model (<xref ref-type="fig" rid="fig6">Figure 6A</xref>):<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The bars above the letters indicate that they represent a vector (of one variable or more). <italic>g</italic> and <italic>h</italic> are functions describing the intrinsic dynamics of the variables (<inline-formula><mml:math id="inf1"><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> respectively) and their dependency on the variables in the preceding stations of the loop (<inline-formula><mml:math id="inf3"><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf4"><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> respectively). The sensory variables (<inline-formula><mml:math id="inf5"><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>) do not depend on their intrinsic dynamics in this formalization, which assumes short sensory time constants; they are determined by the motor variables (<inline-formula><mml:math id="inf6"><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>) and the state of the environment (<italic>u</italic>), according to the function <italic>f</italic>. The function <italic>f</italic> encapsulates the physical laws governing the sensory organ-environment interactions and the transduction of physical signals to neuronal ones.</p><p>The state of the system is defined as the vector containing all the variables (<inline-formula><mml:math id="inf7"><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> <inline-formula><mml:math id="inf8"><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula>). Perception is achieved through the convergence of the system to a steady-state within this state-space. The information of the perceived feature is contained in the values of the dynamic variables (the system’s state) at this steady-state. High-level functions such as integration of the general context or a report mechanism are not included in this model of single-feature acquisition.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.12830.008</object-id><label>Figure 6.</label><caption><title>Synthesis of closed-loop perception in a robotic setup.</title><p>(<bold>A</bold>) A sketch of the MSM-loop model template.m, motor variable; SO, sensory organ; s, sensory variable; n, neuronal variable; h, f, g, transfer functions; u the environment dynamics. The arrows depict the direction of information flow within the loop. (<bold>B</bold>) The SYCLOP robotic platform. A sketch of the robot with its different components: Pan-Tilt control unit (PTCU, only the pan axis was used here) (1), DVS camera (2), and desktop computer (3). The computer sends commands to the PTCU which controls the camera’s rotations in the azimuth (θ) and elevation (ε) axes. The DVS camera sends visual ‘on’ and ‘off’ events to the computer. (<bold>C-F</bold>) Implementation of a specific contrast perceiving CLP model (see text). (<bold>C</bold>,<bold>D</bold>) n<sub>1</sub>, the integrated difference between ‘ON’ and ‘OFF’ events, and ω, sensor angular velocity along the pan axis, (C and D, respectively) as a function of time in two different runs of the CLP algorithm, one facing a contrast of 0.9 (red) and one facing a contrast of 0.5 (green). n<sub>1</sub> is scaled in units of 1000 events. (<bold>E</bold>) System’s trajectories in the 2D n<sub>1</sub>-ω state space. Same data as in C and D. (<bold>F</bold>) Example of emergent smooth-pursuit like behavior when using a moving edge as a stimulus. The trajectory of the system in the n<sub>1</sub>-ω plane (gray line) overlaid on a heat map where the color of each segment corresponds to the amount of time in seconds the system spent within this segment. The smooth pursuit periods are represented by the white and light red squares. While in a smooth pursuit, the camera was moving with a constant angular velocity – smoothly tracking the edge.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.008">http://dx.doi.org/10.7554/eLife.12830.008</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-12830-fig6-v2.tif"/></fig></p></sec><sec id="s2-3"><title>Synthesis of CLP in a robotic setup</title><p>One way to test such CLP models and demonstrate their basic behavior is to implement them using a synthetic agent. We built a simple robot for this purpose; the robot (SYCLOP: SYnthetic Closed-LOop Perceiver) includes two motors, one sensor and their bilateral connections (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). This platform allows the implementation of minimal MSM-loops based models (one motor DOF and one sensor). The SYCLOP uses a biomimetic camera (DVS128, iniLabs Ltd Zurich, Switzerland, <xref ref-type="bibr" rid="bib112">Lichtsteiner et al., 2008</xref>) as its sensor; this camera, like a retina, sends signals only upon luminance intensity changes. The camera is mounted on a pan-tilt control unit (PTU-46-17, DirectedPerception, CA, USA). The motor-to-sensory connection is implemented by moving the camera along the pan-tilt axes while the sensory-to-motor connection is implemented by a computer that implements the model's equations.</p><p>The SYCLOP platform was used, for example, to implement and test the behavior of a single MSM-loop model which was designed to perceive a visual contrast. The stimulus, in this case, was presented on a computer screen: half of the screen was kept dark and on the other half a uniform grayscale surface was displayed. The grayscale values ranged from dark to white. We defined two sensory variables r<sub>on</sub> and r<sub>off</sub> - the rate of ‘ON’ events (single-pixel events in which the luminance intensity increased) and the rate of ‘OFF’ events (single-pixel events in which the luminance intensity decreased) - integrated over the entire camera’s field. The characterization of the dependency of these two sensory variables on the chosen motor variable (sensor angular velocity along the pan axis, ω) and the external feature (contrast, γ) resulted in the following equation:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>γ</mml:mi><mml:mi>ω</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Where C<sub>1</sub> represents a constant and noise is ignored. The MSM-loop model is completed by the addition of two transfer functions that define two differential equations, sensory-to-neuronal (g) and neuronal-to-motor (h):<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>γ</mml:mi><mml:mi>ω</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr/><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>ω</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Where <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is defined as the (single) neuronal variable, which integrates the difference between r<sub>on</sub> and r<sub>off</sub> (<xref ref-type="bibr" rid="bib43">Demb and Singer, 2012</xref>), ω is the (single) motor variable defined as the sensor’s angular velocity and C<sub>2</sub>, C<sub>3</sub> and C<sub>4</sub> represent constants. The functions <italic>g</italic> and <italic>h</italic> were chosen such that the resulting dynamical system would be equivalent (up to constants multiplications, assuming all constants and parameters are positive) to a Van der Pol oscillator (<xref ref-type="bibr" rid="bib92">Kanamaru, 2007</xref>). This specific system was chosen due to its known dynamics: the system converges to a single closed trajectory within its 2D phase plane (i.e. a limit cycle) independently of the initial values of the variables. After convergence each of the dynamic variables is a periodic function of time (e.g., <xref ref-type="fig" rid="fig6">Figure 6C and D</xref>). Clearly, other dynamical systems could fit as well.</p><p>This model was implemented on the SYCLOP platform with the aid of a c program running on the computer incorporated in the platform (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, item 3). The program received the ON and OFF events from the DVS camera, computed the r<sub>on</sub> and r<sub>off</sub> sensory variables and used them to compute the values of <inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and ω by integrating the two differential equations described above. The value of ω was then sent by the program to the pan-tilt controller and modified the camera’s pan velocity. This implementation illustrates a simple CLP convergence process (<xref ref-type="fig" rid="fig5">Figure 5</xref>) and shows how different precepts can be differentiated in CLP. The convergence dynamics involves different dynamics of the sensory (r<sub>on</sub> and r<sub>off</sub>), neuronal (<inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig6">Figure 6C</xref>) and motor (<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig6">Figure 6D</xref>) variables. Yet, the variables are strongly linked, as demonstrated by the phase diagram of the neuronal and motor variables (<xref ref-type="fig" rid="fig6">Figure 6E</xref>); these two variables quickly converge to a limit cycle (i.e., a constant closed trajectory in the phase plane). Similar behavior is observed in the other phase planes (sensory-motor and sensory-neuronal, not shown). Importantly, in all these phase planes the limit cycle depends on the external contrast (γ); while maintaining all loop parameters constant, a monotonic change in γ results in a corresponding monotonic change of the limit cycle (green and red trajectories in <xref ref-type="fig" rid="fig6">Figure 6E</xref> for contrasts of 0.5 and 0.9, respectively). Hence, the image’s contrast can be inferred from the asymptotic behavior of the system or, in other words, the motor-sensory-neuronal trajectory that is uniquely associated with (or, equivalently, the CLP’s IvR of) a given contrast can be “retrieved” by the presentation of that contrast to the perceiver.</p><p>The behavior of the SYCLOP is described here in order to demonstrate how a possible implementation of our CLP model would look like. Interestingly, however, it is worth mentioning that the SYCLOP also exhibits behaviors that it was not intentionally designed to exhibit – for example, a smooth pursuit behavior. When presented with a moving image (back and forth horizontal movement of the contrast image at a constant speed) SYCLOP tended to track the image smoothly in each direction (as indicated by the “dwelling spots” at <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ω</mml:mi><mml:mo>≈</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; and <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> <xref ref-type="fig" rid="fig6">Figure 6F</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Summary of the CLP hypothesis</title><p>CLP suggests that perception of the external environment is a process in which the brain temporarily ‘<italic>grasps</italic>’ external objects and incorporates them in its MSM-loops. Such objects become virtual components of the relevant loops, hardly distinguishable, as long as they are perceived, from other components of the loop such as muscles, receptors and neurons. What primarily distinguishes external objects from body parts are inclusion duration and state; short and transient inclusions mark external objects while long and steady inclusions mark body parts (see also <xref ref-type="bibr" rid="bib173">Uexkull, 1926</xref>). Interestingly, the perceptual dynamics suggested by this hypothesis reconciles a conflict between objective scientific observations and the subjective everyday experience of perceiving objects with no mediation (see also <italic>A philosophical angle</italic> below). Everyday perception of a given external object, CLP suggests, is the dynamic process of inclusion of its features in MSM-loops. This process starts with a perturbation, internal or external, and gradually converges towards a complete inclusion - approaching, although never reaching, a state of “direct” perception. A laboratory-induced flashed stimulus, according to this model, probes the initiation of a perceptual process, whereas dreaming and imagining evoke internal components of the process.</p></sec><sec id="s3-2"><title>Contrasting OLP and CLP – discriminatory testable predictions</title><p>We consider here all versions of OLP, i.e., all versions of hypotheses in which perception does not depend on the integrity of the MSM-loop and its closed-loop dynamics within individual perceptual epochs. We consider here two major OLP classes: in one, sensory OLP (sOLP), the movement of the sensory organ is not an essential component of perception, and in the other, motor-sensory OLP (msOLP), it is (<xref ref-type="fig" rid="fig7">Figure 7</xref>). sOLP thus assumes that IvRs are confined to the brain (i.e., they are specific NRs) and can be fully retrieved by sensory activations alone when the sensor is passive. msOLP, in contrast, postulates that IvRs are not confined to the brain, and can form the basis for perception only if they include the relevant MS-contingencies (<xref ref-type="fig" rid="fig7">Figure 7</xref>). According to msOLP, IvRs cannot be retrieved with passive sensory organs. Importantly, however, msOLP does not assume a motor-sensory-motor loop; that is, its scheme includes a motor-to-sensory arc but not a sensory-to-motor arc (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Hence, with msOLP, movements of the sensory organ are predetermined for each perceptual epoch and are not affected by the ongoing sensory input during that epoch. In contrast to the OLP hypotheses, using the same representational terminology, CLP postulates that IvRs can form the basis for perception only if they contain the dynamics and state of the entire MSM-loop including the relevant features of the object (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Thus, the minimal set of variables that must be included in the IvR of each object, or feature, is different for each hypothesis (<xref ref-type="fig" rid="fig7">Figure 7</xref>, bluish ellipses): internal-only sensory variables in sOLP, internal sensory variables and MS-contingencies in msOLP and the entire perceiving loop in CLP.<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.12830.009</object-id><label>Figure 7.</label><caption><title>Functional connectivity and essential elements of perceptual schemes.</title><p>The essential elements in each scheme are indicated by solid curves and blue titles.MSM, motor-sensory-motor; MS, motor-sensory; S, sensory; NR, neuronal representation; green curves, re-afferent related pathways; magenta curves, ex-afferent related pathways. Note that re-afferent related pathways can form closed-loops with their sensory organs also in OLP schemes (dashed curves). Arrows indicate optional whisker (black) or object (magenta) movement; solid arrows indicate movements that are essential for perception; in the sOLP scheme none of the movements is essential in itself, but it is essential that at least one of them will occur in order to activate the receptors. Appropriate experimental paradigms are indicated by green titles; CLP and msOLP schemes can be studied only via active sensing paradigms.The minimal sets for invariant representations (IvRs) of external features, i.e., the components that must be included in any IvR according to each perceptual scheme, are marked by the bluish ellipses. sOLP: internal, sensory only NRs. msOLP: sensory NRs + motor-object-sensory contingencies. CLP: entire motor-object-sensory-motor loops.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.12830.009">http://dx.doi.org/10.7554/eLife.12830.009</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-12830-fig7-v2.tif"/></fig></p><p>Perhaps the first question that comes to mind when considering msOLP and CLP is whether paralyzed subjects perceive stationary (i.e., not flashing or moving) objects similarly to non-paralyzed subjects. If they do - here go the msOLP and CLP hypotheses. Unfortunately, however, this is not a trivial test. Note that the paralysis must include the relevant sensory organ and the object must be entirely stationary. In the case of touch it should be evident that while contacts may be detectable, no object perception is possible with paralyzed hands – we are not aware of any study contradicting this conjecture. In contrast, our intuition regarding hearing is that action is not a fundamental requirement for hearing. Yet, two important points are relevant here. First, our intuition may be misled by the fact that we cannot be aware of motor activation of the outer hair cells and the muscles of the middle ear – we are not aware of perceptual experiments in which these activations were blocked, or measured. Second, no stationary object exists in audition. Acoustic waves are always dynamic and always activate the inner hair cells. This makes auditory sensation less dependent on self-motion, a fact that indeed may put audition in a motor-sensory regime that is distinct from those of touch and vision.</p><p>Regarding vision, we are aware of only one study analysing visual perception in a congenital ophthalmoplegic patient, a patient who had no eye movements since birth; in this case, the patient developed a pattern of head movements that resembled that of natural eye movements, only on a slower rhythm (<xref ref-type="bibr" rid="bib66">Gilchrist et al., 1997</xref>). This adaptation clearly indicates the need in active sensation for visual perception, at least in that patient. Natural employment of active vision is indicated by the &quot;weird, confusing and indescribable&quot; forms of perceptions reported during acute partial paralysis of the ocular muscles (<xref ref-type="bibr" rid="bib168">Stevens et al., 1976</xref>). These data are certainly not consistent with sOLP. Yet, these data, as well as part of the OLP-challenging data presented above, may still be consistent with msOLP. The distinction between msOLP and CLP hypotheses is thus more demanding, and requires specifically designed experiments.</p><p>We describe here examples of potentially discriminative experiments in three categories.</p><list id="L6" list-type="order"><list-item><p><italic>The motor-to-sensory arc.</italic> The following manipulations are predicted to impair perception according to msOLP or CLP but not according to sOLP: (i) Paralysis of the sensory organ while keeping the sensory flow unimpaired. (ii) Replacing continuous presentation of an object with a series of one or more brief presentations (flashes) while keeping the total stimulus time and/or energy equal.</p></list-item><list-item><p><italic>The sensory-to-motor arc.</italic> The following manipulations are predicted to impair perception according to CLP but not according to sOLP or msOLP: (i) Limiting or forcing sensor movement trajectory via instructions in humans or interventions in rodents. For example, asking humans to scan a scene according to verbal instructions or by pursuing a target, or moving the sensory organ according to a trajectory that was recorded in a previous active session. (ii) Allowing active touch but with the motion of one hand determining the sensory flow to the other hand. (iii) Perturbing neuronal specific sensory-to-motor pathways, such as those connecting the sensory cortex to the motor cortex (<xref ref-type="bibr" rid="bib35">Colechio and Alloway, 2009</xref>), those connecting sensory cortex to motor nuclei (typically via layer 5B neurons), or those connecting the thalamus to motor (cortical and sub-cortical) stations (<xref ref-type="bibr" rid="bib165">Smith et al., 2012</xref>) (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). The exact design should depend on available genetic markers and the testing of these predictions should be conducted in a balanced way, using appropriate sham perturbations. The following observations are predicted by CLP but not by sOLP or msOLP during natural perception: (iv) The motion trajectories of the sensory organ will differ for different object features (expected from affective sensory-to-motor connections). (v) The motion of the sensory organ will depend on the concurrent sensory input; for example, when a rat perceives an object’s shape or texture, the movement trajectory of its whiskers will depend on the sequence of curvatures and stick-slip events preceding it within the same perceptual epoch. Similarly, the motion trajectory of the eye will depend on the retinal activations preceding it within the same perceptual epoch.</p></list-item><list-item><p><italic>Motor-sensory-motor convergence.</italic> The following observations are predicted by CLP but not by sOLP or msOLP: (i) The movement trajectory of the sensory organ will show convergence dynamics, i.e., gradual approach to a steady-state pattern, during natural perception. (ii) Convergence will be to different steady-state patterns while perceiving different features or values. (iii) Specific steady-state patterns will be associated with specific perceptual reports. (iv) Convergence dynamics can predict perceptual report timing and/or error. (v) A virtual object can be perceived when sensory neuronal activity is manipulated to mimic the activity expected by the movement of the sensory organ and the presence of a real object (<xref ref-type="bibr" rid="bib134">O'Connor et al., 2013</xref>); with reliable mimicry a convergence process should follow. (vi) CLP predicts that the lag between the actual and perceived times of an external transition (“perceptual lag”) should decrease along the process of perceptual convergence, when in steady-state no lag is expected. It has been previously shown that perceptual lags of the onset of transient stimuli are longer than those of continuously-present ones (<xref ref-type="bibr" rid="bib131">Nijhawan, 2001</xref>). CLP thus predicts that with similar experimental protocols (e.g., a rotating arm is shown continuously and a dot is transiently displayed (flashed) for various durations at various positions traversed by the rotating arm), when looking at the offset of the transient stimulus rather than its onset, the temporal perceptual lag of the offset will decrease with increasing transient durations. (vii) With a motion-induced-blindness (MIB) protocol, in which stationary targets are surrounded by moving background dots, the targets ‘disappear’ occasionally (<xref ref-type="bibr" rid="bib22">Bonneh et al., 2001</xref>). In one possible implementation of CLP the visual system would control the velocity of retinal image slip, and maintain it within a certain working range, instead of directly controlling drift velocity. This would be achieved by modifying drift speed in a manner that is inversely proportional to the speed of the retinal slip. When the retinal slip is dominated by external motion, such as in MIB, eye drift speed would be reduced significantly. When the drift speed will be reduced below a certain level, retinal receptors at corresponding eccentricities may not receive sufficient luminance changes to be activated by the stationary parts of the image. Thus, in MIB conditions in which the drift speed is inversely correlated with the dots’ speed, target disappearance is expected to be preceded by a reduction of the drift speed below a certain threshold; threshold level should depend on the eccentricity of the disappearing target.</p></list-item></list><p>Ideally, the comparison of the behaviors predicted by CLP and OLP, related to the inter-dependencies of motor, object, sensory and report variables, should be done in natural conditions. Practically, as the scientific method enforces reductionist steps, it is important to notice what reductions are allowed, as behavioral predictions of CLP or msOLP, regarding natural perception, cannot be tested in paradigms in which their basic assumptions are “reduced out.” Clearly, if eye or whisker motion is prevented, critical predictions of CLP or msOLP cannot be tested. Experiments in which eye or whisker motion is allowed but head motion is restrained have a limited discriminative power - conclusions in these cases should take into account the possibility that head-restrained animals develop unique compensatory active strategies which may not be indicative for the head-free condition. When MSM-loops are not given enough time to converge, as is the case with passive sensing (e.g., visual flashes) for example, discrimination between CLP and OLP is usually not possible (as both predict partial perception, <xref ref-type="fig" rid="fig5">Figure 5</xref>).</p></sec><sec id="s3-3"><title>A philosophical angle</title><p>For at least four centuries the philosophical community, and during the last century also the neuroscience community, have been puzzled by the contrast between objective scientific observations that relate to perception and the everyday subjective experience of perception. What feels direct and immediate to every human perceiver appears indirect and mediated when physical constrains are taken into account (<xref ref-type="bibr" rid="bib37">Crane, 2005</xref>; <xref ref-type="bibr" rid="bib96">Kelso, 1997</xref>; <xref ref-type="bibr" rid="bib145">Port and Van Gelder, 1995</xref>; <xref ref-type="bibr" rid="bib174">Ullman, 1980</xref>). Our CLP hypothesis proposes a reconciliation of objective scientific observations and subjective everyday experience via closed-loop dynamics between the perceiver and the perceived. Such closed-loops converge gradually to a state in which the perceiver and the perceived are inseparable. The idea is that, although the loops never actually reach an ideal steady-state, they get closer and closer to these states during a perceptual epoch and typically quit the convergence process when the distance from a steady state is barely sensible. Being close enough to the steady state can give rise to the feeling of direct and immediate perception.</p><p>In practical terms, this article proposes to open the discussion about the phenomenology and mechanisms of perception, and in particular to confront open- and closed-loop schemes. We hope that the set of predictions listed here will serve as a starting point for informative experimental confrontation.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Merav Ahissar, Amos Arieli, Asher Cohen, Coralie Ebert, Ram Frost, Andrei Gorea, Liron Gruber, Ealan Henis, Rafi Malach, Guy Nelinger, Tess Oram, Kevin O’Regan, Dov Sagi and Avi Saig for helpful comments and discussions and Michal Ahissar for linguistic editing. This work was supported by the Israel Science Foundation (grant #1127/14), the United States-Israel Bi-national Science Foundation (grant #2011432), the NSF-BSF Brain Research EAGER program, (grant #2014906), Israel Ministry of Defense and the Minerva Foundation funded by the Federal German Ministry for Education and Research. EA holds the Helen Diller Family Chair in Neurobiology.</p></ack><sec id="s4" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>EAh, Contributed to all aspects of this work</p></fn><fn fn-type="con" id="con2"><p>EAs, Contributed to all aspects of this work</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Temporal-code to rate-code conversion by neuronal phase-locked loops</article-title><source>Neural Computation</source><volume>10</volume><fpage>597</fpage><lpage>650</lpage><pub-id pub-id-type="doi">10.1162/089976698300017683</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Figuring space by time</article-title><source>Neuron</source><volume>32</volume><fpage>185</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00466-4</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Seeing via miniature eye movements: A dynamic hypothesis for vision</article-title><source>Frontiers in Computational Neuroscience</source><volume>6</volume><pub-id pub-id-type="doi">10.3389/fncom.2012.00089</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name><name><surname>Fried</surname><given-names>M</given-names></name><name><surname>Bonneh</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>On the possible roles of microsaccades and drifts in visual perception</article-title><source>Vision Research</source><volume>118</volume><pub-id pub-id-type="doi">10.1016/j.visres.2014.12.004</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Closed-loop neuronal computations: Focus on vibrissa somatosensation in rat</article-title><source>Cerebral Cortex </source><volume>13</volume><fpage>53</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1093/cercor/13.1.53</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Knutsen</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Object localization with whiskers</article-title><source>Biological Cybernetics</source><volume>98</volume><fpage>449</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0214-4</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Ozana</surname><given-names>S</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>1-D vision: Encoding of eye movements by simple receptive fields</article-title><source>Perception</source><volume>44</volume><fpage>986</fpage><lpage>994</lpage><pub-id pub-id-type="doi">10.1177/0301006615594946</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Shinde</surname><given-names>N</given-names></name><name><surname>Haidarliu</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Systems neuroscience of touch</article-title><source>Scholarpedia</source><volume>10</volume><fpage>32785</fpage><pub-id pub-id-type="doi">10.4249/scholarpedia.32785</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Sosnik</surname><given-names>R</given-names></name><name><surname>Haidarliu</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Transformation from temporal to rate coding in a somatosensory thalamocortical pathway</article-title><source>Nature</source><volume>406</volume><fpage>302</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1038/35018568</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Oscillatory activity of single units in a somatosensory cortex of an awake monkey and their possible role in texture analysis</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>87</volume><fpage>8935</fpage><lpage>8939</lpage><pub-id pub-id-type="doi">10.1073/pnas.87.22.8935</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>SR</given-names></name><name><surname>Porrill</surname><given-names>J</given-names></name><name><surname>Pearson</surname><given-names>MJ</given-names></name><name><surname>Pipe</surname><given-names>AG</given-names></name><name><surname>Prescott</surname><given-names>TJ</given-names></name><name><surname>Dean</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>An internal model architecture for novelty detection: Implications for cerebellar and collicular roles in sensory processing</article-title><source>PloS One</source><volume>7</volume><elocation-id>e44560</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0044560</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Arkin</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Behavior-Based Robotics</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ashby</surname><given-names>WR</given-names></name></person-group><year iso-8601-date="1952">1952</year><source>Design for a Brain</source><publisher-name>Chapman and Hall / Science Paperbacks</publisher-name></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayaz</surname><given-names>A</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Schölvinck</surname><given-names>ML</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Locomotion controls spatial integration in mouse visual cortex</article-title><source>Current Biology </source><volume>23</volume><fpage>890</fpage><lpage>894</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.04.012</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baars</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The conscious access hypothesis: Origins and recent evidence</article-title><source>Trends in Cognitive Sciences</source><volume>6</volume><fpage>47</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(00)01819-2</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagdasarian</surname><given-names>K</given-names></name><name><surname>Szwed</surname><given-names>M</given-names></name><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Deutsch</surname><given-names>D</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Pietr</surname><given-names>M</given-names></name><name><surname>Simony</surname><given-names>E</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Pre-neuronal morphological processing of object location by individual whiskers</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>622</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1038/nn.3378</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berry</surname><given-names>MJ</given-names></name><name><surname>Warland</surname><given-names>DK</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The structure and precision of retinal spike trains</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>94</volume><fpage>5411</fpage><lpage>5416</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.10.5411</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berryman</surname><given-names>LJ</given-names></name><name><surname>Yau</surname><given-names>JM</given-names></name><name><surname>Hsiao</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Representation of object size in the somatosensory system</article-title><source>Journal of Neurophysiology</source><volume>96</volume><fpage>27</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1152/jn.01190.2005</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>GH</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>The relation between nerve fiber size and sensory modality: Phylogenetic implications of the afferent innervation of cortex</article-title><source>The Journal of Nervous and Mental Disease</source><volume>128</volume><fpage>89</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1097/00005053-195902000-00001</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bompas</surname><given-names>A</given-names></name><name><surname>O'Regan</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Evidence for a role of action in colour perception</article-title><source>Perception</source><volume>35</volume><fpage>65</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1068/p5356</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonneh</surname><given-names>Y</given-names></name><name><surname>Adini</surname><given-names>Y</given-names></name><name><surname>Sagi</surname><given-names>D</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Fried</surname><given-names>M</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Microsaccade latency uncovers stimulus predictability: Faster and longer inhibition for unpredicted stimuli</article-title><source>Journal of Vision</source><volume>13</volume><fpage>1342</fpage><pub-id pub-id-type="doi">10.1167/13.9.1342</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonneh</surname><given-names>YS</given-names></name><name><surname>Cooperman</surname><given-names>A</given-names></name><name><surname>Sagi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Motion-induced blindness in normal observers</article-title><source>Nature</source><volume>411</volume><fpage>798</fpage><lpage>801</lpage><pub-id pub-id-type="doi">10.1038/35081073</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosman</surname><given-names>LW</given-names></name><name><surname>Houweling</surname><given-names>AR</given-names></name><name><surname>Owens</surname><given-names>CB</given-names></name><name><surname>Tanke</surname><given-names>N</given-names></name><name><surname>Shevchouk</surname><given-names>OT</given-names></name><name><surname>Rahmati</surname><given-names>N</given-names></name><name><surname>Teunissen</surname><given-names>WH</given-names></name><name><surname>Ju</surname><given-names>C</given-names></name><name><surname>Gong</surname><given-names>W</given-names></name><name><surname>Koekkoek</surname><given-names>SK</given-names></name><name><surname>De Zeeuw</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Anatomical pathways involved in generating and sensing rhythmic whisker movements</article-title><source>Frontiers in Integrative Neuroscience</source><volume>5</volume><pub-id pub-id-type="doi">10.3389/fnint.2011.00053</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boubenec</surname><given-names>Y</given-names></name><name><surname>Shulz</surname><given-names>DE</given-names></name><name><surname>Debrégeas</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Whisker encoding of mechanical events during active tactile exploration</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>6</volume><pub-id pub-id-type="doi">10.3389/fnbeh.2012.00074</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breitmeyer</surname><given-names>BG</given-names></name><name><surname>Ogmen</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Recent models and findings in visual backward masking: A comparison, review, and update</article-title><source>Perception &amp; Psychophysics</source><volume>62</volume><fpage>1572</fpage><lpage>1595</lpage><pub-id pub-id-type="doi">10.3758/bf03212157</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>A robust layered control system for a mobile robot</article-title><source>IEEE Journal on Robotics and Automation</source><volume>2</volume><fpage>14</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1109/JRA.1986.1087032</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buonomano</surname><given-names>DV</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Temporal information transformed into a spatial code by a neural network with realistic properties</article-title><source>Science</source><volume>267</volume><fpage>1028</fpage><lpage>1030</lpage><pub-id pub-id-type="doi">10.1126/science.7863330</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Rokni</surname><given-names>U</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Bayesian model of dynamic image stabilization in the visual system</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>107</volume><fpage>19525</fpage><lpage>19530</lpage><pub-id pub-id-type="doi">10.1073/pnas.1006076107</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casagrande</surname><given-names>VA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>A third parallel visual pathway to primate area V1</article-title><source>Trends in Neurosciences</source><volume>17</volume><fpage>305</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(94)90065-5</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Censor</surname><given-names>N</given-names></name><name><surname>Bonneh</surname><given-names>Y</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name><name><surname>Sagi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Early-vision brain responses which predict human visual segmentation and learning</article-title><source>Journal of Vision</source><volume>9</volume><fpage>12</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1167/9.4.12</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chapin</surname><given-names>JK</given-names></name><name><surname>Woodward</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Somatic sensory transmission to the cortex during movement: Gating of single cell responses to touch</article-title><source>Experimental Neurology</source><volume>78</volume><fpage>654</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1016/0014-4886(82)90082-6</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>JL</given-names></name><name><surname>Margolis</surname><given-names>DJ</given-names></name><name><surname>Stankov</surname><given-names>A</given-names></name><name><surname>Sumanovski</surname><given-names>LT</given-names></name><name><surname>Schneider</surname><given-names>BL</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Pathway-specific reorganization of projection neurons in somatosensory cortex during learning</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1101</fpage><lpage>1108</lpage><pub-id pub-id-type="doi">10.1038/nn.4046</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cleeremans</surname><given-names>A</given-names></name><name><surname>Sarrazin</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Time, action, and consciousness</article-title><source>Human Movement Science</source><volume>26</volume><fpage>180</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1016/j.humov.2007.01.009</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cleland</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Early transformations in odor representation</article-title><source>Trends in Neurosciences</source><volume>33</volume><fpage>130</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2009.12.004</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colechio</surname><given-names>EM</given-names></name><name><surname>Alloway</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Differential topography of the bilateral cortical projections to the whisker and forepaw regions in rat motor cortex</article-title><source>Brain Structure &amp; Function</source><volume>213</volume><fpage>423</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1007/s00429-009-0215-7</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connor</surname><given-names>CE</given-names></name><name><surname>Johnson</surname><given-names>KO</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Neural coding of tactile texture: Comparison of spatial and temporal mechanisms for roughness perception</article-title><source>The Journal of Neuroscience </source><volume>12</volume><fpage>3414</fpage><lpage>3426</lpage></element-citation></ref><ref id="bib37"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Crane</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>The Problem of Perception</chapter-title><person-group person-group-type="editor"><name><surname>Zalta</surname> <given-names>E</given-names></name></person-group><source>The Stanford Encyclopedia of Philosophy</source><uri xlink:href="http://plato.stanford.edu/entries/perception-problem/">http://plato.stanford.edu/entries/perception-problem/</uri></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Creutzfeldt</surname><given-names>OD</given-names></name><name><surname>Nothdurft</surname><given-names>HC</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Representation of complex visual stimuli in the brain</article-title><source>Die Naturwissenschaften</source><volume>65</volume><fpage>307</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1007/BF00368371</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Creutzig</surname><given-names>F</given-names></name><name><surname>Globerson</surname><given-names>A</given-names></name><name><surname>Tishby</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Past-future information bottleneck in dynamical systems</article-title><source>Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</source><volume>79</volume><pub-id pub-id-type="doi">10.1103/PhysRevE.79.041925</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curcio</surname><given-names>C</given-names></name><name><surname>Sloan</surname><given-names>KR</given-names></name><name><surname>Packer</surname><given-names>O</given-names></name><name><surname>Hendrickson</surname><given-names>AE</given-names></name><name><surname>Kalina</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Distribution of cones in human and monkey retina: Individual variability and radial asymmetry</article-title><source>Science</source><volume>236</volume><fpage>579</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1126/science.3576186</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dallas</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The active cochlea</article-title><source>The Journal of Neuroscience</source><volume>2</volume><fpage>4575</fpage><lpage>4585</lpage></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Kerszberg</surname><given-names>M</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A neuronal model of a global workspace in effortful cognitive tasks</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>95</volume><fpage>14529</fpage><lpage>14534</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.24.14529</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demb</surname><given-names>JB</given-names></name><name><surname>Singer</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Intrinsic properties and functional circuitry of the AII amacrine cell</article-title><source>Visual Neuroscience</source><volume>29</volume><fpage>51</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1017/S0952523811000368</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deutsch</surname><given-names>D</given-names></name><name><surname>Pietr</surname><given-names>M</given-names></name><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Fast feedback in active sensing: Touch-induced changes to whisker-object interaction</article-title><source>PloS One</source><volume>7</volume><elocation-id>e44272</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0044272</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dewey</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1896">1896</year><article-title>The reflex arc concept in psychology</article-title><source>Psychological Review</source><volume>3</volume><fpage>357</fpage><lpage>370</lpage><pub-id pub-id-type="doi">10.1037/h0070405</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhande</surname><given-names>OS</given-names></name><name><surname>Huberman</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Retinal ganglion cell maps in the brain: Implications for visual processing</article-title><source>Current Opinion in Neurobiology</source><volume>24</volume><fpage>133</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.08.006</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Diamond</surname><given-names>IT</given-names></name></person-group><year iso-8601-date="1983">1983</year><chapter-title>Parellel pathways in the auditory, visual and somatic systems</chapter-title><person-group person-group-type="editor"><name><surname>Macchi</surname> <given-names>G</given-names></name><name><surname>Rustioni</surname> <given-names>A</given-names></name><name><surname>Spreafico</surname> <given-names>R</given-names></name></person-group><source>Somatosensory Integration in the Thalamus</source><publisher-loc>Amsterdam</publisher-loc><publisher-name>Elsevier</publisher-name><fpage>251</fpage><lpage>272</lpage></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>von Heimendahl</surname><given-names>M</given-names></name><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>'Where' and 'what' in the whisker sensorimotor system</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>601</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.1038/nrn2411</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dreyfus</surname><given-names>HL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Intelligence without representation–merleau-ponty's critique of mental representation the relevance of phenomenology to scientific explanation</article-title><source>Phenomenology and the Cognitive Sciences</source><volume>1</volume><fpage>367</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1023/A:1021351606209</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Edelman</surname><given-names>G</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>A Universe of Consciousness How Matter Becomes Imagination</source><publisher-loc>New York, NY</publisher-loc><publisher-name> Basic Books</publisher-name></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edelman</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Neural darwinism: Selection and reentrant signaling in higher brain function</article-title><source>Neuron</source><volume>10</volume><fpage>115</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1016/0896-6273(93)90304-A</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ennis</surname><given-names>R</given-names></name><name><surname>Cao</surname><given-names>D</given-names></name><name><surname>Lee</surname><given-names>BB</given-names></name><name><surname>Zaidi</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Eye movements and the neural basis of context effects on visual sensitivity</article-title><source>The Journal of Neuroscience </source><volume>34</volume><fpage>8119</fpage><lpage>8129</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1048-14.2014</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enns</surname><given-names>JT</given-names></name><name><surname>Di Lollo</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>What's new in visual masking?</article-title><source>Trends in Cognitive Sciences</source><volume>4</volume><fpage>345</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01520-5</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fee</surname><given-names>MS</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Central versus peripheral determinants of patterned spike activity in rat vibrissa cortex during whisking</article-title><source>Journal of Neurophysiology</source><volume>78</volume><fpage>1144</fpage><lpage>1149</lpage></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fetsch</surname><given-names>CR</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Effects of cortical microstimulation on confidence in a perceptual decision</article-title><source>Neuron</source><volume>83</volume><fpage>797</fpage><lpage>804</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.07.011</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Findlay</surname><given-names>JM</given-names></name><name><surname>Gilchrist</surname><given-names>ID</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Active Vision: The Psychology of Looking and Seeing</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780198524793.001.0001</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonio</surname><given-names>E</given-names></name><name><surname>Gordon</surname><given-names>G</given-names></name><name><surname>Barak</surname><given-names>N</given-names></name><name><surname>Winetraub</surname><given-names>Y</given-names></name><name><surname>Oram</surname><given-names>TB</given-names></name><name><surname>Haidarliu</surname><given-names>S</given-names></name><name><surname>Kimchi</surname><given-names>T</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Coordination of sniffing and whisking depends on the mode of interaction with the environment</article-title><source>Israel Journal of Ecology &amp; Evolution</source><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1080/15659801.2015.1124656</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>How Brains Make Up Their Minds</source><publisher-loc>New York</publisher-loc><publisher-name>Columbia University Press</publisher-name></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Nikolić</surname><given-names>D</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The gamma cycle</article-title><source>Trends in Neurosciences</source><volume>30</volume><fpage>309</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2007.05.005</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fries</surname><given-names>W</given-names></name><name><surname>Keizer</surname><given-names>K</given-names></name><name><surname>Kuypers</surname><given-names>HG</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Large layer VI cells in macaque striate cortex (meynert cells) project to both superior colliculus and prestriate visual area V5</article-title><source>Experimental Brain Research</source><volume>58</volume><fpage>613</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1007/BF00235878</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The free-energy principle: A unified brain theory?</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>127</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nrn2787</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujita</surname><given-names>I</given-names></name><name><surname>Tanaka</surname><given-names>K</given-names></name><name><surname>Ito</surname><given-names>M</given-names></name><name><surname>Cheng</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Columns for visual features of objects in monkey inferotemporal cortex</article-title><source>Nature</source><volume>360</volume><fpage>343</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/360343a0</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gamzu</surname><given-names>E</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Importance of temporal cues for tactile spatial- frequency discrimination</article-title><source>The Journal of Neuroscience </source><volume>21</volume><fpage>7416</fpage><lpage>7427</lpage></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Observations on active touch</article-title><source>Psychological Review</source><volume>69</volume><fpage>477</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1037/h0046962</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilad</surname><given-names>A</given-names></name><name><surname>Pesoa</surname><given-names>Y</given-names></name><name><surname>Ayzenshtat</surname><given-names>I</given-names></name><name><surname>Slovin</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Figure-ground processing during fixational saccades in V1: Indication for higher-order stability</article-title><source>The Journal of Neuroscience </source><volume>34</volume><fpage>3247</fpage><lpage>3252</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4375-13.2014</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilchrist</surname><given-names>ID</given-names></name><name><surname>Brown</surname><given-names>V</given-names></name><name><surname>Findlay</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Saccades without eye movements</article-title><source>Nature</source><volume>390</volume><fpage>130</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1038/36478</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>G</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Hierarchical curiosity loops and active sensing</article-title><source>Neural Networks </source><volume>32</volume><fpage>119</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2012.02.024</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>G</given-names></name><name><surname>Dorfman</surname><given-names>N</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reinforcement active learning in the vibrissae system: Optimal object localization</article-title><source>Journal of Physiology, Paris</source><volume>107</volume><fpage>107</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2012.06.004</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>G</given-names></name><name><surname>Fonio</surname><given-names>E</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emergent exploration via novelty management</article-title><source>The Journal of Neuroscience </source><volume>34</volume><fpage>12646</fpage><lpage>12661</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1872-14.2014</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grion</surname><given-names>N</given-names></name><name><surname>Akrami</surname><given-names>A</given-names></name><name><surname>Zuo</surname><given-names>Y</given-names></name><name><surname>Stella</surname><given-names>F</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Coherence between rat sensorimotor system and hippocampus is enhanced during tactile discrimination</article-title><source>PLoS Biology</source><volume>14</volume><elocation-id>e1002384</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002384</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guillery</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Anatomical pathways that link perception and action</article-title><source>Progress in Brain Research</source><volume>149</volume><fpage>235</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(05)49017-2</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guillery</surname><given-names>RW</given-names></name><name><surname>Sherman</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The thalamus as a monitor of motor outputs</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>357</volume><fpage>1809</fpage><lpage>1821</lpage><pub-id pub-id-type="doi">10.1098/rstb.2002.1171</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Guinan</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><chapter-title>Physiology of Olivocochlear Efferents</chapter-title><source>The Cochlea</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer New York</publisher-name><fpage>435</fpage><lpage>502</lpage><pub-id pub-id-type="doi">10.1007/978-1-4612-0757-3_8</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halpern</surname><given-names>BP</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Tasting and smelling as active, exploratory sensory processes</article-title><source>American Journal of Otolaryngology</source><volume>4</volume><fpage>246</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1016/S0196-0709(83)80066-0</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamker</surname><given-names>FH</given-names></name><name><surname>Zirnsak</surname><given-names>M</given-names></name><name><surname>Ziesche</surname><given-names>A</given-names></name><name><surname>Lappe</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Computational models of spatial updating in peri-saccadic perception</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>366</volume><fpage>554</fpage><lpage>571</lpage><pub-id pub-id-type="doi">10.1098/rstb.2010.0229</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartline</surname><given-names>HK</given-names></name></person-group><year iso-8601-date="1938">1938</year><article-title>The response of single optic nerve fibers of the vertebrate eye to illumination of the retina</article-title><source>American Journal of Physiology</source><volume>121</volume><fpage>400</fpage><lpage>415</lpage></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hentschke</surname><given-names>H</given-names></name><name><surname>Haiss</surname><given-names>F</given-names></name><name><surname>Schwarz</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Central signals rapidly switch tactile processing in rat barrel cortex during whisker movements</article-title><source>Cerebral Cortex </source><volume>16</volume><fpage>1142</fpage><lpage>1156</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhj056</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herfst</surname><given-names>LJ</given-names></name><name><surname>Brecht</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Whisker movements evoked by stimulation of single motor neurons in the facial nucleus of the rat</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>2821</fpage><lpage>2832</lpage><pub-id pub-id-type="doi">10.1152/jn.01014.2007</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>DN</given-names></name><name><surname>Curtis</surname><given-names>JC</given-names></name><name><surname>Moore</surname><given-names>JD</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Primary motor cortex reports efferent control of vibrissa motion on multiple timescales</article-title><source>Neuron</source><volume>72</volume><fpage>344</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.020</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hires</surname><given-names>SA</given-names></name><name><surname>Pammer</surname><given-names>L</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Golomb</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Tapered whiskers are required for active tactile sensation</article-title><source>eLife</source><volume>2</volume><pub-id pub-id-type="doi">10.7554/eLife.01350</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochstein</surname><given-names>S</given-names></name><name><surname>Ahissar</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>View from the top: hierarchies and reverse hierarchies in the visual system</article-title><source>Neuron</source><volume>36</volume><fpage>791</fpage><lpage>804</lpage></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horev</surname><given-names>G</given-names></name><name><surname>Saig</surname><given-names>A</given-names></name><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Pietr</surname><given-names>M</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Motor-sensory convergence in object localization: A comparative study in rats and humans</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>366</volume><fpage>3070</fpage><lpage>3076</lpage><pub-id pub-id-type="doi">10.1098/rstb.2011.0157</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A big step along the visual pathway</article-title><source>Nature</source><volume>380</volume><fpage>197</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1038/380197a0</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Receptive fields, binocular interaction and functional architecture in the cat's visual cortex</article-title><source>The Journal of Physiology</source><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphries</surname><given-names>MD</given-names></name><name><surname>Gurney</surname><given-names>K</given-names></name><name><surname>Prescott</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Is there a brainstem substrate for action selection?</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>362</volume><fpage>1627</fpage><lpage>1639</lpage><pub-id pub-id-type="doi">10.1098/rstb.2007.2057</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1890">1890</year><source>The Principles of Psychology</source><publisher-loc>NY, US</publisher-loc><publisher-name>Henry Holt and Company</publisher-name><pub-id pub-id-type="doi">10.1037/11059-000</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarvilehto</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The theory of the organism-environment system: III. role of efferent influences on receptors in the formation of knowledge</article-title><source>Integrative Physiological and Behavioral Science</source><volume>34</volume><fpage>90</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1007/BF02688715</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jennings</surname><given-names>SG</given-names></name><name><surname>Strickland</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Evaluating the effects of olivocochlear feedback on psychophysical measures of frequency selectivity</article-title><source>The Journal of the Acoustical Society of America</source><volume>132</volume><pub-id pub-id-type="doi">10.1121/1.4742723</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johansson</surname><given-names>RS</given-names></name><name><surname>Flanagan</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Coding and use of tactile signals from the fingertips in object manipulation tasks</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>345</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1038/nrn2621</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kagan</surname><given-names>I</given-names></name><name><surname>Gur</surname><given-names>M</given-names></name><name><surname>Snodderly</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Spatial organization of receptive fields of V1 neurons of alert monkeys: Comparison with responses to gratings</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>2557</fpage><lpage>2574</lpage><pub-id pub-id-type="doi">10.1152/jn.00858.2001</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanamaru</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Van der Pol oscillator</article-title><source>Scholarpedia</source><volume>2</volume><fpage>2202</fpage><pub-id pub-id-type="doi">10.4249/scholarpedia.2202</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kareken</surname><given-names>DA</given-names></name><name><surname>Sabri</surname><given-names>M</given-names></name><name><surname>Radnovich</surname><given-names>AJ</given-names></name><name><surname>Claus</surname><given-names>E</given-names></name><name><surname>Foresman</surname><given-names>B</given-names></name><name><surname>Hector</surname><given-names>D</given-names></name><name><surname>Hutchins</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Olfactory system activation from sniffing: Effects in piriform and orbitofrontal cortex</article-title><source>NeuroImage</source><volume>22</volume><fpage>456</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.01.008</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawato</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Internal models for motor control and trajectory planning</article-title><source>Current Opinion in Neurobiology</source><volume>9</volume><fpage>718</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(99)00028-8</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sensorimotor mismatch signals in primary visual cortex of the behaving mouse</article-title><source>Neuron</source><volume>74</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.040</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kelso</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="1997">1997</year><source>Dynamic Patterns: The Self-Organization of Brain and Behavior</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The sniff as a unit of olfactory processing</article-title><source>Chemical Senses</source><volume>31</volume><fpage>167</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1093/chemse/bjj016</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Rapid and precise control of sniffing during olfactory discrimination in rats</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>205</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1152/jn.00071.2007</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleinfeld</surname><given-names>D</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Active sensation: Insights from the rodent vibrissa sensorimotor system</article-title><source>Current Opinion in Neurobiology</source><volume>16</volume><fpage>435</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2006.06.009</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Orthogonal coding of object location</article-title><source>Trends in Neurosciences</source><volume>32</volume><fpage>101</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2008.10.002</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Pietr</surname><given-names>M</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Haptic object localization in the vibrissal system: Behavior and performance</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>8451</fpage><lpage>8464</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1516-06.2006</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ko</surname><given-names>HK</given-names></name><name><surname>Poletti</surname><given-names>M</given-names></name><name><surname>Rucci</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Microsaccades precisely relocate gaze in a high visual acuity task</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1549</fpage><lpage>1553</lpage><pub-id pub-id-type="doi">10.1038/nn.2663</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobler</surname><given-names>JB</given-names></name><name><surname>Guinan</surname><given-names>JJ</given-names></name><name><surname>Vacher</surname><given-names>SR</given-names></name><name><surname>Norris</surname><given-names>BE</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Acoustic reflex frequency selectivity in single stapedius motoneurons of the cat</article-title><source>Journal of Neurophysiology</source><volume>68</volume><fpage>807</fpage><lpage>817</lpage></element-citation></ref><ref id="bib104"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koffka</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1935">1935</year><source>Principles of Gestalt Psychology</source><publisher-loc>New York</publisher-loc><publisher-name>Harcourt, Brace and Company</publisher-name></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>König</surname><given-names>P</given-names></name><name><surname>Luksch</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Active sensing--closing multiple loops</article-title><source>Zeitschrift Für Naturforschung C</source><volume>53</volume><fpage>542</fpage><lpage>549</lpage></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krauzlis</surname><given-names>R</given-names></name><name><surname>Lisberger</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Visual motion commands for pursuit eye movements in the cerebellum</article-title><source>Science</source><volume>253</volume><fpage>568</fpage><lpage>571</lpage><pub-id pub-id-type="doi">10.1126/science.1907026</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuang</surname><given-names>X</given-names></name><name><surname>Poletti</surname><given-names>M</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Rucci</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Temporal encoding of spatial information during active visual fixation</article-title><source>Current Biology </source><volume>22</volume><fpage>510</fpage><lpage>514</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.01.050</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lalazar</surname><given-names>H</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural basis of sensorimotor learning: Modifying internal models</article-title><source>Current Opinion in Neurobiology</source><volume>18</volume><fpage>573</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2008.11.003</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Land</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Eye movements and the control of actions in everyday life</article-title><source>Progress in Retinal and Eye Research</source><volume>25</volume><fpage>296</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.1016/j.preteyeres.2006.01.002</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lappe</surname><given-names>M</given-names></name><name><surname>Bremmer</surname><given-names>F</given-names></name><name><surname>van den Berg</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Perception of self-motion from visual flow</article-title><source>Trends in Cognitive Sciences</source><volume>3</volume><fpage>329</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(99)01364-9</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lederman</surname><given-names>SJ</given-names></name><name><surname>Klatzky</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Hand movements: A window into haptic object recognition</article-title><source>Cognitive Psychology</source><volume>19</volume><fpage>342</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(87)90008-9</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lichtsteiner</surname><given-names>P</given-names></name><name><surname>Posch</surname><given-names>C</given-names></name><name><surname>Delbruck</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A 128× 128 120 dB 15 μs latency asynchronous temporal contrast vision sensor</article-title><source>IEEE Journal of Solid-State Circuits</source><volume>43</volume><fpage>566</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1109/JSSC.2007.914337</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Little</surname><given-names>DY</given-names></name><name><surname>Sommer</surname><given-names>FT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Learning and exploration in action-perception loops</article-title><source>Frontiers in Neural Circuits</source><volume>7</volume><pub-id pub-id-type="doi">10.3389/fncir.2013.00037</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mach</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1959">1959</year><source>The Analysis of Sensations</source><publisher-loc>New York</publisher-loc><publisher-name>Dover publications</publisher-name></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mainland</surname><given-names>J</given-names></name><name><surname>Sobel</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The sniff is part of the olfactory percept</article-title><source>Chemical Senses</source><volume>31</volume><fpage>181</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1093/chemse/bjj012</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malik</surname><given-names>P</given-names></name><name><surname>Dessing</surname><given-names>JC</given-names></name><name><surname>Crawford</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Role of early visual cortex in trans-saccadic memory of object features</article-title><source>Journal of Vision</source><volume>15</volume><fpage>7</fpage><pub-id pub-id-type="doi">10.1167/15.11.7</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maravall</surname><given-names>M</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Algorithms of whisker-mediated touch perception</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>176</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.01.014</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1982 ">1982 </year><source> Vision</source><publisher-loc>San Francisco</publisher-loc><publisher-name>W. H. Freeman</publisher-name></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Microcircuits in visual cortex</article-title><source>Current Opinion in Neurobiology</source><volume>12</volume><fpage>418</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(02)00343-4</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>JH</given-names></name><name><surname>Schemitsch</surname><given-names>M</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Summary statistics in auditory perception</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>493</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1038/nn.3347</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McMahon</surname><given-names>DBT</given-names></name><name><surname>Jones</surname><given-names>AP</given-names></name><name><surname>Bondar</surname><given-names>IV</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Face-selective neurons maintain consistent visual responses across months</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>111</volume><fpage>8251</fpage><lpage>8256</lpage><pub-id pub-id-type="doi">10.1073/pnas.1318331111</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Merleau-Ponty</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1962">1962</year><source>Phenomenology of Perception</source><publisher-loc>London</publisher-loc><publisher-name>Routledge</publisher-name></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Micheyl</surname><given-names>C</given-names></name><name><surname>Xiao</surname><given-names>L</given-names></name><name><surname>Oxenham</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Characterizing the dependence of pure-tone frequency difference limens on frequency, duration, and level</article-title><source>Hearing Research</source><volume>292</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2012.07.004</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchinson</surname><given-names>B</given-names></name><name><surname>Martin</surname><given-names>CJ</given-names></name><name><surname>Grant</surname><given-names>RA</given-names></name><name><surname>Prescott</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Feedback control in active sensing: Rat exploratory whisking is modulated by environmental contact</article-title><source>Proceedings. Biological Sciences / the Royal Society</source><volume>274</volume><fpage>1035</fpage><lpage>1041</lpage><pub-id pub-id-type="doi">10.1098/rspb.2006.0347</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>JD</given-names></name><name><surname>Deschênes</surname><given-names>M</given-names></name><name><surname>Furuta</surname><given-names>T</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Smear</surname><given-names>MC</given-names></name><name><surname>Demers</surname><given-names>M</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hierarchy of orofacial rhythms revealed through whisking and breathing</article-title><source>Nature</source><volume>497</volume><fpage>205</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1038/nature12076</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Najemnik</surname><given-names>J</given-names></name><name><surname>Geisler</surname><given-names>WS</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Optimal eye movement strategies in visual search</article-title><source>Nature</source><volume>434</volume><fpage>387</fpage><lpage>391</lpage><pub-id pub-id-type="doi">10.1038/nature03390</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassi</surname><given-names>JJ</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Parallel processing strategies of the primate visual system</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>360</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1038/nrn2619</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>QT</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Positive feedback in a brainstem tactile sensorimotor loop</article-title><source>Neuron</source><volume>45</volume><fpage>447</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.12.042</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nijhawan</surname><given-names>R</given-names></name><name><surname>Kirschfeld</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Analogous mechanisms compensate for neural delays in the sensory and the motor pathways: Evidence from motor flash-lag</article-title><source>Current Biology : CB</source><volume>13</volume><fpage>749</fpage><lpage>753</lpage><pub-id pub-id-type="doi">10.1016/s0960-9822(03)00248-3</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nijhawan</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The flash-lag phenomenon: Object motion and eye movements</article-title><source>Perception</source><volume>30</volume><fpage>263</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1068/p3172</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nin</surname><given-names>F</given-names></name><name><surname>Reichenbach</surname><given-names>T</given-names></name><name><surname>Fisher</surname><given-names>JAN</given-names></name><name><surname>Hudspeth</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Contribution of active hair-bundle motility to nonlinear amplification in the mammalian cochlea</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>109</volume><fpage>21076</fpage><lpage>21080</lpage><pub-id pub-id-type="doi">10.1073/pnas.1219379110</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noton</surname><given-names>D</given-names></name><name><surname>Stark</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Scanpaths in eye movements during pattern perception</article-title><source>Science</source><volume>171</volume><fpage>308</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1126/science.171.3968.308</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connor</surname><given-names>DH</given-names></name><name><surname>Hires</surname><given-names>SA</given-names></name><name><surname>Guo</surname><given-names>ZV</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Sun</surname><given-names>QQ</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural coding during active somatosensation revealed using illusory touch</article-title><source>Nature Neuroscience</source><volume>16</volume><pub-id pub-id-type="doi">10.1038/nn.3419</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Regan</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Solving the &quot;real&quot; mysteries of visual perception: The world as an outside memory</article-title><source>Canadian Journal of Psychology/Revue Canadienne De Psychologie</source><volume>46</volume><fpage>461</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1037/h0084327</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Regan</surname><given-names>JK</given-names></name><name><surname>Noë</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A sensorimotor account of vision and visual consciousness</article-title><source>The Behavioral and Brain Sciences</source><volume>24</volume><fpage>939</fpage><lpage>973</lpage><pub-id pub-id-type="doi">10.1017/S0140525X01000115</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ölveczky</surname><given-names>BP</given-names></name><name><surname>Baccus</surname><given-names>SA</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Segregation of object and background motion in the retina</article-title><source>Nature</source><volume>423</volume><fpage>401</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1038/nature01652</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Packer</surname><given-names>O</given-names></name><name><surname>Williams</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Blurring by fixational eye movements</article-title><source>Vision Research</source><volume>32</volume><fpage>1931</fpage><lpage>1939</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(92)90052-K</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pammer</surname><given-names>L</given-names></name><name><surname>O'Connor</surname><given-names>DH</given-names></name><name><surname>Hires</surname><given-names>SA</given-names></name><name><surname>Clack</surname><given-names>NG</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The mechanical variables underlying object localization along the axis of the whisker</article-title><source>The Journal of Neuroscience </source><volume>33</volume><fpage>6726</fpage><lpage>6741</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4316-12.2013</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A neural computation for visual acuity in the presence of eye movements</article-title><source>PLoS Biology</source><volume>5</volume><elocation-id>e331</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0050331</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poggio</surname><given-names>T</given-names></name><name><surname>Serre</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Models of visual cortex</article-title><source>Scholarpedia</source><volume>8</volume><fpage>3516</fpage><pub-id pub-id-type="doi">10.4249/scholarpedia.3516</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polani</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Information: Currency of life?</article-title><source>HFSP Journal</source><volume>3</volume><fpage>307</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.2976/1.3171566</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollen</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>On the neural correlates of visual perception</article-title><source>Cerebral Cortex</source><volume>9</volume><fpage>4</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1093/cercor/9.1.4</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pöppel</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Lost in time: a historical frame, elementary processing units and the 3-second window</article-title><source>Acta Neurobiologiae Experimentalis</source><volume>64</volume><fpage>295</fpage><lpage>301</lpage></element-citation></ref><ref id="bib145"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Port</surname><given-names>RF</given-names></name><name><surname>Van</surname> <given-names>Gelder T</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Mind as Motion: Explorations in the Dynamics of Cognition</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulet</surname><given-names>JFA</given-names></name><name><surname>Petersen</surname><given-names>CCH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internal brain state regulates membrane potential synchrony in barrel cortex of behaving mice</article-title><source>Nature</source><volume>454</volume><fpage>881</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1038/nature07150</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Powers</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Feedback: Beyond behaviorism: Stimulus-response laws are wholly predictable within a control-system model of behavioral organization</article-title><source>Science</source><volume>179</volume><fpage>351</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1126/science.179.4071.351</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prescott</surname><given-names>TJ</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>Wing</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Active touch sensing</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>366</volume><fpage>2989</fpage><lpage>2995</lpage><pub-id pub-id-type="doi">10.1098/rstb.2011.0167</pub-id></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prescott</surname><given-names>TJ</given-names></name><name><surname>Montes González</surname><given-names>FM</given-names></name><name><surname>Gurney</surname><given-names>K</given-names></name><name><surname>Humphries</surname><given-names>MD</given-names></name><name><surname>Redgrave</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A robot model of the basal ganglia: Behavior and intrinsic processing</article-title><source>Neural Networks </source><volume>19</volume><fpage>31</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2005.06.049</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Reddy</surname><given-names>L</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Invariant visual representation by single neurons in the human brain</article-title><source>Nature</source><volume>435</volume><fpage>1102</fpage><lpage>1107</lpage><pub-id pub-id-type="doi">10.1038/nature03687</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quist</surname><given-names>BW</given-names></name><name><surname>Hartmann</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Mechanical signals at the base of a rat vibrissa: The effect of intrinsic vibrissa curvature and implications for tactile exploration</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>2298</fpage><lpage>2312</lpage><pub-id pub-id-type="doi">10.1152/jn.00372.2011</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quist</surname><given-names>BW</given-names></name><name><surname>Seghete</surname><given-names>V</given-names></name><name><surname>Huet</surname><given-names>LA</given-names></name><name><surname>Murphey</surname><given-names>TD</given-names></name><name><surname>Hartmann</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Modeling forces and moments at the base of a rat vibrissa during noncontact whisking and whisking against an object</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>9828</fpage><lpage>9844</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1707-12.2014</pub-id></element-citation></ref><ref id="bib153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reich</surname><given-names>DS</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Knight</surname><given-names>BW</given-names></name><name><surname>Ozaki</surname><given-names>T</given-names></name><name><surname>Kaplan</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Response variability and timing precision of neuronal spike trains in vivo</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>2836</fpage><lpage>2841</lpage></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Divergence and reconvergence: Multielectrode analysis of feedforward connections in the visual system</article-title><source>Progress in Brain Research</source><volume>130</volume><fpage>141</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/s0079-6123(01)30010-9</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Models of object recognition</article-title><source>Nature Neuroscience</source><volume>3 Suppl</volume><fpage>1199</fpage><lpage>1204</lpage><pub-id pub-id-type="doi">10.1038/81479</pub-id></element-citation></ref><ref id="bib156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rokni</surname><given-names>U</given-names></name><name><surname>Richardson</surname><given-names>AG</given-names></name><name><surname>Bizzi</surname><given-names>E</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Motor learning with unstable neural representations</article-title><source>Neuron</source><volume>54</volume><fpage>653</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.04.030</pub-id></element-citation></ref><ref id="bib157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rucci</surname><given-names>M</given-names></name><name><surname>Iovin</surname><given-names>R</given-names></name><name><surname>Poletti</surname><given-names>M</given-names></name><name><surname>Santini</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Miniature eye movements enhance fine spatial detail</article-title><source>Nature</source><volume>447</volume><fpage>852</fpage><lpage>855</lpage><pub-id pub-id-type="doi">10.1038/nature05866</pub-id></element-citation></ref><ref id="bib158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rucci</surname><given-names>M</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The unsteady eye: An information-processing stage, not a bug</article-title><source>Trends in Neurosciences</source><volume>38</volume><fpage>195</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2015.01.005</pub-id></element-citation></ref><ref id="bib159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saig</surname><given-names>A</given-names></name><name><surname>Gordon</surname><given-names>G</given-names></name><name><surname>Assa</surname><given-names>E</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Motor-sensory confluence in tactile perception</article-title><source>The Journal of Neuroscience </source><volume>32</volume><fpage>14022</fpage><lpage>14032</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2432-12.2012</pub-id></element-citation></ref><ref id="bib160"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saraf-Sinik</surname><given-names>I</given-names></name><name><surname>Assa</surname><given-names>E</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Motion makes sense: An adaptive motor-sensory strategy underlies the perception of object location in rats</article-title><source>The Journal of Neuroscience </source><volume>35</volume><fpage>8777</fpage><lpage>8789</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4149-14.2015</pub-id></element-citation></ref><ref id="bib161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Wilson</surname><given-names>DA</given-names></name><name><surname>Radman</surname><given-names>T</given-names></name><name><surname>Scharfman</surname><given-names>H</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dynamics of active sensing and perceptual selection</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>172</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.02.010</pub-id></element-citation></ref><ref id="bib162"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Decision making as a window on cognition</article-title><source>Neuron</source><volume>80</volume><fpage>791</fpage><lpage> 806.</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.047</pub-id></element-citation></ref><ref id="bib163"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simony</surname><given-names>E</given-names></name><name><surname>Saraf-Sinik</surname><given-names>I</given-names></name><name><surname>Golomb</surname><given-names>D</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sensation-targeted motor control: Every spike counts? Focus on: &quot;whisker movements evoked by stimulation of single motor neurons in the facial nucleus of the rat&quot;</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>2757</fpage><lpage>2759</lpage><pub-id pub-id-type="doi">10.1152/jn.90432.2008</pub-id></element-citation></ref><ref id="bib164"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smear</surname><given-names>M</given-names></name><name><surname>Shusterman</surname><given-names>R</given-names></name><name><surname>O’Connor</surname><given-names>R</given-names></name><name><surname>Bozza</surname><given-names>T</given-names></name><name><surname>Rinberg</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perception of sniff phase in mouse olfaction</article-title><source>Nature</source><volume>479</volume><fpage>397</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1038/nature10521</pub-id></element-citation></ref><ref id="bib165"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>JB</given-names></name><name><surname>Mowery</surname><given-names>TM</given-names></name><name><surname>Alloway</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Thalamic pom projections to the dorsolateral striatum of rats: Potential pathway for mediating stimulus-response associations for sensorimotor habits</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>160</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1152/jn.00142.2012</pub-id></element-citation></ref><ref id="bib166"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snodderly</surname><given-names>DM</given-names></name><name><surname>Kagan</surname><given-names>I</given-names></name><name><surname>Gur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Selective activation of visual cortex neurons by fixational eye movements: Implications for neural coding</article-title><source>Visual Neuroscience</source><volume>18</volume><fpage>259</fpage><lpage>277</lpage><pub-id pub-id-type="doi">10.1017/s0952523801182118</pub-id></element-citation></ref><ref id="bib167"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Steinman</surname><given-names>RM</given-names></name><name><surname>Levinson</surname><given-names>JZ</given-names></name></person-group><year iso-8601-date="1990">1990</year><chapter-title>The role of eye movement in the detection of contrast and spatial detail</chapter-title><person-group person-group-type="editor"><name><surname>Kowler</surname> <given-names>E</given-names></name></person-group><source>Eye Movementsand Their Role in Visual and Cognitive Processes</source><publisher-loc>Amsterdam</publisher-loc><publisher-name>Elsevier</publisher-name><fpage>115</fpage><lpage>212</lpage></element-citation></ref><ref id="bib168"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stevens</surname><given-names>JK</given-names></name><name><surname>Emerson</surname><given-names>RC</given-names></name><name><surname>Gerstein</surname><given-names>GL</given-names></name><name><surname>Kallos</surname><given-names>T</given-names></name><name><surname>Neufeld</surname><given-names>GR</given-names></name><name><surname>Nichols</surname><given-names>CW</given-names></name><name><surname>Rosenquist</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Paralysis of the awake human: Visual perceptions</article-title><source>Vision Research</source><volume>16</volume><fpage>93</fpage><lpage>IN99</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(76)90082-1</pub-id></element-citation></ref><ref id="bib169"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szwed</surname><given-names>M</given-names></name><name><surname>Bagdasarian</surname><given-names>K</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Encoding of vibrissal active touch</article-title><source>Neuron</source><volume>40</volume><fpage>621</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(03)00671-8</pub-id></element-citation></ref><ref id="bib170"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takatoh</surname><given-names>J</given-names></name><name><surname>Nelson</surname><given-names>A</given-names></name><name><surname>Zhou</surname><given-names>X</given-names></name><name><surname>Bolton</surname><given-names>MM</given-names></name><name><surname>Ehlers</surname><given-names>MD</given-names></name><name><surname>Arenkiel</surname><given-names>BR</given-names></name><name><surname>Mooney</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>New modules are added to vibrissal premotor circuitry with the emergence of exploratory whisking</article-title><source>Neuron</source><volume>77</volume><fpage>346</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.010</pub-id></element-citation></ref><ref id="bib171"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tallon-Baudry</surname><given-names>C</given-names></name><name><surname>Bertrand</surname><given-names>O</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Oscillatory gamma activity in humans and its role in object representation</article-title><source>Trends in Cognitive Sciences</source><volume>3</volume><fpage>151</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(99)01299-1</pub-id></element-citation></ref><ref id="bib172"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The neural correlates of consciousness: An update</article-title><source>Annals of the New York Academy of Sciences</source><volume>1124</volume><fpage>239</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1196/annals.1440.004</pub-id></element-citation></ref><ref id="bib173"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Uexkull</surname><given-names>J.v</given-names></name></person-group><year iso-8601-date="1926">1926</year><source>Theoretical Biology</source><publisher-loc>London</publisher-loc><publisher-name>K. Paul, Trench, Trubner &amp; Co. Ltd</publisher-name></element-citation></ref><ref id="bib174"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ullman</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Against direct perception</article-title><source>Behavioral and Brain Sciences</source><volume>3</volume><fpage>373</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1017/S0140525X0000546X</pub-id></element-citation></ref><ref id="bib175"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ullman</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Object recognition and segmentation by a fragment-based hierarchy</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>58</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.11.009</pub-id></element-citation></ref><ref id="bib176"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanRullen</surname><given-names>R</given-names></name><name><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The time course of visual processing: From early perception to decision-making</article-title><source>Journal of Cognitive Neuroscience</source><volume>13</volume><fpage>454</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1162/08989290152001880</pub-id></element-citation></ref><ref id="bib177"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viskontas</surname><given-names>IV</given-names></name><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Human medial temporal lobe neurons respond preferentially to personally relevant images</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>106</volume><fpage>21329</fpage><lpage>21334</lpage><pub-id pub-id-type="doi">10.1073/pnas.0902319106</pub-id></element-citation></ref><ref id="bib178"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voigts</surname><given-names>J</given-names></name><name><surname>Herman</surname><given-names>DH</given-names></name><name><surname>Celikel</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Tactile object localization by anticipatory whisker motion</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>620</fpage><lpage>632</lpage><pub-id pub-id-type="doi">10.1152/jn.00241.2014</pub-id></element-citation></ref><ref id="bib179"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker-Smith</surname><given-names>GJ</given-names></name><name><surname>Gale</surname><given-names>AG</given-names></name><name><surname>Findlay</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Eye movement strategies involved in face perception</article-title><source>Perception</source><volume>6</volume><fpage>313</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1068/p060313</pub-id></element-citation></ref><ref id="bib180"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>IS</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The proprioceptive representation of eye position in monkey primary somatosensory cortex</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>640</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1038/nn1878</pub-id></element-citation></ref><ref id="bib181"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welker</surname><given-names>WI</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Analysis of sniffing of the albino rat</article-title><source>Behaviour</source><volume>22</volume><fpage>223</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1163/156853964x00030</pub-id></element-citation></ref><ref id="bib182"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wiener</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1949">1949</year><source>Cybernetics</source><publisher-loc>New York</publisher-loc><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib183"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Miall</surname><given-names>RC</given-names></name><name><surname>Kawato</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Internal models in the cerebellum</article-title><source>Trends in Cognitive Sciences</source><volume>2</volume><fpage>338</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(98)01221-2</pub-id></element-citation></ref><ref id="bib184"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>C-T</given-names></name><name><surname>Crouzet</surname><given-names>SM</given-names></name><name><surname>Thorpe</surname><given-names>SJ</given-names></name><name><surname>Fabre-Thorpe</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>At 120 msec you can spot the animal but you don't yet know it's a dog</article-title><source>Journal of Cognitive Neuroscience</source><pub-id pub-id-type="doi">10.1162/jocn_a_00701</pub-id></element-citation></ref><ref id="bib185"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yarbus</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="1967">1967</year><source>Eye Movements and Vision</source><publisher-loc>New York</publisher-loc><publisher-name>John Wiley &amp; Sons</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4899-5379-7</pub-id></element-citation></ref><ref id="bib186"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>C</given-names></name><name><surname>Horev</surname><given-names>G</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Haidarliu</surname><given-names>S</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Coding of object location in the vibrissal thalamocortical system</article-title><source>Cerebral Cortex </source><volume>25</volume><fpage>563</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht241</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.12830.010</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kleinfeld</surname><given-names>David</given-names></name><role>Reviewing editor</role><aff id="aff3"><institution>University of California, San Diego</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your work entitled &quot;Perception as a closed-loop convergence process&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers – including the Reviewing editor, David Kleinfeld –, and the evaluation has been overseen by Eve Marder as the Senior Editor. The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission. While there was considerable interest and enthusiasm for this work, the reviewers also had some substantive critiques that will require attention.</p><p>Summary:</p><p>The basic premise of this manuscript is that &quot;…passive paradigms cannot reveal how sensory information is actually processed during active perception […] For that, a unified analysis of the motor and sensory components engaging brains with their environments is required.&quot; Toward addressing this premise, &quot;The current paper describes an attempt to bring the motor variables back to theoretical modeling of perception, by proposing a motor-sensory closed-loop scheme for the perception of the external environment.&quot; The crux proposal is that internal representation may be a time-varying signal that reaches a steady state behavior perhaps, if only because &quot;Mammalian sensory organs usually acquire information via movements…&quot;.</p><p>This is a &quot;Viewpoint&quot; with some original material as opposed to an &quot;Original Article&quot; per se. Yet it is timely and important. One would think that most rational neuroscientists would agree. Yet much of mammalian systems neuroscience went through a dark period of working with primarily anesthetized animals or highly constrained animals. This was particularly egregious in vision, where one could argue that a generation of neuroscientists attended to second-order effects to Hubel and Wiesel receptive fields while a basic role of visual areas for motion control went undiscovered until a few years back; see, e.g., Carandini (Nat Neurosci 2013), Bonhoeffer (Neuron 2012), and Stryker (Neuron 2010). The current work reviews this dark period, although the authors should note that some areas, including the study of the VOR and the OKR, the study of hippocampal function during learning and memory (2015 Nobel prize), and clearly the study of motor control for locomotion and manipulation, did not fall into this trap. The pioneering gating experiments of Chapin and Woodward (Exp Neurol 1982), which show how motor output gates sensation, deserve special mention as counterpoint to the authors' sarcasm, i.e., &quot;The (re) discovery that mammalian sensation is active…&quot;.</p><p>The authors propose that the internal representation of a stimulus depends on motor output. Thus, unless the animal acts on the information, one does not know if the representation, presumably the pattern of neurons spiking in different brain areas, is a complete or only a partial representation. Further, the partial representation could be too incomplete for action to occur. I think we all would agree. Many highly cited studies on internal representation view a change in motor output in response to a change in internal representation – which could be the act of pushing a lever to declare a sensorimotor process is terminating- as a gold standard. There is a fair literature on this – including the pioneering ICMS experiments of Newsome and colleagues (Nature 1990, J Neurophysiol 1992, Neuron 2014). In the vibrissa literature, which appears prominently in this manuscript, there are the reafferent coding studies of Kleinfeld and colleagues (J Neurophysiol 1997; Neuron 2011). The authors go through many arguments to describe why the notion of a motor-free, or open loop representation, will fail. A key argument involves the time it takes – presumably cycles of recurrence – to form an internal representation. This is reminiscent of the argument by Martin (TiNS 1988) on the formation of visual representation as a recurrent of feedback, which was written as a challenge to the feed forward processing implicit in the wiring maps of Feldman and Van Essen.</p><p>Essential revisions:</p><p>The full reports of all reviewers are appended. All reviewers found merit with the timeliness and importance of the work but all reviewers also found faults that require attention. It is essential to address these issues:</p><p>1) Draw a clear distinction about dynamics that spread beyond sensory areas to involve decision making and motor output, each of which may contain local feedback loops, as opposed to brain-wide feedback dynamics per se.</p><p>2) Provide clearer and more thoughtful experiments to distinguish between the manifestation of open loop and closed loop representation of the sensory world – at least an object!</p><p>3) Properly define and clarify the output from the model / robot (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><p>Specific points:</p><p><italic>Reviewer # 1 (annotated by BRE David Kleinfeld):</italic></p><p>1) In their paper, “Perception as a closed-loop convergence process”, Ahissar and Assa conceptualize perception as an interactive dynamical process. Specifically the authors propose that perception is a convergence process that involves about 4 repeated sensory-interactions through which an object percept is dynamically generated. Further the authors emphasize the constitutive active nature of sensing and stress the presence of loops rather than of a feed-forward architecture in the brain.</p><p>DK: This summary is telling. The reviewer focuses solely on dynamics per se rather than on motor output and control as an integral part of sensation. This implies that the larger message from Ahissar and Assa may have failed to get through.</p><p>2) The paper is a strange mix out high-level assumptions and details of rodent active touch. To me these two different levels never fully merged, i.e. it did not become clear to me, where in the rodent brain the dynamical process happens that forms the perceptual object.</p><p>DK: In fact, there is published evidence that all of vibrissa L5b cells (in both sensory and motor cortices) have a role in motor control; this goes back to work by Glickman. So this is a clear place to note the origin of a perception and one that is, in terms of hypothesis testing, (just barely) accessible with Ca<sup>2+</sup>-imaging.</p><p>3) The predictions that differentiate the OpenLoop and the ClosedLoop model of perception are neither very strong nor very clear. More work is required here.</p><p>DK: All reviewers agree on this point. The section on predictions is a crux aspect of the paper that requires significant improvement, as the key is to entice experimentalists to try to falsify or verify the ideas inherent in representation through motor control. This will take thought and time and still may not work out!</p><p>4) I have major doubts that the authors are right. It is obvious from the literature that passive, or briefly flashed stimulus presentations, which do not allow active sensing, still evoke robust percepts. I would predict that we will find also a lot more single touch percepts in the active touch system, once we look harder in situations, where animals sensing under time pressure.</p><p>DK: I think the confusion results from a mixing of loops for perception, which are hypothesized to include sensory and motor function, and local sensory loops solely for reverberation. The latter are well known to occur with sensory processes, and the most dramatic case is the &gt; 20 s of reverberatory signal in AIT cortex during the delay period of a match to sample task (Fuster &amp; Alexander 1971 Science). Please clarify your text.</p><p><italic>Reviewer # 2 (annotated by BRE David Kleinfeld):</italic></p><p>1) The distinction between &quot;neural representation&quot; and &quot;internal representation&quot; seems unnecessary – and ill-defined.</p><p>DK: This should be fixed.</p><p>2) Although I think I understand the intuition behind referring to a sensory-motor loop as &quot;motor-sensory-motor loop&quot;, this seems unnecessary; &quot;loop&quot; already implies circularity.</p><p>DK: I suspect that this was done to separate loops that are local and lie just in solely sensory or solely regions from brain-wide loops that span the nervous system. As noted above, this needs to be clarified.</p><p>3) It is unclear to me what the distinction between msOLP and CLP is?</p><p>DK: Please either drop or clarify this issue. It should be a straight forward fix.</p><p>4) At times the argument is speculative and unnecessarily strong – to the point of likely already being wrong? E.g., in the subsection “Contrasting OLP and CLP – discriminatory testable predictions” &quot;the question is […] whether paralyzed subjects perceive. If they do – here goes the closed-loop hypothesis&quot;. We clearly perceive by hearing without moving. I will grant the authors that it is still unclear what the function of outer hair cells is – but as far as we know, this is a counter example to their hypothesis?</p><p>DK: please provide a more graded presentation. The manuscript started out this way, in that open loop representations were a primarily seen as a subset of the larger internal representation.</p><p>5) The &quot;mathematical model&quot; and the robotic setup seem to add little to the manuscript. The robotic system example only proves that an oscillatory system can be driven to different attractors with different inputs?</p><p>DK: All reviewers commented on the opaque nature of this presentation. It needs to be rewritten. I do not see a fundamental flaw.</p><p>6) The testable predictions part is a great idea – but as formulated they are not very helpful. A specific motor output can be thought of as the correlate of a dynamic neural attractor instead of an &quot;instantaneous state&quot;.</p><p>DK: All reviewers agree. The section on predictions is a crux aspect of the paper that requires significant improvement, as the key is to entice experimentalists to try to falsify or verify the ideas inherent in representation through motor control. This will take thought and time and still may not work out!</p><p><italic>Reviewer # 3 (RE Kleinfeld):</italic></p><p>1) The statement that &quot;[motor-sensory-motor]-loops are fundamental units of mammalian perception&quot; cannot be right. These loops can support activity and thus a motor-sensory-motor representation, but anatomical loops per se is not a representation.</p><p>2) The discussion of two types of loops notes that the &quot;first uses proprioceptive signals […] The other type uses sensory signals to monitor features of external objects…&quot;. In fact, this extends confusion in the literature. Signals from muscle spindles, usually regarded as proprioceptive in the sense that are used only for motor feedback, are also sensory. See the pioneering work by Hsiao (2006 J Neurophysiol) on discriminating the size of objects based on muscle stretch.</p><p>3) The discussion of reading out the convergence, say, to a limit cycle is muddled. Are convergence cycles related to the accumulation of evidence? If so, it is an interesting idea. But the authors need to describe a mechanism to link dynamics with estimated of confidence. They end with &quot;although the loops never reach the ultimate steady-states, they typically quit the convergence process when the distance from that state is no more sensible&quot;. This seems too soft a statement for a serious article.</p><p>4) The authors discuss the need to share information between limit cycles (perceptual loops). They are a bit glib in listing possibilities as the locking and unlocking of activity in different loops is essential to their scheme of hierarchical loops. Coherence between different loops is tricky – if the interactions cause a pair of loops to phase-lock, then it is not clear how they separate and dephase. The authors have neglected issues of noise, which is a mechanism to break locking and to dephase.</p><p>5) The equations for the SYCLOP model need to be explained. As it stands, this section will lose almost all readers. None of the symbols are explained. I would also start by saying that the simplest model of a loop uses Van der Pol relaxation dynamics. On the one hand it is a bit of a let-down to have the work condensed to a single oscillator that came out of the days of vacuum triodes. On the other hand, the presentation of the realization with the Van der Pol oscillator (<xref ref-type="fig" rid="fig7">Figure 7</xref>) is very condensed. I think <xref ref-type="fig" rid="fig7">Figure 7</xref> needs to be considerably unpacked. Panels A, B, and example dynamics like panel H can be one figure, while panels D-G and I could be a second figure. Also, define &quot;k-events&quot;, label the ordinates of panels H and I.</p><p>6) The authors end with a number of proposed experiments to address the claims of closed versus open loop object representation. One involves the detection of the phase of contact in the whisking cycle, yet is followed by the claim that &quot;…predictions of CLP and OLP can be distinguished only in natural perceiving conditions.&quot; This appears to obviate the use of head-fixed animals, an excellent preparation for combined behavior and electrophysiology. Why is head fixing bad for whisking? It seems that perception must often work under partial constraints.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Perception as a closed-loop convergence process&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Eve Marder (Senior editor), Reviewing editor David Kleinfeld, and one reviewer.</p><p>The manuscript has been improved but there are a few remaining issues raised by the reviewer and verified by Reviewing editor Kleinfeld. In order to complete this odyssey, please address these queries.</p><p>1) In the subsection “Synthesis of CLP in a robotic setup”. Please expand on the solution of the model, a van der Pol oscillator, to make it transparent to the &quot;typical&quot; biologically trained reader. The statement &quot;The implementation of these equations using the SYCLOP platform&quot; needs to be detailed – even in the appendix – so a reader can duplicate your calculation.</p><p>2) In the subsection “Perception can be masked “backwardly”” – &quot;If perception could be reduced to a sequence of pure open loop processes backward masking should not occur.&quot; One might think that any slow integration step in a feed-forward processing system would explain backward masking through injection of a signal within the integration time. Perhaps your statement could be better explained as dependent on a system with only &quot;fast&quot; integration.</p><p>3) In the subsection “Perception can be masked “backwardly”” – &quot;Perceptual masking thus challenges the validity of the 'virtual knife' reduction and the ability to reconstruct perception based on experiments with flashed stimuli only.&quot; The argument leading up to this is not clear.</p><p>Finally, please reread the manuscript in a &quot;copy-edit&quot; manner to improve the grammar and correct any number of typos in punctuation.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.12830.011</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>The basic premise of this manuscript is that &quot;…passive paradigms cannot reveal how sensory information is actually processed during active perception […] For that, a unified analysis of the motor and sensory components engaging brains with their environments is required.&quot; Toward addressing this premise, &quot;The current paper describes an attempt to bring the motor variables back to theoretical modeling of perception, by proposing a motor-sensory closed-loop scheme for the perception of the external environment.&quot; The crux proposal is that internal representation may be a time-varying signal that reaches a steady state behavior perhaps, if only because &quot;Mammalian sensory organs usually acquire information via movements…&quot;.</italic></p><p><italic>This is a &quot;Viewpoint&quot; with some original material as opposed to an &quot;Original Article&quot; per se. Yet it is timely and important. One would think that most rational neuroscientists would agree. Yet much of mammalian systems neuroscience went through a dark period of working with primarily anesthetized animals or highly constrained animals. This was particularly egregious in vision, where one could argue that a generation of neuroscientists attended to second-order effects to Hubel and Wiesel receptive fields while a basic role of visual areas for motion control went undiscovered until a few years back; see, e.g., Carandini (Nat Neurosci 2013), Bonhoeffer (Neuron 2012), and Stryker (Neuron 2010). The current work reviews this dark period, although the authors should note that some areas, including the study of the VOR and the OKR, the study of hippocampal function during learning and memory (2015 Nobel prize), and clearly the study of motor control for locomotion and manipulation, did not fall into this trap. The pioneering gating experiments of Chapin and Woodward (Exp Neurol 1982), which show how motor output gates sensation, deserve special mention as counterpoint to the authors' sarcasm, i.e., &quot;The (re) discovery that mammalian sensation is active…&quot;.</italic></p><p>Thank you for this concise summary. We would only comment here that our crux proposal is that the perception of external objects is a dynamical process encompassing loops that integrate the organism and its environment and converging towards organism-environment steady-states. We now emphasize this in the Abstract.</p><p>The Introduction was revised to cover (and cite) the studies mentioned above and the sarcastic term was removed (subsection “Sensation is normally active”, third paragraph).</p><p><italic>The authors propose that the internal representation of a stimulus depends on motor output. Thus, unless the animal acts on the information, one does not know if the representation, presumably the pattern of neurons spiking in different brain areas, is a complete or only a partial representation. Further, the partial representation could be too incomplete for action to occur. I think we all would agree. Many highly cited studies on internal representation view a change in motor output in response to a change in internal representation – which could be the act of pushing a lever to declare a sensorimotor process is terminating- as a gold standard. There is a fair literature on this – including the pioneering ICMS experiments of Newsome and colleagues (Nature 1990, J Neurophysiol 1992, Neuron 2014). In the vibrissa literature, which appears prominently in this manuscript, there are the reafferent coding studies of Kleinfeld and colleagues (J Neurophysiol 1997; Neuron 2011). The authors go through many arguments to describe why the notion of a motor-free, or open loop representation, will fail. A key argument involves the time it takes – presumably cycles of recurrence – to form an internal representation. This is reminiscent of the argument by Martin (TiNS 1988) on the formation of visual representation as a recurrent of feedback, which was written as a challenge to the feed forward processing implicit in the wiring maps of Feldman and Van Essen.</italic></p><p>Thank you for these valuable points. We have modified the text to refer to these points and cite the relevant papers – ICMS and confidence (subsection “CLP propositions”), reafference and efference-copy signals (subsection “Perceptual systems are organized as motor-sensory-motor (MSM) loops”) and feedforward versus recurrent processing (subsection “The open loop perception (OLP) doctrine”).</p><p><italic>Essential revisions:</italic></p><p><italic>The full reports of all reviewers are appended. All reviewers found merit with the timeliness and importance of the work but all reviewers also found faults that require attention. It is essential to address these issues:</italic></p><p><italic>1) Draw a clear distinction about dynamics that spread beyond sensory areas to involve decision making and motor output, each of which may contain local feedback loops, as opposed to brain-wide feedback dynamics per se.</italic></p><p>This distinction is now clearer. The common dynamics of all components of the relevant MSM-loop(s) is now clearly stated in the Abstract, subsection “CLP propositions”, I, the legend of <xref ref-type="fig" rid="fig5">Figure 5</xref> and the predictions section. The distinction from dynamics of local circuits, as in typical models of decision making, was also added (subsections “The open loop perception (OLP) doctrine” and “CLP propositions”, I).</p><p><italic>2) Provide clearer and more thoughtful experiments to distinguish between the manifestation of open loop and closed loop representation of the sensory world – at least an object!</italic></p><p>The predictions section was substantially revised. We have categorized the predictions in three groups, focusing on motor-to-sensory, sensory-to-motor, and convergence effects. We have also clarified all predictions, made them more explicit, added examples, and added points raised by the reviewers. In order to emphasize the differences between the predictions of the different schemes we are referring now to the invariant representation (IvR), instead of internal representation (IR), as the representational comparative variable throughout the article. We thank the reviewers for these comments, which significantly helped clarifying our thoughts.</p><p><italic>3) Properly define and clarify the output from the model / robot (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</italic></p><p>The output of the model, as demonstrated by the robot, is now clarified and explained. We modified the description substantially by simplifying the figure (<xref ref-type="fig" rid="fig7">Figure 7</xref>, now <xref ref-type="fig" rid="fig6">Figure 6</xref>) and extending the text (see below).</p><p><italic>Specific points:</italic></p><p><italic>Reviewer # 1 (annotated by BRE David Kleinfeld):</italic></p><p><italic>1) In their paper, “Perception as a closed-loop convergence process”, Ahissar and Assa conceptualize perception as an interactive dynamical process. Specifically the authors propose that perception is a convergence process that involves about 4 repeated sensory-interactions through which an object percept is dynamically generated. Further the authors emphasize the constitutive active nature of sensing and stress the presence of loops rather than of a feed-forward architecture in the brain.</italic></p><p><italic>DK: This summary is telling. The reviewer focuses solely on dynamics per se rather than on motor output and control as an integral part of sensation. This implies that the larger message from Ahissar and Assa may have failed to get through.</italic></p><p>We have modified the Abstract to sharpen the crucial suggestions of our hypothesis and make them more explicit, and in particular the crucial role of organism-environment loops. Also, our modifications throughout the paper were done with this issue in mind.</p><p><italic>2) The paper is a strange mix out high-level assumptions and details of rodent active touch. To me these two different levels never fully merged, i.e. it did not become clear to me, where in the rodent brain the dynamical process happens that forms the perceptual object.</italic></p><p><italic>DK: In fact, there is published evidence that all of vibrissa L5b cells (in both sensory and motor cortices) have a role in motor control; this goes back to work by Glickman. So this is a clear place to note the origin of a perception and one that is, in terms of hypothesis testing, (just barely) accessible with Ca<sup>2+</sup>-imaging.</italic></p><p>We probably failed to state it clearly. The dynamical process that forms the perceived object is occurring along the entire MSM-loop(s). Thus, in principle there is no single brain site that preferably represents the object. Still, the comment about L5b makes sense – we now added it to the list of potential tests for the dependency of perception on S-M coupling (subsection “II. The sensory-to-motor arc”). We also make clearer statements about the whole-loop representation in the Abstract and along the paper.</p><p><italic>3) The predictions that differentiate the OpenLoop and the ClosedLoop model of perception are neither very strong nor very clear. More work is required here.</italic></p><p><italic>DK: All reviewers agree on this point. The section on predictions is a crux aspect of the paper that requires significant improvement, as the key is to entice experimentalists to try to falsify or verify the ideas inherent in representation through motor control. This will take thought and time and still may not work out!</italic></p><p>The predictions section was substantially revised. Please see our detailed description in reply to Essential revisions (<xref ref-type="bibr" rid="bib136">2</xref>) above.</p><p><italic>4) I have major doubts that the authors are right. It is obvious from the literature that passive, or briefly flashed stimulus presentations, which do not allow active sensing, still evoke robust percepts. I would predict that we will find also a lot more single touch percepts in the active touch system, once we look harder in situations, where animals sensing under time pressure.</italic></p><p><italic>DK: I think the confusion results from a mixing of loops for perception, which are hypothesized to include sensory and motor function, and local sensory loops solely for reverberation. The latter are well known to occur with sensory processes, and the most dramatic case is the &gt; 20 s of reverberatory signal in AIT cortex during the delay period of a match to sample task (Fuster &amp; Alexander 1971 Science). Please clarify your text.</italic></p><p>We agree with the reviewer that briefly flashed stimuli evoke robust percepts. However, we argue that this observation is consistent with both OLP and CLP schemes. According to CLP such artificial stimuli initiate the perceptual process, which indeed normally would continue longer and include motor-sensory dynamics but which also can gain information from this initial step (<xref ref-type="fig" rid="fig5">Figure 5</xref> and associated text). What precludes discrimination between OLP and CLP based on flashed stimuli is that although the percepts evoked by flashed stimuli can be robust, they most likely include significantly less information than the information actively acquired from stationary objects. Subjects indeed can differentiate between flashed cars and houses, or animals and humans, but probably cannot perceive the details of the images. We have added a paragraph explaining this in subsection “I. Perception (of external feature(s)) ≡ a process of inclusion in MSM-loop(s)”, fourth paragraph.</p><p>We use the terms “most likely” and “probably” because we are not aware of a systematic quantitative comparison of perceptual accuracies of complex images when they are flashed versus being stationary. The first set of predictions in our list includes such a comparison (prediction I-ii; we now added the word “flashes” to make it more explicit) – there we suggest to equalize the total time or energy of the stimuli and thus to use a series of flashes rather than a single one.</p><p><italic>Reviewer # 2 (annotated by BRE David Kleinfeld):</italic></p><p><italic>1) The distinction between &quot;neural representation&quot; and &quot;internal representation&quot; seems unnecessary – and ill-defined.</italic></p><p><italic>DK: This should be fixed.</italic></p><p>We have fixed it. We now distinguish between a “Neuronal Representation” (NR), which can be any pattern that shows some correlation with the external feature, and the “Invariant Representations (IvR), which is <italic>the</italic> representation that represents the feature consistently and uniquely – i.e., it occurs <italic>always</italic> and <italic>only</italic> when that feature occurs. This is now explained better in the subsection “The open loop perception (OLP) doctrine”. The minimal sets for IvR according to each perceptual scheme are now described better in <xref ref-type="fig" rid="fig7">Figure 7</xref> (previously Figure 8), its legend and associated text (subsection “Contrasting OLP and CLP – discriminatory testable predictions”).</p><p><italic>2) Although I think I understand the intuition behind referring to a sensory-motor loop as &quot;motor-sensory-motor loop&quot;, this seems unnecessary; &quot;loop&quot; already implies circularity.</italic></p><p><italic>DK: I suspect that this was done to separate loops that are local and lie just in solely sensory or solely regions from brain-wide loops that span the nervous system. As noted above, this needs to be clarified.</italic></p><p>Both the criticism and comment are well taken. The major reason for using the term MSM-loop instead of MS-loop is that our repeated experience with presenting the ideas discussed in this paper to colleagues indicated that people often automatically refer to sensory-motor arcs, or to inter-modal sensory-motor loops, when sensory-motor loops are mentioned (see our <xref ref-type="fig" rid="fig4">Figure 4</xref>). Thus, many people imagine a kind of a loop that combines visual sensation with arm movement, for example, closing the loop via visual sensation of the arm. This is of course not what we refer to in this paper – we refer to loops that include only one sensory organ, control its movement and sense its signals. We try to emphasize the flow of the loop signals from and to the same sensory organ by using the term motor-sensory-motor loop. We have now expanded the explanation of this term (subsection “subsection “Perceptual systems are organized as motor-sensory-motor (MSM) loops”, third paragraph), which we believe will also help clarifying the scheme we are talking about.</p><p><italic>3) It is unclear to me what the distinction between msOLP and CLP is?</italic></p><p><italic>DK: Please either drop or clarify this issue. It should be a straight forward fix.</italic></p><p>This distinction is important, and we hope that we are now doing a better job in explaining it. The difference is that in msOLP there is no loop – the sensory-to-motor arc is open. We now explain it better in the subsection “Contrasting OLP and CLP – discriminatory testable predictions”, and emphasize it via the classification of our predictions.</p><p><italic>4) At times the argument is speculative and unnecessarily strong – to the point of likely already being wrong? E.g., in the subsection “Contrasting OLP and CLP – discriminatory testable predictions” &quot;the question is […] whether paralyzed subjects perceive. If they do – here goes the closed-loop hypothesis&quot;. We clearly perceive by hearing without moving. I will grant the authors that it is still unclear what the function of outer hair cells is – but as far as we know, this is a counter example to their hypothesis?</italic></p><p><italic>DK: please provide a more graded presentation. The manuscript started out this way, in that open loop representations were a primarily seen as a subset of the larger internal representation.</italic></p><p>The auditory case is indeed interesting. We agree with the reviewer that, based on currently available knowledge, it could very well be the case that hearing does not crucially depend on motor outputs. Yet, the experiment had not been yet done – one needs to paralyze or block the outputs to the outer hair cells and the muscles of the middle ear in order to test it. We now state it in the second paragraph of the subsection “Contrasting OLP and CLP – discriminatory testable predictions”.</p><p>There is an additional point here. The auditory stimulus is fundamentally different than the visual and tactile ones – it can never be stationary. There is no stationary acoustic wave. Thus, the inner hair cells are always activated by a sound. This makes the dependence on sensor motion less crucial. Thus, we have modified the question to “whether paralyzed subjects perceive stationary (i.e., not flashing or moving) objects similarly to non-paralyzed subjects” (see aforementioned paragraph). Given the reviewer’s comment we also found it important to elaborate further on the special case of auditory sensation.</p><p><italic>5) The &quot;mathematical model&quot; and the robotic setup seem to add little to the manuscript. The robotic system example only proves that an oscillatory system can be driven to different attractors with different inputs?</italic></p><p><italic>DK: All reviewers commented on the opaque nature of this presentation. It needs to be rewritten. I do not see a fundamental flaw.</italic></p><p>We agree with the criticism – the description was too laconic and encrypted. We modified this section substantially by simplifying the figure (<xref ref-type="fig" rid="fig7">Figure 7</xref>, now <xref ref-type="fig" rid="fig6">Figure 6</xref> – removing the open-loop responses) and explaining the outcome of the robotic model and its significance (subsection “Synthesis of CLP in a robotic setup”). We think that the demonstrations of how a convergence process may look like, and how a steady-state may look like, are of value in this paper as they can help the reader capturing the type of processes we refer to – we thus prefer to leave this section in.</p><p><italic>6) The testable predictions part is a great idea – but as formulated they are not very helpful. A specific motor output can be thought of as the correlate of a dynamic neural attractor instead of an &quot;instantaneous state&quot;.</italic></p><p><italic>DK: All reviewers agree. The section on predictions is a crux aspect of the paper that requires significant improvement, as the key is to entice experimentalists to try to falsify or verify the ideas inherent in representation through motor control. This will take thought and time and still may not work out!</italic></p><p>The predictions section was substantially revised. Please see our detailed description in reply to Essential revisions (2) above.</p><p><italic>Reviewer # 3 (BRE David Kleinfeld):</italic></p><p><italic>1) The statement that &quot;[motor-sensory-motor]-loops are fundamental units of mammalian perception&quot; cannot be right. These loops can support activity and thus a motor-sensory-motor representation, but anatomical loops per se is not a representation.</italic></p><p>Good point. Indeed, whenever we refer to MSM loops we refer to both their anatomical and functional levels. We are now stating this explicitly in the subsection “Perception can be masked “backwardly”.</p><p><italic>2) The discussion of two types of loops notes that the &quot;first uses proprioceptive signals […] The other type uses sensory signals to monitor features of external objects…&quot;. In fact, this extends confusion in the literature. Signals from muscle spindles, usually regarded as proprioceptive in the sense that are used only for motor feedback, are also sensory. See the pioneering work by Hsiao (2006 J Neurophysiol) on discriminating the size of objects based on muscle stretch.</italic></p><p>Another good point – thank you! Indeed, proprioceptive loops can provide (limited) information about external objects. For example, when a large error between the planned and executed movement occurs, an external object that blocks the movement is a natural interpretation of the brain. We now added this point and a citation of Hsiao’s paper in the subsection “The closed-loop perception (CLP) hypothesis”, last paragraph.</p><p><italic>3) The discussion of reading out the convergence, say, to a limit cycle is muddled. Are convergence cycles related to the accumulation of evidence? If so, it is an interesting idea. But the authors need to describe a mechanism to link dynamics with estimated of confidence. They end with &quot;although the loops never reach the ultimate steady-states, they typically quit the convergence process when the distance from that state is no more sensible&quot;. This seems too soft a statement for a serious article.</italic></p><p>In general we consider the formalization of the link between dynamics and confidence to lie outside the scope of the current paper. Yet, we agree that the description of possible mechanisms is in place here. We have thus added a paragraph describing the potential mechanism we prefer, which is based on internal models (subsection “I Perception (of external feature(s)) ≡ a process of inclusion in MSM-loop(s)”, fifth paragraph).</p><p><italic>4) The authors discuss the need to share information between limit cycles (perceptual loops). They are a bit glib in listing possibilities as the locking and unlocking of activity in different loops is essential to their scheme of hierarchical loops. Coherence between different loops is tricky – if the interactions cause a pair of loops to phase-lock, then it is not clear how they separate and dephase. The authors have neglected issues of noise, which is a mechanism to break locking and to dephase.</italic></p><p>We assume here that the loops composing an object perception remain engaged until the perceptual epoch ends. In this case dephasing will automatically follow. We have added a sentence mentioning that in the first paragraph of the subsection “II. Perception of an external object ≡ a coordinated process of inclusion in a collection of MSM-loops”.</p><p><italic>5) The equations for the SYCLOP model need to be explained. As it stands, this section will lose almost all readers. None of the symbols are explained. I would also start by saying that the simplest model of a loop uses Van der Pol relaxation dynamics. On the one hand it is a bit of a let-down to have the work condensed to a single oscillator that came out of the days of vacuum triodes. On the other hand, the presentation of the realization with the Van der Pol oscillator (<xref ref-type="fig" rid="fig7">Figure 7</xref>) is very condensed. I think <xref ref-type="fig" rid="fig7">Figure 7</xref> needs to be considerably unpacked. Panels A, B, and example dynamics like panel H can be one figure, while panels D-G and I could be a second figure. Also, define &quot;k-events&quot;, label the ordinates of panels H and I.</italic></p><p>The equations of the SYCLOP model are now better explained (subsection “Synthesis of CLP in a robotic setup”). The outcome of SYCLOP model is now described in detail and the motivation for using Van der Pol dynamics is now explained as well (in the aforementioned subsection).</p><p><xref ref-type="fig" rid="fig7">Figure 7</xref> (now <xref ref-type="fig" rid="fig6">Figure 6</xref>) was substantially simplified – the open-loop response panels were removed and the figure now conveys the main messages in a clearer manner.</p><p><italic>6) The authors end with a number of proposed experiments to address the claims of closed versus open loop object representation. One involves the detection of the phase of contact in the whisking cycle, yet is followed by the claim that &quot;…predictions of CLP and OLP can be distinguished only in natural perceiving conditions.&quot; This appears to obviate the use of head-fixed animals, an excellent preparation for combined behavior and electrophysiology. Why is head fixing bad for whisking? It seems that perception must often work under partial constraints.</italic></p><p>We agree. The scope of the term “natural conditions” is too wide. We have modified this paragraph substantially and now explain better which reductionist paradigms would not allow a meaningful testing of the hypotheses. We also now explain better in that paragraph how different conditions, including head fixation, should be taken into account (subsection “III. Motor-sensory-motor convergence”, last paragraph).</p><p><italic>[Editors' note: further revisions were requested prior to acceptance, as described below.]</italic></p><p><italic>The manuscript has been improved but there are a few remaining issues raised by the reviewer and verified by Reviewing editor Kleinfeld. In order to complete this odyssey, please address these queries.</italic></p><p><italic>1) In the subsection “Synthesis of CLP in a robotic setup”. Please expand on the solution of the model, a van der Pol oscillator, to make it transparent to the &quot;typical&quot; biologically trained reader. The statement &quot;The implementation of these equations using the SYCLOP platform&quot; needs to be detailed – even in the appendix – so a reader can duplicate your calculation.</italic></p><p>We have expanded on the solution of the model, and explained the choice of the van der Pol oscillator (subsection “Synthesis of CLP in a robotic setup”). We also provide more details on the SYCLOP implementation, and explain how the model equations were implemented (in the aforementioned subsection).</p><p><italic>2) In the subsection “Perception can be masked “backwardly”” – &quot;If perception could be reduced to a sequence of pure open loop processes backward masking should not occur.&quot; One might think that any slow integration step in a feed-forward processing system would explain backward masking through injection of a signal within the integration time. Perhaps your statement could be better explained as dependent on a system with only &quot;fast&quot; integration.</italic></p><p>The section on backward masking is now clearer. We explain the ‘standard model’ for open loop schemes, which is based on dual channel (fast and slow) integration and interaction (Breitmeyer &amp; Ogmen’s 2000, reference added), its inconsistency with experimental data, and the challenge it forms for OLP (subsection “Perception can be masked “backwardly”).</p><p><italic>3) In the subsection “Perception can be masked “backwardly”” – &quot;Perceptual masking thus challenges the validity of the 'virtual knife' reduction and the ability to reconstruct perception based on experiments with flashed stimuli only.&quot; The argument leading up to this is not clear.</italic></p><p>We hope that the improved explanation of the backward masking challenge (point 2) provides a better background for understanding the statement about the virtual knife. In addition, we have modified this sentence to be more explicit and clear (subsection “Perception can be masked “backwardly”). A related change was introduced in the fourth paragraph of the subsection “I Perception (of external feature(s)) ≡ a process of inclusion in MSM-loop(s)”.</p><p><italic>Finally, please reread the manuscript in a &quot;copy-edit&quot; manner to improve the grammar and correct any number of typos in punctuation.</italic></p><p>We have reread the entire paper, fixed typos and grammatical mistakes (with the aid of a linguistic editor) and improved the clarity of the text where needed – thanks for noting that. <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig7">7</xref> were slightly modified (<xref ref-type="fig" rid="fig1">Figure 1</xref>: eye – object arrows added; <xref ref-type="fig" rid="fig7">Figure 7</xref>: graphics).</p></body></sub-article></article>