<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">85300</article-id><article-id pub-id-type="doi">10.7554/eLife.85300</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Homophilic wiring principles underpin neuronal network topology in vitro</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Akarca</surname><given-names>Danyal</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5931-0295</contrib-id><email>danyal.akarca@mrc-cbu.cam.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="fn1">‡</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Dunn</surname><given-names>Alexander WE</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1504-499X</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="fn1">‡</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Hornauer</surname><given-names>Philipp J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2265-6679</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Ronchi</surname><given-names>Silvia</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Fiscella</surname><given-names>Michele</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Congwei</given-names></name><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author"><name><surname>Terrigno</surname><given-names>Marco</given-names></name><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author"><name><surname>Jagasia</surname><given-names>Ravi</given-names></name><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author"><name><surname>Vértes</surname><given-names>Petra E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0992-3210</contrib-id><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Mierau</surname><given-names>Susanna B</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Paulsen</surname><given-names>Ole</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2258-5455</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Eglen</surname><given-names>Stephen J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8607-8025</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Hierlemann</surname><given-names>Andreas</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3838-2468</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Astle</surname><given-names>Duncan E</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="fn2">§</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Schröter</surname><given-names>Manuel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9347-9203</contrib-id><email>manuel.schroeter@bsse.ethz.ch</email><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="fn2">§</xref><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con15"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>MRC Cognition and Brain Sciences Unit, University of Cambridge</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Department of Electrical and Electronic Engineering, Imperial College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>I-X, Imperial College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>Department of Physiology Development and Neuroscience, University of Cambridge</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>Department of Applied Mathematics and Theoretical Physics, University of Cambridge</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a28rw58</institution-id><institution>Department of Biosystems Science and Engineering in Basel, ETH Zurich</institution></institution-wrap><addr-line><named-content content-type="city">Zurich</named-content></addr-line><country>Switzerland</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00by1q217</institution-id><institution>NRD, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd</institution></institution-wrap><addr-line><named-content content-type="city">Basel</named-content></addr-line><country>Switzerland</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>Department of Psychiatry, University of Cambridge</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04b6nzv94</institution-id><institution>Division of Cognitive and Behavioral Neurology, Brigham &amp; Women’s Hospital</institution></institution-wrap><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff10"><label>10</label><institution>Harvard Medical School</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><addr-line><named-content content-type="city">La Jolla</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution></institution-wrap><addr-line><named-content content-type="city">Heraklion</named-content></addr-line><country>Greece</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="other" id="fn1"><label>‡</label><p>Co-lead first authors</p></fn><fn fn-type="other" id="fn2"><label>§</label><p>Co-lead senior authors</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>08</day><month>07</month><year>2025</year></pub-date><volume>14</volume><elocation-id>e85300</elocation-id><history><date date-type="received" iso-8601-date="2022-12-01"><day>01</day><month>12</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2025-07-03"><day>03</day><month>07</month><year>2025</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-03-10"><day>10</day><month>03</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.03.09.483605"/></event></pub-history><permissions><copyright-statement>© 2025, Akarca, Dunn et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Akarca, Dunn et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-85300-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-85300-figures-v2.pdf"/><abstract><p>Economic efficiency has been a popular explanation for how networks self-organize within the developing nervous system. However, the precise nature of the economic negotiations governing this putative organizational principle remains unclear. Here, we address this question further by combining large-scale electrophysiological recordings to characterize the functional connectivity of developing neuronal networks in vitro, with a generative modeling approach capable of simulating network formation. We find that the best fitting model uses a homophilic generative wiring principle in which neurons form connections to other neurons which are spatially proximal and have similar connectivity patterns to themselves. Homophilic generative models outperform more canonical models in which neurons wire depending upon their spatial proximity either alone or in combination with the extent of their local connectivity. This homophily-based mechanism for neuronal network emergence accounts for a wide range of observations that are described, but not sufficiently explained, by traditional analyses of network topology. Using rodent and human neuronal cultures, we show that homophilic generative mechanisms can accurately recapitulate the topology of emerging cellular functional connectivity, representing an important wiring principle and determining factor of neuronal network formation in vitro.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>generative models</kwd><kwd>neuronal networks</kwd><kwd>neuronal development</kwd><kwd>network science</kwd><kwd>high density micro electrode array</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/694829</award-id><principal-award-recipient><name><surname>Hornauer</surname><given-names>Philipp J</given-names></name><name><surname>Hierlemann</surname><given-names>Andreas</given-names></name><name><surname>Schröter</surname><given-names>Manuel</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MC-A0606-5PQ41</award-id><principal-award-recipient><name><surname>Akarca</surname><given-names>Danyal</given-names></name><name><surname>Dunn</surname><given-names>Alexander WE</given-names></name><name><surname>Astle</surname><given-names>Duncan E</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dy4aq19</institution-id><institution>James S. McDonnel Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Akarca</surname><given-names>Danyal</given-names></name><name><surname>Astle</surname><given-names>Duncan E</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04g6r1b21</institution-id><institution>MQ: Transforming Mental Health</institution></institution-wrap></funding-source><award-id>MQF17_24</award-id><principal-award-recipient><name><surname>Vértes</surname><given-names>Petra E</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/875609</award-id><principal-award-recipient><name><surname>Hornauer</surname><given-names>Philipp J</given-names></name><name><surname>Hierlemann</surname><given-names>Andreas</given-names></name><name><surname>Schröter</surname><given-names>Manuel</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003006</institution-id><institution>ETH Zurich</institution></institution-wrap></funding-source><award-id>PMB-01–18</award-id><principal-award-recipient><name><surname>Hierlemann</surname><given-names>Andreas</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id><institution>Swiss National Science Foundation</institution></institution-wrap></funding-source><award-id>205320_188910/1</award-id><principal-award-recipient><name><surname>Schröter</surname><given-names>Manuel</given-names></name><name><surname>Hierlemann</surname><given-names>Andreas</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02hdt9m26</institution-id><institution>Swiss Data Science Center</institution></institution-wrap></funding-source><award-id>C18-10</award-id><principal-award-recipient><name><surname>Schröter</surname><given-names>Manuel</given-names></name><name><surname>Hierlemann</surname><given-names>Andreas</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Functional connectivity in rodent and human neuronal cultures is best explained by homophilic wiring rules, in which neurons preferentially form connections depending on spatial proximity and shared connectivity patterns, suggesting a unifying principle across scales.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>During mammalian brain development, neuronal networks demonstrate remarkable self-organization that gives rise to complex topological properties, including a greater-than-random clustering and modular structure (<xref ref-type="bibr" rid="bib134">Sporns and Betzel, 2016</xref>; <xref ref-type="bibr" rid="bib103">Newman, 2006</xref>), the selective occurrence of specific network motifs (<xref ref-type="bibr" rid="bib113">Perin et al., 2011</xref>; <xref ref-type="bibr" rid="bib131">Song et al., 2005</xref>), hierarchies (<xref ref-type="bibr" rid="bib69">Hilgetag and Goulas, 2020</xref>), heavy-tailed connectivity distributions (<xref ref-type="bibr" rid="bib9">Alstott et al., 2014</xref>; <xref ref-type="bibr" rid="bib65">Hagmann et al., 2007</xref>), and richly interconnected hubs (<xref ref-type="bibr" rid="bib2">Achard et al., 2006</xref>; <xref ref-type="bibr" rid="bib35">Bullmore and Sporns, 2009</xref>). Studies have indicated that these distinctive characteristics likely endow neuronal networks with robustness and the capability to support dynamic functional computations (<xref ref-type="bibr" rid="bib82">Laughlin and Sejnowski, 2003</xref>; <xref ref-type="bibr" rid="bib102">Müller et al., 2020</xref>), however, our understanding regarding the underlying mechanisms and wiring rules that give rise to these features is still incomplete.</p><p>Neuronal network development can be characterized across spatial scales (<xref ref-type="bibr" rid="bib25">Betzel and Bassett, 2017</xref>; <xref ref-type="bibr" rid="bib124">Schröter et al., 2017</xref>). At the cellular level, neurons form computational units within circuits. Here, the role of individual neurons can be determined by a combination of factors, such as their laminar location, connectivity, neurochemical sensitivities, and morphology (<xref ref-type="bibr" rid="bib78">Kasai et al., 2021</xref>). During embryonic development, a series of spatiotemporally defined genetic and activity-dependent programs (<xref ref-type="bibr" rid="bib116">Pumo et al., 2022</xref>) regulate the expression of cell-type-specific recognition molecules to initiate axonal and dendritic outgrowth, which ultimately leads to the formation of synapses (<xref ref-type="bibr" rid="bib72">Jain et al., 2022</xref>; <xref ref-type="bibr" rid="bib135">Südhof, 2018</xref>; <xref ref-type="bibr" rid="bib158">Yogev and Shen, 2014</xref>). Although there is now a large body of evidence on the mechanisms of specific guidance cues during circuit formation (<xref ref-type="bibr" rid="bib122">Sanes and Zipursky, 2020</xref>), linking this knowledge to explain the emergence of complex topological features remains challenging.</p><p>At the whole-brain level in humans (<xref ref-type="bibr" rid="bib150">Vértes and Bullmore, 2015</xref>), connectivity between brain regions can be inferred via diffusion tensor imaging (DTI) (<xref ref-type="bibr" rid="bib76">Jones et al., 2013</xref>; <xref ref-type="bibr" rid="bib75">Jones and Leemans, 2011</xref>), as myelinated axonal connections, or functional magnetic resonance imaging (fMRI) (<xref ref-type="bibr" rid="bib129">Smith et al., 2013</xref>), as correlated patterns of activity. Inferring connectomes from fetal brains in utero (<xref ref-type="bibr" rid="bib141">Turk et al., 2019</xref>), or from preterm infants (<xref ref-type="bibr" rid="bib146">van den Heuvel et al., 2015</xref>), have confirmed the early presence of organizational hallmarks, such as hubs, a rich-club architecture, and a modular small-world organization. Building on such architectures, studies demonstrate that the functional role and organization of brain regions later on is shaped by their inter-regional connectivity and that a region’s inputs during development influences its functional specialization (<xref ref-type="bibr" rid="bib73">Johnson, 2011</xref>). This principle allows brain regions to undergo a spatially organized functional shift, for example, from distinct sensory and motor systems to more integrated connections with association cortices, likely supporting an acceleration in cognitive development (<xref ref-type="bibr" rid="bib52">Dong et al., 2021</xref>).</p><p>There is growing evidence that some key organizational properties of nervous systems are conserved across scales, and, in some cases, across species (<xref ref-type="bibr" rid="bib25">Betzel and Bassett, 2017</xref>; <xref ref-type="bibr" rid="bib124">Schröter et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Allard and Serrano, 2020</xref>; <xref ref-type="bibr" rid="bib26">Betzel, 2020</xref>; <xref ref-type="bibr" rid="bib29">Bogdan et al., 2022</xref>; <xref ref-type="bibr" rid="bib55">Engel et al., 2021</xref>; <xref ref-type="bibr" rid="bib161">Zheng et al., 2020</xref>). Nervous systems both at the macro- and micro-scale, for example, have been shown to entail a canonical pattern of small-worldness (<xref ref-type="bibr" rid="bib21">Bassett and Bullmore, 2017</xref>; <xref ref-type="bibr" rid="bib100">Muldoon et al., 2016</xref>), a rich-club topology (<xref ref-type="bibr" rid="bib66">Harriger et al., 2012</xref>; <xref ref-type="bibr" rid="bib144">van den Heuvel and Sporns, 2011</xref>; <xref ref-type="bibr" rid="bib140">Towlson et al., 2013</xref>) and a modular structure (<xref ref-type="bibr" rid="bib134">Sporns and Betzel, 2016</xref>; <xref ref-type="bibr" rid="bib96">Meunier et al., 2010</xref>). These complex organizational hallmarks allow for functional hierarchies, in which distinct segregated modules perform specialized local computations. While the later may reflect basic representational features of incoming signals, intermediary nodes integrate those signals to code for a more complex representation of the incoming signals (<xref ref-type="bibr" rid="bib90">Lord et al., 2017</xref>).</p><p>One prominent explanation for these consistent organizational hallmarks is that they reflect the economics of forming and maintaining connections (<xref ref-type="bibr" rid="bib36">Bullmore and Sporns, 2012</xref>; <xref ref-type="bibr" rid="bib37">Bullmore et al., 2016</xref>; <xref ref-type="bibr" rid="bib162">Zhou et al., 2022</xref>). Given finite available resources, trade-offs between incurred costs (e.g., material, metabolic) and functional value must be made continually by all distributed units to ensure optimal network function. In this view, ideas, such as Peters’ rule (<xref ref-type="bibr" rid="bib32">Braitenberg and Schüz, 1998</xref>), which suggest that synaptic contacts simply occur if neurons are close enough in space and if their axons and dendrites overlap, are not sufficient to explain the existence of a specific connection (<xref ref-type="bibr" rid="bib33">Briggman et al., 2011</xref>; <xref ref-type="bibr" rid="bib70">Holler et al., 2021</xref>; <xref ref-type="bibr" rid="bib99">Motta et al., 2019</xref>; <xref ref-type="bibr" rid="bib137">Takemura et al., 2015</xref>). Although spatial embedding and neuron morphology clearly have an impact on cortical network architecture (<xref ref-type="bibr" rid="bib57">Ercsey-Ravasz et al., 2013</xref>; <xref ref-type="bibr" rid="bib142">Udvary et al., 2022</xref>), costly features, such as long-range connectivity hub cells or regions, likely exist because they confer some additive functional value that outweighs the cost of its formation and maintenance (<xref ref-type="bibr" rid="bib36">Bullmore and Sporns, 2012</xref>). Such principles likely apply not only to the connectivity between brain regions, but also to the cellular and subcellular level (<xref ref-type="bibr" rid="bib82">Laughlin and Sejnowski, 2003</xref>; <xref ref-type="bibr" rid="bib150">Vértes and Bullmore, 2015</xref>; <xref ref-type="bibr" rid="bib142">Udvary et al., 2022</xref>; <xref ref-type="bibr" rid="bib43">Chen et al., 2006</xref>).</p><p>If an economic trade-off represents an important principle that guides network development, then it is important to consider the specific mechanisms that determine the outcome of this trade-off. Advances in generative network models (GNMs) provide a formal way of testing competing mechanistic accounts of network formation (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Arnatkeviciute et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib63">Goulas et al., 2019</xref>; <xref ref-type="bibr" rid="bib77">Kaiser and Hilgetag, 2004</xref>; <xref ref-type="bibr" rid="bib79">Klimm et al., 2014</xref>; <xref ref-type="bibr" rid="bib97">Morgan et al., 2018</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>; <xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>; <xref ref-type="bibr" rid="bib159">Yook et al., 2002</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>). These computational models simulate the probabilistic formation of networks over time under specific mathematical rules. For example, recent whole-brain DTI work has shown that structural inter-regional connectivity can be simulated with a GNM (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>) which uses a simple economic wiring equation balancing connection cost with topological value (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>). These two components together define the probability of connections forming iteratively over time. However, the extent to which such models reflect underlying biological processes remains unclear due to the indirect nature of in vivo imaging.</p><p>In the present study, we test whether key economic trade-off rules are also conserved at the cellular scale. Analyses are carried out on spike-sorted, high-density microelectrode array (HD-MEA) recordings that allow us to directly record from individual neurons and track both their activity and connectivity across development (<xref ref-type="bibr" rid="bib101">Müller et al., 2015</xref>; <xref ref-type="bibr" rid="bib126">Schröter et al., 2025</xref>; <xref ref-type="bibr" rid="bib120">Ronchi et al., 2021</xref>). Previous studies have quantified the functional couplings among neurons during spontaneous electrical activity and suggested that the local topological statistics are related to firing properties that may drive neuronal self-organization (<xref ref-type="bibr" rid="bib11">Antonello et al., 2022</xref>; <xref ref-type="bibr" rid="bib27">Blankenship and Feller, 2010</xref>; <xref ref-type="bibr" rid="bib153">Warm et al., 2022</xref>). Here, we expand on these analyses and use functional connectivity inferred for individual neurons tracked over several weeks to probe how spiking patterns of neurons facilitate the implementation of economic wiring. Moreover, we translate prior GNM research at the level of inter-regional brain connectivity (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Arnatkeviciute et al., 2021</xref>; <xref ref-type="bibr" rid="bib77">Kaiser and Hilgetag, 2004</xref>; <xref ref-type="bibr" rid="bib97">Morgan et al., 2018</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>; <xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>; <xref ref-type="bibr" rid="bib86">Liu et al., 2020</xref>) to the cellular scale, to test whether common generative wiring principles are recapitulated in vitro.</p><p>We acquire and analyze HD-MEA network recordings from populations of developing primary cultures (PCs) derived from dissociated embryonic rat cortices, three different lines of cell-type enriched human induced pluripotent stem cell (iPSC)-derived neurons, and sliced embryonic stem cell (ESC)-derived human cerebral organoids (hCOs). We compare the performance of different GNMs, and probe whether they can account for the emerging network topology. We also examine the effect of neuronal plating density (cell/mm<sup>2</sup>) on network topology and test whether GNMs can recapitulate the local organizational properties of the observed networks. Moreover, by chronically blocking GABA<sub>A</sub> receptors, we probe how GABAergic signaling impacts neuronal variability and the subsequent formation of connections in the network. Across four model types, comprising 13 wiring rules, we find that homophilic wiring reliably recapitulates the topology and developmental trajectory of neuronal networks at the cellular scale. Homophily may, therefore, represent an important wiring principle in which local network structure is refined via activity-dependent mechanisms.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Tracking developing neuronal networks at single-cell resolution</title><p>The datasets of this study comprise recordings of rodent and human neuronal networks that were plated and maintained on high-density multielectrode arrays (HD-MEAs; <xref ref-type="bibr" rid="bib126">Schröter et al., 2025</xref>) as previously described (<xref ref-type="fig" rid="fig1">Figure 1a</xref>; <xref ref-type="bibr" rid="bib120">Ronchi et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Bakkum et al., 2013a</xref>; <xref ref-type="bibr" rid="bib125">Schröter et al., 2022</xref>). Our primary analysis focuses on primary rat embryonic day 18/19 cortical cultures (PCs), which were plated at two different densities (sparse plating density: 50,000 cells per well, corresponding to 1000 cells/mm<sup>2</sup>; n=6 cultures; dense plating density: 100,000 cells per well, corresponding to 2000 cells/mm<sup>2</sup>; n=12 cultures) and used to follow neuronal network development across several weeks in vitro. <xref ref-type="fig" rid="fig1">Figure 1</xref> provides an overview of the experimental pipeline. We also analyzed human-induced pluripotent stem cell (iPSC)-derived neuron/astrocyte co-cultures, containing predominantly glutamatergic, dopaminergic, and motor neurons (plated at a density of 100,000 cells per array), as well as sliced human cerebral organoids (hCOs; n=6 slices). For the complete details of the datasets analyzed in the study, see Methods; <italic>Rodent primary cortical neuronal cultures; Human induced pluripotent stem cell-derived neuronal cultures; Human cerebral organoid slice cultures</italic>. All summary statistics across datasets are provided in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1a</xref>.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>High-density microelectrode array extracellular recordings of developing neuronal cultures.</title><p>(<bold>a</bold>) Scanning electron microscope (SEM) image of primary neurons plated on a high-density microelectrode array (HD-MEA; neurons are colored in red, electrodes in green; the electrode center-to-center distance is 17.5 μm). (<bold>b</bold>) Activity scan across the entire HD-MEA for an example sparse primary cortical (PC) neuron culture at DIV 14. Colors depict the average absolute amplitude of online-detected multi-unit activity per electrode (yellow colors indicate the location of potential neurons, i.e., high amplitude deflection, on the array; the array dimensions are 120×220 electrodes; electrode amplitude values are averaged over 1 min recordings). (<bold>c</bold>) Example extracellular trace recorded from one electrode (10 s), with high action potential (AP) spiking activity and bursts (middle panel); a single AP is depicted in the lower panel. (<bold>d</bold>) Electrical footprint (EF) of a single spike-sorted unit on the HD-MEA. The EF is the AP-triggered extracellular potential signature of a single unit on the HD-MEA, here depicted across 16 electrodes of a high-density recording block in light gray: 100 AP-triggered cutouts for this EF; in black: the average EF. The lower panel shows a spike autocorrelogram for this unit. (<bold>e</bold>) Tracking of individual EFs across development in vitro. The upper panel depicts the EFs inferred for the four recording time points (DIV 7, 10, 12, 14); the lower panel shows the average activity of the tracked unit (bin size: 100 s; gray to black colors correspond to the four recording time points; 30 min per recording day). (<bold>f</bold>) Spontaneous electrical activity of neuronal cultures, their average firing rate, increased significantly with development (n=6 sparse rodent PC networks). (<bold>g</bold>) A spike raster plot shows the spike-sorted activity for one culture (300 s-long zoom in on a network recording with 134 units); the lower panel depicts the binned activity of the same recording (bin size: 0.1 s). All neuronal networks showed a mixture of regular and more synchronized activity periods (network bursts). (<bold>h</bold>) In order to probe neuronal network development, we used the spike time tiling coefficient (STTC) to infer functional connectivity statistically. The four parameters required to calculate STTC connectivity graphs between Unit A and Unit B are P<sub>A</sub>, P<sub>B</sub>, T<sub>A</sub>, and T<sub>B</sub>. T<sub>A</sub> is calculated as the fraction of the total recording time ‘tiled’ by ±Δ<italic>t</italic> of any spike from Unit A. P<sub>A</sub> is the proportion of spikes from Unit A, which lies within ±Δ<italic>t</italic> of any spike(s) of Unit B (spikes in red). The spike trains for Unit A and B are depicted as black bars; ±Δ<italic>t</italic> is depicted as blue lines for each spike. The significance of each STTC value was estimated against jittered surrogate spike train data. (<bold>i</bold>) The average STTC increased significantly with development (n=6 sparse rodent PC networks). (<bold>j</bold>) Example functional connectivity graph inferred from a DIV 14 PC network. Only the top 2% strongest connections are displayed; each dot represents the physical location of a putative neuron on the HD-MEA; the dot size corresponds to the nodal degree of the neuronal unit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Tracking neuronal networks at cellular resolution on high-density microelectrode arrays.</title><p>Boxplots depicting the number of units exceeding a firing rate of 0.01 Hz in the sparse rodent network dataset (left panel; plating density 50,000 cells per well; n=6 cultures), and in the dense rodent network dataset (right panel; plating density 100,000 cells per well; n=12 cultures) over developmental time. Blue-colored boxplots/dots indicate the results obtained from the spike-sorting/postprocessing pipeline used in the main report (see Methods); the boxplots/dots in black show the alternative postprocessing pipeline (Kilosort 2.5 and Bombcell quality control; see Methods and <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Global topological measures of sparse rodent cultures over time.</title><p>(<bold>a</bold>) Panel depicts the statistically inferred network density for the n=6 sparse rodent networks until days in vitro (DIV) 14. (<bold>b</bold>) Proportion of extant connection by distance and grouped by DIV 7 (pink), DIV 10 (light purple), DIV 12 (dark purple), and DIV 14 (dark blue). (<bold>c</bold>) The total degree for sparse rodent networks across development.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig1-figsupp2-v2.tif"/></fig></fig-group><p>To record the emerging spontaneous neuronal activity of neuronal cultures and to track developing rodent PC neuronal networks at single-cell resolution, we first acquired whole-array activity scans to localize the neurons (<xref ref-type="fig" rid="fig1">Figure 1b</xref>), and then selected up to 1024 readout electrodes, configured into 4×4 electrode high-density blocks (<xref ref-type="fig" rid="fig1">Figure 1d and e</xref>), at the respective recording start points (i.e. days in vitro (DIV) 7 for the sparse PCs and DIV 14 for the dense PCs networks). Recordings with the same electrode configuration were acquired at the consecutive recording time points and concatenated for spike sorting (<xref ref-type="bibr" rid="bib109">Pachitariu et al., 2016</xref>). Spike-sorted network data enabled us to assign the extracellular electrical activity to individual neurons and to follow them across development (<xref ref-type="fig" rid="fig1">Figure 1e</xref>; see also Methods; <italic>Spike-sorting and post-processing</italic>; number of neurons tracked for sparse rodent PC networks: 136±30 (mean±S.D.); number of neurons tracked for dense PC networks: 140±31; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). In line with previous works, we find that sparse rodent PC networks developed robust network burst activity (<xref ref-type="fig" rid="fig1">Figure 1c and g</xref>) and that the firing rate of tracked units increased significantly in the first weeks of development (repeated measures analysis of variance (rmANOVA): F(3,12)=7.02, p=5.62 × 10<sup>–3</sup>; <xref ref-type="fig" rid="fig1">Figure 1f</xref>).</p><p>To infer functional connectivity between neurons statistically and to characterize neuronal network development of tracked neurons over time, we computed the Spike Time Tiling Coefficient (STTC) among all neurons above a minimum firing rate threshold (0.01 Hz; <xref ref-type="fig" rid="fig1">Figure 1h–j</xref>; <xref ref-type="bibr" rid="bib48">Cutts and Eglen, 2014</xref>) and compared inferred empirical values to jittered surrogate values (see Methods; Functional connectivity inference). We use the STTC because it controls for the variability in firing rates between neuronal units and culture types. STTC values primarily reflect short-latency co-activity rather than firing rates per se (<xref ref-type="bibr" rid="bib48">Cutts and Eglen, 2014</xref>). Although considered a robust measure of pairwise correlations between spike trains, it is important to note that the connectivity graphs inferred by the STTC do not necessarily match the underlying synaptic connections (<xref ref-type="bibr" rid="bib50">Das and Fiete, 2020</xref>). We also apply a recently published transfer entropy (TE) algorithm to show that our results translate to other measures of connectivity (<xref ref-type="bibr" rid="bib127">Shorten et al., 2021</xref>). In line with previous research (<xref ref-type="bibr" rid="bib39">Cabrera-Garcia et al., 2021</xref>; <xref ref-type="bibr" rid="bib152">Walker et al., 2021</xref>), we find that overall STTC values increased with development (F(3,12)=11.82, p=6.77 × 10<sup>–4</sup>; <xref ref-type="fig" rid="fig1">Figure 1i</xref>), as did the network density of inferred functional connectivity graphs (F(3,12)=11.08, p=8.97 × 10<sup>–4</sup>, sparse rodent PC networks; <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2a</xref>). The probability of inferred STTC connections decayed with inter-neuronal distance (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2b</xref>).</p></sec><sec id="s2-2"><title>Generative network models of functional neuronal networks in vitro</title><p>Following STTC connectivity inference, we set out to describe the topology of these networks using graph theory, which provides a mathematical framework for capturing the topological properties of each node within the network, and the network as a whole. In <xref ref-type="fig" rid="fig2">Figure 2a</xref>, we highlight three common topological measures (nodal degree, clustering, and betweenness centrality) and one geometric measure (edge length) that we will use throughout the current paper (see Methods; <italic>Network statistics</italic> for more details; <xref ref-type="bibr" rid="bib35">Bullmore and Sporns, 2009</xref>; <xref ref-type="bibr" rid="bib121">Rubinov and Sporns, 2010</xref>). In <xref ref-type="fig" rid="fig2">Figure 2b</xref>, we show how these statistics allowed us to compute the node-wise statistics for each functional connectivity graph, and to establish the distribution of different statistics across the network.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Probing wiring principles via generative network models.</title><p>(<bold>a</bold>) Example networks highlighting four common graph theoretical metrics. For each schematic, the node size corresponds to the respective graph statistic, and we provide the statistic within the node. The panel on the left shows a schematic for the degree (blue), which relates to the total number of edges that each node has. The left-middle panel shows the clustering coefficient (green), which is a measure of how nodes in a graph tend to cluster together; the right-middle panel shows the betweenness centrality (pink), which relates to the number of shortest paths in the network which pass through the node; the panel on the right shows a schematic for the total edge length (yellow), which relates to the total sum of the edge lengths among all its connections for each node. (<bold>b</bold>) Functional connectivity graphs, as inferred from high-density microelectrode array (HD-MEA) network recordings, were characterized by graph theoretical means. Each panel on the top row shows an example schematic network, with the node size corresponding to the respective graph statistic (degree, clustering, betweenness centrality, total edge length). The lower row shows histograms with the distribution of the metric across the network. (<bold>c</bold>) The generative network model works by simulating network development probabilistically according to the costs incurred in the network (here reflected by the <italic>D<sub>i,j</sub></italic> term, which is modeled as the Euclidean distances) and the topological values. Both terms are parameterized, meaning that for each simulation, there is an altered tuning in how costs and values influence the probability with which nodes form connections iteratively. Parameters (η and γ) alter direction and magnitude to which the costs and values, respectively, influence wiring probabilities. For any combination of wiring parameters, we simulate a network developing over time until it reaches the number of connections, m, equal to the observed empirical network. (<bold>d</bold>) Comparing the simulated and empirically observed network, we fit the generative network model to achieve a simulation that is the least dissimilar to the observation. This is quantified by the energy equation and is shown by dark blue in the parameter space. The energy equation is given by the maximum Kolmogorov-Smirnov (KS) statistic across degree, clustering, betweenness centrality, and edge length. Each parameter combination is plotted on an energy landscape, which demarcates the model fits across the two-dimensional parameter space. Lower energy values correspond to better fits.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Distribution of inter-neuronal Euclidean distances across rodent and human datasets.</title><p>(<bold>a</bold>) Density plot of inter-neuronal Euclidean distances for each culture. Note that each matrix was used as the <italic>D<sub>i,j</sub></italic> term for the generative model constructed for each time point of that culture. For all distributions, we plot the total set of distances between neurons, irrespective of the inferred functional network. Panel <bold>a</bold> depicts Euclidean distances for the sparse rodent networks (50,000 cells per well); the top panel shows the overall distributions; the bottom panel shows the individual distance matrices. (<bold>b</bold>) Euclidean distances for the dense rodent networks (100,000 cells per well). Panels (<bold>c</bold>-<bold>e</bold>) show Euclidean distance distribution across the iPSC-derived human neuron lines at DIV 28 (<bold>c</bold>, glutamatergic;<bold> d</bold> motor and <bold>e </bold>dopaminergic neurons). (<bold>f</bold>) Euclidean distances for the human cerebral organoid recordings.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig2-figsupp1-v2.tif"/></fig></fig-group><p>Although graph theoretic measures provide a way to mathematically formalize the topology of networks, they do not provide an explanation as to what topological attachment principles may have shaped network development. To do this, we tested 13 wiring rules that may best explain the self-organization of cellular-level functional connectivity graphs over time. Each of these 13 rules that we tested is given in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref>. To simplify, for the main report, we group the 13 rules into four broader attachment mechanisms by which they work: (i) <italic>Homophily</italic>, where a neuron, <italic>i</italic>, preferentially wires with another neuron, <italic>j</italic>, as a function of the similarity between <italic>i</italic> and <italic>j</italic> in terms of the other neurons they connect to (we expand on this later). (ii) <italic>Clustering</italic>, where neuron <italic>i</italic> preferentially wires with neuron <italic>j</italic> as a function of neuron <italic>i</italic> and <italic>j</italic>’s independently computed clustered connectivity, or (iii) <italic>Degree</italic>, the number of their connections. (iv) <italic>Spatial</italic>, where neurons only wire with other neurons as a function of the physical distance between each other.</p><p>We start with a model in which <italic>spatial proximity</italic> is the exclusive determining factor for the emergence of a connection. If neurons connect according to Ramón y Cajal’s laws of conservation (<xref ref-type="bibr" rid="bib40">Cajal et al., 1995</xref>), balancing the costs of connections with the functional benefits that they provide, one may predict neurons would simply connect to their geometrically closest neighbors to minimize the cost of maintaining connections (<xref ref-type="bibr" rid="bib124">Schröter et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Bullmore and Sporns, 2012</xref>; <xref ref-type="bibr" rid="bib40">Cajal et al., 1995</xref>). However, other network models incorporating the principle of preferential attachment, such as the Barabási-Albert model (<xref ref-type="bibr" rid="bib19">Barabasi and Albert, 1999</xref>), suggest that a “rich-get-richer” principle may drive the emergence of topology. This is where the more connections a neuron has, the greater the probability of forming more connections - thus leading to scale-free, power law degree distributions (<xref ref-type="bibr" rid="bib159">Yook et al., 2002</xref>; <xref ref-type="bibr" rid="bib19">Barabasi and Albert, 1999</xref>). Therefore, we also apply <italic>degree-based models</italic>, where connections are more likely the more connections one or both neurons have. Another canonical network model, the Watts–Strogatz model (<xref ref-type="bibr" rid="bib154">Watts and Strogatz, 1998</xref>), illustrates how networks deal with the tradeoff between local and global processing—nodes form clusters at the cost of global integration, though local topology is key for modular structure and regional functional specialization, hence are a key component of small-world networks (<xref ref-type="bibr" rid="bib154">Watts and Strogatz, 1998</xref>). We, therefore, include <italic>clustering-based models</italic>. However, clustering-based rules compute how many neighbors of neuron <italic>i</italic> are connected to each other and how many of neuron <italic>j</italic>’s neighbors are connected to each other, separately—they are not necessarily part of the same cluster with the same neighbors. Thus, the benefit of a connection between <italic>i</italic> and <italic>j</italic> may be less than if they had similar neighbors. This could provide a mechanism for neurons with similar functional purposes to connect. Hence, we also include <italic>homophily-based models</italic> based on similarity in neighborhoods between neuron pairs.</p><p>We undertook our simulations using a generative network model, which was previously used to probe whole-brain network organization (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>), to determine to what extent these models and findings generalize to the microscale. Generative network models develop in silico networks according to an economic trade-off, in which new connections are iteratively formed depending on both the modeled costs and values (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). The generative algorithm is expressed as a simple wiring equation (<xref ref-type="bibr" rid="bib77">Kaiser and Hilgetag, 2004</xref>; <xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>), which is updated over time:<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  P_{i,j}\propto \, \left (D_{i,j}\right)^{\eta }\left (K_{i,j}\right)^{\gamma },$$\end{document}</tex-math></alternatives></disp-formula></p><p>where the <italic>D<sub>i,j</sub></italic> term represents the ‘costs’ incurred between neurons modeled as the Euclidean distance between tracked neurons <italic>i</italic> and <italic>j</italic> (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). The <italic>K<sub>i,j</sub></italic> term represents how single neurons <italic>i</italic> and <italic>j</italic> ‘value’ each other, given by an arbitrary topological relationship which is postulated a priori (also termed ‘wiring rule’ given mathematically in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref>). <italic>P<sub>i,j</sub></italic> reflects the probability score of forming a fixed binary connection between neurons <italic>i</italic> and <italic>j</italic>. This is proportional to the parametrized multiplication of costs and values. Two wiring parameters, η and γ, respectively, parametrize the costs and value terms, which calibrate the relative influence of the two terms over time on the likelihood of forming a connection in the next step. We detail the generative network algorithms used in Methods; <italic>Generative network model</italic>. By iterating through different <italic>K<sub>i,j</sub></italic> terms and wiring parameter combinations, we can formally assess how variations in the generative model give rise to synthetic networks, which are statistically similar to those experimentally observed (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). Note that while these models are categorized by the network measures they incorporate (e.g. clustering, homophily), they do not necessarily maximize these properties explicitly but rather use them as the mechanism to form connections when balanced against distance. To assess this similarity, the first test comes in the form of an energy function (<xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>), which computes the Kolmogorov-Smirnov (KS) distance between the observed and simulated distributions of individual network statistics. It then takes the maximum of the four KS statistics considered so that, for any simulation, no KS statistic is greater than the energy:<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  Energy=max\left (KS_{k},KS_{c},KS_{b},KS_{d}\right),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <italic>KS</italic> is the Kolmogorov-Smirnov statistic between the observed and simulated networks at the particular η and γ combination used to construct the simulation, defined by the network degree k, clustering coefficient c, betweenness centrality b and Euclidean edge length d. These four measures are critical statistical properties of realistic networks, have been used in prior GNM research to benchmark model fits (<xref ref-type="bibr" rid="bib43">Chen et al., 2006</xref>; <xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>; <xref ref-type="bibr" rid="bib86">Liu et al., 2020</xref>), and have featured within well-documented simulated network models (<xref ref-type="bibr" rid="bib154">Watts and Strogatz, 1998</xref>; <xref ref-type="bibr" rid="bib6">Albert and Barabási, 2002</xref>; <xref ref-type="bibr" rid="bib22">Beasley and Rodgers, 2012</xref>).</p><p>For each empirical network, we simulated 20,000 networks across a wide parameter space (with η and γ limits –10 to 10) across the 13 wiring rules and for each network across all available time points. In the present study, we used this wide parameter space as there is little prior work guiding our choice of parameters; we also did not select a seed network. A Voronoi tessellation procedure (<xref ref-type="bibr" rid="bib86">Liu et al., 2020</xref>) was used as the parameter selection algorithm (see Methods; <italic>Parameter selection</italic> for details). Foreshadowing our findings, we report all optimized model parameter fits and energy values across all analyzed datasets in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1c</xref>.</p></sec><sec id="s2-3"><title>Homophilic wiring principles recapitulate the topology of developing rodent neuronal networks in vitro</title><p>Previous studies employing generative models of human macroscopic structural brain organization have shown that generative rules based on homophilic attachment mechanisms can achieve very good model fits (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>; <xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>). Homophily-based wiring prioritizes the wiring of nodes preferentially to those with overlapping connectivity patterns (e.g. via neighborhoods or connectivity profiles). For example, under a matching generative model (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>), if two nodes have a large proportion of their connections with the same nodes, they will have a correspondingly high matching score because they have similar connectivity profiles. This matching score is <italic>homophilic,</italic> because the measure is defined in terms of similarity (the Greek <italic>homós</italic>, ‘same’) and preference (<italic>philia</italic>, ‘liking’). To test what generative models can best simulate microscale connectivity, we applied the generative procedure to inferred STTC functional connectivity graphs.</p><p>We first investigate the sparse rodent PC networks at DIV 7, 10, 12, and 14. As previously shown (<xref ref-type="fig" rid="fig1">Figure 1</xref>), PC rodent networks underwent significant developmental changes during this time period, reflected by large changes in their functional networks in terms of increasing number of connections and network density (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). We find that, over the developmental time course, generative models utilizing the homophilic attraction principle as their generative mechanism produce networks with better model fits (lower energy values) compared to the degree-, clustering-, and spatially based rules tested (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). By DIV 14, homophily alone performs best (p&lt;4.11 × 10<sup>–5</sup> for all pairwise comparisons and Cohen’s <italic>d</italic>&gt;1.46 reflecting a very large effect size; <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1d</xref> shows all statistical comparisons). The single best performing homophily model, according to the energy equation, was the ‘matching model’ (see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref> for detail), which generates network topology according to the overlapping connectivity between nodes. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> shows comparisons across individualized models and across significance thresholds. This model, in contrast to non-homophily models, uniquely generates low model fits and optimized model parameters independent of the increasing correlated activity and changing topology of the networks over this developmental period (see <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref> for more details).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Homophilic principles underpin rodent primary network development and explain variance in their maturational trajectories.</title><p>(<bold>a</bold>) The top row shows a representative sparse rodent primary cortical (PC) network developing over the first two weeks in vitro on the high-density microelectrode array (HD-MEA) (DIVs 7, 10, 12, and 14; sparse neuron plating density; gray nodes correspond to single neurons; the size of each neuron corresponds to its nodal degree). Below, we show the energy of the top performing (n=1) simulated networks, given across the four main categories of studied wiring rules (with all models plotted, grouped by their rule). Boxplots represent the median and interquartile range (IQR); outliers are demarcated as small black crosses and are those which exceed 1.5 x the IQR away from the top or bottom of the box. (<bold>b</bold>) Exemplary immunohistochemical staining of a rodent PC culture (control experiment; NeuN staining in blue, βIII-tubulin in red, and Synaptophysin in green). (<bold>c</bold>) All energy landscapes of DIV 14 networks, plotted on top of each other, under the matching generative network model (a homophily model). (<bold>d</bold>) Cumulative density functions (CDFs) of the matching generative model, showing that simulated and observed statistics overlap very well. CDFs are shown across the four network statistics included in the energy equation of the top = 99 simulations for the matching model (best performing generative model) compared to an observed network (black line). Subsequent p<sub>rank</sub> values were computed using a Monte Carlo sampling procedure. (<bold>e</bold> and <bold>f</bold>) Simulated network trajectories were examined to determine if the later generative model’s trajectory (DIV 14) recapitulated earlier observed statistics. Simulated network statistics were derived by computing the modularity Q statistics (<bold>e</bold>) and global efficiency (<bold>f</bold>), at each time-point, within the generative model that was best fit to the DIV 14 networks. Results were scaled to the age of the culture so that observations and simulations could be compared directly, where 50% of the simulated time corresponds to DIV 7 and 100% of simulated time corresponds to DIV 14. Note that simulated time here refers to the percentage completion of the simulation, rather than the number of connections added, so that cultures could be aligned based on time. The quoted r and p values correspond to the Pearson’s correlation between observed and simulated statistics shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Generative network modeling results for the sparse rodent cultures.</title><p>Generative model fits (energy), including all 13 wiring models, for the sparse rodent networks (50,000 cells per well plating density; n=6 cultures) across development. Each boxplot presents the median and interquartile range (IQR). Outliers are demarcated as small black crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box. Generative model performance over time according to the energy equation. In each box, the energy of the top <bold>a</bold> n=1, <bold>b</bold> n=10, and <bold>c</bold> n=50 performing simulations, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Generate network model fits as a function of binarization threshold.</title><p>Comparison of (<bold>a</bold>) network density and (<bold>b</bold>) generative network model fits for the sparse rodent networks (50,000 cell per well plating density; n=6 cultures) at DIV 14 indicates that the observed ordering in energy values is robust against different significance thresholds. As expected, the network density decreased with more conservative thresholds (smaller alpha values). For all alpha values &lt;0.05, we can reproduce the same ordering of network model fits as reported in the main manuscript. Boxplot colors and ordering of generative models are the same as depicted in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. Each boxplot presents the median and interquartile range (IQR). Outliers are demarcated as small black crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Generative model outcomes as a function of empirical network data.</title><p>(<bold>a</bold>) For the sparse rodent networks (50,000 cells per well; n=6 cultures × 4 time-points) across development (DIV 7, DIV 10, DIV 12, DIV 14) we computed the Pearson correlation between the empirical activity/network measures (x-axis) and the energy (left box), η (middle box), γ (right box) across generative models (key provided on the right). Only significant correlations are provided, with non-significant (p&gt;0.05) values grayed out. The circle, triangle and star shapes highlight what plots are plotted subsequently in the remaining panels and pertain to the matching model (generative model 2) and the best performing non-homophily model - the degree average model (generative model 3).(<bold>b</bold>) Under the matching generative model, the relationship between model energy and the mean spike time tiling coefficient (STTC) (left), network density (middle) and modularity (right) is non-significant. (<bold>c</bold>) Under the degree average generative model (the best non-homophily) model, the relationship between model energy and the mean STTC (left), network density (middle) and modularity (right) is positive. This suggests that as networks develop and form more correlated activity, become denser and less modular, this model performs worse. (<bold>d</bold>) Under the matching generative model, the relationship between the optimized η and the mean STTC (left), network density (middle) and modularity (right) is non-significant. (<bold>e</bold>) Under the matching generative model, the relationship between the optimized γ and the mean STTC (left), network density (middle) and modularity (right) is non-significant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Alternative generative model procedures.</title><p>Generative model fits (energy), including all 13 wiring models, for sparse primary rodent networks (n=6 cultures) at DIV 14. (<bold>a</bold>) Generative models fit only using the wiring term (<italic>K<sub>i,j</sub></italic>) when forming networks. (<bold>b</bold>) Random null models. Completely randomized networks (size- and density-matched, left) and networks which have been partially randomized via the <italic>randmio_und</italic>() function, using the Maslov-Sneppen algorithm (<xref ref-type="bibr" rid="bib94">Maslov and Sneppen, 2002</xref>), which rewires each edge approximately five times. In the case of completely random networks (left), there is no difference in relative performance across wiring rules, because the optimal parameter fit is achieved when both wiring parameters are set to zero, as this generates a totally random topology regardless of the rule. (<bold>c</bold>) Inferred transfer entropy (TE) networks. As the TE is a directed graph, we show the results for the symmetrized network (left); out-connections (middle) and in-connections (right). For each graph, the boxplot presents the median and interquartile range (IQR). Outliers are demarcated as small black crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box. Generative model performance over time according to the energy equation. In each box, the energy of top n=1 performing simulation is shown. (<bold>d</bold>) The relationship between the energy acquired from the same networks derived from the spike time tiling coefficient (STTC) (x-axis) and the TE algorithms (y-axis) is consistently positive; with TE derived from symmetrical TE connections, i.e., keeping only reciprocal edges (left; <italic>r</italic>=0.849, p=8.97 × 10-22), derived from all out TE connections (middle; <italic>r</italic>=0.867, p=9.55 × 10-25), derived from all in TE connections (right; <italic>r</italic>=0.901, p=2.91 × 10-29).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Generative model fits recapitulate observed network statistics.</title><p>Cumulative density functions (CDFs) of the top = 99 simulations (of the total 20,000 simulations) for the best performing generative models in each class (<bold>a</bold>, spatial. <bold>b</bold>, matching. <bold>c</bold>, clustering average.<bold> d</bold>, degree average) across the four statistics included in the energy equation (top four panels) and two additional metrics - the local efficiency (gray) and participation coefficient (yellow) - not included in the energy equation (bottom two panels). For visualization, we show only the solutions for a single sparse rodent culture. p values were computed using the Monte-Carlo bootstrapping procedure (see Methods; <italic>Generative network models</italic>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig3-figsupp5-v2.tif"/></fig></fig-group><p>To assess the extent to which these findings go beyond what may be expected by chance, we further examined model performances across a range of alternative procedures for formalizing the generative models, including a <italic>K<sub>i,j</sub></italic> only formalization (where space has no influence), comparison to density- and size-matched random null models, and a comparison of our networks to those constructed using transfer entropy (TE), which is a model-free effective connectivity measure. We find that, regardless of the model specification or connectivity measure tested here, homophily performs best when approximating the sparse empirical networks relative to all other models but not randomized networks (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). For instance, in symmetrized TE networks (i.e. keeping only reciprocal connections), homophily models also perform best (p&lt;1.95 × 10<sup>–6</sup> for all pairwise comparisons and Cohen’s d&gt;1.12 reflecting a very large effect size). Furthermore, there is a clear alignment in the generative properties of the networks irrespective of if they were constructed using the STTC or TE, demonstrated by a very large positive correlation in their subsequent model energies (<italic>r</italic>=0.849, p=8.97 × 10<sup>–22</sup>, <italic>r</italic>=0.867, p=9.55 × 10<sup>–25</sup> and <italic>r</italic>=0.901, p=2.91 × 10<sup>–29</sup> when considering TE symmetrical, in or out (directed) connections, respectively compared to the STTC functional connectivity graphs; see <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4d</xref>).</p><p>In <xref ref-type="fig" rid="fig3">Figure 3b</xref> we show an exemplary immunohistochemical staining of a PC rodent network on an HD-MEA; <xref ref-type="fig" rid="fig3">Figure 3c</xref> shows the energy landscapes acquired from the matching generative model at DIV 14. The matching generative model, beyond providing the lowest energy values (i.e. very good model fits compared to other models), also produced synthetic networks whose aggregate nodal distributions were statistically indistinguishable from the experimentally observed networks (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). We formally demonstrated this using a Monte Carlo sampling procedure (<xref ref-type="bibr" rid="bib22">Beasley and Rodgers, 2012</xref>) to directly compare the statistics produced by the well-performing simulations with our empirical observations (degree, p<sub>rank</sub> = 0.645; clustering, p<sub>rank</sub> = 0.590; betweenness, p<sub>rank</sub> = 0.815; edge length, p<sub>rank</sub> = 0.585; for details of this procedure, see Methods<italic>; Cost functions</italic>). In <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref> we provide the same bootstrapping analysis, but for each of the best performing generative models of each model class (spatial, clustering average, and degree average models). It is of note that this matching generative model was the only model that was able to produce statistically indistinguishable results when compared to the experimental observations; the next best performing non-homophily model, the degree average model, failed to approximate both the empirical edge lengths (p<sub>rank</sub> = 0.025) and participation coefficients (p<sub>rank</sub> = 0.04).</p><p>Next, we asked how well generative models would approximate the time-course trajectories of neuronal network formation. An advantage of the GNM approach is that it allows one to decompose the developmental trajectory. Indeed, if networks are developing according to a homophilic attachment principle then the statistical properties of those simulated trajectories should vary in accordance with our longitudinal observations. To test this, we computed and compared the trajectories of two global network measures of segregation (modularity index Q; <xref ref-type="bibr" rid="bib103">Newman, 2006</xref>) and integration (global efficiency; <xref ref-type="bibr" rid="bib81">Latora and Marchiori, 2001</xref>) across the time course of sparse rodent PC network development. We used these measures because they were both not included in the energy equation (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>)—and it is well established that they capture fundamental aspects of how efficient information can be processed across networks (<xref ref-type="bibr" rid="bib49">Damicelli et al., 2019</xref>; <xref ref-type="bibr" rid="bib60">Fair et al., 2007</xref>). Next, we selected the best-fitting model at DIV 14 and decomposed the simulated trajectories up to that point. This allowed us to test whether these simulated trajectories were consistent with the earlier longitudinal observations at DIV 7, 10, and 12.</p><p>To do this, we compared each of the longitudinal observations (DIV 7, 10, 12, and 14) to the simulation at the corresponding time point of the DIV 14 developing simulation (i.e. DIV 7, 50%; DIV 10, 71%; DIV 12, 86%, and DIV 14, 100% of the simulated time). <xref ref-type="fig" rid="fig3">Figure 3e and f</xref> shows the developmental trajectories of modularity and global efficiency for individual simulations (the gray lines) along with the overlaid observed time points. Simulations using the homophily generative model clearly captured the same developmental trend for modularity (decreasing over time) and efficiency (increasing over time) and accounted for a substantial amount of variance in both metrics (modularity: R<sup>2</sup>=38.2%, <italic>r</italic>=0.618, p=1.28 × 10<sup>–3</sup>; efficiency: R<sup>2</sup>=48.9%, <italic>r</italic>=0.699, p=1.46 × 10<sup>–4</sup>).</p></sec><sec id="s2-4"><title>Topological fingerprints arise from homophilic mechanisms in developing neuronal networks in vitro</title><p>We have shown that homophily-based generative models produce synthetic networks which are statistically similar to observed functional rodent PCs networks. However, this similarity depends upon the maximum <italic>KS</italic> distance of the four topological statistics as defined in the energy equation. Crucially, this means that while experimentally observed and simulated network statistical distributions mirror each other at the <italic>global</italic> level, the <italic>topological fingerprint</italic> (<italic>TF</italic>) of these network statistics may still differ. That is, nodes within simulated and observed networks could have different <italic>local</italic> relationships to one another, because node-wise local organizational properties are not captured per se by the existing energy equation. Previous studies have investigated how well generative models can recapitulate local organizational properties and the location of features, such as hub-nodes in the <italic>C. elegans</italic> connectome (<xref ref-type="bibr" rid="bib85">Lindfield and Penny, 2019</xref>) or MRI-inferred human brain networks (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Arnatkeviciute et al., 2021</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>).</p><p>This can be exemplified by the topological relationship between central and peripheral nodes. Nodes which score high in centrality measures (e.g. <italic>betweenness centrality</italic>—which determines how many shortest paths pass through—as shown by the red node in <xref ref-type="fig" rid="fig4">Figure 4a</xref>, left) tend <italic>not</italic> to sit within segregated modules, meaning it is common that they concurrently score low in measures of segregation (e.g. clustering coefficients, in which neighbors connect to each other). The opposite is true for peripheral nodes (see the green node in <xref ref-type="fig" rid="fig4">Figure 4a</xref>). This means that when correlating measures of centrality with measures of clustering across a network, the correlation tends to be negligible or negative (<xref ref-type="bibr" rid="bib90">Lord et al., 2017</xref>; <xref ref-type="fig" rid="fig4">Figure 4a</xref>, right).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Homophilic generative mechanisms capture the local topology in developing neuronal networks.</title><p>(<bold>a</bold>) Schematic illustrating the inference of topological fingerprints (TFs). A TF measure is computed as the Pearson’s correlation matrix among several topological statistics at the nodal level (degree, clustering, betweenness, edge length, efficiency, and matching). Each node in <bold>a</bold> corresponds to a single neuronal unit/neuron. The right panel shows the negative correlation between clustering and betweenness, which captures an aspect of the topological structure of the network shown on the left. The color bar is clipped to +/-1 (blue/yellow) for clarity. (<bold>b</bold>) The <italic>TF<sub>dissimilarity</sub></italic> measures the extent to which GNM simulations capture the topological structure of the experimentally inferred networks. Homophily generative models, and spatial models show the lowest <italic>TF<sub>dissimilarity</sub></italic>, suggesting that both can reconstruct local connectivity patterns in vitro (n=6, sparse PC networks; boxplots present the median and IQR; outliers are demarcated as small gray crosses, and are those which exceed 1.5 x the interquartile range, IQR). (<bold>c</bold>) Averaged <italic>TF</italic> matrix for the empirically observed data (on the left; DIV 14), versus the GNM results obtained from models with the best fits, i.e., the lowest energy values obtained for each model class: the matching rule (top left panel), the clustering-average rule (bottom left panel), the degree-average rule (top right panel) and the spatial mode (bottom right panel). Each node-wise measure used within the correlation matrix is plotted (left). As matching is an edge-wise measure, the matching calculation presented on row six was derived as a node-wise average. (<bold>d</bold>) This plot depicts the relationship between energy and <italic>TF<sub>dissimilarity</sub></italic> values for each sparse PC network broken down by generative rule class (spatial in yellow, homophily in red, clustering in green, degree in blue). Each dot indicates the value of the two model fit functions for a single simulated network.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Homophilic generative mechanisms account for local relationships in developing dense rodent neuronal networks.</title><p>(<bold>a</bold>) Homophily generative models produce the lowest topological fingerprint (<italic>TF) dissimilarity</italic> for dense rodent networks (DIV 14 and 28), suggesting that it can reconstruct the local connectivity patterns of in vitro neuronal networks. In total, there are n=12 data points (one per culture) shown in each of the 13 boxplots. Boxplots present the median and interquartile range (IQR). Outliers are demarcated as small gray crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box. (<bold>b</bold>) A visualization of the averaged topological organization matrix for the observed (left), matching (middle left), degree-average (middle), clustering-average (middle right), and spatial (right) models at DIV 28.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Relationship between model energy and topological fingerprint dissimilarity in dense rodent neuronal cultures.</title><p>Using dense primary cortical (PC) rodent networks (100,000 cells per well), we show n=156 data points (n=12 cultures x n=13 generative model simulations) corresponding to the top n=1 performing simulation’s energy and its topological fingerprint dissimilarity performances at DIV 14.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig4-figsupp2-v2.tif"/></fig></fig-group><p>To assess the ability of generative models to capture these types of local relationships in settings with no anatomical reference space (as neurons are randomly distributed on the HD-MEAs), we provide a very simple cost function, here termed <italic>topological fingerprint dissimilarity</italic> (<italic>TF<sub>dissimilarity</sub></italic>). The <italic>TF<sub>dissimilarity</sub></italic> demarcates the ability of in silico network simulations to recapitulate observed local hallmarks of organization. It is defined as:<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  TF_{dissimilarity}=\sqrt{\underset{i}{\sum }\underset{j}{\sum }\left (TF_{observed_{ij}}-TF_{simulated_{ij}}\right)^{2}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>The <italic>TF</italic> is defined by the n-by-n correlation matrix of n local network statistics for the observed network (<italic>TF<sub>observed</sub></italic>) and its corresponding (simulated) network (<italic>TF<sub>simulated</sub></italic>). The <italic>TF<sub>dissimilarity</sub></italic> is subsequently equivalent to the Euclidean norm (<xref ref-type="bibr" rid="bib85">Lindfield and Penny, 2019</xref>) of the difference between observed and simulated topological correlation matrices. Here, we use six common measures of topology to compute the <italic>TF</italic> matrix (see Methods; <italic>Cost functions</italic> for details). <italic>TF<sub>dissimilarity</sub></italic> serves as a unitary measure of the difference between the simulated and observed networks in terms of <italic>local</italic> topology, in contrast to the energy metric which reflects <italic>global</italic> topology. <xref ref-type="fig" rid="fig5">Figure 5a</xref> provides a schematic of how the <italic>TFs</italic> were constructed.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Effect of plating density on network topology and generative network principles.</title><p>(<bold>a</bold>) Correlation matrix for global network statistics calculated across sparse (lower triangle) and dense (upper triangle) primary cortical (PC) cultures shows a highly similar covariance structure; colors indicate the Pearson’s correlation coefficient. Elements (5,9) and (9,5) of the correlation matrix are further highlighted in panel. (<bold>b</bold>) This plot shows the correlation between efficiency and small-worldness, for sparse and dense networks (<italic>r</italic>=−0.822, p=2.73 × 10<sup>–14</sup>); each point in the scatter plot corresponds to a single network. (<bold>c</bold>) Sparse (50,000 cells per well) and dense (100,000 cells per well) PC networks can be best simulated by the homophily generative models (DIV 14). Note that the leftmost boxplot is the same as that given in <xref ref-type="fig" rid="fig3">Figure 3a</xref>. (<bold>d</bold>) The energy landscapes for the matching generative network model landscapes inferred for the sparse and densely plated PC networks (DIV 14; see also <xref ref-type="fig" rid="fig3">Figure 3c</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Comparison of global network statistics across sparse and dense rodent networks at DIV 14.</title><p>(<bold>a</bold>) Comparisons were computed for network density, total local efficiency, edge length, matching, betweenness, modularity, strength, total degree, clustering and small-worldness. For each comparison, we provide the p-value computed from a Mann-Whitney U test. Sparse rodent networks were plated at 50,000 cells per well, dense networks were plated at 100,000 cells per well. Note here that the edge length refers to the average length of existing functional connections in the network. This measure contrasts with <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> which shows the inter-neuronal Euclidean distances between all neurons, irrespective of the inferred functional network. (<bold>b</bold>) Direct comparisons of the generative model fits (energy), including all 13 wiring models, for the sparse (left) versus dense-plated (right) rodent networks at DIV 14. Boxplot colors and ordering of generative models are the same as depicted in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. The boxplot presents the median and interquartile range (IQR). Outliers are demarcated as small black crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box. Generative model performance over time according to the energy equation. In each box, the energy of top n=1 performing simulation is shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Generative network modeling results for the dense rodent cultures.</title><p>Generative model fits (energy), including all 13 wiring models, for the dense rodent networks (100,000 cells per well; n=12 cultures) across development showing the top-performing parameter combination. Boxplots present the median and interquartile range (IQR). Outliers are demarcated as small gray crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig5-figsupp2-v2.tif"/></fig></fig-group><p>If homophily is a plausible attachment mechanism by which single neurons together form networks, we should expect homophily-based GNMs to produce networks with a local topological structure resembling the observed data. To probe this (dis)similarity, we calculated the <italic>TF<sub>dissimilarity</sub></italic> between each experimentally inferred functional connectivity graph and the best-performing simulated network (according to the energy equation), for each of the 13 generative models, and across all recording time points (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><p>Results demonstrate that synthetic networks generated with homophilic attachment rules provide the lowest <italic>TF<sub>dissimilarity</sub></italic> from DIV 12 onwards (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). These rules also result in the statistically smallest <italic>TF<sub>dissimilarity</sub></italic> at DIV 14 (compared to degree rules: p=1.91 × 10<sup>–3</sup>, Cohen’s <italic>d</italic>=1.34; compared to clustering rules: p=1.37 × 10<sup>–7</sup>, Cohen’s <italic>d</italic>=2.59). Of note, homophily and spatial rules could be distinguished significantly at DIV 12 (p=9.96 × 10<sup>–4</sup>) but not at other time-points (e.g. at DIV 14; p=0.0952), possibly indicative of spatial costs driving the topological fingerprint at this level of plating density (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1e</xref>). Interestingly, replicate analyses in the denser PC rodent dataset provided almost identical results (at DIV 14 and 28), but with an even stronger distinguishability of homophilic rules relative to spatial models (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1f</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), possibly reflecting a weaker preponderance of costs driving topology. The left-most panel in <xref ref-type="fig" rid="fig4">Figure 4c</xref> shows the experimentally observed <italic>TF</italic> matrix averaged over n=6 sparse PC networks; the adjacent panels show average <italic>TF</italic> matrices for the matching, clustering-average, degree-average, and spatial generative models. Depicted are the best-performing models within their generative rule class.</p><p>In sum, our results highlight the importance of assessing GNM simulation performance both in terms of overall global topology (<italic>energy</italic>) and the local topology generated (<italic>TF</italic>). We find that homophily models concurrently outperform the other models on both fronts (<xref ref-type="fig" rid="fig4">Figure 4d</xref>, see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> for a replication analysis in the dense rodent PC network dataset).</p></sec><sec id="s2-5"><title>Functional topology and generative model outcome hold in both sparse and dense rodent cultures</title><p>So far, we mainly quantified STTC connectivity graphs derived from sparse PC neuronal networks, that is, cultures plated with an initial density of 50,000 cells per well (corresponding to a plating density of ~1000 cells/mm<sup>2</sup>). Of note, the actual numbers of cells on the HD-MEAs are likely smaller due to incomplete adherence of cells to the HD-MEA and naturally occurring cellular processes such as apoptotic cell death that occur during the first weeks in vitro (<xref ref-type="bibr" rid="bib108">Opitz et al., 2002</xref>; <xref ref-type="bibr" rid="bib157">Xing et al., 2021</xref>; see Methods; <italic>Rodent primary cortical neuronal cultures</italic>). Despite some research on the effect of plating density on the emergence of population activity in vitro (<xref ref-type="bibr" rid="bib151">Wagenaar et al., 2006</xref>; <xref ref-type="bibr" rid="bib71">Ivenshitz and Segal, 2010</xref>; <xref ref-type="bibr" rid="bib45">Cohen et al., 2008</xref><italic>),</italic> synaptic strength and connectivity (<xref ref-type="bibr" rid="bib20">Barral and Reyes, 2016</xref>), there is currently no consensus as to how different plating densities affect neuronal topology. As one critical element of the generative network model is the geometric spacing between neurons, we next probed whether our findings in sparse cultures generalize to networks at higher neuronal plating densities. Therefore, we recorded a second independent dataset of more densely plated rodent PC networks (100,000 neurons per well, corresponding to a plating density of ~2000 cells/mm<sup>2</sup>, n=12; see Methods; <italic>Rodent primary cortical neuronal cultures</italic>) in the exact same way as outlined for the first PC rodent dataset and directly compared both densities at DIV 14.</p><p>We found that only the empirical edge lengths and global clustering differed between sparsely versus densely plated PC networks; dense networks showed relatively shorter connections (Mann-Whitney U, p=0.0125) and were more topologically clustered (p=0.0135). All other tested metrics remained very comparable (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). The global correlational structure of these statistics also remained stable (<xref ref-type="fig" rid="fig5">Figure 5a and b</xref>). Given the topological differences in edge lengths and global clustering, we then asked whether this also translated into significant changes in the energy values among the 13 tested generative network models. In <xref ref-type="fig" rid="fig5">Figure 5c</xref>, we show that the model energy is unaffected by plating density (homophily between plating densities, p=0.191). All statistical comparisons, for each time point in the dense PC networks, are presented in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1g</xref>; results demonstrate stability not only at DIV 14, but also at a later time point (DIV 28). In <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>, we show the same results, but broken down by each individual model, in addition to showing that this result also holds when considering the average energy over variable best-performing parameter combinations. In <xref ref-type="fig" rid="fig5">Figure 5d</xref>, we show the energy landscape for both plating densities, which again are very similar.</p></sec><sec id="s2-6"><title>Effect of GABA<sub>A</sub> receptor antagonism on network development and dynamics</title><p>Previous studies have shown that GABAergic interneurons can act as network hubs and regulate synchronicity of spontaneous activity between neurons that is critical for the formation of connections (<xref ref-type="bibr" rid="bib31">Bonifazi et al., 2009</xref>; <xref ref-type="bibr" rid="bib46">Cossart, 2014</xref>; <xref ref-type="bibr" rid="bib64">Hafizi et al., 2021</xref>). The role of GABAergic interneurons during development is also relevant for understanding their function in more mature brain circuits (<xref ref-type="bibr" rid="bib31">Bonifazi et al., 2009</xref>; <xref ref-type="bibr" rid="bib46">Cossart, 2014</xref>; <xref ref-type="bibr" rid="bib83">Le Magueresse and Monyer, 2013</xref>; <xref ref-type="bibr" rid="bib92">Mann et al., 2009</xref>). Moreover, alterations in the ratio of GABAergic interneurons and glutamatergic projection neurons, respectively, the balance of excitation and inhibition, has been implicated in many neurodevelopmental disorders (<xref ref-type="bibr" rid="bib111">Paterno et al., 2020</xref>). Ionotropic GABA<sub>A</sub> receptors are known to mediate fast inhibitory transmission in the cortex (in contrast to slow inhibition mediated by metabotropic GABA<sub>B</sub> receptors; <xref ref-type="bibr" rid="bib92">Mann et al., 2009</xref>; <xref ref-type="bibr" rid="bib139">Terunuma, 2018</xref>) and are critical for persistent network activity required for behavioral functions (<xref ref-type="bibr" rid="bib111">Paterno et al., 2020</xref>). However, the role played by GABA<sub>A</sub> receptors in functional network development is not fully understood. Furthermore, absence of GABA could also delay the developmental switch in GABA polarity from depolarizing to hyperpolarizing (<xref ref-type="bibr" rid="bib61">Ganguly et al., 2001</xref>). Therefore, it is unclear how cellular-scale functional networks would develop in the absence of GABA<sub>A</sub> receptor-mediated inhibition and whether connections would form based on homophily as seen in our previous results. It is also unknown whether effects of perturbation to GABA<sub>A</sub> receptor-mediated inhibition transmission on network activity and functional connectivity would be reversible.</p><p>To address this, we cultured sparse rodent PC neurons under chronic application of media without gabazine (n=6, control) or with gabazine (n=9 gabazine-treated), a selective GABA<sub>A</sub> receptor antagonist (see Methods; <italic>Pharmacological experiments</italic>). Following chronic application of gabazine for two weeks, we washed out gabazine at DIV 14 and performed a final recording at DIV 15 in a subset of six cultures of the gabazine-treated dataset (n=6, termed washout) to determine the extent to which the cultures recovered. We first examine the differences in spiking dynamics and functional connectivity resulting from GABA<sub>A</sub> blockade. Next, we examine changes in energy across rules and parameter values within the best-performing rule. We asked whether GABA<sub>A</sub> receptor blockade affected network formation by (a) preventing any clear connectivity principle being implemented above the others (where all models have the same energy), (b) altering the connectivity principle being implemented (where a different model than homophily has the lowest energy), or (c) altering how homophily is implemented (where homophilic models still have the lowest energy but parameter directions or magnitudes are altered).</p><p>The six control and nine gabazine-treated cultures were compared using Mann-Whitney tests; the six gabazine cultures recorded at DIV 14 were compared to their respective recordings at DIV 15 with Wilcoxon signed-rank tests. In line with previous research (<xref ref-type="bibr" rid="bib157">Xing et al., 2021</xref>; <xref ref-type="bibr" rid="bib18">Baltz et al., 2010</xref>), we find that chronic application of gabazine has a significant impact on single-cell and network firing patterns. Compared to controls, gabazine-treated networks show a more stereotypic burst behavior with less variation in interburst intervals (CV of IBI, Mann-Whitney U: p&lt;0.001; n=6 controls; n=9 gabazine-treated; <xref ref-type="fig" rid="fig6">Figure 6</xref>). Moreover, we find a trend towards lower firing rates during chronic gabazine treatment at DIV 14 (p=0.0567), which was reversed following washout (DIV 15; Wilcoxon signed rank: p=0.0156; n=6). Burst rates and the fraction of spikes occurring in bursts were highly variable across gabazine-treated networks, and both metrics significantly decreased following washout (p=0.013). We provide a more detailed comparison of the spiking activity between control and gabazine-treated cultures in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Chronic block of GABA<sub>A</sub> receptors alters the wiring parameters of the homophily generative model.</title><p>(<bold>a</bold>) Representative neuronal population activity of a control/untreated (red, top) and gabazine-treated networks (bottom, blue) at DIV 14. In the gabazine condition, network burst activity is more strongly synchronized compared to the control networks. (<bold>b</bold>) Panel depicts that the number of putative inhibitory connections increased significantly following the washout of gabazine at DIV 14. Putative inhibitory connections were inferred by a cross-correlogram approach and using an algorithm to infer spike transmission probability, respectively, spike suppression (<xref ref-type="bibr" rid="bib56">English et al., 2017</xref>). (<bold>c</bold>) The energy of the top-performing (n=1) simulated networks, given across the four main categories of studied wiring rules. Boxplots represent the median and interquartile range (IQR); outliers are demarcated as small black crosses and are those which exceed 1.5 x the IQR away from the top or bottom of the box. Energy values and wiring parameters for each individual rule of the top performing (n=1) simulated networks across control, gabazine-treated, and washout cultures are shown in <xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4c</xref>, respectively. (<bold>d</bold>) The average probability score kernel density distributions (<italic>P<sub>ij</sub></italic>) for the control (brown), gabazine (cyan), and washout conditions (lilac) recorded in sparse primary culture networks across simulated network development. The average gabazine probability distribution is shifted to the right and flatter compared to the controls and the washout condition. This indicates that wiring becomes more random across all time points. In <xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4d</xref> we show all distributions used to construct these averages. Asterisk indicates p&lt;0.05.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Chronic gabazine application to block GABA<sub>A</sub> receptor activity led to changes in spiking patterns.</title><p>(<bold>a</bold>) Representative spike train raster plots from a control (upper panel), gabazine-treated culture (middle) and washed out gabazine-treated culture; the panel below shows the representative population activity vectors (activity is aggregated 1 s bins). Panels on the right of the temporal raster plots show example close-ups of 1 s time windows taken from time bins comprising either median network activity (left, indicated by cyan triangle) or peak network activity (right, indicated by yellow triangle). (<bold>b</bold>) A logarithmic histogram of interspike intervals (ISIs; upper panel) showing that gabazine relatively increases the proportion of very short ISIs and long ISIs, giving a bi-modal distribution, equivalent to periods of relative quiescence and periods of fast spiking (bursts). The spike time tiling coefficient (STTC) distribution (probability plotted on a log10 scale for visualization) shows gabazine-treated cultures had a far greater number of strongly correlated units compared to controls in which there were far fewer strong functional connections. (<bold>c</bold>) Cultures treated with gabazine showed decreased mean firing rate (Hz) of cellular activity compared to controls, but increased and more regular spiking and bursting activity (reduced coefficient of variation in inter-spike and inter-burst intervals). Gabazine treatment also led to much stronger edge weights (STTC values) and less positively skewed edge weight distributions (less positive skewness of STTC distribution)—this skewness in controls reflects the presence of high strength (hub) nodes. Asterisks, *, ** and *** indicated p&lt;0.05, 0.01, and 0.001, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Chronic gabazine application to block GABA<sub>A</sub> receptor activity led to changes in functional network topology.</title><p>(<bold>a</bold>) Representative examples of topological network plots from a sparse DIV 14 rodent culture (upper panel) and a culture treated with gabazine from DIV 1 (lower below). Each node (colored circles) represents the spatial location of a putative neuronal unit detected through spike sorting. Each edge (gray lines) represents a significant correlation in spiking activity between a pair of nodes. Functional connections were inferred using the spike timing tiling coefficient (STTC). The size of each node is proportional to the number of significant functional connections; its color reflects its spike rate. (<bold>b</bold>) Each dot represents a single neuronal unit. For both control cultures (upper; brown) and gabazine-treated cultures (lower; blue), there was no clear linear relationship between spike rate and mean STTC (average weight of all significant edges of a given node). Each group had similar firing rate distributions, though very different average functional connection weight distributions with gabazine-treated units being hyperconnected compared to controls. (<bold>c</bold>) A range of global topological metrics inferred from functional connectivity graphs of control (C) and gabazine (G) treated cultures. For each comparison, we provide the p-value computed from a Mann-Whitney U test. Asterisks, *, ** and *** indicated p&lt;0.05, 0.01 and 0.001, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig6-figsupp2-v2.tif"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 3.</label><caption><title>Inferring inhibitory connections using spike-transmission probabilities.</title><p>(<bold>a</bold>) An example deconvolved cross-correlation histogram (dCCH) to estimate the spike-transmission probability (STP) between two neurons in a culture treated with gabazine, and after washout. The median spike count prediction across time lag values is indicated by the orange line. (<bold>b</bold>) The same unit pair as in panel <bold>a</bold>, however, plotted with spike count relative to the prediction (dCCH after washout of gabazine). Red bars indicate where the spike count was lower than predicted in neuron <italic>j</italic> between 0–5ms after neuron <italic>i</italic> fired, thus indicating a putative inhibitory connection.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig6-figsupp3-v2.tif"/></fig><fig id="fig6s4" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 4.</label><caption><title>Comparison of generative model outcomes between control, gabazine-treated and washout conditions.</title><p>(<bold>a</bold>) Direct comparisons of the generative model fits (energy), including all 13 wiring models, for control (left) versus gabazine (middle) and washout (right) condition. The boxplot presents the median and interquartile range (IQR). Outliers are demarcated as small black crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box. In each box, the energy of top n=1 performing simulation is shown. (<bold>b</bold>) The energy landscapes of the matching generative rule for control (left) versus gabazine (middle), and after washout (right). (<bold>c</bold>) Wiring parameters of control (left; colored in red), gabazine (middle; colored in blue) and after washout (right; colored in purple) derived from the top n=1 performing matching simulation in terms of the wiring equation are shown. (<bold>d</bold>) The probability distributions for the control (top), gabazine (middle) and washout (bottom) condition were computed and scaled at 1% increments throughout the developmental course of the simulations. These distributions were averaged over time to form the mean probability distributions shown in <xref ref-type="fig" rid="fig6">Figure 6d</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig6-figsupp4-v2.tif"/></fig></fig-group><p>Control and gabazine-treated networks differed in global functional connectivity (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). Gabazine-treated cultures showed a reduction in the number of units forming significant functional connections (lower network size, p&lt;0.001, and total degree, p=0.012). Note that following washout, network size can change as only spiking neurons are counted as nodes for network size calculation. Network size did not increase significantly (p=0.0625) following washout, though there was a small increase in network size in five of the six washed out cultures (by 18.4 ± 6.2%). On average, gabazine-treated networks showed an increase in average STTC (Mann-Whitney U; p&lt;0.001), a higher network density (p=0.003), and a greater total edge length (p=0.026). Following the washout, average STTC (p=0.031), network density (p=0.031), and edge length (p=0.013) reduced significantly, resembling the untreated cultures. Whereas untreated cultures showed a small fraction of nodes with high nodal strength, indicative of potential hub nodes, we did not see this topological structure during chronic gabazine treatment. That is, control networks had a more positively skewed STTC distribution than controls (p=0.002). This is consistent with the notion that GABA<sub>A</sub> receptors are involved in the regulation of spiking activity and synchrony between neurons in the network, as this was altered by GABA<sub>A</sub> receptor block.</p><p>To further examine the extent to which washing out gabazine returned endogenous inhibitory activity as GABA<sub>A</sub> receptors were released from blockade, we also computed the spike transmission probability (STP) among neuronal units (<xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref>). This cross-correlogram-based metric has been used to identify spike transmission, respectively spike suppression, and to infer putative excitatory/inhibitory functional connectivity from on-going extracellular spiking activity (<xref ref-type="bibr" rid="bib133">Spivak et al., 2022</xref>). Indeed, we find that washout of gabazine led to a significant increase in the number of putative inhibitory connections (Wilcoxon signed rank: p=0.012; <xref ref-type="fig" rid="fig6">Figure 6b</xref>). It should be noted, however, that weaker inhibitory connections are likely missed with the applied STP approach (<xref ref-type="bibr" rid="bib56">English et al., 2017</xref>).</p><p>Despite alterations in cellular activity and functional network topology (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> and <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>), homophilic generative attachment rules were the best fitting models across both control, gabazine-treated, and washout conditions (<xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4a and b</xref>). However, gabazine cultures exhibit a higher energy relative to controls (p=0.0292; <xref ref-type="fig" rid="fig6">Figure 6c</xref>), which suggests that homophilic GNMs cannot approximate the functional topology of gabazine-treated cultures to the same extent as for control cultures. This finding supports our hypothesis that perturbing GABA<sub>A</sub> receptor-mediated inhibition alters functional network characterization, even though homophily remains the best-fitting model. After washout of gabazine, however, these same cultures exhibited homophily energy values indistinguishable from controls (p=0.285), which indicates that this effect may be reversible. <xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4c</xref> shows how gabazine cultures are best fit when the η homophily wiring parameter increases so that it is closer to zero, i.e., moving from more negative to less negative, decreasing in magnitude (p=0.0360). Lower magnitude η corresponds to a weaker influence of physical distance on the probability of forming connections. On the other hand, γ (which varies the extent to which homophily influences wiring probability) is unaffected (p=0.456). Hence, gabazine weakens the spatial extent of functional connectivity wiring, enabling longer-distance connections in the network.</p><p>Differences in wiring parameterization may reflect more fundamental differences in neuronal variability elicited via changes in the neural dynamics. Within the homophily generative model, connections form via continual negotiations between the modeled cost and self-similarity that is present between all neurons. If there are clear <italic>relative</italic> winners in this negotiation, for example, connections that are lower cost than all others and connections that are more homophilic than all others, these connections are more likely to form. Of note, the probability of a connection is proportional to the wiring parameter magnitudes (see <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). Mathematically, the <italic>P<sub>i,j</sub></italic> distribution would look like a canonical lognormal distribution that is found at many anatomical and physiological levels of the brain (<xref ref-type="bibr" rid="bib38">Buzsáki and Mizuseki, 2014</xref>; <xref ref-type="bibr" rid="bib89">Loewenstein et al., 2011</xref>), where a small number of possible candidate connections elicit a higher wiring probability while the majority remains low. However, in the example of gabazine, neuronal synchrony increases, which is equivalent to exhibiting less variability in spike times between neurons. Therefore, we hypothesized that this would lead to a flattening of this lognormal distribution, meaning that the resultant topology became more random (see Methods; Generative probability distributions for details). Indeed, in <xref ref-type="fig" rid="fig6">Figure 6d</xref> we show this to be the case: gabazine-treated networks exhibit a flattened <italic>P<sub>i,j</sub></italic> distribution relative to both controls (median <italic>P<sub>i,j</sub></italic> value = 0.135 and 0.322 for gabazine &amp; control, respectively; p=1.54 × 10<sup>–44</sup>, Cohen’s <italic>d</italic>=0.550) and also after gabazine washout (median <italic>P<sub>i,j</sub></italic> value = 0.179; p=5.04 × 10<sup>–8</sup>, Cohen’s <italic>d</italic>=0.196; see also <xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4d</xref>). This finding suggests that gabazine alters the network wiring distribution as to become more variable in its wiring preferences, rather than being specific to a relatively smaller number of candidate neurons that are deemed particularly valuable to wire with.</p><p>In summary, we find that homophily wiring rules are also the best fitting GNM for neuronal networks chronically treated with gabazine. For the latter, however, homophilic GNMs achieve worse fits compared to control cultures. At the level of model parameters, the homophily γ parameter remains stable over all conditions, but it is η - which alters the spatial extent over which wiring is constrained. Interestingly, following washout of gabazine at DIV 14, numerous topological characteristics are recovered. Within our simulations, the washout effect is reflected as a shift towards a more canonical lognormal connectivity distribution (<xref ref-type="bibr" rid="bib38">Buzsáki and Mizuseki, 2014</xref>).</p></sec><sec id="s2-7"><title>Probing generative wiring principles across different human neuronal networks</title><p>As shown in the previous section, patterns of neuronal spiking dynamics may have an effect on how rodent neurons form functional connectivity in vitro. However, to what extent this idea translates to, for example, networks comprising specific kinds of human neurons and their respective/varying spiking dynamics (<xref ref-type="bibr" rid="bib14">Bakken et al., 2021</xref>; <xref ref-type="bibr" rid="bib23">Berg et al., 2021</xref>) remains unclear. We start to address this question by applying GNMs to purified human iPSC-derived neuron/astrocyte co-cultures. GNM analyses were performed at a time point at which such cultures reach a state of relative maturity (DIV 28) (<xref ref-type="bibr" rid="bib120">Ronchi et al., 2021</xref>). The dataset for this analysis comprises purified glutamatergic neurons (GNs, n=8), motor neurons (MNs, n=7), and dopaminergic neuronal cultures (DNs, n=6). We also included slice cultures derived from 4-month-old human embryonic stem cell-derived cerebral organoids (hCOs, n=6 slices). Previous studies have indicated that hCOs develop functional networks with increasing complexity from as early as 90 days in vitro (<xref ref-type="bibr" rid="bib62">Giandomenico et al., 2019</xref>; <xref ref-type="bibr" rid="bib136">Szebényi et al., 2021</xref>). <xref ref-type="fig" rid="fig7">Figure 7a</xref> shows an immunohistochemical staining of a DIV 21 human iPSC-derived DN culture, expressing neuronal and astrocytic markers (MAP2, GFAP, and TH); <xref ref-type="fig" rid="fig7">Figure 7b</xref> shows stainings for hCOs slices (Tau, NeuN, and GFAP).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Generative network modeling across human monolayer neuron cultures and cerebral organoids.</title><p>(<bold>a</bold>) Immunohistochemical staining of a control dopaminergic neuron (DN) network (top panel: expression of GFAP in red, MAP2 in blue, TH in green, and DAPI in gray). (<bold>b</bold>) Immunohistochemical staining of a single human cerebral organoid (hCO) slice (Tau in green, NeuN in purple and DAPI in blue; bottom panel: Tau in green, GFAP in purple, and DAPI in blue). (<bold>c</bold>) Clustering of human and rodent neuronal cultures based on a t-distributed stochastic neighborhood embedding (tSNE). Each dot corresponds to one culture; similarity was estimated by correlating the spike train autocorrelograms across all datasets and by then applying the tSNE. (<bold>d</bold>) Representative population activity plots for networks of glutamatergic (left), motor (left middle), dopaminergic (right middle) iPSC-derived neuronal cultures and a hCO slice (right). (<bold>e</bold>) Global topological measures of human iPSC-derived neuronal networks at DIV 28: the mean spike time tiling coefficient (STTC) (top left), network density (top right), small-worldness (bottom left) and proportion of extant connections by distance (bottom right). (<bold>f</bold>) STTC functional connectivity measures and small-worldness of hCO slices including: average STTC (top left), network density (top right), small-worldness (bottom left), and connectivity as a function of distance (bottom right). (<bold>g</bold>) Functional connectivity graph inferred from a hCO slice. (<bold>h</bold>) Fits across generative model rules in human iPSC-derived neuronal networks (DIV 28) and hCOs (right). The energy of the top n=1 performing simulated networks are shown. Boxplots represent the median and interquartile range (IQR). Outliers are demarcated as small black crosses and are those which exceed 1.5 x in the IQR away from the top or bottom of the box. The asterisk reflects homophilic rules, which demonstrate statistically lower energy (p&lt;0.05) than other rules. All statistics are provided in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1h</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Spiking dynamics in human monolayer neuron and cerebral organoid cultures compared to rodent cultures.</title><p>(<bold>a</bold>) Temporal raster plots indicate the firing rates (spikes/s) of each cell line over consecutive 1 s time bins through 5 min of recording. Of the iPSC lines shown, motor neuron patterns most closely resemble the example rodent networks showing similar population bursts but lacking the variability across neurons, such as the subset of fast-spiking neurons (upper rows of rodent culture). 28-day-old dense rodent primary cortical (PC) networks (100,000 cells per well) are included here for comparison, as this is the latest time point recorded for the rodent PC cultures, and ostensibly the peak maturity in terms of network activity. Both glutamatergic and dopaminergic iPSC cultures showed highly regular network bursting activity, though at differing frequencies. Human cerebral organoid networks had fewer units but had periods of much higher firing rates. For each culture type, autocorrelograms of spiking activity are plotted to the right of each temporal raster plot. Autocorrelograms were constructed by first cumulatively concatenating spike times across all units in a recording into a single vector of spike times. The count of synchronous spikes across the network (in 1ms bins) was quantified across a range of time lags (zero lag was excluded). This indicates the degree of coactivation at various latencies. In all cell culture types, there was much higher spiking synchrony at shorter latencies indicated by peaks close to 0ms lag. However, rodent primary cultures (PCs) and human motor neurons (MNs) showed sharp declines in autocorrelation at longer latencies, indicating a strong preference for short latency, high frequency coactivation. Human glutamatergic (GNs) and dopaminergic (DNs) cultures had much greater autocorrelation at lag values further away from zero. This indicates coactivation at longer latencies and oscillatory network activity at slower frequencies. Human cerebral organoids (hCOs) were much more variable. (<bold>b</bold>) The autocorrelation vectors (autocorrelation at each lag value) across all cultures were correlated and a high level of concordance within culture sources in terms of latency.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig7-figsupp1-v2.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Replication of the main results using an alternative spike-sorting and postprocessing pipeline.</title><p>(<bold>a</bold>) Panel depicts the generative model energy values for the sparse (1000 cells/mm<sup>2</sup>) rodent cultures across DIV 7–14 (n=6 cultures; functional connectivity inferred through spike time tiling coefficient (STTC)) using an alternative spike sorting and postprocessing pipeline (see Methods). Panel<bold> b</bold> shows the results for the dense (2000 cells/mm<sup>2</sup>) cultures, and panel <bold>c</bold> shows the results for the human neuronal networks (GNs: glutamatergic neurons; MNs: motor neurons; DNs: dopaminergic neurons); the alpha value to threshold the STTC matrices was 0.001. Panel <bold>d </bold>depicts the results of the TE analysis (alpha value to threshold TE matrices: 0.01). Since the used generative network modeling algorithms had been developed for symmetric binary connectivity matrices, we show results across five variants of differently symmetrized TE matrices (left: keeping only the reciprocal connections; middle left: keeping all connections; middle/middle right: symmetrizing either the in or out connections; right: proportional thresholding of the symmetrized weighted TE matrices and keeping only the strongest 5% connections). Boxplot colors as defined in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. Boxplots present the median and IQR. Outliers are demarcated as small gray crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig7-figsupp2-v2.tif"/></fig><fig id="fig7s3" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 3.</label><caption><title>Replication of the main results on a validation dataset.</title><p>Generative network modeling results calculated on an independent dataset, comprising n=12 rodent networks at the sparse plating density (50,000 cells per well or 1000 cell/mm<sup>2</sup>). The recordings were performed at DIV 14. Results are based on binarized spike time tiling coefficient (STTC) functional connectivity matrices (alpha value to threshold STTC matrices: 0.001). The results of this validation dataset strongly resemble the original results reported for the sparse rodent networks in the main manuscript. Boxplot colors as defined in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. Boxplots presents the median and interquartile range (IQR). Outliers are demarcated as small gray crosses and are those which exceed 1.5 x the interquartile range away from the top or bottom of the box.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85300-fig7-figsupp3-v2.tif"/></fig></fig-group><p><xref ref-type="fig" rid="fig7">Figure 7c</xref> provides an overview of the human and rodent neuronal spiking dynamics. Following a t-distributed stochastic neighbor embedding (tSNE) analysis, we find that networks can be clustered well according to their spiking dynamics. The tSNE analysis is based on spike-train autocorrelograms, derived from the aggregated activity of each neuronal network (<xref ref-type="bibr" rid="bib114">Petersen et al., 2021</xref>; see Methods; <italic>Autocorrelogram analysis</italic>). Example network activity plots, illustrating the different firing dynamics and corresponding autocorrelograms, are shown in <xref ref-type="fig" rid="fig7">Figure 7d</xref>; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1a</xref>. Overall, activity-based tSNE clustering allows grouping of different monolayer human neuronal cell lines in space; greater spread/variability is observed for the hCO slices. MN dynamics appear closest to rodent primary cortical neurons (PCs) in the tSNE space, which is reflected by their similarity in ongoing spiking dynamics (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1b</xref>). Representative examples of the observed differences in population activities across different human neuron cultures are depicted in <xref ref-type="fig" rid="fig7">Figure 7d</xref>.</p><p>As for the rodent cultures, we constructed STTC functional connectivity graphs for all human neuron cultures and assessed key connectivity metrics and topology. <xref ref-type="fig" rid="fig7">Figure 7e</xref> and <xref ref-type="fig" rid="fig7">Figure 7f</xref> show these network statistics, respectively; <xref ref-type="fig" rid="fig7">Figure 7g</xref> provides an example of a functional network obtained from a hCO recording. It is notable that human iPSC-derived neuronal networks did not differ significantly in average STTC (ANOVA, p=0.0912). However, we find a significant difference in network density (p=1.02 × 10<sup>–4</sup>) and topological metrics, such as the small-world index (p=1.51 × 10<sup>–4</sup>). MNs show the highest network density, as inferred by the STTC, and small-worldness values within the range previously observed for the rodent PC networks.</p><p><xref ref-type="fig" rid="fig7">Figure 7h</xref> depicts the GNM results across all human monolayer and hCO cultures. Overall, generative model findings approximately mirror the similarity in their underlying spiking dynamics (<xref ref-type="fig" rid="fig7">Figure 7d</xref>), in that human MNs show an energy profile across generative models aligning with rodent cultures, followed by GNs (<xref ref-type="fig" rid="fig7">Figure 7h</xref> left and middle-left), homophilic rules p&lt;3.70 × 10<sup>–3</sup> for all pairwise comparisons and Cohen’s <italic>d</italic>&gt;0.772 reflecting large effect sizes. In contrast, DNs and hCOs, which show differing underlying dynamics, exhibit a very distinct profile with the degree average method achieving the lowest energy, but no non-spatial class of generative rules providing the statistically lowest energy (<xref ref-type="fig" rid="fig7">Figure 7h</xref>, middle-right and right). As noted previously, hCOs exhibited significant variability in their spiking dynamics and topology, and provided an energy profile somewhat resembling randomly rewired graphs (as in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, right). All statistical findings are provided in full in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1h</xref>.</p><p>In summary, GNMs based on homophilic wiring mechanisms best recapitulate functional network connectivity in vitro in rodent PC networks, particularly at later developmental stages (DIV 14 onwards). We replicate our main findings using alternative spike-sorting and postprocessing pipelines, and validate them on an independent dataset in <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplements 2</xref> and <xref ref-type="fig" rid="fig7s3">3</xref>, respectively. In a few cases, including some immature rodent PC networks and human neuron cultures, the degree-average-based model performs well, if not best. This may reflect differences in the underlying spiking dynamics and/or parameter choices during functional network inference (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Human GN and MN networks show the closest resemblance to rodent PC networks and as such, mirror their underlying homophilic generative mechanisms. Results in hCOs are as yet inconclusive, likely due to the observed variability in their spiking activity, the limited number of consistently active units per network, and the prolonged developmental timeline for establishing functional connectivity.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In the current study, we applied large-scale electrophysiological recordings to track and characterize single-unit functional connectivity as neuronal networks develop in vitro. We systematically tested which candidate topological attachment mechanisms could explain this developing self-organization, using a range of generative network models to simulate network formation in silico. In the majority of cases tested, we found that a model utilizing a homophilic attachment mechanism (<xref ref-type="bibr" rid="bib70">Holler et al., 2021</xref>) performed best. This model accurately captures the developmental trajectories of neuronal networks, their local topological organization, and highlights how neuronal variability is likely critical to the emergence of the canonical lognormal distribution (<xref ref-type="bibr" rid="bib38">Buzsáki and Mizuseki, 2014</xref>) of neuronal functional connectivity within networks. The apparent symmetry between these findings and previous work at various scales of analysis (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>; <xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>) and species (<xref ref-type="bibr" rid="bib43">Chen et al., 2006</xref>; <xref ref-type="bibr" rid="bib42">Carozza et al., 2023b</xref>) may have implications for the study of brain development.</p><sec id="s3-1"><title>Topological self-similarity as a driver of in vitro topology</title><p>In line with previous work, we find that functional connectivity increased with development, and that developing neuronal networks in vitro exhibited typical characteristics of complex network architecture seen across numerous scales (<xref ref-type="bibr" rid="bib123">Schroeter et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Downes et al., 2012</xref>). Our work demonstrates that, beyond the other tested models, homophily best recapitulates complex functional network topology in vitro.</p><p>Interestingly, we find that the degree-average model tends to consistently follow the performance of homophily in cultures that are relatively less complex (e.g. immature rodent cultures and human single-cell-type cultures) but do worse relatively later in development (e.g. <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Conceptually, the degree-average generative model prefers connection formation when both neurons simultaneously have large numbers of connections (given that <italic>γ</italic>&gt;0). Importantly, the degree-average model (as with all other models apart from homophily) treats the underlying computation for how networks form connections as entirely independent. That is, the computation for the probability to wire is made not with direct respect to any other node pair—it is made on each neuron before then performing some other operation (e.g. taking the average or maximum). In contrast, homophily is a function made with respect to the <italic>direct</italic> relationship between the connections of the neurons. This is a subtle but important theoretical distinction, because it highlights how homophily can occur via the local communication between neurons, where signals are propagated via their connections. This is likely critical, as any generative mechanism by which complex neurobiological networks develop are likely to emerge from these interactions between the local components over time (<xref ref-type="bibr" rid="bib73">Johnson, 2011</xref>)—without a central mechanism aiming to optimize its global network properties (<xref ref-type="bibr" rid="bib91">Malkov and Ponomarenko, 2016</xref>). It is important to note, however, that the present study focuses on functional connectivity, rather than structural connectivity, and this separation is discussed in more detail later in our limitations.</p><p>A related observation is that the homophily heuristic—much like in social networks (<xref ref-type="bibr" rid="bib95">McPherson et al., 2001</xref>; <xref ref-type="bibr" rid="bib138">Talaga and Nowak, 2020</xref>)—enables each part of the network to interact with its local environment without requiring inordinate computational resources. Indeed, homophily has been shown to provide an efficient trade-off capable of producing small-world networks through which information can propagate efficiently (<xref ref-type="bibr" rid="bib91">Malkov and Ponomarenko, 2016</xref>). Under this view, as limits to <italic>local knowledge</italic> and <italic>computational capacity</italic> hold for any interacting developing system, homophily becomes a generative heuristic for any sufficiently large network. Notably, this resonates with biological accounts of Hebbian learning (<xref ref-type="bibr" rid="bib67">Hebb, 1949</xref>; <xref ref-type="bibr" rid="bib149">Vértes et al., 2014</xref>) and spike-timing dependent plasticity (STDP) (<xref ref-type="bibr" rid="bib130">Song et al., 2000</xref>) whereby neurons wire with each other as a function of <italic>similarity</italic> to themselves (e.g. concurrent or temporally precedent neuronal firing, respectively) provided that neurons are sufficiently close in space (<xref ref-type="bibr" rid="bib132">Song et al., 2014</xref>; <xref ref-type="bibr" rid="bib88">Liu et al., 2024</xref>). This also resonates with computational accounts of other developing networks, such as the internet or metabolic networks, that use hyperbolic maps to define node attractiveness in terms of both ‘popularity’ (e.g. nodes having a large number of connections) and ‘similarity’ (e.g. being physically proximal or having similar connectivity profiles) (<xref ref-type="bibr" rid="bib110">Papadopoulos et al., 2012</xref>). These representations of networks have the benefit that nodes can efficiently route information across the network using only the coordinates of their neighbors (<xref ref-type="bibr" rid="bib30">Boguñá et al., 2010</xref>); emphasizing both the importance of including geometry in network representations and that homophily has a core role in network organization.</p></sec><sec id="s3-2"><title>Models of developing networks across scales, species, and time</title><p>The combination of generative modeling and graph theory allows us to use in silico simulations as a lingua franca to probe micro-connectomic self-organization (<xref ref-type="bibr" rid="bib124">Schröter et al., 2017</xref>). Comparative studies have examined economic accounts of connectomic organization across different species (<xref ref-type="bibr" rid="bib150">Vértes and Bullmore, 2015</xref>)—such as in the worm <italic>C. elegans</italic> (<xref ref-type="bibr" rid="bib140">Towlson et al., 2013</xref>; <xref ref-type="bibr" rid="bib104">Nicosia et al., 2013</xref>; <xref ref-type="bibr" rid="bib155">Witvliet et al., 2021</xref>), larval zebrafish (<xref ref-type="bibr" rid="bib26">Betzel, 2020</xref>), mouse (<xref ref-type="bibr" rid="bib74">Johnson et al., 2019</xref>), macaque (<xref ref-type="bibr" rid="bib44">Chen et al., 2017</xref>) and human connectome (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Arnatkeviciute et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>; <xref ref-type="bibr" rid="bib77">Kaiser and Hilgetag, 2004</xref>; <xref ref-type="bibr" rid="bib79">Klimm et al., 2014</xref>; <xref ref-type="bibr" rid="bib97">Morgan et al., 2018</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>; <xref ref-type="bibr" rid="bib86">Liu et al., 2020</xref>). For example, <xref ref-type="bibr" rid="bib104">Nicosia et al., 2013</xref> modeled the growth of <italic>C. elegans</italic> using the known birth times of its somatic neurons—finding that as the body of the animal progressively elongates, the cost of longer-distance connections become increasingly penalized. In human brain scans, <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref> incorporated known early changes in brain macroscopic geometry and other physiological measures of homophily (e.g., correlated gene expression) to improve an additive generative model’s network embedding (also see <xref ref-type="bibr" rid="bib12">Arnatkeviciute et al., 2021</xref>). These works have highlighted the benefit of incorporating specific developmental changes, that are specific to the organism, within a growth model able to simulate developmental outcomes.</p></sec><sec id="s3-3"><title>Homogeneous spiking dynamics may lead to stochastic wiring through reduced parameter magnitude</title><p>In line with previous findings, the inhibition of GABA<sub>A</sub> receptors led to increased neuronal synchronization compared to untreated cultures (<xref ref-type="bibr" rid="bib92">Mann et al., 2009</xref>; <xref ref-type="bibr" rid="bib13">Assenza et al., 2011</xref>). Despite this difference in population dynamics, the homophily generative model better reproduced network topology than the other models, albeit with less error in the control networks. Crucially, GABA<sub>A</sub> receptor block did significantly push the model parameter, η, closer to zero. Reduced η magnitude indicates a weaker preference for short-distance connections in gabazine-treated networks compared to controls, whilst still preferring shorter connections, as indicated by η being negative. One explanation might be that increased synchronicity with gabazine application leads to functionally less distinguishable spike dynamics between neurons—hence, the connection probability distribution was flatter and shifted to the right relative to the probability distribution of controls. Given this shift, it could be expected that simply spatial proximity would better explain connection formation. However, η magnitude decreased rather than increased with gabazine treatment. This indicates that gabazine-treated cultures showed a weaker rather than stronger preference for short-distance connections compared to controls. One explanation could be that gabazine-treated cultures fail to deselect less homophilic long-distance connections. Consistent with this, gabazine-treated cultures showed a longer total edge length, reflecting more long-distance, high-cost connectivity than controls. Together, these results support that GABA<sub>A</sub> receptor-mediated activity influences connection specification that can elicit the same network topology more efficiently by maximizing value relative to the cost of connections.</p><p>Interestingly, previous GNM work at the whole-brain scale has shown that lower magnitude wiring parameters are associated with poorer cognitive scores (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>, age <xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>) and a diagnosis of Schizophrenia (<xref ref-type="bibr" rid="bib148">Vértes et al., 2012</xref>; <xref ref-type="bibr" rid="bib160">Zhang et al., 2021</xref>). Perhaps, inhibitory hub neurons fail to implement the principle of homophily in the same way, thus constraining the emergence of small-worldness which has also been related cognitive function (<xref ref-type="bibr" rid="bib143">van den Heuvel et al., 2009</xref>; <xref ref-type="bibr" rid="bib145">van den Heuvel and Sporns, 2013</xref>). This may suggest convergent evidence for how developmental stochasticity, intrinsic to how developing parts interact with each other, may influence functional outcomes (<xref ref-type="bibr" rid="bib68">Hiesinger and Hassan, 2018</xref>; <xref ref-type="bibr" rid="bib41">Carozza et al., 2023a</xref>). A remaining challenge in the field is to be able to directly parse the extent to which stochasticity and specific economic trade-offs may influence network outcomes under different conditions.</p></sec><sec id="s3-4"><title>Limitations and future work</title><p>Currently, there is a lack of consensus as to how functional connectivity can be inferred from the spontaneous activity of neurons developing in vitro (<xref ref-type="bibr" rid="bib1">Abril et al., 2018</xref>). In the present study, we utilized the spike time tiling coefficient (STTC; <xref ref-type="bibr" rid="bib48">Cutts and Eglen, 2014</xref>) which was developed to improve on some of the limitations of traditional metrics for the coupling between neurons, such as the correlation index (<xref ref-type="bibr" rid="bib156">Wong et al., 1993</xref>). Crucially, our goal was not to infer synaptic connections, direct structural connections nor reconstruct the underlying circuit of synaptic (and autaptic; <xref ref-type="bibr" rid="bib51">Deleuze et al., 2014</xref>) connections present. Rather, we sought to infer relationships in temporal patterns of spiking activity between neuronal units that may be relevant to network emergence and its functioning. Thus, the present analysis sits at a larger spatial scale than the synaptic or circuit level within the spatial and temporal structure of the brain. Nevertheless, in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, we show that our results resemble a TE-based method (<xref ref-type="bibr" rid="bib127">Shorten et al., 2021</xref>; <xref ref-type="bibr" rid="bib105">Novelli et al., 2019</xref>; i.e. measures of effective connectivity), which may better correspond to how information flows between neurons in a network. Furthermore, similar results were found in standard density MEAs, though neuronal units were not tracked over time (<xref ref-type="bibr" rid="bib11">Antonello et al., 2022</xref>). Nevertheless, it is important to keep in mind how our presented results and interpretations may or may not generalize to structural connectivity graphs of in vitro neuronal networks directly, despite the same rules approximating macroscopic structural connectomes (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>; <xref ref-type="bibr" rid="bib63">Goulas et al., 2019</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>). For example, the type of cost incurred by the existence of a long-range functional connection is not necessarily equivalent to that incurred by a structural connection, as a direct physical connection may not exist. Future work is needed to investigate directly structural connectivity at this scale and examine the extent to which there are equivalences between the formation and development of structural components (e.g. synapses and axons) alongside their functional interactions.</p><p>Another important consideration is the impact of subsampling, and specifically, how the selection of HD-MEA recording configurations and neuronal units (e.g. including units only above a specific activity threshold) impacts the reported organizational properties in functional connectivity. Previous studies established that subsampling can significantly affect the inference of network dynamics and connectivity (<xref ref-type="bibr" rid="bib50">Das and Fiete, 2020</xref>; <xref ref-type="bibr" rid="bib115">Pillow and Latham, 2007</xref>), and this should be considered when interpreting our results. Future studies could further probe how different parameter choices for selecting HD-MEA recording configurations and the exclusion of low activity units alter the inference of neuronal topology at this scale. Similarly, it would be important to test if the reported results also hold for more advanced network inference algorithms (<xref ref-type="bibr" rid="bib53">Donner et al., 2024</xref>).</p><p>Moreover, an important outstanding question is also how the role of GABA<sub>A</sub> receptor-mediated activity changes with development, and whether there is any link to the observed findings. From DIV 7 to DIV 14, homophily became more distinguishable from other rules in terms of its recapitulation of network topology in rodent PC networks. This coincides with the gradually increasing proportion of GABAergic synapse switching from depolarization to hyperpolarization during this time in rodent cultures (<xref ref-type="bibr" rid="bib61">Ganguly et al., 2001</xref>; <xref ref-type="bibr" rid="bib118">Rheims et al., 2008</xref>). However, we inhibited GABA<sub>A</sub> receptors chronically from DIV 1 and found homophilic rules still provided the best fit. Therefore, whilst GABA<sub>A</sub> receptor-mediated inhibition may play a role in de-coupling neurons and hub node function (<xref ref-type="bibr" rid="bib31">Bonifazi et al., 2009</xref>; <xref ref-type="bibr" rid="bib46">Cossart, 2014</xref>; <xref ref-type="bibr" rid="bib92">Mann et al., 2009</xref>), further work is required to understand the precise relationship between inhibition mediated by different receptor subtypes (e.g. GABA<sub>B</sub> receptor-mediated), cell types, and how this changes wiring parameter magnitude, and ultimately network topology, over development. Incorporating computational models that sit at the molecular-level (e.g. <xref ref-type="bibr" rid="bib10">Andrews and Iglesias, 2007</xref>; <xref ref-type="bibr" rid="bib84">Libby et al., 2007</xref>; <xref ref-type="bibr" rid="bib98">Mortimer et al., 2009</xref>), as opposed to our network-level models, will be particularly useful in this endeavor. Despite being at a different descriptive level, these models often emphasize highly analogous principles. For example, just as between-neuron spatial relationships are core to how networks form, within-neuron spatial relationships between the center of growth cones and signaled receptors are core to axonal guidance (<xref ref-type="bibr" rid="bib98">Mortimer et al., 2009</xref>). It also remains unclear to what extent the smaller size of gabazine-treated networks, compared to controls, affects other network statistics. However, given the homogeneity of activity across neurons in gabazine-treated networks, smaller network size, rather than flattened probability distributions, is unlikely to explain differences in best-fitting model parameters. Future work should aim to further formalize across-level explanations of neural development.</p><p>Another potential limitation relates to the application of our modeling approach to human monolayer and organoid cultures. The human iPSC-derived neuronal networks consist of purified cell-types, which is clearly artificial. As reflected by the lack of connectivity and topology in some of these cultures, such as the DN networks, which also did not show homophilic wiring, there is perhaps little surprise they performed differently. A more veridical account will likely come from cultures with mixed iPSC lines exhibiting more complex spiking dynamics arising from defined cell-type driven heterogeneity (<xref ref-type="bibr" rid="bib112">Perez-Nieves et al., 2021</xref>). It is also possible that the spatial extent of the recording from 3D hCOs onto the 2D HD-MEA system may have limited our network inferences. Despite these caveats, our present work shows that homophilic generative models per se are appropriate growth models for in vitro neuronal networks as they were capable of recapitulating key statistical properties—both at the local and global level. However, as noted in prior GNM studies (<xref ref-type="bibr" rid="bib4">Akarca et al., 2021</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>), a significant future advance in this research area will come from weighted generative network models capable of recapitulating weighted topological architectures. Such an approach would allow for both the tuning of connection weights over developmental time—a clear principle of network maturation <xref ref-type="bibr" rid="bib74">Johnson et al., 2019</xref>—but also enable further study of how developing network topology, genetics (<xref ref-type="bibr" rid="bib12">Arnatkeviciute et al., 2021</xref>; <xref ref-type="bibr" rid="bib107">Oldham et al., 2022</xref>; <xref ref-type="bibr" rid="bib106">Oldham and Fornito, 2019</xref>) and information processing (<xref ref-type="bibr" rid="bib43">Chen et al., 2006</xref>; <xref ref-type="bibr" rid="bib7">Ali et al., 2022</xref>; <xref ref-type="bibr" rid="bib3">Achterberg et al., 2023</xref>) together explain neuronal network organization across scales.</p><p>In conclusion, we find that the complex topology of developing rodent and many human neuronal networks in vitro can be simulated via a simple homophily generative model, where neurons aim to maximize locally shared connectivity within an economic context. With this, and prior research at the macroscopic level in mind, we suggest that homophily wiring rules provide a compelling isomorphic explanation for decentralized, locally computing, developing systems.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>High-density microelectrode arrays</title><p>Two types of CMOS-based high-density microelectrode array (HD-MEA) recording systems, produced by MaxWell Biosystems (Zurich, Switzerland), were used in the present study (<xref ref-type="bibr" rid="bib101">Müller et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Ballini et al., 2014</xref>). The single-well HD-MEA MaxOne, consists of 26,400 electrodes with a center-to-center electrode pitch of 17.5 μm, arranged in a 120x220 electrode array structure. This HD-MEA can record simultaneously from a total of 1024 user-selected readout-channels at 20 kHz (HD-MEAs have a sensing area of 3.85×2.10 mm<sup>2</sup>). For more technical details, see previous studies (<xref ref-type="bibr" rid="bib101">Müller et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Ballini et al., 2014</xref>). The second recording platform was the multi-well HD-MEA MaxTwo system (MaxWell Biosystems), capable of recording from plates with either 6- or 24-wells, that comprised the same number of electrodes and readout-channels and very similar electrode specifications as the MaxOne for each well (while the electrode size is 8.75×12.50 µm<sup>2</sup> for the MaxOne chip and HD-MEAs of the 6-well plate, it is 12.0×8.8 µm<sup>2</sup> for the 24-well plate HD-MEA). With this system, it is possible to simultaneously record from six wells at a time and at a sampling rate of 10 kHz. To decrease the impedance and to improve the signal-to-noise ratio (SNR), electrodes of single- and six-well HD-MEAs were coated with platinum black (<xref ref-type="bibr" rid="bib101">Müller et al., 2015</xref>).</p></sec><sec id="s4-2"><title>Rodent primary cortical neuronal cultures</title><p>Before plating, HD-MEAs were sterilized in 70% ethanol for 30 min and rinsed three times with sterile water. To enhance cell adhesion, the electrode area of all HD-MEAs was treated with poly-D-lysine (PDL, 20 μL, 0.1 mg mL<sup>−1</sup>; #A3890401, Gibco, Thermo Fisher Scientific, Waltham, USA) for 1 hr at room temperature and then rinsed three times with sterile water. Next, 10 μL Geltrex (#A1569601, Gibco, 0.16 mg mL<sup>−1</sup>) was pipetted on each array and again left for about 1 hr at room temperature. For the main analysis of the paper, we used rodent primary cortical (PC) neurons prepared as previously described (<xref ref-type="bibr" rid="bib119">Ronchi et al., 2019</xref>). Briefly, cortices of embryonic day (E) 18/19 Wistar rats were dissociated in trypsin with 0.25% EDTA (Gibco, #25200–056), washed after 20 min of digestion in plating medium (see below), and triturated. Following cell counting with a hemocytometer, either 50,000 cells (~1000 cells/mm<sup>2</sup>; here referred to as ‘sparse’ plating condition) or 100,000 cells (2000 cells/mm<sup>2</sup>; referred to as ‘dense’ plating condition) were seeded on each array and afterwards placed in a cell culture incubator for 30 min at 37 °C/5% CO<sub>2</sub>. Next, the plating medium was added carefully to each well. The plating medium contained 450 mL Neurobasal (Invitrogen, Carlsbad, CA, United States, #21103049), 50 mL horse serum (HyClone, Thermo Fisher Scientific, #SH30074), 1.25 mL Glutamax (Invitrogen, #35050–038), and 10 mL B-27 (Invitrogen, #A3582801). After 2 days, half of the plating medium was exchanged with growth medium containing 450 mL D-MEM (Invitrogen, #11960–044), 50 mL horse serum (HyClone), 1.25 mL Glutamax (Invitrogen), and 5 mL sodium pyruvate (Invitrogen, #11360–039). Across all experiments, the medium was exchanged twice a week, at least one day before the recording sessions. All animal experiments were approved by the veterinary office of the Kanton Basel-Stadt (license #2358) and carried out according to federal laws on animal welfare. All cell lines were tested negative for mycoplasma contamination. A summary of the data used is provided in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1a</xref>.</p><p>Notably, cell densities were estimated only on the day of plating and not on the actual recording days. As reported in previous research (<xref ref-type="bibr" rid="bib157">Xing et al., 2021</xref>), it is assumed that the actual cell numbers on the HD-MEAs, on the respective recording days, were significantly lower than the initially plated numbers. This reduction may result from incomplete adherence to the HD-MEA, stress during the plating process, the composition of plated cells, and/or naturally occurring cellular processes such as apoptotic cell death.</p></sec><sec id="s4-3"><title>Rodent primary cortical culture validation dataset</title><p>To probe the reproducibility of our results, we obtained a second set of sparse rodent PC cultures. The protocol to prepare this dataset was very similar to the procedures described previously for our main datasets. The wells of a 24-well HD-MEA plate (MaxWell Biosystems) were sterilized in 70% ethanol for 30 min and rinsed three times with sterile water. To enhance cell adhesion, the electrode area of the HD-MEAs was treated for 1 hr at room temperature with 20 µL of 0.05% (v/v) poly(ethyleneimine) (Sigma-Aldrich, #181978) in borate buffer (Thermo Fisher Scientific, #28341) at 8.5 pH, and then washed three times with sterile water. Next, 10 μL of laminin (0.02 mg ml<sup>−1</sup>; Sigma-Aldrich, #L2020) in Neurobasal medium (Gibco, Thermo Fisher Scientific) was pipetted on each array and again left for 1 hr at room temperature. Rodent PC neurons were prepared as previously described (<xref ref-type="bibr" rid="bib119">Ronchi et al., 2019</xref>). The plating density for this dataset was 50,000 cells per well (~1000 cells/mm<sup>2</sup>); the recordings included in the replication analysis were performed on DIV 14. The results for this analysis are depicted in <xref ref-type="fig" rid="fig7s3">Figure 7—figure supplement 3</xref>.</p></sec><sec id="s4-4"><title>Human induced pluripotent stem cell-derived neuronal cultures</title><p>Three different human iPSC-derived neuronal cell lines were included in the study: iCell DopaNeurons, iCell Motor Neurons, and iCell GlutaNeurons, all commercially available from FUJIFILM Cellular Dynamics International (FCDI, Madison, USA). All neural cells were co-cultured with human iCell Astrocytes (FCDI, see above). Cell plating: Cell plating medium consisted of 95 mL of BrainPhys Neuronal Medium (STEMCELL Technologies, Vancouver, Canada), 2 mL of iCell Neuronal Supplement B (FCDI), 1 mL iCell Nervous System Supplement (FCDI), 1 mL N-2 Supplement (100 X, Gibco), 0.1 mL laminin (1 mg/mL, Sigma-Aldrich), and 1 mL Penicillin-Streptomycin (100 X, Gibco). Neurons and astrocytes were thawed in a 37 °C water bath for 3 min. The cells were then transferred to 50 mL centrifuge tubes, and 8 mL plating medium (at room temperature) was carefully added. Cell suspensions were centrifuged at 380 × g (1600 RPM) for 5 min, and the supernatant was aspirated. Cell pellets were then resuspended in plating medium and combined to achieve a final concentration of 10,000 neurons and 2000 astrocytes per μL. Finally, 100,000 neurons (10,000 cells/mm<sup>2</sup>) and 20,000 astrocytes were seeded per HD-MEA by adding 10 μL of the prepared solution, after removing the Geltrex droplet. After incubating the cells for 1 hr at 37 °C/5% CO<sub>2</sub>, another 0.6 mL (for MaxOne chips of the PSM type)/1.2 mL (for MaxOne chips of the PLM type) of plating medium was added. Half of the medium was changed twice a week. For more details, see <xref ref-type="bibr" rid="bib120">Ronchi et al., 2021</xref>.</p></sec><sec id="s4-5"><title>Human cerebral organoid slice cultures</title><p>Human embryonic stem cell (ESC)-derived cerebral organoids (hCOs) were generated from a commercially available human ESC line (Takara Bio, Osaka, Japan), using the STEMdiff cerebral organoid kit (STEMCELL Technologies) following the manufacturer’s instructions. Slices were obtained from 120-days-old hCOs. Single organoids were first transferred from maturation medium to ice-cold BrainPhys (STEMCELL Technologies) using cut 1000 µl pipette tips. Next, cross-sectional 500-µm-thick slices were cut from hCOs using a sterile razor blade and collected in petri dishes filled with BrainPhys medium at room temperature. Before the plating, HD-MEAs were sterilized in 70% ethanol for 30 min and rinsed three times with distilled water. To improve tissue adhesion, arrays were coated with 0.05% (v/v) poly(ethyleneimine) (Sigma-Aldrich) in borate buffer (pH 8.5, Thermo Fisher Scientific) for 30 min at room temperature, rinsed with distilled water, and left to dry. To attach hCOs on HD-MEAs, we applied a thin layer of Matrigel (Corning) to the center of the HD-MEA and then transferred individual organoid slices to the coated HD-MEAs. After positioning the tissue, we placed a tissue ‘harp’ on top of the organoid slice and applied several drops of recording medium (see below; STEMCELL Technologies, #05793) around the organoid. HD-MEAs were then covered with a lid and placed in a humidified incubator at 37 °C, 5% CO<sub>2</sub>/95% air for 30 min, before adding more medium to a final volume of 2 ml per chip. Half of the recording medium was changed every 2–3 days. The recording medium is composed of BrainPhys, N2-A supplement, and SM1 neuronal supplement (for 10 mL of BrainPhys, we added 100 μL of N2 supplement and 200 μL of SM1 supplement). Note that all three forms of neuronal culture described in this section and above (rodent PC networks, human monolayer neuronal cultures, and organoid cultures) have been replicated many times internally in the laboratory.</p></sec><sec id="s4-6"><title>Immunohistochemistry</title><p>PC neurons were fixed using 4% paraformaldehyde solution (Thermo Fisher, #FB001). Samples were permeabilized and blocked using a PBS 10 X (Thermo Fisher, #AM9625) solution containing 10% normal donkey serum (NDS) (Jackson ImmunoResearch, West Grove, USA, #017000001), 1% bovine serum albumin (BSA) (Sigma-Aldrich, #05482), 0.02% Na-Az (Sigma-Aldrich, #S2002), and 0.5% Triton X (Sigma-Aldrich, #93443). Permeabilization facilitated antigen access to the cell, while blocking prevented non-specific binding of antibodies to neurons. Primary and secondary antibodies were diluted in a PBS solution containing 3% NDS, 1% BSA, 0.02% Na-Az, and 0.5% Triton X. The used antibodies are also listed in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1i</xref>. Note, immunohistochemistry was performed on control PC cultures prepared as previously outlined (<xref ref-type="bibr" rid="bib120">Ronchi et al., 2021</xref>).</p><p>Human iPSC-derived neurons were fixed using 8% PFA solution (#15714 S, Electron Microscopy Sciences) and blocked for 1 hr at room temperature (RT) in blocking buffer containing 10% normal donkey serum (NDS) (Jackson ImmunoResearch, West Grove, USA, #017-000-001), 1% bovine serum albumin (BSA) (#05482, Sigma-Aldrich), and 0.2% Triton X (Sigma-Aldrich, #93443) in PBS (Thermo Fisher Scientific, #AM9625). Primary antibodies (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1i</xref>) were diluted in a blocking buffer and incubated overnight at 4 °C. Samples were washed three times with 1% BSA in PBS and incubated with the secondary antibody (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1i</xref>) diluted in blocking buffer for 1 hr at RT. After three additional washes with PBS, DAPI was added for 2 min at RT (1:10000). Images were acquired using the Opera Phenix Plus High-Content Screening System (#HH14001000, PerkinElmer, Waltham, MA, USA).</p><p>hCOs were fixed using 4% paraformaldehyde (PFA) for 4 hr at room temperature, washed with PBS, and immersed in 30% sucrose solution at 4 °C overnight. PFA-fixed organoids were embedded in OCT compound (Sakura Finetek, Alphen aan den Rijn, Netherlands, #4583) and stored at –80 °C. 10 μm sections were cut on a cryostat and collected on Superfrost plus slides (Thermo Scientific, #22-037-246). For immunohistochemistry, sections were permeabilized in 0.1% Triton X-100 and blocked with animal-free blocker (Vector Laboratories, Burlingame, CA, USA, #SP-5030–250). Slides were incubated with primary antibodies for 1 hr at room temperature. Sections were washed in PBS and further incubated with secondary antibodies for 1 hr at room temperature. After washing with PBS, sections were incubated with PureBlu DAPI (Bio-Rad, Hercules, CA, USA, #1351303) for 3 min and mounted with ProLong Gold antifade mounting medium (Thermo Scientific, #P36930). Fluorescence images were acquired with a SP8 confocal microscope (Leica, Wetzlar, Germany). The primary and secondary antibodies used for hCO stainings are listed in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1i</xref>.</p></sec><sec id="s4-7"><title>Scanning electron microscope imaging</title><p>Fresh tissue samples were fixed in 2.5% glutaraldehyde solution (Sigma-Aldrich, St. Louis, USA) overnight. After fixation, the samples were dehydrated in an ascending acetone series (50%, 70%, 80%, 90%, 95%, 100%), and critically point dried (CPD; Quorum Technologies, West Sussex, UK), using CO<sub>2</sub> as the substitution fluid. The procedure is generally suited for SEM preparation and ensures that surface structures of animal tissue samples are preserved in their natural state, i.e., without shrinkage, distortion, or dissolution. After CPD, specimens were carefully mounted on aluminum stubs using double-sticky carbon-coated tabs as adhesive (Plano, Wetzlar, Germany). Thereafter, they were coated with gold-palladium in a sputter device for 45 s (Bio-Rad SC 510, Munich, Germany). SEM analyses were carried out with a Zeiss Digital Scanning Electron Microscope (SUPRA 40 VP, Oberkochen, Germany) in SE2 mode at 5–10 kV.</p></sec><sec id="s4-8"><title>Electrophysiological recordings</title><p>To characterize rodent in vitro neuronal networks on HD-MEAs, and to track their functional connectivity, we performed developmental recordings, starting one week after the plating. Using the MaxLab Live software (MaxWell Biosystems), we first used the ‘Activity Scan Assay’ module, which performs a series of high-density recordings, to screen for active electrodes across the entire HD-MEA. During the activity scan the multi-unit activity for each electrode was estimated by applying an online sliding window threshold-crossing spike-detection algorithm. After the activity scan, we used the MaxLab Live ‘Network Assay’ module to select up to 1024 readout-electrodes based on the identified active electrodes. To track networks at single-cell resolution over development, we obtained high-density network recordings, consisting of up to 64 non-overlapping 4×4 electrode blocks (electrode-to-electrode pitch of 17.5 μm), and a minimum spacing of at least 87.5 μm between the centroids of the blocks. Depending on the dataset at hand, the block configurations were based on an activity scan performed on DIV 7 (sparse PC networks) or DIV 14 (dense PC networks). The duration of the HD-MEA network recordings was 30 min (for each day); an overview on the different datasets is provided in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1a</xref>. The sparse/dense rodent PC neuronal networks (main manuscript) and the hCO’s were recorded on MaxTwo six-well plates (MaxWell Biosystems); the human iPSC-derived neurons (glutamatergic, motor, and dopaminergic neurons) were recorded on single-well MaxOne HD-MEAs (MaxWell Biosystems; see also <xref ref-type="bibr" rid="bib120">Ronchi et al., 2021</xref>). Finally, the validation dataset (<xref ref-type="fig" rid="fig7s3">Figure 7—figure supplement 3</xref>), comprising sparse rodent PC neuronal networks, was acquired on 24-well plates (MaxWell Biosystems).</p></sec><sec id="s4-9"><title>Spike-sorting and post-processing</title><p>HD-MEA network recordings underwent an initial quality control to assess the overall noise level and signal stability of each recording. Next, we used the software package Kilosort (version 2.0; <xref ref-type="bibr" rid="bib109">Pachitariu et al., 2016</xref>) to spike sort the data, applying default parameters. For the developmental tracking analyses, we concatenated all recordings (i.e. DIV 7, 10, 12, and 14 for the sparse rodent PC cultures, and DIV 14 and 28 for the dense rodent PC cultures). After spike sorting, we inferred array-wide spike-triggered averages (STAs) for all units labeled as ‘good’ by Kilosort. Next, we calculated the spatial similarity between all detected units/STAs to minimize the influence of potential cluster splits that might have occurred during spike sorting of bursty spontaneous activity. The spatial similarity among the inferred array-wide templates was probed by the normalized pairwise maximum cross-correlation: units/STAs that showed a similarity <italic>r</italic>&gt;0.75 and had at least five electrodes in common underwent an iterative elimination process using a simple clustering heuristic (based on a standard modularity algorithm; <xref ref-type="bibr" rid="bib28">Blondel et al., 2008</xref>). Please see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1a</xref> for a summary of the datasets used.</p><p>To probe whether the reported main results depend on our spike-sorting/post-processing pipeline, we also prepared the data using an alternative pipeline. This alternative pipeline used a later version of Kilosort (version 2.5), accessed through SpikeInterface (<xref ref-type="bibr" rid="bib34">Buccino et al., 2020</xref>), and the quality control toolbox Bombcell (<xref ref-type="bibr" rid="bib59">Fabre et al., 2023</xref>) to screen for units that may be included in the analysis. Moreover, we restricted functional connectivity inference (see below) to unit pairs with a minimum of co-activity, i.e., at least 50 spikes within a±50 ms time window of the cross-correlogram calculated between the units. We also excluded neuron pairs with potential spike sorting issues, slightly modifying the spike sorting index introduced by a recent study to our data (<xref ref-type="bibr" rid="bib117">Ren et al., 2020</xref>). As we show in <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, results from this analysis were mostly in line with the initial results reported in the main manuscript. Of note, for most datasets, the number of included units was higher with the alternative sorting/post-processing pipeline (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></sec><sec id="s4-10"><title>Pharmacological experiments</title><p>Pharmacological experiments with the GABA<sub>A</sub> receptor blocker gabazine (SR 95531 hydrobromide, Sigma-Aldrich, #104104509), were performed on sparse rodent PC neuronal cultures. Nine cultures were treated with 1 μM gabazine one day after plating and tracked until DIV 14; media + gabazine media exchanges were performed 2–3 times per week.</p></sec><sec id="s4-11"><title>Firing rate and burst statistics</title><p>Firing rates across neuronal units were calculated as the total number of spikes per unit time (in seconds) in the entire recording. Array values were calculated as the mean across all active units (firing rates &gt;0.01 Hz). Burst rates were calculated using a maximum interspike interval (ISI) method (<xref ref-type="bibr" rid="bib47">Cotterill et al., 2016</xref>) based on the ISI between every N-th spike (ISI<sub>N</sub>; <xref ref-type="bibr" rid="bib16">Bakkum et al., 2013b</xref>). The ISI<sub>N</sub> threshold for determining the onset/offset of bursting activity was determined by finding the local trough in the bimodal logISI distribution (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1b</xref>). The two peaks, at short ISIs and long ISIs represent more high frequency bursting and regular activity, respectively. The coefficient of variation (CV) of interburst intervals (IBIs) was calculated as the standard deviation of IBIs relative to the mean IBI of a given neuronal unit; the array value was the mean of this across all neuronal units.</p></sec><sec id="s4-12"><title>Functional connectivity inference</title><p>To detect pairwise correlations in spike trains, here referred to as functional connectivity, we computed the spike time tiling coefficient (STTC; <xref ref-type="bibr" rid="bib48">Cutts and Eglen, 2014</xref>). The STTC aims to mitigate potential confounding in basic correlation indices introduced by different firing rates, by quantifying the proportion of spikes in one train which fall within ± Δt (the synchronicity window) of another. It is given by:<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:msub><mml:mi>T</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  STTC=\frac{1}{2}\left(\frac{P_A-T_B}{1-P_AT_B}+\frac{P_B-T_A}{1-P_BT_A}\right),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where T<sub>A</sub> is the proportion of total recording time which lies within ±Δt of any spike from A (T<sub>B</sub> is calculated similarly). P<sub>A</sub> is the proportion of spikes from A which lies within ±Δt of any spike from B (P<sub>B</sub> is calculated similarly). The synchronicity window, Δt, is the only free parameter in the STTC calculation. In the present study, we used a Δt=10 ms. A visualization of the STTC calculation is provided in <xref ref-type="fig" rid="fig1">Figure 1h</xref>; STTC was calculated using publicly available Matlab code (<xref ref-type="bibr" rid="bib48">Cutts and Eglen, 2014</xref>). We used permutation-based testing to determine the significance of connections: For a given neuronal unit’s spike train, spike times were randomly jittered by sampling from a normal distribution with a standard deviation of 10 ms, generating a surrogate spike train. The code for jittering spike trains was adopted from the Neural Complexity and Criticality Toolbox (<xref ref-type="bibr" rid="bib93">Marshall et al., 2016</xref>). The jittering and STTC inference procedure was repeated for each neuronal unit for 1000 permutations. To calculate the significance of pairwise functional connectivity, experimentally inferred STTC values were compared to the distribution of surrogate SSTC values. A significance value of p&lt;0.001 was used as a cutoff to binarize functional connectivity matrices and to calculate network related analysis throughout the manuscript; only units with firing rates &gt;0.01 Hz were considered.</p></sec><sec id="s4-13"><title>Transfer Entropy Estimation</title><p>We used the CoTETE package (<ext-link ext-link-type="uri" xlink:href="https://github.com/dpshorten/CoTETE.jl">https://github.com/dpshorten/CoTETE.jl</ext-link>; <xref ref-type="bibr" rid="bib128">Shorten, 2022</xref>) to infer transfer entropy (TE). CoTETE allows for TE estimation between even-based time series in continuous time, i.e. without binning of the data (<xref ref-type="bibr" rid="bib127">Shorten et al., 2021</xref>). Parameters that were changed from their defaults are listed in <xref ref-type="table" rid="table1">Table 1</xref> and were largely adapted from <xref ref-type="bibr" rid="bib127">Shorten et al., 2021</xref>. For each putative connection, the distribution of surrogate TE values was approximated by a normal distribution with mean and variance estimated from the surrogates. The corresponding cumulative distribution function (CDF) was then evaluated at the empirical TE value. The p-value was defined as the probability of observing a surrogate TE greater than or equal to the empirical TE, i.e., p=1−CDF(TE<sub>emp</sub>).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Non-default parameter values used for the continuous-time TE inference.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Description</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">lX</td><td align="left" valign="bottom">Number of interspike intervals in target history embeddings</td><td align="left" valign="bottom">4</td></tr><tr><td align="left" valign="bottom">lY</td><td align="left" valign="bottom">Number of interspike intervals in source history embeddings</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">kglobal</td><td align="left" valign="bottom">Number of nearest neighbours to find in the initial search</td><td align="left" valign="bottom">10</td></tr><tr><td align="left" valign="bottom">kperm</td><td align="left" valign="bottom">Number of nearest neighbours to consider during surrogate generation</td><td align="left" valign="bottom">4</td></tr><tr><td align="left" valign="bottom">Nsurrogates</td><td align="left" valign="bottom">Number of surrogates to generate for each node pair</td><td align="left" valign="bottom">100</td></tr><tr><td align="left" valign="bottom">sampling_method</td><td align="left" valign="bottom">Method with which to place the random sampling points.</td><td align="left" valign="bottom">&quot;jittered_target&quot;</td></tr><tr><td align="left" valign="bottom">jittered_sampling_noise</td><td align="left" valign="bottom">Width of the uniform jitter added to the target spike times used in resampling when sampling_method is set to &quot;jittered_target&quot;.</td><td align="left" valign="bottom">200.0</td></tr></tbody></table></table-wrap></sec><sec id="s4-14"><title>Network statistics</title><p>In <xref ref-type="fig" rid="fig2">Figure 2a</xref>, we provide a visualization of key graph theoretical metrics relevant for this study. Here, we provide both a written and mathematical definition for each measure used. Each statistic was calculated using the Brain Connectivity Toolbox (<xref ref-type="bibr" rid="bib121">Rubinov and Sporns, 2010</xref>):</p><sec id="s4-14-1"><title>Network size and total degree</title><p>The network size here refers to the number of <italic>nodes</italic> in the network. This excludes nodes that did not form any connections (neuronal units with &lt;0.01 spikes/s were already excluded as above). Network size is sometimes referred to as network order in graph theory literature to avoid confusion with the number of <italic>edges</italic>, however, we refer to the total number of edges in the network as total degree.</p></sec><sec id="s4-14-2"><title>Degree</title><p>The degree is the number of edges connected to a node. The degree of node <italic>i</italic> is given by:<disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  k_{i}\ =\ \underset{j\in N}{\sum }a_{i,j},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1">\begin{document}$a_{i,j}$\end{document}</tex-math></alternatives></inline-formula> is the connection status between <italic>i</italic> and <italic>j</italic>. <inline-formula><alternatives><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft2">\begin{document}$a_{i,j}$\end{document}</tex-math></alternatives></inline-formula> = 1 when link <italic>i</italic>,<italic>j</italic> exists (when <italic>i</italic> and <italic>j</italic> are neighbors); <inline-formula><alternatives><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft3">\begin{document}$a_{i,j}$\end{document}</tex-math></alternatives></inline-formula> = 0 otherwise (<inline-formula><alternatives><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft4">\begin{document}$a_{i,i}$\end{document}</tex-math></alternatives></inline-formula>=0 for all <italic>i</italic>).</p></sec><sec id="s4-14-3"><title>Clustering coefficient</title><p>The clustering coefficient is the fraction of a node’s neighbors that are neighbors of each other. The clustering coefficient for node <italic>i</italic> is given by:<disp-formula id="equ6"><label>(6)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  c_{i}=\frac{1}{n}\underset{i\in N}{\sum }\frac{2t_{i}}{k_{i}\left (k_{i}-1\right)},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft5">\begin{document}$c_{i}$\end{document}</tex-math></alternatives></inline-formula> is the clustering coefficient of node <italic>i</italic> (<inline-formula><alternatives><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft6">\begin{document}$c_{i}$\end{document}</tex-math></alternatives></inline-formula>=0 for <inline-formula><alternatives><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft7">\begin{document}$k_{i}$\end{document}</tex-math></alternatives></inline-formula> &lt; 2).</p></sec><sec id="s4-14-4"><title>Betweenness centrality</title><p>The betweenness centrality is the fraction of all shortest paths in the network that contain a given node. Nodes with high values of betweenness centrality, therefore, participate in a large number of shortest paths. The betweenness centrality for node <italic>i</italic> is given by:<disp-formula id="equ7"><label>(7)</label><alternatives><mml:math id="m7"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  b_{i}=\underset{h,j\in N}{\sum }\frac{\rho _{hj}\left (i\right)}{\rho _{hj}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft8">\begin{document}$\rho _{hj}$\end{document}</tex-math></alternatives></inline-formula> is the number of shortest paths between <italic>h</italic> and <italic>j</italic>, and <inline-formula><alternatives><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft9">\begin{document}$\rho _{hj}$\end{document}</tex-math></alternatives></inline-formula>(<italic>i</italic>) is the number of shortest paths between <italic>h</italic> and <italic>j</italic> that pass through <italic>i</italic>.</p></sec><sec id="s4-14-5"><title>Edge length</title><p>The edge length is the total edge length connected to a node. It is given by:<disp-formula id="equ8"><label>(8)</label><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  d_i = \sum_{j \in N} a_{i,j} d_{i,j} ,$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <italic>d<sub>i,j</sub></italic> is the Euclidean distance between <italic>i</italic> and <italic>j</italic>. The Euclidean distances of functional connectivity graphs inferred in the present study are depicted in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>.</p></sec><sec id="s4-14-6"><title>Global efficiency</title><p>The global efficiency is the average of the inverse shortest path length. It is given by:<disp-formula id="equ9"><label>(9)</label><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle  E_{i}=\frac{1}{n}\underset{i\in N}{\sum}\frac{\sum_{j\in N,j\neq i}d_{i,j}^{-1}}{n-1},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where here, <inline-formula><alternatives><mml:math id="inf10"><mml:mstyle><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft10">\begin{document}$d_{i,j}$\end{document}</tex-math></alternatives></inline-formula> represents the shortest path length between <italic>i</italic> and <italic>j</italic>. <inline-formula><alternatives><mml:math id="inf11"><mml:mstyle><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft11">\begin{document}$d_{i,j}^{-1}$\end{document}</tex-math></alternatives></inline-formula>, therefore, represents the inverse shortest path length, meaning that a high efficiency corresponds to a low shortest path length.</p></sec><sec id="s4-14-7"><title>Local efficiency</title><p>The local efficiency of the network is given by:<disp-formula id="equ10"><label>(10)</label><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mtext>loc</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mtext>loc</mml:mtext><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:munder><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle  E_{\text{loc}} = \frac{1}{n} \sum_{i \in N} E_{\text{loc},i} = \frac{1}{n} \sum_{i \in N} \frac{\sum_{\substack{j,h \in N j \neq i}} a_{ij} , a_{ih} \, \bigl[d_{jh}(N_{i})\bigr]^{-1}}{k_{i}\,(k_{i} - 1)} $$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft12">\begin{document}$E_{loc}$\end{document}</tex-math></alternatives></inline-formula> is the local efficiency of node <italic>i</italic>, and <inline-formula><alternatives><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="inft13">\begin{document}$d_{jh}\left (N_{i}\right)$\end{document}</tex-math></alternatives></inline-formula> is the length of the shortest path between <italic>j</italic> and <italic>h</italic>, that contains only neighbors of <italic>i</italic>.</p></sec><sec id="s4-14-8"><title>Matching</title><p>The matching index computes the proportion of overlap in the connectivity between two nodes. It is given by:<disp-formula id="equ11"><label>(11)</label><alternatives><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>∩</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>∪</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle M_{i,j} = \frac{\left|N_{i/j}\,\cap N_{j/i}\,\right|}{\left|N_{i/j}\,\cup N_{j/i}\,\right|}, $$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>/</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft14">\begin{document}$N_{i/j}$\end{document}</tex-math></alternatives></inline-formula> refers to the neighbors of the node <italic>i</italic> excluding node <italic>j</italic>. Where global measures of matching have been used, we averaged across the upper triangle of the computed matching matrix.</p></sec><sec id="s4-14-9"><title>Small-worldness</title><p>Small-worldness refers to a graph property where most nodes are not neighbors of one another, but the neighbors of nodes are likely to be neighbors of each other. This means that most nodes can be reached from every other node in a small number of steps. It is given by:<disp-formula id="equ12"><label>(12)</label><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle \sigma=\frac{c/c_{rand}}{l/l_{rand}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <italic>c</italic> and <italic>c</italic> <sub><italic>rand</italic></sub> are the clustering coefficients, and <italic>l</italic> and <italic>l<sub>rand</sub></italic> are the characteristic path lengths of the respective tested network and a random network with the same size and density of the empirical network. Networks are generally considered as small-world networks at σ&gt;1. In our work, we computed the random network as the mean statistic across a distribution of n=1000 random networks. The characteristic path length is given by:<disp-formula id="equ13"><label>(13)</label><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle  L_{i}=\frac{1}{n}\underset{i\in N}{\sum }\frac{\sum _{j\in N,j\neq i}d_{i,j}}{n-1},$$\end{document}</tex-math></alternatives></disp-formula></p></sec><sec id="s4-14-10"><title>Modularity</title><p>The modularity statistic, Q, quantifies the extent to which the network can be subdivided into clearly delineated groups:<disp-formula id="equ14"><label> (14)</label><alternatives><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>l</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>l</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t14">\begin{document}$$\displaystyle  Q=\frac{1}{l}\underset{i,j\in N}{\sum}\left (a_{i,j}-\frac{k_{i}k_{,j}}{l}\right)\delta_{m_{i}m_{j}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft15">\begin{document}$m_{i}$\end{document}</tex-math></alternatives></inline-formula> is the module containing node <italic>i,</italic> and  <inline-formula><alternatives><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft16">\begin{document}$\delta _{m_{i}m_{j}}$\end{document}</tex-math></alternatives></inline-formula> = 1 if <inline-formula><alternatives><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft17">\begin{document}$m_{i}$\end{document}</tex-math></alternatives></inline-formula> = <inline-formula><alternatives><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft18">\begin{document}$m_{j}$\end{document}</tex-math></alternatives></inline-formula>, and 0 otherwise.</p></sec><sec id="s4-14-11"><title>Participation coefficient</title><p>The participation coefficient is a measure of diversity of intermodular connections of individual nodes, where community allocation was determined via a Louvain algorithm, with a resolution parameter <italic>γ</italic>=1, which aims to form a subdivision of the network which maximizes the number of within-group edges and minimizes between-group edges.</p></sec></sec><sec id="s4-15"><title>Generative network modeling</title><p>The generative network model can be expressed as a simple wiring equation, where wiring probabilities are computed iteratively by trading-off the cost of forming a connection, against the value of the connection being formed in terms of a network topology term. Connections are added iteratively according to these wiring probabilities. It is given by the wiring equation as provided in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. The <italic>D<sub>i,j</sub></italic> term represents the ‘costs’ incurred between neuron modeled as the Euclidean distance between tracked units (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). The <italic>K<sub>i,j</sub></italic> term represents how neurons ‘value’ each other, given by an arbitrary topological relationship which is postulated a priori (also termed ‘wiring rule’ given mathematically in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref>). <italic>P<sub>i,j</sub></italic> reflects the probability score of forming a fixed binary connection at the current time step. Note that, as this is a probability score, the sum of the values may not necessarily equal one. This is because the score indicates the relative likelihood of nodes forming a connection over others. The simulation continues until the simulated network has the same number of connections as the observed network. The <italic>D<sub>i,j</sub></italic> term remains constant during the simulation, while the <italic>K<sub>i,j</sub></italic> term updates at each time point (and, therefore, also the <italic>P<sub>i,j</sub></italic> term).</p></sec><sec id="s4-16"><title>Cost functions</title><p>In the present study, we make a distinction between simulated networks which mirror the statistical distributions of observed networks and those which mirror the topological organization of those statistics. The former can be accessed via a previously established energy equation (<xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>), whereby the model fit is given by the ‘worst’ of the four <italic>KS</italic> distances assessed, given by <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. <italic>KS</italic> is the Kolmogorov-Smirnov statistic between the observed and simulated networks at the particular η and γ combination used to construct the simulation, defined by the network degree <italic>k</italic>, clustering coefficient <italic>c</italic>, betweenness centrality <italic>b,</italic> and Euclidean edge length <italic>d</italic>. Notably, the KS distance between two vectors simply considers their statistical <italic>distributions</italic>. When we report model fits in the main report, we group the model fits based on the broad generative rule group (as shown by the distinct colors in <xref ref-type="fig" rid="fig2">Figure 2d</xref>). <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1c</xref> contains a summary of all optimized parameters and model fits. <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1d-h</xref> show all statistical comparisons (One-way ANOVA and pairwise comparisons) between generative rule groups, over all time points for each considered analysis. This was done to simplify the main report, and whenever we report grouped results, we provide Figure supplements which show all results broken down by the individual model.</p><p>In <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>, we further assess the ability of the best performing generative models in each class (spatial, matching, clustering average, and degree average) to recapitulate network statistics as included in the energy equation, but also two measures outside (local efficiency and participation coefficient). We did this via a Monte Carlo sampling procedure (<xref ref-type="bibr" rid="bib22">Beasley and Rodgers, 2012</xref>). First, we took the top n=99 performing simulations for each sparse rodent culture’s model considered and computed each of the six local statistics as shown in <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref> as cumulative density plots. For each statistic, we computed a KS statistic between the observed local statistics distribution and an average of the statistics of the 99 simulations. We then undertook 99 individual leave-one-out iterations in which we replaced a single simulation of the 99 with the observed distribution. For each of the 99 permutations, we computed the same statistic, forming a null distribution. We then calculated a p<sub>rank</sub> by ranking how close the original observed statistic was to the mean of this computed null distribution (i.e. how close was the observation to the middle of the null). This was computed for each culture and statistic, for each of the considered generative models. We then quoted the median p<sub>rank</sub> across cultures.</p><p>Later in the study, we provide an alternative but simple cost function which does not assess distributions of statistics but instead assesses the <italic>topological fingerprint dissimilarity</italic> of these network statistics. The <italic>TF</italic> matrix is calculated as a Pearson’s correlation matrix between each pair-wise combination of the local statistics. In our study, we used six common network statistics to form this correlation matrix; however, in principle, these can be extended to any number or range of local statistical measures. Moreover, there are alternative procedures to the one provided that could be taken to estimate the dissimilarity between the topological fingerprint matrices, that may or may not provide greater capacity to distinguish generative model performances. For example, the Pearson’s correlation (as in representational similarity analysis; <xref ref-type="bibr" rid="bib80">Kriegeskorte et al., 2008</xref>) or the non-Euclidean geodesic distance (which better captures the non-Euclidean geometry of functional connectivity in functional magnetic resonance imaging; <xref ref-type="bibr" rid="bib147">Venkatesh et al., 2020</xref>) could be used. Future work should examine the advantages and disadvantages of these approaches for the case of generative network models.</p><p>The construction of the <italic>TF</italic> is visualized in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. The <italic>TF<sub>dissimilarity</sub></italic> is then calculated as the Euclidean norm (<xref ref-type="bibr" rid="bib85">Lindfield and Penny, 2019</xref>) of the difference between the observed and simulated <italic>TF</italic> matrices. This is given in <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>.</p></sec><sec id="s4-17"><title>Parameter selection</title><p>We optimized η and γ using a Voronoi tessellation procedure as used in prior work (<xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref>). This procedure works by first randomly sampling the parameter space and evaluating the model fits of the resulting simulated networks, via the energy equation. As there is little prior literature that can be used to guide the present study, we considered a wider range of parameter values, with η values in the range from –10 to 10 and γ values in the range –10 to 10. Following an initial search of 4000 parameters in this space, we then applied a Voronoi tessellation to partition the space into two-dimensional cells. We then preferentially sampled from cells with better model fits according to the energy equation (see <xref ref-type="bibr" rid="bib24">Betzel et al., 2016</xref> for further detail). Preference was computed with a severity of <italic>α</italic>=2, which determines the extent to which cell performance led to preferential sampling in the next step. This procedure was repeated a further four times, leading to a total of 20,000 simulations being run for each considered network across the 13 generative rules, as described in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref>.</p><p>Our search was intentionally extensive, such that we had a greater likelihood of converging on accurate parameter estimates for each culture with the capacity to generate good model fits. In the main paper, we report the top-performing n=1 parameter simulation, but in each case, we replicate our findings across a variable number of high-performing parameters (n=10 and n=50). This was done to show robustness to possible stochasticity entering the model, possibly biasing the obtained results. Of note, recent work has provided a new solution to enable easier convergence on true parameter estimates in generative models (<xref ref-type="bibr" rid="bib87">Liu et al., 2023</xref>), but this approach requires the sample to have the same geometric structure, which is not the case across our HD-MEA recordings.</p><p>Due to different amounts of data across datasets (e.g. see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1c</xref>), we conducted a subsampling procedure in which we sampled from our largest dataset (dense rodent PC cultures) to assess to what extent results may depend on the dataset size. To do this, we took the n=12 cultures across developmental time points (DIV 14 and DIV 28) and sampled n=6 and n=3 (respectively) samples 1000 times. For each of the 1000 sub-samples, we computed statistical testing on the model energy acquired from all assessed generative models and provided 95% confidence intervals on pairwise comparisons and effect sizes. We report these findings in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1j</xref>, showing that even when sampling as low as n=3, our results appear to generalize very well, with homophily remaining as the rule generating the lowest energy. Of note, we find a general trend that lowering the empirical sample size increases the p-value, which can be considered by those conducting future studies.</p></sec><sec id="s4-18"><title>Generative probability distributions</title><p>In <xref ref-type="fig" rid="fig6">Figure 6d</xref>, we show the mean probability score (<italic>P<sub>i,j</sub></italic>) distributions within the generative models fit to gabazine and control networks. This was calculated by measuring the <italic>P<sub>i,j</sub></italic> across all node pairs <italic>i</italic> and <italic>j</italic> in the network, in 1% intervals, before plotting the average distribution of <italic>P<sub>i,j</sub></italic> across these timesteps. In <xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4</xref>, we show each distribution of these probability distributions (that was averaged to provide comparisons in <xref ref-type="fig" rid="fig6">Figure 6d</xref>).</p><p>Note that the probability score distribution ‘flattening’ (from a relative lognormal distribution toward a uniform distribution) means that relatively more candidate connections come to have a higher probability of being connected in the future. This leads to a decreased specificity of future wiring (i.e. the scope of possible outcomes increases). This flattening effect is equivalent to the network outcomes becoming more random, because a greater number of possible future connections have a non-trivial probability score, and the formation of a connection is less driven by the underlying network topology. Note, a completely singular and uniform <italic>P<sub>i,j</sub></italic> distribution (i.e. where all connections have the same probability of wiring) generates an entirely random graph (<xref ref-type="bibr" rid="bib58">Erdős and Rényi, 1959</xref>). In contrast, when a generative network has a heterogeneous distribution in its <italic>P<sub>i,j</sub></italic> distribution (e.g. with large numbers of small probability scores and small numbers of large probability scores), the network will have a smaller scope for variability. The probability score distributions, <italic>P<sub>i,j</sub></italic>, shown in this work, are plotted with the score value on the x-axis and the frequency on the y-axis. It is of note that there are alternative ways that one could represent these distributions, such as the edge index on the x-axis and <italic>P<sub>i,j</sub></italic> on the y-axis, which would provide different appearing distributions (for more detail, see <xref ref-type="bibr" rid="bib41">Carozza et al., 2023a</xref>; <xref ref-type="bibr" rid="bib1">Abril et al., 2018</xref> which provides a detailed analysis of the magnitude of randomness of generated networks under different parameter conditions).</p></sec><sec id="s4-19"><title>Autocorrelogram analysis</title><p>Autocorrelogram analysis (as in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>) was carried out using the CCG function provided by the CellExplorer Matlab Toolbox (<xref ref-type="bibr" rid="bib56">English et al., 2017</xref>; <xref ref-type="bibr" rid="bib114">Petersen et al., 2021</xref>). First, spike times were concatenated cumulatively across units to give a single vector of spike times. Spikes were summed into consecutive one-millisecond bins giving a vector where each element is a one-millisecond bin containing the number of spikes occurring in the network at each time point. This vector, <italic>v</italic>, was then correlated with itself plus a lag value, <italic>x</italic>. The range of lag values tested was between –500 and 500 ms. Lag values between –1–1ms were removed to impose a refractory period—hence, these values are 0 in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>. For example, where <italic>x</italic> is 5ms, the CCG function is the sum of <italic>v<sub>i</sub></italic> and <italic>v<sub>t+x</sub></italic> across all time points, <italic>t</italic>. This gives a vector of CCG values, corresponding to spatiotemporal overlap in spike times in increment 1 ms 1ms. To control for variability in firing rate between recordings, the CCG values were normalized to the maximum value in this CCG vector.</p></sec><sec id="s4-20"><title>Code availability</title><p>Results were generated using code written in Matlab 2020b. All code is available at (<ext-link ext-link-type="uri" xlink:href="https://github.com/DanAkarca/MEA_generative_models">https://github.com/DanAkarca/MEA_generative_models</ext-link>, copy archived at <xref ref-type="bibr" rid="bib5">Akarca, 2025</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>is employed by MaxWell Biosystems AG, which commercializes HD-MEA technology</p></fn><fn fn-type="COI-statement" id="conf3"><p>is affiliated with F Hoffmann-La Roche Ltd The author has no financial interests to declare</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation, Methodology</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation, Visualization</p></fn><fn fn-type="con" id="con5"><p>Data curation, Investigation, Visualization</p></fn><fn fn-type="con" id="con6"><p>Data curation, Investigation, Visualization</p></fn><fn fn-type="con" id="con7"><p>Data curation, Investigation, Visualization</p></fn><fn fn-type="con" id="con8"><p>Data curation, Investigation, Visualization</p></fn><fn fn-type="con" id="con9"><p>Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con10"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con12"><p>Investigation, Methodology</p></fn><fn fn-type="con" id="con13"><p>Data curation, Funding acquisition, Investigation, Methodology</p></fn><fn fn-type="con" id="con14"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con15"><p>Conceptualization, Resources, Data curation, Supervision, Funding acquisition, Investigation, Visualization, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal experiments were approved by the veterinary office of the Kanton Basel-Stadt (license #2358) and carried out according to Swiss federal laws on animal welfare.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Supplementary tables.</title><p>(<bold>a</bold>) Overview of the datasets used in the study. (<bold>b</bold>) A list of all the value <italic>Ki,j</italic> terms that were included in the generative modeling, as given in the wiring equation. (<bold>c</bold>) A summary of all optimized parameters and energy values, for each dataset, across generative rules. (<bold>d</bold>) Statistical comparisons of the sparse rodent culture energy values across generative rules. (<bold>e</bold>) Statistical comparisons of the sparse rodent culture topological fingerprint dissimilarity across generative rules. (<bold>f</bold>) Statistical comparisons of the dense rodent culture topological fingerprint dissimilarity across generative rules. (<bold>g</bold>) Statistical comparisons of the dense rodent culture energy values across generative rules. (<bold>h</bold>) Statistical comparisons of human monolayer neuron and cerebral organoid culture energy values across generative rules. (<bold>i</bold>) Overview of used antibodies. (<bold>j</bold>) Confidence intervals of model energies, generated by subsampling from the dense rodent networks.</p></caption><media xlink:href="elife-85300-supp1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-85300-mdarchecklist1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data used in this study, along with documentation detailing each dataset, is openly available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6109413">https://doi.org/10.5281/zenodo.6109413</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Dunn</surname><given-names>A</given-names></name><name><surname>Hornauer</surname><given-names>P</given-names></name><name><surname>Ronchi</surname><given-names>S</given-names></name><name><surname>Fiscella</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Terrigno</surname><given-names>M</given-names></name><name><surname>Jagasia</surname><given-names>R</given-names></name><name><surname>Vértes</surname><given-names>P</given-names></name><name><surname>Mierau</surname><given-names>S</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name><name><surname>Eglen</surname><given-names>S</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name><name><surname>Astle</surname><given-names>D</given-names></name><name><surname>Schröter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Homophilic wiring principles underpin neuronal network topology in vitro</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.6109413</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the European Union through the European Research Council (ERC) Advanced Grant 694829 ‘neuroXscales’ and the corresponding proof-of-concept Grant 875609 ‘HD-Neu-Screen,’ by the two Cantons of Basel through a Personalized Medicine project (PMB-01–18), granted by ETH Zurich, the Innosuisse Project 25933.2 PFLS-LS, the Swiss National Science Foundation under contract 205320_188910/1 and a Swiss Data Science Center project grant (C18-10). Danyal Akarca and Alexander Dunn are supported by the Medical Research Council Doctoral Training Programme. Danyal Akarca is supported by the Cambridge Trust Vice Chancellor’s Award Scholarship. Duncan Astle is supported by Medical Research Council Program Grant MC-A0606-5PQ41. Both Duncan Astle and Danyal Akarca are supported by The James S McDonnell Foundation Opportunity Award. Congwei Wang and Marco Terrigno are supported by Roche postdoctoral fellowship program. Petra Vertes is a fellow of MQ: Transforming Mental Health (MQF17_24). We thank Dr Martin Oeggerli for contributing the serial section electron microscopy image (<xref ref-type="fig" rid="fig1">Figure 1a</xref>), and the IT department at the MRC Cognition and Brain Sciences Unit, Cambridge, as well as the HPC team at ETH Zürich, for assistance with high performance computing.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abril</surname><given-names>I</given-names></name><name><surname>Yoshimoto</surname><given-names>J</given-names></name><name><surname>Doya</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Connectivity inference from neural recording data: Challenges, mathematical bases and research directions</article-title><source>Neural Networks</source><volume>102</volume><fpage>120</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2018.02.016</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Achard</surname><given-names>S</given-names></name><name><surname>Salvador</surname><given-names>R</given-names></name><name><surname>Whitcher</surname><given-names>B</given-names></name><name><surname>Suckling</surname><given-names>J</given-names></name><name><surname>Bullmore</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A resilient, low-frequency, small-world human brain functional network with highly connected association cortical hubs</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>63</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3874-05.2006</pub-id><pub-id pub-id-type="pmid">16399673</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Achterberg</surname><given-names>J</given-names></name><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Strouse</surname><given-names>DJ</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Astle</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings</article-title><source>Nature Machine Intelligence</source><volume>5</volume><fpage>1369</fpage><lpage>1381</lpage><pub-id pub-id-type="doi">10.1038/s42256-023-00748-9</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><collab>CALM team</collab><name><surname>Astle</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A generative network model of neurodevelopmental diversity in structural brain organization</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4216</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24430-z</pub-id><pub-id pub-id-type="pmid">34244490</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Akarca</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>MEA_generative_models</data-title><version designator="swh:1:rev:f51d581f90df55ee33008c4a4ee73b08854a9900">swh:1:rev:f51d581f90df55ee33008c4a4ee73b08854a9900</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:e73f75bfa2f76c8c7d63d8be6e57bde43b3f0969;origin=https://github.com/DanAkarca/MEA_generative_models;visit=swh:1:snp:1a112502c2cce3cbbaef4466ee1d493beee06a74;anchor=swh:1:rev:f51d581f90df55ee33008c4a4ee73b08854a9900">https://archive.softwareheritage.org/swh:1:dir:e73f75bfa2f76c8c7d63d8be6e57bde43b3f0969;origin=https://github.com/DanAkarca/MEA_generative_models;visit=swh:1:snp:1a112502c2cce3cbbaef4466ee1d493beee06a74;anchor=swh:1:rev:f51d581f90df55ee33008c4a4ee73b08854a9900</ext-link></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albert</surname><given-names>R</given-names></name><name><surname>Barabási</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Statistical mechanics of complex networks</article-title><source>Reviews of Modern Physics</source><volume>74</volume><fpage>47</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1103/RevModPhys.74.47</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ali</surname><given-names>A</given-names></name><name><surname>Ahmad</surname><given-names>N</given-names></name><name><surname>de Groot</surname><given-names>E</given-names></name><name><surname>Johannes van Gerven</surname><given-names>MA</given-names></name><name><surname>Kietzmann</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Predictive coding is a consequence of energy efficiency in recurrent neural networks</article-title><source>Patterns</source><volume>3</volume><elocation-id>100639</elocation-id><pub-id pub-id-type="doi">10.1016/j.patter.2022.100639</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allard</surname><given-names>A</given-names></name><name><surname>Serrano</surname><given-names>MÁ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Navigable maps of structural brain networks across species</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007584</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007584</pub-id><pub-id pub-id-type="pmid">32012151</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alstott</surname><given-names>J</given-names></name><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Powerlaw: a Python package for analysis of heavy-tailed distributions</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e85777</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0085777</pub-id><pub-id pub-id-type="pmid">24489671</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews</surname><given-names>BW</given-names></name><name><surname>Iglesias</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>An information-theoretic characterization of the optimal gradient sensing response of cells</article-title><source>PLOS Computational Biology</source><volume>3</volume><elocation-id>e153</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.0030153</pub-id><pub-id pub-id-type="pmid">17676949</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antonello</surname><given-names>PC</given-names></name><name><surname>Varley</surname><given-names>TF</given-names></name><name><surname>Beggs</surname><given-names>J</given-names></name><name><surname>Porcionatto</surname><given-names>M</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Faber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Self-organization of in vitro neuronal assemblies drives to complex network topology</article-title><source>eLife</source><volume>11</volume><elocation-id>e74921</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.74921</pub-id><pub-id pub-id-type="pmid">35708741</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnatkeviciute</surname><given-names>A</given-names></name><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Oldham</surname><given-names>S</given-names></name><name><surname>Tiego</surname><given-names>J</given-names></name><name><surname>Paquola</surname><given-names>C</given-names></name><name><surname>Gerring</surname><given-names>Z</given-names></name><name><surname>Aquino</surname><given-names>K</given-names></name><name><surname>Hawi</surname><given-names>Z</given-names></name><name><surname>Johnson</surname><given-names>B</given-names></name><name><surname>Ball</surname><given-names>G</given-names></name><name><surname>Klein</surname><given-names>M</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Franke</surname><given-names>B</given-names></name><name><surname>Bellgrove</surname><given-names>MA</given-names></name><name><surname>Fornito</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Genetic influences on hub connectivity of the human connectome</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4237</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24306-2</pub-id><pub-id pub-id-type="pmid">34244483</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Assenza</surname><given-names>S</given-names></name><name><surname>Gutiérrez</surname><given-names>R</given-names></name><name><surname>Gómez-Gardeñes</surname><given-names>J</given-names></name><name><surname>Latora</surname><given-names>V</given-names></name><name><surname>Boccaletti</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Emergence of structural patterns out of synchronization in networks with competitive interactions</article-title><source>Scientific Reports</source><volume>1</volume><elocation-id>99</elocation-id><pub-id pub-id-type="doi">10.1038/srep00099</pub-id><pub-id pub-id-type="pmid">22355617</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakken</surname><given-names>TE</given-names></name><name><surname>Jorstad</surname><given-names>NL</given-names></name><name><surname>Hu</surname><given-names>Q</given-names></name><name><surname>Lake</surname><given-names>BB</given-names></name><name><surname>Tian</surname><given-names>W</given-names></name><name><surname>Kalmbach</surname><given-names>BE</given-names></name><name><surname>Crow</surname><given-names>M</given-names></name><name><surname>Hodge</surname><given-names>RD</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Eggermont</surname><given-names>J</given-names></name><name><surname>Yao</surname><given-names>Z</given-names></name><name><surname>Aevermann</surname><given-names>BD</given-names></name><name><surname>Aldridge</surname><given-names>AI</given-names></name><name><surname>Bartlett</surname><given-names>A</given-names></name><name><surname>Bertagnolli</surname><given-names>D</given-names></name><name><surname>Casper</surname><given-names>T</given-names></name><name><surname>Castanon</surname><given-names>RG</given-names></name><name><surname>Crichton</surname><given-names>K</given-names></name><name><surname>Daigle</surname><given-names>TL</given-names></name><name><surname>Dalley</surname><given-names>R</given-names></name><name><surname>Dee</surname><given-names>N</given-names></name><name><surname>Dembrow</surname><given-names>N</given-names></name><name><surname>Diep</surname><given-names>D</given-names></name><name><surname>Ding</surname><given-names>SL</given-names></name><name><surname>Dong</surname><given-names>W</given-names></name><name><surname>Fang</surname><given-names>R</given-names></name><name><surname>Fischer</surname><given-names>S</given-names></name><name><surname>Goldman</surname><given-names>M</given-names></name><name><surname>Goldy</surname><given-names>J</given-names></name><name><surname>Graybuck</surname><given-names>LT</given-names></name><name><surname>Herb</surname><given-names>BR</given-names></name><name><surname>Hou</surname><given-names>X</given-names></name><name><surname>Kancherla</surname><given-names>J</given-names></name><name><surname>Kroll</surname><given-names>M</given-names></name><name><surname>Lathia</surname><given-names>K</given-names></name><name><surname>van Lew</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>YE</given-names></name><name><surname>Liu</surname><given-names>CS</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Lucero</surname><given-names>JD</given-names></name><name><surname>Mahurkar</surname><given-names>A</given-names></name><name><surname>McMillen</surname><given-names>D</given-names></name><name><surname>Miller</surname><given-names>JA</given-names></name><name><surname>Moussa</surname><given-names>M</given-names></name><name><surname>Nery</surname><given-names>JR</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>Niu</surname><given-names>SY</given-names></name><name><surname>Orvis</surname><given-names>J</given-names></name><name><surname>Osteen</surname><given-names>JK</given-names></name><name><surname>Owen</surname><given-names>S</given-names></name><name><surname>Palmer</surname><given-names>CR</given-names></name><name><surname>Pham</surname><given-names>T</given-names></name><name><surname>Plongthongkum</surname><given-names>N</given-names></name><name><surname>Poirion</surname><given-names>O</given-names></name><name><surname>Reed</surname><given-names>NM</given-names></name><name><surname>Rimorin</surname><given-names>C</given-names></name><name><surname>Rivkin</surname><given-names>A</given-names></name><name><surname>Romanow</surname><given-names>WJ</given-names></name><name><surname>Sedeño-Cortés</surname><given-names>AE</given-names></name><name><surname>Siletti</surname><given-names>K</given-names></name><name><surname>Somasundaram</surname><given-names>S</given-names></name><name><surname>Sulc</surname><given-names>J</given-names></name><name><surname>Tieu</surname><given-names>M</given-names></name><name><surname>Torkelson</surname><given-names>A</given-names></name><name><surname>Tung</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Xie</surname><given-names>F</given-names></name><name><surname>Yanny</surname><given-names>AM</given-names></name><name><surname>Zhang</surname><given-names>R</given-names></name><name><surname>Ament</surname><given-names>SA</given-names></name><name><surname>Behrens</surname><given-names>MM</given-names></name><name><surname>Bravo</surname><given-names>HC</given-names></name><name><surname>Chun</surname><given-names>J</given-names></name><name><surname>Dobin</surname><given-names>A</given-names></name><name><surname>Gillis</surname><given-names>J</given-names></name><name><surname>Hertzano</surname><given-names>R</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name><name><surname>Höllt</surname><given-names>T</given-names></name><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Keene</surname><given-names>CD</given-names></name><name><surname>Kharchenko</surname><given-names>PV</given-names></name><name><surname>Ko</surname><given-names>AL</given-names></name><name><surname>Lelieveldt</surname><given-names>BP</given-names></name><name><surname>Luo</surname><given-names>C</given-names></name><name><surname>Mukamel</surname><given-names>EA</given-names></name><name><surname>Pinto-Duarte</surname><given-names>A</given-names></name><name><surname>Preissl</surname><given-names>S</given-names></name><name><surname>Regev</surname><given-names>A</given-names></name><name><surname>Ren</surname><given-names>B</given-names></name><name><surname>Scheuermann</surname><given-names>RH</given-names></name><name><surname>Smith</surname><given-names>K</given-names></name><name><surname>Spain</surname><given-names>WJ</given-names></name><name><surname>White</surname><given-names>OR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Macosko</surname><given-names>EZ</given-names></name><name><surname>McCarroll</surname><given-names>SA</given-names></name><name><surname>Ting</surname><given-names>JT</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Feng</surname><given-names>G</given-names></name><name><surname>Ecker</surname><given-names>JR</given-names></name><name><surname>Linnarsson</surname><given-names>S</given-names></name><name><surname>Lein</surname><given-names>ES</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Comparative cellular analysis of motor cortex in human, marmoset and mouse</article-title><source>Nature</source><volume>598</volume><fpage>111</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03465-8</pub-id><pub-id pub-id-type="pmid">34616062</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakkum</surname><given-names>DJ</given-names></name><name><surname>Frey</surname><given-names>U</given-names></name><name><surname>Radivojevic</surname><given-names>M</given-names></name><name><surname>Russell</surname><given-names>TL</given-names></name><name><surname>Müller</surname><given-names>J</given-names></name><name><surname>Fiscella</surname><given-names>M</given-names></name><name><surname>Takahashi</surname><given-names>H</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Tracking axonal action potential propagation on a high-density microelectrode array across hundreds of sites</article-title><source>Nature Communications</source><volume>4</volume><elocation-id>2181</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms3181</pub-id><pub-id pub-id-type="pmid">23867868</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakkum</surname><given-names>DJ</given-names></name><name><surname>Radivojevic</surname><given-names>M</given-names></name><name><surname>Frey</surname><given-names>U</given-names></name><name><surname>Franke</surname><given-names>F</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name><name><surname>Takahashi</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Parameters for burst detection</article-title><source>Frontiers in Computational Neuroscience</source><volume>7</volume><elocation-id>193</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2013.00193</pub-id><pub-id pub-id-type="pmid">24567714</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ballini</surname><given-names>M</given-names></name><name><surname>Müller</surname><given-names>J</given-names></name><name><surname>Livi</surname><given-names>P</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Frey</surname><given-names>U</given-names></name><name><surname>Stettler</surname><given-names>A</given-names></name><name><surname>Shadmani</surname><given-names>A</given-names></name><name><surname>Viswam</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>IL</given-names></name><name><surname>Jäckel</surname><given-names>D</given-names></name><name><surname>Radivojevic</surname><given-names>M</given-names></name><name><surname>Lewandowska</surname><given-names>MK</given-names></name><name><surname>Gong</surname><given-names>W</given-names></name><name><surname>Fiscella</surname><given-names>M</given-names></name><name><surname>Bakkum</surname><given-names>DJ</given-names></name><name><surname>Heer</surname><given-names>F</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A 1024-Channel CMOS microelectrode array with 26,400 electrodes for recording and stimulation of electrogenic cells in vitro</article-title><source>IEEE Journal of Solid-State Circuits</source><volume>49</volume><fpage>2705</fpage><lpage>2719</lpage><pub-id pub-id-type="doi">10.1109/JSSC.2014.2359219</pub-id><pub-id pub-id-type="pmid">28502989</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baltz</surname><given-names>T</given-names></name><name><surname>de Lima</surname><given-names>AD</given-names></name><name><surname>Voigt</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Contribution of GABAergic interneurons to the development of spontaneous activity patterns in cultured neocortical networks</article-title><source>Frontiers in Cellular Neuroscience</source><volume>4</volume><elocation-id>15</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2010.00015</pub-id><pub-id pub-id-type="pmid">20617185</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barabasi</surname><given-names>AL</given-names></name><name><surname>Albert</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Emergence of scaling in random networks</article-title><source>Science</source><volume>286</volume><fpage>509</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1126/science.286.5439.509</pub-id><pub-id pub-id-type="pmid">10521342</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barral</surname><given-names>J</given-names></name><name><surname>Reyes</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Synaptic scaling rule preserves excitatory–inhibitory balance and salient neuronal network dynamics</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1690</fpage><lpage>1696</lpage><pub-id pub-id-type="doi">10.1038/nn.4415</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Small-World Brain Networks Revisited</article-title><source>The Neuroscientist</source><volume>23</volume><fpage>499</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1177/1073858416667720</pub-id><pub-id pub-id-type="pmid">27655008</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Beasley</surname><given-names>WH</given-names></name><name><surname>Rodgers</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2012">2012</year><chapter-title>Bootstrapping and monte carlo methods</chapter-title><person-group person-group-type="editor"><name><surname>Beasley</surname><given-names>WH</given-names></name></person-group><source>APA Handbook of Research Methods in Psychology</source><publisher-name>American Psychological Association</publisher-name><fpage>407</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1037/13620-022</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname><given-names>J</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Ting</surname><given-names>JT</given-names></name><name><surname>Miller</surname><given-names>JA</given-names></name><name><surname>Chartrand</surname><given-names>T</given-names></name><name><surname>Buchin</surname><given-names>A</given-names></name><name><surname>Bakken</surname><given-names>TE</given-names></name><name><surname>Budzillo</surname><given-names>A</given-names></name><name><surname>Dee</surname><given-names>N</given-names></name><name><surname>Ding</surname><given-names>S-L</given-names></name><name><surname>Gouwens</surname><given-names>NW</given-names></name><name><surname>Hodge</surname><given-names>RD</given-names></name><name><surname>Kalmbach</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>BR</given-names></name><name><surname>Alfiler</surname><given-names>L</given-names></name><name><surname>Baker</surname><given-names>K</given-names></name><name><surname>Barkan</surname><given-names>E</given-names></name><name><surname>Beller</surname><given-names>A</given-names></name><name><surname>Berry</surname><given-names>K</given-names></name><name><surname>Bertagnolli</surname><given-names>D</given-names></name><name><surname>Bickley</surname><given-names>K</given-names></name><name><surname>Bomben</surname><given-names>J</given-names></name><name><surname>Braun</surname><given-names>T</given-names></name><name><surname>Brouner</surname><given-names>K</given-names></name><name><surname>Casper</surname><given-names>T</given-names></name><name><surname>Chong</surname><given-names>P</given-names></name><name><surname>Crichton</surname><given-names>K</given-names></name><name><surname>Dalley</surname><given-names>R</given-names></name><name><surname>de Frates</surname><given-names>R</given-names></name><name><surname>Desta</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>SD</given-names></name><name><surname>D’Orazi</surname><given-names>F</given-names></name><name><surname>Dotson</surname><given-names>N</given-names></name><name><surname>Egdorf</surname><given-names>T</given-names></name><name><surname>Enstrom</surname><given-names>R</given-names></name><name><surname>Farrell</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Fong</surname><given-names>O</given-names></name><name><surname>Furdan</surname><given-names>S</given-names></name><name><surname>Galakhova</surname><given-names>AA</given-names></name><name><surname>Gamlin</surname><given-names>C</given-names></name><name><surname>Gary</surname><given-names>A</given-names></name><name><surname>Glandon</surname><given-names>A</given-names></name><name><surname>Goldy</surname><given-names>J</given-names></name><name><surname>Gorham</surname><given-names>M</given-names></name><name><surname>Goriounova</surname><given-names>NA</given-names></name><name><surname>Gratiy</surname><given-names>S</given-names></name><name><surname>Graybuck</surname><given-names>L</given-names></name><name><surname>Gu</surname><given-names>H</given-names></name><name><surname>Hadley</surname><given-names>K</given-names></name><name><surname>Hansen</surname><given-names>N</given-names></name><name><surname>Heistek</surname><given-names>TS</given-names></name><name><surname>Henry</surname><given-names>AM</given-names></name><name><surname>Heyer</surname><given-names>DB</given-names></name><name><surname>Hill</surname><given-names>D</given-names></name><name><surname>Hill</surname><given-names>C</given-names></name><name><surname>Hupp</surname><given-names>M</given-names></name><name><surname>Jarsky</surname><given-names>T</given-names></name><name><surname>Kebede</surname><given-names>S</given-names></name><name><surname>Keene</surname><given-names>L</given-names></name><name><surname>Kim</surname><given-names>L</given-names></name><name><surname>Kim</surname><given-names>M-H</given-names></name><name><surname>Kroll</surname><given-names>M</given-names></name><name><surname>Latimer</surname><given-names>C</given-names></name><name><surname>Levi</surname><given-names>BP</given-names></name><name><surname>Link</surname><given-names>KE</given-names></name><name><surname>Mallory</surname><given-names>M</given-names></name><name><surname>Mann</surname><given-names>R</given-names></name><name><surname>Marshall</surname><given-names>D</given-names></name><name><surname>Maxwell</surname><given-names>M</given-names></name><name><surname>McGraw</surname><given-names>M</given-names></name><name><surname>McMillen</surname><given-names>D</given-names></name><name><surname>Melief</surname><given-names>E</given-names></name><name><surname>Mertens</surname><given-names>EJ</given-names></name><name><surname>Mezei</surname><given-names>L</given-names></name><name><surname>Mihut</surname><given-names>N</given-names></name><name><surname>Mok</surname><given-names>S</given-names></name><name><surname>Molnar</surname><given-names>G</given-names></name><name><surname>Mukora</surname><given-names>A</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Ngo</surname><given-names>K</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>Nyhus</surname><given-names>J</given-names></name><name><surname>Olah</surname><given-names>G</given-names></name><name><surname>Oldre</surname><given-names>A</given-names></name><name><surname>Omstead</surname><given-names>V</given-names></name><name><surname>Ozsvar</surname><given-names>A</given-names></name><name><surname>Park</surname><given-names>D</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Pham</surname><given-names>T</given-names></name><name><surname>Pom</surname><given-names>CA</given-names></name><name><surname>Potekhina</surname><given-names>L</given-names></name><name><surname>Rajanbabu</surname><given-names>R</given-names></name><name><surname>Ransford</surname><given-names>S</given-names></name><name><surname>Reid</surname><given-names>D</given-names></name><name><surname>Rimorin</surname><given-names>C</given-names></name><name><surname>Ruiz</surname><given-names>A</given-names></name><name><surname>Sandman</surname><given-names>D</given-names></name><name><surname>Sulc</surname><given-names>J</given-names></name><name><surname>Sunkin</surname><given-names>SM</given-names></name><name><surname>Szafer</surname><given-names>A</given-names></name><name><surname>Szemenyei</surname><given-names>V</given-names></name><name><surname>Thomsen</surname><given-names>ER</given-names></name><name><surname>Tieu</surname><given-names>M</given-names></name><name><surname>Torkelson</surname><given-names>A</given-names></name><name><surname>Trinh</surname><given-names>J</given-names></name><name><surname>Tung</surname><given-names>H</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Waleboer</surname><given-names>F</given-names></name><name><surname>Ward</surname><given-names>K</given-names></name><name><surname>Wilbers</surname><given-names>R</given-names></name><name><surname>Williams</surname><given-names>G</given-names></name><name><surname>Yao</surname><given-names>Z</given-names></name><name><surname>Yoon</surname><given-names>J-G</given-names></name><name><surname>Anastassiou</surname><given-names>C</given-names></name><name><surname>Arkhipov</surname><given-names>A</given-names></name><name><surname>Barzo</surname><given-names>P</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Cobbs</surname><given-names>C</given-names></name><name><surname>de Witt Hamer</surname><given-names>PC</given-names></name><name><surname>Ellenbogen</surname><given-names>RG</given-names></name><name><surname>Esposito</surname><given-names>L</given-names></name><name><surname>Ferreira</surname><given-names>M</given-names></name><name><surname>Gwinn</surname><given-names>RP</given-names></name><name><surname>Hawrylycz</surname><given-names>MJ</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name><name><surname>Idema</surname><given-names>S</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Keene</surname><given-names>CD</given-names></name><name><surname>Ko</surname><given-names>AL</given-names></name><name><surname>Murphy</surname><given-names>GJ</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Ojemann</surname><given-names>JG</given-names></name><name><surname>Patel</surname><given-names>AP</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Silbergeld</surname><given-names>DL</given-names></name><name><surname>Smith</surname><given-names>K</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name><name><surname>Segev</surname><given-names>I</given-names></name><name><surname>de Kock</surname><given-names>CPJ</given-names></name><name><surname>Mansvelder</surname><given-names>HD</given-names></name><name><surname>Tamas</surname><given-names>G</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Lein</surname><given-names>ES</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Human neocortical expansion involves glutamatergic neuron diversification</article-title><source>Nature</source><volume>598</volume><fpage>151</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03813-8</pub-id><pub-id pub-id-type="pmid">34616067</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betzel</surname><given-names>RF</given-names></name><name><surname>Avena-Koenigsberger</surname><given-names>A</given-names></name><name><surname>Goñi</surname><given-names>J</given-names></name><name><surname>He</surname><given-names>Y</given-names></name><name><surname>de Reus</surname><given-names>MA</given-names></name><name><surname>Griffa</surname><given-names>A</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Mišic</surname><given-names>B</given-names></name><name><surname>Thiran</surname><given-names>JP</given-names></name><name><surname>Hagmann</surname><given-names>P</given-names></name><name><surname>van den Heuvel</surname><given-names>M</given-names></name><name><surname>Zuo</surname><given-names>XN</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Generative models of the human connectome</article-title><source>NeuroImage</source><volume>124</volume><fpage>1054</fpage><lpage>1064</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.09.041</pub-id><pub-id pub-id-type="pmid">26427642</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betzel</surname><given-names>RF</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Multi-scale brain networks</article-title><source>NeuroImage</source><volume>160</volume><fpage>73</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.11.006</pub-id><pub-id pub-id-type="pmid">27845257</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betzel</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Organizing principles of whole-brain functional connectivity in zebrafish larvae</article-title><source>Network Neuroscience</source><volume>4</volume><fpage>234</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1162/netn_a_00121</pub-id><pub-id pub-id-type="pmid">32166210</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blankenship</surname><given-names>AG</given-names></name><name><surname>Feller</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Mechanisms underlying spontaneous patterned activity in developing neural circuits</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>18</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1038/nrn2759</pub-id><pub-id pub-id-type="pmid">19953103</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blondel</surname><given-names>VD</given-names></name><name><surname>Guillaume</surname><given-names>JL</given-names></name><name><surname>Lambiotte</surname><given-names>R</given-names></name><name><surname>Lefebvre</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Fast unfolding of communities in large networks</article-title><source>Journal of Statistical Mechanics</source><volume>2008</volume><elocation-id>10008</elocation-id><pub-id pub-id-type="doi">10.1088/1742-5468/2008/10/P10008</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogdan</surname><given-names>P</given-names></name><name><surname>Caetano-Anollés</surname><given-names>G</given-names></name><name><surname>Jolles</surname><given-names>A</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Morris</surname><given-names>J</given-names></name><name><surname>Murphy</surname><given-names>CA</given-names></name><name><surname>Royer</surname><given-names>C</given-names></name><name><surname>Snell</surname><given-names>EH</given-names></name><name><surname>Steinbrenner</surname><given-names>A</given-names></name><name><surname>Strausfeld</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Biological networks across scales—the theoretical and empirical foundations for time-varying complex networks that connect structure and function across levels of biological organization</article-title><source>Integrative and Comparative Biology</source><volume>61</volume><fpage>1991</fpage><lpage>2010</lpage><pub-id pub-id-type="doi">10.1093/icb/icab069</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boguñá</surname><given-names>M</given-names></name><name><surname>Papadopoulos</surname><given-names>F</given-names></name><name><surname>Krioukov</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sustaining the Internet with hyperbolic mapping</article-title><source>Nature Communications</source><volume>1</volume><elocation-id>62</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1063</pub-id><pub-id pub-id-type="pmid">20842196</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonifazi</surname><given-names>P</given-names></name><name><surname>Goldin</surname><given-names>M</given-names></name><name><surname>Picardo</surname><given-names>MA</given-names></name><name><surname>Jorquera</surname><given-names>I</given-names></name><name><surname>Cattani</surname><given-names>A</given-names></name><name><surname>Bianconi</surname><given-names>G</given-names></name><name><surname>Represa</surname><given-names>A</given-names></name><name><surname>Ben-Ari</surname><given-names>Y</given-names></name><name><surname>Cossart</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>GABAergic hub neurons orchestrate synchrony in developing hippocampal networks</article-title><source>Science</source><volume>326</volume><fpage>1419</fpage><lpage>1424</lpage><pub-id pub-id-type="doi">10.1126/science.1175509</pub-id><pub-id pub-id-type="pmid">19965761</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Braitenberg</surname><given-names>V</given-names></name><name><surname>Schüz</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><chapter-title>Microscopic evidence of the spacing of synapses on axons</chapter-title><person-group person-group-type="editor"><name><surname>Braitenberg</surname><given-names>V</given-names></name><name><surname>Schüz</surname><given-names>A</given-names></name></person-group><source>Cortex: Statistics and Geometry of Neuronal Connectivity</source><publisher-name>Springer</publisher-name><fpage>45</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1007/978-3-662-03733-1_9</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggman</surname><given-names>KL</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Wiring specificity in the direction-selectivity circuit of the retina</article-title><source>Nature</source><volume>471</volume><fpage>183</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1038/nature09818</pub-id><pub-id pub-id-type="pmid">21390125</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buccino</surname><given-names>AP</given-names></name><name><surname>Hurwitz</surname><given-names>CL</given-names></name><name><surname>Garcia</surname><given-names>S</given-names></name><name><surname>Magland</surname><given-names>J</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Hurwitz</surname><given-names>R</given-names></name><name><surname>Hennig</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>SpikeInterface, a unified framework for spike sorting</article-title><source>eLife</source><volume>9</volume><elocation-id>e61834</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.61834</pub-id><pub-id pub-id-type="pmid">33170122</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>186</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1038/nrn2575</pub-id><pub-id pub-id-type="pmid">19190637</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The economy of brain network organization</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>336</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1038/nrn3214</pub-id><pub-id pub-id-type="pmid">22498897</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Fornito</surname><given-names>A</given-names></name><name><surname>Zalesky</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><chapter-title>Chapter 8 - motifs, small worlds, and network economy</chapter-title><person-group person-group-type="editor"><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><source>Fundamentals of Brain Network Analysis</source><publisher-name>Academic press</publisher-name><fpage>257</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-407908-3.00008-X</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Mizuseki</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The log-dynamic brain: how skewed distributions affect network operations</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>264</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1038/nrn3687</pub-id><pub-id pub-id-type="pmid">24569488</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabrera-Garcia</surname><given-names>D</given-names></name><name><surname>Warm</surname><given-names>D</given-names></name><name><surname>de la Fuente</surname><given-names>P</given-names></name><name><surname>Fernández-Sánchez</surname><given-names>MT</given-names></name><name><surname>Novelli</surname><given-names>A</given-names></name><name><surname>Villanueva-Balsera</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Early prediction of developing spontaneous activity in cultured neuronal networks</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>20407</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-99538-9</pub-id><pub-id pub-id-type="pmid">34650146</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cajal</surname><given-names>SR</given-names></name><name><surname>Swanson</surname><given-names>N</given-names></name><name><surname>Swanson</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Cajal’s Histology of the Nervous System of Man and Vertebrates</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/oso/9780195074017.001.0001</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carozza</surname><given-names>S</given-names></name><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Astle</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023a</year><article-title>The adaptive stochasticity hypothesis: Modeling equifinality, multifinality, and adaptation to adversity</article-title><source>PNAS</source><volume>120</volume><elocation-id>e2307508120</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2307508120</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carozza</surname><given-names>S</given-names></name><name><surname>Holmes</surname><given-names>J</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Arefin</surname><given-names>TM</given-names></name><name><surname>Pugliese</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Kaffman</surname><given-names>A</given-names></name><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Astle</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2023">2023b</year><article-title>Early adversity changes the economic conditions of mouse structural brain network organization</article-title><source>Developmental Psychobiology</source><volume>65</volume><elocation-id>e22405</elocation-id><pub-id pub-id-type="doi">10.1002/dev.22405</pub-id><pub-id pub-id-type="pmid">37607894</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>BL</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Wiring optimization can relate neuronal structure and function</article-title><source>PNAS</source><volume>103</volume><fpage>4723</fpage><lpage>4728</lpage><pub-id pub-id-type="doi">10.1073/pnas.0506806103</pub-id><pub-id pub-id-type="pmid">16537428</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Hilgetag</surname><given-names>CC</given-names></name><name><surname>Zhou</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Features of spatial and functional segregation and integration of the primate connectome revealed by trade-off between wiring cost and efficiency</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005776</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005776</pub-id><pub-id pub-id-type="pmid">28961235</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>E</given-names></name><name><surname>Ivenshitz</surname><given-names>M</given-names></name><name><surname>Amor-Baroukh</surname><given-names>V</given-names></name><name><surname>Greenberger</surname><given-names>V</given-names></name><name><surname>Segal</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Determinants of spontaneous activity in networks of cultured hippocampus</article-title><source>Brain Research</source><volume>1235</volume><fpage>21</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2008.06.022</pub-id><pub-id pub-id-type="pmid">18602907</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cossart</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Operational hub cells: a morpho-physiologically diverse class of GABAergic neurons united by a common function</article-title><source>Current Opinion in Neurobiology</source><volume>26</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.12.002</pub-id><pub-id pub-id-type="pmid">24650504</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cotterill</surname><given-names>E</given-names></name><name><surname>Charlesworth</surname><given-names>P</given-names></name><name><surname>Thomas</surname><given-names>CW</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name><name><surname>Eglen</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A comparison of computational methods for detecting bursts in neuronal spike trains and their application to human stem cell-derived neuronal networks</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>306</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1152/jn.00093.2016</pub-id><pub-id pub-id-type="pmid">27098024</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cutts</surname><given-names>CS</given-names></name><name><surname>Eglen</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Detecting pairwise correlations in spike trains: an objective comparison of methods and application to the study of retinal waves</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>14288</fpage><lpage>14303</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2767-14.2014</pub-id><pub-id pub-id-type="pmid">25339742</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damicelli</surname><given-names>F</given-names></name><name><surname>Hilgetag</surname><given-names>CC</given-names></name><name><surname>Hütt</surname><given-names>MT</given-names></name><name><surname>Messé</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Topological reinforcement as a principle of modularity emergence in brain networks</article-title><source>Network Neuroscience</source><volume>3</volume><fpage>589</fpage><lpage>605</lpage><pub-id pub-id-type="doi">10.1162/netn_a_00085</pub-id><pub-id pub-id-type="pmid">31157311</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Das</surname><given-names>A</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Systematic errors in connectivity inferred from activity in strongly recurrent networks</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1286</fpage><lpage>1296</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0699-2</pub-id><pub-id pub-id-type="pmid">32895567</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deleuze</surname><given-names>C</given-names></name><name><surname>Pazienti</surname><given-names>A</given-names></name><name><surname>Bacci</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Autaptic self-inhibition of cortical GABAergic neurons: synaptic narcissism or useful introspection?</article-title><source>Current Opinion in Neurobiology</source><volume>26</volume><fpage>64</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.12.009</pub-id><pub-id pub-id-type="pmid">24434607</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>HM</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Zuo</surname><given-names>XN</given-names></name><name><surname>Holmes</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Shifting gradients of macroscale cortical organization mark the transition from childhood to adolescence</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2024448118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2024448118</pub-id><pub-id pub-id-type="pmid">34260385</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donner</surname><given-names>C</given-names></name><name><surname>Bartram</surname><given-names>J</given-names></name><name><surname>Hornauer</surname><given-names>P</given-names></name><name><surname>Kim</surname><given-names>T</given-names></name><name><surname>Roqueiro</surname><given-names>D</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name><name><surname>Obozinski</surname><given-names>G</given-names></name><name><surname>Schröter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Ensemble learning and ground-truth validation of synaptic connectivity inferred from spike trains</article-title><source>PLOS Computational Biology</source><volume>20</volume><elocation-id>e1011964</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011964</pub-id><pub-id pub-id-type="pmid">38683881</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downes</surname><given-names>JH</given-names></name><name><surname>Hammond</surname><given-names>MW</given-names></name><name><surname>Xydas</surname><given-names>D</given-names></name><name><surname>Spencer</surname><given-names>MC</given-names></name><name><surname>Becerra</surname><given-names>VM</given-names></name><name><surname>Warwick</surname><given-names>K</given-names></name><name><surname>Whalley</surname><given-names>BJ</given-names></name><name><surname>Nasuto</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Emergence of a small-world functional network in cultured neurons</article-title><source>PLOS Computational Biology</source><volume>8</volume><elocation-id>e1002522</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002522</pub-id><pub-id pub-id-type="pmid">22615555</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>TA</given-names></name><name><surname>Schölvinck</surname><given-names>ML</given-names></name><name><surname>Lewis</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The diversity and specificity of functional connectivity across spatial and temporal scales</article-title><source>NeuroImage</source><volume>245</volume><elocation-id>118692</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118692</pub-id><pub-id pub-id-type="pmid">34751153</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>English</surname><given-names>DF</given-names></name><name><surname>McKenzie</surname><given-names>S</given-names></name><name><surname>Evans</surname><given-names>T</given-names></name><name><surname>Kim</surname><given-names>K</given-names></name><name><surname>Yoon</surname><given-names>E</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Pyramidal cell-interneuron circuit architecture and dynamics in hippocampal networks</article-title><source>Neuron</source><volume>96</volume><fpage>505</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.033</pub-id><pub-id pub-id-type="pmid">29024669</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ercsey-Ravasz</surname><given-names>M</given-names></name><name><surname>Markov</surname><given-names>NT</given-names></name><name><surname>Lamy</surname><given-names>C</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Toroczkai</surname><given-names>Z</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A predictive network model of cerebral cortical connectivity based on a distance rule</article-title><source>Neuron</source><volume>80</volume><fpage>184</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.036</pub-id><pub-id pub-id-type="pmid">24094111</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erdős</surname><given-names>P</given-names></name><name><surname>Rényi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>On random graphs I</article-title><source>Publicationes Mathematicae Debrecen</source><volume>6</volume><fpage>290</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.5486/PMD.1959.6.3-4.12</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Fabre</surname><given-names>JMJ</given-names></name><name><surname>Beest van</surname><given-names>E</given-names></name><name><surname>Peters</surname><given-names>AJ</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Bombcell: automated curation and cell classification of spike-sorted electrophysiology data</data-title><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.8172821">https://doi.org/10.5281/zenodo.8172821</ext-link></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fair</surname><given-names>DA</given-names></name><name><surname>Dosenbach</surname><given-names>NUF</given-names></name><name><surname>Church</surname><given-names>JA</given-names></name><name><surname>Cohen</surname><given-names>AL</given-names></name><name><surname>Brahmbhatt</surname><given-names>S</given-names></name><name><surname>Miezin</surname><given-names>FM</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Development of distinct control networks through segregation and integration</article-title><source>PNAS</source><volume>104</volume><fpage>13507</fpage><lpage>13512</lpage><pub-id pub-id-type="doi">10.1073/pnas.0705843104</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganguly</surname><given-names>K</given-names></name><name><surname>Schinder</surname><given-names>AF</given-names></name><name><surname>Wong</surname><given-names>ST</given-names></name><name><surname>Poo</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>GABA itself promotes the developmental switch of neuronal GABAergic responses from excitation to inhibition</article-title><source>Cell</source><volume>105</volume><fpage>521</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1016/s0092-8674(01)00341-5</pub-id><pub-id pub-id-type="pmid">11371348</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giandomenico</surname><given-names>SL</given-names></name><name><surname>Mierau</surname><given-names>SB</given-names></name><name><surname>Gibbons</surname><given-names>GM</given-names></name><name><surname>Wenger</surname><given-names>LMD</given-names></name><name><surname>Masullo</surname><given-names>L</given-names></name><name><surname>Sit</surname><given-names>T</given-names></name><name><surname>Sutcliffe</surname><given-names>M</given-names></name><name><surname>Boulanger</surname><given-names>J</given-names></name><name><surname>Tripodi</surname><given-names>M</given-names></name><name><surname>Derivery</surname><given-names>E</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name><name><surname>Lakatos</surname><given-names>A</given-names></name><name><surname>Lancaster</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cerebral organoids at the air-liquid interface generate diverse nerve tracts with functional output</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>669</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0350-2</pub-id><pub-id pub-id-type="pmid">30886407</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goulas</surname><given-names>A</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name><name><surname>Hilgetag</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spatiotemporal ontogeny of brain wiring</article-title><source>Science Advances</source><volume>5</volume><elocation-id>eaav9694</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aav9694</pub-id><pub-id pub-id-type="pmid">31206020</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafizi</surname><given-names>H</given-names></name><name><surname>Nigam</surname><given-names>S</given-names></name><name><surname>Barnathan</surname><given-names>J</given-names></name><name><surname>Ren</surname><given-names>N</given-names></name><name><surname>Stevenson</surname><given-names>IH</given-names></name><name><surname>Masmanidis</surname><given-names>SC</given-names></name><name><surname>Newman</surname><given-names>EL</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Beggs</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Inhibition-dominated rich-club shapes dynamics in cortical microcircuits</article-title><source>Neuroscience</source><volume>1</volume><elocation-id>443074</elocation-id><pub-id pub-id-type="doi">10.1101/2021.05.07.443074</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hagmann</surname><given-names>P</given-names></name><name><surname>Kurant</surname><given-names>M</given-names></name><name><surname>Gigandet</surname><given-names>X</given-names></name><name><surname>Thiran</surname><given-names>P</given-names></name><name><surname>Wedeen</surname><given-names>VJ</given-names></name><name><surname>Meuli</surname><given-names>R</given-names></name><name><surname>Thiran</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Mapping human whole-brain structural networks with diffusion MRI</article-title><source>PLOS ONE</source><volume>2</volume><elocation-id>e597</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0000597</pub-id><pub-id pub-id-type="pmid">17611629</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harriger</surname><given-names>L</given-names></name><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rich club organization of macaque cerebral cortex and its role in network communication</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e46497</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0046497</pub-id><pub-id pub-id-type="pmid">23029538</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hebb</surname><given-names>DO</given-names></name></person-group><year iso-8601-date="1949">1949</year><source>The Organization of Behavior: A Neuropsychological Theory</source><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hiesinger</surname><given-names>PR</given-names></name><name><surname>Hassan</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The evolution of variability and robustness in neural development</article-title><source>Trends in Neurosciences</source><volume>41</volume><fpage>577</fpage><lpage>586</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2018.05.007</pub-id><pub-id pub-id-type="pmid">29880259</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hilgetag</surname><given-names>CC</given-names></name><name><surname>Goulas</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>‘Hierarchy’ in the organization of brain networks</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>375</volume><elocation-id>20190319</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2019.0319</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holler</surname><given-names>S</given-names></name><name><surname>Köstinger</surname><given-names>G</given-names></name><name><surname>Martin</surname><given-names>KAC</given-names></name><name><surname>Schuhknecht</surname><given-names>GFP</given-names></name><name><surname>Stratford</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Structure and function of a neocortical synapse</article-title><source>Nature</source><volume>591</volume><fpage>111</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-03134-2</pub-id><pub-id pub-id-type="pmid">33442056</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ivenshitz</surname><given-names>M</given-names></name><name><surname>Segal</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neuronal density determines network connectivity and spontaneous activity in cultured hippocampus</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>1052</fpage><lpage>1060</lpage><pub-id pub-id-type="doi">10.1152/jn.00914.2009</pub-id><pub-id pub-id-type="pmid">20554850</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jain</surname><given-names>S</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name><name><surname>Kurmangaliyev</surname><given-names>YZ</given-names></name><name><surname>Valdes-Aleman</surname><given-names>J</given-names></name><name><surname>LoCascio</surname><given-names>SA</given-names></name><name><surname>Mirshahidi</surname><given-names>P</given-names></name><name><surname>Parrington</surname><given-names>B</given-names></name><name><surname>Zipursky</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A global timing mechanism regulates cell-type-specific wiring programmes</article-title><source>Nature</source><volume>603</volume><fpage>112</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1038/s41586-022-04418-5</pub-id><pub-id pub-id-type="pmid">35197627</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Interactive specialization: a domain-general framework for human functional brain development?</article-title><source>Developmental Cognitive Neuroscience</source><volume>1</volume><fpage>7</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2010.07.003</pub-id><pub-id pub-id-type="pmid">22436416</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>AG</given-names></name><name><surname>Wang</surname><given-names>N</given-names></name><name><surname>Anderson</surname><given-names>RJ</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Cofer</surname><given-names>GP</given-names></name><name><surname>Gee</surname><given-names>JC</given-names></name><name><surname>Pratson</surname><given-names>F</given-names></name><name><surname>Tustison</surname><given-names>N</given-names></name><name><surname>White</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Whole mouse brain connectomics</article-title><source>Journal of Comparative Neurology</source><volume>527</volume><fpage>2146</fpage><lpage>2157</lpage><pub-id pub-id-type="doi">10.1002/cne.24560</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>DK</given-names></name><name><surname>Leemans</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Diffusion tensor imaging</article-title><source>Methods in Molecular Biology</source><volume>711</volume><fpage>127</fpage><lpage>144</lpage><pub-id pub-id-type="doi">10.1007/978-1-61737-992-5_6</pub-id><pub-id pub-id-type="pmid">21279600</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>DK</given-names></name><name><surname>Knösche</surname><given-names>TR</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>White matter integrity, fiber count, and other fallacies: the do’s and don’ts of diffusion MRI</article-title><source>NeuroImage</source><volume>73</volume><fpage>239</fpage><lpage>254</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.06.081</pub-id><pub-id pub-id-type="pmid">22846632</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaiser</surname><given-names>M</given-names></name><name><surname>Hilgetag</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Modelling the development of cortical systems networks</article-title><source>Neurocomputing</source><volume>58–60</volume><fpage>297</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2004.01.059</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasai</surname><given-names>H</given-names></name><name><surname>Ziv</surname><given-names>NE</given-names></name><name><surname>Okazaki</surname><given-names>H</given-names></name><name><surname>Yagishita</surname><given-names>S</given-names></name><name><surname>Toyoizumi</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Spine dynamics in the brain, mental disorders and artificial neural networks</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>407</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00467-3</pub-id><pub-id pub-id-type="pmid">34050339</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimm</surname><given-names>F</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Carlson</surname><given-names>JM</given-names></name><name><surname>Mucha</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Resolving structural variability in network models and the brain</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003491</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003491</pub-id><pub-id pub-id-type="pmid">24675546</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Mur</surname><given-names>M</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Latora</surname><given-names>V</given-names></name><name><surname>Marchiori</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Efficient behavior of small-world networks</article-title><source>Physical Review Letters</source><volume>87</volume><elocation-id>198701</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.87.198701</pub-id><pub-id pub-id-type="pmid">11690461</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laughlin</surname><given-names>SB</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Communication in neuronal networks</article-title><source>Science</source><volume>301</volume><fpage>1870</fpage><lpage>1874</lpage><pub-id pub-id-type="doi">10.1126/science.1089662</pub-id><pub-id pub-id-type="pmid">14512617</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Magueresse</surname><given-names>C</given-names></name><name><surname>Monyer</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>GABAergic interneurons shape the functional maturation of the cortex</article-title><source>Neuron</source><volume>77</volume><fpage>388</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.01.011</pub-id><pub-id pub-id-type="pmid">23395369</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libby</surname><given-names>E</given-names></name><name><surname>Perkins</surname><given-names>TJ</given-names></name><name><surname>Swain</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Noisy information processing through transcriptional regulation</article-title><source>PNAS</source><volume>104</volume><fpage>7151</fpage><lpage>7156</lpage><pub-id pub-id-type="doi">10.1073/pnas.0608963104</pub-id><pub-id pub-id-type="pmid">17420464</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lindfield</surname><given-names>G</given-names></name><name><surname>Penny</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><chapter-title>Linear equations and eigensystems</chapter-title><person-group person-group-type="editor"><name><surname>Lindfield</surname><given-names>G</given-names></name><name><surname>Penny</surname><given-names>J</given-names></name></person-group><source>Numerical Methods</source><publisher-name>Academic Press</publisher-name><fpage>1</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-812256-3.00011-7</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Si</surname><given-names>S</given-names></name><name><surname>Hu</surname><given-names>B</given-names></name><name><surname>Zhao</surname><given-names>H</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A generative network model of the human brain normal aging process</article-title><source>Symmetry</source><volume>12</volume><elocation-id>91</elocation-id><pub-id pub-id-type="doi">10.3390/sym12010091</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Seguin</surname><given-names>C</given-names></name><name><surname>Mansour</surname><given-names>S</given-names></name><name><surname>Oldham</surname><given-names>S</given-names></name><name><surname>Betzel</surname><given-names>R</given-names></name><name><surname>Di Biase</surname><given-names>MA</given-names></name><name><surname>Zalesky</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Parameter estimation for connectome generative models: Accuracy, reliability, and a fast parameter fitting method</article-title><source>NeuroImage</source><volume>270</volume><elocation-id>119962</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.119962</pub-id><pub-id pub-id-type="pmid">36822248</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Seguin</surname><given-names>C</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name><name><surname>Han</surname><given-names>D</given-names></name><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Di Biase</surname><given-names>MA</given-names></name><name><surname>Zalesky</surname><given-names>A</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Seguin</surname><given-names>C</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name><name><surname>Han</surname><given-names>D</given-names></name><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Di Biase</surname><given-names>MA</given-names></name><name><surname>Zalesky</surname><given-names>A</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Seguin</surname><given-names>C</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name><name><surname>Han</surname><given-names>D</given-names></name><name><surname>Akarca</surname><given-names>D</given-names></name><name><surname>Di Biase</surname><given-names>MA</given-names></name><name><surname>Zalesky</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>A generative model of the connectome with dynamic axon growth</article-title><source>Network Neuroscience</source><volume>8</volume><fpage>1192</fpage><lpage>1211</lpage><pub-id pub-id-type="doi">10.1162/netn_a_00397</pub-id><pub-id pub-id-type="pmid">39735503</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loewenstein</surname><given-names>Y</given-names></name><name><surname>Kuras</surname><given-names>A</given-names></name><name><surname>Rumpel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multiplicative dynamics underlie the emergence of the log-normal distribution of spine sizes in the neocortex in vivo</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>9481</fpage><lpage>9488</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6130-10.2011</pub-id><pub-id pub-id-type="pmid">21715613</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lord</surname><given-names>LD</given-names></name><name><surname>Stevner</surname><given-names>AB</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Kringelbach</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Understanding principles of integration and segregation using whole-brain computational connectomics: implications for neuropsychiatric disorders</article-title><source>Philosophical Transactions of the Royal Society A</source><volume>375</volume><elocation-id>20160283</elocation-id><pub-id pub-id-type="doi">10.1098/rsta.2016.0283</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malkov</surname><given-names>YA</given-names></name><name><surname>Ponomarenko</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Growing homophilic networks are natural navigable small worlds</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0158162</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0158162</pub-id><pub-id pub-id-type="pmid">27348120</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mann</surname><given-names>EO</given-names></name><name><surname>Kohl</surname><given-names>MM</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Distinct roles of GABA(A) and GABA(B) receptors in balancing and terminating persistent cortical activity</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>7513</fpage><lpage>7518</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6162-08.2009</pub-id><pub-id pub-id-type="pmid">19515919</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshall</surname><given-names>N</given-names></name><name><surname>Timme</surname><given-names>NM</given-names></name><name><surname>Bennett</surname><given-names>N</given-names></name><name><surname>Ripp</surname><given-names>M</given-names></name><name><surname>Lautzenhiser</surname><given-names>E</given-names></name><name><surname>Beggs</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Analysis of power laws, shape collapses, and neural complexity: new techniques and MATLAB support via the NCC toolbox</article-title><source>Frontiers in Physiology</source><volume>7</volume><elocation-id>250</elocation-id><pub-id pub-id-type="doi">10.3389/fphys.2016.00250</pub-id><pub-id pub-id-type="pmid">27445842</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maslov</surname><given-names>S</given-names></name><name><surname>Sneppen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Specificity and stability in topology of protein networks</article-title><source>Science</source><volume>296</volume><fpage>910</fpage><lpage>913</lpage><pub-id pub-id-type="doi">10.1126/science.1065103</pub-id><pub-id pub-id-type="pmid">11988575</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McPherson</surname><given-names>M</given-names></name><name><surname>Smith-Lovin</surname><given-names>L</given-names></name><name><surname>Cook</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Birds of a feather: homophily in social networks</article-title><source>Annual Review of Sociology</source><volume>27</volume><fpage>415</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1146/annurev.soc.27.1.415</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meunier</surname><given-names>D</given-names></name><name><surname>Lambiotte</surname><given-names>R</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modular and hierarchically modular organization of brain networks</article-title><source>Frontiers in Neuroscience</source><volume>4</volume><elocation-id>200</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2010.00200</pub-id><pub-id pub-id-type="pmid">21151783</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>SE</given-names></name><name><surname>Achard</surname><given-names>S</given-names></name><name><surname>Termenon</surname><given-names>M</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Low-dimensional morphospace of topological motifs in human fMRI brain networks</article-title><source>Network Neuroscience</source><volume>2</volume><fpage>285</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1162/netn_a_00038</pub-id><pub-id pub-id-type="pmid">30215036</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mortimer</surname><given-names>D</given-names></name><name><surname>Feldner</surname><given-names>J</given-names></name><name><surname>Vaughan</surname><given-names>T</given-names></name><name><surname>Vetter</surname><given-names>I</given-names></name><name><surname>Pujic</surname><given-names>Z</given-names></name><name><surname>Rosoff</surname><given-names>WJ</given-names></name><name><surname>Burrage</surname><given-names>K</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Richards</surname><given-names>LJ</given-names></name><name><surname>Goodhill</surname><given-names>GJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A Bayesian model predicts the response of axons to molecular gradients</article-title><source>PNAS</source><volume>106</volume><fpage>10296</fpage><lpage>10301</lpage><pub-id pub-id-type="doi">10.1073/pnas.0900715106</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motta</surname><given-names>A</given-names></name><name><surname>Berning</surname><given-names>M</given-names></name><name><surname>Boergens</surname><given-names>KM</given-names></name><name><surname>Staffler</surname><given-names>B</given-names></name><name><surname>Beining</surname><given-names>M</given-names></name><name><surname>Loomba</surname><given-names>S</given-names></name><name><surname>Hennig</surname><given-names>P</given-names></name><name><surname>Wissler</surname><given-names>H</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dense connectomic reconstruction in layer 4 of the somatosensory cortex</article-title><source>Science</source><volume>366</volume><elocation-id>eaay3134</elocation-id><pub-id pub-id-type="doi">10.1126/science.aay3134</pub-id><pub-id pub-id-type="pmid">31649140</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muldoon</surname><given-names>SF</given-names></name><name><surname>Bridgeford</surname><given-names>EW</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Small-world propensity and weighted brain networks</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>22057</elocation-id><pub-id pub-id-type="doi">10.1038/srep22057</pub-id><pub-id pub-id-type="pmid">26912196</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Müller</surname><given-names>J</given-names></name><name><surname>Ballini</surname><given-names>M</given-names></name><name><surname>Livi</surname><given-names>P</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Radivojevic</surname><given-names>M</given-names></name><name><surname>Shadmani</surname><given-names>A</given-names></name><name><surname>Viswam</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>IL</given-names></name><name><surname>Fiscella</surname><given-names>M</given-names></name><name><surname>Diggelmann</surname><given-names>R</given-names></name><name><surname>Stettler</surname><given-names>A</given-names></name><name><surname>Frey</surname><given-names>U</given-names></name><name><surname>Bakkum</surname><given-names>DJ</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>High-resolution CMOS MEA platform to study neurons at subcellular, cellular, and network levels</article-title><source>Lab on a Chip</source><volume>15</volume><fpage>2767</fpage><lpage>2780</lpage><pub-id pub-id-type="doi">10.1039/c5lc00133a</pub-id><pub-id pub-id-type="pmid">25973786</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Müller</surname><given-names>EJ</given-names></name><name><surname>Munn</surname><given-names>BR</given-names></name><name><surname>Shine</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Diffuse neural coupling mediates complex network dynamics through the formation of quasi-critical brain states</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>6337</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-19716-7</pub-id><pub-id pub-id-type="pmid">33303766</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname><given-names>MEJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Modularity and community structure in networks</article-title><source>PNAS</source><volume>103</volume><fpage>8577</fpage><lpage>8582</lpage><pub-id pub-id-type="doi">10.1073/pnas.0601602103</pub-id><pub-id pub-id-type="pmid">16723398</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicosia</surname><given-names>V</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Schafer</surname><given-names>WR</given-names></name><name><surname>Latora</surname><given-names>V</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Phase transition in the economically modeled growth of a cellular nervous system</article-title><source>PNAS</source><volume>110</volume><fpage>7880</fpage><lpage>7885</lpage><pub-id pub-id-type="doi">10.1073/pnas.1300753110</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Novelli</surname><given-names>L</given-names></name><name><surname>Wollstadt</surname><given-names>P</given-names></name><name><surname>Mediano</surname><given-names>P</given-names></name><name><surname>Wibral</surname><given-names>M</given-names></name><name><surname>Lizier</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Large-scale directed network inference with multivariate transfer entropy and hierarchical statistical testing</article-title><source>Network Neuroscience</source><volume>3</volume><fpage>827</fpage><lpage>847</lpage><pub-id pub-id-type="doi">10.1162/netn_a_00092</pub-id><pub-id pub-id-type="pmid">31410382</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldham</surname><given-names>S</given-names></name><name><surname>Fornito</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The development of brain network hubs</article-title><source>Developmental Cognitive Neuroscience</source><volume>36</volume><elocation-id>100607</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2018.12.005</pub-id><pub-id pub-id-type="pmid">30579789</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldham</surname><given-names>S</given-names></name><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Aquino</surname><given-names>K</given-names></name><name><surname>Arnatkevičiūtė</surname><given-names>A</given-names></name><name><surname>Paquola</surname><given-names>C</given-names></name><name><surname>Shishegar</surname><given-names>R</given-names></name><name><surname>Fornito</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Modeling spatial, developmental, physiological, and topological constraints on human brain connectivity</article-title><source>Science Advances</source><volume>8</volume><elocation-id>eabm6127</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abm6127</pub-id><pub-id pub-id-type="pmid">35658036</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Opitz</surname><given-names>T</given-names></name><name><surname>De Lima</surname><given-names>AD</given-names></name><name><surname>Voigt</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Spontaneous development of synchronous oscillatory activity during maturation of cortical networks in vitro</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>2196</fpage><lpage>2206</lpage><pub-id pub-id-type="doi">10.1152/jn.00316.2002</pub-id><pub-id pub-id-type="pmid">12424261</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Kadir</surname><given-names>SN</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fast and accurate spike sorting of high-channel count probes with kilosort</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>4448</fpage><lpage>4456</lpage></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papadopoulos</surname><given-names>F</given-names></name><name><surname>Kitsak</surname><given-names>M</given-names></name><name><surname>Serrano</surname><given-names>MÁ</given-names></name><name><surname>Boguñá</surname><given-names>M</given-names></name><name><surname>Krioukov</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Popularity versus similarity in growing networks</article-title><source>Nature</source><volume>489</volume><fpage>537</fpage><lpage>540</lpage><pub-id pub-id-type="doi">10.1038/nature11459</pub-id><pub-id pub-id-type="pmid">22972194</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paterno</surname><given-names>R</given-names></name><name><surname>Casalia</surname><given-names>M</given-names></name><name><surname>Baraban</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Interneuron deficits in neurodevelopmental disorders: Implications for disease pathology and interneuron-based therapies</article-title><source>European Journal of Paediatric Neurology</source><volume>24</volume><fpage>81</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1016/j.ejpn.2019.12.015</pub-id><pub-id pub-id-type="pmid">31870698</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perez-Nieves</surname><given-names>N</given-names></name><name><surname>Leung</surname><given-names>VCH</given-names></name><name><surname>Dragotti</surname><given-names>PL</given-names></name><name><surname>Goodman</surname><given-names>DFM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural heterogeneity promotes robust learning</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>5791</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26022-3</pub-id><pub-id pub-id-type="pmid">34608134</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perin</surname><given-names>R</given-names></name><name><surname>Berger</surname><given-names>TK</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A synaptic organizing principle for cortical neuronal groups</article-title><source>PNAS</source><volume>108</volume><fpage>5419</fpage><lpage>5424</lpage><pub-id pub-id-type="doi">10.1073/pnas.1016051108</pub-id><pub-id pub-id-type="pmid">21383177</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>PC</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Mahallati</surname><given-names>S</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>CellExplorer: A framework for visualizing and characterizing single neurons</article-title><source>Neuron</source><volume>109</volume><fpage>3594</fpage><lpage>3608</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.002</pub-id><pub-id pub-id-type="pmid">34592168</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pillow</surname><given-names>J</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural characterization in partially observed populations of spiking neurons</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>1161</fpage><lpage>1168</lpage></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pumo</surname><given-names>GM</given-names></name><name><surname>Kitazawa</surname><given-names>T</given-names></name><name><surname>Rijli</surname><given-names>FM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Epigenetic and transcriptional regulation of spontaneous and sensory activity dependent programs during neuronal circuit development</article-title><source>Frontiers in Neural Circuits</source><volume>16</volume><elocation-id>911023</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2022.911023</pub-id><pub-id pub-id-type="pmid">35664458</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ren</surname><given-names>N</given-names></name><name><surname>Ito</surname><given-names>S</given-names></name><name><surname>Hafizi</surname><given-names>H</given-names></name><name><surname>Beggs</surname><given-names>JM</given-names></name><name><surname>Stevenson</surname><given-names>IH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Model-based detection of putative synaptic connections from spike recordings with latency and type constraints</article-title><source>Journal of Neurophysiology</source><volume>124</volume><fpage>1588</fpage><lpage>1604</lpage><pub-id pub-id-type="doi">10.1152/jn.00066.2020</pub-id><pub-id pub-id-type="pmid">32937091</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rheims</surname><given-names>S</given-names></name><name><surname>Minlebaev</surname><given-names>M</given-names></name><name><surname>Ivanov</surname><given-names>A</given-names></name><name><surname>Represa</surname><given-names>A</given-names></name><name><surname>Khazipov</surname><given-names>R</given-names></name><name><surname>Holmes</surname><given-names>GL</given-names></name><name><surname>Ben-Ari</surname><given-names>Y</given-names></name><name><surname>Zilberter</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Excitatory GABA in rodent developing neocortex in vitro</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>609</fpage><lpage>619</lpage><pub-id pub-id-type="doi">10.1152/jn.90402.2008</pub-id><pub-id pub-id-type="pmid">18497364</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ronchi</surname><given-names>S</given-names></name><name><surname>Fiscella</surname><given-names>M</given-names></name><name><surname>Marchetti</surname><given-names>C</given-names></name><name><surname>Viswam</surname><given-names>V</given-names></name><name><surname>Müller</surname><given-names>J</given-names></name><name><surname>Frey</surname><given-names>U</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-cell electrical stimulation using CMOS-based high-density microelectrode arrays</article-title><source>Frontiers in Neuroscience</source><volume>13</volume><elocation-id>208</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2019.00208</pub-id><pub-id pub-id-type="pmid">30918481</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ronchi</surname><given-names>S</given-names></name><name><surname>Buccino</surname><given-names>AP</given-names></name><name><surname>Prack</surname><given-names>G</given-names></name><name><surname>Kumar</surname><given-names>SS</given-names></name><name><surname>Schröter</surname><given-names>M</given-names></name><name><surname>Fiscella</surname><given-names>M</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Electrophysiological phenotype characterization of human iPSC-derived neuronal cell lines by means of high-density microelectrode arrays</article-title><source>Advanced Biology</source><volume>5</volume><elocation-id>e2000223</elocation-id><pub-id pub-id-type="doi">10.1002/adbi.202000223</pub-id><pub-id pub-id-type="pmid">33729694</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinov</surname><given-names>M</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Complex network measures of brain connectivity: uses and interpretations</article-title><source>NeuroImage</source><volume>52</volume><fpage>1059</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.003</pub-id><pub-id pub-id-type="pmid">19819337</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanes</surname><given-names>JR</given-names></name><name><surname>Zipursky</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Synaptic specificity, recognition molecules, and assembly of neural circuits</article-title><source>Cell</source><volume>181</volume><fpage>536</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.04.008</pub-id><pub-id pub-id-type="pmid">32359437</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeter</surname><given-names>MS</given-names></name><name><surname>Charlesworth</surname><given-names>P</given-names></name><name><surname>Kitzbichler</surname><given-names>MG</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Emergence of rich-club topology and coordinated dynamics in development of hippocampal functional networks in vitro</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>5459</fpage><lpage>5470</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4259-14.2015</pub-id><pub-id pub-id-type="pmid">25855164</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schröter</surname><given-names>M</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Micro-connectomics: probing the organization of neuronal networks at the cellular scale</article-title><source>Nature Reviews. Neuroscience</source><volume>18</volume><fpage>131</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.182</pub-id><pub-id pub-id-type="pmid">28148956</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schröter</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Terrigno</surname><given-names>M</given-names></name><name><surname>Hornauer</surname><given-names>P</given-names></name><name><surname>Huang</surname><given-names>Z</given-names></name><name><surname>Jagasia</surname><given-names>R</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Functional imaging of brain organoids using high-density microelectrode arrays</article-title><source>MRS Bulletin</source><volume>47</volume><fpage>530</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1557/s43577-022-00282-w</pub-id><pub-id pub-id-type="pmid">36120104</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schröter</surname><given-names>M</given-names></name><name><surname>Cardes</surname><given-names>F</given-names></name><name><surname>Bui</surname><given-names>C-VH</given-names></name><name><surname>Dodi</surname><given-names>LD</given-names></name><name><surname>Gänswein</surname><given-names>T</given-names></name><name><surname>Bartram</surname><given-names>J</given-names></name><name><surname>Sadiraj</surname><given-names>L</given-names></name><name><surname>Hornauer</surname><given-names>P</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Pascual-Garcia</surname><given-names>M</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Advances in large-scale electrophysiology with high-density microelectrode arrays</article-title><source>Lab on a Chip</source><volume>25</volume><fpage>4844</fpage><lpage>4885</lpage><pub-id pub-id-type="doi">10.1039/D5LC00058K</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shorten</surname><given-names>DP</given-names></name><name><surname>Spinney</surname><given-names>RE</given-names></name><name><surname>Lizier</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Estimating transfer entropy in continuous time between neural spike trains or other event-based data</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008054</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008054</pub-id><pub-id pub-id-type="pmid">33872296</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Shorten</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>CoTETE.jl</data-title><version designator="4a8de3f">4a8de3f</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/dpshorten/CoTETE.jl">https://github.com/dpshorten/CoTETE.jl</ext-link></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Vidaurre</surname><given-names>D</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>KL</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Uğurbil</surname><given-names>K</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Functional connectomics from resting-state fMRI</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>666</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.09.016</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Competitive Hebbian learning through spike-timing-dependent synaptic plasticity</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>919</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1038/78829</pub-id><pub-id pub-id-type="pmid">10966623</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Sjöström</surname><given-names>PJ</given-names></name><name><surname>Reigl</surname><given-names>M</given-names></name><name><surname>Nelson</surname><given-names>S</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title><source>PLOS Biology</source><volume>3</volume><elocation-id>e68</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0030068</pub-id><pub-id pub-id-type="pmid">15737062</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatial embedding of structural similarity in the cerebral cortex</article-title><source>PNAS</source><volume>111</volume><fpage>16580</fpage><lpage>16585</lpage><pub-id pub-id-type="doi">10.1073/pnas.1414153111</pub-id><pub-id pub-id-type="pmid">25368200</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spivak</surname><given-names>L</given-names></name><name><surname>Levi</surname><given-names>A</given-names></name><name><surname>Sloin</surname><given-names>HE</given-names></name><name><surname>Someck</surname><given-names>S</given-names></name><name><surname>Stark</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Deconvolution improves the detection and quantification of spike transmission gain from spike trains</article-title><source>Communications Biology</source><volume>5</volume><elocation-id>520</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-022-03450-5</pub-id><pub-id pub-id-type="pmid">35641587</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Modular Brain Networks</article-title><source>Annual Review of Psychology</source><volume>67</volume><fpage>613</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-122414-033634</pub-id><pub-id pub-id-type="pmid">26393868</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Südhof</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Towards an understanding of synapse formation</article-title><source>Neuron</source><volume>100</volume><fpage>276</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.09.040</pub-id><pub-id pub-id-type="pmid">30359597</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szebényi</surname><given-names>K</given-names></name><name><surname>Wenger</surname><given-names>LMD</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Dunn</surname><given-names>AWE</given-names></name><name><surname>Limegrover</surname><given-names>CA</given-names></name><name><surname>Gibbons</surname><given-names>GM</given-names></name><name><surname>Conci</surname><given-names>E</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name><name><surname>Mierau</surname><given-names>SB</given-names></name><name><surname>Balmus</surname><given-names>G</given-names></name><name><surname>Lakatos</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Human ALS/FTD brain organoid slice cultures display distinct early astrocyte and targetable neuronal pathology</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1542</fpage><lpage>1554</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00923-4</pub-id><pub-id pub-id-type="pmid">34675437</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>CS</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Rivlin</surname><given-names>PK</given-names></name><name><surname>Parag</surname><given-names>T</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Plaza</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Katz</surname><given-names>WT</given-names></name><name><surname>Umayam</surname><given-names>L</given-names></name><name><surname>Weaver</surname><given-names>C</given-names></name><name><surname>Hess</surname><given-names>HF</given-names></name><name><surname>Horne</surname><given-names>JA</given-names></name><name><surname>Nunez-Iglesias</surname><given-names>J</given-names></name><name><surname>Aniceto</surname><given-names>R</given-names></name><name><surname>Chang</surname><given-names>L-A</given-names></name><name><surname>Lauchie</surname><given-names>S</given-names></name><name><surname>Nasca</surname><given-names>A</given-names></name><name><surname>Ogundeyi</surname><given-names>O</given-names></name><name><surname>Sigmund</surname><given-names>C</given-names></name><name><surname>Takemura</surname><given-names>S</given-names></name><name><surname>Tran</surname><given-names>J</given-names></name><name><surname>Langille</surname><given-names>C</given-names></name><name><surname>Le Lacheur</surname><given-names>K</given-names></name><name><surname>McLin</surname><given-names>S</given-names></name><name><surname>Shinomiya</surname><given-names>A</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name><name><surname>Meinertzhagen</surname><given-names>IA</given-names></name><name><surname>Scheffer</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Synaptic circuits and their variations within different columns in the visual system of <italic>Drosophila</italic></article-title><source>PNAS</source><volume>112</volume><fpage>13711</fpage><lpage>13716</lpage><pub-id pub-id-type="doi">10.1073/pnas.1509820112</pub-id><pub-id pub-id-type="pmid">26483464</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talaga</surname><given-names>S</given-names></name><name><surname>Nowak</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Homophily as a process generating social networks: insights from social distance attachment model</article-title><source>Journal of Artificial Societies and Social Simulation</source><volume>23</volume><elocation-id>4252</elocation-id><pub-id pub-id-type="doi">10.18564/jasss.4252</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Terunuma</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Diversity of structure and function of GABAB receptors: a complexity of GABAB-mediated signaling</article-title><source>Proceedings of the Japan Academy. Series B, Physical and Biological Sciences</source><volume>94</volume><elocation-id>390</elocation-id><pub-id pub-id-type="doi">10.2183/pjab.94.026</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Towlson</surname><given-names>EK</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Ahnert</surname><given-names>SE</given-names></name><name><surname>Schafer</surname><given-names>WR</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The rich club of the <italic>C. elegans</italic> neuronal connectome</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>6380</fpage><lpage>6387</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3784-12.2013</pub-id><pub-id pub-id-type="pmid">23575836</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turk</surname><given-names>E</given-names></name><name><surname>van den Heuvel</surname><given-names>MI</given-names></name><name><surname>Benders</surname><given-names>MJ</given-names></name><name><surname>de Heus</surname><given-names>R</given-names></name><name><surname>Franx</surname><given-names>A</given-names></name><name><surname>Manning</surname><given-names>JH</given-names></name><name><surname>Hect</surname><given-names>JL</given-names></name><name><surname>Hernandez-Andrade</surname><given-names>E</given-names></name><name><surname>Hassan</surname><given-names>SS</given-names></name><name><surname>Romero</surname><given-names>R</given-names></name><name><surname>Kahn</surname><given-names>RS</given-names></name><name><surname>Thomason</surname><given-names>ME</given-names></name><name><surname>van den Heuvel</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Functional connectome of the fetal brain</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>9716</fpage><lpage>9724</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2891-18.2019</pub-id><pub-id pub-id-type="pmid">31685648</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Udvary</surname><given-names>D</given-names></name><name><surname>Harth</surname><given-names>P</given-names></name><name><surname>Macke</surname><given-names>JH</given-names></name><name><surname>Hege</surname><given-names>HC</given-names></name><name><surname>de Kock</surname><given-names>CPJ</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name><name><surname>Oberlaender</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The impact of neuron morphology on cortical network architecture</article-title><source>Cell Reports</source><volume>39</volume><elocation-id>110677</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2022.110677</pub-id><pub-id pub-id-type="pmid">35417720</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>Stam</surname><given-names>CJ</given-names></name><name><surname>Kahn</surname><given-names>RS</given-names></name><name><surname>Hulshoff Pol</surname><given-names>HE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Efficiency of functional brain networks and intellectual performance</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>7619</fpage><lpage>7624</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1443-09.2009</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Rich-club organization of the human connectome</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>15775</fpage><lpage>15786</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3539-11.2011</pub-id><pub-id pub-id-type="pmid">22049421</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Network hubs in the human brain</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>683</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.09.012</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>Kersbergen</surname><given-names>KJ</given-names></name><name><surname>de Reus</surname><given-names>MA</given-names></name><name><surname>Keunen</surname><given-names>K</given-names></name><name><surname>Kahn</surname><given-names>RS</given-names></name><name><surname>Groenendaal</surname><given-names>F</given-names></name><name><surname>de Vries</surname><given-names>LS</given-names></name><name><surname>Benders</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neonatal connectome during preterm brain development</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3000</fpage><lpage>3013</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu095</pub-id><pub-id pub-id-type="pmid">24833018</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Venkatesh</surname><given-names>M</given-names></name><name><surname>Jaja</surname><given-names>J</given-names></name><name><surname>Pessoa</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Comparing functional connectivity matrices: A geometry-aware approach applied to participant identification</article-title><source>NeuroImage</source><volume>207</volume><elocation-id>116398</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116398</pub-id><pub-id pub-id-type="pmid">31783117</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Alexander-Bloch</surname><given-names>AF</given-names></name><name><surname>Gogtay</surname><given-names>N</given-names></name><name><surname>Giedd</surname><given-names>JN</given-names></name><name><surname>Rapoport</surname><given-names>JL</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Simple models of human brain functional networks</article-title><source>PNAS</source><volume>109</volume><fpage>5868</fpage><lpage>5873</lpage><pub-id pub-id-type="doi">10.1073/pnas.1111738109</pub-id></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Alexander-Bloch</surname><given-names>A</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Generative models of rich clubs in Hebbian neuronal networks and large-scale human brain networks</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>369</volume><elocation-id>20130531</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0531</pub-id><pub-id pub-id-type="pmid">25180309</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Annual research review: Growth connectomics--the organization and reorganization of brain networks during normal and abnormal development</article-title><source>Journal of Child Psychology and Psychiatry, and Allied Disciplines</source><volume>56</volume><fpage>299</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1111/jcpp.12365</pub-id><pub-id pub-id-type="pmid">25441756</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenaar</surname><given-names>DA</given-names></name><name><surname>Pine</surname><given-names>J</given-names></name><name><surname>Potter</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>An extremely rich repertoire of bursting patterns during the development of cortical cultures</article-title><source>BMC Neuroscience</source><volume>7</volume><elocation-id>11</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2202-7-11</pub-id><pub-id pub-id-type="pmid">16464257</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>AS</given-names></name><name><surname>Raliski</surname><given-names>BK</given-names></name><name><surname>Karbasi</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>P</given-names></name><name><surname>Sanders</surname><given-names>K</given-names></name><name><surname>Miller</surname><given-names>EW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Optical spike detection and connectivity analysis with a far-red voltage-sensitive fluorophore reveals changes to network connectivity in development and disease</article-title><source>Frontiers in Neuroscience</source><volume>15</volume><elocation-id>643859</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2021.643859</pub-id><pub-id pub-id-type="pmid">34054405</pub-id></element-citation></ref><ref id="bib153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warm</surname><given-names>D</given-names></name><name><surname>Bassetti</surname><given-names>D</given-names></name><name><surname>Schroer</surname><given-names>J</given-names></name><name><surname>Luhmann</surname><given-names>HJ</given-names></name><name><surname>Sinning</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Spontaneous activity predicts survival of developing cortical neurons</article-title><source>Frontiers in Cell and Developmental Biology</source><volume>10</volume><elocation-id>937761</elocation-id><pub-id pub-id-type="doi">10.3389/fcell.2022.937761</pub-id><pub-id pub-id-type="pmid">36035995</pub-id></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watts</surname><given-names>DJ</given-names></name><name><surname>Strogatz</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Collective dynamics of “small-world” networks</article-title><source>Nature</source><volume>393</volume><fpage>440</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1038/30918</pub-id><pub-id pub-id-type="pmid">9623998</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witvliet</surname><given-names>D</given-names></name><name><surname>Mulcahy</surname><given-names>B</given-names></name><name><surname>Mitchell</surname><given-names>JK</given-names></name><name><surname>Meirovitch</surname><given-names>Y</given-names></name><name><surname>Berger</surname><given-names>DR</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Koh</surname><given-names>WX</given-names></name><name><surname>Parvathala</surname><given-names>R</given-names></name><name><surname>Holmyard</surname><given-names>D</given-names></name><name><surname>Schalek</surname><given-names>RL</given-names></name><name><surname>Shavit</surname><given-names>N</given-names></name><name><surname>Chisholm</surname><given-names>AD</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name><name><surname>Samuel</surname><given-names>ADT</given-names></name><name><surname>Zhen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Connectomes across development reveal principles of brain maturation</article-title><source>Nature</source><volume>596</volume><fpage>257</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03778-8</pub-id><pub-id pub-id-type="pmid">34349261</pub-id></element-citation></ref><ref id="bib156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>RO</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name><name><surname>Shatz</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Transient period of correlated bursting activity during development of the mammalian retina</article-title><source>Neuron</source><volume>11</volume><fpage>923</fpage><lpage>938</lpage><pub-id pub-id-type="doi">10.1016/0896-6273(93)90122-8</pub-id><pub-id pub-id-type="pmid">8240814</pub-id></element-citation></ref><ref id="bib157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>W</given-names></name><name><surname>de Lima</surname><given-names>AD</given-names></name><name><surname>Voigt</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The structural E/I balance constrains the early development of cortical network activity</article-title><source>Frontiers in Cellular Neuroscience</source><volume>15</volume><elocation-id>687306</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2021.687306</pub-id><pub-id pub-id-type="pmid">34349623</pub-id></element-citation></ref><ref id="bib158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yogev</surname><given-names>S</given-names></name><name><surname>Shen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cellular and molecular mechanisms of synaptic specificity</article-title><source>Annual Review of Cell and Developmental Biology</source><volume>30</volume><fpage>417</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1146/annurev-cellbio-100913-012953</pub-id><pub-id pub-id-type="pmid">25150010</pub-id></element-citation></ref><ref id="bib159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yook</surname><given-names>SH</given-names></name><name><surname>Jeong</surname><given-names>H</given-names></name><name><surname>Barabasi</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Modeling the internet’s large-scale topology</article-title><source>PNAS</source><volume>99</volume><fpage>13382</fpage><lpage>13386</lpage><pub-id pub-id-type="doi">10.1073/pnas.172501399</pub-id><pub-id pub-id-type="pmid">12368484</pub-id></element-citation></ref><ref id="bib160"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Braun</surname><given-names>U</given-names></name><name><surname>Harneit</surname><given-names>A</given-names></name><name><surname>Zang</surname><given-names>Z</given-names></name><name><surname>Geiger</surname><given-names>LS</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Schweiger</surname><given-names>JI</given-names></name><name><surname>Schwarz</surname><given-names>K</given-names></name><name><surname>Reinwald</surname><given-names>JR</given-names></name><name><surname>Fritze</surname><given-names>S</given-names></name><name><surname>Witt</surname><given-names>S</given-names></name><name><surname>Rietschel</surname><given-names>M</given-names></name><name><surname>Nöthen</surname><given-names>MM</given-names></name><name><surname>Degenhardt</surname><given-names>F</given-names></name><name><surname>Schwarz</surname><given-names>E</given-names></name><name><surname>Hirjak</surname><given-names>D</given-names></name><name><surname>Meyer-Lindenberg</surname><given-names>A</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Tost</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Generative network models of altered structural brain connectivity in schizophrenia</article-title><source>NeuroImage</source><volume>225</volume><elocation-id>117510</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117510</pub-id><pub-id pub-id-type="pmid">33160087</pub-id></element-citation></ref><ref id="bib161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>M</given-names></name><name><surname>Allard</surname><given-names>A</given-names></name><name><surname>Hagmann</surname><given-names>P</given-names></name><name><surname>Alemán-Gómez</surname><given-names>Y</given-names></name><name><surname>Serrano</surname><given-names>MÁ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Geometric renormalization unravels self-similarity of the multiscale human connectome</article-title><source>PNAS</source><volume>117</volume><fpage>20244</fpage><lpage>20253</lpage><pub-id pub-id-type="doi">10.1073/pnas.1922248117</pub-id><pub-id pub-id-type="pmid">32759211</pub-id></element-citation></ref><ref id="bib162"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>D</given-names></name><name><surname>Lynn</surname><given-names>CW</given-names></name><name><surname>Cui</surname><given-names>Z</given-names></name><name><surname>Ciric</surname><given-names>R</given-names></name><name><surname>Baum</surname><given-names>GL</given-names></name><name><surname>Moore</surname><given-names>TM</given-names></name><name><surname>Roalf</surname><given-names>DR</given-names></name><name><surname>Detre</surname><given-names>JA</given-names></name><name><surname>Gur</surname><given-names>RC</given-names></name><name><surname>Gur</surname><given-names>RE</given-names></name><name><surname>Satterthwaite</surname><given-names>TD</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Efficient coding in the economics of human brain connectomics</article-title><source>Network Neuroscience</source><volume>6</volume><fpage>234</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1162/netn_a_00223</pub-id><pub-id pub-id-type="pmid">36605887</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85300.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><addr-line><named-content content-type="city">La Jolla</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>This valuable study examines the principles according to which neurons connect to each other in vitro. The authors show solid evidence that data could be best explained by the homophillic wiring principle where neurons preferentially connect to neurons within overlapping groups.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85300.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><addr-line><named-content content-type="city">La Jolla</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.03.09.483605">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.03.09.483605v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Homophilic wiring principles underpin neuronal network topology in vitro&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Panayiota Poirazi as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p><italic>Essential Revisions:</italic></p><p>Both Reviewers appreciate the scope and importance of the study in both experimental and modelling components. There was also a consensus among Reviewers that it is necessary to</p><p>1) clarify the separation between functional and structural connectivity;</p><p>2) provide the actual optimized model parameters in addition to the rough overview in plots like Figure 3C;</p><p>3) clarify differences between &quot;more structured&quot; vs. &quot;more random&quot; networks</p><p>4) make an effort to control for different amounts of data across datasets. For example, for a larger dataset, analyses could be carried out on a subset of the data to show how results might depend on the dataset size.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>First a list of apparent inconsistencies and minor points of the presentation:</p><p>Figure 2b: Is reported to be from network recordings, but seems to have only ~28 nodes based on the histograms. That is lower than reported in S1.</p><p>Figure 2b: Why are values for betweenness &gt; 100? Would not expect that, given the equation in the methods. Looks more like the total number of shortest paths is reported, rather than a fraction.</p><p>Figure 2d: The list puts models 3-7 as degree-based, and 8-12 as clustering-based; the boxplot has it inverse.</p><p>Figure 3f: Maybe more of a question: Why does DIV 7 correspond to 50% of &quot;simulated time&quot;? According to Supp Figure S2, DIV 14 has a median density of around 7% and DIV7 has &lt; 1%. Is simulated time not the fraction of edges placed?</p><p>Figure 5: What exactly is &quot;matching&quot; that is depicted in the 6th row and column of the correlation matrices? It is explained in the methods as a measurement related to pairs of nodes, but I would expect a per-node-level measurement.</p><p>Figure 6: Aren't the P_ij values a bit high? The way I understand the generative algorithm after reading this manuscript and Akarca et al., 2021, is at each step a single edge is selected and placed according to P_ij. So the value should add up to 1.0. Even if more than one is selected at a time, with a median value around 0.2, we would reach an edge density of 0.2 in a single step, so that can't be it.</p><p>Figure 7: Caption for panels b and c swapped</p><p>Line 592: The case of &quot;no principle being implemented&quot; is listed as being indicated by high energy for all models. Yet, random null models in S5b all have very low energy. (As expected, just set both wiring parameters to 0.)</p><p>Line 1198: The explanation of global efficiency as depicted uses Euclidean distance (d_ij) and is independent of the graph structure.</p><p>Global efficiency is explained in the methods, but not the local efficiency that is used in Supp Figure S6.</p><p>Supp Figure S11b: I am not sure I understand the plot. the x-axis is labeled &quot;log10&quot;, but the tick labels are also logarithmically spaced. Also, is the unit really in ms?</p><p>General notes:</p><p>Overall, a number of powerful and interesting methods and analyses are employed. But their selection seems a bit random. Between Figure S6 and S9 &quot;participation&quot; is swapped for &quot;matching&quot;. The &quot;topological fingerprint&quot; is used to evaluate model match for sparse and dense cultures, but not for the GABA block case. In the GABA block case, the internals of the generative model is inspected, but not for dense vs sparse. And more. This makes the whole work seem disconnected.</p><p>I think Figure 5 belongs before Figure 4 as it provides further data supporting the idea that the &quot;matching&quot; algorithm builds networks comparable to the in vitro data. Branching off to the case of denser cultures is separate from that.</p><p>If I understood correctly that different wiring parameters (η and γ) are optimized for the same model but different cultures of the same type, then it should be attempted to explain the differences. (Not just for the GABA block case.) Do they depend on the size of the model? Age? Density? Average activity level?</p><p>I am curious why the main point of the paper is based on the sparse cultures and the dense cultures are much less prominently featured, although the sparse case has n=6 and the dense case n=12.</p><p>Overall, I am surprised by which data are shown in the main figures, and which ones are supplementary.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>General:</p><p>I am a little confused about how the statistics of the different generative networks are computed. Sometimes it mentions &quot;top performing simulated networks&quot;, sometimes &quot;top 10&quot; or &quot;top 50&quot;, others &quot;top n=1&quot;, and &quot;top n=99 and average&quot;. I do not understand why several results are based on the &quot;top n=1 performing simulated networks&quot;. These are probabilistic models for small networks, how is the best simulation representative of the underlying wiring principle? The original methodological paper (Betzel, Neuroimage 2016) appears to report the top 1% of energies (100 networks).</p><p>Similarly, it is often difficult to understand how significance was assessed across many figures and tables. For example for the anovas, and cohens effects on the energies. Sometimes energies are presented with 4 groups, others with 13. It is unclear if the same procedure was always followed.</p><p>Line-based:</p><p>159: It is very difficult to relate the reported plating densities with densities reported in other studies. It'd be much better to report real densities (in cells/ mm2) measured at the time of recording (or after staining). See for example the works by Potter, Segal, Moses, labs, and others.</p><p>171: After the whole-array activity scan, how were the 4x4 blocks selected? I assume one ends up with 64 independent 4x4 blocks, was the distance between them consistent? Was the ranking procedure from 1103 also used? Given that each 4x4 block can identify more than 1 cell, it is unclear why the number of tracked units in the sparse and dense cultures is so similar. Could it be that the electrode selection procedure was biased?</p><p>190: Regarding the jittering procedure, it is unclear whether it involved a random shift of either + or – 10 ms? or any value within that range (uniform distribution?)</p><p>310: Based on all the energy/exponent maps (e.g., Figure 2d right), the relevant range of exponents is always between -1 and 1 (or -3,3 at best). It is very difficult to read the value of the exponents based on the actual maps (e.g., Figure 3c). Maybe the authors could report the actual exponents somewhere (as they did in Sup Figure 14c for example). These values might help the interpretability of the results (for example, whether the exponents are positive or negative could be quite relevant).</p><p>357: What &quot;large topological changes&quot; do the authors refer to? Figure S2 only reports an overall increase in the number of connections. Also, is the network density measured as &quot;total degree / (1/2*N*(N-1))&quot; ? Or is there an extra factor of 2 somewhere? I'm trying to relate the values in S2a S2c, and supp Table 1.</p><p>374: Regarding &quot;homophily performs best when approximating empirical networks, but not randomized networks&quot;, how did the authors measure that? The full random case in S5b has the lowest energy of all, and lower energy would mean a better fit if I'm not mistaken. Or were the authors only talking about the &quot;randmio&quot; procedure? If so, the authors might want to plot S5b in the same range as the figure it has to be compared with (0 to 0.6).</p><p>375: I don't understand how the staining panel relates to the rest of this figure.</p><p>376: F3C, to which of the 13 generative models does this plot correspond to? If I'm not mistaken, the exponents are calculated independently for each of the 13 models and 4 time points.</p><p>415: Unsure what the R2, r and p measures mean. Is this just pearson on F3e,f right panels, and its p-value?</p><p>442: Same as the comment on L159, the authors should report the density at the time of recording. It is also worth noting that there are many more processes affecting the final density than just apoptosis.</p><p>444: I'd like to point out a few important references on this matter. Ivenshitz and Segal, J Neurophysiol 2010. Cohen et al., Brain Research 2008. They looked in detail at how different densities affect activity and network connectivity in cultures.</p><p>455: Related to L171. I have difficulties understanding the relationship between plating densities, the number of recorded cells, the distance between cells, and inferred connectivity. From S3, the distribution of Euclidean distances for the two plated densities looks very similar. And the number of tracked units in S1 is also very similar. However, S7 reports functional connectivity with smaller edge lengths and higher clustering. This would be consistent if the higher plating density just resulted in more &quot;cells/mm2&quot; and the activity being invariant. But that doesn't seem the case. The authors should clarify that.</p><p>509: Why did the authors choose a dissimilarity measure based on the Euclidean norm? Distances between correlation matrices are non-euclidean (see for example Venkatesh et al., Neuroimage 2020).</p><p>625: If I understood this measure correctly, the STP is asymmetric STP(i-&gt;j) != STP(j-&gt;i). If that's the case, did the putative inhibitory connections cluster around specific input cells? i.e., following Dale's rule? That would be an interesting check.</p><p>904: How was this replication of the results with TE-based methods quantified? S5b only shows a similar trend as those in Figure 3, but no quantification. Was this measured on the sparse networks only? And were the properties of the TE-based network and the STTC ones similar regarding their topological properties and fingerprint?</p><p>1119: How many cultures were treated with gabazine? Here it mentions &quot;Three&quot;. But F6 and the text mention n=9 (6 of them with washout).</p><p>1172: A significance value of p &lt; 0.01 was chosen for the connectivity. If I understood it correctly, that means, that on average at this threshold, there's a 0.01 probability the observed SSTC value comes from the surrogate distribution. That would result in a 1% network density just from the false positive rate. That's in line with the values reported in S2a at 7 DIV where the network is probably not yet formed. But does that mean that at 14 DIV the expected number of false positives in the inferred connectivity is ~ 20%? Are the inferred networks robust to changes in the binarization threshold?</p><p>Figures:</p><p>Figure 2d. Energy. The Clustering and Degree labels might have been swapped.</p><p>Figure 3c. Is this for a representative network? Or averaged across the networks?</p><p>Figure 6d. How is the shift in the probability distribution related to the wiring becoming more random across all timepoints? Not sure what the authors mean by this.</p><p>Figure 6d. There's a mention of SF13e,f, which doesn't exist. Could it be S14c,d?</p><p>Figure 7c. Why does the tsne plot only include the dense DIV 28 primary cultures? The other datapoints should also be included, e.g., sparse DIV 14 and gabazine experiments.</p><p>Supplementary:</p><p>Figure 3. left/right panels should be top/bottom panels.</p><p>Figure 10. This figure mentions the dense cultures at DIV 14. Why do they report n=6 when dense cultures are n=12? Or is this figure for sparse cultures instead? The caption also mentions &quot;Distributions are plotted for each […].&quot; There are no distributions in this figure.</p><p>Figure 11. It would be beneficial to also add a representative raster (panel a) for the washout case. Results in c report a very high firing rate but no bursting rate for the washout case. What does that look like in the raster?</p><p>Figure 11b. The axis should read ISI (it's already in the log scale). Caption mentions a tri-modal distribution for gabazine. Very hard to see when the washout distribution is on top.</p><p>Figure 12c. Why is the network size so different between controls, gabazine, and washouts? This is never explained, yet several other measures might depend on this value, e.g., total degree.</p><p>Figure 15. Why were only the n=12 DIV 14 dense cultures included here?</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Homophilic wiring principles underpin neuronal network topology in vitro&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Panayiota Poirazi (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The authors have addressed the points I listed in my original recommendations for the authors. I thank them for the effort.</p><p>With respect to my point about &quot;random&quot; vs. &quot;specific&quot; wiring in the context of the GABA block I now have an additional concern:</p><p>I now understand that the Pi,j values are not direct probabilities, but just indicate relative preferences for edge placement. In that case, I am not sure a direct comparison of distributions in Figure 6d, and of their means is very meaningful. If all values for Pi,j of a given model were multiplied by a constant &gt;1 then it would not affect the model wiring, as the relative preferences remained unchanged. But in a plot such as 6d it would stretch the distribution out and increase its mean.</p><p>Besides, after reading the authors' reply where they elaborate on 6d, I now wonder if there is some confusion about the following two potential ways to plot Pi,j: First, where all potential edges are along the x-axis and Pi,j along the y-axis. Here, an ER network has a uniform distribution. Second, where Pi,j values are along the x-axis and their frequency along the y-axis, as in Figure 6. Here, an ER network shows a single δ peak -- as far away from a uniform distribution as possible.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85300.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential Revisions:</p><p>Both Reviewers appreciate the scope and importance of the study in both experimental and modelling components. There was also a consensus among Reviewers that it is necessary to</p><p>1) clarify the separation between functional and structural connectivity;</p></disp-quote><p>This is an excellent point, which also echoes points raised by both reviewers in their public reviews; thank you for pushing us to clarify. We have focused on functional connectivity rather than structural connectivity. We had previously placed this in the Discussion, but we have now clarified in multiple places the distinction between functional structural connectivity:</p><p>We updated a caveat at a key part of the early discussion:</p><p>[Page 26] “It is important to note however that the present study focuses on functional connectivity, rather than structural connectivity, and this separation is discussed in more detail later in our limitations.”</p><p>We then added in key clarity in line with Reviewer 1’s public suggestions:</p><p>[Page 28] “Nevertheless, it is important to keep in mind how our presented results and interpretations may or may not generalize to structural connectivity graphs of in vitro neuronal networks directly, despite the same rules approximating macroscopic structural connectomes. For example, the type of cost incurred by the existence of a long-range functional connection is not necessarily equivalent to that incurred by a structural connection, as a <italic>direct</italic> physical connection may not exist. Future work is needed to investigate directly structural connectivity at this scale and examine the extent to which there are equivalences between the formation and development of structural components (e.g., synapses and axons) alongside their functional interactions.”</p><p>We also have clarified it is <italic>functional</italic> topology in line with Reviewer 2’s public suggestions, adding in the term whenever it was possible:</p><p>[Page 20] “Despite alterations in cellular activity and functional network topology (Figure 6— figure supplement 1 and Figure 6—figure supplement 2), homophilic generative attachment rules were the best fitting models across both control, gabazine-treated and washout conditions (Figure 6—figure supplement 4a,b). However, gabazine cultures exhibit a higher energy relative to controls (p=0.0292; Figure 6c), which suggests that homophilic GNMs cannot approximate the functional topology of gabazine-treated cultures to the same extent as for control cultures. This finding supports our hypothesis that perturbing GABAA receptor-mediated inhibition alters functional network characterization, even though homophily remains the best fitting model.”</p><disp-quote content-type="editor-comment"><p>2) provide the actual optimized model parameters in addition to the rough overview in plots like Figure 3C;</p></disp-quote><p>We are happy to provide all the optimized model parameters. We have now added a new Supplementary file 1c that documents precisely the optimized parameters for each group of cultures across time and group. This means that readers can now cross-reference the parameters directly.</p><p>[Page 9] “Foreshadowing our findings, we report all optimized model parameter fits and energy values, across all analyzed datasets, in Supplementary file 1c.”</p><disp-quote content-type="editor-comment"><p>3) clarify differences between &quot;more structured&quot; vs. &quot;more random&quot; networks</p></disp-quote><p>Thank you for highlighting the need for further clarity on this. We very much appreciated both Reviewer 1 and Reviewer 2’s comments regarding this point too. We have now moved away from more broad statements of “structured” versus “random” to be precise that we mean is the specificity of wiring in the generative process. In a situation in which the probability distribution becomes flatter (compared to a positively skewed distribution), when a new connection is formed it is less specific precisely where this connection will emerge. This has also been shown in recent animal work by Carozza et al. 2023, which we now cite. This work shows that as wiring parameters are weakened in magnitude, probability distributions flatten, leading to less certainty in the eventual network outcome. In the situation where there are stronger wiring parameters, there is a greater probability skew on a smaller number of future possible connections (i.e., smaller number of high probability score connections) which increases the relative specificity that this is where the connection will fall in the next timestep.</p><p>We’ve updated the main text to be clearer to the readers:</p><p>[Page 21] “Therefore, we hypothesized that this would lead to a flattening of this lognormal distribution, meaning that the resultant topology became more random (see Methods; Generative probability distributions for detail). Indeed, in Figure 6d we show this to be the case: gabazine-treated networks exhibit a flattened <italic>P<sub>i,j</sub></italic> distribution relative to both controls (median <italic>P<sub>i,j</sub></italic> value=0.135 and 0.322 for gabazine &amp; control, respectively; p=1.54x10<sup>-44</sup>, Cohen’s <italic>d</italic>=0.550) and also after gabazine washout (median <italic>P<sub>i,j</sub></italic> value=0.179; p=5.04x10<sup>-8</sup>, Cohen’s <italic>d</italic>=0.196; see also Figure 6—figure supplement 4d). This finding suggests that gabazine alters the network wiring distribution as to become more variable in its wiring preferences, rather than being specific to a relatively smaller number of candidate neurons that are deemed particularly valuable to wire with.”</p><p>We also took this opportunity to address a comment from Reviewer 1’s public review (but was not in the private comments) which was a clarification query relating to how flattening the probability distribution:</p><p>[Page 41/42] “Note that the probability score distribution “flattening” (from a relative lognormal distribution toward a uniform distribution) means that relatively more candidate connections come to have a higher probability of being connected in the future. This leads to a decreased specificity of future wiring (i.e., the scope of possible outcomes increases). This flattening effect is equivalent to the network outcomes becoming more random, because a greater number of possible future connections have a non-trivial probability score, and the formation of a connection is less driven by the underlying network topology. Note, a completely singular and uniform <italic>P<sub>i,j</sub></italic> distribution (i.e., where all connections have the same probability of wiring) generates an entirely random graph (Erdos &amp; Renyi, et al. 1959). In contrast, when a generative network has a heterogeneous distribution in its <italic>P<sub>i,j</sub></italic> distribution (e.g., with large numbers of small probability scores and small numbers of large probability scores) the network will have a smaller scope for variability (for more detail, see (Carozza, et al. 2023)).”</p><p>References:</p><p>Erdös, P., &amp; Rényi, A. (1959). On Random Graphs I. Publicationes Mathematicae Debrecen, 6, 290-297.</p><p>Carozza, S., Akarca, D. &amp; Astle, D. The adaptive stochasticity hypothesis: Modeling equifinality, multifinality, and adaptation to adversity. Proceedings of the National Academy of Sciences 120, e2307508120 (2023).</p><disp-quote content-type="editor-comment"><p>4) make an effort to control for different amounts of data across datasets. For example, for a larger dataset, analyses could be carried out on a subset of the data to show how results might depend on the dataset size.</p></disp-quote><p>This is a great point and we are happy to include this in the revised manuscript. All the models are fit at the level of individual neuronal cultures, but practically speaking, it was not possible to generate equal numbers of cultures across all the varied experiments. As noted, this means that whilst all the statistics consider the number of cultures, it is possible that our sensitivity to detect differences varies across the datasets. The largest dataset we have is in the dense rodent PC dataset (n=12 cultures over the time points; 100,000 cells per well plating density). As suggested, we can subsample (at n=6 and n=3, to bring in line with the other datasets) to test the model outcomes (model fits and parameters) sensitivity to dataset size. We find that the results are robust to sample size because the effect sizes are particularly large. We have also validated our analysis in Figure 7—figure supplement 3 (see below).</p><p>We outline the key results within a new Supplementary file 1aj.</p><p>We outline in the Methods how we conducted this experiment and the interpretation:</p><p>[Page 41] “Due to different amounts of data across datasets (e.g., see Supplementary file 1c) we conducted a subsampling procedure in which we sampled from our largest dataset (dense rodent PC cultures) to assess to what extent results may depend on the dataset size. To do this, we took the n=12 cultures across developmental time-points (DIV 14 and DIV 28) and sampled n=6 and n=3 (respectively) samples 1000 times. For each of the 1000 sub-samples, we computed statistical testing on the model energy acquired from all assessed generative models and provided 95% confidence intervals on pairwise comparisons and effect sizes. We report these findings in Supplementary file 1j, showing that even when sampling as low as n=3 our results appear to generalize very well, with homophily remaining as the rule generating the lowest energy. Of note, we find a general trend that lowering the empirical sample size increases the p-value, which can be considered by those conducting future studies.”</p><p>For completeness, we have also added in a further analysis to show how our results are consistent across alternative spike-sorting/post-processing pipelines and provided a new Figure 7—figure supplement 2:</p><p>[Page 35] “To probe whether the reported main results depend on our spike-sorting/postprocessing pipeline, we also prepared the data using an alternative pipeline used a later version of Kilosort (version 2.5), accessed through SpikeInterface<sup>151</sup>, and the quality control toolbox Bombcell152 to screen for units that may be included in the analysis.”</p><p>Moreover, we restricted functional connectivity inference to unit pairs with a minimum of co-activity, i.e., at least 50 spikes within a ±50 ms time window of the cross correlogram calculated between the units. We also excluded neuron pairs with potential spike sorting issues, slightly modifying the spike sorting index introduced by a recent study to our data153. As we show in Figure 7—figure supplement 2, results from this analysis were mostly in line with the initial results reported in the main manuscript.</p><p>Moreover, we replicated our analysis on another, independent dataset of sparse rodent PC cultures (n=12; plating condition: 50,000 cells per well; recording time point: DIV 14). We added a short paragraph on this dataset to the Methods.</p><p>[Page 32] “Rodent primary cortical culture validation dataset</p><p>To probe the reproducibility of our results, we obtained a second set of rodent PC cultures. The protocol to prepare this dataset was very similar to the procedures described previously for our main datasets. The wells of a 24-well HD-MEA plate (MaxWell Biosystems) were sterilized in 70% ethanol for 30 minutes and rinsed three times with sterile water. To enhance cell adhesion, the electrode area of the HD-MEAs was treated for one hour at room temperature with 20 µL of 0.05% (v/v) poly(ethyleneimine) (Σ-Aldrich, #181978) in borate buffer (Thermo Fisher Scientific, #28341) at 8.5 pH, and then washed three times with sterile water. Next, 10 μL of laminin (0.02 mg ml<sup>−1</sup>; Σ-Aldrich, #L2020) in Neurobasal medium (Gibco, Thermo Fisher Scientific, #21103049) was pipetted on each array and again left for one hour at room temperature. Rodent PC neurons were prepared and plated as previously described (Ronchi, et al. 2019). The plating density for this dataset was 50,000 cells per well (1000 cells/mm<sup>2</sup>); the recordings included in the replication analysis were performed on DIV 14. The results for this analysis are depicted in Figure 7—figure supplement 3.”</p><p>Reference: Ronchi, S. et al. Single-Cell Electrical Stimulation Using CMOS-Based High-Density Microelectrode Arrays. Front. Neurosci. 13, (2019).</p><p>The results of this replication/validation analysis are presented in Figure 7—figure supplement 3.</p><p>To point this to readers more clearly, in the main text, we have added:</p><p>[Page 24] “We replicate our main findings using alternative spike-sorting and post-processing pipelines and validate on an independent dataset in Figure 7—figure supplement 3 and Figure 7—figure supplement 3 respectively.”</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>First a list of apparent inconsistencies and minor points of the presentation:</p><p>Figure 2b: Is reported to be from network recordings, but seems to have only ~28 nodes based on the histograms. That is lower than reported in S1.</p></disp-quote><p>We apologize for this ambiguity. The caption was not meant to imply that the presented graph in Figure 2b was recorded. It was only meant to describe what was done in the paper. The image in Figure 2b is a subpart of an empirical graph just to demonstrate graph-theory concepts to the readers. We’ve now made this clearer by updating the caption:</p><p>[Page 9] “Each panel on the top row shows an example schematic network, with the node size corresponding to the respective graph statistic (degree, clustering, betweenness centrality, total edge length).”</p><disp-quote content-type="editor-comment"><p>Figure 2b: Why are values for betweenness &gt; 100? Would not expect that, given the equation in the methods. Looks more like the total number of shortest paths is reported, rather than a fraction.</p></disp-quote><p>Thank you for picking up this error on our part. You are correct. We had quoted a normalized version of the same measure. We have now updated equation 7 to remove this normalization to now provide:<inline-formula><alternatives><mml:math id="sa2m1"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mtext>hj</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mtext>hj</mml:mtext></mml:mrow></mml:msub></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}$b_{i} = \sum_{h,J \in N}\frac{\rho_{\text{hj}}(i)}{\rho_{\text{hj}}}$\end{document}</tex-math></alternatives></inline-formula></p><disp-quote content-type="editor-comment"><p>Figure 2d: The list puts models 3-7 as degree-based, and 8-12 as clustering-based; the boxplot has it inverse.</p></disp-quote><p>Thank you for picking up this error. We have now corrected this in the new Figure 2d plot.</p><disp-quote content-type="editor-comment"><p>Figure 3f: Maybe more of a question: Why does DIV 7 correspond to 50% of &quot;simulated time&quot;? According to Supp Figure S2, DIV 14 has a median density of around 7% and DIV7 has &lt; 1%. Is simulated time not the fraction of edges placed?</p></disp-quote><p>This is a great question. Rather than aligning the simulations of the culture on the plot with respect to the number of connections, we aligned the cultures with respect to the <italic>age</italic> of the cultures. As DIV 7 is half the age of DIV 14 we compared them to the half-way point of the simulations of DIV 14. We did this, rather than with respect to the number of edges, so that we could more easily align across which will have the same DIV but have subtly variable numbers of connections (within- and between- time points). We have added this consideration in the Methods section to ensure clarity for readers:</p><p>Page [13/14] “Results were scaled to the age of the culture so that observations and simulations could be compared directly, where 50% of the simulated time corresponds to DIV 7 and 100% of simulated time corresponds to DIV 14. Note that simulated time here refers to the percentage completion of the simulation, rather than the number of connections added, so that cultures could be aligned based on time. The quoted r and p value correspond to the correlation between observed and simulated statistics.”</p><disp-quote content-type="editor-comment"><p>Figure 5: What exactly is &quot;matching&quot; that is depicted in the 6th row and column of the correlation matrices? It is explained in the methods as a measurement related to pairs of nodes, but I would expect a per-node-level measurement.</p></disp-quote><p>This is a very good point, and we apologize for not being explicit. It is indeed a measurement related to a pair of nodes. Put simply, the matching value corresponds to the normalized overlap in connections in the neighborhoods of two nodes. But, as you allude to, all measures in the correlation matrix represent node measures (not a node-pair / edge measure). Here, matching is the <italic>average</italic> matching index between its node-pairs, making it a node measure. This is why it can be used in the topological fingerprint calculation. We’ve now made this clear in the caption for readers:</p><p>[Page 16] “Each node-wise measure used within the correlation matrix is plotted (left). As matching is an edge-wise measure, the matching calculation presented on row six was derived as a node-wise average.”</p><disp-quote content-type="editor-comment"><p>Figure 6: Aren't the P_ij values a bit high? The way I understand the generative algorithm after reading this manuscript and Akarca et al., 2021, is at each step a single edge is selected and placed according to P_ij. So the value should add up to 1.0. Even if more than one is selected at a time, with a median value around 0.2, we would reach an edge density of 0.2 in a single step, so that can't be it.</p></disp-quote><p>While the P_ij does refer to a probability distribution, it is better described as a probability <italic>score</italic> distribution rather than a strict probability score that sums to 1. This is because it is a calculated probability score distribution that determines the likelihood of it forming a connection in the timestep. We agree that we should make this clear to the reader. We have now added the following:</p><p>[Page 8] “<italic>P<sub>i,j</sub></italic> reflects the probability score of forming a fixed binary connection between neurons <italic>I</italic> and <italic>j</italic>. This is proportional to the parametrized multiplication of costs and values. Two wiring parameters, η and γ, respectively parameterize the costs and value terms, which calibrate the relative influence of the two terms over time on the likelihood of forming a connection in the next step.”</p><p>and</p><p>[Page 39] <italic>“P<sub>i,j</sub></italic> reflects the probability score of forming a fixed binary connection at the current time step. Note that, as this is a probability <italic>score</italic>, the sum of the values may not necessarily equal one. This is because the score indicates the relative likelihood of nodes forming a connection over others.”</p><disp-quote content-type="editor-comment"><p>Figure 7: Caption for panels b and c swapped</p></disp-quote><p>Thank you for pointing this out. We have now corrected this.</p><disp-quote content-type="editor-comment"><p>Line 592: The case of &quot;no principle being implemented&quot; is listed as being indicated by high energy for all models. Yet, random null models in S5b all have very low energy. (As expected, just set both wiring parameters to 0.)</p></disp-quote><p>This is a good point and highlights that our phrase was not universally accurate. We have updated this language to be specific that they would have the same energy (irrespective of high or low):</p><p>[Page 19] “preventing any clear connectivity principle being implemented above the others (where all models have the same energy).”</p><disp-quote content-type="editor-comment"><p>Line 1198: The explanation of global efficiency as depicted uses Euclidean distance (d_ij) and is independent of the graph structure.</p></disp-quote><p>Thank you for pointing this out. Our writing was confusing because we had defined d_ij above as the Euclidean distance for the purposes of the computational model, but when calculating the graph theory metric ‘efficiency’ we mean shortest path lengths. We have clarified this now by adding the following below the global efficiency equation:</p><p>[Page 37] “where here, <italic>d</italic><sub>I,j</sub> represents the shortest path length between <italic>i</italic> and <italic>j</italic>. <inline-formula><alternatives><mml:math id="sa2m2"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}$d_{i,j}^{- 1}$\end{document}</tex-math></alternatives></inline-formula>, therefore, represents the inverse shortest path length, meaning that a high efficiency corresponds to a low shortest path length.”</p><disp-quote content-type="editor-comment"><p>Global efficiency is explained in the methods, but not the local efficiency that is used in Supp Figure S6.</p></disp-quote><p>Thank you for pointing out the missing equation. We have now added the following full</p><p>explanation of local efficiency:</p><p>[Page 38] <italic>Local efficiency.</italic> The local efficiency of the network is given by: <inline-formula><alternatives><mml:math id="sa2m3"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mtext>loc</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mtext>ij</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mtext>ih</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mtext>jh</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:munderover></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft21">\begin{document}$E_{\text{loc}} = \frac{1}{n}\sum_{i \in N}^\frac{\sum_{j,h \in N,j \neq i}a_{\text{ij}}a_{\text{ih}}\left\lbrack d_{\text{jh}}\left( N_{i} \right) \right\rbrack^{- 1}}{k_{i}\left( k_{i} - 1 \right)}$\end{document}</tex-math></alternatives></inline-formula> where E is the local efficiency of node i, and d(N) is the length of the shortest path between <italic>j</italic> and h, that contains only neighbors of <italic>i</italic>.</p><disp-quote content-type="editor-comment"><p>Supp Figure S11b: I am not sure I understand the plot. the x-axis is labeled &quot;log10&quot;, but the tick labels are also logarithmically spaced. Also, is the unit really in ms?</p></disp-quote><p>We apologize for the confusion. We have plotted the log (base 10) scaled ISI that were measured in ms. But we understand that because the x-ticks are logarithmically scaled (rather than the power) this would cause confusion. We have instead now replaced the x label to simply state ISI (ms). Now it should be clear that we have plotted a histogram of the ISI (in ms) but transformed onto the log scale, and this is consistent with the caption.</p><disp-quote content-type="editor-comment"><p>General notes:</p><p>Overall, a number of powerful and interesting methods and analyses are employed. But their selection seems a bit random. Between Figure S6 and S9 &quot;participation&quot; is swapped for &quot;matching&quot;. The &quot;topological fingerprint&quot; is used to evaluate model match for sparse and dense cultures, but not for the GABA block case. In the GABA block case, the internals of the generative model is inspected, but not for dense vs sparse. And more. This makes the whole work seem disconnected.</p></disp-quote><p>Thank you for this comment. We appreciate that some aspects of the paper may seem disconnected due to the extent of the analyses/datasets. We hope our changes above and below have addressed/will address these concerns, as we think this has better systematized the study.</p><disp-quote content-type="editor-comment"><p>I think Figure 5 belongs before Figure 4 as it provides further data supporting the idea that the &quot;matching&quot; algorithm builds networks comparable to the in vitro data. Branching off to the case of denser cultures is separate from that.</p></disp-quote><p>On reflection, we agree. We have now swapped these sections directly. Thank you very much for this suggestion.</p><disp-quote content-type="editor-comment"><p>If I understood correctly that different wiring parameters (η and γ) are optimized for the same model but different cultures of the same type, then it should be attempted to explain the differences. (Not just for the GABA block case.) Do they depend on the size of the model? Age? Density? Average activity level?</p></disp-quote><p>This is a good point. Each η and γ are optimized for each individual culture across the 13 different models. So you are right that we could do better in explaining the differences in η and γ as a function of the age, density and other relevant factors present in the networks. We’ve added the following new Figure 3—figure supplement 3 which presents this analysis for the sparse (50,000 cells per well plating density) rodent data over its development. We now show that all non-homophily models are highly dependent on the network properties, but this isn’t the case with homophily models. This means in our sample, for example, that homophily does equally well at approximating observed networks across time, and if the networks are larger/smaller and have higher/lower correlated activity. But these factors make other models worse. We’ve added the following text to point readers to our analysis, which can be found now in the new Figure 3—figure supplement 3:</p><p>[Page 11] “This model, in contrast to non-homophily models, uniquely generates low model fits and optimized model parameters independent of the increasing correlated activity and changing topology of the networks over this developmental period (see Figure 3—figure supplement 3 for detail).”</p><disp-quote content-type="editor-comment"><p>I am curious why the main point of the paper is based on the sparse cultures and the dense cultures are much less prominently featured, although the sparse case has n=6 and the dense case n=12.</p><p>Overall, I am surprised by which data are shown in the main figures, and which ones are supplementary.</p></disp-quote><p>We appreciate your comment about what is shown in the main versus supplementary figures. Initially, we only had the sparse network data for earlier developmental times (DIVs 7-14), and we found it an interesting observation that the energy value landscapes emerged as networks developed (whereas after DIV 14, these values seemed stable). Moreover, due to the length of the material in the manuscript and supplement, it has been a real challenge to curate what should show up in the main versus supplementary reports. We wanted to construct the paper to provide the key message that homophily models best approximate in vitro neuronal networks because we think this will appeal to the broadest audience; while still allowing those from different disciplines to explore specific aspects that they may find most interesting in the supplement, in depth. We hope our responses have facilitated this for you.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>General:</p><p>I am a little confused about how the statistics of the different generative networks are computed. Sometimes it mentions &quot;top performing simulated networks&quot;, sometimes &quot;top 10&quot; or &quot;top 50&quot;, others &quot;top n=1&quot;, and &quot;top n=99 and average&quot;. I do not understand why several results are based on the &quot;top n=1 performing simulated networks&quot;. These are probabilistic models for small networks, how is the best simulation representative of the underlying wiring principle? The original methodological paper (Betzel, Neuroimage 2016) appears to report the top 1% of energies (100 networks).</p></disp-quote><p>Thank you for bringing up this good point. There is some variability in the literature about what to report for the best performing parameters in these generative models. To improve the clarify, we made the following changes:</p><p>1. We have now kept the nomenclature consistent to additionally state “top n=1” rather than just saying “top performing simulated networks”. This occurred three times in captions, so hopefully this now clarifies precisely what we mean by our statement “top performing simulated networks”.</p><p>2. The reason we provided numerous numbers of top performing simulations was because we wanted to show consistency across numerous numbers of top performing parameters (e.g., n=1, n=10 and n=50) rather than just show it at a single threshold (e.g., top 1% of energies as in Betzel et al. 2016) which may present a potential bias (due to an accuracy-precision trade-off). An alternative approach would be to re-run the generative landscapes for each culture multiple times and average the top n=1 best simulation across these landscapes. This method was put forward since our submission by Liu, et al. 2023 NeuroImage (https://www.sciencedirect.com/science/article/pii/S1053811923001088). However, this approach requires all cultures to have the same number of nodes (as in human in vivo imaging) but this is not possible with HD-MEAs. We have outlined this in our limitations which we hope clarifies this:</p><p>[Page 40/41] Our search was intentionally extensive such that we had greater likelihood of converging on accurate parameter estimates for each culture with the capacity to generate good model fits. In the main paper, we report the top performing n=1 parameter simulation, but in each case, we replicate our findings across a variable number of high performing parameters (n=10 and n=50). This was done to show robustness to possible model stochasticity, which might have biased our results. Of note, recent work has provided a new solution to enable easier convergence on true parameter estimates in generative models (Liu, et al. 2023), but this approach requires the sample to have the same geometric structure which is not the case across our HD-MEA recordings.</p><p>Reference: Liu, Y., Seguin, C., Mansour, S., Oldham, S., Betzel, R., Di Biase, M.A., Zalesky, A. (2023). Parameter estimation for connectome generative models: Accuracy, reliability, and a fast parameter fitting method, NeuroImage, 270, 119962, https://doi.org/10.1016/j.neuroimage.2023.119962.</p><p>3. Across the whole paper, when presenting model energies acquired from the generative modeling, we had reported the main n=1 top performing simulation but then also provided additional simulation results (in the supplement) across the top n=10 and n=50 simulations to demonstrate robustness. However, we did find a single case where we only provided the top n=1 simulation, but not the others. This was for Figure 3—figure supplement 3. We’ve now extended Figure 3—figure supplement 1 to show, as in all other cases, that the results are consistent:</p><disp-quote content-type="editor-comment"><p>Similarly, it is often difficult to understand how significance was assessed across many figures and tables. For example for the anovas, and cohens effects on the energies. Sometimes energies are presented with 4 groups, others with 13. It is unclear if the same procedure was always followed.</p></disp-quote><p>We are happy to clarify our procedures. We have now updated our Methods to make it clear that we have reported all rule-based statistical comparisons (4 groups) for every analysis, but that we also provide Supplementary Figures showing the model fits by each individual model type too (of which there are 13):</p><p>[Page 39] When we report model fits in the main report, we group the model fits based on the broad generative rule group (as shown by the distinct colors in Figure 2d). Supplementary file 1c contains a summary of all optimized parameters and model fits. Supplementary files 1d-h show all statistical comparisons (One-way ANOVA and pairwise comparisons) between generative rule groups, over all time points for each considered analysis.</p><disp-quote content-type="editor-comment"><p>Line-based:</p><p>159: It is very difficult to relate the reported plating densities with densities reported in other studies. It'd be much better to report real densities (in cells/ mm2) measured at the time of recording (or after staining). See for example the works by Potter, Segal, Moses, labs, and others.</p></disp-quote><p>We thank the reviewer for bringing up this point and agree that the description of the cell densities could have been clearer. In the revised manuscript, we have added such details in the Supplementary file 1a.</p><p>We also agree that providing direct estimates of cell counts on the recording day would be more informative, as it is well established that not all neurons initially plated survive to the later developmental time points. Although tracking neurons across development on our chips might have been possible with reporter lines (e.g., that express a fluorescence tag in neurons for livecell imaging), we did not have such lines at hand. Moreover, another complication is that the used HD-MEAs are non-transparent. Nevertheless, to address this important comment, we added a sentence to the Methods</p><p><bold>[</bold>Page 31/32] Notably, cell densities were estimated only on the day of plating and not on the actual recording days. As reported in previous research (Xing, et al. 2021), it is assumed that the actual cell numbers on the HD-MEAs, on the respective recording days, were significantly lower than the initially plated numbers. This reduction may result from incomplete adherence to the HD-MEA, stress during the plating process, the composition of plated cells, and/or naturally occurring cellular processes such as apoptotic cell death.</p><p>Reference: Xing, W., de Lima, A. D. &amp; Voigt, T. The Structural E/I Balance Constrains the Early Development of Cortical Network Activity. Front. Cell. Neurosci. <bold>15</bold>, (2021).</p><disp-quote content-type="editor-comment"><p>171: After the whole-array activity scan, how were the 4x4 blocks selected? I assume one ends up with 64 independent 4x4 blocks, was the distance between them consistent? Was the ranking procedure from 1103 also used? Given that each 4x4 block can identify more than 1 cell, it is unclear why the number of tracked units in the sparse and dense cultures is so similar. Could it be that the electrode selection procedure was biased?</p></disp-quote><p>The electrode selection procedure for the network recordings with 4x4 electrode blocks is based on the whole-array pre-scan, the so-called activity scan. The electrode selection for these blocks applied the “Neuronal Units” option in the “Network Assay”, as provided by the MaxLab Live software (MaxWell Biosystems). It combines values, on either the detected spike amplitude or activity of electrodes, and a minimum distance between the centroids of the blocks. This minimum distance between the centroids, however, does not guarantee that all blocks are equally far apart. Because the used HD-MEAs do not allow for full-frame readouts, the selection of electrodes is focused on neurons which exceed a predefined activity/amplitude threshold – hence, there is clearly a selectin bias. The actual number of blocks and the number of connected read-out electrodes, however, also depends on other factors such as the location of the centroid of each block on the chip, and how well the switch-matrix routing procedure was able to connect electrodes for readout.</p><p>We clarify this now in the Methods:</p><p>[Page 34/35] “To characterize rodent in vitro neuronal networks on HD-MEAs, and to track their functional connectivity, we performed developmental recordings, starting one week after the plating. Using the MaxLab Live software (MaxWell Biosystems), we first used the “Activity Scan Assay” module, which performs a series of high-density recordings, to screen for active electrodes across the entire HD-MEA. During the activity scan the multi-unit activity for each electrode was estimated by applying an online sliding window threshold-crossing spikedetection algorithm. After the activity scan, we used the MaxLab Live “Network Assay” module to select up to 1024 readout-electrodes based on the identified active electrodes. To track networks at single-cell resolution over development, we obtained high-density network recordings, consisting of up to 64 non-overlapping 4 x 4 electrode blocks (electrode-to-electrode pitch of 17.5 μm), and a minimum spacing of at least 87.5 μm between the centroids of the blocks. Depending on the dataset at hand, the block configurations were based on an activity scan performed on DIV 7 (sparse PC networks) or DIV 14 (dense PC networks). The duration of the HD-MEA network recordings was 30 minutes (for each day); an overview on the different datasets is provided in Supplementary file 1a. The sparse/dense rodent PC neuronal networks (main manuscript) and the hCO’s were recorded on MaxTwo 6-well plates (MaxWell Biosystems); the human iPSC-derived neurons (glutamatergic, motor and dopaminergic neurons) were recorded on single-well MaxOne HD-MEAs (MaxWell Biosystems; see also (Ronchi, et al. 2021)). Finally, the validation dataset (Figure 7—figure supplement 3), comprising sparse rodent PC neuronal networks, was acquired on 24-well plates (MaxWell Biosystems).”</p><p>Reference: Ronchi, S. et al. Electrophysiological Phenotype Characterization of Human iPSC Derived Neuronal Cell Lines by Means of High-Density Microelectrode Arrays. Advanced Biology <bold>5</bold>, 2000223 (2021).</p><p>Importantly, the number of tracked units also depends on other factors, such as how well the spike sorting worked and how many cells met the criteria set during the post-processing and quality-control operations. All these factors contribute to the number of units inferred from the dense/sparse primary networks – and impact the size of the network. However, since our results generalize across densities, we do not regard this as a major limitation. Our results also replicate across different cell lines, which were not based on the 4x4 block recordings, but an electrode selection scheme that used the top 1024 most active electrodes (human neurons). Nevertheless, we agree with Reviewer 2 that studies should investigate how the (sub-)sampling of the underlying network affects the inferred connectivity/topology and the resulting generative model fits. We added a brief paragraph on this aspect to the Discussion/limitations section:</p><p>[Page 28/29] “Another important consideration is the impact of subsampling, and specifically, how the selection of HD-MEA recording configurations and neuronal units (e.g., including units only above a specific activity threshold) impacts the reported organizational properties in functional connectivity. Previous studies established that subsampling can significantly affect the inference of network dynamics and connectivity (Das, et al. 2020, Pillow, et al. 2007), and this should be considered when interpreting our results. Future studies could further probe how different parameter choices for selecting HD-MEA recording configurations and the exclusion of low activity units alters neuronal topology. Similarly, it would be important to test if the reported results also hold for more advanced network inference algorithms (Donner, et al. 2024).”</p><p>References: Das A, Fiete IR. Systematic errors in connectivity inferred from activity in strongly recurrent networks. Nature Neuroscience. 2020;23(10):1286–1296. pmid:32895567</p><p>Pillow JW, Latham P. Neural characterization in partially observed populations of spiking neurons. Advances in Neural Information Processing Systems. 2007;20.</p><p>Donner, C. <italic>et al.</italic> Ensemble learning and ground-truth validation of synaptic connectivity inferred from spike trains. <italic>PLOS Computational Biology</italic> 20, e1011964 (2024).</p><disp-quote content-type="editor-comment"><p>190: Regarding the jittering procedure, it is unclear whether it involved a random shift of either + or – 10 ms? or any value within that range (uniform distribution?)</p></disp-quote><p>We thank the reviewer for this comment and improved the description of the jittering procedure in the revised manuscript:</p><p>[Page 36] “For a given neuronal unit’s spike train, spike times were randomly jittered by sampling from a normal distribution with a standard deviation of 10 ms, generating a surrogate spike train. The code for jittering spike trains was adopted from the Neural Complexity and Criticality Toolbox<sup>156</sup>. The jittering and STTC inference procedure was repeated for each neuronal unit for 1000 permutations.”</p><disp-quote content-type="editor-comment"><p>310: Based on all the energy/exponent maps (e.g., Figure 2d right), the relevant range of exponents is always between -1 and 1 (or -3,3 at best). It is very difficult to read the value of the exponents based on the actual maps (e.g., Figure 3c). Maybe the authors could report the actual exponents somewhere (as they did in Sup Figure 14c for example). These values might help the interpretability of the results (for example, whether the exponents are positive or negative could be quite relevant).</p></disp-quote><p>This is a great suggestion, thank you. We have now added a new Supplementary file 1c that documents precisely the optimized parameters for each group of cultures across time and group. This means that readers can now cross-reference the parameters directly. For example, you can now clearly see whether the parameters are positive or negative.</p><p>[Page 8] “Foreshadowing our findings, we report all optimized model parameter fits and energy values, across all analyzed datasets, in Supplementary file 1c.”</p><disp-quote content-type="editor-comment"><p>357: What &quot;large topological changes&quot; do the authors refer to? Figure S2 only reports an overall increase in the number of connections. Also, is the network density measured as &quot;total degree / (1/2*N*(N-1))&quot; ? Or is there an extra factor of 2 somewhere? I'm trying to relate the values in S2a S2c, and supp Table 1.</p></disp-quote><p>We have now made this statement more specific to what we meant by “large topological changes” in terms of an increasing number of connections and network density:</p><p>[Page 11] “As previously shown (Figure 1), PC rodent networks underwent significant developmental changes during this time period. These changes are reflected by large changes in their functional networks, with an increasing number of connections and network density (Figure 1—figure supplement 2).”</p><p>On your second point, indeed the density is calculated as the percentage of present connections relative to all possible connections, which is exactly as you describe as a percentage: 100*total degree/(0.5*n*(n-1)). However, this is a graph measure of the network rather than the plating density quoted in Supplementary file 1a which we think may have caused the confusion. We’ve updated the caption to Supplementary file 1a to clarify this point:</p><p>[Page 28, Supplement] “The plating density here reflects the number of cells plated, rather than the graph density of the connectivity of the functional networks that are subsequently inferred following developmental time.”</p><disp-quote content-type="editor-comment"><p>374: Regarding &quot;homophily performs best when approximating empirical networks, but not randomized networks&quot;, how did the authors measure that? The full random case in S5b has the lowest energy of all, and lower energy would mean a better fit if I'm not mistaken. Or were the authors only talking about the &quot;randmio&quot; procedure? If so, the authors might want to plot S5b in the same range as the figure it has to be compared with (0 to 0.6).</p></disp-quote><p>Thank you for this point. The crucial clarification we needed to give is that we mean the <italic>relative</italic> performance of homophily to approximate the topology. For example, in S5b left we see that random networks can be simulated by all of the generative models simply because both wiring parameters can be tuned to zero – which is equivalent to random wiring. To make this clear, we have updated the S5b panel caption to make this clear:</p><p>[Page 10/11, Supplement] “In the case of completely random networks (left), there is no difference in relative performance across wiring rules, because the optimal parameter fit is achieved when both wiring parameters are set to zero, as this generates a totally random topology regardless of the rule.”</p><p>We’ve also updated the main text too:</p><p>[Page 11] “We find that, regardless of the model specification or connectivity measure tested here, homophily performs best when approximating empirical networks relative to all other models, but not randomized networks (Figure 3—figure supplement 4).”</p><p>We’ve kept the y-axis from 0-1 in this figure just to allow all null models to be compared on the same scale. We hope that our above changes have clarified your point.</p><disp-quote content-type="editor-comment"><p>375: I don't understand how the staining panel relates to the rest of this figure.</p></disp-quote><p>This staining panel is just to provide the readers with a visualization of some of the data that was recorded. When sharing our work with others, several people asked to see something like this to give them an intuition of how the cultures look. Unfortunately, outside of our description, we could not find an appropriate place to explicitly state this.</p><disp-quote content-type="editor-comment"><p>376: F3C, to which of the 13 generative models does this plot correspond to? If I'm not mistaken, the exponents are calculated independently for each of the 13 models and 4 time points.</p></disp-quote><p>The current caption states: “All energy landscapes of the matching generative network model for DIV 14”. We’ve now changed it to the following to make this clearer:</p><p>[Page 13] “All energy landscapes of DIV 14 networks, plotted on top of each other, under the matching generative network model (a homophily model).”</p><disp-quote content-type="editor-comment"><p>415: Unsure what the R2, r and p measures mean. Is this just pearson on F3e,f right panels, and its p-value?</p></disp-quote><p>Yes, the reviewer is correct. We apologize that this was not clear. We have updated the caption for F3e,f:</p><p>[Page 14] “The quoted r and p value correspond to the Pearson’s correlation between observed and simulated statistics shown.”</p><disp-quote content-type="editor-comment"><p>442: Same as the comment on L159, the authors should report the density at the time of recording. It is also worth noting that there are many more processes affecting the final density than just apoptosis.</p></disp-quote><p>We agree with Reviewer 2 and have added a paragraph to the Methods and a Supplementary file (see reply to L159). We also refer the reader to a study that probed the development of primary neuron numbers on transparent MEAs during a similar developmental period and at a similar plating density (Xing et al., 2021: https://doi.org/10.3389/fncel.2021.687306). Moreover, we now mention some of the other factors that very likely contribute to a decrease in neuron numbers at later time points (e.g., incomplete adherence to the HD-MEA, and stress during plaiting). See reply to L159 and reply on page 31/32 (of the manuscript).</p><disp-quote content-type="editor-comment"><p>444: I'd like to point out a few important references on this matter. Ivenshitz and Segal, J Neurophysiol 2010. Cohen et al., Brain Research 2008. They looked in detail at how different densities affect activity and network connectivity in cultures.</p></disp-quote><p>Thank you for pointing out these references. We have now included these references in the relevant section for readers to refer to.</p><disp-quote content-type="editor-comment"><p>455: Related to L171. I have difficulties understanding the relationship between plating densities, the number of recorded cells, the distance between cells, and inferred connectivity. From S3, the distribution of Euclidean distances for the two plated densities looks very similar. And the number of tracked units in S1 is also very similar. However, S7 reports functional connectivity with smaller edge lengths and higher clustering. This would be consistent if the higher plating density just resulted in more &quot;cells/mm2&quot; and the activity being invariant. But that doesn't seem the case. The authors should clarify that.</p></disp-quote><p>This is a very good point that we did not clarify appropriately in the paper. S3 reported the interneuronal Euclidean distances between all neurons that exist: i.e., the total distances existing between neurons irrespective of the inferred network. This is not the same as the empirical edge lengths of the network which, in (now Figure 5—figure supplement 1), reports the empirical edge lengths of the connections. This means that in the higher plating density the distribution of space between neurons doesn’t change, but the inferred functional connectivity length does. We have now updated this in the caption of both Figure 2—figure supplement 1 and Figure 5—figure supplement 1 to clarify this point.</p><p>In Figure 2—figure supplement 1, we’ve added:</p><p>[Page 6, Supplement] “For all distributions, we plot the total set of distances between neurons, irrespective of the inferred functional network.”</p><p>In Figure 5—figure supplement 1, we’ve added:</p><p>[Page 15, Supplement] “Note here that the edge length refers to the average length of existing functional connections in the network. This measure contrasts with Figure 2—figure supplement 1 which shows the inter-neuronal Euclidean distances between all neurons irrespective of the inferred functional network.”</p><disp-quote content-type="editor-comment"><p>509: Why did the authors choose a dissimilarity measure based on the Euclidean norm? Distances between correlation matrices are non-euclidean (see for example Venkatesh et al., Neuroimage 2020).</p></disp-quote><p>Thank you for this reference, as we were not aware of this paper. Here, the Euclidean norm is taken simply as a composite dissimilarity measure between the two matrices derived from the correlation structure of the network properties, rather than functional correlation matrices in as in Venkatesh et al. 2020 – which as you say is non-Euclidean in geometry. In this work, because we are measuring competing model performance, we believe the approach remains valid, but we acknowledge that alternative types of model fitting procedures could be used and should be the subject of future study. We have now added this caveat in the Methods section, and we thank you for pointing us to this:</p><p>[Page 39/40] “Moreover, there are alternative procedures to the one provided that could be taken to estimate the dissimilarity between the topological fingerprint matrices, that could provide greater capacity to distinguish generative model performances. For example, the Pearson’s correlation (as in representational similarity analysis; Kriegeskorte, et al. 2008) or the nonEuclidean geodesic distance (which better captures the non-Euclidean geometry of functional connectivity in functional magnetic resonance imaging; Venkatesh, et al. 2020) could be used. Future work should examine the advantages and disadvantages of these approaches for the case of generative network models.”</p><p>References: Kriegeskorte, N., Mur, M. &amp; Bandettini, P. A. Representational similarity analysis – connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, (2008).</p><p>Venkatesh, M., Jaja, J. &amp; Pessoa, L. Comparing functional connectivity matrices: A geometry aware approach applied to participant identification. NeuroImage 207, 116398 (2020).</p><disp-quote content-type="editor-comment"><p>625: If I understood this measure correctly, the STP is asymmetric STP(i-&gt;j) != STP(j-&gt;i). If that's the case, did the putative inhibitory connections cluster around specific input cells? i.e., following Dale's rule? That would be an interesting check.</p></disp-quote><p>We agree with Reviewer 2 that testing Dale’s rule would be an interesting check. For the present data, however, we focused only on strong inhibitory connections, i.e. connections that could be clearly picked up in pair-wise cross-correlation histograms. As outlined in previous work (e.g., English et al., 2017: https://doi.org/10.1016/j.neuron.2017.09.033), weak connections are likely missed with the STP approach. The number of putative strong inhibitory connections (in our data) was therefore low, which complicates more detailed analysis on clustering on specific input cells. We therefore leave this interesting idea for more in-depth analysis on inhibitory connections to future research. We clarified and rephrased the corresponding section in the Results, to point to this limitation of STP analyses:</p><p>[Page 20] “To further examine the extent to which washing out gabazine returned endogenous inhibitory activity as GABAA receptors are released from blockade, we also computed the spike transmission probability (STP) among neuronal units (Figure 6—figure supplement 3). This cross-correlogram based metric has been used to identify spike transmission, respectively spike suppression, and to infer putative excitatory/inhibitory functional connectivity from on-going extracellular spiking activity<sup>105</sup>. Indeed, we find that washout of gabazine led to a significant increase in the number of putative inhibitory connections (Wilcoxon signed rank: p=0.012; Figure 6b). It should be noted, however, that weaker inhibitory connections are likely missed with the applied STP approach (English, et al. 2017).”</p><p>Reference: English, D. F. et al. Pyramidal Cell-Interneuron Circuit Architecture and Dynamics in Hippocampal Networks. <italic>Neuron</italic> 96, 505-520 7 (2017).</p><disp-quote content-type="editor-comment"><p>904: How was this replication of the results with TE-based methods quantified? S5b only shows a similar trend as those in Figure 3, but no quantification. Was this measured on the sparse networks only? And were the properties of the TE-based network and the STTC ones similar regarding their topological properties and fingerprint?</p></disp-quote><p>We previously had not added statistics to the TE-based methods, because we aimed to show that the trend was similar in this TE comparison. However, we have now conducted statistical comparisons alongside a new analysis that we think will provide clarity to readers. Beyond showing the homophily performs best in TE-networks, we have added a new finding to the Supplementary Figure that shows a large correlation in the energy acquired between TE and STTC measures of connectivity (r = 0.849, r = 0.867 and r = 0.901 respectively for symmetrical, out and in transfer entropy respectively). This suggests that irrespective of the measure used to construct the networks (e.g., STTC or TE) there is a clear alignment in the generative outcomes. We’ve added this point to the main report:</p><p>[Page 11/12] “We find that, regardless of the model specification or connectivity measure tested here, homophily performs best when approximating the sparse empirical networks relative to all other models, but not randomized networks (Figure 3—figure supplement 4). For instance, in symmetrized TE networks (i.e., keeping only reciprocal connections), homophily models also perform best (p&lt;1.95x10<sup>-6</sup> for all pairwise comparisons and Cohen’s <italic>d</italic>&gt;1.12 reflecting a very large effect size). Furthermore, there is a clear alignment in the generative properties of the networks irrespective of if they were constructed using the STTC or TE, demonstrated by a very large positive correlation in their subsequent model energies (r = 0.849, p = 8.97x10<sup>-22</sup>, r = 0.867, p = 9.55x10<sup>-25</sup> and r = 0.901, p = 2.91x10<sup>-29</sup> when considering TE symmetrical, in or out (directed) connections respectively compared to the STTC; see Figure 3—figure supplement 4d).”</p><p>You can see the new panel in the figure.</p><p>Note that further to this, as described above, we have now reported all model parameters and acquired energy values for each dataset to provide additional quantification.</p><disp-quote content-type="editor-comment"><p>1119: How many cultures were treated with gabazine? Here it mentions &quot;Three&quot;. But F6 and the text mention n=9 (6 of them with washout).</p></disp-quote><p>Sorry for the confusion: n=9 were treated with gabazine, but n=6 of these were then “washed out”. We have now clarified this more clearly in the main text</p><p>[Page 19] “To address this, we cultured sparse rodent PC neurons under chronic application of media without gabazine (n=6, control) or with gabazine (n=9 gabazine-treated), a selective GABAA receptor antagonist (see Methods; Pharmacological experiments). Following chronic application of gabazine for two weeks, we washed out gabazine at DIV 14 and performed a final recording at DIV 15 in a subset of six cultures of the gabazine-treated dataset (n=6, termed washout) to determine the extent to which the cultures recovered.”</p><disp-quote content-type="editor-comment"><p>1172: A significance value of p &lt; 0.01 was chosen for the connectivity. If I understood it correctly, that means, that on average at this threshold, there's a 0.01 probability the observed SSTC value comes from the surrogate distribution. That would result in a 1% network density just from the false positive rate. That's in line with the values reported in S2a at 7 DIV where the network is probably not yet formed. But does that mean that at 14 DIV the expected number of false positives in the inferred connectivity is ~ 20%? Are the inferred networks robust to changes in the binarization threshold?</p></disp-quote><p>Thank you for this point. We have now added a new Figure 3—figure supplement 2 that shows our findings are indeed robust to changes in the binarization threshold:</p><p>[Page 11] “Figure 3—figure supplement 1 and Figure 3—figure supplement 2 shows comparisons across individualized models and across significance thresholds.”</p><disp-quote content-type="editor-comment"><p>Figures:</p><p>Figure 2d. Energy. The Clustering and Degree labels might have been swapped.</p></disp-quote><p>Thank you for spotting this. We have now updated this error.</p><disp-quote content-type="editor-comment"><p>Figure 3c. Is this for a representative network? Or averaged across the networks?</p></disp-quote><p>This plot shows the energy achieved from all DIV 14 rodent PC networks.</p><disp-quote content-type="editor-comment"><p>Figure 6d. How is the shift in the probability distribution related to the wiring becoming more random across all timepoints? Not sure what the authors mean by this.</p></disp-quote><p>We apologize for not being clearer. We have now added extra clarity to this, citing recent work for which readers can explore further. Put simply, when generative networks are made to have stronger constraints (i.e., higher magnitude parameters), the space of possible outcomes grows smaller. This is because the probability score distribution (P_ij) for subsequent wiring becomes more skewed (i.e, has lower entropy). This means that there is a <italic>relative</italic> higher likelihood of specific connections becoming wired together as there are small numbers of possible future connections with high probability scores (relative to the larger number of small probability scores). Conversely, networks with weaker wiring constraints (i.e., small magnitude scalar parameters) generate flatter probability distributions (i.e., has higher entropy). This means that when the next connection is forming, it is less certain precisely which connection will form. This is because there is now less of a disparity in the distribution of possible future connections compared to the prior example. This has been shown, for instance, from a recent Carozza et al. 2023 paper, e.g., see the following figure which shows how – as you increase wiring parameters – the dissimilarity decreases:</p><p>We have added the following clarifications in the text regarding P_ij flattening:</p><p>[Page 41] “Note that the probability score distribution “flattening” (from a relative lognormal distribution toward a uniform distribution) means that relatively more candidate connections come to have a higher probability of being connected in the future. This leads to a decreased specificity of future wiring (i.e., the scope of possible outcomes increases). This flattening effect is equivalent to the network outcomes becoming more random, because a greater number of possible future connections have a non-trivial probability score, and the formation of a connection is less driven by the underlying network topology. Note, a completely singular and uniform <italic>P<sub>i,j</sub></italic> distribution (e.g., where all connections have the same likelihood of wiring) generates an entirely random graph (e.g., Erdös &amp; Rényi, 1959). In contrast, when a generative network has a heterogeneous distribution in its <italic>P<sub>i,j</sub></italic> distribution (e.g., with large numbers of small probability scores and small numbers of large probability scores) the network will have a smaller scope for variability (for more detail, see Carozza, et al. 2023).”</p><p>References:</p><p>Erdös, P., &amp; Rényi, A. (1959). On Random Graphs I. Publicationes Mathematicae Debrecen, 6, 290-297.</p><p>Carozza, S., Akarca, D. &amp; Astle, D. The adaptive stochasticity hypothesis: modeling equifinality, multifinality and adaptation to adversity. 2023. <italic>PNAS.</italic></p><disp-quote content-type="editor-comment"><p>Figure 6d. There's a mention of SF13e,f, which doesn't exist. Could it be S14c,d?</p></disp-quote><p>Thank you for spotting this error. The Supplementary Figure labels were incorrect in that figure caption. They are all correct now. They were indeed 14, not 13.</p><disp-quote content-type="editor-comment"><p>Figure 7c. Why does the tsne plot only include the dense DIV 28 primary cultures? The other datapoints should also be included, e.g., sparse DIV 14 and gabazine experiments.</p></disp-quote><p>We agree and have updated Figure 7c tSNE plot to also include the sparse DIV 14 and gabazine experiments:</p><disp-quote content-type="editor-comment"><p>Supplementary:</p><p>Figure 3. left/right panels should be top/bottom panels.</p></disp-quote><p>Thank you for spotting this. This is now corrected.</p><disp-quote content-type="editor-comment"><p>Figure 10. This figure mentions the dense cultures at DIV 14. Why do they report n=6 when dense cultures are n=12? Or is this figure for sparse cultures instead? The caption also mentions &quot;Distributions are plotted for each […].&quot; There are no distributions in this figure.</p></disp-quote><p>Thank you for spotting this mistake. It is indeed dense cultures, and thus n=12. We have removed this incorrect last sentence regarding distributions. It now reads:</p><p>[Page 14, Supplement] “Using dense PC rodent networks (100,000 cells per well), we show n=156 data points (n=12 cultures x n=13 generative model simulations) corresponding to the top n=1 performing simulation’s energy and its topological fingerprint dissimilarity performances at DIV 14.”</p><disp-quote content-type="editor-comment"><p>Figure 11. It would be beneficial to also add a representative raster (panel a) for the washout case. Results in c report a very high firing rate but no bursting rate for the washout case. What does that look like in the raster?</p></disp-quote><p>Yes, we agree with you. We have now added in a third horizontal panel to show this. The washout temporal raster plot appears to more closely resemble the control recordings, though some of the population bursting that was seen in the gabazine condition can still be seen following washout. This is now shown in the new Figure 6—figure supplement 1, (previously S11):</p><disp-quote content-type="editor-comment"><p>Figure 12b. The axis should read ISI (it's already in the log scale). Caption mentions a tri-modal distribution for gabazine. Very hard to see when the washout distribution is on top.</p></disp-quote><p>Thank you for pointing this out. We have now corrected this (see above).</p><disp-quote content-type="editor-comment"><p>Figure 12c. Why is the network size so different between controls, gabazine, and washouts? This is never explained, yet several other measures might depend on this value, e.g., total degree.</p></disp-quote><p>This is a good question. It is possible that neuronal survival rate decreases with chronic gabazine treatment leading to fewer neurons surviving to the age at which we recorded. To these ends the network size indicates the number of neurons that met the various inclusion criteria, as defined during the postprocessing, that are sufficiently active and that formed connections. GABAA receptor block ultimately leads to fewer neurons satisfying these conditions. A reduction in inhibition might be expected to increase network activity or potentially lead to excitotoxicity in some neurons, though this likely depends on the complex circuitry. We agree that it is unclear how the measures may depend on this value. However, importantly, we have now shown in a new Figure 3—figure supplement 3 that model energy is low, independent of these factors. Nevertheless, we agree that this is a possible confound and have now mentioned this finding in the Results:</p><p>[Page 20] “Gabazine-treated cultures showed a reduction in the number of units forming significant functional connections (lower network size, p &lt; 0.001 and total degree, p=0.012). Note that following washout, network size can change as only spiking neurons are counted as nodes for network size calculation. Network size did not increase significantly (p=0.0625) following washout, though there was a small increase in network size in five of the six washed out cultures (by 18.4±6.2 %).”</p><p>We have also clarified these quantifications in the methods:</p><p>[Page 36/37] “Network size and total degree. The network size here refers to the number of nodes in the network. This excludes nodes that did not form any connections (neuronal units with &lt;0.01 spikes/s already excluded as above). Network size is sometimes referred to as network order in graph theory literature to avoid confusion with number of edges, however, we refer to the total number of edges in the network as total degree.”</p><p>And acknowledged this in the discussion:</p><p>[Page 29] “It also remains unclear to what extent the smaller size of gabazine-treated networks, compared to controls, affects other network statistics. However, given the homogeneity of activity across neurons in gabazine-treated networks, smaller network size, rather than flattened probability distributions, is unlikely to explain differences in best-fitting model parameters.”</p><disp-quote content-type="editor-comment"><p>Figure 15. Why were only the n=12 DIV 14 dense cultures included here?</p></disp-quote><p>This was the n = 12 DIV 28 dense rodent PC cultures because these were the most mature rodent recordings (the other human data is also DIV 28). We have now stated this in the caption of Figure 7—figure supplement 1 (previously S15):</p><p>[Page 23, Supplement]. “28-day-old dense rodent PC networks (100,000 cells per well) are included here for comparison, as this is the latest time point recorded for the rodent PC cultures, and ostensibly the peak maturity in terms of network activity.”</p><p>[Editors’ note: what follows is the authors’ response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>Reviewer #2 (Recommendations for the authors):</p><p>The authors have addressed the points I listed in my original recommendations for the authors. I thank them for the effort.</p><p>With respect to my point about &quot;random&quot; vs. &quot;specific&quot; wiring in the context of the GABA block I now have an additional concern:</p><p>I now understand that the Pi,j values are not direct probabilities, but just indicate relative preferences for edge placement. In that case, I am not sure a direct comparison of distributions in Figure 6d, and of their means is very meaningful. If all values for Pi,j of a given model were multiplied by a constant &gt;1 then it would not affect the model wiring, as the relative preferences remained unchanged. But in a plot such as 6d it would stretch the distribution out and increase its mean.</p><p>Besides, after reading the authors' reply where they elaborate on 6d, I now wonder if there is some confusion about the following two potential ways to plot Pi,j: First, where all potential edges are along the x-axis and Pi,j along the y-axis. Here, an ER network has a uniform distribution. Second, where Pi,j values are along the x-axis and their frequency along the y-axis, as in Figure 6. Here, an ER network shows a single δ peak -- as far away from a uniform distribution as possible.</p></disp-quote><p>You raise an excellent point about the interpretation of these distributions. You are correct that the relative preference would indeed remain unchanged if multiplied by a constant. Our point does not relate to the absolute distribution values, but rather to the shape differences between the distributions across experimental groups. These shape differences remain meaningful because all groups undergo identical generative procedures, so any scaling effects would be consistent across conditions. That is, the observed differences in distribution means reflect genuine differences in the underlying generative processes between conditions.</p><p>On your second point, you are completely correct there are several ways to plot P<sub>ij,</sub> and this changes the distribution referred to. Much of this is motivated by the work outlined by Carozza, et al. 2023 – which in a detailed way outlines the randomness of the resulting networks from the generative process. We previously updated our text to reflect the editorial question on this, but we have now added some additional text too reflecting your comment here and also outlining the key distinction between the ways of rendering the distributions to avoid any confusion:</p><p>[Page 41/42] “The probability score distributions, P<sub>i,j</sub>, shown in this work are plotted with the score value on the x-axis and the frequency on the y-axis. It is of note that there are alternative ways that one could represent these distributions, such as the edge index on the x-axis and P<sub>i,j</sub> on the y-axis, which would provide different appearing distributions which should be carefully considered (for more detail, see Carozza, et al. 2023 which provides a detailed analysis of the magnitude of randomness of generated networks under different parameter conditions).”</p><p>We also added some additional clarity in the manuscript:</p><p>[Page 21] “Therefore, we hypothesized that this would lead to a flattening of this lognormal distribution, meaning that the resultant topology became more random (see Methods; Generative probability distributions for detail). Indeed, in Figure 6d we show this to be the case: gabazine-treated networks exhibit a flattened P<sub>i,j</sub> distribution relative to both controls (median P<sub>i,j</sub> value=0.135 and 0.322 for gabazine &amp; control, respectively; p=1.54x10<sup>44</sup>, Cohen’s d=0.550) and also after gabazine washout (median P<sub>i,j</sub> value=0.179; p=5.04x10<sup>-8</sup>, Cohen’s d=0.196; see also Figure 6—figure supplement 4d). This finding suggests that gabazine alters the network wiring distribution as to become more variable in its wiring preferences, rather than being specific to a relatively smaller number of candidate neurons that are deemed particularly valuable to wire with.”</p><p>We hope these revisions and clarifications address your concerns. We sincerely appreciate your thorough and constructive review.</p></body></sub-article></article>