<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">76452</article-id><article-id pub-id-type="doi">10.7554/eLife.76452</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Coordinated multiplexing of information about separate objects in visual cortex</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-176526"><name><surname>Jun</surname><given-names>Na Young</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8841-3947</contrib-id><email>nayoung.jun@duke.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-46291"><name><surname>Ruff</surname><given-names>Douglas A</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-266819"><name><surname>Kramer</surname><given-names>Lily E</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-266798"><name><surname>Bowes</surname><given-names>Brittany</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-266799"><name><surname>Tokdar</surname><given-names>Surya T</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund10"/><xref ref-type="other" rid="fund11"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-266820"><name><surname>Cohen</surname><given-names>Marlene R</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-61015"><name><surname>Groh</surname><given-names>Jennifer M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6435-3935</contrib-id><email>jmgroh@duke.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf3"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Neurobiology, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Center for Cognitive Neuroscience, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Duke Institute for Brain Sciences</institution><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Neuroscience, University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Center for the Neural Basis of Cognition, University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Statistical Science, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Psychology and Neuroscience, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Biomedical Engineering, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Computer Science, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ray</surname><given-names>Supratim</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dese585</institution-id><institution>Indian Institute of Science Bangalore</institution></institution-wrap><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>29</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e76452</elocation-id><history><date date-type="received" iso-8601-date="2021-12-17"><day>17</day><month>12</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-10-21"><day>21</day><month>10</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2019-09-23"><day>23</day><month>09</month><year>2019</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/777912"/></event></pub-history><permissions><copyright-statement>© 2022, Jun et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Jun et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-76452-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-76452-figures-v1.pdf"/><abstract><p>Sensory receptive fields are large enough that they can contain more than one perceptible stimulus. How, then, can the brain encode information about <italic>each</italic> of the stimuli that may be present at a given moment? We recently showed that when more than one stimulus is present, single neurons can fluctuate between coding one vs. the other(s) across some time period, suggesting a form of neural multiplexing of different stimuli (Caruso et al., 2018). Here, we investigate (a) whether such coding fluctuations occur in early visual cortical areas; (b) how coding fluctuations are coordinated across the neural population; and (c) how coordinated coding fluctuations depend on the parsing of stimuli into separate vs. fused objects. We found coding fluctuations do occur in macaque V1 but only when the two stimuli form separate objects. Such separate objects evoked a novel pattern of V1 spike count (‘noise’) correlations involving distinct distributions of positive and negative values. This bimodal correlation pattern was most pronounced among pairs of neurons showing the strongest evidence for coding fluctuations or multiplexing. Whether a given pair of neurons exhibited positive or negative correlations depended on whether the two neurons both responded better to the same object or had different object preferences. Distinct distributions of spike count correlations based on stimulus preferences were also seen in V4 for separate objects but not when two stimuli fused to form one object. These findings suggest multiple objects evoke different response dynamics than those evoked by single stimuli, lending support to the multiplexing hypothesis and suggesting a means by which information about multiple objects can be preserved despite the apparent coarseness of sensory coding.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>noise correlations</kwd><kwd>variability</kwd><kwd>multiplexing</kwd><kwd>population coding</kwd><kwd>object vision</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R00EY020844</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01EY022930</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>Core Grant P30 EY008098s</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01DC013906</award-id><principal-award-recipient><name><surname>Groh</surname><given-names>Jennifer M</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01DC016363</award-id><principal-award-recipient><name><surname>Groh</surname><given-names>Jennifer M</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000872</institution-id><institution>McKnight Endowment Fund for Neuroscience</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000879</institution-id><institution>Alfred P. Sloan Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 DC013906</award-id><principal-award-recipient><name><surname>Tokdar</surname><given-names>Surya T</given-names></name></principal-award-recipient></award-group><award-group id="fund11"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 DC016363</award-id><principal-award-recipient><name><surname>Tokdar</surname><given-names>Surya T</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Two distinct objects evoke fluctuating activity in visual cortex in a manner that could preserve information about both items.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Coarse population coding has been widely explored in motor systems, where neurons show broad activity profiles and are thought to ‘vote’ for the movement typically associated with their peak activity (e.g., <xref ref-type="bibr" rid="bib26">Georgopoulos et al., 1986</xref>; <xref ref-type="bibr" rid="bib44">Lee et al., 1988</xref>). However, individual motor systems only generate one movement at a time. Such a coarse coding/population voting scheme cannot work in sensory systems where there are generally many stimuli to be represented rather than a single (e.g., arm or eye) movement to be specified. It has been assumed that sensory receptive fields are small enough that coarse coding does not apply, but this seems questionable. For example, the letters on the page you are reading now are probably &lt;0.25° apart, but foveal V1 receptive fields are approximately 0.5–2° in diameter (<xref ref-type="bibr" rid="bib18">Dow et al., 1981</xref>; <xref ref-type="bibr" rid="bib2">Alonso and Chen, 2009</xref>; <xref ref-type="bibr" rid="bib80">Xing et al., 2009</xref>; <xref ref-type="bibr" rid="bib19">Dubey and Ray, 2016</xref>; <xref ref-type="bibr" rid="bib42">Keliris et al., 2019</xref>). Receptive fields get even larger at later stages along the visual processing stream (e.g., <xref ref-type="bibr" rid="bib2">Alonso and Chen, 2009</xref>). In the auditory system, mammalian neurons may be responsive to nearly any location in space (e.g., <xref ref-type="bibr" rid="bib77">Woods et al., 2001</xref>; <xref ref-type="bibr" rid="bib31">Groh et al., 2003</xref>; <xref ref-type="bibr" rid="bib50">McAlpine and Grothe, 2003</xref>; <xref ref-type="bibr" rid="bib74">Werner-Reiss and Groh, 2008</xref>; <xref ref-type="bibr" rid="bib32">Grothe et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Higgins et al., 2010</xref>) and even frequency tuning is broad at conversational sound levels (<xref ref-type="bibr" rid="bib8">Bulkin and Groh, 2011</xref>; <xref ref-type="bibr" rid="bib76">Willett and Groh, 2022</xref>). Such breadth of tuning means that there can be overlap in the population of neurons activated by individual stimuli, making it unclear how information about multiple objects is preserved.</p><p>Logic suggests that information about each distinct stimulus must be segregated within the neural code in some fashion, either into exclusive neural subpopulations, different epochs of time, or some combination of both. We have recently presented the hypothesis that the nervous system might employ a form of neural turn-taking (time division multiplexing) in which individual neurons fluctuate between responding to each of the items in or near their receptive fields across various epochs of time (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Mohl et al., 2020</xref>). Such a coding scheme could preserve information about each stimulus across time and/or across neural subpopulations.</p><p>This theory raises three key open questions. First, is multiplexing a general phenomenon that occurs across a range of different brain areas? Our original study tested one subcortical auditory area (the inferior colliculus) and one extrastriate visual cortical area (area MF of the inferotemporal [IT] face patch system). More areas need to be tested to understand how such a coding scheme might operate. Second, in brain areas that exhibit such coding fluctuations, do neurons fluctuate together, and if so, how? Pairs of neurons might show positive, negative, or no correlations with each other. The pattern of such correlations across the population can reveal whether the population as a whole retains information about both stimuli and whether there is bias favoring one stimulus over another.</p><p>Third, does the pattern of fluctuations depend on the parsing of the scene into separate objects? Individual stimuli can fuse into one object or be perceived as distinct from each other. Stimuli that segregate into separate objects may be more likely to be associated with fluctuations in neural activity and their attendant correlations across neurons (<xref ref-type="bibr" rid="bib53">Milner, 1974</xref>; <xref ref-type="bibr" rid="bib28">Gray and Singer, 1989</xref>; <xref ref-type="bibr" rid="bib72">Von Der Malsburg, 1994</xref>; <xref ref-type="bibr" rid="bib69">Singer and Gray, 1995</xref>; <xref ref-type="bibr" rid="bib29">Gray, 1999</xref>) (but see <xref ref-type="bibr" rid="bib60">Palanca and DeAngelis, 2005</xref>), whereas stimuli that fuse into a single distinct object may cause activity patterns that are akin to those observed when only one stimulus is present. Such a pattern would specifically implicate activity fluctuations in playing a role in the perceptual process of object segregation.</p><p>To address these questions, we turned to the primary visual cortex (V1). V1 allows for a strong test of these hypotheses since V1 neurons have comparatively small receptive fields and are therefore less subject to the multiple-stimulus-overlap problem than the more broadly tuned areas such as the inferior colliculus or inferotemporal (IT) cortex that were assessed in our previous report (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>). Even though V1 neurons themselves have comparatively small receptive fields, V1 contributes to processing in higher cortical areas where spatial tuning is coarser. V1 could therefore also exhibit fluctuating activity patterns so as to facilitate preservation of information about multiple stimuli at higher stages.</p><p>We evaluated activity in V1 while monkeys viewed either individual stimuli (gratings) or two different types of combined stimuli (superimposed vs. adjacent gratings). When the two gratings were superimposed, they presumably appeared as one fused object, or plaid (<xref ref-type="bibr" rid="bib1">Adelson and Movshon, 1982</xref>; <xref ref-type="bibr" rid="bib64">Rodman and Albright, 1989</xref>; <xref ref-type="bibr" rid="bib33">Heeger et al., 1996</xref>; <xref ref-type="bibr" rid="bib13">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="bib47">Lima et al., 2010</xref>), whereas when they were adjacent they appeared as two distinct objects. We found evidence for coding fluctuations when two gratings were present at separate locations (two objects) but not when the gratings were superimposed at the same location and appeared as one fused object. We then evaluated the degree and sign of the spike count correlations (commonly referred to as ‘noise’ correlations; <xref ref-type="bibr" rid="bib16">Cohen and Kohn, 2011</xref>) observed between pairs of simultaneously recorded units in response to presentations of particular stimulus conditions. We found that the pattern of correlations varied dramatically depending on whether the stimuli were presented either individually or superimposed (single stimuli or one fused object) vs. when they were presented side-by-side (two separate objects). In the two-object case, the distribution of spike count correlations was markedly different from previous reports involving individual stimuli (<xref ref-type="table" rid="table1">Table 1</xref>, <xref ref-type="bibr" rid="bib16">Cohen and Kohn, 2011</xref>), and encompassed a range spanning many negative correlations in addition to positive ones. Whether the correlations tended to be positive vs. negative depended on whether the two neurons in the pair preferred the same stimulus (median correlation + 0.25) or preferred different stimuli (median correlation –0.05). The distribution of spike count correlation values was even more widely spread among pairs of neurons that showed demonstrably fluctuating activity across stimulus presentations (same preference: +0.49 and different preference: –0.14). In contrast, in the single stimuli and fused object (superimposed gratings) cases, positive correlations predominated (single stimuli: median value 0.15–0.19; fused object: median value +0.15). Distinct tuning-preference-related distributions of spike count correlations for adjacent stimuli but not for superimposed/fused stimuli were also seen in a smaller additional dataset in V4.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Summary of included data.</title><p>Analyses were conducted on ‘triplets,’ consisting of a combination of A, B, and AB conditions. If the spikes evoked by the A and B stimuli failed to follow Poisson distributions with substantially separated means, the triplet was excluded from analysis. This table shows the numbers of triplets that survived these exclusion criteria for each brain area and type of stimulus condition (last column), as well as the numbers of monkeys, distinct units, and sessions that they were derived from (columns 6–9).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">1. Stimuli</th><th align="left" valign="bottom">2. Brain area</th><th align="left" valign="bottom">3. Task</th><th align="left" valign="bottom">4. Monkeys</th><th align="left" valign="bottom">5. Available sessions</th><th align="left" valign="bottom">6. Sessions for which at least one triplet was included</th><th align="left" valign="bottom">7. Available units</th><th align="left" valign="bottom">8. Units for which at least one triplet was included</th><th align="left" valign="bottom">9. Triplets passing exclusion criteria for analysis</th></tr></thead><tbody><tr><td align="left" valign="bottom">Adjacent</td><td align="left" valign="bottom">V1</td><td align="left" valign="bottom">Attention</td><td align="left" valign="bottom">ST, BR</td><td align="char" char="." valign="bottom">16</td><td align="char" char="." valign="bottom">16</td><td align="char" char="." valign="bottom">1604</td><td align="char" char="." valign="bottom">935</td><td align="char" char="." valign="bottom">1389</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">V4</td><td align="left" valign="bottom">Fixation</td><td align="left" valign="bottom">BA, HO</td><td align="char" char="." valign="bottom">17</td><td align="char" char="." valign="bottom">17</td><td align="char" char="." valign="bottom">991</td><td align="char" char="." valign="bottom">274</td><td align="char" char="." valign="bottom">456</td></tr><tr><td align="left" valign="bottom">Superimposed</td><td align="left" valign="bottom">V1</td><td align="left" valign="bottom">Fixation</td><td align="left" valign="bottom">ST, BR</td><td align="char" char="." valign="bottom">25</td><td align="char" char="." valign="bottom">23</td><td align="char" char="." valign="bottom">2304</td><td align="char" char="." valign="bottom">770</td><td align="char" char="." valign="bottom">1686</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">V4</td><td align="left" valign="bottom">Fixation</td><td align="left" valign="bottom">JD, SY</td><td align="char" char="." valign="bottom">21</td><td align="char" char="." valign="bottom">21</td><td align="char" char="." valign="bottom">1744</td><td align="char" char="." valign="bottom">817</td><td align="char" char="." valign="bottom">1529</td></tr></tbody></table></table-wrap><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Trial counts for included sessions.</title><p>The values reported are calculated for individual recording sessions for which at least one triplet was included for the analysis; the numbers of trials are the same for all simultaneously recorded units within a session. The values for ‘A’ and ‘B’ trials indicate the values for either A or B; that is, there were on average 21 ‘A’ trials and 21 ‘B’ trials for each triplet in the adjacent V1 dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="2">Stimuli</th><th align="left" valign="bottom" rowspan="2">Brain area</th><th align="left" valign="bottom" colspan="4">Number of ‘A’ and ‘B’ trials</th><th align="left" valign="bottom" colspan="4">Number of ‘AB’ trials</th></tr><tr><th align="left" valign="bottom">Mean</th><th align="left" valign="bottom">SD</th><th align="left" valign="bottom">Min</th><th align="left" valign="bottom">Max</th><th align="left" valign="bottom">Mean</th><th align="left" valign="bottom">SD</th><th align="left" valign="bottom">Min</th><th align="left" valign="bottom">Max</th></tr></thead><tbody><tr><td align="left" valign="bottom">Adjacent</td><td align="left" valign="bottom">V1</td><td align="char" char="." valign="bottom">21.0</td><td align="char" char="." valign="bottom">12.3</td><td align="char" char="." valign="bottom">6</td><td align="char" char="." valign="bottom">56</td><td align="char" char="." valign="bottom">17.8</td><td align="char" char="." valign="bottom">12.8</td><td align="char" char="." valign="bottom">6</td><td align="char" char="." valign="bottom">59</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">V4</td><td align="char" char="." valign="bottom">72.8</td><td align="char" char="." valign="bottom">30.3</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">136</td><td align="char" char="." valign="bottom">72.2</td><td align="char" char="." valign="bottom">30.7</td><td align="char" char="." valign="bottom">6</td><td align="char" char="." valign="bottom">132</td></tr><tr><td align="left" valign="bottom">Superimposed</td><td align="left" valign="bottom">V1</td><td align="char" char="." valign="bottom">25.4</td><td align="char" char="." valign="bottom">15.4</td><td align="char" char="." valign="bottom">7</td><td align="char" char="." valign="bottom">74</td><td align="char" char="." valign="bottom">23.3</td><td align="char" char="." valign="bottom">12.1</td><td align="char" char="." valign="bottom">7</td><td align="char" char="." valign="bottom">64</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">V4</td><td align="char" char="." valign="bottom">131.3</td><td align="char" char="." valign="bottom">42.0</td><td align="char" char="." valign="bottom">20</td><td align="char" char="." valign="bottom">196</td><td align="char" char="." valign="bottom">184.5</td><td align="char" char="." valign="bottom">64.6</td><td align="char" char="." valign="bottom">20</td><td align="char" char="." valign="bottom">270</td></tr></tbody></table></table-wrap><p>Overall, this pattern of results is consistent with the possibility that when two visual objects are presented in close proximity, a subpopulation of visual cortical neurons fluctuates in a coordinated fashion, generally retaining information about segregated objects and suggesting an account for why they can be perceived at once.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>General experimental design</title><p>The activity of neurons in visual cortex was recorded in three experimental designs in six monkeys (N = 2 per experiment per brain area), using chronically implanted multielectrode arrays (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, <xref ref-type="table" rid="table1">Table 1</xref>). In the ‘superimposed’ dataset, the activity of neurons in V1 and V4 was recorded while monkeys passively fixated (for details, see <xref ref-type="bibr" rid="bib66">Ruff et al., 2016</xref>). In the ‘adjacent’ datasets, the activity of V1 and V4 neurons was recorded while monkeys either passively fixated (V4 recordings) or fixated while performing an orientation change discrimination task involving either one of these stimuli or a third stimulus presented in the ipsilateral hemifield (V1) (for details, see <xref ref-type="bibr" rid="bib67">Ruff and Cohen, 2016</xref>). In the ‘superimposed’ dataset, the gratings were large, spanning the receptive fields of the recorded neurons, and were presented either individually or in combinations of two orthogonal gratings at a consistent location on every trial (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). When the two gratings were presented, they superimposed and formed one fused ‘plaid’ object. In the ‘adjacent’ datasets, the stimuli were smaller Gabor patches (V1, V4, <xref ref-type="fig" rid="fig1">Figure 1d and e</xref>) or natural images (V4, <xref ref-type="fig" rid="fig1">Figure 1e</xref>, stimuli from <xref ref-type="bibr" rid="bib48">Long et al., 2018</xref>) and were presented either individually or adjacent to one another as two separate objects. Together they spanned the receptive fields of the V1 or V4 neurons being recorded in a fashion similar to the ‘superimposed’ experiment. For data collected during performance of the attention task (V1), we focused our analyses on trials in which the monkeys attended to the third stimulus and judged its orientation, that is, attention was consistently directed away from either of the two adjacent Gabor patches that elicited responses in the neurons under study (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). Trials in which the monkey was required to attend to one or the other of the adjacent Gabor patches were excluded from the analyses, as were incorrectly performed trials.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design.</title><p>(<bold>a</bold>) Multiunit activity was recorded in V1 and V4 using chronically implanted 10 × 10 or 6 × 8 electrode arrays in six monkeys (see ‘Methods’). (<bold>b</bold>) In both ‘superimposed’ and ‘adjacent’ datasets, the stimuli were positioned to overlap with (‘adjacent’ dataset) or completely span (‘superimposed’ dataset) the centers of the receptive fields of the recorded neurons. (<bold>c</bold>) In the ‘superimposed’ dataset, gratings were presented either individually or in combination at a consistent location and were large enough to cover the V1 and V4 receptive fields (stimulus diameter range: 2.5–7<sup>o</sup>). The combined gratings appeared as a plaid (rightmost panel). Monkeys maintained fixation throughout stimulus presentation and performed no other task. (<bold>d</bold>) In the V1 ‘adjacent’ dataset, Gabor patches were smaller (typically ~1<sup>o</sup>, see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) and were presented individually or side-by-side roughly covering the region of the V1 receptive fields. Monkeys maintained fixation while performing an orientation change detection task. The data analyzed in this study involved trials in which the monkeys were attending a third Gabor patch located in the ipsilateral hemifield to perform the orientation change detection. (<bold>e</bold>) In the V4 ‘adjacent’ dataset, the stimuli consisted of either Gabor patches or natural image stimuli, and monkeys performed a fixation task. Incorrectly performed trials and stimulus presentations during which we detected microsaccades were excluded from all analyses.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Stimulus and receptive field positions for the V1 &quot;adjacent stimuli&quot; dataset.</title><p>(<bold>a</bold>) Example receptive field positions, sample estimated receptive field size, and layout of stimuli for the V1 dataset involving adjacent stimuli. This figure was adapted from Figure 1B of <xref ref-type="bibr" rid="bib67">Ruff and Cohen, 2016</xref>. (<bold>b</bold>) Actual stimuli used. One ‘A’ and one ‘B’ stimulus was used in each session. The sizes of the circles indicate the sizes of the Gabor patches; specifically, the radii are equal to twice the standard deviations of the Gaussian envelopes used to construct the patches. Some stimuli were centered slightly into the ipsilateral hemifield but extended into the contralateral hemifield.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Eye positions did not differ on single vs. combined stimulus trials (adjacent dataset).</title><p>(<bold>a</bold>) Average eye positions during stimulus presentations on single (gray) vs. dual (magenta) stimulus trials during one recording session. Box indicates the fixation window, which was ±0.5°. (<bold>b</bold>) Geometric mean of the horizontal and vertical standard deviations of eye position for this session. (<bold>c</bold>) Average standard deviation of eye position across all 16 recording sessions as a function of stimulus type. The single vs. combined stimulus values did not differ (one-tailed paired <italic>t</italic>-test, p=0.927).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Relationship between receptive field (RF) location, stimulus location, spike count model classification , and whether firing rates also correlated with scatter in eye position.</title><p>For clarity, receptive field centers are shown in relationship to the location of the more contralateral of the two stimuli; the other stimulus location is shown as the average of all the other stimulus locations in relation to the most contralateral one. Each dot shows the RF center of one unit condition (i.e., unit and particular set of stimulus conditions tested in the analysis). Yellow-orange dots correspond to the RF centers for unit conditions that met criteria for inclusion but for which the Bayesian response pattern classification did not yield a high-confidence result (i.e., probability of successful classification was less than 0.67). Magenta and green symbols indicate RF centers for unit conditions that were classified as ‘mixture’ (magenta) or as something other than a ‘mixture’ (green) with high confidence (probability of successful classification was greater than 0.67). The magenta and green bull’s eye symbols correspond to unit conditions that also showed a significant correlation between firing rate and fixational scatter along the dimension connecting the two stimuli for that session (p&lt;0.01). A small number of unit conditions are not plotted here if the RF mapping did not produce a good estimate of RF center. Overall, significant correlations between spike count and scatter of eye fixation (p&lt;0.01) were identified in 4% of the stimulus conditions that were included for analysis (57/1389, see <xref ref-type="table" rid="table1">Table 1</xref>). Among the conditions that could be successfully categorized with a probability of at least 0.67 (see <xref ref-type="fig" rid="fig2">Figure 2</xref>), the prevalence of significant eye position correlations did not differ significantly for conditions labels as ‘mixtures’ (~9%) vs. those that received some other label (~5%). These proportions did not differ from one another by chi-square test (p=0.1730), nor is there any clear pattern in the location of unit conditions showing correlations with eye scatter in relation to RF centers and stimulus locations as shown in this figure. Finally, about 9% of ‘mixtures’ (n = 9) were responsive to both stimuli (i.e., RF centers were intermediate between the two stimuli and responses exceeded baseline firing by at least 1 standard deviation for both stimuli alone); among these nine, only one showed sensitivity to eye position (11%).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig1-figsupp3-v1.tif"/></fig></fig-group><p>Any potential contribution of eye movements and/or fixation variation to visually evoked activity was minimized as follows: (1) fixation windows were small, ±0.5° horizontally and vertically, and trials with broken fixations were excluded from further analysis. (2) Any trials with microsaccades during the stimulus presentations (defined as eye velocity exceeding 6 standard deviations above the mean velocity observed during steady fixation; <xref ref-type="bibr" rid="bib21">Engbert and Kliegl, 2003</xref>) were excluded from further analysis. (3) Only a 200 ms period after stimulus onset was analyzed. Our reasoning is that any stimulus-evoked modulation in eye position would have a latency of 150–350 ms (<xref ref-type="bibr" rid="bib21">Engbert and Kliegl, 2003</xref>). This would have limited the consequences of any potential stimulus-evoked fixational modulation to at most only roughly the last 50 ms of the 200 ms spike counting window. In addition, we verified that there actually was no difference in eye position variation based on the stimulus conditions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>), so even this slim possibility was not borne out. Finally, we assessed the responses of individual units to ascertain what proportion of units showed a correlation between firing rate and fixational scatter; this proportion was small overall (4–9%) and did not co-vary with the outcomes of the main analyses of the study (see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref> for details).</p></sec><sec id="s2-2"><title>Two objects evoke fluctuating activity patterns in V1</title><p>We first evaluated the response patterns for evidence of fluctuating activity profiles consistent with multiplexing of information on multistimulus trials. <xref ref-type="fig" rid="fig2">Figure 2a</xref> illustrates three V1 example units from the adjacent-stimuli dataset, each of which showed spike count distributions on dual stimulus presentations (black lines, 200 ms spike-counting window) that reflected a mixture of the distributions evident on the corresponding single-stimulus presentations (red and blue lines). The dual-stimulus distributions of spike counts are over-dispersed compared to what would be expected if the spikes on dual-stimulus presentations were generated from a similar Poisson process as the single- stimulus presentations, and a tendency for bimodality with modes near the modes for each of the individual stimulus presentations is evident.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Examples of V1 units showing fluctuating activity pattern and formal statistical analysis.</title><p>(<bold>a</bold>) Distribution of spike counts on single stimuli (red, blue) and dual adjacent stimulus presentations (black) for three units in V1 tested with adjacent stimuli. Spikes were counted in a 200 ms window following stimulus onset. (<bold>b</bold>) Bayesian model comparison regarding spike count distributions. We evaluated the distribution of spike counts on combined stimulus presentations in relation to the distributions observed on when individual stimuli were presented alone. Four possible models were considered as described in the equations and text. Only one case each of the ‘single’ (B-like) and ‘outside’ (λ<sup>AB</sup> &gt; max(λ<sup>A</sup>, λ<sup>B</sup>) is shown. (<bold>c, d</bold>) Best spike count models for the adjacent (<bold>c</bold>) and superimposed (<bold>d</bold>) stimulus datasets, meeting a minimum winning probability of at least 0.67, i.e., the winning model is at least twice as likely as the best alternative. Pie chart insets illustrate proportion of tested conditions that met this confidence threshold. While ‘singles’ dominated in the adjacent stimulus dataset and ‘singles’ and ‘outsides’ dominated in the superimposed stimulus datasets, we focus on the presence of a ‘mixtures’ as an important minority subpopulation present nearly exclusively in the ‘adjacent’ stimulus dataset.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Detailed results of the spike count response pattern classification analysis on V1 units for the adjacent (<bold>a</bold>) and superimposed datasets (<bold>b</bold>).</title><p>Shading indicates the confidence level of the model categorization. A winning probability of &gt;0.5 indicates that the winning model is at least as likely as all other models combined; a probability of &gt;0.67 indicates the winner is at least twice as likely as all others, and a probability of 0.95 indicates it is at least 20 times as likely as all others. Cases with a winning probability of &gt;0.25 (the minimum possible) but less than 0.5 are not shown. As noted in the main text, for the adjacent dataset, ‘mixtures’ represented 33% of the cases in which a particular model was at least twice as likely as all other models combined (i.e., the winning probability of 0.67); overall they represented 14% of the cases that passed the exclusion criteria as described in ‘Methods’ and <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig2-figsupp1-v1.tif"/></fig></fig-group><p>While it is visually evident that the spiking responses of these three V1 example units on combined AB stimulus presentations appear drawn from a mixture of the A-like and B-like response distributions, evaluating this systematically across the population requires a formal statistical assessment. We developed such an assessment in our previous work concerning fluctuating activity in the context of encoding of multiple simultaneous stimuli (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Mohl et al., 2020</xref>; <xref ref-type="bibr" rid="bib27">Glynn et al., 2021</xref>). In particular, we can model the firing rate behavior of neurons when two simultaneous grating stimuli A and B are presented in relation to the firing rates that occur when stimuli A and B are presented individually. We assume that each single-stimulus condition induces Poisson-distributed spike counts and we exclude cases where this assumption is violated (see ‘Methods’ for details). We use a Bayesian model comparison framework to consider four hypotheses concerning the combined AB stimulus presentations (<xref ref-type="fig" rid="fig2">Figure 2b</xref>): (1) the responses to A and B together appear drawn from the same distribution as either A or B and consistently so on every stimulus presentation, as if the unit responded to only one of the two stimuli (‘<italic>single’</italic>). (2) Responses to A and B together appear drawn from a distribution ‘<italic>outside’</italic> the range spanned by the A and B response distributions; this is the predicted pattern if neurons generally exhibited enhanced responses to combined AB stimuli than either stimulus alone, or if one stimulus strongly suppressed the response to the other. (3) The responses to A and B together are drawn from a single distribution with a mean at an ‘<italic>intermediate’</italic> value between the A-like and B-like response rates. This is the response pattern that would be expected under theories such as divisive normalization in which the responses of an individual neuron to a more favored stimulus are reduced when other stimuli are also present, but can also represent fluctuating activity on a fast, sub-stimulus-duration timescale, as shown for some neurons in the IT face patch system and inferior colliculus (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>). (4) The responses to A and B together appear to be drawn from a ‘<italic>mixture’</italic> of the A-like and B-like response distributions. Mixtures are the category of interest for this analysis as they indicate the presence of activity fluctuations at the stimulus-presentation timescale.</p><p>The overall presence of ‘mixtures’ in V1 differed substantially depending on whether one object or two was presented (the superimposed vs. adjacent grating datasets). <xref ref-type="fig" rid="fig2">Figure 2c</xref> shows the results for conditions that produced a winning model that was at least twice as likely as its nearest competitor (‘win prob &gt;0.67,’ the full results are provided in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). We found that ‘mixtures’ were evident in a third of V1 units (33%) when two objects were presented (adjacent gratings, <xref ref-type="fig" rid="fig2">Figure 2c</xref>), but were very rare when only one ‘object’ was present (superimposed gratings, <xref ref-type="fig" rid="fig2">Figure 2d</xref>, 2%). The incidence of ‘mixtures’ in V1 for the adjacent stimuli was slightly below that observed in the MF face patch in IT cortex (38%) and about half the rate observed in the inferior colliculus (67%; IT and IC data reanalyzed from <xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref> to use similar winning model criteria as shown here for this study). The remainder of the tested conditions were best explained by the ‘single’ hypotheses for the adjacent stimuli, indicating winner (or loser)-take-all response patterns, or a blend of ‘single’ and ‘outside’ for the superimposed plaid stimuli, indicating the predominance of winner/loser-take-all and either enhancement or suppression in this dataset (see also <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). This ‘single’ vs. ‘single-or-outside’ difference almost certainly stems from differences in the size of the stimuli being presented in these two datasets – typically only one of the two adjacent gratings was located within the classical receptive field of a given V1 unit, whereas this was often not the case for the superimposed dataset. This difference is a side note to our main focus on the fluctuating activity patterns that do occur in V1 in response to multiple objects but not in response to individual objects.</p></sec><sec id="s2-3"><title>Possible ways fluctuating activity might be coordinated across the population</title><p>Our next question concerns how fluctuating activity patterns are coordinated at the population level, and the implications for preserving information about each of the stimuli that are present. To assess such coordination, we computed Pearson’s correlation between the spike count responses observed during presentations a given stimulus combination for pairs of units in each data set (spike count correlation, r<sub>sc</sub>, also commonly called a noise correlation). We begin by discussing the possible results and their interpretation schematically in <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>. The overall point is that the activity of pairs of neurons might be either positively or negatively correlated, and the interpretation of such correlation patterns will depend on the turning preferences of the two neurons in the pair.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Schematic depiction of possible response patterns and resulting correlations.</title><p>(<bold>a</bold>) Three hypothetical neurons and their possible spike count distributions for single-stimulus presentations. Units 1 and 2 both respond better to stimulus ‘A’ than to stimulus ‘B’ (“congruent” preferences). Unit 3 shows the opposite pattern (‘incongruent’ preferences). (<bold>b, c</bold>) Possible pairwise spike count correlation (Rsc) patterns for these units. Two units that have congruent A vs. B response preferences will show positive correlations with each other if they both show ‘A-like’ or ‘B-like’ activity on the same trials (panel <bold>b</bold>, left). In contrast, if one unit prefers ‘A’ and the other ‘B’ (incongruent), then A-like or B-like activity in both units on the same trial will produce a negative spike count correlation (panel <bold>b</bold>, right). The opposite pattern applies when units tend to respond to different stimuli on different trials (panel <bold>c</bold>). (<bold>d–f</bold>). Key examples of the inferences to be drawn at the population level from these potential correlation patterns. (<bold>d</bold>) Positive correlations among ‘congruent’ pairs negative correlations among ‘incongruent’ pairs would suggest only one stimulus is encoded at the population level at a time. (<bold>e</bold>) If both stimuli are encoded in the population, then both positive and negative correlations might be observed among both congruent and incongruent pairs. (<bold>f</bold>) Both stimuli may be encoded, but not necessarily equally. This example shows a pattern intermediate between the illustrations in (<bold>d</bold>) and (<bold>e</bold>), and is consistent with one of the two stimuli being overrepresented compared to the other. Other possibilities exist as well, including that neurons may could be uncorrelated with one another (not shown), which would also serve to preserve information about both stimuli at the population level.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Details of population-level predictions under different scenarios.</title><p>Schematic histograms of the possible patterns of spike count correlations across all the pairs of recorded neurons as a function of whether they share the same (‘<italic>congruent’</italic>) stimulus preferences or have different (‘<italic>incongruent’</italic>) preferences, and whether they tend to ‘encode’ the same stimulus or different stimuli on each presentation (panel <bold>h</bold> is panel <bold>a</bold> + panel <bold>d</bold>; <bold>i</bold> = <bold>a</bold> + <bold>e</bold>;<bold> j</bold> =<bold> b</bold> + <bold>f</bold>; <bold>k</bold> = <bold>c</bold> + <bold>g</bold>; the bottom row [<bold>c, g, k</bold>] is a biased version of the row above [<bold>b, f, j</bold>]). Panels (<bold>h</bold>), (<bold>j</bold>), and (<bold>k</bold>) are included in <xref ref-type="fig" rid="fig3">Figure 3</xref> as panels (<bold>d</bold>), (<bold>e</bold>), and (<bold>f</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig3-figsupp1-v1.tif"/></fig></fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Patterns of spike count correlations among pairs of V1 neurons in different subgroups and conditions.</title><p>(<bold>a</bold>) Example units’ correlation patterns (same units as <xref ref-type="fig" rid="fig2">Figure 2a</xref>). The two units that shared a similar tuning preference (‘congruent’) exhibited positively correlated spike count variation on individual stimulus presentations for the dual stimulus condition (left), whereas both units 1 and 2 exhibited a negative correlation with the differently tuned (‘incongruent’) unit 3 (middle and right panels). (<bold>b</bold>) Distribution of R<sub>sc</sub> values for the other units that were simultaneously recorded with unit 1 and were also classified as ‘mixtures,’ color coded according to whether the stimulus preference of the other unit was the same as that of unit 1 (‘congruent,’ green) or different (‘incongruent,’ brown). All of the ‘congruent’ pairs exhibited positive correlations, and 5 of 5 were individually significant (p&lt;0.05). All of the ‘incongruent’ pairs exhibited negative correlations, and 1 of 5 was individually significant (p&lt;0.05). (<bold>c</bold>) Overall, neural pairs in which both units met the ‘mixture’ classification showed distinct positive and negative patterns of correlation in response to adjacent stimuli. Positive correlations were more likely to occur among pairs of neurons that responded more strongly to the same individual stimuli (‘congruent,’ green bars, median r<sub>sc</sub> = 0.486), and negative correlations were more likely to occur among pairs of neurons that responded more strongly to different individual stimuli (‘incongruent,’ brown bars, median r<sub>sc</sub> = –0.14, p&lt;0.0001, see ‘Methods’). This bimodal distribution did not occur when only a single stimulus was presented (dashed orange line). (<bold>d, e</bold>) This pattern of results held even when all the unit pairs were considered in aggregate (<bold>d</bold>, ‘congruent preference’ pairs, median r<sub>sc</sub> = 0.252; ‘incongruent preference’ pairs, median r<sub>sc</sub> = –0.052, p&lt;0.0001), and also occurred for well-isolated single units (<bold>e</bold>). (<bold>f</bold>) However, among pairs recorded during presentation of superimposed gratings, this pattern was not apparent: unit pairs tended to show positive correlations in both cases (‘congruent-preference’ median r<sub>sc</sub> = 0.159, ‘incongruent-preference’ median r<sub>sc</sub> = 0.144), and there was little evident difference compared to when a single grating was presented (orange line). See <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref> for additional information.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Median spike count correlations for additional subgroups of the V1 adjacent stimuli dataset.</title><p>The top two rows show the median spike count correlations observed for dual stimuli for various types of pairs of units, and correspond to the data shown in <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig5">Figure 5</xref> in the main text (gray background). The next three rows show the same analyses conducted for trials involving single stimuli. Here, the ‘congruent’ group was subdivided according to whether the presented stimulus was the one that elicited the stronger response (‘driven’) or the weaker one (‘not driven’). The bottom two rows show the differences in the medians observed for the relevant congruent and incongruent groups (lines 1 minus 2 and lines 3 minus 5; green background).</p></caption><media mimetype="application" mime-subtype="docx" xlink:href="elife-76452-fig4-data1-v1.docx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig4-v1.tif"/></fig><p><xref ref-type="fig" rid="fig3">Figure 3</xref> illustrates potential correlation patterns for pairs of several hypothetical neurons, each having a ‘mixture’ response patterns, but two with a similar or ‘congruent’ individual stimulus preference (unit 1, unit 2, more spikes elicited by ‘A’ than ‘B’ when presented alone) and one with a different stimulus preference compared to the other two (unit 3, more spikes elicited by ‘B’ than ‘A’ when presented alone, ‘incongruent’) (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). When spike count correlations are computed across trials in which both ‘A’ and ‘B’ are presented, four different scenarios (or combinations thereof) could occur. ‘Congruent’ units 1 and 2 could be positively correlated, suggesting they are encoding the same stimulus on the same trials (i.e., both ‘A’ or both ‘B,’ <xref ref-type="fig" rid="fig3">Figure 3b</xref>, left). Alternatively, they could be negatively correlated, suggesting they are encoding different stimuli on different trials (i.e., one ‘A’ and the other ‘B,’ <xref ref-type="fig" rid="fig3">Figure 3c</xref>, left). Conversely, when considering the spike count correlations between pairs of neurons exhibiting ‘incongruent’ stimulus preferences (e.g., a ‘B’ preferring unit 3 vs. the ‘A’ preferring unit 1), the opposite applies – a positive correlation would be consistent with the two neurons encoding different stimuli in concert (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, right), and a negative correlation would be consistent with encoding the same stimulus in concert (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, left). In short, positive vs. negative spike count correlations in response to combined stimuli will have different interpretations depending on whether the two neurons in the pair both respond more vigorously to the same component stimulus or to different component stimuli.</p><p>Several key potential patterns of spike count correlations across a population of pairs of neurons are illustrated in <xref ref-type="fig" rid="fig3">Figure 3d–f</xref>. If the population tends to encode the same stimulus at the same time, then pairs of neurons with congruent preferences will exhibit positive correlations and those with incongruent preferences will exhibit negative correlations (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). If the population tends to encode both stimuli, then both positive and negative correlations should occur in both pairs with congruent preferences and pairs with incongruent preferences (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). A third possibility is that both stimuli may be represented at the population level but not evenly so. Such a bias could be reflected by unequal amounts of positive and negative correlations (<xref ref-type="fig" rid="fig3">Figure 3f</xref>).</p><p>It should be noted that it is likely that all spike count correlations between pairs of neurons ride on an overall wave of at least slight positivity due to shared sensitivity to non-stimulus-related factors like overall arousal level or satiety-related signals that might accompany task performance. Thus, the negative- and positive modes of a broad distribution may not be symmetric around zero but slightly shifted toward the positive side.</p></sec><sec id="s2-4"><title>With two objects, distinct distributions of positive and negative spike count correlations occur in V1</title><p>We now turn to the actual results with these predictions in mind, starting with the example units illustrated in <xref ref-type="fig" rid="fig2">Figure 2a</xref>. Units 1 and 2 exhibited congruent stimulus preferences: stimulus ‘A,’ elicited higher spike counts (red line) than stimulus ‘B’ (blue line) for both. Unit 3 had the opposite (incongruent) preference, with higher spike counts for ‘B’ than for ‘A.’ <xref ref-type="fig" rid="fig4">Figure 4a</xref> shows the activity of each of these units on individual ‘A-and-B’ stimulus presentations plotted against the others. The pattern of spike count correlation on individual stimulus presentations varied depending on the stimulus tuning preferences, with the pairing between the units with congruent preferences yielding a positive value (0.56, panel d) and the two pairings involving incongruent preferences yielding negative spike count correlations (−0.45, –0.34, panels e and f). This pattern is borne out when the full set of pairings involving unit 1 and other units recorded at the same time that also showed ‘mixture’ response patterns is considered (<xref ref-type="fig" rid="fig4">Figure 4b</xref>): all the pairings that involved congruent tuning preferences yielded positive correlations, and all of these correlations are individually significant (green bars, p&lt;0.05). In contrast, all the pairings that involve incongruent tuning preferences yielded negative correlations (brown bars); as expected, these are slightly more weakly negative than the congruent pairings are positive, but 1 of 5 reaches individual significance (darker brown, p&lt;0.05).</p><p>We next considered the population level (with each pair of units contributing multiple r<sub>sc</sub> values to the population distribution, one value for each relevant stimulus condition; see ‘Methods’ for additional details). We first focused on the full set of formally identified ‘mixtures’ subgroup in the adjacent stimulus dataset (<xref ref-type="fig" rid="fig4">Figure 4c</xref>), we can see that the pattern observed for the example cells in <xref ref-type="fig" rid="fig2">Figures 2a</xref> and <xref ref-type="fig" rid="fig4">4a</xref> holds at the population level: neural pairs in which both units responded better to the same individual stimuli tended to have positive correlations with each other (‘congruent preferences,’ green bars, median 0.486), whereas those that had different (‘incongruent’) stimulus preferences tended to exhibit negative correlations (brown bars, median –0,14). The spread of values is broad, with many of the pairs of ‘incongruent-preference’ neurons in particular exhibiting positive values (a point we will return to in Figure 6).</p><p>Because of the lack of an adequate population of ‘mixture’-classified pairs in the V1 superimposed gratings dataset to compare to the adjacent gratings dataset, we next compared the populations as a whole (<xref ref-type="fig" rid="fig4">Figure 4d and f</xref>). The patterns are quite different between these two datasets. In the adjacent-stimulus dataset, the overall broad distribution and distinction between congruent-preference and incongruent-preference subgroups holds even when not selecting for ‘mixture’ fluctuating patterns (green bars vs. brown bars, median r<sub>sc</sub> 0.252, –0.052). However, this is much less true of the superimposed-gratings dataset (<xref ref-type="fig" rid="fig4">Figure 4f</xref>): here, there is very little difference between the congruent-preference and incongruent-preference pairs of neurons (median congruent-preference r<sub>sc</sub> = 0.159, median incongruent-preference r<sub>sc</sub> = 0.144), nor is there much difference between the spike count correlations observed on dual-gratings presentations vs. individual grating presentations for this dataset (orange dashed line). In contrast, there is a distinct difference between spike count correlations observed on the dual-stimuli vs. individual-stimulus presentations in the adjacent-stimulus dataset (orange dashed line, <xref ref-type="fig" rid="fig4">Figure 4c and d</xref>). We verified that this unusual pattern of positive and negative spike count correlations evoked by two objects was not an artifact of multiunit recordings: <xref ref-type="fig" rid="fig4">Figure 4e</xref> shows the spike count correlation patterns observed for the subset of 24 combinations of well-isolated units recorded simultaneously in the adjacent gratings dataset. While the data is sparse, the overall pattern is consistent with the observations from the full dataset.</p><p>We next considered whether this overall pattern was robust to the classification categories emerging from the Bayesian model comparison. While ‘mixtures’ reflect the strongest evidence for activity fluctuations at a stimulus presentation timescale, activity fluctuations are not fully ruled out among ‘singles’ and ‘intermediates.’ For example, if a neuron tended to respond in an ‘A-like’ fashion on a preponderance of trials but in a ‘B-like’ fashion on only a few of them, the Bayesian model classifier will rate ‘single’ as more likely than ‘mixture’ even though there is some evidence of fluctuation. Relatedly, if a neuron tended to switch between A-like and B-like response patterns more rapidly than the 200 ms stimulus presentation timescale, its overall response pattern would be best described as ‘intermediate.’ Thus, one might expect the general pattern observed among ‘mixtures’ to also be present to a lesser degree in these other model categories.</p><p>Indeed, this is the case. <xref ref-type="fig" rid="fig5">Figure 5</xref> illustrates the median spike count correlation by model classification category, for ‘congruent-preference’ and ‘incongruent-preference’ pairs of neurons. We excluded the ‘outside’ category from this analysis as there were too few units that were classified as such. We found that all nine combinations of classifications yielded positive median spike count correlations among ‘congruent’ preference pairs and negative correlations among ‘incongruent’ preference pairs. Thus, the overall pattern of results described above does not rest critically on the particular details of the model comparison we implemented here, and is present even among units that could not be formally shown to be fluctuating fully between ‘A’-like and ‘B’-like response distributions.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Median spike count correlations as a function of congruent-incongruent preference (panel <bold>a</bold> vs. panel <bold>b</bold>) and as a function of the spike count response profile classification resulting from the Bayesian model comparison for the V1 adjacent stimulus dataset.</title><p>The ‘mixture’-‘mixture’ combinations produced the strongest positive (congruent preference pairs) and strongest negative (incongruent preference pairs) median spike count correlations, but all other combinations also involved positive median correlations for congruent preference pairs and negative median correlations for incongruent preference pairs. See <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref> for additional information.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig5-v1.tif"/></fig><p>Returning to the predictions laid out in <xref ref-type="fig" rid="fig3">Figure 3d–f</xref>, the implication of congruent-preference units being on average positively correlated and incongruent-preference units being on average negatively correlated from a coding perspective is that V1’s representation (among ‘mixture’ units) may be slightly biased toward one or the other stimulus on each individual stimulus presentation, most closely resembling the schematic depiction in <xref ref-type="fig" rid="fig3">Figure 3d</xref>. However, the actual data involves a broad distribution with positive spike count correlations also occurring among the incongruent-preference pairs and negative spike count correlations among the congruent-preference pairs. Overall, this is most consistent with the schematic depiction in <xref ref-type="fig" rid="fig3">Figure 3f</xref>. In short, while the overall pattern of activity among ‘mixture’ units is biased toward one stimulus over the other on individual stimulus presentations, there are ample cases of units that do not follow this pattern, and these exceptions may be sufficient to preserve information about the other stimulus on any given trial.</p><p>To visualize this in another way, we repeated the calculation of Pearson’s correlations between pairs of unit conditions classified as mixtures using not the spike counts on each stimulus presentation but an assignment score concerning how ‘A’-like vs. ‘B’-like the spike count was on an individual stimulus presentation (ranging from 0 to 1; see ‘Methods’). Plotted this way, a positive correlation indicates that the two units in the pair tended to exhibit response patterns consistent with the same object at the same time, whereas a negative correlation indicates that the two units tended to exhibit responses consistent with different objects at the same time. The overall pattern in the data is positively skewed (<xref ref-type="fig" rid="fig6">Figure 6</xref>), but with a long tail on the negative side, consistent with the population of units giving an edge to one stimulus over the other on each individual presentation, but not to the complete exclusion of the other stimulus.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Activity fluctuations in ‘mixture’ pairs of unit conditions are consistent with a bias toward both units in the pair tending to signal the same stimulus at the same time.</title><p>This analysis involved the Pearson’s correlation coefficients computed on assignments scores (r<sub>as</sub>), which take into account whether the response on combined ‘AB’ stimulus presentations is more ‘A-like’ vs. ‘B-like.’ For two units that share a similar preference (e.g., both respond better to A or both respond better to B), this correlation will have the same sign as the spike count correlation (panel <bold>a</bold>, green points, positively sloped best-fit line). For two units that prefer different stimuli, this correlation will be opposite in sign to the spike count correlation (panel <bold>a</bold>, brown points, negatively sloped best-fit line). The overall positive skew in the assignment score correlations for both the ‘same’ and ‘different’ preferring unit condition pairs (panel <bold>b</bold>) therefore indicates a bias for the same stimulus at the same time. The negative tail indicates the other stimulus is nevertheless also represented in a (smaller) subpopulation of neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig6-v1.tif"/></fig><p>We note that this correlation pattern cannot be accounted for by any obvious confounds. As mentioned previously, all stimulus presentations with microsaccades were excluded from the analyses, limiting the degree to which shared dependence on eye movements could affect the correlation patterns. Furthermore, any variability in fixation position across stimulus presentations might affect the assessment of spike count correlations within a particular pair of neurons, but would not be expected to produce (1) a bimodal distribution of spike count correlations at the population level, that (2) occurs especially strongly when two distinct objects are presented. For example, if variability in fixation caused positive correlations between pairs of neurons whose receptive fields were aligned (likely at most a very small subset of our data), this effect should be equally present on both single-stimulus presentations when the stimulus is in those receptive fields and on double-stimulus presentations. Yet, as can be seen in <xref ref-type="fig" rid="fig5">Figure 5c and d</xref>, the positive extent of the correlations on double-stimulus presentations among ‘congruent preference’ pairs is higher than is observed on single-stimulus presentations (green bars extend to higher values than the orange curve), and vice versa for the ‘incongruent preference’ pairs.</p></sec><sec id="s2-5"><title>With two objects, distinct distributions of spike count correlations occur in V4</title><p>We next assessed V4, which showed both similarities and differences in comparison to V1. Like V1, activity patterns differed considerably in the superimposed vs. adjacent stimuli cases. However, the details of these differences differed: while ‘mixtures’ were present in both the superimposed and adjacent stimulus conditions in V4, ‘intermediates’ were more prevalent in the adjacent stimulus case than in the superimposed stimulus case. Given that ‘intermediates’ could also reflect fluctuations (like ‘mixtures’ but on a faster-than-stimulus-presentation timescale), we considered both mixtures and intermediates as subcategories of particular interest for the V4 dataset (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Results of the spike count response pattern classification analysis for V4 units.</title><p>Shown here are classifications for all units regardless of confidence level, and results from gabors and natural images are combined. See <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> for a breakdown by confidence level and for gabors and natural images separately. ‘Mixtures’ were seen in both datasets, but ‘intermediates’ were seen primarily in the adjacent-stimulus dataset. These two categories can in principle both contain fluctuating activity, and are grouped here as ‘between’ (i.e., the average response for dual stimuli for these two categories is between the average responses to single stimuli). As with V1, the relative proportions of ‘singles’ vs. ‘outsides’ also differed across these datasets. The combined incidence of these ‘not between’ categories was higher for the superimposed dataset than for the adjacent dataset.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Detailed results of the spike count response pattern classification analysis on V4 units for the adjacent (<bold>a–c, e</bold>) and superimposed datasets (<bold>d, f</bold>).</title><p>Shading indicates the confidence level of the model categorization as described in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Experiments involving adjacent gabors and adjacent images are combined in panels (<bold>a</bold>) and (<bold>e</bold>) and broken out separately in panels (<bold>b</bold>) and (<bold>c</bold>). Panels (<bold>e</bold>) and (<bold>f</bold>) show the sums of the corresponding bars in panels (<bold>a</bold>) and (<bold>d</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig7-figsupp1-v1.tif"/></fig></fig-group><p>The patterns of spike count correlations across mixture–mixture pairs in V4 varied considerably based on whether the stimuli were adjacent vs. superimposed and, for adjacent stimuli, whether the two units in the pair exhibited the congruent or incongruent stimulus preferences (<xref ref-type="fig" rid="fig8">Figure 8</xref>). For adjacent mixture–mixture pairs (panel a), the congruent-preferring units again tended to show positive spike count correlations, whereas for incongruent-preferring pairs, the distribution appeared centered around zero. It is unclear whether these pairs are truly uncorrelated or if they might appear uncorrelated due to a negative, stimulus-related, correlation being canceled out by a comparable, globally shared positive correlation that could stem from other factors (e.g., shared reward sensitivity). When intermediate–intermediate patterns are included, the overall pattern of a difference between the congruent-preferring and incongruent-preferring distributions is preserved (panel b), although now the incongruent-preference pairs are slightly positive. This pattern was still present when no selection for response pattern was applied (panel c), and is perhaps best appreciated by comparing the medians of the distributions (<xref ref-type="fig" rid="fig8">Figure 8f</xref>): there is a distinct difference between the median spike count correlation for same-preference and different-preference pairs for the adjacent dataset. Similar differences in the correlation patterns of congruent-preference vs. incongruent-preference pairs have also been identified in a previous study involving responses of V4 neurons to adjacent gratings (<xref ref-type="bibr" rid="bib71">Verhoef and Maunsell, 2017</xref>).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Like V1, pairs of V4 units show different patterns of spike count correlations when there are two adjacent stimuli vs. when there is one superimposed stimulus, depending on the tuning preferences of the pair.</title><p>(<bold>a</bold>) Mixture–mixture pairs for adjacent stimuli (gabors or images), color coded by whether the two units in the pair shared the same or had different tuning preferences. The ‘congruent preference’ and ‘incongruent preference’ median correlations differed (p&lt;0.002, see ‘Methods’). (<bold>b</bold>) Similar but including intermediate–intermediate pairs since they too may be fluctuating (median difference p&lt;0.0001). (<bold>c</bold>) All unit pairs tested with adjacent stimuli, regardless of classification in the modeling analysis (median difference p&lt;0.0001). Orange line shows the results for single-stimulus presentations. (<bold>d</bold>) Similar to (<bold>a</bold>) but for superimposed stimuli (median difference not significant). (<bold>e</bold>) Similar to (<bold>c</bold>) but for superimposed stimuli (median difference not significant). (<bold>f</bold>) Comparison of median spike count correlations in the adjacent vs. superimposed datasets, color coded by tuning preference.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig8-v1.tif"/></fig><p>However, again like V1, when the two stimuli were presented in a superimposed fashion, this difference was no longer evident. This was the case across the whole dataset (<xref ref-type="fig" rid="fig8">Figure 8e and f</xref>) as well as for mixture–mixture pairs (<xref ref-type="fig" rid="fig8">Figure 8d and f</xref>), suggesting that when fluctuations do occur for superimposed/bound stimuli, they likely reflect a somewhat different underlying mechanism or purpose than when distinct stimuli are presented.</p><p>The preceding spike count correlation analyses capture correlations as a single correlation value per pair of units. This approach is necessary for population-level statistical comparisons and comparison with similar published values in the literature. Reassuringly, the general findings from this approach can also be observed when considering the pattern of responses in a larger set of simultaneously recorded units across individual trials within individual recording sessions. <xref ref-type="fig" rid="fig9">Figure 9a</xref> shows the results from an individual recording session involving V1 units responding to pairs of adjacent stimuli. Ten units that exhibited ‘mixture’ response patterns to a particular set of stimuli are shown, with their activity illustrated in color across the 18 trials involving those stimuli. Key observations from this figure match the observations presented previously: (1) individual units show both ‘A-like’ and ‘B-like’ (red and blue) response patterns across trials – as expected since we selected ‘mixture’ units to include in the plot; (2) pairs of units can show correlations with each other (e.g., units 1 and 2 show strongly positively correlated fluctuation patterns, and units 3–5 show positive correlations that are present but somewhat weaker). However, this figure also makes clear that simultaneously recorded units do not correlate perfectly – there is considerable independence in what individual units are doing (compare, for example, units 3–5 with units 1 and 2). The net result of this is that on individual trials some units across the population are responding in an A-like fashion and others are responding in a B-like fashion. <xref ref-type="fig" rid="fig9">Figure 9b and c</xref> quantify this in a different way – at the cell level and at the trial level, individual cells exhibit some A-like and some B-like responses (as baked in by the selection criteria <xref ref-type="fig" rid="fig9">Figure 9c</xref>), and on individual trials, some cells exhibit A-like and others B-like responses (<xref ref-type="fig" rid="fig9">Figure 9b</xref>). This supports our overall interpretation that, at the population level, information about both stimuli is preserved on individual trials.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>At the population level, each stimulus appears to be encoded by at least some units on every trial.</title><p>(<bold>a</bold>) The activity of 10 simultaneously recorded V1 units on 18 trials in which a particular combination of two adjacent gratings were presented. The activity of each unit was color coded according to how ‘A-like’ (red) or ‘B-like’ (blue) the responses were on that trial. Only units for which ‘mixture’ was the best descriptor of their response patterns are shown (winning probability &gt;0.5, indicating ‘mixture’ was at least as likely as all other possibilities combined). There are both red and blue squares in every row, supporting the interpretation that these cells exhibited fluctuations across trials. There are also red and blue squares in every column, indicating that on every trial some cells were responding in an ‘A-like’ fashion and others in a ‘B-like’ fashion. (<bold>b</bold>) Histogram of the number of cells responding in ‘A-like,’ ‘B-like,’ or intermediate levels on each trial (each trace is a separate trial). (<bold>c</bold>) Similar histogram, but indicating the number of trials in which each cell responded in an ‘A-like,’ ‘B-like,’ or intermediate firing pattern. (<bold>d</bold>) A simulation of the expected pattern if the observed fluctuations chiefly involved covert fluctuations of attention – cells would be expected to show strong correlations with each other and respond in ‘A-like’ or ‘B-like’ fashion on the same trials. This simulation was constructed by retaining the cell identity and sets of responses observed for each cell, then instituting a strong correlation between them and shuffling the trials in random order. (<bold>e</bold>) A simulation of the expected pattern if cells were not fluctuating but instead averaging their inputs. This simulation was constructed by assuming that each trial’s response represented a draw from a normal distribution with the same mean as the observed distribution (0.34) and a standard deviation of 0.10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-fig9-v1.tif"/></fig><p><xref ref-type="fig" rid="fig9">Figure 9d and e</xref> illustrate how very different these observed patterns are from two a priori alternative possibilities that would involve loss of information about the two stimuli at the population level. <xref ref-type="fig" rid="fig9">Figure 9d</xref> captures what one might expect if fluctuations were due to covert shifts of attention – in this case, there might have been strongly correlated fluctuations in activity across all the neurons in the population, not merely individual pairs or small groups. This would appear as vertical stripes of shared blue or shared red across the neural population, indicating that only one stimulus was being encoded at a time. <xref ref-type="fig" rid="fig9">Figure 9e</xref> captures what one might expect if neurons were not fluctuating at all, but responding to combinations of stimuli by exhibiting normalized or averaged responses intermediate between the responses evoked by either stimulus along – a relatively uniform purple pattern across the neural population. In short, the pattern of responses we observed is quite different from these two alternative ‘lossy’ possibilities.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The central observations in this article are twofold. First, we identified fluctuating activity patterns in V1, evoked only by combinations of stimuli that are parsed as separate objects. These fluctuations were formally identified using a statistical analysis method benchmarked to the response patterns evoked by each of the stimuli independently (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Mohl et al., 2020</xref>; <xref ref-type="bibr" rid="bib27">Glynn et al., 2021</xref>). This finding suggests not only that multiplexing of information may be a general characteristic of sensory signals in the brain, but also implicates it in the process of separating vs. grouping of stimuli into objects.</p><p>These findings laid the groundwork for our second major question, how fluctuating activity patterns are coordinated across neurons and the implications for coding of stimuli at the population level. We found patterns of spike count correlations that differed substantially from those observed previously, but only when two objects were presented. Single objects (whether individual gratings or two superimposed gratings) yielded correlation patterns very similar to previous reports in the literature (<xref ref-type="bibr" rid="bib16">Cohen and Kohn, 2011</xref>; <xref ref-type="bibr" rid="bib66">Ruff et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Ruff and Cohen, 2016</xref>), and the correlations did not greatly depend on whether the two units in the pair preferred the same individual stimulus or different ones. In contrast, when two stimuli were presented adjacent to one another other, two distinct distributions emerged based on whether the two units in the pair preferred the same (congruent) individual stimulus (associated with generally positive spike count correlations) vs. different (incongruent) individual stimuli (associated with generally negative spike count correlations in V1 or simply less positive spike count correlations in V4). This pattern was observed in the population as a whole, but was especially pronounced in the subset of units that exhibited ‘mixture’-type response patterns indicating fluctuating across stimulus presentations between the response distributions associated with each of the individual stimuli.</p><p>We interpret these observations under the conceptual framework of the challenge that visual cortex faces when representing a visual scene that contains either individual stimuli, combinations of stimuli that bind to form one object, or combinations of stimuli that remain perceptually distinct from each other. The pattern of positive and negative (or less positive) correlations exhibited between pairs of such units is consistent with a population code biased toward one of the two stimuli on any given stimulus presentation, but that preserves information about the other stimulus as well.</p><p>It is interesting to note that we observed evidence of multiplexing each stimulus even in V1 where receptive fields are small and the stimuli we used did not themselves typically span more than one receptive field. Put another way, for most of these V1 ‘mixtures,’ the observed fluctuations involved responding vs. not responding rather than fluctuating between two different levels of responding. Thus, the coarseness of tuning did not necessarily pose a problem for the encoding of these particular stimuli in this particular brain area, and yet fluctuations were observed. Thus, the precision of V1’s spatial code may not be the limiting factor. Multiplexing is likely to have some as yet unknown characteristic spatial scale that may be determined by the coarsest tuning evident at any stage in the sensory pathway. Future work in which stimuli are systematically varied to manipulate the amount of overlap in the activity patterns evoked in different brain areas by each stimulus alone is needed to answer this question.</p><p>The constellation of our findings cannot be easily explained by any obvious alternative explanations. For example, could our focus on the activity patterns of multiunit clusters have impacted the results? If anything, this would be expected to work against the sensitivity of the analyses, if such clusters consisted of individual neurons who were behaving differently from one another. In fact, our findings were broadly similar in the subset of the data that involved well-isolated single units as compared to the full dataset involving multiunit activity. Furthermore, our previous study identifying coding fluctuations in the inferior colliculus and the MF face patch of inferotemporal cortex was conducted on well-isolated single units (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>). Thus, it seems unlikely that single vs. multiunit isolation significantly impacted our findings.</p><p>Could either microsaccades or small differences in the fixation position across trials have impacted the results? As noted earlier, we excluded trials with microsaccades, so such small eye movements are unlikely to have affected the findings, and fixational scatter did not vary by stimulus conditions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Thus, it is unlikely that variation in fixation position contributed to the difference we observed between two-object vs. fused-object response patterns or the differences between congruent-preference and incongruent-preference pairs of units. Furthermore, as noted above, we observed similar coding fluctuations in two brain areas (the IC and MF face patch) for auditory and large visual stimuli – that is, stimulus conditions that are thought to involve less sensitivity to differences in fixation position than V1 and V4 (<xref ref-type="bibr" rid="bib7">Bremmer, 2000</xref>; <xref ref-type="bibr" rid="bib30">Groh et al., 2001</xref>; <xref ref-type="bibr" rid="bib61">Porter et al., 2006</xref>; <xref ref-type="bibr" rid="bib62">Porter et al., 2007</xref>; <xref ref-type="bibr" rid="bib46">Lehky et al., 2008</xref>; <xref ref-type="bibr" rid="bib49">Maier and Groh, 2010</xref>; <xref ref-type="bibr" rid="bib9">Bulkin and Groh, 2012a</xref>; <xref ref-type="bibr" rid="bib10">Bulkin and Groh, 2012b</xref>; <xref ref-type="bibr" rid="bib51">Merriam et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>).</p><p>Finally, there is precedent in the literature for differences in the spike count correlation patterns of congruent vs. incongruent-preference pairs: a previous study in V4 (<xref ref-type="bibr" rid="bib71">Verhoef and Maunsell, 2017</xref>) also reported such correlation differences. The general effect size of our V4 results seems to be similar to theirs, particularly when considering the most comparable conditions. The Verhoef and Maunsell study was not designed to identify coding fluctuations, so the most comparable point of comparison in our study would be the pooled results across all model categories (<xref ref-type="fig" rid="fig8">Figure 8a</xref>). Our analysis focused on units with well-separated responses to the individual stimuli, which is most comparable to the right side of their Fig. 2C; our unit pairs were classified categorically as congruent- or incongruent-preferring rather than on a sliding scale, so it is not immediately apparent how to relate the two studies in that dimension (y axis in their Fig. 2C). Nevertheless, the approximate difference between the median or mean congruent-preferring vs. incongruent-preferring correlations is reassuringly similar at about 0.06 in our study and a maximum of about 0.12 in theirs. This suggests that the same-preference vs. different-preference correlation patterns observed in the two studies are likely to generalize across different experimental designs.</p><p>There has been a rich literature concerning the implications of correlated activity between visually responsive neurons in recent decades. One school of thought considers correlations in the context of the variability of neural firing. Under this ‘noise correlation’ view, positive correlations have historically been seen as detrimental for encoding information at the population level (<xref ref-type="bibr" rid="bib68">Shadlen and Newsome, 1994</xref>; <xref ref-type="bibr" rid="bib81">Zohary et al., 1994</xref>). Such views have also seen notable refinement and qualification since these early studies (<xref ref-type="bibr" rid="bib65">Romo et al., 2003</xref>; <xref ref-type="bibr" rid="bib3">Averbeck and Lee, 2004</xref>; <xref ref-type="bibr" rid="bib4">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib55">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="bib41">Kanitscheider et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Kohn et al., 2016</xref>; <xref ref-type="bibr" rid="bib59">Nogueira et al., 2020</xref>; <xref ref-type="bibr" rid="bib40">Kafashan et al., 2021</xref>), including recent work noting that neural variability could be a signal reflecting stimulus uncertainty (<xref ref-type="bibr" rid="bib37">Hénaff et al., 2020</xref>). Arguably closer to the current work is a different school of thought, the temporal correlation hypothesis (<xref ref-type="bibr" rid="bib53">Milner, 1974</xref>; <xref ref-type="bibr" rid="bib28">Gray and Singer, 1989</xref>; <xref ref-type="bibr" rid="bib72">Von Der Malsburg, 1994</xref>; <xref ref-type="bibr" rid="bib69">Singer and Gray, 1995</xref>; <xref ref-type="bibr" rid="bib29">Gray, 1999</xref>). This theory focused on the need to connect the brain’s representation of different attributes of a given object together, and proposed that such binding might be mediated through precise synchrony of spikes among neurons responding to the same object. This view, then, sees correlated activity as both useful and specifically relevant to object vision. Studies exploring this hypothesis have, however, primarily focused on within-trial temporal synchrony of spikes on the order of milliseconds, whereas the noise correlation literature has focused on spike counts in the domain of hundreds of milliseconds and analysis at the level of the ensemble of trials or stimulus presentations. By evaluating spike count variation at the level of stimulus presentations and comparing the results as a function of the number of stimuli/objects, the present work forges a bridge between these two areas of the literature.</p><p>Our findings also suggest reconsideration of two other key processes in visual neuroscience: selective attention and normalization. Selective attention refers to the fact that perceptual awareness is not equal across all stimuli present in a sensory scene. Selective attention can be controlled through ‘top-down’ means, such as via tasks in which participants are cued to focus on one stimulus and ignore others. Indeed, the monkeys were performing just such a task in our adjacent V1 dataset, and thus were in theory ignoring the stimuli whose responses we studied here. But even with correct task performance, top-down control of attention is imperfect. Might the fluctuating responses we observed be due to covert shifts of attention from one of the supposedly unattended stimuli to the other (which could contribute to the observed activity patterns; <xref ref-type="bibr" rid="bib20">Ecker et al., 2016</xref>; <xref ref-type="bibr" rid="bib22">Engel et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Denfield et al., 2018</xref>)? We think not. If this were the case, then the neurons should have fluctuated in more perfect harmony with one another. As shown quantitatively in <xref ref-type="fig" rid="fig6">Figure 6</xref> and qualitatively in <xref ref-type="fig" rid="fig9">Figure 9</xref>, although there is a bias in which stimulus is ‘capturing’ the response patterns on individual trials, there remains a substantial portion of the neural population that is responding to the other stimulus. And the observed pattern of fluctuating activity is very different from a simulation of covert attention (<xref ref-type="fig" rid="fig9">Figure 9a</xref> vs. <xref ref-type="fig" rid="fig9">Figure 9d</xref>). While further work on this question is needed, we think it is worth noting that the patterns of activity that we observed can in principle support preservation of information about all stimuli in the scene. Processes involved in selective attention might contribute to the creation of biases within this representation or could act at later stages on the information preserved within these representations to enhance awareness of one or more of the represented stimuli.</p><p>Previous findings from the existing literature on attention and related areas are consistent with this new view, and could easily be evaluated anew using the approach we described here. Trial-averaged neural responses to attended and unattended stimuli can often be modeled as a weighted combination of the responses to those stimuli when presented alone (<xref ref-type="bibr" rid="bib6">Boynton, 2009</xref>; <xref ref-type="bibr" rid="bib45">Lee and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib63">Reynolds and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib56">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Ni and Maunsell, 2017</xref>; <xref ref-type="bibr" rid="bib71">Verhoef and Maunsell, 2017</xref>; <xref ref-type="bibr" rid="bib58">Ni and Maunsell, 2019</xref>; <xref ref-type="bibr" rid="bib45">Lee and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib56">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Ni and Maunsell, 2017</xref>; <xref ref-type="bibr" rid="bib71">Verhoef and Maunsell, 2017</xref>; <xref ref-type="bibr" rid="bib58">Ni and Maunsell, 2019</xref>). Such averaging responses are seen not only in attention paradigms but in other contexts as well (e.g., see also <xref ref-type="bibr" rid="bib78">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="bib79">Xiao and Huang, 2015</xref>) and are generally referred to as normalization. Importantly, these reports have generally concerned responses pooled across trials. Trial-wise spike count distribution models such as those used here and/or faster subtrial analyses such as those we have introduced in previous work (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib27">Glynn et al., 2021</xref>) might indicate that such apparently averaging responses actually indicate fluctuations occurring on either the stimulus presentation or sub-stimulus presentation timescales, and not a true stable average (e.g., <xref ref-type="fig" rid="fig9">Figure 9a</xref> vs. <xref ref-type="fig" rid="fig9">Figure 9e</xref>).</p><p>That ‘normalization’ may not involve a fixed, stable operation that is constant across trials has recently garnered considerable interest. For example, several important recent studies have begun to explore how recurrent circuit mechanisms might implement dynamic fluctuations in neural activity (<xref ref-type="bibr" rid="bib34">Heeger and Mackey, 2019</xref>; <xref ref-type="bibr" rid="bib35">Heeger and Zemlianova, 2020</xref>) and have postulated that shifts in the balanced excitation and inhibition that is thought to underlie normalized average responses when two stimuli are presented might contribute to sizeable positive or negative spike count correlations (<xref ref-type="bibr" rid="bib71">Verhoef and Maunsell, 2017</xref>). Finally, recent work by Coen-Cagli and colleagues proposes a method of assessing normalization strength on individual trials and demonstrated a connection between the neural responses that are well-described under a normalization model and the level of variability of firing that they show (<xref ref-type="bibr" rid="bib15">Coen-Cagli and Solomon, 2019</xref>; <xref ref-type="bibr" rid="bib73">Weiss et al., 2022</xref>).</p><p>Returning to the topic of attention, recent work suggests a perceptual tie to the findings we report here. The likelihood of detecting a brief near-threshold visual stimulus varies with the phase of the brain wave oscillations at the time the stimulus is presented (<xref ref-type="bibr" rid="bib11">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib12">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib70">Vanrullen et al., 2011</xref>; <xref ref-type="bibr" rid="bib23">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Fiebelkorn et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Helfrich et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Fiebelkorn and Kastner, 2019</xref>; see also <xref ref-type="bibr" rid="bib22">Engel et al., 2016</xref>). This might reflect a perceptual consequence of a brain mechanism in which neurons are slightly biased toward representing some stimuli in the visual scene over others in a naturally occurring oscillatory fashion. Such bias was evident in the responses observed here, although we did not deploy a task to assess any potential connection to behavior. In our previous study (<xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>), we found that the LFP signal prior to stimulus onset was predictive of whether neurons would ‘pick’ A vs. B on a given trial. Future work will be needed to ascertain whether a similar phenomenon occurs in V1 or V4.</p><p>Finally, it is worth noting here that considering how the brain preserves information about <italic>two</italic> visual stimuli presented is still a far cry from understanding how the myriad details present in a natural scene are encoded. When the number of objects gets too great, it is unlikely that neurons can fluctuate between all of them, and this is likely to have consequences for perception, perhaps accounting for well-known limits on the number of objects we can perceive, attend to, and remember (e.g., <xref ref-type="bibr" rid="bib52">Miller, 1956</xref>; <xref ref-type="bibr" rid="bib75">Whitney and Levi, 2011</xref>; <xref ref-type="bibr" rid="bib38">Henry and Kohn, 2020</xref>). Future studies incorporating many stimuli and investigating how this changes the pattern of fluctuating activity and correlations between units are needed to shed light on how our brains operate outside the rarefied environment of the laboratory.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Electrophysiological recordings and visual stimuli</title><p>The full experimental procedures are described in <xref ref-type="bibr" rid="bib66">Ruff et al., 2016</xref> and <xref ref-type="bibr" rid="bib67">Ruff and Cohen, 2016</xref> and summarized below. All animal procedures were approved by the Institutional Animal Care and Use Committees of the University of Pittsburgh and Carnegie Mellon University (Protocol #: 20067560 PHS Assurance Number: D16-00118). Each of the datasets consisted of multielectrode recordings from two adult male rhesus monkeys for each brain area (<xref ref-type="table" rid="table1 table2">Tables 1 and 2</xref>). Recordings were made using chronically implanted a 10 × 10 microelectrode arrays (Blackrock Microsystems) in V1 and 6 × 8 arrays in V4 (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). The electrode shafts were 1 mm long, and the minimum distance between the nearest electrodes was 400 μm. In some sessions, recordings were also made using other electrodes in areas MT and 7a, but these data are not included in the current analyses.</p><p>The visual stimuli and behavioral experiment for the superimposed stimulus dataset are fully described in <xref ref-type="bibr" rid="bib66">Ruff et al., 2016</xref>. Monkeys were rewarded for passively viewing individual or superimposed orthogonal drifting gratings, positioned to span the receptive fields of the entire population of neurons under study (size range: 2.5–7<sup>o</sup>). As noted above, the fixation windows were ±0.5° horizontally and vertically, and stimulus presentations with microsaccades (defined as eye velocity exceeding 6 standard deviations above the mean velocity observed during steady fixation; <xref ref-type="bibr" rid="bib21">Engbert and Kliegl, 2003</xref>) were excluded from further analysis. In the full dataset, multiple contrast levels were presented, most of which were not included for analysis in this study. Here, we included trials in which one grating had a contrast of 0 (i.e., was not visible) and the other had a contrast of 0.5 (‘A’-alone and ‘B’-alone cases) or both gratings had a contrast of 0.5 (‘AB’). In most sessions, each stimulus lasted for 200 ms; a few sessions with 1000 ms stimuli were also included but only the first 200 ms were analyzed, that is, spikes were counted in a 200 ms window after stimulus onset for all the analyses in this study. This spike counting window was offset by the typical response latency for the region under study, that is, 30–230 ms for V1 and 50–250 ms for V4.</p><p>The visual stimuli and behavioral experiment for the V1 adjacent stimulus dataset are fully described in <xref ref-type="bibr" rid="bib67">Ruff and Cohen, 2016</xref>. The animals performed a motion direction change detection task in which they were cued in blocks of trials to attend to small drifting Gabor patches (~1<sup>o</sup>) in various locations and respond when the orientation of the attended location changed. In this study, we analyzed trials in which attention was directed to a Gabor patch located in the hemisphere ipsilateral to the recorded V1 neurons (i.e., well away from those neurons’ receptive fields, see below). On these trials, two unattended Gabor patches were presented in close proximity to each other within the area covered by the receptive fields of the recorded V1 neurons – these receptive fields were approximately 3° eccentric and had classical receptive field diameters typically estimated to be &lt;1° of visual angle. These patches were centered 2.5–3.5° eccentrically and each stimulus typically subtended 1° of visual angle (see <xref ref-type="bibr" rid="bib67">Ruff and Cohen, 2016</xref> Fig. 1B for a sketch, reproduced here in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The patches had the same orientation but drifted in opposite directions and were flashed on for 200 ms and off for 200–400 ms. We analyzed responses to all stimuli before the orientation change, excluding the first stimulus in every trial. Again, only correctly performed trials with no microsaccades during stimulus presentations were included for analysis. As noted previously, monkeys were required to maintain fixation within ±0.5°, and typically fixation was more precise than required; see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref> for fixational scatter in an example session and across sessions. Correlations between firing rates and scatter in fixation position were assessed for the dual-stimulus trials using the component of eye position that lay along a line connecting the two stimulus locations chosen for the recording session (see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref> for results).</p><p>The adjacent stimulus dataset for V4 involved two types of stimuli, small drifting Gabor patches as above or natural images of animals or common objects, from <xref ref-type="bibr" rid="bib48">Long et al., 2018</xref>. Results for the two types of stimuli were combined for the main analyses presented in this article (<xref ref-type="fig" rid="fig7">Figures 7</xref> and <xref ref-type="fig" rid="fig8">8</xref>), and are broken out separately in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>. The monkeys performed a fixation task.</p></sec><sec id="s4-2"><title>Analysis of spike count distributions</title><p>The full description of the statistical evaluation of spike count distributions on combined stimulus presentations can be found in <xref ref-type="bibr" rid="bib14">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Mohl et al., 2020</xref>. Briefly, we deployed a Bayesian procedure for modeling the distribution of spike counts in response to combined stimuli. Assuming that the spike counts corresponding to condition A and condition B are both Poisson-distributed with the rate parameters λ<sup>A</sup> and λ<sup>B</sup>, respectively (and excluding exceptions, see below), the four hypotheses for the spike count distributions for condition AB consist of</p><list list-type="order"><list-item><p>‘Single’: A single Poisson distribution Poi(λ<sup>AB</sup>), where λ<sup>AB</sup> exactly equals either λ<sup>A</sup> or λ<sup>B</sup>.</p></list-item><list-item><p>‘Outside’: A single Poisson distribution Poi(λ<sup>AB</sup>), where λ<sup>AB</sup> lies outside the range between λ<sup>A</sup> and λ<sup>B</sup>.</p></list-item><list-item><p>‘Intermediate’: A single Poisson distribution Poi(λ<sup>AB</sup>), where λ<sup>AB</sup> lies inside the range between λ<sup>A</sup> and λ<sup>B</sup>.</p></list-item><list-item><p>‘Mixture’: A mixture of the two single-stimulus distribution with an unknown mixing rate α: α Poi(λ<sup>A</sup>) + (1-α) Poi(λ<sup>B</sup>).</p></list-item></list><p>For each ‘triplet’ or combination of A, B, and AB conditions, the hypothesis with the highest posterior probability was selected, based on the intrinsic Bayes factor (<xref ref-type="bibr" rid="bib5">Berger and Pericchi, 1996</xref>) and using the equal prior (¼) among the four hypotheses, Jeffrey’s prior (<xref ref-type="bibr" rid="bib5">Berger and Pericchi, 1996</xref>) for the Poisson rate parameters, and a uniform prior in [0, 1] for the mixing weight α.</p><p>Only the triplets satisfying two exclusion criteria are used: (1) the single-stimulus distributions follow Poisson distributions, and (2) the single-stimulus rate parameters λ<sup>A</sup> and λ<sup>B</sup> are substantially separated. The first criterion was tested using Monte Carlo p-value calculation for a chi-square goodness-of-fit test (p&gt;0.10), and the second criterion was tested by whether the intrinsic Bayes factor of the model λ<sup>A</sup> ≠ λ<sup>B</sup> is more than three times higher than that of the model λ<sup>A</sup> = λ<sup>B</sup>. These exclusion criteria were applied to all the analyses in the article, even those that did not build specifically on this model classification, to ensure that comparisons between subpopulations of the data were not affected by differences in data selection criteria.</p><p>The numbers of trials involved for the different datasets are provided in <xref ref-type="table" rid="table2">Table 2</xref>. The trial counts were adequate to provide accurate model identification according to our previous simulations. Depending on the separation between λ<sup>A</sup> and λ<sup>B</sup>, we previously found that model identification accuracy in simulations is high for trial counts as low as 5 ‘AB’ trials, and plateaus near ceiling around ‘AB’ trial counts of about 10 trials and above – that is, below the mean trial counts available here for all datasets (see Figure 4 of <xref ref-type="bibr" rid="bib54">Mohl et al., 2020</xref>).</p></sec><sec id="s4-3"><title>Correlation analysis</title><p>We calculated spike count correlations between pairs of units recorded at the same time in the same experiment. The Pearson correlation coefficient was calculated on the spike counts for each presentation of each relevant stimulus combination. Stimulus presentations in which one or both units in the pair exhibited an ‘outlier’ response, that is, more than 3 standard deviations from the mean, were excluded from the analysis. The spike count correlations for particular unit pairs for different stimulus combinations were included in the population analyses as separate observations and were not averaged together. For example, in the V1 adjacent stimulus dataset, pairs were typically tested with two separate adjacent stimulus combinations, differing in the direction of motion, potentially yielding two values of the spike count correlation (assuming both conditions passed the Poisson and response-separation exclusion criteria noted above). Similarly, V4 neurons tested with different combinations of drifting gabors and/or images contributed values of spike count correlations for each stimulus set to the population.</p></sec><sec id="s4-4"><title>Congruent or incongruent preference</title><p>Preference of a unit for a particular stimulus was determined by higher spike counts. Unit pairs that both exhibited more spikes in response to stimulus A than to B, or both exhibited more spikes in response to stimulus B than to A, were defined as ‘congruent preference.’ Unit pairs in which one responded with more spikes to A and the other with more spikes to B were defined as ‘incongruent preference’.</p></sec><sec id="s4-5"><title>Comparison of distributions of spike count correlations</title><p>The medians of the ‘congruent preference’ vs. ‘incongruent preference’ distributions of spike count correlations were statistically compared using Monte Carlo methods in which the same/different preference assignments were randomly shuffled and the medians recalculated 10,000 times. When the true difference between the medians was greater than any of the shuffled versions, the p-value can be said to be less than 1/10,000 or 0.0001.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf3"><p>Reviewing editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Validation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Data curation, Software, Validation, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Software, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Software, Supervision, Funding acquisition, Investigation, Methodology, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal procedures were approved by the Institutional Animal Care and Use Committees of the University of Pittsburgh and Carnegie Mellon University: Protocol #: 20067560 PHS Assurance Number: D16-00118.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-76452-transrepform1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="sdata1"><label>Source data 1.</label><caption><title>Source data for the figures and analyses in this article are included as a zip file.</title><p>The file and folder names are informative regarding which analyses they relate to. Some analyses are based on multiple runs of the modeling code, with slight variations due to the probabilistic nature of the analysis.</p></caption><media xlink:href="elife-76452-data1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Source data is provided in a zip file; the individual files have informative names that indicate what they contain and thus to what figures they are linked.</p></sec><ack id="ack"><title>Acknowledgements</title><p>The authors thank Valeria C Caruso, Yunran Chen, Jeffrey T Mohl, Meredith N Schmehl, and Shawn M Willett for helpful comments on the analysis and manuscript. This work was supported by the National Institutes of Health grant nos. R00EY020844 (MRC), R01EY022930 (MRC); Core Grant P30 EY008098s (MRC); R01DC013906 (JMG, STT); and R01DC016363 (JMG, STT); and by support to MRC from the McKnight, Whitehall, Sloan and Simons Foundations.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adelson</surname><given-names>EH</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Phenomenal coherence of moving gratings</article-title><source>Nature</source><volume>300</volume><fpage>523</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1038/300523a0</pub-id><pub-id pub-id-type="pmid">7144903</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Receptive field</article-title><source>Scholarpedia</source><volume>4</volume><elocation-id>5393</elocation-id><pub-id pub-id-type="doi">10.4249/scholarpedia.5393</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Coding and transmission of information by neural ensembles</article-title><source>Trends in Neurosciences</source><volume>27</volume><fpage>225</fpage><lpage>230</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.02.006</pub-id><pub-id pub-id-type="pmid">15046882</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural correlations, population coding and computation</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nrn1888</pub-id><pub-id pub-id-type="pmid">16760916</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname><given-names>JO</given-names></name><name><surname>Pericchi</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The intrinsic bayes factor for model selection and prediction</article-title><source>Journal of the American Statistical Association</source><volume>91</volume><fpage>109</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1080/01621459.1996.10476668</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boynton</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A framework for describing the effects of attention on visual responses</article-title><source>Vision Research</source><volume>49</volume><fpage>1129</fpage><lpage>1143</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.11.001</pub-id><pub-id pub-id-type="pmid">19038281</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bremmer</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Eye position effects in macaque area V4</article-title><source>Neuroreport</source><volume>11</volume><fpage>1277</fpage><lpage>1283</lpage><pub-id pub-id-type="doi">10.1097/00001756-200004270-00027</pub-id><pub-id pub-id-type="pmid">10817607</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bulkin</surname><given-names>DA</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Systematic mapping of the monkey inferior colliculus reveals enhanced low frequency sound representation</article-title><source>Journal of Neurophysiology</source><volume>105</volume><fpage>1785</fpage><lpage>1797</lpage><pub-id pub-id-type="doi">10.1152/jn.00857.2010</pub-id><pub-id pub-id-type="pmid">21307328</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bulkin</surname><given-names>DA</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Distribution of eye position information in the monkey inferior colliculus</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>785</fpage><lpage>795</lpage><pub-id pub-id-type="doi">10.1152/jn.00662.2011</pub-id><pub-id pub-id-type="pmid">22031775</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bulkin</surname><given-names>DA</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Distribution of visual and saccade related information in the monkey inferior colliculus</article-title><source>Frontiers in Neural Circuits</source><volume>6</volume><elocation-id>61</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2012.00061</pub-id><pub-id pub-id-type="pmid">22973196</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The phase of ongoing EEG oscillations predicts visual perception</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>7869</fpage><lpage>7876</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0113-09.2009</pub-id><pub-id pub-id-type="pmid">19535598</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spontaneous EEG oscillations reveal periodic sampling of visual attention</article-title><source>PNAS</source><volume>107</volume><fpage>16048</fpage><lpage>16053</lpage><pub-id pub-id-type="doi">10.1073/pnas.1004801107</pub-id><pub-id pub-id-type="pmid">20805482</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname><given-names>L</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title><source>Neuron</source><volume>64</volume><fpage>931</fpage><lpage>942</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.004</pub-id><pub-id pub-id-type="pmid">20064398</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Glynn</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Willett</surname><given-names>SM</given-names></name><name><surname>Zaman</surname><given-names>A</given-names></name><name><surname>Ebihara</surname><given-names>AF</given-names></name><name><surname>Estrada</surname><given-names>R</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single neurons may encode simultaneous stimuli by switching between activity patterns</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2715</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05121-8</pub-id><pub-id pub-id-type="pmid">30006598</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Solomon</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Relating divisive normalization to neuronal response variability</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>7344</fpage><lpage>7356</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0126-19.2019</pub-id><pub-id pub-id-type="pmid">31387914</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Measuring and interpreting neuronal correlations</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>811</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1038/nn.2842</pub-id><pub-id pub-id-type="pmid">21709677</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denfield</surname><given-names>GH</given-names></name><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Shinn</surname><given-names>TJ</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attentional fluctuations induce shared variability in macaque primary visual cortex</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2654</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05123-6</pub-id><pub-id pub-id-type="pmid">29985411</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dow</surname><given-names>BM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Vautin</surname><given-names>RG</given-names></name><name><surname>Bauer</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Magnification factor and receptive field size in foveal striate cortex of the monkey</article-title><source>Experimental Brain Research</source><volume>44</volume><fpage>213</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1007/BF00237343</pub-id><pub-id pub-id-type="pmid">7286109</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dubey</surname><given-names>A</given-names></name><name><surname>Ray</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spatial spread of local field potential is band-pass in the primary visual cortex</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>1986</fpage><lpage>1999</lpage><pub-id pub-id-type="doi">10.1152/jn.00443.2016</pub-id><pub-id pub-id-type="pmid">27489369</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Denfield</surname><given-names>GH</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>On the structure of neuronal population activity under fluctuations in attentional state</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>1775</fpage><lpage>1789</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2044-15.2016</pub-id><pub-id pub-id-type="pmid">26843656</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engbert</surname><given-names>R</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Microsaccades uncover the orientation of covert attention</article-title><source>Vision Research</source><volume>43</volume><fpage>1035</fpage><lpage>1045</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(03)00084-1</pub-id><pub-id pub-id-type="pmid">12676246</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>TA</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Gieselmann</surname><given-names>MA</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Boahen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Selective modulation of cortical state during spatial attention</article-title><source>Science</source><volume>354</volume><fpage>1140</fpage><lpage>1144</lpage><pub-id pub-id-type="doi">10.1126/science.aag1420</pub-id><pub-id pub-id-type="pmid">27934763</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Saalmann</surname><given-names>YB</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rhythmic sampling within and between objects despite sustained attention at a cued location</article-title><source>Current Biology</source><volume>23</volume><fpage>2553</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.10.063</pub-id><pub-id pub-id-type="pmid">24316204</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Pinsk</surname><given-names>MA</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A dynamic interplay within the frontoparietal network underlies rhythmic spatial attention</article-title><source>Neuron</source><volume>99</volume><fpage>842</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.038</pub-id><pub-id pub-id-type="pmid">30138590</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A rhythmic theory of attention</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>87</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.11.009</pub-id><pub-id pub-id-type="pmid">30591373</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>AP</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name><name><surname>Kettner</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Neuronal population coding of movement direction</article-title><source>Science</source><volume>233</volume><fpage>1416</fpage><lpage>1419</lpage><pub-id pub-id-type="doi">10.1126/science.3749885</pub-id><pub-id pub-id-type="pmid">3749885</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glynn</surname><given-names>C</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Zaman</surname><given-names>A</given-names></name><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Willett</surname><given-names>SM</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Analyzing second order stochasticity of neural spiking under stimuli-bundle exposure</article-title><source>The Annals of Applied Statistics</source><volume>15</volume><fpage>41</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1214/20-AOAS1383</pub-id><pub-id pub-id-type="pmid">34413921</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>CM</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Stimulus-specific neuronal oscillations in orientation columns of cat visual cortex</article-title><source>PNAS</source><volume>86</volume><fpage>1698</fpage><lpage>1702</lpage><pub-id pub-id-type="doi">10.1073/pnas.86.5.1698</pub-id><pub-id pub-id-type="pmid">2922407</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The temporal correlation hypothesis of visual feature integration: still alive and well</article-title><source>Neuron</source><volume>24</volume><fpage>31</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)80820-x</pub-id><pub-id pub-id-type="pmid">10677025</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groh</surname><given-names>JM</given-names></name><name><surname>Trause</surname><given-names>AS</given-names></name><name><surname>Underhill</surname><given-names>AM</given-names></name><name><surname>Clark</surname><given-names>KR</given-names></name><name><surname>Inati</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Eye position influences auditory responses in primate inferior colliculus</article-title><source>Neuron</source><volume>29</volume><fpage>509</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(01)00222-7</pub-id><pub-id pub-id-type="pmid">11239439</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groh</surname><given-names>JM</given-names></name><name><surname>Kelly</surname><given-names>KA</given-names></name><name><surname>Underhill</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A monotonic code for sound azimuth in primate inferior colliculus</article-title><source>Journal of Cognitive Neuroscience</source><volume>15</volume><fpage>1217</fpage><lpage>1231</lpage><pub-id pub-id-type="doi">10.1162/089892903322598166</pub-id><pub-id pub-id-type="pmid">14709238</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grothe</surname><given-names>B</given-names></name><name><surname>Pecka</surname><given-names>M</given-names></name><name><surname>McAlpine</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Mechanisms of sound localization in mammals</article-title><source>Physiological Reviews</source><volume>90</volume><fpage>983</fpage><lpage>1012</lpage><pub-id pub-id-type="doi">10.1152/physrev.00026.2009</pub-id><pub-id pub-id-type="pmid">20664077</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Computational models of cortical visual processing</article-title><source>PNAS</source><volume>93</volume><fpage>623</fpage><lpage>627</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.2.623</pub-id><pub-id pub-id-type="pmid">8570605</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Mackey</surname><given-names>WE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Oscillatory recurrent gated neural integrator circuits (organics), a unifying theoretical framework for neural dynamics</article-title><source>PNAS</source><volume>116</volume><fpage>22783</fpage><lpage>22794</lpage><pub-id pub-id-type="doi">10.1073/pnas.1911633116</pub-id><pub-id pub-id-type="pmid">31636212</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Zemlianova</surname><given-names>KO</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A recurrent circuit implements normalization, simulating the dynamics of V1 activity</article-title><source>PNAS</source><volume>117</volume><fpage>22494</fpage><lpage>22505</lpage><pub-id pub-id-type="doi">10.1073/pnas.2005417117</pub-id><pub-id pub-id-type="pmid">32843341</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich</surname><given-names>RF</given-names></name><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Szczepanski</surname><given-names>SM</given-names></name><name><surname>Lin</surname><given-names>JJ</given-names></name><name><surname>Parvizi</surname><given-names>J</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural mechanisms of sustained attention are rhythmic</article-title><source>Neuron</source><volume>99</volume><fpage>854</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.032</pub-id><pub-id pub-id-type="pmid">30138591</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hénaff</surname><given-names>OJ</given-names></name><name><surname>Boundy-Singer</surname><given-names>ZM</given-names></name><name><surname>Meding</surname><given-names>K</given-names></name><name><surname>Ziemba</surname><given-names>CM</given-names></name><name><surname>Goris</surname><given-names>RLT</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Representation of visual uncertainty through neural gain variability</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>2513</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15533-0</pub-id><pub-id pub-id-type="pmid">32427825</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname><given-names>CA</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Spatial contextual effects in primary visual cortex limit feature representation under crowding</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>1687</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15386-7</pub-id><pub-id pub-id-type="pmid">32245941</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Higgins</surname><given-names>NC</given-names></name><name><surname>Storace</surname><given-names>DA</given-names></name><name><surname>Escabí</surname><given-names>MA</given-names></name><name><surname>Read</surname><given-names>HL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Specialization of binaural responses in ventral auditory cortices</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>14522</fpage><lpage>14532</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2561-10.2010</pub-id><pub-id pub-id-type="pmid">20980610</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kafashan</surname><given-names>M</given-names></name><name><surname>Jaffe</surname><given-names>AW</given-names></name><name><surname>Chettih</surname><given-names>SN</given-names></name><name><surname>Nogueira</surname><given-names>R</given-names></name><name><surname>Arandia-Romero</surname><given-names>I</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Scaling of sensory information in large neural populations shows signatures of information-limiting correlations</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>473</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-20722-y</pub-id><pub-id pub-id-type="pmid">33473113</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Origin of information-limiting noise correlations</article-title><source>PNAS</source><volume>112</volume><fpage>E6973</fpage><lpage>E6982</lpage><pub-id pub-id-type="doi">10.1073/pnas.1508738112</pub-id><pub-id pub-id-type="pmid">26621747</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keliris</surname><given-names>GA</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Papanikolaou</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Smirnakis</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Estimating average single-neuron visual receptive field sizes by fmri</article-title><source>PNAS</source><volume>116</volume><fpage>6425</fpage><lpage>6434</lpage><pub-id pub-id-type="doi">10.1073/pnas.1809612116</pub-id><pub-id pub-id-type="pmid">30867291</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Correlations and neuronal population information</article-title><source>Annual Review of Neuroscience</source><volume>39</volume><fpage>237</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id><pub-id pub-id-type="pmid">27145916</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>C</given-names></name><name><surname>Rohrer</surname><given-names>WH</given-names></name><name><surname>Sparks</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Population coding of saccadic eye movements by neurons in the superior colliculus</article-title><source>Nature</source><volume>332</volume><fpage>357</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1038/332357a0</pub-id><pub-id pub-id-type="pmid">3352733</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A normalization model of attentional modulation of single unit responses</article-title><source>PLOS ONE</source><volume>4</volume><elocation-id>e4651</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0004651</pub-id><pub-id pub-id-type="pmid">19247494</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lehky</surname><given-names>SR</given-names></name><name><surname>Peng</surname><given-names>X</given-names></name><name><surname>McAdams</surname><given-names>CJ</given-names></name><name><surname>Sereno</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatial modulation of primate inferotemporal responses by eye position</article-title><source>PLOS ONE</source><volume>3</volume><elocation-id>e3492</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0003492</pub-id><pub-id pub-id-type="pmid">18946508</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lima</surname><given-names>B</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>NH</given-names></name><name><surname>Neuenschwander</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Synchronization dynamics in response to plaid stimuli in monkey V1</article-title><source>Cerebral Cortex</source><volume>20</volume><fpage>1556</fpage><lpage>1573</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp218</pub-id><pub-id pub-id-type="pmid">19812238</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>B</given-names></name><name><surname>Yu</surname><given-names>CP</given-names></name><name><surname>Konkle</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mid-level visual features underlie the high-level categorical organization of the ventral stream</article-title><source>PNAS</source><volume>115</volume><fpage>E9015</fpage><lpage>E9024</lpage><pub-id pub-id-type="doi">10.1073/pnas.1719616115</pub-id><pub-id pub-id-type="pmid">30171168</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maier</surname><given-names>JX</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Comparison of gain-like properties of eye position signals in inferior colliculus versus auditory cortex of primates</article-title><source>Frontiers in Integrative Neuroscience</source><volume>4</volume><fpage>121</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.3389/fnint.2010.00121</pub-id><pub-id pub-id-type="pmid">20838470</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAlpine</surname><given-names>D</given-names></name><name><surname>Grothe</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Sound localization and delay lines -- do mammals fit the model?</article-title><source>Trends in Neurosciences</source><volume>26</volume><fpage>347</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(03)00140-1</pub-id><pub-id pub-id-type="pmid">12850430</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merriam</surname><given-names>EP</given-names></name><name><surname>Gardner</surname><given-names>JL</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Modulation of visual responses by gaze direction in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>9879</fpage><lpage>9889</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0500-12.2013</pub-id><pub-id pub-id-type="pmid">23761883</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="1956">1956</year><article-title>The magical number seven plus or minus two: some limits on our capacity for processing information</article-title><source>Psychological Review</source><volume>63</volume><fpage>81</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1037/h0043158</pub-id><pub-id pub-id-type="pmid">13310704</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milner</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>A model for visual shape recognition</article-title><source>Psychological Review</source><volume>81</volume><fpage>521</fpage><lpage>535</lpage><pub-id pub-id-type="doi">10.1037/h0037149</pub-id><pub-id pub-id-type="pmid">4445414</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Sensitivity and Specificity of a Bayesian Single Trial Analysis for Time Varying Neural Signals</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/690958</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Beck</surname><given-names>J</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Information-limiting correlations</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1410</fpage><lpage>1417</lpage><pub-id pub-id-type="doi">10.1038/nn.3807</pub-id><pub-id pub-id-type="pmid">25195105</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>AM</given-names></name><name><surname>Ray</surname><given-names>S</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Tuned normalization explains the size of attention modulations</article-title><source>Neuron</source><volume>73</volume><fpage>803</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.006</pub-id><pub-id pub-id-type="pmid">22365552</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>AM</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatially tuned normalization explains attention modulation variance within neurons</article-title><source>Journal of Neurophysiology</source><volume>118</volume><fpage>1903</fpage><lpage>1913</lpage><pub-id pub-id-type="doi">10.1152/jn.00218.2017</pub-id><pub-id pub-id-type="pmid">28701536</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>A.M</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuronal effects of spatial and feature attention differ due to normalization</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>5493</fpage><lpage>5505</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2106-18.2019</pub-id><pub-id pub-id-type="pmid">31068439</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nogueira</surname><given-names>R</given-names></name><name><surname>Peltier</surname><given-names>NE</given-names></name><name><surname>Anzai</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Martínez-Trujillo</surname><given-names>J</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The effects of population tuning and trial-by-trial variability on information encoding and behavior</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>1066</fpage><lpage>1083</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0859-19.2019</pub-id><pub-id pub-id-type="pmid">31754013</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palanca</surname><given-names>BJA</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Does neuronal synchrony underlie visual feature grouping?</article-title><source>Neuron</source><volume>46</volume><fpage>333</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.03.002</pub-id><pub-id pub-id-type="pmid">15848810</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porter</surname><given-names>KK</given-names></name><name><surname>Metzger</surname><given-names>RR</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Representation of eye position in primate inferior colliculus</article-title><source>Journal of Neurophysiology</source><volume>95</volume><fpage>1826</fpage><lpage>1842</lpage><pub-id pub-id-type="doi">10.1152/jn.00857.2005</pub-id><pub-id pub-id-type="pmid">16221747</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porter</surname><given-names>KK</given-names></name><name><surname>Metzger</surname><given-names>RR</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Visual- and saccade-related signals in the primate inferior colliculus</article-title><source>PNAS</source><volume>104</volume><fpage>17855</fpage><lpage>17860</lpage><pub-id pub-id-type="doi">10.1073/pnas.0706249104</pub-id><pub-id pub-id-type="pmid">17978183</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>JH</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The normalization model of attention</article-title><source>Neuron</source><volume>61</volume><fpage>168</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.002</pub-id><pub-id pub-id-type="pmid">19186161</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodman</surname><given-names>HR</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Single-Unit analysis of pattern-motion selective properties in the middle temporal visual area (MT)</article-title><source>Experimental Brain Research</source><volume>75</volume><fpage>53</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1007/BF00248530</pub-id><pub-id pub-id-type="pmid">2707356</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Hernández</surname><given-names>A</given-names></name><name><surname>Zainos</surname><given-names>A</given-names></name><name><surname>Salinas</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Correlated neuronal discharges that increase coding efficiency during perceptual discrimination</article-title><source>Neuron</source><volume>38</volume><fpage>649</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(03)00287-3</pub-id><pub-id pub-id-type="pmid">12765615</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Alberts</surname><given-names>JJ</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relating normalization to neuronal populations across cortical areas</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>1375</fpage><lpage>1386</lpage><pub-id pub-id-type="doi">10.1152/jn.00017.2016</pub-id><pub-id pub-id-type="pmid">27358313</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Attention increases spike count correlations between visual cortical areas</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>7523</fpage><lpage>7534</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0610-16.2016</pub-id><pub-id pub-id-type="pmid">27413161</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Noise, neural codes and cortical organization</article-title><source>Current Opinion in Neurobiology</source><volume>4</volume><fpage>569</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1016/0959-4388(94)90059-0</pub-id><pub-id pub-id-type="pmid">7812147</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Gray</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Visual feature integration and the temporal correlation hypothesis</article-title><source>Annual Review of Neuroscience</source><volume>18</volume><fpage>555</fpage><lpage>586</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.18.030195.003011</pub-id><pub-id pub-id-type="pmid">7605074</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanrullen</surname><given-names>R</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Drewes</surname><given-names>J</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ongoing EEG phase as a trial-by-trial predictor of perceptual and attentional variability</article-title><source>Frontiers in Psychology</source><volume>2</volume><elocation-id>60</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2011.00060</pub-id><pub-id pub-id-type="pmid">21716580</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verhoef</surname><given-names>BE</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attention-related changes in correlated neuronal activity arise from normalization mechanisms</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>969</fpage><lpage>977</lpage><pub-id pub-id-type="doi">10.1038/nn.4572</pub-id><pub-id pub-id-type="pmid">28553943</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Von Der Malsburg</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1994">1994</year><chapter-title>The correlation theory of brain function</chapter-title><source>Models of Neural Networks</source><publisher-name>Springer</publisher-name><fpage>95</fpage><lpage>119</lpage></element-citation></ref><ref id="bib73"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Weiss</surname><given-names>O</given-names></name><name><surname>Bounds</surname><given-names>HA</given-names></name><name><surname>Adesnik</surname><given-names>H</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Modeling the Diverse Effects of Divisive Normalization on Noise Correlations</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.06.08.495145</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werner-Reiss</surname><given-names>U</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A rate code for sound azimuth in monkey auditory cortex: implications for human neuroimaging studies</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>3747</fpage><lpage>3758</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5044-07.2008</pub-id><pub-id pub-id-type="pmid">18385333</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitney</surname><given-names>D</given-names></name><name><surname>Levi</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Visual crowding: a fundamental limit on conscious perception and object recognition</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>160</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.02.005</pub-id><pub-id pub-id-type="pmid">21420894</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willett</surname><given-names>SM</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Multiple sounds degrade the frequency representation in monkey inferior colliculus</article-title><source>The European Journal of Neuroscience</source><volume>55</volume><fpage>528</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1111/ejn.15545</pub-id><pub-id pub-id-type="pmid">34844286</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woods</surname><given-names>TM</given-names></name><name><surname>Su</surname><given-names>TK</given-names></name><name><surname>Recanzone</surname><given-names>GH</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Spatial tuning as a function of stimulus intensity of single neurons in awake macaque monkey auditory cortex</article-title><source>Soc Neurosci Abstr</source><volume>27</volume><fpage>512</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.83.4.2315</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>J</given-names></name><name><surname>Niu</surname><given-names>YQ</given-names></name><name><surname>Wiesner</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Normalization of neuronal responses in cortical area MT across signal strengths and motion directions</article-title><source>Journal of Neurophysiology</source><volume>112</volume><fpage>1291</fpage><lpage>1306</lpage><pub-id pub-id-type="doi">10.1152/jn.00700.2013</pub-id><pub-id pub-id-type="pmid">24899674</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distributed and dynamic neural encoding of multiple motion directions of transparently moving stimuli in cortical area MT</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>16180</fpage><lpage>16198</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2175-15.2015</pub-id><pub-id pub-id-type="pmid">26658869</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>D</given-names></name><name><surname>Yeh</surname><given-names>CI</given-names></name><name><surname>Shapley</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial spread of the local field potential and its laminar variation in visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>11540</fpage><lpage>11549</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2573-09.2009</pub-id><pub-id pub-id-type="pmid">19759301</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zohary</surname><given-names>E</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title><source>Nature</source><volume>370</volume><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1038/370140a0</pub-id><pub-id pub-id-type="pmid">8022482</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76452.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ray</surname><given-names>Supratim</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dese585</institution-id><institution>Indian Institute of Science Bangalore</institution></institution-wrap><country>India</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/777912" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/777912"/></front-stub><body><p>The authors report that neurons in V1 and V4 multiplex information of simultaneously presented objects. A combination of multi-single unit recordings, statistical modelling of neuronal responses and neuronal correlations analyses argues in favor of their claims. Pairs of neurons having similar object preferences tended to be positively correlated when both objects were presented, while pairs of neurons having different object preferences tended to be negatively correlated and these patterns and others suggest that information about the two objects is multiplexed in time. These results are of broad interest to the field, as they shed new light on the &quot;binding&quot; problem and highlight the importance of underexplored features of cortical activity for neural coding.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76452.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ray</surname><given-names>Supratim</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dese585</institution-id><institution>Indian Institute of Science Bangalore</institution></institution-wrap><country>India</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Coen-Cagli</surname><given-names>Ruben</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05cf8a891</institution-id><institution>Albert Einstein College of Medicine</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/777912">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/777912v5">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Coordinated multiplexing of information about separate objects in visual cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Joshua Gold as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Ruben Coen-Cagli (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>While this paper shows some intriguing results, we feel that there are a lot of open questions that need to be addressed before convincing evidence of multiplexing can be established. These points are discussed below:</p><p>1. The best spike count model shown in Figure 2C is confusing. It seems that the number of &quot;conditions&quot; is a small fraction of the total number of conditions (and neurons?) that were tested. Supplementary Figure 1 provides more details (for example, the &quot;mixture&quot; corresponds to only 14% of total cases), but it is still confusing (for example, what does WinProb&gt;Min mean?). From what I understood, the total number of neurons recorded for the Adjacent case in V1 is 1604, out of which 935 are Poisson-like with substantially separated means. Each one has 2 conditions (for the two directions), leading to 1870 conditions (perhaps a few less in case both conditions were not available). I think the authors should show 5 bar plots – the first one showing the fraction for which none of the models won by 2/3 probability, and then the remaining 4 ones. That way it is clear how many of the total cases show the &quot;multiplexing&quot; effect. I also think that it would be good to only consider neurons/conditions for which at least some minimum number of trials are available (a cutoff of say ~15) since the whole point is about finding a bimodal distribution for which enough trials are needed.</p><p>2. More RF details need to be provided. What was the size of the V1 RFs? What was the eccentricity? Typically, the RF diameter in V1 at an eccentricity of ~3 degrees is no more than 1 degree. It is not enough to put 2 Gabors of size 1 degree each to fit inside the RF. How close were the Gabors? We are confused about the statement in the second paragraph of page 9 &quot;typically only one of the two adjacent gratings was located within the RF&quot; – we thought the whole point of multiplexing is that when both stimuli (A and B) are within the RF, the neuron nonetheless fires like A or B? The analysis should only be conducted for neurons for which both stimuli are inside the RF. When studying noise correlations, only pairs that have overlapping RFs such as both A and B and within the RFs of both neurons should be considered. The cortical magnification factor at ~3-degree eccentricity is 2-2.5mm/degree, so we expect the RF center to shift by at least 2 degrees from one end of the array to the other.</p><p>3. Eye data analysis: the reviewers are concerned that this could potentially be a big confound. Removing trials that had microsaccades is not enough. Typically, in these tasks the fixation window is 1.5-2 degrees, so that if the monkey fixates on one corner in some trials and another corner in other trials (without making any microsaccades in either), the stimuli may nonetheless fall inside or away from the RFs, leading to differences in responses. This needs to be ruled out. We do not find the argument presented on pages 18 or 23 completely convincing, since the eye positions could be different for a single stimulus versus when both stimuli are presented. It is important to show that the eye positions are similar in &quot;AB&quot; trials for which the responses are &quot;A&quot; like versus &quot;B&quot; like, and these, in turn, are similar to when &quot;A&quot; and &quot;B&quot; are presented alone.</p><p>Relatedly, more details on the detection of microsaccades and threshold values for inclusion (relative to stimulus and RF sizes) should be provided, given how central a role they might play. In particular, the authors state in Discussion that small residual eye movements would inflate response variability in all stimulus conditions. This is correct, but because of the stimulus design, it is possible (likely?) that the effects are quite different for segregated stimuli versus superimposed and single-stimulus conditions. Furthermore, the difference might be precisely in the direction of the effects reported. That is because segregated stimuli are spatially separate, and each stimulus only covers some receptive fields in the recording, it is possible that eye movements would bring inside the RF a different stimulus in each trial. In addition to producing bimodal response distributions for individual neurons, this would also induce positive correlations for pairs with the same preference and negative correlations for pairs with opposite preferences. On the other hand, in the superimposed condition where the stimulus is large enough to cover all RFs, at most eye movements would bring (part of) the stimulus inside versus outside the RF across trials, therefore contributing to positive noise correlations for all pairs (i.e., to shifts from stimulus-driven to spontaneous activity, in the extreme case). In our opinion, the main concern raised in the public review deserves more in-depth analysis, of the data and/or simulations, for us to be convinced that eye movements truly do not play a role. Conversely, if they do, it may be worth discussing the possibility that they are part of the mechanism underlying the proposed coding scheme.</p><p>4. Figures 5 and 6 show that the difference in noise correlations between the same preference and different preference neurons remains even for non-mixture type neurons. So, although the reason for the particular type of noise correlation was given for multiplexing neurons (Figure 3 and 4), it seems that the same pattern holds even for non-multiplexers. Although the absolute values are somewhat different across categories, one confound that still remains is that the noise correlations are typically dependent on signal correlation, but here the signal correlation is not computed (only responses to 2 stimuli are available). If there is any tuning data available for these recordings, it would be great to look at the noise correlations as a function of signal correlations for these different pairs. Another analysis of interest would be to check whether the difference in the noise correlation for simply &quot;A&quot;/&quot;B&quot; versus &quot;AB&quot; varies according to neuron pair category. Finally, since the authors mention in the Discussion that &quot;correlations did not depend on whether the two units preferred the same stimulus or different&quot;, it would be nice to explicitly show that in figure 5C by showing the orange trace (&quot;A&quot; alone or &quot;B&quot; alone) for both same (green) and different (brown) pairs separately.</p><p>5.We are confused about the nature of Poisson models. If we are correct, the Poisson(a+b) is the sum of the two Poisson(a) and Poisson(b), that is, Poisson(a+b) = Poisson(a) + Poisson(b). Then, the mixture and intermediate models are very similar, identical if a*λ_A and (1-a)*λ_B happen to be integer numbers.</p><p>6. It is unclear why the 'outside' model predicts responses outside the range if neurons were to linearly sum the A and B responses.</p><p>7. It is also unclear why the 'single' hypothesis would indicate a winner-take-all response. If we understand correctly, under this model, the response to A+B is either the rate A or B, but not the max between λ_A and λ_B. Also, this model could have given an extra free parameter to modulate its amplitude to the stimulus A+B.</p><p>8. The concept of &quot;coarse population coding&quot; can be misleading, as actual population coding can represent stimulus with quite good precision. The authors refer to the broad tuning of single cells, but this does not readily correspond to coarse population coding. This could be clarified.</p><p>9. As a complement to the correlation analysis, one could check whether, on a trial-by-trial basis, the neuronal response of a single neuron is closer to the A+B response average, or to either the A or B responses. This would clearly indicate that the response fluctuates between representing A or B, or simultaneously represents A+B. I am trying to understand why this is not one of the main analyses of the paper instead of the correlation analysis, which involves two neurons instead of one.</p><p>10. In the discussion about noise correlations, the recent papers Nogueira et al., J Neuroscience, 2020 and Kafashan et al., Nat Comm, 2021 could be cited. Also, noise correlations can also be made time-dependent, so the distinction between the temporal correlation hypotheses and noise correlations might not be fundamental.</p><p>11. It would be interesting to study the effect of contrast on the mixed responses. Is it reasonable to predict that with higher contrast the mixture responses would be more dominant than the single ones? This could be the case if the selection mechanism has a harder time suppressing one of the object responses. This would also predict that noise correlations will go down with higher contrast.</p><p>12. What is the time bin size used for the analysis? Would the results be the same if one focuses on the early time responses or on the late time responses? At least from the units shown in Figure 2, it looks that there is always an object response that is delayed respect to the other, so it would seem interesting to test noise correlations in those two temporal windows.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Coordinated multiplexing of information about separate objects in visual cortex&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Joshua Gold (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved and many of the reviewers' concerns have been addressed. However, some major issues remain. Although we typically avoid repeated revise/resubmit cycles, we believe that it is important for these issues to be addressed in a new revision. Specifically, upon discussion the reviewers unanimously remained concerned about the possibility that at least some of your results could be accounted for by subtle differences in eye movements. The new analyses related to that issue were appreciated but considered inadequate.</p><p>As detailed below, we would like you to provide:</p><p>1. More information about whether the electrodes that show evidence of multiplexing are the ones whose RF straddles the two stimuli, because in that case, small eye movements will bring one of the two stimuli inside the RF.</p><p>2. Further analyses of eye position to rule out the possibility described above. In our discussions, it was noted that the new Figure 1 – Supplementary Figure 1 appears to show that numerous V1 RFs straddle the two stimuli, and under those conditions, we really want to know if the &quot;multiplexed&quot; responses are because of small fixational differences/microsaccades that affect which of the two stimuli takes a more dominant position in the RF. To test for this kind of effect, just the STD of eye position per trial for one-stimulus vs two-stimuli conditions does not seem to be sufficient. Instead, it seems important to know whether, in the two-stimuli condition, responses were more &quot;A-like&quot; when gaze put the A stimulus closer to the RF center, and were more &quot;B-like&quot; when gaze put the B stimulus closer to the RF center. So something like a linear regression of spiking response versus &quot;eye position along the axis defined by the centers of the two stimuli, increasing towards the stimulus that alone elicited the larger response&quot; could be useful.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>The authors have made several changes in the manuscript to address previous concerns. However, the fact that typically only one stimulus spanned the RF makes it difficult to make a case for multiplexing, since the other stimulus is outside the classical RF. The arguments made by the authors in response to the previous RF-related question (point 2) are based on their own hypothesis about some underlying &quot;spatial scale&quot; of multiplexing which is coarser than the RF size of V1, which I do not find particularly convincing and would be extremely difficult to implement in V1. Further, while the authors showed more results related to eye position analysis, they do not show the key comparison that was requested previously.</p><p>To better appreciate the spatial scales involved, I refer to figures from the following two studies in V1 where very small stimuli (0.1 – 0.2 degrees) were used to map the RFs: Figure 2 of Xing et al., 2009, JNS, and Figure 2 of Dubey and Ray, 2016, JNP. Typically, the SD of fitted Gaussian is typically no more than 0.25 degrees at an eccentricity of 2-3 degrees (if you consider the radius as 2SD (0.5 degrees), the diameter is about a degree). For such RFs, there is no response if a stimulus is more than a degree away from the RF. For Gabor patches used in this paper, only the &quot;size&quot; is mentioned. Does size refer to the radius or SD? In either case, there is no way to fit two Gabors within the RF. What is the separation between two Gabors? Figure 1 should highlight all these details, including the radius (not just the center) of the V1 units.</p><p>Given the concern that one of the stimuli is always outside the RF, how do we explain the findings? One possible answer is in small differences in eye position. Multiplexing is anyway observed in only ~100 out of 1389 units. I suspect these are the units whose RF center is between the two stimuli. For the AB condition (i.e., both stimuli are presented), small jitters in eye position would bring one of the two stimuli in the RF, and therefore the unit would respond like either A or B. To address this, the authors should show the RF centers of the units that show evidence of multiplexing, along with the stimuli.</p><p>In addition, it is important to check for possible differences in eye position within AB conditions for trials for which responses were &quot;A like&quot; versus &quot;B like&quot;. The authors have compared the AB condition to A and B conditions presented alone, but that is not enough. The argument that the stimuli were presented for a short duration and in pseudorandom order and therefore it is not possible for the animal to have systematically different eye positions for A/B versus AB conditions is obviously true, but that is not the point. The point is that the eye positions have small variations from trial to trial (as shown in Figure 1 – Supp 2) even before stimulus onset, and AB trials in which the position happens to be in one location get classified as &quot;A like&quot; and another location gets classified as &quot;B like&quot;. It is in fact very hard to rule out this possibility given the instrument noise which affects the precision of eye positions, but it is crucial to rule this out.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The authors have appropriately addressed all comments. In particular, the controls on eye movements are sound.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>The authors have addressed my concerns and all other concerns raised in the editor's summary. My main concern was whether uncontrolled fixational eye movements (microsaccades) could account in part for the observed multiplexing. I understand now that concern was largely because of missing details about eye position, RF sizes, stimulus sizes, etc, which are now reported. The possibility remains that trial-by-changes in eye position (within the fixation window) would inflate the proportion of single-neuron &quot;mixture&quot; cases for adjacent two-object stimuli (by effectively changing which object is inside the RF in any given trial). But, importantly, this could not explain the observed patterns of noise correlations.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Coordinated multiplexing of information about separate objects in visual cortex&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Joshua Gold (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed. We realized we were not as specific as we should have been in the last round of feedback and have tried to clarify here exactly what the reviewers are looking for.</p><p>In particular, because the authors claim that ~100 electrodes have mixture responses, the possible influence of eye movements should be tested for all the mixture units, not only 9/100 as done in the previous review. We would therefore like the analyses done for all the mixtures. To avoid ambiguity, we are listing the requested analyses in more detail below:</p><p>1. Show the RF centers of ALL the units labeled as mixtures (~100). The best way to do this would be to make a line passing through the centers of the two stimuli, and make five groups of units depending on their RF centers – (i) left of the left stimulus, (ii) on the left stimulus, (iii), between left and right stimulus, (iv) on the right stimulus and (v) right of the right stimulus. Then show what proportion of units in each category are mixtures. The eye movement hypothesis predicts that mixtures will be predominant in (iii). Actually, since 91/100 units have one of the two modes at zero (as far as I could understand the previous analysis), these units could even be at (i) or (v).</p><p>2. Do the eye position analysis for ALL mixture units. Since the stimuli are mainly separated along the x-axis, all we are asking is to make a scatter plot of spike counts and average eyeX position for each trial and then check for correlation between the two. This analysis is valid even for units that only respond to one stimulus (i.e. the remaining 91 units). We expect to find a significant correlation (either positive or negative) if the results are due to small eye movements, but not if the firing is due to their multiplexing hypothesis. Or, if you find significant correlations since the RF sizes are comparable to the stimulus sizes, you need to show that these correlations are insufficient to explain the bimodality.</p><p>3. In addition, I think the authors should at least show the typical RF radius of the units (make a circle of radius of 0.5 degrees on a few of the units, perhaps the ones shown in Figure 4). We think it is important to show that the RFs do not encompass both stimuli, which is not clear from the plots.</p><p>4. The fact that one mode of the bimodal distribution is zero in 91/100 cases should also be made clearer, perhaps in the methods section. Essentially the bimodal response in most cases is not A versus B, but A/B versus zero.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76452.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>While this paper shows some intriguing results, we feel that there are a lot of open questions that need to be addressed before convincing evidence of multiplexing can be established. These points are discussed below:</p><p>1. The best spike count model shown in Figure 2C is confusing. It seems that the number of &quot;conditions&quot; is a small fraction of the total number of conditions (and neurons?) that were tested. Supplementary Figure 1 provides more details (for example, the &quot;mixture&quot; corresponds to only 14% of total cases), but it is still confusing (for example, what does WinProb&gt;Min mean?). From what I understood, the total number of neurons recorded for the Adjacent case in V1 is 1604, out of which 935 are Poisson-like with substantially separated means. Each one has 2 conditions (for the two directions), leading to 1870 conditions (perhaps a few less in case both conditions were not available). I think the authors should show 5 bar plots – the first one showing the fraction for which none of the models won by 2/3 probability, and then the remaining 4 ones. That way it is clear how many of the total cases show the &quot;multiplexing&quot; effect. I also think that it would be good to only consider neurons/conditions for which at least some minimum number of trials are available (a cutoff of say ~15) since the whole point is about finding a bimodal distribution for which enough trials are needed.</p></disp-quote><p>We thank you for catching this confusion. We have revised Figure 2C as requested, modified Supplementary Figure 1 (now Figure 2 – Supp Figure 1) to be more clear, and improved Table 1 and its legend to more succinctly walk the reader through the numbers of included conditions and how many units and distinct sessions they concern. We have also added a Table 2 to provide the trial counts, which exceed the criteria we have previously benchmarked and used (Mohl et al 2020; Caruso et al., 2018).</p><p>Details:</p><p>We first explain the changes to Table 1. The most important column is the last one; this column provides the total numbers of conditions (“Triplets”) that passed the Poisson and good response-separation criteria for inclusion in the analyses. The remaining columns illustrate how many units and sessions these included triplets came from. For example, in the adjacent data set in V1, there were 16 sessions; all 16 sessions yielded data that was included. There were 1604 units of which 935 yielded data that was included. We’ve re-written the legend to better explain this.</p><p>Note: if the reviewers feel it would be beneficial to simplify, we could easily delete the “Available sessions” and “Available units” columns, and just report the number of sessions and units that were actually used.</p><p>Regarding “the total number of neurons recorded for the Adjacent case in V1 is 1604, out of which 935 are Poisson-like with substantially separated means. Each one has 2 conditions (for the two directions), leading to 1870 conditions” – this is not quite correct, but it was a very helpful explanation of how we had confused the matter. To summarize the Adjacent case in V1, 935 units provided triplets, 1-2 each, yielding a total of 1389.</p><p>For Figure 2C (now 2C and D), “I think the authors should show 5 bar plots - the first one showing the fraction for which none of the models won by 2/3 probability, and then the remaining 4 ones.”, we have included a pie chart to complement the bar chart to illustrate the total number of conditions involved.</p><p>For Supplementary Figure 1 <italic>“what does WinProb&gt;Min mean”,</italic> that refers to the lowest possible winning probability. We used a flat prior, i.e. each model starts off with a 0.25 probability of being the best model. We have modified this figure (now Figure 2 – Supplementary Figure 1) to replace “WinProb&gt;Min” with “WinProb&gt;0.25”.</p><p>Regarding “I also think that it would be good to only consider neurons/conditions for which at least some minimum number of trials are available (a cutoff of say ~15) since the whole point is about finding a bimodal distribution for which enough trials are needed”, we think we are in good shape on this front, but we agree we had not documented this. Accordingly, we now include Table 2 which is accompanied by following text in the Methods section: “The numbers of trials involved for the different data sets are provided in Table 2. The trial counts were adequate to provide accurate model identification according to our previous simulations. Depending on the separation between λA and λB, we previously found that model identification accuracy in simulations is high for trial counts as low as 5 “AB” trials, and plateaus near ceiling around “AB” trial counts of about 10 trials and above – i.e. below the mean trial counts available here for all datasets (see Figure 4 of Mohl et al., 2020).”</p><p>The relevant figure supporting this point is Figure 4 from Mohl et al. (2020).</p><p>Mohl JT, Caruso VC, Tokdar S, Groh JM (2020) Sensitivity and specificity of a Bayesian single trial analysis for time varying neural signals. Neurons, Theory, Data Analysis, and Behavior.</p><disp-quote content-type="editor-comment"><p>2. More RF details need to be provided. What was the size of the V1 RFs? What was the eccentricity? Typically, the RF diameter in V1 at an eccentricity of ~3 degrees is no more than 1 degree. It is not enough to put 2 Gabors of size 1 degree each to fit inside the RF. How close were the Gabors? We are confused about the statement in the second paragraph of page 9 &quot;typically only one of the two adjacent gratings was located within the RF&quot; – we thought the whole point of multiplexing is that when both stimuli (A and B) are within the RF, the neuron nonetheless fires like A or B? The analysis should only be conducted for neurons for which both stimuli are inside the RF. When studying noise correlations, only pairs that have overlapping RFs such as both A and B and within the RFs of both neurons should be considered. The cortical magnification factor at ~3-degree eccentricity is 2-2.5mm/degree, so we expect the RF center to shift by at least 2 degrees from one end of the array to the other.</p></disp-quote><p>We now provide the requested details regarding stimulus size and receptive field locations in the Methods. But before summarizing those results, we would like to clarify a conceptual point: while our study is motivated by the observation that tuning in sensory structures is coarse relative to our perceptual capabilities, we did not mean to limit this consideration to the spatial scale of V1 neurons specifically. Rather, we see this as an overall problem across sensory pathways. For example, even if two particular stimuli activate completely separate populations in V1, this may not be the case at later stages of processing such as IT cortex where receptive fields are quite large. We believe the brain has to solve this problem at the scale of the entire sensory processing stream, and It must do so without prior knowledge of the particular spacing of particular individual stimuli.</p><p>That said, we agree that it could well have turned out that fluctuating activity might only be evident when two stimuli were within the same receptive fields of individual neurons in a particular brain area. However, this did not turn out to be the case. Many of the units in the present study only had one stimulus in the receptive field, yet a subset showed evidence of fluctuating response patterns.</p><p>Perhaps we would have observed <italic>more</italic> evidence for multiplexing if both stimuli were in the receptive field. Indeed, in our previous study involving the inferior colliculus and inferotemporal cortex (Caruso et al 2018), we observed a higher incidence of multiplexing than in the current study. In the IC, spatial tuning is very broad (sound location is rate coded in the mammalian brain), so in general most neurons responded to both sounds. We are currently working on a followup study in which we are parametrically varying the frequency of the two sounds to smoothly vary the response differences between the A and B stimuli. In this new study, we find that multiplexing is indeed more prevalent when the two stimuli are both in the frequency response area of the neuron than when only one stimulus is. So the fact that in general only one stimulus drove the units in the current study may well have limited the evidence for multiplexing in the current dataset.</p><p>Changes made: We have modified the language in the introduction to describe the rationale more carefully, so as not to imply that multiplexing need only occur in cases where the two stimuli are within the same receptive field of the neurons under study in a particular brain area. Rather, multiplexing is likely to have some as yet unknown characteristic spatial scale that may be determined by the coarsest tuning evident at any stage in the sensory pathway. We also now return to this topic in the Discussion to specifically clarify our interpretation regarding this issue. We have future experiments planned in which we will systematically vary the locations of the stimuli involved, so we expect to have data to address this issue in the future.</p><p>Key changes in the introduction: The sentence “Such breadth of tuning means that individual neurons will commonly experience more than one stimulus to which they could in principle respond, making it unclear how information about multiple objects is preserved.” has been rewritten as: “Such breadth of tuning means that there will be overlap in the population of neurons activated by individual stimuli, making it unclear how information about multiple objects is preserved.” This shifts the meaning to focus on the (implied) population overlap rather than the receptive fields of the particular individual neurons we studied.</p><p>Key changes in the Methods: The requested information regarding receptive fields and stimulus locations is provided in the Methods section under “Electrophysiological recordings and visual stimuli”: “…we analyzed trials in which attention was directed to a Gabor patch located in the hemisphere ipsilateral to the recorded V1 neurons (i.e. well away from those neurons’ receptive fields, see below). On these trials, two unattended Gabor patches were presented in close proximity to each other within the area covered by the receptive fields of the recorded V1 neurons – these receptive fields were approximately 3 degrees eccentric and had classical receptive field diameters typically estimated to be &lt;1 degree of visual angle. These patches were centered 2.5-3.5 degrees eccentrically and each stimulus typically subtended 1 degree of visual angle (see Ruff and Cohen 2016 Figure 1B for a sketch, reproduced here in Figure 1 – Supplementary Figure 1)…”</p><p>Key changes in the Discussion: We inserted a new paragraph that reads “It is interesting to note that we observed evidence of multiplexing each stimulus even in V1 where there receptive fields are small and the stimuli we used did not themselves typically span more than one receptive field – thus the coarseness of tuning did not necessarily pose a problem for the encoding of these particular stimuli in this particular brain area. However, the precision of V1’s spatial code may not be the limiting factor.</p><p>Multiplexing is likely to have some as yet unknown characteristic spatial scale that may be determined by the coarsest tuning evident at any stage in the sensory pathway. Future work in which stimuli are systematically varied to manipulate the amount of overlap in the activity patterns evoked in different brain areas by each stimulus alone are needed to answer this question. “</p><disp-quote content-type="editor-comment"><p>3. Eye data analysis: the reviewers are concerned that this could potentially be a big confound. Removing trials that had microsaccades is not enough. Typically, in these tasks the fixation window is 1.5-2 degrees, so that if the monkey fixates on one corner in some trials and another corner in other trials (without making any microsaccades in either), the stimuli may nonetheless fall inside or away from the RFs, leading to differences in responses. This needs to be ruled out. We do not find the argument presented on pages 18 or 23 completely convincing, since the eye positions could be different for a single stimulus versus when both stimuli are presented. It is important to show that the eye positions are similar in &quot;AB&quot; trials for which the responses are &quot;A&quot; like versus &quot;B&quot; like, and these, in turn, are similar to when &quot;A&quot; and &quot;B&quot; are presented alone.</p><p>Relatedly, more details on the detection of microsaccades and threshold values for inclusion (relative to stimulus and RF sizes) should be provided, given how central a role they might play. In particular, the authors state in Discussion that small residual eye movements would inflate response variability in all stimulus conditions. This is correct, but because of the stimulus design, it is possible (likely?) that the effects are quite different for segregated stimuli versus superimposed and single-stimulus conditions. Furthermore, the difference might be precisely in the direction of the effects reported. That is because segregated stimuli are spatially separate, and each stimulus only covers some receptive fields in the recording, it is possible that eye movements would bring inside the RF a different stimulus in each trial. In addition to producing bimodal response distributions for individual neurons, this would also induce positive correlations for pairs with the same preference and negative correlations for pairs with opposite preferences. On the other hand, in the superimposed condition where the stimulus is large enough to cover all RFs, at most eye movements would bring (part of) the stimulus inside versus outside the RF across trials, therefore contributing to positive noise correlations for all pairs (i.e., to shifts from stimulus-driven to spontaneous activity, in the extreme case). In our opinion, the main concern raised in the public review deserves more in-depth analysis, of the data and/or simulations, for us to be convinced that eye movements truly do not play a role. Conversely, if they do, it may be worth discussing the possibility that they are part of the mechanism underlying the proposed coding scheme.</p></disp-quote><p>We appreciate the reviewers raising these concerns, which we now address more fully in the manuscript with a combination of new data analysis, additional methodological details, and more fully fleshed-out reasoning. The key points are as follows:</p><p>(a) Eye position did not differ during the A/B vs. AB stimulus presentations. See new Figure 1 -Supplementary Figure 2 in the manuscript, and included below. This is the simplest answer to the above questions, but lest any concerns remain, read on:</p><p>(b) The timing doesn’t work for variation in eye position to pose a substantial confound. The A/B/AB stimuli are delivered in pseudorandom order, so it was not possible for the animals to anticipate which stimulus would appear; thus pre-stimulus eye position effects are not a possibility. And there isn’t time for post-stimulus eye position effects to have a meaningful influence during the short spike counting window we used – 200 ms after stimulus onset. It typically takes 150-350 ms for visual stimuli to elicit a macrosaccade; a similar latency is likely involved for any potential stimulus-influenced modulation of fixational eye movements (Engbert and Kliegl, 2003). Because we only analyzed a 200 ms spike counting temporal epoch, even if stimuli were to differentially modulate the position of the eyes within the fixation window, there is very little time for such modulation to affect the spikes we counted.</p><p>(Note – any saccades directed to one or the other targets would of course be excluded as incorrect trials, but we understood the concern to relate to any more subtle tendencies to <italic>fixate</italic> differently based on the stimulus conditions.)</p><p>(c) Given that there was no difference in eye position between conditions in the adjacent stimuli data sets, we believe it is beyond the scope of this paper to conduct this analysis for the superimposed stimuli datasets as the lack of an effect in the adjacent dataset is sufficient to eliminate this as a candidate explanation for our findings.</p><p>(d) Details regarding microsaccade detection, RF sizes, stimulus sizes, and fixation windows are now included as described above. We apologize for omitting these details. To recap for the adjacent V1 dataset:</p><p>Fixation windows were +/- 0.5 degrees.</p><p>RF sizes: typically less than 1 degree</p><p>Stimulus sizes: typically 1 degree, about 2.5-3.5 eccentric</p><p>Microsaccade detection criteria: stimulus presentations in which eye velocity ever exceed six standard deviations from the mean eye velocity during fixation were excluded from further analysis, following the method of Engbert and Kliegl, 2003.</p><p>(f) Regarding “this would also induce positive correlations for pairs with the same preference and negative correlations for pairs with opposite preferences”, we respectfully disagree. This would only be the case if the receptive fields of the neurons with the same preferences were truly precisely aligned in space, as opposed to merely overlapping. As shown in Ruff and Cohen 2016 Figure 1B, and now illustrated in our Figure 1 – Supplementary Figure 1, this was not the case. The logic is most easily conveyed in <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>:</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>This schematic focuses on the “congruent” situation, assuming these involve neurons with adjacentreceptive fields.</title><p>Even within this group, variation in eye position would create both positive and negative correlations, and would not be expected to selectively impact dual stimulus trials or congruent vs incongruent pairs of neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-sa2-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>4. Figures 5 and 6 show that the difference in noise correlations between the same preference and different preference neurons remains even for non-mixture type neurons. So, although the reason for the particular type of noise correlation was given for multiplexing neurons (Figure 3 and 4), it seems that the same pattern holds even for non-multiplexers. Although the absolute values are somewhat different across categories, one confound that still remains is that the noise correlations are typically dependent on signal correlation, but here the signal correlation is not computed (only responses to 2 stimuli are available). If there is any tuning data available for these recordings, it would be great to look at the noise correlations as a function of signal correlations for these different pairs. Another analysis of interest would be to check whether the difference in the noise correlation for simply &quot;A&quot;/&quot;B&quot; versus &quot;AB&quot; varies according to neuron pair category. Finally, since the authors mention in the Discussion that &quot;correlations did not depend on whether the two units preferred the same stimulus or different&quot;, it would be nice to explicitly show that in figure 5C by showing the orange trace (&quot;A&quot; alone or &quot;B&quot; alone) for both same (green) and different (brown) pairs separately.</p></disp-quote><p>We thank you for this interesting suggestion. We have conducted the desired analysis (see <xref ref-type="table" rid="sa2table1">Author response table 1</xref>). The basic conclusions have not changed as described below.</p><table-wrap id="sa2table1" position="float"><label>Author response table 1.</label><caption><title>Median spike count correlations for additional subgroups of the V1 adjacent stimuli dataset.</title><p>The top two rows show the median spike count correlations observed for dual stimuli for various types of pairs of units, and correspond to the data shown in figures 4 and 5 in the main text (first two rows). The next three rows show the same analyses conducted for trials involving single stimuli. Here, the “congruent” group was subdivided according to whether the presented stimulus was the one that elicited the stronger response (“driven”) or the weaker one (“not driven”). The bottom two rows show the differences in the medians observed for the relevant congruent and incongruent groups (lines 1 minus 2 and lines 3 minus 5)</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>All</th><th>Mixture-Mixture pairs</th><th>Intermediate-Intermediate pairs</th><th>Single-Single pairs</th></tr></thead><tbody><tr><td align="left" valign="top">Congruent AB</td><td align="left" valign="top">0.252</td><td align="left" valign="top">0.486</td><td align="left" valign="top">0.263</td><td align="left" valign="top">0.233</td></tr><tr><td align="left" valign="top">Incongruent AB</td><td align="left" valign="top">-0.052</td><td align="left" valign="top">-0.140</td><td align="left" valign="top">-0.009</td><td align="left" valign="top">-0.032</td></tr><tr><td align="left" valign="top">Congruent driven A or B</td><td align="left" valign="top">0.251</td><td align="left" valign="top">0.384</td><td align="left" valign="top">0.266</td><td align="left" valign="top">0.250</td></tr><tr><td align="left" valign="top">Congruent not driven A or B</td><td align="left" valign="top">0.145</td><td align="left" valign="top">0.132</td><td align="left" valign="top">0.142</td><td align="left" valign="top">0.147</td></tr><tr><td align="left" valign="top">Incongruent A or B</td><td align="left" valign="top">0.116</td><td align="left" valign="top">0.127</td><td align="left" valign="top">0.076</td><td align="left" valign="top">0.108</td></tr><tr><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Congruent minus Incongruent AB</td><td align="left" valign="top">0.304</td><td align="left" valign="top">0.626</td><td align="left" valign="top">0.272</td><td align="left" valign="top">0.265</td></tr><tr><td align="left" valign="top">Congruent driven minus incongruent A or B</td><td align="left" valign="top">0.135</td><td align="left" valign="top">0.257</td><td align="left" valign="top">0.190</td><td align="left" valign="top">0.142</td></tr></tbody></table></table-wrap><p>Details: This analysis required one additional complexity, namely that the concepts of “congruent” and “incongruent” don’t translate cleanly to the single stimulus case. Consider an “incongruent” pair in which unit 1 prefers “A” and unit 2 prefers “B”. When “A” is presented, unit 1 will be strongly driven but unit 2 will not. When “B” is presented, the pattern will be the opposite. These two cases are thus more or less equivalent. However, for “congruent” pairs, when they both prefer “A” and “A” is the stimulus that is presented, the correlations could be quite different than when “B” is presented. Accordingly, for the “congruent” pairs, we subdivided according to whether the stimuli were the better (“driven”) or worse (“not driven”) of the two stimuli, and we focused the comparison on the difference between the congruent-driven and the incongruent spike count correlations. The bottom two rows of the Supplementary Table show the results for the single stimulus (A or B) conditions compared to the dual stimulus (AB) conditions.</p><p>Results: The basic pattern of a larger difference in the correlation patterns between the Congruent and Incongruent units for dual (AB) stimuli than for individual stimuli (A or B) holds across all the different categories of tested pairs. Compare the bottom two rows:</p><p>We have revised the wording in the Discussion to be consistent with the data as presented.</p><disp-quote content-type="editor-comment"><p>5. We are confused about the nature of Poisson models. If we are correct, the Poisson(a+b) is the sum of the two Poisson(a) and Poisson(b), that is, Poisson(a+b) = Poisson(a) + Poisson(b). Then, the mixture and intermediate models are very similar, identical if a*λ_A and (1-a)*λ_B happen to be integer numbers.</p></disp-quote><p>We thank the reviewers for bringing this confusion to our attention. We have modified Figure 2 to be more clear. The key distinction involves the rate parameter (λ) vs the draws from the Poisson distribution involving that rate parameter. This is most easily explained with an expanded illustration in <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>:</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>The red and blue curves illustrate two Poisson distributions with rates A and B.</title><p>The black curve illustrates draws from a mixture of those two poissons – in this case, there is a 50% chance that the draw is from rate A and a 50% chance from rate B. The green curve illustrates draws from a single Poisson whose rate is equal to A+B. We would classify the green curve as an outside because A+B&gt;max(A,B). An intermediate is not shown here but it would have a shape like the green curve and a peak between the red and blue curves – e.g. Poi((A+B)/2).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-sa2-fig2-v1.tif"/></fig><p>These patterns (and more) are illustrated in Figure 2B, and we have clarified the associated equations to be readable in plain language – see the section now entitled “Spike count drawn from:” on the right hand side:</p><disp-quote content-type="editor-comment"><p>6. It is unclear why the 'outside' model predicts responses outside the range if neurons were to linearly sum the A and B responses.</p></disp-quote><p>We hope this is now more clear with the improved explanation above. Suppose a neuron’s average response to a stimulus “A” is 5 spikes and a stimulus “B” is 10 spikes. If “A” and “B” are both presented together and the neuron responds with 15 spikes, this is linear summation. We would define it as an “outside” response because 15 is not between 5 and 10. In short, linear summation is very rare in the V1 adjacent dataset, since we almost never observed “outside” classifications.</p><disp-quote content-type="editor-comment"><p>7. It is also unclear why the 'single' hypothesis would indicate a winner-take-all response. If we understand correctly, under this model, the response to A+B is either the rate A or B, but not the max between λ_A and λ_B. Also, this model could have given an extra free parameter to modulate its amplitude to the stimulus A+B.</p></disp-quote><p>Correct – “single” can also be “loser-take-all”. This is now stated on page 9 (“indicating a winner (or loser) -take-all response patterns”). Regarding an extra free parameter related to amplitude (of response?), we are not sure we follow. The distributions of spike counts observed over the set of trials involving the A, B, and AB stimuli are fully incorporated into the model comparison. Thus, response “amplitude”, meaning spike count, is already evaluated by the model.</p><disp-quote content-type="editor-comment"><p>8. The concept of &quot;coarse population coding&quot; can be misleading, as actual population coding can represent stimulus with quite good precision. The authors refer to the broad tuning of single cells, but this does not readily correspond to coarse population coding. This could be clarified.</p></disp-quote><p>We thank the reviewers for noting that clarification is needed on this issue. Our key point is that while codes of coarsely tuned units can produce very precise estimates of the value being encoded - c.f. excellent modeling work by Baldi and Heiligenberg (1988) – this has only been shown in circumstances where only one value is being encoded, such as in motor systems. We can only make one movement with a given body part at a given moment in time, whereas sensory systems must at least initially encode a broad array of stimuli.</p><p>We have revised the wording of the introductory paragraph to provide more emphasis on the “one movement” limitation of previous work involving coarse coding in motor systems (Introduction, paragraph 1: “However, individual motor systems only generate one movement at a time.”).Baldi P, Heiligenberg W (1988) How sensory maps could enhance resolution through ordered arrangements of broadly tuned receivers. Biological Cybernetics 59:313-318.</p><disp-quote content-type="editor-comment"><p>9. As a complement to the correlation analysis, one could check whether, on a trial-by-trial basis, the neuronal response of a single neuron is closer to the A+B response average, or to either the A or B responses. This would clearly indicate that the response fluctuates between representing A or B, or simultaneously represents A+B. I am trying to understand why this is not one of the main analyses of the paper instead of the correlation analysis, which involves two neurons instead of one.</p></disp-quote><p>We thank the reviewers for this suggestion and have added a new figure (Figure 9) to the manuscript. Details: At the individual cell level, the analysis suggested above is accomplished formally by the Bayesian model comparison presented in Figure 2 and subsequent figures – units classified as “mixtures” have responses on a trial-by-trial basis that alternate between A-like and B-like patterns.</p><p>Then, the coordinations in these fluctuations are assessed using the pair-wise correlation analysis.</p><p>What we now add is an example recording session showing the full pattern of fluctuations across a set of simultaneously recorded “mixture”-responding units. This example shows all of the main findings - individual units alternating between A- and B-like responses across trials, positive correlations between some pairs of units, negative correlation between others, and lack of correlation between yet others.</p><p>There is a bias in the overall representation – in this case, “A” is over represented compared to “B”.</p><p>However, on any given individual trial, there are some units responding in an “A-like” fashion and others in a “B-like” fashion (red and blue squares are present in every column).</p><disp-quote content-type="editor-comment"><p>10. In the discussion about noise correlations, the recent papers Nogueira et al., J Neuroscience, 2020 and Kafashan et al., Nat Comm, 2021 could be cited. Also, noise correlations can also be made time-dependent, so the distinction between the temporal correlation hypotheses and noise correlations might not be fundamental.</p></disp-quote><p>We appreciate having these excellent studies brought to our attention, and have included them in the list of citations. We concur that the temporal correlation and noise correlation distinctions may be a matter of techniques employed to date.</p><disp-quote content-type="editor-comment"><p>11. It would be interesting to study the effect of contrast on the mixed responses. Is it reasonable to predict that with higher contrast the mixture responses would be more dominant than the single ones? This could be the case if the selection mechanism has a harder time suppressing one of the object responses. This would also predict that noise correlations will go down with higher contrast.</p></disp-quote><p>This would be interesting but we do not have the data to address this question for this particular study. In a study that is currently in progress in the Groh lab, we have evidence in the inferior colliculus that when a visual stimulus is paired with one of two sounds, the neural responses are biased to the visually-paired sound in comparison with the non-visually-paired sound. This will be its own separate publication when we have completed the data collection in a second animal.</p><disp-quote content-type="editor-comment"><p>12. What is the time bin size used for the analysis? Would the results be the same if one focuses on the early time responses or on the late time responses? At least from the units shown in Figure 2, it looks that there is always an object response that is delayed respect to the other, so it would seem interesting to test noise correlations in those two temporal windows.</p></disp-quote><p>We apologize for the confusion, but the only time bin used in the current study is the 200-ms spike counting window. The examples shown in Figure 2 are spike count distribution plots, not PSTHs - the x axis is spike counts, not time. We have revised the title of Figure 2A to make this more clear.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved and many of the reviewers' concerns have been addressed. However, some major issues remain. Although we typically avoid repeated revise/resubmit cycles, we believe that it is important for these issues to be addressed in a new revision. Specifically, upon discussion the reviewers unanimously remained concerned about the possibility that at least some of your results could be accounted for by subtle differences in eye movements. The new analyses related to that issue were appreciated but considered inadequate.&lt;break /&gt;As detailed below, we would like you to provide:&lt;break /&gt;1. More information about whether the electrodes that show evidence of multiplexing are the ones whose RF straddles the two stimuli, because in that case, small eye movements will bring one of the two stimuli inside the RF.</p></disp-quote><p>Among the 100 triplets classified as showing “mixture” response patterns with a winning probability of at least 0.67 (i.e. “mixture” is 2X as likely as all other possible classifications combined), we identified only 9 triplets exhibiting responses to both the A and B stimuli alone, as defined as a response greater than 1 SD above baseline.</p><p>As context, recall that one of the critical exclusionary screens for all the analyses in this paper is that a unit’s responses to the A and B stimuli must be sufficiently different that the Bayesian spike count distribution classification can be conducted. If the responses are too similar, it is not possible to evaluate whether a given spike count is more “A-like” or “B-like” etc. So, it is perhaps not very surprising that so few of our “mixtures” were responsive to both “A” and “B” stimuli.</p><p>Nevertheless, we proceeded with the additional analysis suggested below.</p><disp-quote content-type="editor-comment"><p>2. Further analyses of eye position to rule out the possibility described above. In our discussions, it was noted that the new Figure 1 – Supplementary Figure 1 appears to show that numerous V1 RFs straddle the two stimuli, and under those conditions, we really want to know if the &quot;multiplexed&quot; responses are because of small fixational differences/microsaccades that affect which of the two stimuli takes a more dominant position in the RF. To test for this kind of effect, just the STD of eye position per trial for one-stimulus vs two-stimuli conditions does not seem to be sufficient. Instead, it seems important to know whether, in the two-stimuli condition, responses were more &quot;A-like&quot; when gaze put the A stimulus closer to the RF center, and were more &quot;B-like&quot; when gaze put the B stimulus closer to the RF center. So something like a linear regression of spiking response versus &quot;eye position along the axis defined by the centers of the two stimuli, increasing towards the stimulus that alone elicited the larger response&quot; could be useful.</p></disp-quote><p>Of these 9 doubly-responsive triplet conditions identified above, only 1 showed a strongly statistically significant effect of fixational variation on the response patterns (linear regression as requested above, i.e. spiking response as a function of eye position along the axis defined by the centers of the two stimuli, p&lt;0.01; two others showed borderline effects 0.05&gt;p&gt;0.025 whose potential significance did not survive when checked in a second multiple linear regression with both parallel and orthogonal dimensions of eye position included).</p><p>In short, the number of triplets involving any provable impact of eye position on the response patterns is a very small proportion of the total and does not impact the overall pattern of the results.</p><p>The outcome of these control experiments is summarized here:</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76452-sa2-fig3-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>The authors have made several changes in the manuscript to address previous concerns. However, the fact that typically only one stimulus spanned the RF makes it difficult to make a case for multiplexing, since the other stimulus is outside the classical RF. The arguments made by the authors in response to the previous RF-related question (point 2) are based on their own hypothesis about some underlying &quot;spatial scale&quot; of multiplexing which is coarser than the RF size of V1, which I do not find particularly convincing and would be extremely difficult to implement in V1. Further, while the authors showed more results related to eye position analysis, they do not show the key comparison that was requested previously.</p></disp-quote><p>It is true that the hypothesis about a coarser-than-V1-RF spatial scale is only a hypothesis, but it is consistent with the observations of our paper so we feel it is a reasonable speculation to offer. We hope future studies will be able to answer this question. The underlying mechanism(s) that might create these multiplexed signals – whether in V1 or elsewhere – likewise remains unknown.</p><disp-quote content-type="editor-comment"><p>To better appreciate the spatial scales involved, I refer to figures from the following two studies in V1 where very small stimuli (0.1 – 0.2 degrees) were used to map the RFs: Figure 2 of Xing et al., 2009, JNS, and Figure 2 of Dubey and Ray, 2016, JNP. Typically, the SD of fitted Gaussian is typically no more than 0.25 degrees at an eccentricity of 2-3 degrees (if you consider the radius as 2SD (0.5 degrees), the diameter is about a degree). For such RFs, there is no response if a stimulus is more than a degree away from the RF. For Gabor patches used in this paper, only the &quot;size&quot; is mentioned. Does size refer to the radius or SD? In either case, there is no way to fit two Gabors within the RF. What is the separation between two Gabors? Figure 1 should highlight all these details, including the radius (not just the center) of the V1 units.</p></disp-quote><p>1. We thank the reviewer for pointing out these omissions. We have clarified the text associated with Figure 1, and we now include the stimulus location details in an expanded Figure 1 Supplementary Figure 1, which has a new panel B:</p><p>In the main text, the legend to Figure 1 now clarifies the size/diameter issue and points explicitly to Figure 1 Supplementary Figure 1 for the full description:</p><p>“C. In the “superimposed” dataset, gratings were presented either individually or in combination at a consistent location and were large enough to cover the V1 and V4 receptive fields (stimulus diameter range: 2.5-7o,). The combined gratings appeared as a plaid (rightmost panel). Monkeys maintained fixation throughout stimulus presentation and performed no other task. D. In the V1 “adjacent” dataset, Gabor patches were smaller (typically ~1o,see Figure 1 Supplementary Figure 1).”</p><p>As for the receptive fields, these were mapped with stimuli of fixed sizes, permitting identification of the centers as shown in Supplementary Figure 1A, but the precise boundaries were not systematically evaluated as this would require varying the sizes of the mapping stimuli. This limitation reflects the original experimental needs of choosing satisfactory stimulus locations for performance of the behavioral task and optimizing the stimulus positions for the simultaneously recorded MT units (Ruff and Cohen 2016; MT data not analyzed here). Hence, we must rely on a rough sense inferred from a combination of the stimulus positions and the inclusion criteria: i.e. only units responsive to at least one of these stimuli were included for analysis.</p><p>2. We appreciate the elegant work of Xing et al., 2009 and Dubey and Ray, 2016 on receptive field mapping and have included citations to these studies.</p><disp-quote content-type="editor-comment"><p>Given the concern that one of the stimuli is always outside the RF, how do we explain the findings? One possible answer is in small differences in eye position. Multiplexing is anyway observed in only ~100 out of 1389 units. I suspect these are the units whose RF center is between the two stimuli. For the AB condition (i.e., both stimuli are presented), small jitters in eye position would bring one of the two stimuli in the RF, and therefore the unit would respond like either A or B. To address this, the authors should show the RF centers of the units that show evidence of multiplexing, along with the stimuli.</p></disp-quote><p>See analysis above. Only 9 (9%) of the “mixture”-classified units are receptive field straddlers. Note that to be included for analysis, units had to exhibit different responses to the A and B stimuli individually; this tended to limit the number of units responsive to both that were included in the final tally.</p><disp-quote content-type="editor-comment"><p>In addition, it is important to check for possible differences in eye position within AB conditions for trials for which responses were &quot;A like&quot; versus &quot;B like&quot;. The authors have compared the AB condition to A and B conditions presented alone, but that is not enough. The argument that the stimuli were presented for a short duration and in pseudorandom order and therefore it is not possible for the animal to have systematically different eye positions for A/B versus AB conditions is obviously true, but that is not the point. The point is that the eye positions have small variations from trial to trial (as shown in Figure 1 – Supp 2) even before stimulus onset, and AB trials in which the position happens to be in one location get classified as &quot;A like&quot; and another location gets classified as &quot;B like&quot;. It is in fact very hard to rule out this possibility given the instrument noise which affects the precision of eye positions, but it is crucial to rule this out.</p></disp-quote><p>We apologized for the previous confusion: we understood the previous concern to involve the very distinct patterns of spike count correlation exhibited on dual stimulus trials rather than the mixture classification itself. We hope the reviewer’s concern is now satisfactorily addressed by the analysis described above.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>The authors have addressed my concerns and all other concerns raised in the editor's summary. My main concern was whether uncontrolled fixational eye movements (microsaccades) could account in part for the observed multiplexing. I understand now that concern was largely because of missing details about eye position, RF sizes, stimulus sizes, etc, which are now reported. The possibility remains that trial-by-changes in eye position (within the fixation window) would inflate the proportion of single-neuron &quot;mixture&quot; cases for adjacent two-object stimuli (by effectively changing which object is inside the RF in any given trial). But, importantly, this could not explain the observed patterns of noise correlations.</p></disp-quote><p>We thank you, and see above analyses for reassurance on the mixture-inflation question.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed. We realized we were not as specific as we should have been in the last round of feedback and have tried to clarify here exactly what the reviewers are looking for.</p></disp-quote><p>We appreciate the efforts of the reviewers to help us improve our paper and make it as strong and clear as possible. Before we delve into the detailed results of the newly requested analyses – which we think the reviewers will find reassuring – we think it is worth re-capping the evidence as a whole regarding the main topic at issue, which we understand to be eye position/eye movement as a possible factor in the observations reported in this paper and the inferences we draw from those observations.</p><p>The observations in this paper fall into two overarching categories: (1) a “multiplexing” analysis, first introduced in Caruso et al. 2018 (involving recordings in an auditory brain area (the inferior colliculus) and a visual brain area (the face patch system of IT cortex); and (2) patterns of spike count (“noise”) correlations between pairs of simultaneously recorded neurons.</p><p>Our present paper shows that the pattern of spike count correlations in V1 is very different when two stimuli are presented vs when only one stimulus is presented – there are stronger correlations, in both positive and negative directions, than observed when only one stimulus is presented (Figure 4). Regarding contributions of eye position to this pattern, as discussed in earlier rounds or review, the single- and dual-stimulus conditions were randomly interleaved and trials with microsaccades excluded, so variation in eye position cannot account for this aspect of our findings (Figure 1 Supplementary Figure 2). Our understanding is that the reviewers are satisfied as to this point.</p><p>In the immediately prior and current rounds of review, concerns have centered further on the potential role of eye position in the “mixture” classification itself. For this to undermine our conclusions, such an effect would need to be sufficiently prevalent that any remaining results after excluding potentially confounded ones are insufficient to support the overall interpretations. Put simply, for correlation-witheye-position to be a confound, it would have to be some combination of <italic>big</italic>, <italic>common</italic>, <italic>systematic</italic>, and <italic>related not only to the mixture classification but also the spike count correlation</italic>. We think correlation with-eye-position fails as an explanation due to shortcomings in all of these realms.</p><p>First: how common is correlation with eye position? In the previous round, we were asked to consider a subset of the “mixtures”, those that were doubly-responsive to both stimuli. We showed that only about 11% of this subset had a significant effect of eye position evident in the response patterns. In the current round, reviewers requested that we extend this analysis to the full population of mixtures, which we have now done (detailed below). Again, only about 9% of the conditions labeled “mixture” exhibited a significant correlation with eye position. This compares with about 5% of the conditions not labeled as “mixtures” showing such an effect. The prevalence of eye position correlation in “mixtures” vs “non mixtures” is not significantly different by chi-square analysis (p=0.17).</p><p>Second: is correlation with eye position systematically related to stimulus location/receptive field location? The analyses requested by the reviewers (and presented in full below) answer this question definitively: the incidence of a correlation with eye position is not related to the relationship between RF location and stimulus location in any particularly obvious way.</p><p>Third: If we were to exclude any of the modest number of conditions that showed a correlation with eye position, the remaining observations in the manuscript would not change in any meaningful way. Indeed, our manuscript already shows that while the bimodal spike count correlation pattern is especially strong when both units in a pair are classified as “mixtures” (Figure 4) it is <italic>also seen other combinations of response patterns</italic> (Figure 5). This supports the interpretation that even if variation in eye position were to erroneously contribute to labeling of some conditions as “mixtures” when they shouldn’t be, this error would not meaningfully undermine the overall observations regarding spike count correlations differing on single vs dual stimulus conditions.</p><p>Zooming out to a larger context, as noted above, we have previously identified “mixture” response patterns in an auditory brain region and a visual brain region with much larger receptive fields than those in V1 (Caruso et al. 2018). Eye position within a small fixation window is unlikely to have affected the classification of response patterns in these areas. We also have numerous additional datasets (not yet published) that support “mixtures” as a general phenomenon. For example, we have seen “mixture” response pattern in datasets involving visual and auditory stimuli and recordings in the superior colliculus and prefrontal cortex, as well as additional data involving visual stimuli and area MT. Thus, we are quite confident that “mixtures” do not reflect some weird artifact or exceptional sensitivity to eye position that might hold true only for the present study.</p><p>We turn below to the specific analyses requested:</p><disp-quote content-type="editor-comment"><p>In particular, because the authors claim that ~100 electrodes have mixture responses, the possible influence of eye movements should be tested for all the mixture units, not only 9/100 as done in the previous review. We would therefore like the analyses done for all the mixtures. To avoid ambiguity, we are listing the requested analyses in more detail below:</p><p>1. Show the RF centers of ALL the units labeled as mixtures (~100). The best way to do this would be to make a line passing through the centers of the two stimuli, and make five groups of units depending on their RF centers – (i) left of the left stimulus, (ii) on the left stimulus, (iii), between left and right stimulus, (iv) on the right stimulus and (v) right of the right stimulus. Then show what proportion of units in each category are mixtures. The eye movement hypothesis predicts that mixtures will be predominant in (iii). Actually, since 91/100 units have one of the two modes at zero (as far as I could understand the previous analysis), these units could even be at (i) or (v).</p><p>2. Do the eye position analysis for ALL mixture units. Since the stimuli are mainly separated along the x-axis, all we are asking is to make a scatter plot of spike counts and average eyeX position for each trial and then check for correlation between the two. This analysis is valid even for units that only respond to one stimulus (i.e. the remaining 91 units). We expect to find a significant correlation (either positive or negative) if the results are due to small eye movements, but not if the firing is due to their multiplexing hypothesis. Or, if you find significant correlations since the RF sizes are comparable to the stimulus sizes, you need to show that these correlations are insufficient to explain the bimodality.</p></disp-quote><p>As requested in point #1, Figure 1—figure supplement 3 shows the RF centers of all* the units, aligned on one of the two stimuli for clarity (since the relationship between the two stimuli was relatively consistent, this is a reasonable simplification that allows for visualization). The data points indicate the RF centers of conditions labeled as mixtures (pink dots) and those labeled as non-mixtures (green dots); conditions that passed criterion for inclusion but did not achieve a high-confidence label in the spike-count distribution analysis are shown in yellow-orange.</p><p>Breaking these down into the groups as requested in the second part of point #1 above, we get:</p><table-wrap id="sa2table2" position="float"><label>Author response table 2.</label><table frame="hsides" rules="groups"><thead><tr><th valign="bottom">RF location</th><th valign="bottom">Left of left stim (group “i”)</th><th valign="bottom">“In” left stim(group “ii”)</th><th valign="bottom">Between stims(group “iii”)</th><th valign="bottom">“In” right stim(group “iv”)</th><th valign="bottom">Right of right stim (group “v”)</th></tr></thead><tbody><tr><td align="left" valign="bottom">totals</td><td align="left" valign="bottom">37</td><td align="left" valign="bottom">128</td><td align="left" valign="bottom">58</td><td align="left" valign="bottom">28</td><td align="left" valign="bottom">0</td></tr><tr><td align="left" valign="bottom">“mixtures”</td><td align="left" valign="bottom">22</td><td align="left" valign="bottom">45</td><td align="left" valign="bottom">19</td><td align="left" valign="bottom">4</td><td align="left" valign="bottom">0</td></tr><tr><td align="left" valign="bottom">Percent “mixtures”</td><td align="left" valign="bottom">59%</td><td align="left" valign="bottom">35%</td><td align="left" valign="bottom">33%</td><td align="left" valign="bottom">14%</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Num mixtures also eye position sensitive</td><td align="left" valign="bottom">3</td><td align="left" valign="bottom">4</td><td align="left" valign="bottom">2</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Percent of mixtures that are eye position sensitive</td><td align="left" valign="bottom">13.6%</td><td align="left" valign="bottom">8.9%</td><td align="left" valign="bottom">10.5%</td><td align="left" valign="bottom">0%</td><td align="left" valign="bottom">-</td></tr></tbody></table></table-wrap><p>Note that following the method requested by the reviewers in point #1, the “in” groups also include units with RF centers above or below the corresponding stimuli. We think it can be seen from the figure that the conclusion would not differ if we were to adjust these category boundaries to define “in” as inside the estimated circumference of the gabor patch stimuli.</p><p>Completing the requested analysis as described in point #2, a statistically significant relationship between spike counts and variation in eye position is observed in ~9% of units labeled “mixtures” (9/102), and ~5% of units not labeled mixtures (10/206). These proportions do not differ significantly (chi square test, p=0.17).</p><p>Altogether, we conclude that the correlation with eye position is insufficient to account for the bimodality in ~91% of the cases we labeled as “mixtures”. This is based on the following:</p><list list-type="alpha-lower"><list-item><label>a)</label><p>Correlation with eye position is rare (9%) and only somewhat more prevalent among “mixtures” vs.non mixtures (5%)</p></list-item><list-item><label>b)</label><p>Mixtures-with-eye-position-correlation appear quite randomly distributed in space in relationship to RF center and stimulus location.</p></list-item></list><p>Methodological details: Note that there were no included units with RF centers to the right of the rightmost stimulus, because it was usually placed on or near the vertical meridian. Note also that some units were excluded from this analysis due to a failure to identify an RF center with high confidence for that electrode location. Finally, since the electrode arrays were fixed in position, RF centers did not move much on a day to day basis. Accordingly, for this analysis we used one estimate of the RF centers for each monkey and applied it across all sessions for that monkey.</p><p>Changes to manuscript: The analysis is described in the methods “Correlations between firing rates and scatter in fixation position were assessed for the dual stimulus trials using the component of eye position that lay along a line connecting the two stimulus locations chosen for the recording session (see Figure 1 – Supplementary Figure 3 for results). “ and text has been added to the second paragraph of the Results: “Finally, we assessed the responses of individual units to ascertain what proportion of units showed a correlation between firing rate and fixational scatter; this proportion was small overall (4-9%) and did not co-vary with the outcomes of the main analyses of the study (see Figure 1 – Supplementary Figure 3 for details) “</p><p>The larger pink and green bull’s eye circles indicate the conditions showing a correlation with eye position (p&lt;0.01) among the mixtures (pink) and non mixtures (green).</p><disp-quote content-type="editor-comment"><p>3. In addition, I think the authors should at least show the typical RF radius of the units (make a circle of radius of 0.5 degrees on a few of the units, perhaps the ones shown in Figure 4). We think it is important to show that the RFs do not encompass both stimuli, which is not clear from the plots.</p><p>4. The fact that one mode of the bimodal distribution is zero in 91/100 cases should also be made clearer, perhaps in the methods section. Essentially the bimodal response in most cases is not A versus B, but A/B versus zero.</p></disp-quote><p>We agree.</p><p>Changes:</p><p>In the discussion, we have added the underlined sentence to paragraph 4 (with a little re-writing around it):</p><p>“It is interesting to note that we observed evidence of multiplexing each stimulus even in V1 where receptive fields are small and the stimuli we used did not themselves typically span more than one receptive field. Put another way, for most of these V1 “mixtures”, the observed fluctuations involved responding vs not responding rather than fluctuating between two different levels of responding. Thus the coarseness of tuning did not necessarily pose a problem for the encoding of these particular stimuli in this particular brain area, and yet fluctuations were observed. Thus, the precision of V1’s spatial code may not be the limiting factor. Multiplexing is likely to have some as yet unknown characteristic spatial scale that may be determined by the coarsest tuning evident at any stage in the sensory pathway. Future work in which stimuli are systematically varied to manipulate the amount of overlap in the activity patterns evoked in different brain areas by each stimulus alone are needed to answer this question. “</p><p>The numeric results are now presented in the legend to Figure 1 Supplementary Figure 3: “Finally, about 9% of “mixtures” (n=9) were responsive to both stimuli (i.e. RF centers were intermediate between the two stimuli and responses exceeded baseline firing by at least one standard deviation for both stimuli alone); among these 9 only 1 showed sensitivity to eye position (11%).”.</p><p>And we have added a sample RF size (0.5 degrees radius) to Figure 1 Supplementary Figure 1.</p></body></sub-article></article>