<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">60404</article-id><article-id pub-id-type="doi">10.7554/eLife.60404</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Structural Biology and Molecular Biophysics</subject></subj-group></article-categories><title-group><article-title>DeepFRET, a software for rapid and automated single-molecule FRET data classification using deep learning</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-196328"><name><surname>Thomsen</surname><given-names>Johannes</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0148-9114</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-196329"><name><surname>Sletfjerding</surname><given-names>Magnus Berg</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8669-4039</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-196332"><name><surname>Jensen</surname><given-names>Simon Bo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8946-3831</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-196330"><name><surname>Stella</surname><given-names>Stefano</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9078-4659</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-196331"><name><surname>Paul</surname><given-names>Bijoya</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-196333"><name><surname>Malle</surname><given-names>Mette Galsgaard</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3722-502X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-182195"><name><surname>Montoya</surname><given-names>Guillermo</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-196334"><name><surname>Petersen</surname><given-names>Troels Christian</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-194737"><name><surname>Hatzakis</surname><given-names>Nikos S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4202-0328</contrib-id><email>hatzakis@chem.ku.dk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Chemistry and Nanoscience Centre, University of Copenhagen</institution><addr-line><named-content content-type="city">Copenhagen</named-content></addr-line><country>Denmark</country></aff><aff id="aff2"><label>2</label><institution>Structural Molecular Biology Group, Novo Nordisk Foundation Centre for Protein Research, Faculty of Health and Medical Sciences, University of Copenhagen</institution><addr-line><named-content content-type="city">Copenhagen</named-content></addr-line><country>Denmark</country></aff><aff id="aff3"><label>3</label><institution>Niels Bohr Institute, University of Copenhagen</institution><addr-line><named-content content-type="city">Copenhagen</named-content></addr-line><country>Denmark</country></aff><aff id="aff4"><label>4</label><institution>Novo Nordisk Foundation Centre for Protein Research, Faculty of Health and Medical Sciences, University of Copenhagen</institution><addr-line><named-content content-type="city">Copenhagen</named-content></addr-line><country>Denmark</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Deindl</surname><given-names>Sebastian</given-names></name><role>Reviewing Editor</role><aff><institution>Uppsala University</institution><country>Sweden</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Pfeffer</surname><given-names>Suzanne R</given-names></name><role>Senior Editor</role><aff><institution>Stanford University School of Medicine</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>03</day><month>11</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e60404</elocation-id><history><date date-type="received" iso-8601-date="2020-06-25"><day>25</day><month>06</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-10-02"><day>02</day><month>10</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Thomsen et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Thomsen et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-60404-v1.pdf"/><abstract><p>Single-molecule Förster Resonance energy transfer (smFRET) is an adaptable method for studying the structure and dynamics of biomolecules. The development of high throughput methodologies and the growth of commercial instrumentation have outpaced the development of rapid, standardized, and automated methodologies to objectively analyze the wealth of produced data. Here we present DeepFRET, an automated, open-source standalone solution based on deep learning, where the only crucial human intervention in transiting from raw microscope images to histograms of biomolecule behavior, is a user-adjustable quality threshold. Integrating standard features of smFRET analysis, DeepFRET consequently outputs the common kinetic information metrics. Its classification accuracy on ground truth data reached &gt;95% outperforming human operators and commonly used threshold, only requiring ~1% of the time. Its precise and rapid operation on real data demonstrates DeepFRET’s capacity to objectively quantify biomolecular dynamics and the potential to contribute to benchmarking smFRET for dynamic structural biology.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>Proteins are folded into particular shapes in order to carry out their roles in the cell. However, their structures are not rigid: proteins bend and rotate in response to their environment. Identifying these movements is an important part of understanding how proteins work and interact with each other. Unfortunately, when researchers study the structures of proteins, they often look at the ‘average’ shape a protein takes, missing out on other conformations the protein might only be in temporarily.</p><p>An important technique for studying protein flexibility is known as single molecule Förster resonance energy transfer (FRET). In this technique, two light-sensitive tags are attached to the same protein molecule and give off a signal when they come into close contact. This nano-scale sensor allows structural biologists to get information from individual protein movements that can be lost when looking at the average conformations of proteins.</p><p>Advances in the instruments used to perform FRET have made observing the motion of individual proteins more widely accessible to non-specialists, but the analysis of the data that these instruments produce still requires a high level of expertise. To lower the barrier for non-specialists to use the technology, and to ensure that experiments can be reproduced on different instruments and by different researchers, Thomsen et al. have developed a new way to automate the data analysis. They used machine learning technology to recognize, filter and characterize data so as to produce reliable results, with the user only needing to perform a couple of steps.</p><p>This new analysis approach could help expand the use of single-molecule FRET to different fields , allowing researchers to investigate the importance of protein flexibility for certain diseases, or to better understand the roles that proteins have in a cell.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>single molecule</kwd><kwd>FRET</kwd><kwd>biophysics</kwd><kwd>deep learning</kwd><kwd>microscopy</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002808</institution-id><institution>Carlsbergfondet</institution></institution-wrap></funding-source><award-id>CF16-0797</award-id><principal-award-recipient><name><surname>Thomsen</surname><given-names>Johannes</given-names></name><name><surname>Jensen</surname><given-names>Simon Bo</given-names></name><name><surname>Hatzakis</surname><given-names>Nikos S</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100008397</institution-id><institution>Velux Fonden</institution></institution-wrap></funding-source><award-id>10099</award-id><principal-award-recipient><name><surname>Hatzakis</surname><given-names>Nikos S</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100008397</institution-id><institution>Velux Fonden</institution></institution-wrap></funding-source><award-id>18333</award-id><principal-award-recipient><name><surname>Sletfjerding</surname><given-names>Magnus Berg</given-names></name><name><surname>Malle</surname><given-names>Mette Galsgaard</given-names></name><name><surname>Hatzakis</surname><given-names>Nikos S</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004191</institution-id><institution>Novo Nordisk</institution></institution-wrap></funding-source><award-id>NNF14CC0001</award-id><principal-award-recipient><name><surname>Stella</surname><given-names>Stefano</given-names></name><name><surname>Paul</surname><given-names>Bijoya</given-names></name><name><surname>Montoya</surname><given-names>Guillermo</given-names></name><name><surname>Hatzakis</surname><given-names>Nikos S</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004191</institution-id><institution>Novo Nordisk</institution></institution-wrap></funding-source><award-id>NNF0024386</award-id><principal-award-recipient><name><surname>Montoya</surname><given-names>Guillermo</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004191</institution-id><institution>Novo Nordisk</institution></institution-wrap></funding-source><award-id>NNF17SA0030214</award-id><principal-award-recipient><name><surname>Montoya</surname><given-names>Guillermo</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004191</institution-id><institution>Novo Nordisk</institution></institution-wrap></funding-source><award-id>NNF18OC0055061</award-id><principal-award-recipient><name><surname>Montoya</surname><given-names>Guillermo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>An open-source user-friendly toolbox implementing machine learning for single-molecule FRET analysis enabling experts and non-experts to reproducibly provide dynamic structural biology insights.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Single-molecule Förster resonance energy transfer (smFRET) combined with TIRFm (total internal reflection fluorescence microscopy) is a key powerful method to study the structure of biomolecules and provide a dynamic perspective in structural biology (<xref ref-type="bibr" rid="bib34">Lerner et al., 2018</xref>). Capturing the real-time readouts of nanometer-scale distances of individual biomolecules by smFRET allows the direct observations of dynamics, interactions, and intermediates of stochastic non-accumulating events, as well as dynamic equilibria between unsynchronized molecules, all of which are obscured in ensemble averaging techniques (<xref ref-type="bibr" rid="bib8">Dimura et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>; <xref ref-type="bibr" rid="bib23">Holmstrom et al., 2019</xref>; <xref ref-type="bibr" rid="bib27">Juette et al., 2016</xref>; <xref ref-type="bibr" rid="bib38">Newton et al., 2019</xref>; <xref ref-type="bibr" rid="bib44">Preus et al., 2015</xref>; <xref ref-type="bibr" rid="bib46">Roy et al., 2008</xref>; <xref ref-type="bibr" rid="bib52">Schuler and Eaton, 2008</xref>; <xref ref-type="bibr" rid="bib58">Stella et al., 2018</xref>). The high fidelity and proficiency of smFRET established it as a key toolbox for the accurate characterization of mechanisms, biomolecular interactions function, and even structures of biomolecules (<xref ref-type="bibr" rid="bib7">Craggs and Kapanidis, 2012</xref>; <xref ref-type="bibr" rid="bib9">Dulin et al., 2018</xref>; <xref ref-type="bibr" rid="bib28">Kalinin et al., 2012</xref>; <xref ref-type="bibr" rid="bib31">Kilic et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ratzke et al., 2014</xref>), under both in vitro (<xref ref-type="bibr" rid="bib49">Schluesche et al., 2007</xref>; <xref ref-type="bibr" rid="bib54">Sharma et al., 2008</xref>; <xref ref-type="bibr" rid="bib57">Stein et al., 2011</xref>) and in vivo (<xref ref-type="bibr" rid="bib40">Okamoto et al., 2020</xref>; <xref ref-type="bibr" rid="bib47">Sakon and Weninger, 2010</xref>) conditions. Despite its great quantitative utility and profound impact on structural biology, smFRET is not a direct imaging modality and data treatment for extracting quantitative dynamic information relies on multiple layers of preprocessing: raw image treatment, trace selection, and data analysis. Raw image treatment (<xref ref-type="bibr" rid="bib16">Greenfeld et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Hon and Gonzalez, 2019</xref>; <xref ref-type="bibr" rid="bib27">Juette et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Preus et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Stella et al., 2018</xref>) and data analysis of the selected smFRET traces is in general well-standardized and relies on well-defined methodologies with strong theoretical backing (<xref ref-type="bibr" rid="bib24">Hon and Gonzalez, 2019</xref>; <xref ref-type="bibr" rid="bib50">Schmid et al., 2016</xref>).</p><p>The actual trace selection can be time-consuming but crucial due to the presence of undesired phenomena at the single-molecule scale, such as sample aggregation, fluorescent contaminants, incomplete or incorrect sample labeling, complex photophysical behaviors, and high noise, to mention a few (<xref ref-type="bibr" rid="bib1">Algar et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Roy et al., 2008</xref>). Existing software (<xref ref-type="bibr" rid="bib16">Greenfeld et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">Hon and Gonzalez, 2019</xref>; <xref ref-type="bibr" rid="bib27">Juette et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Preus et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Stella et al., 2018</xref>) by single-molecule labs can simplify the tedious and time-consuming selection of traces and were recently expanded to large datasets (<xref ref-type="bibr" rid="bib27">Juette et al., 2016</xref>) albeit requiring some form of manual supervision and hyper-parameter tuning selecting the proper thresholds by an expert user. This need for human intervention could potentially be subjected to cognitive biases especially by less experienced users and could limit the expansion of smFRET to classic biology labs. The increasing expansion of smFRET to structural biology labs would benefit from rapid and benchmarked methodologies, reproducible across laboratories, with minimal human intervention. This is highlighted by several initiatives to standardize the smFRET field (<xref ref-type="bibr" rid="bib16">Greenfeld et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>; <xref ref-type="bibr" rid="bib34">Lerner et al., 2018</xref>; <xref ref-type="bibr" rid="bib48">Sali et al., 2015</xref>).</p><p>Recent advances in machine learning (ML) and specifically deep learning (DL) (<xref ref-type="bibr" rid="bib32">LeCun et al., 2015</xref>), have radically improved our capacity to access and extract information from abstract and noisy inputs independently of human interventions as we (<xref ref-type="bibr" rid="bib2">ATLAS collaboration, 2014</xref>) and others have shown (<xref ref-type="bibr" rid="bib3">Berg et al., 2019</xref>; <xref ref-type="bibr" rid="bib6">Christiansen et al., 2018</xref>; <xref ref-type="bibr" rid="bib11">Falk et al., 2019</xref>; <xref ref-type="bibr" rid="bib14">Gómez-García et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Jones, 2019</xref>; <xref ref-type="bibr" rid="bib42">Ouyang et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Smith et al., 2019</xref>; <xref ref-type="bibr" rid="bib69">Zhang et al., 2018</xref>). DL implementations are providing high-level robust performances and have been successfully used to analyze and augment a wide range of the fluorescence microscopy analysis pipeline including assessing microscope image quality (<xref ref-type="bibr" rid="bib67">Yang et al., 2018</xref>), in-silico cell labeling (<xref ref-type="bibr" rid="bib6">Christiansen et al., 2018</xref>), single-cell morphology analysis (<xref ref-type="bibr" rid="bib3">Berg et al., 2019</xref>; <xref ref-type="bibr" rid="bib11">Falk et al., 2019</xref>), detecting single molecules (<xref ref-type="bibr" rid="bib63">White et al., 2020</xref>; <xref ref-type="bibr" rid="bib66">Wu and Rifkin, 2015</xref>) and linking smFRET experiments with molecular dynamics simulations (<xref ref-type="bibr" rid="bib36">Matsunaga and Sugita, 2018</xref>), amongst others (<xref ref-type="bibr" rid="bib3">Berg et al., 2019</xref>; <xref ref-type="bibr" rid="bib6">Christiansen et al., 2018</xref>; <xref ref-type="bibr" rid="bib11">Falk et al., 2019</xref>; <xref ref-type="bibr" rid="bib14">Gómez-García et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Jones, 2019</xref>; <xref ref-type="bibr" rid="bib42">Ouyang et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Smith et al., 2019</xref>; <xref ref-type="bibr" rid="bib69">Zhang et al., 2018</xref>).</p><p>Deep learning-based analysis has several advantages over other approaches: It recognizes abstract patterns and learns useful features directly from the raw input data, which allows the implementation of analysis routines that do not require extensive data preprocessing or empirically defined rules, and thus offer reproducible and less opinionated evaluation of single-molecule data; It is significantly faster than human annotation for large single-molecule datasets; it comes close to, or outperforms human performance; and its performance is increased when increasing dataset size constituting an ideal case for evaluating the large datasets obtained from single-molecule data (<xref ref-type="bibr" rid="bib3">Berg et al., 2019</xref>; <xref ref-type="bibr" rid="bib6">Christiansen et al., 2018</xref>; <xref ref-type="bibr" rid="bib11">Falk et al., 2019</xref>; <xref ref-type="bibr" rid="bib14">Gómez-García et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Jones, 2019</xref>; <xref ref-type="bibr" rid="bib42">Ouyang et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Smith et al., 2019</xref>; <xref ref-type="bibr" rid="bib69">Zhang et al., 2018</xref>). Especially important are convolutional deep neural networks (DNN), artificial neural networks that learn to approximate the underlying function that transforms input to associated output through multiple rounds of optimization. The strength of DNN is the ability to learn arbitrarily complex functions to best recognize particular aspects of the given input data and model complex nonlinear relationships. The DNN is then able to classify data into predefined classes based on the provided training labels. While the training of a DNN is generally a computationally intensive process, once trained the final model can easily be shared and used for making predictions at almost no computational cost to end-users.</p><p>Here we provide DeepFRET, an all-inclusive analysis software with a pre-trained DNN at its core, for a rapid, objective, and accurate assessment of smFRET data for quantifying biomolecular dynamics. The fully automated analysis software operates with minimal crucial human intervention and requires only a threshold on the data quality confidence, as an initial step, to output detailed quantification of structural dynamic from raw images. This is attained by an intuitive and user-friendly interface that integrates and automates common smFRET analysis procedures (<xref ref-type="bibr" rid="bib16">Greenfeld et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">Hon and Gonzalez, 2019</xref>; <xref ref-type="bibr" rid="bib27">Juette et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Preus et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Stella et al., 2018</xref>) from raw image analysis and background-corrected intensity trace extraction (<xref ref-type="bibr" rid="bib59">Thomsen et al., 2019</xref>), to sophisticated trace classification, statistical analysis of single-molecule data and production of publication-quality figures of dynamic structural biology insights (see Materials and methods). DeepFRET comes as a free-to-use standalone executable for both Windows and Mac users allowing end-users with limited programming skills to easily operate it. A script-based version implemented entirely in Python enables experts to adjust features pipelining the analysis specified for their needs. We anticipate DeepFRET to take full advantage of the widespread digitization and open repository of smFRET data and form a reference point setting a bar for the data quality and data classification performance metrics, offering additional benchmarking the field for dynamic structural biology.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>DeepFRET software package</title><p>DeepFRET is an open-source software package that implements a neural network model architecture for data evaluation integrating into a user-friendly platform all common procedures for smFRET analysis (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplements 1</xref>–<xref ref-type="fig" rid="fig1s2">2</xref>). The neural network model architecture used here is based on a deep convolutional neural network to recognize particular spatial features present in the data. The model first passes the data through several layers of convolutions of different lengths, and in the process learns to recognize which particular elements of a sample are present at different length scales, to best classify it correctly. This has previously been used to label time-series data such as electrocardiographs (<xref ref-type="bibr" rid="bib17">Hannun et al., 2019</xref>) or electrical readouts in DNA sequencing (<xref ref-type="bibr" rid="bib64">Wick et al., 2018</xref>). Additionally, we added a long short-term memory (LSTM) layer after the convolutional layers, as this will also help the model to learn temporality in the data and propagate to the later frames the learned information (<xref ref-type="bibr" rid="bib29">Karim et al., 2018</xref>; <xref ref-type="bibr" rid="bib39">Oh et al., 2018</xref>). A detailed description of the model hyperparameters and architecture can be found in the Materials and methods section.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Overview of smFRET evaluation and analysis using DeepFRET.</title><p>(<bold>a</bold>) Cartoon of the typical heterogeneous data acquired in smFRET experiments. Varying criteria for data selection for downstream analysis may yield different structural and kinetic information. (<bold>b</bold>) Screenshots of the provided standalone software that integrates deep learning and reduces the selection to a single-user-adjustable criterion: the DEEP FRET confidence threshold. The simple and intuitive GUI integrates all the features of our approach for rapid traces extraction from raw images to filtering of traces based on the predicted classification, treatment of smFRET data to extraction of publication-quality figures. (<bold>c</bold>) End-to-end sequence classification of smFRET traces by deep learning. Raw signals of donor-donor, donor-acceptor, and acceptor-acceptor intensities in the form of ASCII files can also be loaded with the DeepFRET software. The pre-trained DNN will classify individual frames into one of six different categories: bleached, static smFRET, dynamic smFRET, aggregate, noisy, and scrambled. A final smFRET confidence score is calculated, depending on each of the categories, that is used for threshold.</p><p> <supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Data underlying <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplements 3</xref>, <xref ref-type="fig" rid="fig1s4">4 ,</xref> and <xref ref-type="fig" rid="fig1s7">7</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60404-fig1-data1-v1.zip"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Schematic overview of the neural network model architecture.</title><p>Each residual block (Res) is made up of 1D convolutional filters of size n × k with batch normalization and ReLU activations in between. The initial convolution after the input layer has the same hyper-parameters as the first residual block. A 1 × k convolution is added in each bottleneck unit for efficiency. The ‘+’ symbol denotes a skip-connection, where the residual block’s input is added to its output. The final convolved output goes to a bidirectional long short-term memory (LSTM) layer. For each frame, the outputs are distributed among the different classes by a dense layer with softmax activation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Data generator algorithm overview.</title><p>To generate unbiased distributions of smFRET traces, most steps include randomization, sampling from uniform distributions (except for bleaching probability, which follows an exponential distribution) for the given input parameter ranges. User-adjustable parameters include the probability of aggregation, fluorophore blinking, bleaching, and more. All output data is automatically sequence-annotated with the ground truth behavior, for supervised machine learning. A scrambling probability is used to generate a fraction of heavily distorted data to improve model robustness and prevent misclassification of data containing artifacts.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>FRET values, dynamic FRET state lifetimes, and transition pathways are uniformly sampled for all ground truth smFRET traces.</title><p>(<bold>a</bold>) smFRET traces were generated with 1–4 randomly defined FRET states with the same transition probabilities as used for model training. Comparing FRET calculated from uniformly sampled donor/acceptor intensities between 0 and 1 reveals identical, uniform distributions. (<bold>b</bold>) Theoretical lifetime distributions for various ranges of sampled transition probabilities. The lifetime distribution follows an evenly weighted average over the exponential decays for each possible number of FRET states and transition probabilities. A Monte Carlo simulation derived by sampling transition probabilities uniformly between 0 and 0.2, as in the training data, on n = 10,000 traces sampling from 2 to 4 FRET states is in agreement with the underlying model. (<bold>C</bold>) Transition density plot displaying the idealized transitions of n = 1000 simulated FRET traces. A minimum distance of 0.1 FRET between states was used, as in the training data, to distinguish actual transitions from noise fluctuations, hence the grayed out diagonal. The simulated training data does not introduce any bias in the model training.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp3-v1.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 4.</label><caption><title>Noise threshold for simulated data.</title><p>(<bold>a</bold>) To tune the accepted noise level for our deep learning model, we simulated 200 smFRET traces with a single state at 0.5 FRET, with varying noise levels. (<bold>b</bold>) At a noise level of 0.25, the distributions in (<bold>a</bold>) could no longer be considered normal, using a D’Agostino-Pearson test for normality (p&lt;0.05).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp4-v1.tif"/></fig><fig id="fig1s5" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 5.</label><caption><title>Examples of randomly generated traces.</title><p>Randomly generated traces, corresponding to each of the six defined categories, shown with raw signals, E (FRET), and S (stoichiometry). The color code in the bottom panel corresponds to the frame-level ground truth labeling of each trace.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp5-v1.tif"/></fig><fig id="fig1s6" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 6.</label><caption><title>Trace simulator interface.</title><p>To facilitate fast and easy experimentation of any kind on smFRET traces, the DeepFRET GUI includes a visual trace simulator with ground-truth labels associated with every trace. The traces can be exported to ASCII or DAT and used for all kinds of statistical procedures.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp6-v1.tif"/></fig><fig id="fig1s7" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 7.</label><caption><title>Training label dependence on the frame number.</title><p>The distribution of labels for all frames in the training dataset, after balancing classes based on the first frame. The ‘bleaching’ label is excluded from balancing, as it occurs in most of the generated traces, due to photobleaching.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp7-v1.tif"/></fig><fig id="fig1s8" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 8.</label><caption><title>Calculation of confidence score from model predictions.</title><p>(<bold>a</bold>) Short toy-examples of selected traces for each category and the corresponding frame-wise predictions used for calculating confidence scores. The color code corresponds to classified behavior. All bleached data points (marked with gray in the trace) are excluded from the confidence score calculation. (<bold>b</bold>) Step-by-step calculation of trace scores.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp8-v1.tif"/></fig><fig id="fig1s9" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 9.</label><caption><title>Histogram interface window.</title><p>DeepFRET includes a histogram window which automatically finds BIC-optimal Gaussian mixtures, and allows the user to test enter the number of Gaussians to include in a mixture model. The histogram interface also includes an option for β- and γ-correction. Data is simulated from DeepFRETs trace generator with three states with means 0.15, 0.5, and 0.85, as in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp9-v1.tif"/></fig><fig id="fig1s10" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 10.</label><caption><title>Transition density window.</title><p>To visualize transitions between FRET states, DeepFRET includes a window to fit exponential lifetime distributions of clusters in a transition density plot. The transition density interface also allows the user to test a different number of clusters for the transition density window. Data is simulated from DeepFRET’s trace generator with three states with means 0.15, 0.5, and 0.85, as in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp10-v1.tif"/></fig><fig id="fig1s11" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 11.</label><caption><title>Traces window.</title><p>To provide direct visualization of the Hidden Markov modeling of smFRET traces, traces can be imported directly for HMM analysis using the commonly used pomegranate implementation of the Baum-Welch algorithm. The transitions from the traces window are used in the transition density window. Data is simulated from DeepFRET’s trace generator with three states with means 0.15, 0.5, and 0.85, as in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig1-figsupp11-v1.tif"/></fig></fig-group><p>To ensure that the predictions of DeepFRET would generalize to a wide range of experimentally observable behaviors independently of biological systems or experimental conditions, we provide a fully pre-trained DNN model. The implemented DNN is pre-trained on 150,000 simulated traces that uniformly sample all possible FRET states, their respective lifetimes, occupancies, and transition pathways, as well as all possible noise levels, ensuring that the data represents all theoretically possible configurations (see <xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplements 3</xref>–<xref ref-type="fig" rid="fig1s5">5</xref>, Materials and methods for software and algorithms). As such DeepFRET does not require the selection of any direct initial guesses of FRET values or user-defined parameter pretraining. However, we do provide both a script-based method for simulating smFRET data and a simple graphical interface for expert end-users to adjust simulation distribution parameters (see <xref ref-type="fig" rid="fig1">Figure 1b</xref>, <xref ref-type="fig" rid="fig1s6">Figure 1—figure supplement 6</xref> and Materials and methods) for model re-training if needed (e.g. for specific circumstances or stricter criteria). This offers experts the possibility to benchmark the impact of, for example, one’s sorting criteria, noise, and optical correction factors.</p><p>We built DeepFRET to treat both alternating laser excitation (ALEX) and non-ALEX FRET data. DeepFRET imports raw microscope images and performs colocalization of the two channels, to extract background corrected intensity traces of DD (donor excitation; donor emission), DA (donor excitation; acceptor emission), their respective stoichiometry, and in the case of ALEX data, also AA (acceptor excitation; acceptor emission; see <xref ref-type="fig" rid="fig1">Figure 1a</xref>, <xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>). Alternatively, one can directly load and process previously-obtained time-traces ASCII format as exported from the popular software package iSMS (<xref ref-type="bibr" rid="bib44">Preus et al., 2015</xref>) without their associated videos.</p><p>For a given time trace the DNN predicts and outputs six softmaxed probabilities <italic>p<sub>i</sub></italic> to each time frame (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplement 5</xref> and Materials and methods), representing the six categories it has been trained to recognize: bleached (B), static smFRET within the experimental time frame (S), dynamic smFRET (D), aggregate (A), noisy (N), and all other types of non treatable data smFRET data defined here as scrambled (X) (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplements 5</xref> and <xref ref-type="fig" rid="fig1s7">7</xref>). Both static and dynamic traces are included for further analysis. Given these probabilities, which sums to one, a simple sliding window then searches for frames predicted by the DNN to be bleached (<italic>p<sub>B</sub> &gt;0.5</italic>, see (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplements 5</xref>–<xref ref-type="fig" rid="fig1s8">8</xref>) for evaluation accuracy, and blinking exclusion). When bleaching is found, the rest of the trace is removed to exclude the photobleached frames part of a trace from further analysis. If the trace still contains a minimum number of viable frames (here set to 15 but adjustable), the probabilities are summed up over all remaining time frames for each of the five remaining categories and divided by the number of frames for normalization (see Materials and methods and <xref ref-type="fig" rid="fig1">Figure 1c</xref>, <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplements 5</xref>–<xref ref-type="fig" rid="fig1s8">8</xref>). We define the summaries of the combined static and dynamic trace scores as the ‘DeepFRET score’, representing the DNN model confidence that a trace is truly smFRET. The user-friendly interface displays all the categories and their associated probabilities, and offers the option for expert users to manually revise the classified traces.</p><p>If the DeepFRET score is above the user-defined threshold, the trace is accepted for the subsequent analysis (see <xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s8">Figure 1—figure supplement 8</xref> and Materials and methods). Subsequent analysis involves two-channel fitting of idealized FRET traces using Hidden Markov modeling <italic>HMM</italic> (using the open-source package pomegranate); data and statistical evaluation of the abundance of FRET states and lifetimes; application of correction factors; and transition density plots (see <xref ref-type="fig" rid="fig1">Figure 1b</xref>, <xref ref-type="fig" rid="fig1s6">Figure 1—figure supplements 6</xref> and <xref ref-type="fig" rid="fig1s9">9</xref>–<xref ref-type="fig" rid="fig1s11">11</xref>). The number of underlying FRET distributions is automatically determined using Bayesian information criterion (BIC), offering the unbiased analysis of distribution of biomolecular distances (see <xref ref-type="fig" rid="fig1">Figure 1b</xref>, <xref ref-type="fig" rid="fig1s6">Figure 1—figure supplements 6</xref> and <xref ref-type="fig" rid="fig1s9">9</xref>–<xref ref-type="fig" rid="fig1s11">11</xref>). All data can be directly exported in publication-quality figures or extracted as data for user specific analysis if required.</p></sec><sec id="s2-2"><title>Performance of DeepFRET</title><p>To test our DeepFRET performance in practice, we initially compared it with commonly used threshold values. To be on the safe site, we simulated 200 ground truth smFRET traces and merged them with a dataset containing 5000 random, non-smFRET traces (too noisy, aggregates of multiple molecules, aberrant single-molecule behavior, see Materials and methods for parameter descriptions). The obtained overall FRET distribution would be akin to what one would observe experimentally before any preprocessing of smFRET data on a low purity protein sample (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). Common procedures for pre-selecting valid data for treatment often rely on an initial automatic threshold for discarding this large fraction of non-smFRET data (see <xref ref-type="fig" rid="fig1">Figure 1a</xref>). This is based on any number of combinations of the anticorrelated signal of the donor and acceptor, fluorophore bleaching, noise levels, or certain ranges of fluorophore stoichiometry, if recorded using ALEX methods (<xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>; <xref ref-type="bibr" rid="bib22">Hohlbein et al., 2014</xref>; <xref ref-type="bibr" rid="bib27">Juette et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Lee et al., 2005</xref>; <xref ref-type="bibr" rid="bib37">McKinney et al., 2006</xref>; <xref ref-type="bibr" rid="bib44">Preus et al., 2015</xref>; <xref ref-type="bibr" rid="bib61">van de Meent et al., 2014</xref>). We first removed photobleaching and then accepted or rejected traces based on commonly used thresholds of median stoichiometry and max intensity (but not anticorrelation, see Materials and methods) without any manual post-inspection of the data. <xref ref-type="fig" rid="fig2">Figure 2b</xref> displays ground truth distribution (green) and the distribution of the accepted traces (pink) for varying the above thresholds. We recovered a poorly-defined FRET distribution that even at the tightest threshold does not recapitulate the underlying ground truth two-state conformational equilibrium. We calculated the common model evaluation metrics ‘precision’ and ‘recall’ (see Materials and methods) to quantify the quality of the predictions. The precision and recall, though improved by tightening the threshold, remain around 0.22 and 0.40, in the best case for simple thresholding (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). The fact that out of 366 selected traces only 80 were true positive, while 286 were false positive and 120 false negative, highlights the need for human intervention as many traces are indistinguishable with simple statistical characterization (selected examples are shown below the histograms [<xref ref-type="fig" rid="fig2">Figure 2b</xref>]).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>High quality FRET data evaluation.</title><p>(<bold>a</bold>) Simulated dynamic smFRET traces transitioning between FRET states 0.3 and 0.7 (left, ‘ground truth’) were mixed with a larger number of traces not showing smFRET (center). The overall distribution (right, ‘combined’) shows how the desired data can be drowned out in non-smFRET contaminant traces. The distribution would correspond to a raw distribution as extracted from raw image analysis of smFRET on low purity protein sample before any trace selection. (<bold>b</bold>) Automatic selection of data based on median stoichiometry, single-molecule intensity and bleaching. The number <italic>n</italic> designates the number of traces accepted by the model. Tightening the selection thresholds results in slight improvement of the poor overlap of the selected data with ground truth data, highlighting the need for a time-consuming and prone to potential cognitive biases human intervention. (<bold>c</bold>) Automatic classification of all traces of the combined set by DeepFRET, based only on the DeepFRET score threshold variation. Even at a low threshold DeepFRET selection follows the ground truth data. Increasing the score threshold further increases the fidelity of data selection. DeepFRET correctly assigns the dynamic, bleaching and aggregate behavior on the same smFRET traces as in (b) (see <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplement 5</xref> for more data). The single-user adjustable score threshold outperforms commonly used thresholds offering rapid, cross-lab reproducibility, and fully automatic data treatment. P: precision, R: recall, TN: true negatives, FP: false positives, FN: false negatives, TP: true positives.</p><p> <supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Data underlying <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref>–<xref ref-type="fig" rid="fig2s3">3</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60404-fig2-data1-v1.zip"/></supplementary-material> </p><p> <supplementary-material id="fig2sdata2"><label>Figure 2—source data 2.</label><caption><title>Data underlying <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref>–<xref ref-type="fig" rid="fig2s3">3</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60404-fig2-data2-v1.zip"/></supplementary-material> </p><p> <supplementary-material id="fig2sdata3"><label>Figure 2—source data 3.</label><caption><title>Data underlying <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref>–<xref ref-type="fig" rid="fig2s3">3</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60404-fig2-data3-v1.zip"/></supplementary-material> </p><p> <supplementary-material id="fig2sdata4"><label>Figure 2—source data 4.</label><caption><title>Data underlying <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref>–<xref ref-type="fig" rid="fig2s3">3</xref> .</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60404-fig2-data4-v1.zip"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Precision-recall for correctly identifying smFRET traces at different thresholds.</title><p>(<bold>a</bold>) Visual display of recovered smFRET distributions for several thresholds for a 2-state system (same data as <xref ref-type="fig" rid="fig2">Figure 2</xref>). (<bold>b</bold>) The precision and recall are calculated for all thresholds on the datasets shown in <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>. For 1-, 2-, and 3-state systems we find that a threshold around 0.8–0.9 provides the best trade-off between the two measures, in order to recover the underlying FRET distribution faithfully.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Comparison of smFRET distribution recovery by DeepFRET at different thresholds and semi-automated methodologies under various conditions in the absence of further human intervention.</title><p>In each of the figures (<bold>a</bold>) and (<bold>b</bold>); Top: ground truth distribution and distribution of randomly selected non-smFRET data from an external test set. Middle: Performance of DeepFRET sorting at different thresholds. Bleached frames were excluded from analysis in all cases. Bottom: Performance of sorting by semi-automated methodologies using common thresholds-based sorting at different thresholds. Classification metrics for smFRET trace detection are shown in the graph. (<bold>a</bold>) The performance, given a 1-state system centered at FRET mean value 0.5. (<bold>b</bold>) The performance, given a 3-state system centered at FRET mean values 0.15, 0.5, and 0.85.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Relationship between model performance and noise level.</title><p>(<bold>a</bold>) 3D illustration of the precision or recall (pseudocolor) as a function of trace noise and the distance between FRET states for dynamic 2-state traces. Prediction accuracy is minimal at ~0.2 noise levels. At lower noise, the trace is accepted and correctly classified with an accuracy of &gt;0.96, while at high noise levels the trace is accurately classified as non-FRET. (<bold>b</bold>) Examples of simulated dynamic traces used, with input simulation noise. At a high simulated noise level, only some traces are below the lower limit of acceptable noise, when measuring the per-state standard deviation of FRET of the final output trace.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig2-figsupp3-v1.tif"/></fig></fig-group><p>DeepFRET, on the other hand, allowed the high-fidelity recovery of the underlying ground truth distribution reaching a precision of 0.91 when setting a DeepFRET score of 0.85 (<xref ref-type="fig" rid="fig2">Figure 2c</xref>) without the need for human intervention. The virtually identical FRET distributions, matching the ground truth data, that are derived for a large fraction of score thresholds (0.5– 0.85) show no systematic biases originating from data evaluation and illustrate the minimum impact of human interventions when using DeepFRET (see <xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). As expected, the fidelity of DeepFRET pertained to correctly identifying single or complex multistate FRET distributions (see <xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref>–<xref ref-type="fig" rid="fig2s2">2</xref>) reaching precision 0.91 as compared to just 0.22 for standard threshold setting in the absence of further human intervention. The practically identical precision and recall for single, double or triple, state FRET distributions independently of threshold further support the wide applicability to multiple biological systems.</p><p>Quantification of precision and recall of the selection for various DeepFRET score thresholds displays the tradeoffs in recovering a high fraction of useful data. Thresholding data with scores in the regime 0.8–0.9 appears optimal for maintaining sufficient and high-fidelity data (<xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) for the trace characteristics here. Based on these data, we employed a DeepFRET score threshold of 0.85 as optimal for maintaining high precision at reasonable recall values. We note that depending on datasets, imaging condition, noise levels, etc., users may need to adjust the threshold. The power of DeepFRET is further highlighted by the classification for the traces that were assigned as false negative and false positive by commonly accepted thresholds (traces in <xref ref-type="fig" rid="fig2">Figure 2b</xref> and <xref ref-type="fig" rid="fig2">Figure 2c</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). In summary, the fidelity of classification accuracy appears to supersede currently used simple thresholding, without human interventions. This was achieved in a fraction of the time required for data classification by human operators (~1 min for 10,000 traces on a normal laptop, as compared to potentially days for manually inspected traces). This improved classification was also achieved entirely without any preprocessing or post-inspection of data, illustrating the power of DeepFRET to operate without human interventions and its potential to benchmark the reproducibility of smFRET data acquisition methods for multiple biomolecular systems across laboratories.</p><p>We quantified and displayed using confusion matrix the discordance between the ground truth data and the data selected and classified by DeepFRET (<xref ref-type="fig" rid="fig3">Figure 3</xref>). In the confusion matrices, displayed in <xref ref-type="fig" rid="fig3">Figure 3</xref>, each row represents the predicted classification of traces while each column represents the ground truth data. The high classification accuracy for the annotation of individual frames is highlighted by the clear diagonal feature. We found similar classification performance for a DNN trained on non-ALEX FRET (by a DNN with only DD and DA inputs, which we will refer to as ‘ALEX-disabled’; <xref ref-type="fig" rid="fig3">Figure 3</xref> right panels) signifying the applicability of the DeepFRET approach to both ALEX and non-ALEX FRET data. The misclassification between static and dynamic smFRET traces is practically non-existent and consists of &lt;3% dynamic traces being misclassified as static, for both model types. This is important for accurately quantifying the abundance of static and dynamic subpopulations within the experimental time frame, which has been shown to have a clear experimental impact (<xref ref-type="bibr" rid="bib20">He et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Kilic et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Osuka et al., 2018</xref>; <xref ref-type="bibr" rid="bib65">Wood et al., 2012</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Confusion matrices of DeepFRET classification based on the ground truth data test.</title><p>(<bold>a</bold>) Classification accuracy of data in the six categories for the ALEX-enabled model, or the ALEX-disabled model. The absolute number of frames is shown while the fractions for each classification is displayed in parentheses (as calculated row-wise for each true label). The diagonal percentages show the accurate classification of DeepFRET (<bold>b</bold>) per-trace classification accuracy based on accepting only traces that are classified as smFRET (static/dynamic), and non-FRET data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Precision-recall of the neural network and human participants.</title><p>Precision is plotted against recall for all precision on a simulated dataset containing 46 true smFRET traces and 954 non-smFRET traces. Additionally, the precision-recall for the entire test set (20,000 traces) is plotted for the model. The error bars on the average participant performance represent the standard deviation of the three individual participants.</p><p> <supplementary-material id="fig3s1sdata1"><label>Figure 3—figure supplement 1—source data 1.</label><caption><title>Data underlying <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60404-fig3-figsupp1-data1-v1.zip"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig3-figsupp1-v1.tif"/></fig></fig-group><p>DeepFRET was found to classify bleached or aggregated frames with a 98% the true positives for ALEX-FRET model enabled (97% for the non-ALEX model), whereas only 89% (and 83% for ALEX-disabled) of the scrambled traces were correctly classified (see also <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref> for a detailed breakdown of the precision and recall). We note that the model is trained with a noise contribution that is drawn from a normal distribution of varying width (σ uniformly distributed between 0.01 and 0.30, multiplied by the maximum single fluorophore intensity) with a small contribution of gamma-distributed noise. As such, traces with σ above 0.25 are characterized by the employed DNN as ‘noisy’ (see <xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref> and Materials and methods). In a regime where transition rates are similar to the imaging temporal resolution, traces may be incorrectly classified as noisy by the model. To allow experts to accept more noisy traces or traces with fast transition rates that may appear as noisy for given imaging conditions, we integrated into the DeepFRET a visual trace simulator. This user-friendly simulator allows the generation of traces with ground truth labels of traces where all parameters are tunable to integrate the specific needs of each lab (see <xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s6">Figure 1—figure supplements 6</xref> and <xref ref-type="fig" rid="fig1s11">11</xref>).</p><p>We found the classification accuracy of each frame to be consistent with the classification accuracy on each trace, later derived from the overall most probable class given all predictions of individual frames of a trace (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, <xref ref-type="fig" rid="fig3">Figure 3b</xref>, <xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s6">Figure 1—figure supplement 6</xref> and Materials and methods). This is achieved by adding a bidirectional long short-term memory, LSTM, layer at the end of the DNN (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The LSTM layer allows coherent predictions throughout the trace and forward propagation of information detected in the first frames, such as fluorophore detection or bleaching, to the predictions for later frames. By collapsing the per-trace confusion matrix into a binary ‘smFRET’ and ‘non-smFRET’ (as shown by the cross-lines in <xref ref-type="fig" rid="fig3">Figure 3b</xref>), DeepFRET was found to be very balanced overall, with a true-positive rate of 94% for smFRET traces, and a true-negative rate of non-smFRET traces (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), resulting in an overall balanced classification accuracy of 94% for the ALEX-enabled model and 93% for the ALEX-disabled model.</p><p>We then compared the classification accuracy of DeepFRET to the accuracy of three different human operators working with smFRET to evaluate the feasibility of manually inspecting and making decisions about smFRET examples. We simulated 1000 ground truth traces, of which only 46 contained actual smFRET, at different, randomly chosen levels of noise. The participants were neither informed about the underlying distribution nor the true number of smFRET traces. The test revealed that the average performance of the human operators, scoring 0.76 ± 0.10 in precision and 0.83 ± 0.14 in recall, was close to the precision-recall curve of the DNN, on a relatively small dataset (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Notably, one participant scored slightly better than the model in both precision and recall but spent an average of 5 s per trace, which would significantly increase data treatment time, thus making this unfeasible in a high-throughput setting. The large spread on precision and recall attained by human operators on these data furthermore suggest a large possible spread in experimental outcomes and highlights the advantages of unifying, reproducible methodologies independent of human interventions. We, therefore, argue that DeepFRET is equally good, or better, as careful manual inspection while offering orders of magnitude faster data evaluation.</p></sec><sec id="s2-3"><title>DeepFRET performance on real data compared to the existing robust software for smFRET analysis</title><p>The model’s generalizability was initially examined by evaluation on real experimental smFRET data previously published by us (<xref ref-type="bibr" rid="bib58">Stella et al., 2018</xref>). The selected published dataset contains thousands of traces that included aggregates and incomplete labeled molecules, due to low labeling efficiency. Our pre-screening (using median stoichiometry and intensity distributions) and subsequent manual inspection of the data resulted in 214 traces to exhibit smFRET. Applying our trained model with a threshold of 0.85, without any other parameter tuning, recovered 228 traces, with a FRET distribution very closely matching manual selection (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The DeepFRET score of human versus machine selection displays the importance of quantitative and reproducible assessment of trace scores (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). The total data evaluation time of &lt;50 ms per trace (on a recent laptop) free of human intervention highlights the potential of DeepFRET to rapidly and reliably evaluate high throughput smFRET data. Most importantly, the trace selection is deterministic, strictly relies on the score threshold, and is thus independent of potential human cognitive bias. This demonstrates the ability of the DNN to generalize to a completely new set of experimental data, without any prior expectations for signal-to-noise ratio, anti-correlation, underlying FRET distribution, etc., offering the possibility to rapidly analyze smFRET data for structural biology insights.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Method evaluation on real previously published smFRET data.</title><p>(<bold>a</bold>) Raw FRET distribution as it would look before any sorting to remove incomplete or multi-labeled proteins, aggregates, cross talk, etc. (<bold>b</bold>, <bold>c</bold>) Comparison of DeepFRET data selection with published distributions for 0.7 in (<bold>b</bold>) and 0.85 in (<bold>c</bold>) thresholds. At the DeepFRET score threshold of 0.85, a high-fidelity data selection is achieved resulting in a similar distribution as compared to manual selection.</p><p> <supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Data underlying <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplements 2</xref>–<xref ref-type="fig" rid="fig4s4">4</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60404-fig4-data1-v1.zip"/></supplementary-material> </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>DeepFRET applied to experimentally-obtained data.</title><p>We applied DeepFRET to a previously obtained smFRET dataset on CRISPR-Cas12a. At the DeepFRET threshold of ~0.8–0.85 an excellent agreement with previously used sorting methodologies involving manual inspection of data was achieved.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Distribution of trace quality of the experimental dataset.</title><p>(<bold>a</bold>) The predicted confidence score of every trace in experimentally recorded dataset (<bold>b</bold>) Confidence score distribution of manual versus automatic selection of smFRET traces. Automatic selection exclusively accepts high-confidence traces. (<bold>c</bold>) Pearson’s test displaying no correlation (r = −0.12) between predicted trace confidence and mean FRET in the manually selected dataset.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Comparison of DeepFRET, SPARTAN, iSMS, HAMMY, and ebFRET performance on simulated, ground truth data.</title><p>(<bold>a</bold>) 200 simulated, ground truth smFRET traces (left) were merged with 1800 simulated, non-smFRET traces (middle) to yield a combined distribution of 2000 traces (right). (<bold>b</bold>) Performance of DeepFRET, SPARTAN, iSMS, HAMMY, and ebFRET on the simulated data employing various sorting criteria. In SPARTAN, six commonly used thresholds were employed on parameters including donor/acceptor correlation, SNR, intensity, FRET lifetime, exclusion of photoblinking, and step-wise drops in fluorescence intensity. In iSMS, aggregates were removed by intensity thresholds with subsequent sorting based on stoichiometries of ~0.4–0.6 and removal of FRET outliers. In HAMMY, sorting was based on intensity thresholds, while in ebFRET, sorting was based on the removal of FRET outliers (0 &lt; E &lt; 1). Data is displayed without applying correction factors. Note that, expert users can navigate through all thresholds and define their own to further, and even more accurately, optimize data selection of both SPARTAN and iSMS, while HAMMY and ebFRET may require additional manual selection or sorting via other software packages. DeepFRET only required a single quality threshold of 0.8.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Comparison of DeepFRET, SPARTAN, and iSMS performance on the published experimental data.</title><p>DeepFRET, SPARTAN, and iSMS performance on (<bold>a</bold>) non-ALEX data published by <xref ref-type="bibr" rid="bib31">Kilic et al., 2018</xref> and (<bold>b</bold>) ALEX data published by <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>. In both cases, all software packages were found to reproduce the published FRET distributions from raw tif files with a little discrepancy. The raw movies resulted in 294 and 719 traces, respectively, before sorting. Data selection relied on removing aggregates and using stoichiometries of ~0.4–0.6 for iSMS and the commonly used thresholds for SPARTAN including thresholds on donor/acceptor correlation, SNR, intensity, FRET lifetime, exclusion of photoblinking step-wise drops in fluorescence intensity, and using 10 first frames minimizing bleaching effect. Note that expert users can navigate through all thresholds and define their own to further, and even more accurately, optimize data selection of iSMS and SPARTAN. In DeepFRET, a single quality score was used to sort traces. Data selection resulted in removal of ~40–60% of the traces in all cases, and are displayed without applying correction factors.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60404-fig4-figsupp4-v1.tif"/></fig></fig-group><p>To further evaluate the performance of DeepFRET we compared it to the existing, robust, and widely used software packages for classification and treatment of smFRET data, iSMS, and SPARTAN (<xref ref-type="bibr" rid="bib27">Juette et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Preus et al., 2015</xref>), as well as ebFRET and HAMMY that focus on the kinetic analysis (<xref ref-type="bibr" rid="bib37">McKinney et al., 2006</xref>; <xref ref-type="bibr" rid="bib61">van de Meent et al., 2014</xref>). The performance was initially tested on simulated, ground truth data and further evaluated on published and publicly available experimental data (<xref ref-type="bibr" rid="bib31">Kilic et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>). For the simulated data, 200 ground truth smFRET traces were merged with 1800 simulated, non-smFRET traces and sorted by the various software packages. SPARTAN and iSMS both have sophisticated tools for automated sorting of traces (intensity, stoichiometry, and FRET thresholds in iSMS, and 26 parameter thresholds in SPARTAN including donor/acceptor correlation, SNR, intensity, FRET lifetime, and exclusion of photoblinking), while ebFRET and HAMMY relies on simple thresholds on the intensity and FRET. Here, practically the commonly used thresholds were employed in all software packages. DeepFRET was found to sort traces at least similarly to, or better than, both SPARTAN and iSMS without any parameter tuning, closely matching the underlying ground truth distribution, while ebFRET and HAMMY would require further sorting by manual selection or additional software packages for optimal results (see <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). We then compared the performance of the three software packages offering advanced sorting on experimental data from other groups (<xref ref-type="bibr" rid="bib31">Kilic et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">Hellenkamp et al., 2018</xref>). To ensure proper testing, the performance was evaluated on both ALEX and non-ALEX data. Our data show that all software packages were able to reproduce published FRET distributions from raw tif files with a little discrepancy (see <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>). We used practically the default settings in both software. We note that expert users are well trained to navigate through all thresholds and define their own to further, and even more accurately, optimize data selection. This task however may become more challenging on data where the ground truth distribution is unknown and fine-tuning parameters could be subject to bias, especially for non-specialized users. The use of a single threshold and thus minimal required expertise, offered by DeepFRET may be crucial for a greater number of scientists to take advantage of this tool.</p><p>To ensure the facile operation of DeepFRET by non-machine learning experts and users without any programming skills, we provided a standalone executable along with simple and detailed instructions on how to use it (see Materials and methods). DeepFRET implements and automates in a user-friendly and intuitive platform all common procedures for smFRET analysis: sophisticated raw image analysis from raw. tiff files; particle and signal detection and localization; pixel intensity extraction for each biomolecule on both spectral channels and background corrected fluorescence and FRET trace trajectories; automatic trace classification and sorting; unbiased analysis of number of FRET states based on BIC analysis; 2-channel fitting of idealized FRET traces using HMM analysis based on calculated number of states by BIC; data and statistical evaluation of abundance of FRET states and lifetimes; application of correction factors; and transition density plots (see <xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s9">Figure 1—figure supplements 9</xref>–<xref ref-type="fig" rid="fig1s11">11</xref>). DeepFRET furthermore offers interoperability and backward-compatible trace loading from. txt files exported from the popular iSMS software package. The software can export all results to publication-ready quality figures and also allows the extraction of data for further user-specific downstream analysis if desired.</p><p>The freely available open-source code and the underlying mathematical operations that are based on many commonly used packages (e.g. NumPy, SciPy, Matplotlib) will allow expert users to adjust features pipelining the analysis depending on their needs (see Code Availability). The DNN model is trained using Keras/TensorFlow, one of the most popular frameworks for deep learning. While the DNN is pre-trained with DeepFRET, we also provide the option for simulating new data with additional parameters offering the possibility of DNN model re-training to meet the specialized needs of trained users (e.g. multicolor FRET). The programming interface, on the other hand, allows the convenient implementation of additional scripts pipelining the analysis and to potentially expand it to additional single-molecule time-series analysis.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>smFRET is a powerful toolkit, key for exploring dynamic structural biology, but to meet its full potential, automated standardized and user-independent analysis of data is essential. Because the experimental conditions, instruments, and biological systems drastically vary across laboratories, the treatment of data based on semi-automatic methods and simplified assumptions could yield different conclusions. DeepFRET is designed to fill this void and analyze data independently of any assumptions and reproducibly across laboratories. Our experiments show that a neural network classifier trained on purely simulated smFRET time-series accurately and efficiently recognizes and classifies smFRET both in simulated ground truth data and in a real-world dataset. DeepFRET classification accuracy consistently outperformed trace selection using commonly published thresholds. Similarly, it supersedes the selection accuracy of human operators and importantly, only requiring a fraction of the time (minutes versus weeks if traces are manually selected). Such a drastic reduction of analysis times will allow the acquisition of even larger datasets expanding the field for high throughput analysis and improving the robustness of conclusion. The fact that DeepFRET does so only requiring a score threshold, as a sole human intervention, demonstrates its strength as a novel smFRET analysis method and its potential to form a reference against which the quality of the data and the structural biology insights are benchmarked. DeepFRET was found to perform accurately for both ALEX and non-ALEX smFRET data (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref>–<xref ref-type="fig" rid="fig4s4">4</xref>) highlighting its precise classification and applicability across laboratories and methods. The limited effect of human operators on data selection on the other hand illustrates its potential to contribute to the standardization of the field, increasing reproducibility across laboratories. We anticipate that DeepFRET, combined with the advent of commercial single-molecule instruments, will contribute in materializing the smFRET as a robust mainstream toolkit for structural biology labs.</p><p>DeepFRET is currently trained and thoroughly tested to operate on 2-color ALEX and non-ALEX smFRET data. Other experimental techniques such as 3- and 4-color FRET (<xref ref-type="bibr" rid="bib57">Stein et al., 2011</xref>; <xref ref-type="bibr" rid="bib68">Yoo et al., 2020</xref>), protein-induced fluorescence enhancement (PIFE; <xref ref-type="bibr" rid="bib25">Hwang and Myong, 2014</xref>), metal-induced energy transfer (MIET; <xref ref-type="bibr" rid="bib5">Chizhik et al., 2014</xref>) or intraparticle surface energy transfer (i-SET; <xref ref-type="bibr" rid="bib70">Zhou et al., 2020</xref>) could be implemented in the future through additional simulation of training data with subsequent DNN re-training and software optimization (see Materials and methods and data availability for instructions). The simulation of data in DeepFRET is based on the assumption that protein dynamics as observed by smFRET follows a Markov process. Based on this assumption, practically any kind of experimental data can be simulated, using the implemented visual trace simulator, to meet specific requirements. This may include additional noise levels above 0.30, transition probabilities larger than 0.2, traces with more than 4 FRET states, slower or faster lifetimes that may be classified as noisy, etc. In its current version, DeepFRET operates on surface-immobilized particles only, however implementing single-particle tracking as described in <xref ref-type="bibr" rid="bib4">Bohr et al., 2019</xref> would allow simultaneous tracking and extraction of dynamics through smFRET on freely diffusing particles open up exciting possibilities, for example, live cell imaging with single-particletracking (<xref ref-type="bibr" rid="bib55">Singh et al., 2020</xref>) and in vivo high throughput smFRET studies (<xref ref-type="bibr" rid="bib63">White et al., 2020</xref>).</p><p>DeepFRET’s neural network is trained to operate for smFRET data but our approach of time-series classification and sequence annotation can conveniently be extended to consider a spectrum of stochastic single-molecule trajectories of individual turnovers including tracking (<xref ref-type="bibr" rid="bib4">Bohr et al., 2019</xref>; <xref ref-type="bibr" rid="bib12">Ferro et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Lu et al., 1998</xref>; <xref ref-type="bibr" rid="bib43">Persson et al., 2013</xref>), constant force measurements (<xref ref-type="bibr" rid="bib13">Goldman et al., 2015</xref>) and blinking of individual molecules (<xref ref-type="bibr" rid="bib10">Durisic et al., 2014</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2019</xref>) using either simulated or high-quality annotated experimental data for training. Consequently, we expect the neural network of DeepFRET or similar approaches to be a paradigm shift and enable new fully automated analysis methodologies related to biomolecular recognition, protein folding and dynamics, and super resolution. Such advances are paramount for increasing the breadth and impact of single-molecule studies to be fully exploited in structural biology.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>We first define a nomenclature that will be used throughout the text and plots: <italic>DD</italic>, <italic>DA</italic>, <italic>AA</italic> (donor excitation→donor emission, donor excitation→acceptor emission, acceptor excitation→acceptor emission, respectively). A separate background signal is not considered, as we assume all model inputs to be background-corrected (i.e. background is 0).</p><sec id="s4-1"><title>Synthetic smFRET data generation</title><p>Deep learning requires large amounts of diverse data in order to generalize well to unseen data. We have developed a method to generate the required thousands of ground truth traces to cover every type of empirically observed trace, with a dedicated user interface option (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplements 2</xref> and <xref ref-type="fig" rid="fig1s6">6</xref>). This algorithm includes the generation of TIRF-microscopy smFRET traces of ALEX or non-ALEX data. The traces sample any given FRET value with tunable dye photobleaching lifetime, signal noise, dye blinking, donor bleedthrough, aggregates (i.e. more than one donor/acceptor fluorophore) of any given size, as well as a ‘scrambling’ feature, to account for fluorophore phenomena that could not be classified as stemming from smFRET.</p><p>In order to generate traces, for each pair, we first generate the underlying FRET states from an adjustable Hidden Markov model and assume unscaled unit-intensities for <italic>DD, DA, AA</italic>. Then, if the energy transferred is defined by<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>A</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>the remaining intensity of the donor is<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>and from (1), the transferred intensity is<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:msup><mml:mi/><mml:mo>∗</mml:mo></mml:msup></mml:mrow><mml:mtext> </mml:mtext><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In a perfectly-aligned setup, one can expect that<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>D</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>such that the stoichiometry S will be exactly<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Initially, all fluorophores are simulated with an intensity of 1 (with absolute scaling only adjusted after applying all other parameters). Additionally, the intensity of AA should always be 1, regardless of the current FRET state. In practice, the AA intensity may not be exactly half of DD+DA (and consequently one might observe S that deviates slightly from 0.5). To account for this, we uniformly sample ‘AA-mismatch’ as a percentage of the unit intensity signal. Upon fluorophore photobleaching, with lifetimes sampled from an exponential distribution, either DD or DA/AA is set to 0. Noise, AA-mismatch, and donor bleedthrough are added to the ground truth signals to obtain the <italic>observable</italic> DD, DA, and AA, we can calculate realistic, <italic>observable</italic> values for E and S. For each synthetic trace, the noise is drawn from a Normal (μ = 0, σ) distribution of varying σ. We found that, on top of the normally distributed noise, we could add the noise from a (centered) Gamma(k = 1, θ = 1.1) distribution multiplied with the noise amplitude at each frame (and is thus controlled via the noise parameter). This did not visually alter the spread of the distribution significantly but improved the robustness of predictions on real data, as we found empirically that the noise of experimental data never exactly followed a pure normal distribution.</p><p>State-of-the-art neural networks can achieve human-like or better performance on a wide range of classification tasks. Recently, however, it has been demonstrated how small modifications to the input can lead to wildly inaccurate outputs (<xref ref-type="bibr" rid="bib15">Goodfellow et al., 2014</xref>). During the development of our smFRET classification model, we observed how photophysical artifacting (described as ‘interesting effects’ by TJ Ha’s group [<xref ref-type="bibr" rid="bib46">Roy et al., 2008</xref>]) would lead the model to make confident yet very inaccurate predictions to fix this, our trace generation algorithm contains extensive ‘scrambling’; we found that by randomly flipping one of the channels, creating strong correlations by multiplication of the channels or adding bursts of high noise and long dark states we could avoid ‘adversarial-like’ predictions. We note that scrambled data is not meant to mimic observable data but instead to make the model robust against mispredictions on highly aberrant data that does not fall into the other observable categories.</p><p>We generated ground truth traces, where every frame of the sequence was labeled as one of five categories: ‘(B) bleached’, ‘(A) aggregate’, ‘(N) noisy’, ‘(X) scrambled’, ‘(S) static smFRET’, or ‘(D) dynamic smFRET’ (see <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplements 5</xref>–<xref ref-type="fig" rid="fig1s7">7</xref>). Additionally, we applied label smoothing with a strength of 0.05, as this has been shown to greatly improve model robustness and prediction confidence (<xref ref-type="bibr" rid="bib53">Shafahi et al., 2019</xref>).</p><p>A central element of model training is the uniform sampling of the infinite number of possible permutations of FRET data (FRET states, occupancies, lifetimes, transition pathways, and noise). For training the model, we set the following parameters (easily adjustable in the interface, see <xref ref-type="fig" rid="fig1s6">Figure 1—figure supplement 6</xref>):</p><list list-type="bullet"><list-item><p>Up to four distinct FRET states within each trace uniformly sampled between FRET values 0 and 1 with a minimum distance of 0.1 FRET between states to be able to distinguish actual transitions from noise fluctuations. The uniformly sampled occupancies as well as FRET values are shown in <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3a</xref>.</p></list-item> <list-item><p>A transition probability from one state to another, at any frame, uniformly sampled between 0 and 0.2. In a 4-state system, the maximum sampled transition probability is thus 0.2 between each of the four states yielding a total transition probability of 0.2*(4-1)=0.6 and thus a 1–0.6 = 0.4 probability of not transitioning at any given frame. The lifetime distribution of dynamic FRET states is an evenly weighted average over the exponential decays for each possible number of FRET states and transition probabilities. A Monte Carlo simulation on 10,000 traces sampling transition probabilities uniformly between 0 and 0.2 on 2–4 state traces, verifies that our training data follows the underlying model (see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3b</xref>).</p></list-item> <list-item><p>0.15 probability that the trace is an aggregate.</p></list-item> <list-item><p>Transition pathway sampling of an unbiased fraction of the entire smFRET space as shown in <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3c</xref>, where a transition density plot of 1000 simulated traces is plotted displaying a random transition pathway with no measurable bias.</p></list-item> <list-item><p>0.20 probability that a non-aggregate trace contains photoblinking.</p></list-item> <list-item><p>0.15 probability that a trace is scrambled, and in this case 0.90 probability that the scrambling is due to incorrectly colocalized fluorophores.</p></list-item> <list-item><p>Acceptor-only mismatch between 70% and 130% of the donor intensity.</p></list-item> <list-item><p>Donor-bleedthrough between 0% and 15% the donor intensity into the acceptor channel.</p></list-item> <list-item><p>Noise drawn from a Normal(0, σ) distribution with σ values uniformly distributed between 0.01 and 0.30 (see <xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>).</p></list-item> <list-item><p>0.8 probability that the noise has an additional layer of gamma noise on top, to mimic shot noise.</p></list-item> <list-item><p>Individual trace duration of 300 frames.</p></list-item> <list-item><p>Exponentially decaying photobleaching lifetime centered around 500 frames (which will generate a fraction of traces that do not contain any photobleaching).</p></list-item> <list-item><p>0.1 probability that the molecule will fall off the surface at a time given by an exponentially decaying lifetime centered around 500 frames (so it might not happen during the time of observation).</p></list-item></list><p>With these parameters, directly applicable as input for the algorithm (see Code availability), we randomly initially generated 250.000 traces of 300 frames each of randomized configurations. We then under-sampled data to balance the labels (as neural network classifiers perform worse if trained on highly class-imbalanced datasets) based on the first frame of each trace. This resulted in approximately 150,000 traces, roughly equally distributed over the five possible classes (bleaching being present in most traces naturally ends up accounting for a higher fraction of the overall frames). We used 80% for training the classifier and the remaining 20% for validation. After the training procedure, we generated an additional test set with 33.000 new traces and under-sampled it as previously, to roughly 20.000 traces, and based our statistical analysis on those alone.</p><p>We supplied only the raw features DD, DA, and AA to the model (or only DD and DA for the non-ALEX-enabled model), where for each trace, signals were normalized to the max of all signals in that trace to preserve the relative intensities between donor and acceptor. In this way, predictions done on individual smFRET traces are fully independent from every other in a given experiment, and also independent of non-standardized instrument intensity units (i.e. ‘arbitrary units’).</p></sec><sec id="s4-2"><title>Neural network model setup and hyperparameters</title><p>An LSTM-RNN (long short-term memory recurrent neural network) classifier was implemented in Keras with TensorFlow as backend. The structure of the network (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) was inspired by a recent sequence classifier for ECG time-series (<xref ref-type="bibr" rid="bib17">Hannun et al., 2019</xref>) that employs both skip connections and batch normalization as means to prevent overfitting. Here we replaced the global pooling layer with stride-1 max pooling layers, and added a bidirectional LSTM layer before the final fully connected layer, which we found lead to more temporally causal and context-sensitive predictions (e.g. if the model spots multiple bleaching steps in the beginning of a trace, this information is propagated throughout, so the whole trace can be confidently marked as aggregated).</p><p>Each residual block (‘Res’ in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) contains n = 2<sup>x</sup> filters, where x is five and is incremented by 1 at every 4th block. The kernel size k starts from 16 and is reduced by 4 at every 4th Res block, so as to learn larger-scale features and gradually smaller ones. The initial convolution has the same hyper-parameters as the first residual block. A 1 × k convolution is added in each residual block for efficiency (<xref ref-type="bibr" rid="bib19">He et al., 2016</xref>). To avoid problems with vanishing gradients throughout such a deep model, each residual block keeps a copy of the input vector and adds it to the output vector (denoted by the ‘+” symbol). The long short-term memory (LSTM) cell is bidirectional and contains 16 units, and has a dropout rate of 0.4 applied to the outputs. For each frame, the outputs are distributed among six different classes by a dense layer with softmax activation.</p><p>The model loss was minimized in batches of 32 samples with the Adam optimizer, using the default parameters and the default learning rate of 0.001. The learning rate was decreased by a factor of 10 if validation loss showed no improvement over two consecutive epochs. The training was stopped early if no improvement in the validation loss was observed over five consecutive epochs. Convolutional kernels were initialized as proposed by <xref ref-type="bibr" rid="bib18">He et al., 2015</xref>. Other layer configurations were left at their Keras defaults. The final model output is passed through a softmax layer, thus that for each frame the probabilities between all classes sum up to exactly 1. Further experimentation with optimizers and learning rates showed no significant improvement over the above configuration.</p><sec id="s4-2-1"><title>Bleaching detection</title><p>In order to avoid having single-frame bleaching triggering the remainder of the trace being marked as bleached, we employ a sliding window over the whole trace. In each window, at least 4 out of 7 frames must be marked as bleached with &gt;0.5 probability by the model. If this condition is satisfied, all frames in the window and every frame onwards is marked as bleached, and excluded from the calculation of smFRET confidence. The model predicts with &gt;99% accuracy bleaching (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Additionally, if bleaching happens faster than the first 15 frames, the whole trace is classified as bleached, regardless of model classification, as the DeepFRET score would otherwise end up being artificially inflated (see below).</p><p>For stoichiometry-based thresholding (<xref ref-type="fig" rid="fig2">Figure 2</xref>), we employed a similar sliding window but instead marked frames as bleached if the stoichiometry was outside of the range (0.3, 0.7).</p></sec><sec id="s4-2-2"><title>Precision and recall</title><p>We use precision and recall to quantify classifier performance. These are defined as,<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>:</mml:mo><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">R</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where Tp, Fp, Fn are True positive, False positive, and False negative, respectively.</p></sec><sec id="s4-2-3"><title>DeepFRET score calculation and trace classification</title><p>In order to calculate the confidence score, probabilities for all categories for each frame are first predicted by the model, and bleached frames (see above) excluded from the score calculation. The average probability p<italic>i</italic> over all frames <italic>t</italic>, for each of the remaining five categories is calculated, resulting in five category scores P<italic>i</italic> for each category <italic>i</italic>.<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Static smFRET (S), dynamic smFRET (D) scores are summed into the final DeepFRET score, and aggregate (A), noisy (N), and scrambled (X) scores ignored for calculation of this (but retained and displayed for explainability for the user). See <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplements 5</xref>–<xref ref-type="fig" rid="fig1s8">8</xref> for examples on all trace types.</p></sec></sec><sec id="s4-3"><title>Model performance evaluation</title><sec id="s4-3-1"><title>Noise level of synthetic data</title><p>We changed the label of traces to ‘noisy’ if the initial noise was drawn from a normal(μ = 0, σ) with σ above 0.25. Traces above this level of noise could no longer statistically be approximated as normally distributed by D’Agostino-Pearson two-sided test for normality (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>; which is a requirement for fitting the correct number of FRET states in a trace, using a mixture model). Although a σ of 0.20 also fulfilled the p&lt;0.05 test statistic, we chose to opt for a limit of 0.25, as we found that the neural network would otherwise tend to discard less noisy data too frequently.</p></sec><sec id="s4-3-2"><title>Trends in human versus machine selection</title><p>To test for differences in the way a human versus our trained model would select traces, three participants partook in the manual selection of generated data (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), similar to that of <xref ref-type="fig" rid="fig2">Figure 2</xref>, only this time with 1000 traces, wherein 46 were true smFRET traces and 954 non-usable traces. The number of true smFRET traces and underlying distributions were unknown to the participants.</p></sec><sec id="s4-3-3"><title>Performance test and comparison with existing software</title><p>For testing simple thresholding versus DeepFRET (<xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref>–<xref ref-type="fig" rid="fig2s2">2</xref> and <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>) we generated data with the following parameters:</p><list list-type="bullet"><list-item><p>Acceptor-only mismatch between 70% and 130% of the donor intensity.</p></list-item> <list-item><p>Donor-bleedthrough of 5% of the donor intensity into the acceptor channel.</p></list-item> <list-item><p>Noise drawn from a normal(σ = 0.11) distribution</p></list-item> <list-item><p>1 (0.5 FRET), 2 (0.3, 0.7 FRET), or 3 FRET states (0.2, 0.5, 0.8 FRET)</p></list-item> <list-item><p>Transition probability of 0.1 between states, at each frame.</p></list-item></list><p>Other parameters were set to the same value as what is used to generate training data. Furthermore, all generated ground truth traces that did not bleach were discarded.</p><p>Our definition of ‘simple thresholding’ is based on single-molecule intensity, median stoichiometry, and the presence of bleaching. Here we chose not to use any values for anti-correlation as this assumes that all molecules of interest are equally dynamic, when smFRET studies have shown that this may not always be the case (<xref ref-type="bibr" rid="bib20">He et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Kilic et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Osuka et al., 2018</xref>).</p></sec></sec><sec id="s4-4"><title>Extra features of the software platform</title><sec id="s4-4-1"><title>Hidden Markov model and statistical analysis</title><p>The DeepFRET GUI has the option to fit traces with a Hidden Markov model, with adjustable strictness on the number of states, according to recent best practices for smFRET data analysis, including the ability to switch between predicting states from raw fluorescence intensities or EFRET values (<xref ref-type="bibr" rid="bib30">Kelly et al., 2012</xref>). We fit the traces using the pomegranate implementation of the Baum-Welch algorithm (<xref ref-type="bibr" rid="bib51">Schreiber, 2018</xref>). We further provide the option to predict state values directly from the Markov Model or from the median of the classified frames for each trace, to maintain compatibility and comparability with current results in the field. We provide clustering of subsequent transition density plots, lifetime estimates with detection of degenerate states, and publication-ready plots for Pearson's correlation coefficients, DD/DA histograms, and EFRET-stoichiometry histograms.</p><p>The Hidden Markov model was verified on externally available data from the kinSoft challenge, as well as simulated data produced within DeepFRET.</p></sec></sec><sec id="s4-5"><title>Data availability</title><p>All data used for model training and instructions on how to use it, is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hatzakislab/DeepFRET-Model/">https://github.com/hatzakislab/DeepFRET-Model</ext-link> (<xref ref-type="bibr" rid="bib60">Thomsen, 2020</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/DeepFRET-Model">https://github.com/elifesciences-publications/DeepFRET-Model</ext-link>).</p></sec><sec id="s4-6"><title>Code availability</title><p>We provide DeepFRET as an accessible GUI for everyone, as well as the Python source code for expert users. The code for the GUI as well as compiled executables, with instructions for how to edit and recompile the GUI is located at <ext-link ext-link-type="uri" xlink:href="https://github.com/hatzakislab/DeepFRET-GUI">https://github.com/hatzakislab/DeepFRET-GUI</ext-link>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Soeren SR Bohr and Henrik Pinholt for fruitful discussions. GM and NSH are members of the Integrative Structural Biology Cluster (ISBUC) at the University of Copenhagen.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Validation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Validation, Investigation, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Data curation, Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Validation, Writing - review and editing</p></fn><fn fn-type="con" id="con7"><p>Resources, Data curation, Supervision, Funding acquisition</p></fn><fn fn-type="con" id="con8"><p>Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Resources, Data curation, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-60404-transrepform-v1.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data sets used for figures are provided as source data in the manuscript Source code and executable can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/hatzakislab/DeepFRET-Model/">https://github.com/hatzakislab/DeepFRET-Model/</ext-link> (copy archived at<ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/DeepFRET-Model">https://github.com/elifesciences-publications/DeepFRET-Model</ext-link>), <ext-link ext-link-type="uri" xlink:href="https://github.com/hatzakislab/DeepFRET-GUI">https://github.com/hatzakislab/DeepFRET-GUI</ext-link>. All source data are also available at: <ext-link ext-link-type="uri" xlink:href="https://sid.erda.dk/sharelink/AOEC0wxxXO">https://sid.erda.dk/sharelink/AOEC0wxxXO</ext-link>.</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Kilic</surname><given-names>S</given-names></name><name><surname>Felekyan</surname><given-names>S</given-names></name><name><surname>Doroshenko</surname><given-names>O</given-names></name><name><surname>Boichenko</surname><given-names>I</given-names></name><name><surname>Dimura</surname><given-names>M</given-names></name><name><surname>Vardanyan</surname><given-names>H</given-names></name><name><surname>Bryan</surname><given-names>LC</given-names></name><name><surname>Arya</surname><given-names>G</given-names></name><name><surname>Seidel</surname><given-names>CAM</given-names></name><name><surname>Fierz</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Single-molecule FRET reveals multiscale chromatin dynamics modulated by HP1α</data-title><source>Zenodo</source><pub-id assigning-authority="Zenodo" pub-id-type="doi">10.5281/zenodo.1069675</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Hellenkamp</surname><given-names>B</given-names></name><name><surname>Schmid</surname><given-names>S</given-names></name><name><surname>Doroshenko</surname><given-names>O</given-names></name><name><surname>Opanasyuk</surname><given-names>O</given-names></name><name><surname>Kühnemuth</surname><given-names>R</given-names></name><name><surname>Rezaei</surname><given-names>Adariani S</given-names></name><name><surname>Ambrose</surname><given-names>B</given-names></name><name><surname>Aznauryan</surname><given-names>M</given-names></name><name><surname>Barth</surname><given-names>A</given-names></name><name><surname>Birkedal</surname><given-names>V</given-names></name><name><surname>Bowen</surname><given-names>ME</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Cordes</surname><given-names>T</given-names></name><name><surname>Eilert</surname><given-names>T</given-names></name><name><surname>Fijen</surname><given-names>C</given-names></name><name><surname>Gebhardt</surname><given-names>C</given-names></name><name><surname>Götz</surname><given-names>M</given-names></name><name><surname>Gouridis</surname><given-names>G</given-names></name><name><surname>Gratton</surname><given-names>E</given-names></name><name><surname>Ha</surname><given-names>T</given-names></name><name><surname>Hao</surname><given-names>P</given-names></name><name><surname>Hanke</surname><given-names>CA</given-names></name><name><surname>Hartmann</surname><given-names>A</given-names></name><name><surname>Hendrix</surname><given-names>J</given-names></name><name><surname>Hildebrandt</surname><given-names>LL</given-names></name><name><surname>Hirschfeld</surname><given-names>V</given-names></name><name><surname>Hohlbein</surname><given-names>J</given-names></name><name><surname>Hua</surname><given-names>B</given-names></name><name><surname>Hübner</surname><given-names>CG</given-names></name><name><surname>Kallis</surname><given-names>E</given-names></name><name><surname>Kapanidis</surname><given-names>AN</given-names></name><name><surname>Kim</surname><given-names>JY</given-names></name><name><surname>Krainer</surname><given-names>G</given-names></name><name><surname>Lamb</surname><given-names>DC</given-names></name><name><surname>Lee</surname><given-names>NK</given-names></name><name><surname>Lemke</surname><given-names>EA</given-names></name><name><surname>Levesque</surname><given-names>B</given-names></name><name><surname>Levitus</surname><given-names>M</given-names></name><name><surname>McCann</surname><given-names>JJ</given-names></name><name><surname>Naredi-Rainer</surname><given-names>N</given-names></name><name><surname>Nettels</surname><given-names>D</given-names></name><name><surname>Ngo</surname><given-names>T</given-names></name><name><surname>Qiu</surname><given-names>R</given-names></name><name><surname>Robb</surname><given-names>NC</given-names></name><name><surname>Röcker</surname><given-names>C</given-names></name><name><surname>Sanabria</surname><given-names>H</given-names></name><name><surname>Schlierf</surname><given-names>M</given-names></name><name><surname>Schröder</surname><given-names>T</given-names></name><name><surname>Schuler</surname><given-names>B</given-names></name><name><surname>Seidel</surname><given-names>H</given-names></name><name><surname>Streit</surname><given-names>L</given-names></name><name><surname>Thurn</surname><given-names>J</given-names></name><name><surname>Tinnefeld</surname><given-names>P</given-names></name><name><surname>Tyagi</surname><given-names>S</given-names></name><name><surname>Vandenberk</surname><given-names>N</given-names></name><name><surname>Vera</surname><given-names>AM</given-names></name><name><surname>Weninger</surname><given-names>KR</given-names></name><name><surname>Wünsch</surname><given-names>B</given-names></name><name><surname>Yanez-Orozco</surname><given-names>IS</given-names></name><name><surname>Michaelis</surname><given-names>J</given-names></name><name><surname>Seidel</surname><given-names>CAM</given-names></name><name><surname>Craggs</surname><given-names>TD</given-names></name><name><surname>Hugel</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Precision and accuracy of single-molecule FRET measurements-a multi-laboratory benchmark study</data-title><source>Zenodo</source><pub-id assigning-authority="Zenodo" pub-id-type="doi">10.5281/zenodo.1249497</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Algar</surname> <given-names>WR</given-names></name><name><surname>Hildebrandt</surname> <given-names>N</given-names></name><name><surname>Vogel</surname> <given-names>SS</given-names></name><name><surname>Medintz</surname> <given-names>IL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>FRET as a biomolecular research tool - understanding its potential while avoiding pitfalls</article-title><source>Nature Methods</source><volume>16</volume><fpage>815</fpage><lpage>829</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0530-8</pub-id><pub-id pub-id-type="pmid">31471616</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>ATLAS collaboration</collab></person-group><year iso-8601-date="2014">2014</year><article-title>A neural network clustering algorithm for the ATLAS silicon pixel detector</article-title><source>Journal of Instrumentation</source><volume>9</volume><elocation-id>P09009</elocation-id><pub-id pub-id-type="doi">10.1088/1748-0221/9/09/P09009</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Kutra</surname> <given-names>D</given-names></name><name><surname>Kroeger</surname> <given-names>T</given-names></name><name><surname>Straehle</surname> <given-names>CN</given-names></name><name><surname>Kausler</surname> <given-names>BX</given-names></name><name><surname>Haubold</surname> <given-names>C</given-names></name><name><surname>Schiegg</surname> <given-names>M</given-names></name><name><surname>Ales</surname> <given-names>J</given-names></name><name><surname>Beier</surname> <given-names>T</given-names></name><name><surname>Rudy</surname> <given-names>M</given-names></name><name><surname>Eren</surname> <given-names>K</given-names></name><name><surname>Cervantes</surname> <given-names>JI</given-names></name><name><surname>Xu</surname> <given-names>B</given-names></name><name><surname>Beuttenmueller</surname> <given-names>F</given-names></name><name><surname>Wolny</surname> <given-names>A</given-names></name><name><surname>Zhang</surname> <given-names>C</given-names></name><name><surname>Koethe</surname> <given-names>U</given-names></name><name><surname>Hamprecht</surname> <given-names>FA</given-names></name><name><surname>Kreshuk</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Ilastik: interactive machine learning for (bio)image analysis</article-title><source>Nature Methods</source><volume>16</volume><fpage>1226</fpage><lpage>1232</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0582-9</pub-id><pub-id pub-id-type="pmid">31570887</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohr</surname> <given-names>SS</given-names></name><name><surname>Lund</surname> <given-names>PM</given-names></name><name><surname>Kallenbach</surname> <given-names>AS</given-names></name><name><surname>Pinholt</surname> <given-names>H</given-names></name><name><surname>Thomsen</surname> <given-names>J</given-names></name><name><surname>Iversen</surname> <given-names>L</given-names></name><name><surname>Svendsen</surname> <given-names>A</given-names></name><name><surname>Christensen</surname> <given-names>SM</given-names></name><name><surname>Hatzakis</surname> <given-names>NS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Direct observation of Thermomyces lanuginosus lipase diffusional states by single particle tracking and their remodeling by mutations and inhibition</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>16169</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-52539-1</pub-id><pub-id pub-id-type="pmid">31700110</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chizhik</surname> <given-names>AI</given-names></name><name><surname>Rother</surname> <given-names>J</given-names></name><name><surname>Gregor</surname> <given-names>I</given-names></name><name><surname>Janshoff</surname> <given-names>A</given-names></name><name><surname>Enderlein</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Metal-induced energy transfer for live cell nanoscopy</article-title><source>Nature Photonics</source><volume>8</volume><fpage>124</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1038/nphoton.2013.345</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christiansen</surname> <given-names>EM</given-names></name><name><surname>Yang</surname> <given-names>SJ</given-names></name><name><surname>Ando</surname> <given-names>DM</given-names></name><name><surname>Javaherian</surname> <given-names>A</given-names></name><name><surname>Skibinski</surname> <given-names>G</given-names></name><name><surname>Lipnick</surname> <given-names>S</given-names></name><name><surname>Mount</surname> <given-names>E</given-names></name><name><surname>O'Neil</surname> <given-names>A</given-names></name><name><surname>Shah</surname> <given-names>K</given-names></name><name><surname>Lee</surname> <given-names>AK</given-names></name><name><surname>Goyal</surname> <given-names>P</given-names></name><name><surname>Fedus</surname> <given-names>W</given-names></name><name><surname>Poplin</surname> <given-names>R</given-names></name><name><surname>Esteva</surname> <given-names>A</given-names></name><name><surname>Berndl</surname> <given-names>M</given-names></name><name><surname>Rubin</surname> <given-names>LL</given-names></name><name><surname>Nelson</surname> <given-names>P</given-names></name><name><surname>Finkbeiner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>In Silico labeling: predicting fluorescent labels in unlabeled images</article-title><source>Cell</source><volume>173</volume><fpage>792</fpage><lpage>803</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.03.040</pub-id><pub-id pub-id-type="pmid">29656897</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craggs</surname> <given-names>TD</given-names></name><name><surname>Kapanidis</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Six steps closer to FRET-driven structural biology</article-title><source>Nature Methods</source><volume>9</volume><fpage>1157</fpage><lpage>1158</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2257</pub-id><pub-id pub-id-type="pmid">23223168</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimura</surname> <given-names>M</given-names></name><name><surname>Peulen</surname> <given-names>TO</given-names></name><name><surname>Hanke</surname> <given-names>CA</given-names></name><name><surname>Prakash</surname> <given-names>A</given-names></name><name><surname>Gohlke</surname> <given-names>H</given-names></name><name><surname>Seidel</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Quantitative FRET studies and integrative modeling unravel the structure and dynamics of biomolecular systems</article-title><source>Current Opinion in Structural Biology</source><volume>40</volume><fpage>163</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1016/j.sbi.2016.11.012</pub-id><pub-id pub-id-type="pmid">27939973</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dulin</surname> <given-names>D</given-names></name><name><surname>Bauer</surname> <given-names>DLV</given-names></name><name><surname>Malinen</surname> <given-names>AM</given-names></name><name><surname>Bakermans</surname> <given-names>JJW</given-names></name><name><surname>Kaller</surname> <given-names>M</given-names></name><name><surname>Morichaud</surname> <given-names>Z</given-names></name><name><surname>Petushkov</surname> <given-names>I</given-names></name><name><surname>Depken</surname> <given-names>M</given-names></name><name><surname>Brodolin</surname> <given-names>K</given-names></name><name><surname>Kulbachinskiy</surname> <given-names>A</given-names></name><name><surname>Kapanidis</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pausing controls branching between productive and non-productive pathways during initial transcription in bacteria</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1478</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-03902-9</pub-id><pub-id pub-id-type="pmid">29662062</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durisic</surname> <given-names>N</given-names></name><name><surname>Laparra-Cuervo</surname> <given-names>L</given-names></name><name><surname>Sandoval-Álvarez</surname> <given-names>A</given-names></name><name><surname>Borbely</surname> <given-names>JS</given-names></name><name><surname>Lakadamyali</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Single-molecule evaluation of fluorescent protein photoactivation efficiency using an in vivo nanotemplate</article-title><source>Nature Methods</source><volume>11</volume><fpage>156</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2784</pub-id><pub-id pub-id-type="pmid">24390439</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falk</surname> <given-names>T</given-names></name><name><surname>Mai</surname> <given-names>D</given-names></name><name><surname>Bensch</surname> <given-names>R</given-names></name><name><surname>Çiçek</surname> <given-names>Ö</given-names></name><name><surname>Abdulkadir</surname> <given-names>A</given-names></name><name><surname>Marrakchi</surname> <given-names>Y</given-names></name><name><surname>Böhm</surname> <given-names>A</given-names></name><name><surname>Deubner</surname> <given-names>J</given-names></name><name><surname>Jäckel</surname> <given-names>Z</given-names></name><name><surname>Seiwald</surname> <given-names>K</given-names></name><name><surname>Dovzhenko</surname> <given-names>A</given-names></name><name><surname>Tietz</surname> <given-names>O</given-names></name><name><surname>Dal Bosco</surname> <given-names>C</given-names></name><name><surname>Walsh</surname> <given-names>S</given-names></name><name><surname>Saltukoglu</surname> <given-names>D</given-names></name><name><surname>Tay</surname> <given-names>TL</given-names></name><name><surname>Prinz</surname> <given-names>M</given-names></name><name><surname>Palme</surname> <given-names>K</given-names></name><name><surname>Simons</surname> <given-names>M</given-names></name><name><surname>Diester</surname> <given-names>I</given-names></name><name><surname>Brox</surname> <given-names>T</given-names></name><name><surname>Ronneberger</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>U-Net: deep learning for cell counting, detection, and morphometry</article-title><source>Nature Methods</source><volume>16</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0261-2</pub-id><pub-id pub-id-type="pmid">30559429</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferro</surname> <given-names>LS</given-names></name><name><surname>Can</surname> <given-names>S</given-names></name><name><surname>Turner</surname> <given-names>MA</given-names></name><name><surname>ElShenawy</surname> <given-names>MM</given-names></name><name><surname>Yildiz</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Kinesin and dynein use distinct mechanisms to bypass obstacles</article-title><source>eLife</source><volume>8</volume><elocation-id>e48629</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.48629</pub-id><pub-id pub-id-type="pmid">31498080</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname> <given-names>DH</given-names></name><name><surname>Kaiser</surname> <given-names>CM</given-names></name><name><surname>Milin</surname> <given-names>A</given-names></name><name><surname>Righini</surname> <given-names>M</given-names></name><name><surname>Tinoco</surname> <given-names>I</given-names></name><name><surname>Bustamante</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Ribosome. Mechanical force releases nascent chain-mediated ribosome arrest in vitro and in vivo</article-title><source>Science</source><volume>348</volume><fpage>457</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1126/science.1261909</pub-id><pub-id pub-id-type="pmid">25908824</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gómez-García</surname> <given-names>PA</given-names></name><name><surname>Garbacik</surname> <given-names>ET</given-names></name><name><surname>Otterstrom</surname> <given-names>JJ</given-names></name><name><surname>Garcia-Parajo</surname> <given-names>MF</given-names></name><name><surname>Lakadamyali</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Excitation-multiplexed multicolor superresolution imaging with fm-STORM and fm-DNA-PAINT</article-title><source>PNAS</source><volume>115</volume><fpage>12991</fpage><lpage>12996</lpage><pub-id pub-id-type="doi">10.1073/pnas.1804725115</pub-id><pub-id pub-id-type="pmid">30509979</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Goodfellow</surname> <given-names>I</given-names></name><name><surname>Shlens</surname> <given-names>J</given-names></name><name><surname>Szegedy</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Explaining and harnessing adversarial examples</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6572">https://arxiv.org/abs/1412.6572</ext-link></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenfeld</surname> <given-names>M</given-names></name><name><surname>Pavlichin</surname> <given-names>DS</given-names></name><name><surname>Mabuchi</surname> <given-names>H</given-names></name><name><surname>Herschlag</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Single molecule analysis research tool (SMART): an integrated approach for analyzing single molecule data</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e30024</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0030024</pub-id><pub-id pub-id-type="pmid">22363412</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hannun</surname> <given-names>AY</given-names></name><name><surname>Rajpurkar</surname> <given-names>P</given-names></name><name><surname>Haghpanahi</surname> <given-names>M</given-names></name><name><surname>Tison</surname> <given-names>GH</given-names></name><name><surname>Bourn</surname> <given-names>C</given-names></name><name><surname>Turakhia</surname> <given-names>MP</given-names></name><name><surname>Ng</surname> <given-names>AY</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network</article-title><source>Nature Medicine</source><volume>25</volume><fpage>65</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1038/s41591-018-0268-3</pub-id><pub-id pub-id-type="pmid">30617320</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname> <given-names>K</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Ren</surname> <given-names>S</given-names></name><name><surname>Sun</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Delving deep into rectifiers: surpassing Human-Level performance on ImageNet classification in: 2015 IEEE International Conference on Computer Vision (ICCV)</article-title><conf-name>Presented at the 2015 IEEE International Conference on Computer Vision</conf-name><fpage>1026</fpage><lpage>1034</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2015.123</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname> <given-names>K</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Ren</surname> <given-names>S</given-names></name><name><surname>Sun</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deep residual learning for image recognition, in: ieee conference on computer vision and pattern recognition (CVPR)</article-title><conf-name>Presented at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE</conf-name><fpage>770</fpage><lpage>778</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2016.90</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname> <given-names>S</given-names></name><name><surname>Yang</surname> <given-names>C</given-names></name><name><surname>Peng</surname> <given-names>S</given-names></name><name><surname>Chen</surname> <given-names>C</given-names></name><name><surname>Zhao</surname> <given-names>XS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-molecule study on conformational dynamics of M.HhaI</article-title><source>RSC Advances</source><volume>9</volume><fpage>14745</fpage><lpage>14749</lpage><pub-id pub-id-type="doi">10.1039/C9RA00021F</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hellenkamp</surname> <given-names>B</given-names></name><name><surname>Schmid</surname> <given-names>S</given-names></name><name><surname>Doroshenko</surname> <given-names>O</given-names></name><name><surname>Opanasyuk</surname> <given-names>O</given-names></name><name><surname>Kühnemuth</surname> <given-names>R</given-names></name><name><surname>Rezaei Adariani</surname> <given-names>S</given-names></name><name><surname>Ambrose</surname> <given-names>B</given-names></name><name><surname>Aznauryan</surname> <given-names>M</given-names></name><name><surname>Barth</surname> <given-names>A</given-names></name><name><surname>Birkedal</surname> <given-names>V</given-names></name><name><surname>Bowen</surname> <given-names>ME</given-names></name><name><surname>Chen</surname> <given-names>H</given-names></name><name><surname>Cordes</surname> <given-names>T</given-names></name><name><surname>Eilert</surname> <given-names>T</given-names></name><name><surname>Fijen</surname> <given-names>C</given-names></name><name><surname>Gebhardt</surname> <given-names>C</given-names></name><name><surname>Götz</surname> <given-names>M</given-names></name><name><surname>Gouridis</surname> <given-names>G</given-names></name><name><surname>Gratton</surname> <given-names>E</given-names></name><name><surname>Ha</surname> <given-names>T</given-names></name><name><surname>Hao</surname> <given-names>P</given-names></name><name><surname>Hanke</surname> <given-names>CA</given-names></name><name><surname>Hartmann</surname> <given-names>A</given-names></name><name><surname>Hendrix</surname> <given-names>J</given-names></name><name><surname>Hildebrandt</surname> <given-names>LL</given-names></name><name><surname>Hirschfeld</surname> <given-names>V</given-names></name><name><surname>Hohlbein</surname> <given-names>J</given-names></name><name><surname>Hua</surname> <given-names>B</given-names></name><name><surname>Hübner</surname> <given-names>CG</given-names></name><name><surname>Kallis</surname> <given-names>E</given-names></name><name><surname>Kapanidis</surname> <given-names>AN</given-names></name><name><surname>Kim</surname> <given-names>JY</given-names></name><name><surname>Krainer</surname> <given-names>G</given-names></name><name><surname>Lamb</surname> <given-names>DC</given-names></name><name><surname>Lee</surname> <given-names>NK</given-names></name><name><surname>Lemke</surname> <given-names>EA</given-names></name><name><surname>Levesque</surname> <given-names>B</given-names></name><name><surname>Levitus</surname> <given-names>M</given-names></name><name><surname>McCann</surname> <given-names>JJ</given-names></name><name><surname>Naredi-Rainer</surname> <given-names>N</given-names></name><name><surname>Nettels</surname> <given-names>D</given-names></name><name><surname>Ngo</surname> <given-names>T</given-names></name><name><surname>Qiu</surname> <given-names>R</given-names></name><name><surname>Robb</surname> <given-names>NC</given-names></name><name><surname>Röcker</surname> <given-names>C</given-names></name><name><surname>Sanabria</surname> <given-names>H</given-names></name><name><surname>Schlierf</surname> <given-names>M</given-names></name><name><surname>Schröder</surname> <given-names>T</given-names></name><name><surname>Schuler</surname> <given-names>B</given-names></name><name><surname>Seidel</surname> <given-names>H</given-names></name><name><surname>Streit</surname> <given-names>L</given-names></name><name><surname>Thurn</surname> <given-names>J</given-names></name><name><surname>Tinnefeld</surname> <given-names>P</given-names></name><name><surname>Tyagi</surname> <given-names>S</given-names></name><name><surname>Vandenberk</surname> <given-names>N</given-names></name><name><surname>Vera</surname> <given-names>AM</given-names></name><name><surname>Weninger</surname> <given-names>KR</given-names></name><name><surname>Wünsch</surname> <given-names>B</given-names></name><name><surname>Yanez-Orozco</surname> <given-names>IS</given-names></name><name><surname>Michaelis</surname> <given-names>J</given-names></name><name><surname>Seidel</surname> <given-names>CAM</given-names></name><name><surname>Craggs</surname> <given-names>TD</given-names></name><name><surname>Hugel</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Precision and accuracy of single-molecule FRET measurements-a multi-laboratory benchmark study</article-title><source>Nature Methods</source><volume>15</volume><fpage>669</fpage><lpage>676</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0085-0</pub-id><pub-id pub-id-type="pmid">30171252</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hohlbein</surname> <given-names>J</given-names></name><name><surname>Craggs</surname> <given-names>TD</given-names></name><name><surname>Cordes</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Alternating-laser excitation: single-molecule FRET and beyond</article-title><source>Chem. Soc. Rev.</source><volume>43</volume><fpage>1156</fpage><lpage>1171</lpage><pub-id pub-id-type="doi">10.1039/C3CS60233H</pub-id><pub-id pub-id-type="pmid">24037326</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmstrom</surname> <given-names>ED</given-names></name><name><surname>Liu</surname> <given-names>Z</given-names></name><name><surname>Nettels</surname> <given-names>D</given-names></name><name><surname>Best</surname> <given-names>RB</given-names></name><name><surname>Schuler</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Disordered RNA chaperones can enhance nucleic acid folding via local charge screening</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2453</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10356-0</pub-id><pub-id pub-id-type="pmid">31165735</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hon</surname> <given-names>J</given-names></name><name><surname>Gonzalez</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Bayesian-Estimated hierarchical HMMs enable robust analysis of Single-Molecule kinetic heterogeneity</article-title><source>Biophysical Journal</source><volume>116</volume><fpage>1790</fpage><lpage>1802</lpage><pub-id pub-id-type="doi">10.1016/j.bpj.2019.02.031</pub-id><pub-id pub-id-type="pmid">31010664</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hwang</surname> <given-names>H</given-names></name><name><surname>Myong</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Protein induced fluorescence enhancement (PIFE) for probing protein-nucleic acid interactions</article-title><source>Chem. Soc. Rev.</source><volume>43</volume><fpage>1221</fpage><lpage>1229</lpage><pub-id pub-id-type="doi">10.1039/C3CS60201J</pub-id><pub-id pub-id-type="pmid">24056732</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>DT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Setting the standards for machine learning in biology</article-title><source>Nature Reviews Molecular Cell Biology</source><volume>20</volume><fpage>659</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1038/s41580-019-0176-5</pub-id><pub-id pub-id-type="pmid">31548714</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juette</surname> <given-names>MF</given-names></name><name><surname>Terry</surname> <given-names>DS</given-names></name><name><surname>Wasserman</surname> <given-names>MR</given-names></name><name><surname>Altman</surname> <given-names>RB</given-names></name><name><surname>Zhou</surname> <given-names>Z</given-names></name><name><surname>Zhao</surname> <given-names>H</given-names></name><name><surname>Blanchard</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Single-molecule imaging of non-equilibrium molecular ensembles on the millisecond timescale</article-title><source>Nature Methods</source><volume>13</volume><fpage>341</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3769</pub-id><pub-id pub-id-type="pmid">26878382</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalinin</surname> <given-names>S</given-names></name><name><surname>Peulen</surname> <given-names>T</given-names></name><name><surname>Sindbert</surname> <given-names>S</given-names></name><name><surname>Rothwell</surname> <given-names>PJ</given-names></name><name><surname>Berger</surname> <given-names>S</given-names></name><name><surname>Restle</surname> <given-names>T</given-names></name><name><surname>Goody</surname> <given-names>RS</given-names></name><name><surname>Gohlke</surname> <given-names>H</given-names></name><name><surname>Seidel</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A toolkit and benchmark study for FRET-restrained high-precision structural modeling</article-title><source>Nature Methods</source><volume>9</volume><fpage>1218</fpage><lpage>1225</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2222</pub-id><pub-id pub-id-type="pmid">23142871</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Karim</surname> <given-names>F</given-names></name><name><surname>Majumdar</surname> <given-names>S</given-names></name><name><surname>Darabi</surname> <given-names>H</given-names></name><name><surname>Chen</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>LSTM fully convolutional networks for time series classification</article-title><conf-name>IEEE Access</conf-name><fpage>1662</fpage><lpage>1669</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2017.2779939</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname> <given-names>D</given-names></name><name><surname>Dillingham</surname> <given-names>M</given-names></name><name><surname>Hudson</surname> <given-names>A</given-names></name><name><surname>Wiesner</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A new method for inferring hidden markov models from noisy time sequences</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e29703</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0029703</pub-id><pub-id pub-id-type="pmid">22247783</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kilic</surname> <given-names>S</given-names></name><name><surname>Felekyan</surname> <given-names>S</given-names></name><name><surname>Doroshenko</surname> <given-names>O</given-names></name><name><surname>Boichenko</surname> <given-names>I</given-names></name><name><surname>Dimura</surname> <given-names>M</given-names></name><name><surname>Vardanyan</surname> <given-names>H</given-names></name><name><surname>Bryan</surname> <given-names>LC</given-names></name><name><surname>Arya</surname> <given-names>G</given-names></name><name><surname>Seidel</surname> <given-names>CAM</given-names></name><name><surname>Fierz</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single-molecule FRET reveals multiscale chromatin dynamics modulated by HP1α</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>235</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-02619-5</pub-id><pub-id pub-id-type="pmid">29339721</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname> <given-names>Y</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Hinton</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning</article-title><source>Nature</source><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>NK</given-names></name><name><surname>Kapanidis</surname> <given-names>AN</given-names></name><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Michalet</surname> <given-names>X</given-names></name><name><surname>Mukhopadhyay</surname> <given-names>J</given-names></name><name><surname>Ebright</surname> <given-names>RH</given-names></name><name><surname>Weiss</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Accurate FRET measurements within single diffusing biomolecules using alternating-laser excitation</article-title><source>Biophysical Journal</source><volume>88</volume><fpage>2939</fpage><lpage>2953</lpage><pub-id pub-id-type="doi">10.1529/biophysj.104.054114</pub-id><pub-id pub-id-type="pmid">15653725</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerner</surname> <given-names>E</given-names></name><name><surname>Cordes</surname> <given-names>T</given-names></name><name><surname>Ingargiola</surname> <given-names>A</given-names></name><name><surname>Alhadid</surname> <given-names>Y</given-names></name><name><surname>Chung</surname> <given-names>S</given-names></name><name><surname>Michalet</surname> <given-names>X</given-names></name><name><surname>Weiss</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Toward dynamic structural biology: two decades of single-molecule förster resonance energy transfer</article-title><source>Science</source><volume>359</volume><elocation-id>eaan1133</elocation-id><pub-id pub-id-type="doi">10.1126/science.aan1133</pub-id><pub-id pub-id-type="pmid">29348210</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname> <given-names>HP</given-names></name><name><surname>Xun</surname> <given-names>L</given-names></name><name><surname>Xie</surname> <given-names>XS</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Single-Molecule enzymatic dynamics</article-title><source>Science</source><volume>282</volume><fpage>1877</fpage><lpage>1882</lpage><pub-id pub-id-type="doi">10.1126/science.282.5395.1877</pub-id><pub-id pub-id-type="pmid">9836635</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsunaga</surname> <given-names>Y</given-names></name><name><surname>Sugita</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Linking <italic>time-series</italic> of single-molecule experiments with molecular dynamics simulations by machine learning</article-title><source>eLife</source><volume>7</volume><elocation-id>e32668</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32668</pub-id><pub-id pub-id-type="pmid">29723137</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKinney</surname> <given-names>SA</given-names></name><name><surname>Joo</surname> <given-names>C</given-names></name><name><surname>Ha</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Analysis of single-molecule FRET trajectories using hidden markov modeling</article-title><source>Biophysical Journal</source><volume>91</volume><fpage>1941</fpage><lpage>1951</lpage><pub-id pub-id-type="doi">10.1529/biophysj.106.082487</pub-id><pub-id pub-id-type="pmid">16766620</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newton</surname> <given-names>MD</given-names></name><name><surname>Taylor</surname> <given-names>BJ</given-names></name><name><surname>Driessen</surname> <given-names>RPC</given-names></name><name><surname>Roos</surname> <given-names>L</given-names></name><name><surname>Cvetesic</surname> <given-names>N</given-names></name><name><surname>Allyjaun</surname> <given-names>S</given-names></name><name><surname>Lenhard</surname> <given-names>B</given-names></name><name><surname>Cuomo</surname> <given-names>ME</given-names></name><name><surname>Rueda</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>DNA stretching induces Cas9 off-target activity</article-title><source>Nature Structural &amp; Molecular Biology</source><volume>26</volume><fpage>185</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1038/s41594-019-0188-z</pub-id><pub-id pub-id-type="pmid">30804513</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oh</surname> <given-names>SL</given-names></name><name><surname>Ng</surname> <given-names>EYK</given-names></name><name><surname>Tan</surname> <given-names>RS</given-names></name><name><surname>Acharya</surname> <given-names>UR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Automated diagnosis of arrhythmia using combination of CNN and LSTM techniques with variable length heart beats</article-title><source>Computers in Biology and Medicine</source><volume>102</volume><fpage>278</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1016/j.compbiomed.2018.06.002</pub-id><pub-id pub-id-type="pmid">29903630</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okamoto</surname> <given-names>K</given-names></name><name><surname>Hibino</surname> <given-names>K</given-names></name><name><surname>Sako</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>In-cell single-molecule FRET measurements reveal three conformational state changes in RAF protein</article-title><source>Biochimica Et Biophysica Acta (BBA) - General Subjects</source><volume>1864</volume><elocation-id>129358</elocation-id><pub-id pub-id-type="doi">10.1016/j.bbagen.2019.04.022</pub-id><pub-id pub-id-type="pmid">31071411</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osuka</surname> <given-names>S</given-names></name><name><surname>Isomura</surname> <given-names>K</given-names></name><name><surname>Kajimoto</surname> <given-names>S</given-names></name><name><surname>Komori</surname> <given-names>T</given-names></name><name><surname>Nishimasu</surname> <given-names>H</given-names></name><name><surname>Shima</surname> <given-names>T</given-names></name><name><surname>Nureki</surname> <given-names>O</given-names></name><name><surname>Uemura</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Real-time observation of flexible domain movements in CRISPR-Cas9</article-title><source>The EMBO Journal</source><volume>37</volume><elocation-id>e96941</elocation-id><pub-id pub-id-type="doi">10.15252/embj.201796941</pub-id><pub-id pub-id-type="pmid">29650679</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ouyang</surname> <given-names>W</given-names></name><name><surname>Aristov</surname> <given-names>A</given-names></name><name><surname>Lelek</surname> <given-names>M</given-names></name><name><surname>Hao</surname> <given-names>X</given-names></name><name><surname>Zimmer</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deep learning massively accelerates super-resolution localization microscopy</article-title><source>Nature Biotechnology</source><volume>36</volume><fpage>460</fpage><lpage>468</lpage><pub-id pub-id-type="doi">10.1038/nbt.4106</pub-id><pub-id pub-id-type="pmid">29658943</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Persson</surname> <given-names>F</given-names></name><name><surname>Lindén</surname> <given-names>M</given-names></name><name><surname>Unoson</surname> <given-names>C</given-names></name><name><surname>Elf</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Extracting intracellular diffusive states and transition rates from single-molecule tracking data</article-title><source>Nature Methods</source><volume>10</volume><fpage>265</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2367</pub-id><pub-id pub-id-type="pmid">23396281</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preus</surname> <given-names>S</given-names></name><name><surname>Noer</surname> <given-names>SL</given-names></name><name><surname>Hildebrandt</surname> <given-names>LL</given-names></name><name><surname>Gudnason</surname> <given-names>D</given-names></name><name><surname>Birkedal</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>iSMS: single-molecule FRET microscopy software</article-title><source>Nature Methods</source><volume>12</volume><fpage>593</fpage><lpage>594</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3435</pub-id><pub-id pub-id-type="pmid">26125588</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratzke</surname> <given-names>C</given-names></name><name><surname>Hellenkamp</surname> <given-names>B</given-names></name><name><surname>Hugel</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Four-colour FRET reveals directionality in the Hsp90 multicomponent machinery</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>4192</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms5192</pub-id><pub-id pub-id-type="pmid">24947016</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname> <given-names>R</given-names></name><name><surname>Hohng</surname> <given-names>S</given-names></name><name><surname>Ha</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A practical guide to single-molecule FRET</article-title><source>Nature Methods</source><volume>5</volume><fpage>507</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1208</pub-id><pub-id pub-id-type="pmid">18511918</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakon</surname> <given-names>JJ</given-names></name><name><surname>Weninger</surname> <given-names>KR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Detecting the conformation of individual proteins in live cells</article-title><source>Nature Methods</source><volume>7</volume><fpage>203</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1421</pub-id><pub-id pub-id-type="pmid">20118931</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sali</surname> <given-names>A</given-names></name><name><surname>Berman</surname> <given-names>HM</given-names></name><name><surname>Schwede</surname> <given-names>T</given-names></name><name><surname>Trewhella</surname> <given-names>J</given-names></name><name><surname>Kleywegt</surname> <given-names>G</given-names></name><name><surname>Burley</surname> <given-names>SK</given-names></name><name><surname>Markley</surname> <given-names>J</given-names></name><name><surname>Nakamura</surname> <given-names>H</given-names></name><name><surname>Adams</surname> <given-names>P</given-names></name><name><surname>Bonvin</surname> <given-names>AM</given-names></name><name><surname>Chiu</surname> <given-names>W</given-names></name><name><surname>Peraro</surname> <given-names>MD</given-names></name><name><surname>Di Maio</surname> <given-names>F</given-names></name><name><surname>Ferrin</surname> <given-names>TE</given-names></name><name><surname>Grünewald</surname> <given-names>K</given-names></name><name><surname>Gutmanas</surname> <given-names>A</given-names></name><name><surname>Henderson</surname> <given-names>R</given-names></name><name><surname>Hummer</surname> <given-names>G</given-names></name><name><surname>Iwasaki</surname> <given-names>K</given-names></name><name><surname>Johnson</surname> <given-names>G</given-names></name><name><surname>Lawson</surname> <given-names>CL</given-names></name><name><surname>Meiler</surname> <given-names>J</given-names></name><name><surname>Marti-Renom</surname> <given-names>MA</given-names></name><name><surname>Montelione</surname> <given-names>GT</given-names></name><name><surname>Nilges</surname> <given-names>M</given-names></name><name><surname>Nussinov</surname> <given-names>R</given-names></name><name><surname>Patwardhan</surname> <given-names>A</given-names></name><name><surname>Rappsilber</surname> <given-names>J</given-names></name><name><surname>Read</surname> <given-names>RJ</given-names></name><name><surname>Saibil</surname> <given-names>H</given-names></name><name><surname>Schröder</surname> <given-names>GF</given-names></name><name><surname>Schwieters</surname> <given-names>CD</given-names></name><name><surname>Seidel</surname> <given-names>CA</given-names></name><name><surname>Svergun</surname> <given-names>D</given-names></name><name><surname>Topf</surname> <given-names>M</given-names></name><name><surname>Ulrich</surname> <given-names>EL</given-names></name><name><surname>Velankar</surname> <given-names>S</given-names></name><name><surname>Westbrook</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Outcome of the first wwPDB hybrid/Integrative methods task force workshop</article-title><source>Structure</source><volume>23</volume><fpage>1156</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1016/j.str.2015.05.013</pub-id><pub-id pub-id-type="pmid">26095030</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schluesche</surname> <given-names>P</given-names></name><name><surname>Stelzer</surname> <given-names>G</given-names></name><name><surname>Piaia</surname> <given-names>E</given-names></name><name><surname>Lamb</surname> <given-names>DC</given-names></name><name><surname>Meisterernst</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>NC2 mobilizes TBP on core promoter TATA boxes</article-title><source>Nature Structural &amp; Molecular Biology</source><volume>14</volume><fpage>1196</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1038/nsmb1328</pub-id><pub-id pub-id-type="pmid">17994103</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmid</surname> <given-names>S</given-names></name><name><surname>Götz</surname> <given-names>M</given-names></name><name><surname>Hugel</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Single-Molecule analysis beyond dwell times: demonstration and assessment in and out of equilibrium</article-title><source>Biophysical Journal</source><volume>111</volume><fpage>1375</fpage><lpage>1384</lpage><pub-id pub-id-type="doi">10.1016/j.bpj.2016.08.023</pub-id><pub-id pub-id-type="pmid">27705761</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreiber</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pomegranate: fast and flexible probabilistic modeling in Python</article-title><source>Journal of Machine Learning Research</source><volume>18</volume><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuler</surname> <given-names>B</given-names></name><name><surname>Eaton</surname> <given-names>WA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Protein folding studied by single-molecule FRET</article-title><source>Current Opinion in Structural Biology</source><volume>18</volume><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1016/j.sbi.2007.12.003</pub-id><pub-id pub-id-type="pmid">18221865</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Shafahi</surname> <given-names>A</given-names></name><name><surname>Ghiasi</surname> <given-names>A</given-names></name><name><surname>Huang</surname> <given-names>F</given-names></name><name><surname>Goldstein</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Label smoothing and logit squeezing: a replacement for adversarial training?</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1910.11585">https://arxiv.org/abs/1910.11585</ext-link></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharma</surname> <given-names>S</given-names></name><name><surname>Chakraborty</surname> <given-names>K</given-names></name><name><surname>Müller</surname> <given-names>BK</given-names></name><name><surname>Astola</surname> <given-names>N</given-names></name><name><surname>Tang</surname> <given-names>YC</given-names></name><name><surname>Lamb</surname> <given-names>DC</given-names></name><name><surname>Hayer-Hartl</surname> <given-names>M</given-names></name><name><surname>Hartl</surname> <given-names>FU</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Monitoring protein conformation along the pathway of chaperonin-assisted folding</article-title><source>Cell</source><volume>133</volume><fpage>142</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2008.01.048</pub-id><pub-id pub-id-type="pmid">18394994</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname> <given-names>PK</given-names></name><name><surname>Bohr</surname> <given-names>SS-R</given-names></name><name><surname>Hatzakis</surname> <given-names>NS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Direct observation of sophorolipid micelle docking in model membranes and cells by single particle studies reveals optimal fusion conditions</article-title><source>Biomolecules</source><volume>10</volume><elocation-id>1291</elocation-id><pub-id pub-id-type="doi">10.3390/biom10091291</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>JT</given-names></name><name><surname>Yao</surname> <given-names>R</given-names></name><name><surname>Sinsuebphon</surname> <given-names>N</given-names></name><name><surname>Rudkouskaya</surname> <given-names>A</given-names></name><name><surname>Un</surname> <given-names>N</given-names></name><name><surname>Mazurkiewicz</surname> <given-names>J</given-names></name><name><surname>Barroso</surname> <given-names>M</given-names></name><name><surname>Yan</surname> <given-names>P</given-names></name><name><surname>Intes</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fast fit-free analysis of fluorescence lifetime imaging via deep learning</article-title><source>PNAS</source><volume>116</volume><fpage>24019</fpage><lpage>24030</lpage><pub-id pub-id-type="doi">10.1073/pnas.1912707116</pub-id><pub-id pub-id-type="pmid">31719196</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname> <given-names>IH</given-names></name><name><surname>Steinhauer</surname> <given-names>C</given-names></name><name><surname>Tinnefeld</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Single-molecule four-color FRET visualizes energy-transfer paths on DNA origami</article-title><source>Journal of the American Chemical Society</source><volume>133</volume><fpage>4193</fpage><lpage>4195</lpage><pub-id pub-id-type="doi">10.1021/ja1105464</pub-id><pub-id pub-id-type="pmid">21250689</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stella</surname> <given-names>S</given-names></name><name><surname>Mesa</surname> <given-names>P</given-names></name><name><surname>Thomsen</surname> <given-names>J</given-names></name><name><surname>Paul</surname> <given-names>B</given-names></name><name><surname>Alcón</surname> <given-names>P</given-names></name><name><surname>Jensen</surname> <given-names>SB</given-names></name><name><surname>Saligram</surname> <given-names>B</given-names></name><name><surname>Moses</surname> <given-names>ME</given-names></name><name><surname>Hatzakis</surname> <given-names>NS</given-names></name><name><surname>Montoya</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Conformational activation promotes CRISPR-Cas12a catalysis and resetting of the endonuclease activity</article-title><source>Cell</source><volume>175</volume><fpage>1856</fpage><lpage>1871</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.10.045</pub-id><pub-id pub-id-type="pmid">30503205</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomsen</surname> <given-names>RP</given-names></name><name><surname>Malle</surname> <given-names>MG</given-names></name><name><surname>Okholm</surname> <given-names>AH</given-names></name><name><surname>Krishnan</surname> <given-names>S</given-names></name><name><surname>Bohr</surname> <given-names>SS</given-names></name><name><surname>Sørensen</surname> <given-names>RS</given-names></name><name><surname>Ries</surname> <given-names>O</given-names></name><name><surname>Vogel</surname> <given-names>S</given-names></name><name><surname>Simmel</surname> <given-names>FC</given-names></name><name><surname>Hatzakis</surname> <given-names>NS</given-names></name><name><surname>Kjems</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A large size-selective DNA nanopore with sensing applications</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>5655</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-13284-1</pub-id><pub-id pub-id-type="pmid">31827087</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Thomsen</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>DeepFRET-Model</data-title><source>GitHub</source><version designator="b3d8458">b3d8458</version><ext-link ext-link-type="uri" xlink:href="https://github.com/hatzakislab/DeepFRET-Model">https://github.com/hatzakislab/DeepFRET-Model</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van de Meent</surname> <given-names>JW</given-names></name><name><surname>Bronson</surname> <given-names>JE</given-names></name><name><surname>Wiggins</surname> <given-names>CH</given-names></name><name><surname>Gonzalez</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Empirical bayes methods enable advanced population-level analyses of single-molecule FRET experiments</article-title><source>Biophysical Journal</source><volume>106</volume><fpage>1327</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1016/j.bpj.2013.12.055</pub-id><pub-id pub-id-type="pmid">24655508</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>G</given-names></name><name><surname>Simon</surname> <given-names>DJ</given-names></name><name><surname>Wu</surname> <given-names>Z</given-names></name><name><surname>Belsky</surname> <given-names>DM</given-names></name><name><surname>Heller</surname> <given-names>E</given-names></name><name><surname>O'Rourke</surname> <given-names>MK</given-names></name><name><surname>Hertz</surname> <given-names>NT</given-names></name><name><surname>Molina</surname> <given-names>H</given-names></name><name><surname>Zhong</surname> <given-names>G</given-names></name><name><surname>Tessier-Lavigne</surname> <given-names>M</given-names></name><name><surname>Zhuang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Structural plasticity of actin-spectrin membrane skeleton and functional role of actin and spectrin in axon degeneration</article-title><source>eLife</source><volume>8</volume><elocation-id>e38730</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.38730</pub-id><pub-id pub-id-type="pmid">31042147</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname> <given-names>DS</given-names></name><name><surname>Goldschen-Ohm</surname> <given-names>MP</given-names></name><name><surname>Goldsmith</surname> <given-names>RH</given-names></name><name><surname>Chanda</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Top-down machine learning approach for high-throughput single-molecule analysis</article-title><source>eLife</source><volume>9</volume><elocation-id>e53357</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.53357</pub-id><pub-id pub-id-type="pmid">32267232</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname> <given-names>RR</given-names></name><name><surname>Judd</surname> <given-names>LM</given-names></name><name><surname>Holt</surname> <given-names>KE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deepbinner: demultiplexing barcoded oxford nanopore reads with deep convolutional neural networks</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006583</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006583</pub-id><pub-id pub-id-type="pmid">30458005</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname> <given-names>S</given-names></name><name><surname>Ferré-D'Amaré</surname> <given-names>AR</given-names></name><name><surname>Rueda</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Allosteric tertiary interactions preorganize the c-di-GMP riboswitch and accelerate ligand binding</article-title><source>ACS Chemical Biology</source><volume>7</volume><fpage>920</fpage><lpage>927</lpage><pub-id pub-id-type="doi">10.1021/cb300014u</pub-id><pub-id pub-id-type="pmid">22380737</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname> <given-names>AC</given-names></name><name><surname>Rifkin</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Aro: a machine learning approach to identifying single molecules and estimating classification error in fluorescence microscopy images</article-title><source>BMC Bioinformatics</source><volume>16</volume><elocation-id>102</elocation-id><pub-id pub-id-type="doi">10.1186/s12859-015-0534-z</pub-id><pub-id pub-id-type="pmid">25880543</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>SJ</given-names></name><name><surname>Berndl</surname> <given-names>M</given-names></name><name><surname>Michael Ando</surname> <given-names>D</given-names></name><name><surname>Barch</surname> <given-names>M</given-names></name><name><surname>Narayanaswamy</surname> <given-names>A</given-names></name><name><surname>Christiansen</surname> <given-names>E</given-names></name><name><surname>Hoyer</surname> <given-names>S</given-names></name><name><surname>Roat</surname> <given-names>C</given-names></name><name><surname>Hung</surname> <given-names>J</given-names></name><name><surname>Rueden</surname> <given-names>CT</given-names></name><name><surname>Shankar</surname> <given-names>A</given-names></name><name><surname>Finkbeiner</surname> <given-names>S</given-names></name><name><surname>Nelson</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Assessing microscope image focus quality with deep learning</article-title><source>BMC Bioinformatics</source><volume>19</volume><elocation-id>77</elocation-id><pub-id pub-id-type="doi">10.1186/s12859-018-2087-4</pub-id><pub-id pub-id-type="pmid">29540156</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname> <given-names>J</given-names></name><name><surname>Kim</surname> <given-names>JY</given-names></name><name><surname>Louis</surname> <given-names>JM</given-names></name><name><surname>Gopich</surname> <given-names>IV</given-names></name><name><surname>Chung</surname> <given-names>HS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Fast three-color single-molecule FRET using statistical inference</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3336</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17149-w</pub-id><pub-id pub-id-type="pmid">32620782</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>P</given-names></name><name><surname>Liu</surname> <given-names>S</given-names></name><name><surname>Chaurasia</surname> <given-names>A</given-names></name><name><surname>Ma</surname> <given-names>D</given-names></name><name><surname>Mlodzianoski</surname> <given-names>MJ</given-names></name><name><surname>Culurciello</surname> <given-names>E</given-names></name><name><surname>Huang</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Analyzing complex single-molecule emission patterns with deep learning</article-title><source>Nature Methods</source><volume>15</volume><fpage>913</fpage><lpage>916</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0153-5</pub-id><pub-id pub-id-type="pmid">30377349</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>J</given-names></name><name><surname>Li</surname> <given-names>C</given-names></name><name><surname>Li</surname> <given-names>D</given-names></name><name><surname>Liu</surname> <given-names>X</given-names></name><name><surname>Mu</surname> <given-names>Z</given-names></name><name><surname>Gao</surname> <given-names>W</given-names></name><name><surname>Qiu</surname> <given-names>J</given-names></name><name><surname>Deng</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Single-molecule photoreaction quantitation through intraparticle-surface energy transfer (i-SET) spectroscopy</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>4297</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-18223-z</pub-id><pub-id pub-id-type="pmid">32855425</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60404.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Deindl</surname><given-names>Sebastian</given-names></name><role>Reviewing Editor</role><aff><institution>Uppsala University</institution><country>Sweden</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Liu</surname><given-names>Shixin</given-names> </name><role>Reviewer</role><aff><institution>The Rockefeller University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>DeepFRET, a new deep learning-based platform for standardized, automated, and unbiased single-molecule FRET data analysis, has great potential to lower the threshold for smFRET expertise, allowing for a greater number of scientists to take advantage of this powerful technique.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;DeepFRET: Rapid and automated single molecule FRET data classification using deep learning&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by Sebastian Deindl as the Reviewing Editor and Suzanne Pfeffer as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Shixin Liu (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>A major bottleneck in many single-molecule FRET experiments is the need to sort through and classify the single-molecule time traces in order to separate the good traces in an experiment from ones that contain artifacts. In this work, Thomsen et al. describe a new platform for standardized, automated, and unbiased single-molecule FRET data analysis. The software is based on deep learning and is intended to act as the sole tool required to go from smFRET data acquisition all the way to quantitative analyses and publication-quality figure production. Rapid and automated analysis is enabled following a single user-input parameter (quality threshold), ensuring minimal user intervention in the data analysis process. A user-friendly GUI is provided to further simplify analysis. Importantly, the platform is open source written in Python, so users may adjust the code for their specific needs.</p><p>If successful, this platform could lower the threshold for smFRET expertise, allowing for a greater number of scientists to take advantage of this powerful tool. However, in its current form the manuscript could benefit from important clarifications to convince the readers of the novelty and superiority of this platform compared to the numerous previously published smFRET data analysis software packages. One weakness of the validation is that it was done only on a single real data set from one experiment performed by their lab.</p><p>Essential revisions:</p><p>1) It is unclear how pre-training the model can account for the infinite possible FRET states/lifetimes/occupancies/transition pathways/noise etc. How can this not bias the results to look for traces that are similar SNR etc. to the training data? For example, the 0.2 max probability of transition between states in the training dataset could bias analysis toward long-lived FRET states. The authors should comment on this.</p><p>2) Comparison of DeepFRET to human accuracy in picking &quot;clean traces&quot; does not seem to be an appropriate comparison (and is obviously faster). Manual trace selection is generally no longer a standard means to analyze smFRET data given the freely available open-source automated alternatives (e.g. HAMMY, ebFRET, SPARTAN, etc.). The comparison to other available software packages is important to convince users of the superior or at least equivalent performance of DeepFRET in automated trace selection. The authors should include such a comparison in the revised version of the manuscript.</p><p>3) Along the same lines, a better way to prove DeepFRET's trace analysis power is to take several datasets and compare analyses from HAMMY, ebFRET etc. vs. DeepFRET. The authors should include such comparative analyses on more than one dataset in the revised version of the manuscript.</p><p>4) It would be helpful if, in the Discussion section, the authors could provide a discussion of the tool's limitations. A discussion that talks about cases where their tool might fail would be useful for researchers who want to use their tool or build upon it. For example, in the discussion, the Materials and methods section notes that photophysical effects that are sometimes observed in smFRET experiments can be problematic for the method (it seems like the tool would likely classify these as non-useful traces even though they might reflect the &quot;true&quot; signal from the experiment [e.g. observation of PIFE in work from TJ Ha's group]).</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60404.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) It is unclear how pre-training the model can account for the infinite possible FRET states/lifetimes/occupancies/transition pathways/noise etc. How can this not bias the results to look for traces that are similar SNR etc. to the training data? For example, the 0.2 max probability of transition between states in the training dataset could bias analysis toward long-lived FRET states. The authors should comment on this.</p></disp-quote><p>This is indeed a very valid comment and has been central for the process as there is an infinite number of possible permutations of FRET data, and improper training of the model could lead to biased trace selection. We thank the reviewers for allowing us to further comment on this as it may not have been clear in the manuscript.</p><p>To introduce as little bias as possible towards specific FRET states, we strived to generate a representative fraction of the entire smFRET space sampling uniformly a large number of the infinite possible permutations of data (<italic>FRET states/lifetimes/occupancies/transition pathways/noise)</italic>. To verify this and further characterize the training data, we took a series of cautious steps which are outlined below:</p><p>a) <italic>FRET states and occupancies</italic>. The number of FRET states in a given trace was sampled uniformly from 1 to 4 states. Each state was randomly assigned a FRET value by uniform sampling between 0 and 1. For traces with more than one state, a minimum distance of 0.1 FRET was required between states (i.e. random, uniform sampling was repeated until the requirement was fulfilled) to be able to distinguish actual transitions from noise fluctuations. We verified that all FRET states as well as occupancies of the 150 k traces in the training data were uniformly distributed between 0 and 1 as displayed in Figure 1—figure supplement 3A. We realised that this may not have been clear in the original submission, so we have detailed this further in the Materials and methods subsection “Synthetic smFRET data generation”, in the revised version. Also, we corrected the legend of Figure 1—figure supplement 3A to “smFRET traces were generated with 1-4 randomly defined FRET states […]” as due to a phrasing error it stated that traces were generated with either 1, 2 or 3 states in the original submission.</p><p>b) <italic>Transition probability and lifetimes.</italic> We thank the reviewers for noticing the phrasing error in the original submission “with below 0 and 0.2 probability of transitioning”. The transition probability for each frame of the trace, from a given state to another, is uniformly sampled <italic>between</italic> 0 and 0.2. The transition probabilities are relevant <italic>between</italic> states, such that in a 4-state system with maximum allowed transition probabilities of 0.2, the combined transition probability at any given frame is 0.2*(4-1 states)=0.6. On the other hand, in a 2-state system with 0.01 transition probabilities between states, the combined transition probability at any given frame is 0.01*(2-1 states)=0.01. The mean lifetimes of the above mentioned systems are thus 1/0.6=1.7 frames and 1/0.01=100 frames, respectively. The lifetime distribution of the entire training data is an evenly weighted average over the exponential decays for each possible number of FRET states and transition probabilities as shown in Figure 1—figure supplement 3B. A Monte Carlo simulation on 10,000 traces sampling transition probabilities uniformly between 0 and 0.2 on 2-4 state traces, verifies that our training data follows the underlying model (Figure 1—figure supplement 3B). Hence, we sample a broad range of transition probabilities uniformly covering both long- and short-lived FRET states, striving to resemble most experimental data without introducing bias towards specific lifetimes. Acknowledging that this may not have been clear in the manuscript, we have added the new Figure 1—figure supplement 3B with lifetime distributions and the Monte Carlo simulation together with a brief description of how these were derived in the Materials and methods subsection “Synthetic smFRET data generation”.</p><p>c) <italic>The transition pathway</italic> follows a Markov chain which is randomly generated from a transition matrix with probabilities sampled as described above. The Markov chain of each simulated trace is generated using the Hidden Markov Model implementation of the opensource Python package named pomegranate. To verify that the training data sample a subset of all possible transition pathways uniformly, we have plotted a transition density plot of n=10,000 simulated traces. This convincingly illustrates a completely random and uniform transition pathway as expected. Acknowledging that this critical information was not implemented in the original submission, we have added the plot as a new Figure 1—figure supplement 3C, and made further clarifications in the Materials and methods subsection “Synthetic smFRET data generation”.</p><p>d) <italic>Noise level.</italic> Experimental data can sample a wide range of noise levels dependent on the biological system, instrumentation, experimental setup etc. To cover a broad range of possible noise levels, we took the following steps: First, donor and acceptor intensities of each trace were generated from the underlying true FRET values. Then, noise was added to the intensities by sampling from a normal distribution with σ values uniformly distributed between 0.01 and 0.30. To mimic shot noise, an additional layer of gamma noise was added on top with 0.8 probability. To justify the chosen range of σ values, we had plotted simulated FRET distributions at various noise levels as shown in Figure 1—figure supplement 4. The broad range of noise levels that we sample in the training data resemble most experimental data without introducing bias towards specific SNR due to uniform sampling supporting our training data and thus the model is unbiased towards specific SNR within the given range of σ values. We have clarified in the revised version both in the subsection “Performance of DeepFRET” and Discussion that in a regime where transition rates are similar to the imaging temporal resolution, dynamic smFRET traces may be incorrectly classified as noisy by the model. Trace simulation and model re-training (or changing imaging settings) would solve this.</p><p>We acknowledge that despite our rigorous attempts to introduce as little bias as possible by sampling all parameters uniformly, specialised users may have a better judgement and knowledge of their specific systems, noise levels, state lifetimes or transition probabilities amongst other parameters. When training a model, there might be some kind of bias defining the interval limits of the sampled parameters. If therefore, an expert user wants to tailor the model to better meet their specific needs, DeepFRET implements a user-friendly trace simulation interface where new FRET traces can easily be simulated based on user-defined parameters (see Figure 1—figure supplement 6) and used for retraining of the DNN model following our instructions (https://github.com/hatzakislab/DeepFRETModel). We have further highlighted this in the new paragraph in the Discussion section.</p><disp-quote content-type="editor-comment"><p>2) Comparison of DeepFRET to human accuracy in picking &quot;clean traces&quot; does not seem to be an appropriate comparison (and is obviously faster). Manual trace selection is generally no longer a standard means to analyze smFRET data given the freely available open-source automated alternatives (e.g. HAMMY, ebFRET, SPARTAN, etc.). The comparison to other available software packages is important to convince users of the superior or at least equivalent performance of DeepFRET in automated trace selection. The authors should include such a comparison in the revised version of the manuscript.</p></disp-quote><p>We wish to highlight that the main the scope of this manuscript is to provide an intuitive platform requiring minimal human intervention, that as the reviewers commented “[…] <italic>could lower the threshold for smFRET expertise, allowing for a greater number of scientists to take advantage of this powerful tool”,</italic> rather than prove wrong the existing, robust, software packages developed and operated by experts in the field. We also acknowledge that manual trace selection should not be the standard means to analyse smFRET data, but despite the wide range of available software packages for smFRET data analysis, only some implement advanced automatic sorting of traces. <italic>HAMMY</italic> and <italic>ebFRET</italic> as the reviewers suggested focus on kinetic rate extraction and offer simple thresholds based on intensity and FRET values. Cleaning up traces beyond these simple thresholds often requires extra manual selection. <italic>iSMS</italic> offers more advanced sorting by donor/acceptor intensity, mean FRET and mean stoichiometry for ALEX data as well as automatic detection of photobleaching. <italic>SPARTAN</italic> offers more extensive implementations for automated sorting (26 parameters in total) and is optimised for non-ALEX data. The actual threshold criteria however may vary significantly for each group and experimental system (Fessl et al., 2018; Gouge et al., 2017; Schärfen and Schlierf, 2019; Tsuboyama et al., 2018; Yao et al., 2015). Specialised groups are well trained to navigate through these multiple criteria and accurately define their own, which are optimised to operate on their specific systems (Aznauryan et al., 2016; Fessl et al., 2018; Gouge et al., 2017; Schärfen and Schlierf, 2019; Tsuboyama et al., 2018; Wu et al., 2018; Yao et al., 2015). However the diversity of these sorting criteria might introduce unnecessary bias in an already complicated series of data processing, especially since the advent of commercial instruments has rapidly expanded the smFRET field.</p><p>To directly address the comments of the reviewers we performed two types of experimental validations. We firstly compared DeepFRET directly with HAMMY, ebFRET, SPARTAN and iSMS sorting capabilities on simulated data where the ground truth is known. We then compared SPARTAN and iSMS, that have advanced sorting options, on experimental data sets published by other groups.</p><p>In the first case, we merged 200 simulated, ground truth smFRET traces with 1800 simulated, nonsmFRET traces (Figure 4—figure supplement 3A and the Materials and methods for FRET distributions and parameter descriptions, respectively) and reverse engineered tif files that would correspond to raw smFRET data. We simulated both ALEX and non-ALEX data as iSMS is optimized for ALEX data while HAMMY, ebFRET and SPARTAN operate optimally on non-ALEX data. The tif files were loaded into the respective software packages and used for extraction and sorting of traces applying a quality score of 0.80 in DeepFRET, default sorting parameters in SPARTAN (except background noise threshold), intensity, stoichiometry and FRET thresholds in iSMS, intensity thresholds in HAMMY and FRET thresholds in ebFRET. We found DeepFRET, SPARTAN and iSMS to recover the underlying ground truth FRET distribution to various levels of detail, while the simple intensity and FRET thresholds of HAMMY and ebFRET would require further sorting for optimal results. Notably, DeepFRET was found to sort traces at least similarly to, or better than, both SPARTAN and iSMS without any parameter tuning (Figure 4—figure supplement 3B). We strongly note that expert users would be able to fine-tune all possible thresholds to better match the ground truth data. However, in a real-world experiment where the ground truth is unknown the task becomes more challenging and finetuning parameters may be subject to bias, especially for non-specialised users. The single threshold-based classification offered by DeepFRET may be crucial for a greater number of scientists to take advantage of this tool.</p><p>In the second case, we compared the performance of the three software packages offering advanced sorting on experimental data published by other groups. Selecting non-ALEX and ALEX datasets published by Kilic et al. (Kilic et al., 2018) and Hellenkamp et al. (Hellenkamp et al., 2018), respectively ensures proper testing in diverse FRET settings and data sets. We used practically the default settings in both softwares and cropped data to the first 10 frames of each trace, minimising bleaching without using the default hard threshold at FRET &lt; 0.2 in SPARTAN. Our analysis illustrates that all three software packages are able to reproduce the published FRET distributions from raw tif files with little discrepancy (Figure 4—figure supplement 4). DeepFRET displays equivalent or superior performance to existing sophisticated software packages also on experimental data. We emphasize that existing software packages are very robust and expert users would be able to navigate through and optimize all of the required settings for the individual datasets. The power of DeepFRET is its capacity to analyse both ALEX and non-ALEX data in a reproducible manner only requiring minimal human intervention, and thus minimal expertise in threshold setting, <italic>a</italic>llowing for a greater number of scientists to take advantage of this powerful tool. Acknowledging the lack of comparison to existing software, we have added the new Figure 4—figure supplements 3-4. We have also renamed the sub section “DeepFRET performance on real data,” to “DeepFRET performance on real data, comparison to existing robust softwares for smFRET analysis” and also added a new paragraph in the section explicitly discussing the comparison on simulated ground truth and published data.</p><disp-quote content-type="editor-comment"><p>3) Along the same lines, a better way to prove DeepFRET's trace analysis power is to take several datasets and compare analyses from HAMMY, ebFRET etc. vs. DeepFRET. The authors should include such comparative analyses on more than one dataset in the revised version of the manuscript.</p></disp-quote><p>To address the comment of the reviewers we directly compared the performance of DeepFRET to published results on two experimental datasets (ALEX and non-ALEX) across different groups (Figure 4—figure supplement 4 and answer to comment 2). We found that DeepFRET was able to reproduce the published smFRET distributions using a simple quality threshold of 0.80 without further human intervention, and furthermore so equally or better than existing software, (see also answer to reviewer comment 2). These data further validate the performance and power of DeepFRET as compared to other existing software requiring user-defined thresholds that may require specialised expertise of its users. We have explained the comparison in the main text and added the new Figure 4—figure supplement 4 in the manuscript.</p><disp-quote content-type="editor-comment"><p>4) It would be helpful if, in the Discussion section, the authors could provide a discussion of the tool's limitations. A discussion that talks about cases where their tool might fail would be useful for researchers who want to use their tool or build upon it. For example, in the discussion, the Materials and methods section notes that photophysical effects that are sometimes observed in smFRET experiments can be problematic for the method (it seems like the tool would likely classify these as non-useful traces even though they might reflect the &quot;true&quot; signal from the experiment [e.g. observation of PIFE in work from TJ Ha's group]).</p></disp-quote><p>Following the comment of the reviewers, we added a new paragraph to the Discussion section outlining the limitations of the current version of DeepFRET and what could be done in the future to improve it. As outlined in the previous sections, DeepFRET performs accurately on both simulated and experimental 2-color smFRET data across multiple laboratories. The limitations that are discussed in the revised version of the manuscript can be addressed by expert users through simulation of new training data and re-training of the DNN model following our instructions (https://github.com/hatzakislab/DeepFRET-Model) as described in the Materials and methods section.</p><p>References:</p><p>Aznauryan, M., Søndergaard, S., Noer, S.L., Schiøtt, B., Birkedal, V., 2016. A direct view of the complex multi-pathway folding of telomeric G-quadruplexes. Nucleic Acids Res. 44, 11024– 11032. doi:10.1093/nar/gkw1010</p><p>Fessl, T., Watkins, D., Oatley, P., Allen, W.J., Corey, R.A., Horne, J., Baldwin, S.A., Radford, S.E., Collinson, I., Tuma, R., 2018. Dynamic action of the Sec machinery during initiation, protein translocation and termination. <italic>eLife</italic> 7. doi:10.7554/<italic>eLife</italic>.35112</p><p>Gouge, J., Guthertz, N., Kramm, K., Dergai, O., Abascal-Palacios, G., Satia, K., Cousin, P., Hernandez, N., Grohmann, D., Vannini, A., 2017. Molecular mechanisms of Bdp1 in TFIIIB assembly and RNA polymerase III transcription initiation. Nat. Commun. 8, 130.</p><p>doi:10.1038/s41467-017-00126-1</p><p>Schärfen, L., Schlierf, M., 2019. Real-time monitoring of protein-induced DNA conformational changes using single-molecule FRET. Methods 169, 11–20.</p><p>doi:10.1016/j.ymeth.2019.02.011</p><p>Tsuboyama, K., Tadakuma, H., Tomari, Y., 2018. Conformational activation of argonaute by distinct yet coordinated actions of the hsp70 and hsp90 chaperone systems. Mol. Cell 70, 722-729.e4. doi:10.1016/j.molcel.2018.04.010</p><p>Wu, S., Liu, J., Wang, W., 2018. Dissecting the Conformational Dynamics-Modulated Enzyme Catalysis with Single-Molecule FRET. J. Phys. Chem. B 122, 6179–6187.</p><p>doi:10.1021/acs.jpcb.8b02374</p><p>Yao, C., Sasaki, H.M., Ueda, T., Tomari, Y., Tadakuma, H., 2015. Single-Molecule Analysis of the Target Cleavage Reaction by the <italic>Drosophila</italic> RNAi Enzyme Complex. Mol. Cell 59, 125–132. doi:10.1016/j.molcel.2015.05.015</p></body></sub-article></article>