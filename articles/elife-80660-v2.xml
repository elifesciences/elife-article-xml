<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">80660</article-id><article-id pub-id-type="doi">10.7554/eLife.80660</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A searchable image resource of <italic>Drosophila</italic> GAL4 driver expression patterns with single neuron resolution</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-92823"><name><surname>Meissner</surname><given-names>Geoffrey W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0369-9788</contrib-id><email>meissnerg@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-66439"><name><surname>Nern</surname><given-names>Aljoscha</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3822-489X</contrib-id><email>nerna@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-283283"><name><surname>Dorman</surname><given-names>Zachary</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9933-7217</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283286"><name><surname>DePasquale</surname><given-names>Gina M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283287"><name><surname>Forster</surname><given-names>Kaitlyn</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283288"><name><surname>Gibney</surname><given-names>Theresa</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5461-724X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283289"><name><surname>Hausenfluck</surname><given-names>Joanna H</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-165614"><name><surname>He</surname><given-names>Yisheng</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-18456"><name><surname>Iyer</surname><given-names>Nirmala A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283290"><name><surname>Jeter</surname><given-names>Jennifer</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283291"><name><surname>Johnson</surname><given-names>Lauren</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283292"><name><surname>Johnston</surname><given-names>Rebecca M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283293"><name><surname>Lee</surname><given-names>Kelley</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283294"><name><surname>Melton</surname><given-names>Brian</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283295"><name><surname>Yarbrough</surname><given-names>Brianna</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con15"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283296"><name><surname>Zugates</surname><given-names>Christopher T</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1882-3665</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con16"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-111423"><name><surname>Clements</surname><given-names>Jody</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con17"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283297"><name><surname>Goina</surname><given-names>Cristian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2835-7602</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con18"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-165616"><name><surname>Otsuna</surname><given-names>Hideo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2107-8881</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con19"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283298"><name><surname>Rokicki</surname><given-names>Konrad</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2799-9833</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con20"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-181662"><name><surname>Svirskas</surname><given-names>Robert R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8374-6008</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con21"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-285479"><name><surname>Aso</surname><given-names>Yoshinori</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2939-1688</contrib-id><email>asoy@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con22"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-300930"><name><surname>Card</surname><given-names>Gwyneth M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7679-3639</contrib-id><email>cardg@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con23"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-3094"><name><surname>Dickson</surname><given-names>Barry J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0715-892X</contrib-id><email>dicksonb@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con24"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-283299"><name><surname>Ehrhardt</surname><given-names>Erica</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9252-1414</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con25"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283300"><name><surname>Goldammer</surname><given-names>Jens</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5623-8339</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con26"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283301"><name><surname>Ito</surname><given-names>Masayoshi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con27"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-181654"><name><surname>Kainmueller</surname><given-names>Dagmar</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9830-2415</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con28"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-18451"><name><surname>Korff</surname><given-names>Wyatt</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8396-1533</contrib-id><email>korffw@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con29"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-283302"><name><surname>Mais</surname><given-names>Lisa</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con30"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283303"><name><surname>Minegishi</surname><given-names>Ryo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2895-9438</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con31"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-102841"><name><surname>Namiki</surname><given-names>Shigehiro</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1559-799X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con32"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-53801"><name><surname>Rubin</surname><given-names>Gerald M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8762-8703</contrib-id><email>rubing@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con33"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-244280"><name><surname>Sterne</surname><given-names>Gabriella R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7221-648X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con34"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-83906"><name><surname>Wolff</surname><given-names>Tanya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8681-1749</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con35"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-283304"><name><surname>Malkesman</surname><given-names>Oz</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2219-7476</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con36"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><collab>FlyLight Project Team</collab><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con37"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013sk6x84</institution-id><institution>Janelia Research Campus, Howard Hughes Medical Institute</institution></institution-wrap><addr-line><named-content content-type="city">Ashburn</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04p5ggc03</institution-id><institution>Max-Delbrueck-Center for Molecular Medicine in the Helmholtz Association (MDC)</institution></institution-wrap><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Grunwald Kadow</surname><given-names>Ilona C</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041nas322</institution-id><institution>University of Bonn</institution></institution-wrap><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Desplan</surname><given-names>Claude</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>New York University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>23</day><month>02</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e80660</elocation-id><history><date date-type="received" iso-8601-date="2022-05-30"><day>30</day><month>05</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-02-21"><day>21</day><month>02</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2020-05-30"><day>30</day><month>05</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.05.29.080473"/></event></pub-history><permissions><copyright-statement>© 2023, Meissner et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Meissner et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-80660-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-80660-figures-v2.pdf"/><abstract><p>Precise, repeatable genetic access to specific neurons via GAL4/UAS and related methods is a key advantage of <italic>Drosophila</italic> neuroscience. Neuronal targeting is typically documented using light microscopy of full GAL4 expression patterns, which generally lack the single-cell resolution required for reliable cell type identification. Here, we use stochastic GAL4 labeling with the MultiColor FlpOut approach to generate cellular resolution confocal images at large scale. We are releasing aligned images of 74,000 such adult central nervous systems. An anticipated use of this resource is to bridge the gap between neurons identified by electron or light microscopy. Identifying individual neurons that make up each GAL4 expression pattern improves the prediction of split-GAL4 combinations targeting particular neurons. To this end, we have made the images searchable on the NeuronBridge website. We demonstrate the potential of NeuronBridge to rapidly and effectively identify neuron matches based on morphology across imaging modalities and datasets.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neuron search</kwd><kwd>MultiColor FlpOut</kwd><kwd>GAL4</kwd><kwd>split-GAL4</kwd><kwd>NeuronBridge</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Meissner</surname><given-names>Geoffrey W</given-names></name><name><surname>Nern</surname><given-names>Aljoscha</given-names></name><name><surname>Aso</surname><given-names>Yoshinori</given-names></name><name><surname>Card</surname><given-names>Gwyneth M</given-names></name><name><surname>Dickson</surname><given-names>Barry J</given-names></name><name><surname>Korff</surname><given-names>Wyatt</given-names></name><name><surname>Rubin</surname><given-names>Gerald M</given-names></name><institution>FlyLight Project Team</institution></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Single neuron images of <italic>Drosophila</italic> driver lines reveal neuron shape and are searchable, enabling comparisons to electron microscopy and prediction of intersectional neuron targeting strategies.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Many experimental approaches to understanding the nervous system require the ability to repeatedly target-specific neurons in order to efficiently explore their anatomy, physiology, gene expression, or function. In <italic>Drosophila melanogaster</italic>, the dominant approaches to targeting cells have been GAL4/UAS and related binary systems (<xref ref-type="bibr" rid="bib7">Brand and Perrimon, 1993</xref>; <xref ref-type="bibr" rid="bib28">Lai and Lee, 2006</xref>; <xref ref-type="bibr" rid="bib44">Pfeiffer et al., 2010</xref>; <xref ref-type="bibr" rid="bib46">Potter et al., 2010</xref>). The GAL4 protein, expressed from one transgene, binds upstream activation sequence (UAS) elements inserted in a separate transgene and activates the expression and translation of an adjacent functional protein. An extensive toolkit of UAS transgenes has been developed (reviewed in <xref ref-type="bibr" rid="bib21">Guo et al., 2019</xref>). Large collections of GAL4 driver lines have been created, including collections (referred to here as ‘Generation 1’ or ‘Gen1’ GAL4 lines) in which GAL4 expression is typically controlled by 2–4 kilobase fragments of enhancer and promoter regions (<xref ref-type="bibr" rid="bib43">Pfeiffer et al., 2008</xref>; <xref ref-type="bibr" rid="bib25">Jenett et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Tirian and Dickson, 2017</xref>). Published image libraries of the expression patterns of these GAL4 lines are available and provide a basis for visual or computational searches for driver lines with expression in cell populations of interest.</p><p>Despite these extensive resources, obtaining precise experimental access to individual neuronal cell types remains challenging. A GAL4 driver line from one of the above collections typically expresses in tens or more neuronal cell types and even more individual neurons, which is not sufficiently specific for many experiments. Several intersectional approaches have been designed to improve targeting specificity (reviewed in <xref ref-type="bibr" rid="bib21">Guo et al., 2019</xref>), the most widely used of which is the split-GAL4 system (<xref ref-type="bibr" rid="bib30">Luan et al., 2006</xref>; <xref ref-type="bibr" rid="bib44">Pfeiffer et al., 2010</xref>). In brief, to create a split-GAL4 driver, the activation domain (AD) and DNA-binding domain (DBD) of GAL4 are individually placed under control of separate enhancer fragments. The AD and DBD are attached to leucine zipper motifs that further stabilize binding. Only in those neurons where both enhancer fragments are active is a functional GAL4 reassembled to activate the UAS, resulting in a positive intersection between enhancer expression patterns. The split-GAL4 system provides the required targeting specificity and has been used at an increasingly large scale (e.g., <xref ref-type="bibr" rid="bib18">Gao et al., 2008</xref>; <xref ref-type="bibr" rid="bib58">Tuthill et al., 2013</xref>; <xref ref-type="bibr" rid="bib2">Aso et al., 2014a</xref>; <xref ref-type="bibr" rid="bib62">Wu et al., 2016</xref>; <xref ref-type="bibr" rid="bib38">Namiki et al., 2018</xref>; <xref ref-type="bibr" rid="bib61">Wolff and Rubin, 2018</xref>; <xref ref-type="bibr" rid="bib15">Dolan et al., 2019</xref>; <xref ref-type="bibr" rid="bib13">Davis et al., 2020</xref>; <xref ref-type="bibr" rid="bib53">Sterne et al., 2021</xref>), but good split combinations remain challenging to predict.</p><p>Split-GAL4 construction typically begins with the identification of GAL4 driver lines with expression in the cell type of interest. While the stereotyped shape of fly neurons can sometimes be directly distinguished by visual inspection, the specific features of a neuron are often obscured by other cells in a GAL4 expression pattern. Several stochastic labeling methods that reveal single cells present in broader expression patterns have been developed (reviewed in <xref ref-type="bibr" rid="bib19">Germani et al., 2018</xref>). While large libraries of single-cell images exist (<xref ref-type="bibr" rid="bib8">Chiang et al., 2011</xref>), these were mainly generated using a few widely expressed GAL4 lines. MultiColor FlpOut (MCFO; <xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>) enables the labeling of stochastic subsets of neurons within a GAL4 or split-GAL4 pattern in multiple colors. In brief, MCFO can use several UAS reporters that are independently stochastically activated by low levels of Flp recombinase. Flp levels can be adjusted to tailor MCFO labeling density for different GAL4 lines or purposes. Labeling a GAL4 pattern using MCFO allows for the efficient determination of a significant fraction of the neurons present within it.</p><p>The need for resources to identify single cells of interest using genetic tools (GAL4 lines) has become more urgent due to recent advances in connectomics. Comprehensive electron microscopy (EM) mapping of specific brain regions or whole nervous systems is transforming neuroscience (e.g., <xref ref-type="bibr" rid="bib64">Zheng et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Maniates-Selvin et al., 2020</xref>; <xref ref-type="bibr" rid="bib51">Scheffer et al., 2020</xref>) by providing anatomy at unparalleled resolution, near complete cell type coverage, and connectivity information. Leveraging these new datasets to understand more than pure anatomy will be greatly facilitated by the ability to genetically target-specific neurons and circuits. Light microscopy (LM) data also complement EM datasets by revealing features outside a reconstructed EM volume or by providing independent validation of cell shapes with a greater sample size. To integrate these formats requires datasets and methods for matching EM neurons with LM-derived GAL4/split-GAL4 data.</p><p>Recently developed techniques allow searching for neuron shapes (including neuron fragments, whole neurons, or overlapping groups of neurons) in coregistered LM and EM data. Two leading approaches are NBLAST (<xref ref-type="bibr" rid="bib12">Costa et al., 2016</xref>), which performs comparisons between segmented neurons, and Color Depth Maximum intensity projection (CDM) search (<xref ref-type="bibr" rid="bib41">Otsuna et al., 2018</xref>), which efficiently compares bitmap images using color to represent depth within the samples. NBLAST was recently expanded upon with the combination of PatchPerPix neuron segmentation (<xref ref-type="bibr" rid="bib22">Hirsch et al., 2020</xref>) and PatchPerPixMatch search (PPPM; <xref ref-type="bibr" rid="bib31">Mais et al., 2021</xref>). PPPM identifies neuron segments with similar color and high NBLAST scores that best cover a target neuron of interest, allowing the use of partial segments from densely labeled MCFO samples. Overlapping neurons remain challenging to segment manually or algorithmically, making this an area of rapid development. Advanced anatomical templates such as JRC2018 improve point-to-point mapping between samples and modalities (<xref ref-type="bibr" rid="bib6">Bogovic et al., 2020</xref>). These search tools and templates bridge the EM/LM gap but require single-cell-level image collections that cover many neurons present within Gen1 GAL4 patterns to reach their maximum utility. In particular, to identify multiple Gen1 GAL4s that can be combined to make a split-GAL4 driver, the morphologies of individual neurons within many GAL4 lines must be available.</p><p>Here, we used MCFO to dissect Gen1 GAL4 line patterns at scale to create a resource for linking EM-reconstructed neurons to GAL4 lines, and to improve the process of making split-GAL4 reporters to target neurons, whether they were first identified in EM or LM. We therefore focused on 5155 Gen1 GAL4 lines, most of which have been converted into split-GAL4 hemidrivers, performing three rounds of MCFO labeling to improve coverage of neurons. The resource includes images of 74,337 fly samples, with an average of 14 brain and 7 ventral nerve cord (VNC) images per line. We have released the image data and made it searchable on the NeuronBridge website together with data from the FlyEM Hemibrain and published split-GAL4 lines.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We used the MCFO approach on Generation 1 GAL4 lines (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) to visualize individual neurons (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) making up the GAL4 expression pattern. These neurons can be matched to EM neurons (<xref ref-type="fig" rid="fig1">Figure 1C, D</xref>) in order to predict split-GAL4 combinations for an EM neuron of interest (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). We generated two collections of Gen1 MCFO images (<xref ref-type="table" rid="table1">Table 1</xref>). The collection imaged with 20× and 63× microscope objectives targeted particular neurons of interest to collaborators annotating regions primarily in the brain and optic lobes. The collection imaged with 40× objectives broadly canvassed neurons in the central brain and VNC.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Generation 1 MultiColor FlpOut (MCFO) and electron microscopy (EM)/light microscopy (LM) comparison overview.</title><p>(<bold>A</bold>) Overall GAL4 expression pattern of a driver line containing a cell type of interest, shown as a color depth maximum intensity projection (MIP) (<xref ref-type="bibr" rid="bib41">Otsuna et al., 2018</xref>). Original images are from published datasets (<xref ref-type="bibr" rid="bib25">Jenett et al., 2012</xref>). (<bold>B1</bold>) Example MCFO labeled cells from the driver line in (<bold>A</bold>). MCFO labeling reveals a prominent descending neuron. (<bold>B2</bold>) An additional MCFO labeled cell of the same type but from a different line. The color depth MIPs in B1 and B2 represent data from one of the three MCFO markers, so color changes indicate changes in the <italic>z</italic>-dimension rather than differential MCFO labeling. (<bold>C1, C2</bold>) Matching EM reconstructions for the cell type. Both panels show reconstructions from the right-side Hemibrain; the lower panel is mirrored to facilitate comparison to the LM data. (<bold>D</bold>) PatchPerPixMatch (PPPM) overlay of MCFO from (<bold>B1</bold>) and EM reconstruction from (<bold>C2</bold>). (<bold>E</bold>) Split-GAL4 made from split hemidrivers derived from GAL4 lines in A and B. Driver lines used are R56H09 (<bold>A, B1</bold>), R23E11 (<bold>B2</bold>), and SS01588 (<bold>E</bold>). Hemibrain body IDs are 571346836 (<bold>C1</bold>) and 1786496543 (<bold>C2</bold>). All scale bars, 50 µm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80660-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Generation 1 MultiColor FlpOut (MCFO) expression density categories.</title><p>(<bold>A</bold>) Two example brain maximum intensity projections (MIPs) are shown for each expression density category, except Category 5, where a single brain is shown both as an MIP and a single confocal slice through its center. Qualitative categorization was manually performed on a line level based on 2D MIPs of MCFO and full central nervous system (CNS) expression patterns. Category 1 lines contained no visible neurons or only commonly repeated ones. Categories 2–4 labeled identifiable neurons with increasing density. Category 5 lines had such dense expression that the immunohistochemical labeling approach failed to fully label the center of the brain. Category 1 and 5 lines were generally excluded from imaging and the collection as a whole. Scale bar, 50 µm. (<bold>B</bold>) The frequency distribution of lines within the different expression density categories are shown. Sample size is all 4919 lines considered for inclusion in either phase of the 40× pipeline. 95% of lines were within the desired range.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80660-fig1-figsupp1-v2.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Image collection statistics.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom">20×/63× collection</th><th align="left" valign="bottom">40× collection</th><th align="left" valign="bottom">Total</th></tr></thead><tbody><tr><td align="left" valign="bottom">Gen1 GAL4 lines</td><td align="char" char="." valign="bottom">2463</td><td align="char" char="." valign="bottom">4575</td><td align="char" char="." valign="bottom">5155</td></tr><tr><td align="left" valign="bottom">Samples</td><td align="char" char="." valign="bottom">27,546</td><td align="char" char="." valign="bottom">46,791</td><td align="char" char="." valign="bottom">74,337</td></tr><tr><td align="left" valign="bottom">Average samples/line</td><td align="char" char="." valign="bottom">11.2</td><td align="char" char="." valign="bottom">10.2</td><td align="char" char="." valign="bottom">14.4</td></tr><tr><td align="left" valign="bottom">Std. Dev. samples/line</td><td align="char" char="." valign="bottom">7.6</td><td align="char" char="." valign="bottom">4.6</td><td align="char" char="." valign="bottom">8.7</td></tr><tr><td align="left" valign="bottom">Average brain/line</td><td align="char" char="." valign="bottom">11.2</td><td align="char" char="." valign="bottom">10.1</td><td align="char" char="." valign="bottom">14.3</td></tr><tr><td align="left" valign="bottom">Average VNC/line</td><td align="char" char="." valign="bottom">0.9</td><td align="char" char="." valign="bottom">7.1</td><td align="char" char="." valign="bottom">6.8</td></tr><tr><td align="left" valign="bottom">Female %</td><td align="char" char="." valign="bottom">94.2%</td><td align="char" char="." valign="bottom">44.9%</td><td align="char" char="." valign="bottom">63.2%</td></tr><tr><td align="left" valign="bottom">20×/40× image tiles</td><td align="char" char="." valign="bottom">29,784</td><td align="char" char="." valign="bottom">111,380</td><td align="char" char="." valign="bottom">141,164</td></tr><tr><td align="left" valign="bottom">63× image tiles</td><td align="char" char="." valign="bottom">22,775</td><td align="char" char="." valign="bottom">–</td><td align="char" char="." valign="bottom">22,775</td></tr><tr><td align="left" valign="bottom">Lines with 63× images</td><td align="char" char="." valign="bottom">1748</td><td align="char" char="." valign="bottom">–</td><td align="char" char="." valign="bottom">1748</td></tr><tr><td align="left" valign="bottom">Samples with 63× images</td><td align="char" char="." valign="bottom">8447</td><td align="char" char="." valign="bottom">–</td><td align="char" char="." valign="bottom">8447</td></tr></tbody></table></table-wrap><p>A challenge with any stochastic neuron labeling approach is to optimize the number of identifiable neurons in each sample: too sparse and samples are empty or have few labeled neurons; too dense and the neurons overlap, making it difficult to fully isolate individual neurons even if they are labeled in different colors. MCFO allows for control of labeling density by optimizing the amount of Flp activity, either by selecting different Flp drivers, or altering heat shock duration for hs-Flp (<xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>). GAL4 lines with broader expression typically require lower Flp activity to yield isolated neurons. In the 20×/63× MCFO collection, labeling density was customized for collaborators focused on annotating particular central nervous system (CNS) regions, iterating on prior results (<xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>). In the 40× MCFO collection, labeling density was initially standardized (Phase 1), then optimized based on overall GAL4 expression density (Phase 2; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). For many lines, there is no globally ideal level of Flp activity, as they have varying levels of expression density in different CNS regions.</p><p>The 20×/63× and 40× datasets differed in several other respects (<xref ref-type="table" rid="table1">Table 1</xref>). The 20×/63× collection was imaged with 20× objectives, followed by 63× imaging of specific regions of interest, whereas the 40× collection was uniformly imaged at 40×. The 20×/63× collection was focused on a smaller set of lines visualized primarily in female brains (94.2%), whereas the 40× collection covered more lines (4575 vs. 2463), a mixture of male and female samples (44.9% female), and both brains and VNCs (7.1 VNCs per line vs. 0.9 in the 20×/63× dataset).</p><p>Finally, as the 20×/63× dataset and existing publications (e.g., <xref ref-type="bibr" rid="bib16">Fischbach and Dittrich, 1989</xref>; <xref ref-type="bibr" rid="bib35">Morante and Desplan, 2008</xref>; <xref ref-type="bibr" rid="bib54">Takemura et al., 2013</xref>; <xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Takemura et al., 2015</xref>) effectively documented the largely repetitive structure of the optic lobes, the 40× dataset excluded them. Collections of split-GAL4 driver lines for many optic lobe cell types are already available (<xref ref-type="bibr" rid="bib58">Tuthill et al., 2013</xref>; <xref ref-type="bibr" rid="bib62">Wu et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">Davis et al., 2020</xref>). Many neurons that connect the optic lobe with the central brain can still be identified in the 40× dataset based on their central brain arborizations. The optic lobe anatomy of such cells could be further characterized in follow-up experiments with the identified GAL4 lines.</p><sec id="s2-1"><title>40× Gen1 MCFO collection</title><p>After performing extensive MCFO labeling for the 20×/63× dataset, we performed comprehensive MCFO mapping of Gen1 GAL4 lines across most of the CNS. MCFO labeling of <italic>Drosophila</italic> neurons was performed with a pan-neuronal Flp recombinase (R57C10-Flp) on 4562 Generation 1 GAL4 lines in Phase 1. We generated images of 27,226 central brains and 26,512 VNCs from 27,729 flies. The CNS was typically dissected from six flies per line. A medium-strength Flp transgene (<italic>R57C10-Flp2::PEST in attP18</italic>; <xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>) was used for almost all lines, yielding a wide range of neuronal labeling in each MCFO sample. 238 of the sparser lines were crossed to an MCFO reporter with a stronger Flp transgene (<italic>R57C10-FlpL in su(Hw)attP8</italic>), and 71 lines were crossed to both reporters.</p><p>GAL4 lines were qualitatively categorized into rough groups by density of expression within the central brain and VNC, ranging from Category 1 yielding no unique neurons per sample, to Category 5 being so dense that it overwhelmed our immunohistochemical approach, leaving a shell of partially labeled neurons around the outside of each sample (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). Category 2 lines were characterized by sparse, easily separable neurons, whereas Category 3 yielded denser but identifiable neurons. Category 4 displayed densely labeled neurons that were challenging to distinguish. Most lines ranged between Categories 2 and 4 (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>).</p><p>In order to increase the number of identifiable neurons, a subset of lines was re-examined with altered parameters. Phase 2 of the 40× pipeline generated images of an additional 18,894 central brains and 6235 VNCs from 19,062 flies. Phase 2 GAL4 expression density was optimized by (1) selecting lines with expression most likely useful for split halves, (2) adjusting MCFO parameters to maximize separable neurons obtained per sample, and (3) limiting brains and VNCs processed per line to minimize the diminishing returns associated with oversampling. Phase 2 focused on Category 2 and 3 lines as most likely to be useful for split-GAL4 creation. Category 1 and 5 lines were outside our effective labeling range and were therefore excluded from further work. High neuron density within Category 4 means that although the theoretical neuron yield from each sample is high, our ability to distinguish individual neurons is low (although future improvements to neuron segmentation approaches are expected to improve yields).</p><p>Heat-shock Flp (hs-Flp) was used in Phase 2 rather than R57C10-Flp (<xref ref-type="fig" rid="fig2">Figure 2</xref>). While both R57C10-Flp and hs-Flp are theoretically expected to label all neurons, in practice each is likely to have subtle biases as previously proposed (<xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>; see also below). By switching Flp enhancers in Phase 2, we attempted to mitigate the impact of these biases. The 37°C heat shock duration for hs-Flp was optimized for each density category. Prior results reported by <xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref> indicated that heat shock effectiveness is nonlinear: limited to background activity up to ~10 min, a somewhat linear range between 10 and 20 min, and gradually diminishing returns up to ~40 min; heat shocks longer than an hour begin to harm fly survival. We chose a heat shock duration of 40 min for Category 2 lines to yield as many neurons as possible per sample. For Category 3 a 13 min heat shock provided the desired labeling density similar to Category 3 in Phase 1. To increase the chance of obtaining sex-specific neurons and neuronal morphology, we randomly choose one sex for each half of the lines in Phase 1 and then in Phase 2 switched them to the opposite sex.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Phase 1 and 2 overview and labeling examples.</title><p>R14E12-GAL4 in attP2 crossed to (<bold>A</bold>) pJFRC2-10XUAS-IVS-mCD8::GFP, (<bold>B</bold>) R57C10-Flp MCFO, or (<bold>C</bold>) hs-Flp MCFO. Adult central nervous system (CNS) maximum intensity projections (MIPs) are shown, with neuropil reference in gray and neuronal signal in green (<bold>A</bold>) or full MultiColor FlpOut (MCFO) colors (<bold>B, C</bold>). Multiple examples are shown for B, C. Scale bars, 50 µm. (<bold>D</bold>) Glia are seen with VT008658-GAL4 in attP2 crossed to (<bold>D1</bold>) pJFRC2-10XUAS-IVS-mCD8::GFP and (<bold>D3</bold>) hs-Flp MCFO, but not (<bold>D2</bold>) R57C10-Flp MCFO. (<bold>E</bold>) Kenyon cell labeling is not seen with R86H02-GAL4 in attP2 crossed to (<bold>E1</bold>) pJFRC2-10XUAS-IVS-mCD8::GFP or (<bold>E2</bold>) R57C10-Flp MCFO, but is seen when crossed to (<bold>E3</bold>) hs-Flp MCFO. (<bold>F</bold>) Kenyon cell labeling is seen with R91B01-GAL4 in attP2 crossed to (<bold>F1</bold>) pJFRC2-10XUAS-IVS-mCD8::GFP and (<bold>F3</bold>) hs-Flp MCFO, but is not seen when crossed to (<bold>F2</bold>) R57C10-Flp MCFO. (<bold>G</bold>) An ascending neuron (sparse T) is commonly seen with many Gen1 GAL4 lines crossed to different reporters. VT010592-GAL4 in attP2 crossed to R57C10-Flp MCFO is shown as an example. A single neuron channel plus reference are shown for clarity. The inset shows a lateral (<italic>y</italic>-axis) MIP of the brain. All scale bars, 50 µm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80660-fig2-v2.tif"/></fig><p>As the number of MCFO samples for a given GAL4 line increases, the probability of labeling additional unique neurons diminishes until every neuron labeled by that GAL4 line is represented within the MCFO dataset. Sparser lines approach saturation more rapidly, especially because we can use higher Flp activity to label a greater fraction of available GAL4 neurons per sample without overwhelming detection. Thus, in Phase 2 we processed fewer samples for Category 2 GAL4 lines than for Category 3. In addition to diminishing returns within each GAL4 line, there are diminishing returns within each region of the CNS. Although recent estimates vary (37–100k neurons for the central brain including subesophageal ganglion but not the optic lobes, 15–20k for the VNC; <xref ref-type="bibr" rid="bib4">Bates et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Godfrey et al., 2021</xref>; <xref ref-type="bibr" rid="bib37">Mu et al., 2021</xref>; <xref ref-type="bibr" rid="bib47">Raji and Potter, 2021</xref>), the adult <italic>Drosophila</italic> central brain has many more neurons than the VNC, suggesting earlier diminishing returns in the VNC. Thus, we focused Phase 2 more heavily on the brain than the VNC, which together with the above density adjustment led to imaging on average 6.0 brains in Category 2 or 9.1 brains in Category 3, and 2.5 VNCs per line across both categories.</p></sec><sec id="s2-2"><title>MCFO labeling observations</title><p>The large number of lines processed under mostly uniform MCFO conditions provided an opportunity to observe, at scale, some features of MCFO labeling with the specific Flp recombinase drivers used here. Similar observations were noted previously (<xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>). As with R57C10-GAL4, which contains the same fragment of the <italic>synaptobrevin</italic> enhancer region (<xref ref-type="bibr" rid="bib43">Pfeiffer et al., 2008</xref>), R57C10-Flp is thought to be exclusively expressed in postmitotic neurons. In contrast, hs-Flp is expected to label most if not all cells in the fly, including neurons, glia, and trachea, as reviewed in <xref ref-type="bibr" rid="bib1">Ashburner and Bonner, 1979</xref>. Thus, glial patterns were obtained in 8% of lines (36 of 460 lines tabulated) in Phase 2 with <italic>pBPhsFlp2::PEST in attP3</italic>. This obscured neurons in maximum intensity projections (MIPs), but typically did not impair three-dimensional visualization or searching, and may prove of use for future glial studies (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). For example, the split-GAL4 approach has also been successfully applied to several types of glia in the optic lobe (<xref ref-type="bibr" rid="bib13">Davis et al., 2020</xref>).</p><p>Kenyon cells of the mushroom body were labeled at different rates with each reporter. We scored for the presence of Kenyon cell labeling in a random sample of 10% of the total lines imaged (<italic>n</italic> = 460 lines). Labeling manifested as either distinctly labeled neurons, a relatively faint hazy labeling or both. Kenyon cells were much more commonly labeled using hs-Flp MCFO (430 lines, or 93%) than with R57C10-Flp MCFO (44 lines, or 10%) or UAS-GFP (111 lines, or 24%; <xref ref-type="fig" rid="fig2">Figure 2</xref>). Most frequently lines had unlabeled Kenyon cells with GFP and R57C10-Flp MCFO and labeled Kenyon cells with hs-Flp (253 lines, or 55%; <xref ref-type="fig" rid="fig2">Figure 2E</xref>). Lines were also observed with labeled Kenyon cells using GFP and hs-Flp MCFO, but not R57C10-Flp (59 lines, or 13%; <xref ref-type="fig" rid="fig2">Figure 2F</xref>). As the Kenyon cells are well characterized (and thus an unlikely target for new split-GAL4s), compact, and easily identified, this labeling can be ignored except when substantially brighter than other neurons of interest.</p><p>A characteristic ascending neuron (sometimes referred to as ‘sparse T’) was observed at very high frequency. The neuron(s) has a cell body near the metathoracic ganglion and projections ascending to the anterior then the posterior brain, loosely resembling the letter ‘T’ in MIP images (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). It was observed in at least one sample from over 60% of lines crossed to either MCFO reporter (67 lines in Phase 1 and 64 lines in Phase 2, out of 107 lines scored) and was likely present but obscured in other lines. The greater density of labeling in full GAL4 patterns (when crossed to UAS-GFP) made scoring more difficult, yet a similar neuron was seen in 22 of the same 107 lines. This suggests that the high labeling frequency of this neuron in our dataset is a property of the GAL4 collections rather than an artifact of our sampling methods. No other neurons were observed to be so frequently labeled.</p></sec><sec id="s2-3"><title>Neuron searching across image collections</title><p>This image collection makes it possible to identify GAL4 driver lines with expression in identified single neurons using manual or computational searches without the need for new anatomical experiments. The cellular resolution of the data enables many analyses that are impossible with the existing libraries of full GAL4 driver expression patterns. The single-cell data are particularly useful for identifying a neuron in both EM and LM datasets.</p><p>Although LM images do not match the synaptic resolution of EM data, they can provide additional, complementary anatomical information. First, identification of LM matches provides an independent quality check for EM reconstructions (e.g., <xref ref-type="bibr" rid="bib51">Scheffer et al., 2020</xref>; <xref ref-type="bibr" rid="bib45">Phelps et al., 2021</xref>). Second, the LM data often include multiple examples of a cell type and thus provide insights into variable features of cell shapes. Finally, except for the optic lobes, our LM data include the full brain and (for many specimens) VNC and thus provide the full shape of cells that are only partly contained in current EM volumes. For example, the Hemibrain dataset does not fully include neurons that span both brain hemispheres or project to or from the VNC (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). It is thus important to be able to perform EM/LM matching.</p><p>While accurate matching of EM reconstructions with single-cell LM images can sometimes be achieved by direct visual inspection (e.g., <xref ref-type="bibr" rid="bib54">Takemura et al., 2013</xref>), automated approaches for image alignment, segmentation, and search are essential for efficient use of these large datasets. Alignment here was accomplished by registering all LM and EM data to JRC2018 brain and VNC templates (<xref ref-type="bibr" rid="bib6">Bogovic et al., 2020</xref>). We have also made the neuron search tool NeuronBridge (<ext-link ext-link-type="uri" xlink:href="https://neuronbridge.janelia.org/">https://neuronbridge.janelia.org/</ext-link>) (<xref ref-type="bibr" rid="bib11">Clements et al., 2022</xref>) publicly available.</p><p>NeuronBridge currently allows the user to perform anatomical similarity searches between published datasets reported by Janelia’s FlyLight and FlyEM Team Projects. Searching is based on two approaches: (1) Color Depth MIP (CDM), which allows direct comparisons of expression similarity in registered images without the need for a complete skeletonization (<xref ref-type="bibr" rid="bib41">Otsuna et al., 2018</xref>) and (2) PatchPerPixMatch (PPPM), which enhances NBLAST to find groups of neuron segments (identified in our samples by PatchPerPix segmentation) that best match a target neuron (<xref ref-type="bibr" rid="bib12">Costa et al., 2016</xref>; <xref ref-type="bibr" rid="bib22">Hirsch et al., 2020</xref>; <xref ref-type="bibr" rid="bib31">Mais et al., 2021</xref>).</p><p>The basic strategy of CDM searching is to represent neuronal expression with a two-dimensional MIP, using color to indicate the third depth dimension. Two aligned brain images can then be compared by looking for pixels of similar color at similar <italic>x</italic>–<italic>y</italic> coordinates of their color depth MIPs. The color depth MIP search approach used for NeuronBridge was extended in several ways to improve matches for denser MCFO data (<xref ref-type="bibr" rid="bib42">Otsuna et al., 2023</xref>). These include (1) preprocessing the MCFO images with direction selective local thresholding (<xref ref-type="bibr" rid="bib26">Kawase et al., 2015</xref>) 3D segmentation to create a separate color depth MIP for each fully connected component; (2) color depth searching using mirrored EM Hemibrain neurons as masks and MCFO images as target libraries; and (3) weighting of match scores based on signal outside of the search masks.</p><p>PPPM searching is based on the evaluation of fully (but often imperfectly) segmented neurons (<xref ref-type="bibr" rid="bib22">Hirsch et al., 2020</xref>; <xref ref-type="bibr" rid="bib31">Mais et al., 2021</xref>). The underlying NBLAST algorithm compares the similarity in 3D location and neuronal arbor orientation at many points along two neuron segments. PPPM looks for an optimal combination of neuron segments that together maximize an NBLAST-derived similarity score for the target neuron. It includes optimizations for identifying non-overlapping segments that tile a target, along with positive weighting for segments of similar color, as would be expected from an MCFO neuron broken into multiple segments.</p><p>These comparisons are currently pre-computed as data are added or updated in NeuronBridge, so searching is fast. Searches can begin at NeuronBridge given a GAL4 line name or EM body ID, or from FlyEM’s neuPrint (<ext-link ext-link-type="uri" xlink:href="https://neuprint.janelia.org/">https://neuprint.janelia.org/</ext-link>) (<xref ref-type="bibr" rid="bib9">Clements et al., 2020</xref>; <xref ref-type="bibr" rid="bib51">Scheffer et al., 2020</xref>) and FlyLight’s Gen1 MCFO (<ext-link ext-link-type="uri" xlink:href="https://gen1mcfo.janelia.org/">https://gen1mcfo.janelia.org/</ext-link>) and Split-GAL4 anatomy (<ext-link ext-link-type="uri" xlink:href="https://splitgal4.janelia.org/">https://splitgal4.janelia.org/</ext-link>) websites, leading directly to potential matches in the complementary modality. Search results are sorted by match quality and displayed for easy comparison (<xref ref-type="bibr" rid="bib11">Clements et al., 2022</xref>). The color depth MIP format is also well suited for fast visual inspection of search results, simplifying the exclusion of false positives, which are difficult to avoid without compromising search sensitivity. Search results are linked directly to corresponding data in other online resources such as Virtual Fly Brain (<xref ref-type="bibr" rid="bib34">Milyaev et al., 2012</xref>).</p><p>In addition to pre-computed search results for published datasets, we have also made custom search capability available in NeuronBridge (<xref ref-type="bibr" rid="bib11">Clements et al., 2022</xref>). An unaligned 3D image stack can be uploaded, and the service will register it to the JRC2018 standard reference template (<xref ref-type="bibr" rid="bib6">Bogovic et al., 2020</xref>). CDMs are automatically generated from the aligned image, and an interactive selection tool allows the user to choose a channel and mask a target neuron for the search. Targets can be searched against either the EM or LM image database, in a highly parallel (~3000 threads) cloud-based implementation that completes within a few minutes. Custom search results are browsed in the same way as pre-computed results.</p></sec><sec id="s2-4"><title>Search approach evaluation</title><p>We performed limited evaluations of CDM and PPPM search performance between the EM Hemibrain (<xref ref-type="bibr" rid="bib51">Scheffer et al., 2020</xref>) and the Gen1 MCFO dataset in the context of making split-GAL4 lines specifically targeting EM bodies of interest (<xref ref-type="fig" rid="fig3">Figure 3</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Electron microscopy (EM)/light microscopy (LM) search for split-GAL4 creation.</title><p>Neuron search techniques allow for the identification of Gen1 MultiColor FlpOut (MCFO) images containing an EM body of interest. The corresponding Gen1 GAL4 lines should label the same neuron with other upstream activation sequence (UAS) reporters, as should split-GAL4 hemidrivers constructed with the same enhancer fragment. The two hemidrivers can then be combined into a split-GAL4 with the aim of generating a driver that specifically targets that neuron. An example is shown of the anticipated search process, from a neuron identified via EM to the creation of a split-GAL4 driver. As in <xref ref-type="fig" rid="fig1">Figure 1</xref>, NeuronBridge displays color depth maximum intensity projections (MIPs) of single MCFO markers rather than the full MCFO image, so color changes indicate depth rather than different neurons. NeuronBridge result order was reformatted for display purposes. The example shown includes FlyEM Hemibrain body ID 733036127 (<xref ref-type="bibr" rid="bib51">Scheffer et al., 2020</xref>), Generation 1 GAL4 lines R17C11-GAL4, R52G04-GAL4, and split-GAL4 MB310C (MBON07) (<xref ref-type="bibr" rid="bib25">Jenett et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Aso et al., 2014b</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80660-fig3-v2.tif"/></fig><p>Search performance can be evaluated in several ways depending on the application (<xref ref-type="bibr" rid="bib12">Costa et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Otsuna et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Mais et al., 2021</xref>). We refer here to ‘forward’ and ‘reverse’ analysis in the context of split-GAL4 creation. Forward analysis consisted of direct qualitative evaluation of EM to LM search results, determining whether top LM results appeared to contain the searched for EM body. Forward analysis is best performed with detailed knowledge of the examined neurons to avoid false positives, and we restricted our analyzed set of neurons accordingly. Reverse analysis made use of previously documented associations between split-GAL4 lines and EM bodies. If a split-GAL4 line labels a neuron, its constituent split hemidrivers should as well, as should some MCFO of Gen1 GAL4 lines with the same enhancers. We thus evaluated whether known EM/LM matches were highly ranked within the search results. Due to the stochastic nature of MCFO, not every sample of a valid matching GAL4 line will contain the target neuron.</p><p>Evaluation of the search approaches also addressed neuron coverage of the Gen1 MCFO dataset. For both search directions the total number of correct matching samples and GAL4 lines gave a measure of how completely the Gen1 MCFO dataset labels each queried neuron.</p><p>We performed forward analysis on the top 100 CDM and PPPM Phase 1 Gen1 MCFO search results for 10 Hemibrain bodies (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Both CDM and PPPM correctly identified many highly ranked matches in the dataset for each examined EM body. CDM identified 17.6 ± 8.3 (average ± standard deviation) correct lines per Hemibrain body, whereas PPPM identified 20.1 ± 10.6.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Forward analysis: direct evaluation of Color Depth Maximum intensity projection (CDM) and PatchPerPixMatch (PPPM) search results.</title><p>EM bodies were searched for in Phase 1 40× Gen1 MultiColor FlpOut (MCFO) light images using CDM and PPPM approaches. Search results were qualitatively evaluated by an anatomical expert for the presence of the sought neuron. Most results were scored based on color depth maximum intensity projection (MIP) images. Full image stacks were used to score about 20% of samples, including the majority of samples scored as containing the sought neuron. The cumulative number of correct matches found is plotted against the depth of searching for CDM (green) and PPPM (magenta). (<bold>A</bold>) Average results for each search approach are plotted in bold on top of individual results. (<bold>B</bold>) Cell type LC18 (Hemibrain body 1722342048) search result evaluation. (<bold>C</bold>) Cell type CT1 (Hemibrain body 1311993208) search result evaluation.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Table of forward analysis results by cell type.</title><p>Table shows all individual scores and the following metrics: the number of lines independently identified by CDM and PPPM, number only identified by one approach (XOR), number identified by both approaches (AND), and total number identified (OR).</p></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-80660-fig4-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80660-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Forward analysis individual plots for Color Depth Maximum intensity projection (CDM) and PatchPerPixMatch (PPPM).</title><p>(<bold>A–J</bold>) Individual CDM and PPPM results for the indicated cell types. (<bold>K</bold>) All cell types composited with partial lobula and lobula plate. Includes duplicated images from <xref ref-type="fig" rid="fig4">Figure 4</xref>. Electron microscopy (EM) images are from <ext-link ext-link-type="uri" xlink:href="https://neuprint.janelia.org">https://neuprint.janelia.org</ext-link> (<xref ref-type="bibr" rid="bib9">Clements et al., 2020</xref>; <xref ref-type="bibr" rid="bib51">Scheffer et al., 2020</xref>). <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80660-fig4-figsupp1-v2.tif"/></fig></fig-group><p>For cell type LC18, PPPM outperformed CDM, with 24 and 13 correct matches in the top 100, respectively (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). For cell type CT1, on the other hand, CDM correctly found 8 results in the top 100, compared to 3 for PPPM (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). More generally, CDM and PPPM each identified many lines in the top 100 results that were not identified by the other search approach (<xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>). CDM uniquely identified 8.2 ± 6.1 and PPPM uniquely identified 10.7 ± 8.7 lines, respectively.</p><p>Thus, at least for this limited set of neurons, the Gen1 MCFO collection isolates enough examples of each neuron to likely create a split-GAL4 combination. CDM and PPPM successfully identify these correct matches, although they are interspersed with a larger number of false matches. Both approaches varied widely by neuron, without obvious correlation to neuron morphology (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Although all 10 neurons examined here yielded at least 9 matching lines, we do not expect this to hold for every neuron. It remains likely that expanding the MCFO collection with more samples or more drivers would improve the chances of obtaining a good set of matches.</p><p>We extended the PPPM reverse analysis in <xref ref-type="bibr" rid="bib31">Mais et al., 2021</xref> with a comparison to CDM (<xref ref-type="table" rid="table2">Table 2</xref>). We examined nine Hemibrain bodies, each with 2–13 published split-GAL4 associations (<xref ref-type="bibr" rid="bib52">Schretter et al., 2020</xref>; <xref ref-type="bibr" rid="bib60">Wang et al., 2020b</xref>). The best rank of each known-matching line was recorded, with <xref ref-type="table" rid="table2">Table 2</xref> showing the median line rank and the percentage of lines with ranks in the top 50 results. PPPM and CDM both had median line ranks under 100 for most EM bodies. PPPM was somewhat more consistent, with 33–80% of known matches in the top 50 results, compared to 0–100% for CDM. As with the forward analysis, each approach performed better on some neurons than the other approach.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Reverse analysis: scoring known match search ranks in Color Depth Maximum intensity projection (CDM) and PatchPerPixMatch (PPPM) results.</title><p>PPPM and CDM search results on nine Hemibrain bodies were scored for the presence of known GAL4 matches from the literature (<xref ref-type="bibr" rid="bib52">Schretter et al., 2020</xref>; <xref ref-type="bibr" rid="bib59">Wang et al., 2020a</xref>). Only the top-ranking sample for each line and EM body comparison was considered. Searches were performed across only Phase 140× Gen1 MCFO collection data. vpoDN PPPM median line ranks were 7, 49, &gt;400, and &gt;400. Results for bodies 514850616 and 5813063587 are reformatted from <xref ref-type="bibr" rid="bib31">Mais et al., 2021</xref> Figure 9.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Name</th><th align="left" valign="bottom">Hemibrain body ID</th><th align="left" valign="bottom">Known-matching lines</th><th align="left" valign="bottom">PPPM median line rank</th><th align="left" valign="bottom">CDM median line rank</th><th align="left" valign="bottom">PPPM % in top 50</th><th align="left" valign="bottom">CDM % in top 50</th></tr></thead><tbody><tr><td align="left" valign="bottom">pC1e</td><td align="char" char="." valign="bottom">514850616</td><td align="char" char="." valign="bottom">13</td><td align="char" char="." valign="bottom">14</td><td align="char" char="." valign="bottom">58</td><td align="char" char="." valign="bottom">69%</td><td align="char" char="." valign="bottom">46%</td></tr><tr><td align="left" valign="bottom">pC1d</td><td align="char" char="." valign="bottom">5813063587</td><td align="char" char="." valign="bottom">12</td><td align="char" char="." valign="bottom">28</td><td align="char" char="." valign="bottom">41</td><td align="char" char="." valign="bottom">58%</td><td align="char" char="." valign="bottom">50%</td></tr><tr><td align="left" valign="bottom">aIPg</td><td align="char" char="." valign="bottom">645456880</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">6</td><td align="char" char="." valign="bottom">3</td><td align="char" char="." valign="bottom">80%</td><td align="char" char="." valign="bottom">100%</td></tr><tr><td align="left" valign="bottom">oviDN</td><td align="char" char="." valign="bottom">550655668</td><td align="char" char="." valign="bottom">4</td><td align="char" char="." valign="bottom">70</td><td align="char" char="." valign="bottom">42</td><td align="char" char="." valign="bottom">50%</td><td align="char" char="." valign="bottom">75%</td></tr><tr><td align="left" valign="bottom">oviDN</td><td align="char" char="." valign="bottom">519949044</td><td align="char" char="." valign="bottom">4</td><td align="char" char="." valign="bottom">95</td><td align="char" char="." valign="bottom">41</td><td align="char" char="." valign="bottom">50%</td><td align="char" char="." valign="bottom">50%</td></tr><tr><td align="left" valign="bottom">SAG</td><td align="char" char="." valign="bottom">517587356</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">49</td><td align="char" char="." valign="bottom">78</td><td align="char" char="." valign="bottom">50%</td><td align="char" char="." valign="bottom">0%</td></tr><tr><td align="left" valign="bottom">SAG</td><td align="char" char="." valign="bottom">5812981862</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">44</td><td align="char" char="." valign="bottom">118</td><td align="char" char="." valign="bottom">50%</td><td align="char" char="." valign="bottom">0%</td></tr><tr><td align="left" valign="bottom">vpoDN</td><td align="char" char="." valign="bottom">5813057864</td><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">NA</td><td align="char" char="." valign="bottom">95</td><td align="char" char="." valign="bottom">50%</td><td align="char" char="." valign="bottom">50%</td></tr><tr><td align="left" valign="bottom">DNp13</td><td align="char" char="." valign="bottom">887195902</td><td align="char" char="." valign="bottom">3</td><td align="char" char="." valign="bottom">84</td><td align="char" char="." valign="bottom">53</td><td align="char" char="." valign="bottom">33%</td><td align="char" char="." valign="bottom">33%</td></tr></tbody></table></table-wrap></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have described an extensive MCFO image resource from Generation 1 GAL4 lines, providing single-cell-level resolution of the neurons labeled by each line. The NeuronBridge website allows rapid searching of this resource from published EM datasets or uploaded images. CDM and PPPM search approaches both find valid EM/LM matches for several tested neurons, supporting their effectiveness and the good coverage of the brain by the Gen1 MCFO collection. NeuronBridge has already seen frequent usage (<xref ref-type="bibr" rid="bib5">Bidaye et al., 2020</xref>; <xref ref-type="bibr" rid="bib36">Morimoto et al., 2020</xref>; <xref ref-type="bibr" rid="bib40">Nojima et al., 2021</xref>; <xref ref-type="bibr" rid="bib50">Sareen et al., 2021</xref>; <xref ref-type="bibr" rid="bib65">Zolin et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Israel et al., 2022</xref>; <xref ref-type="bibr" rid="bib56">Tanaka and Clark, 2022</xref>; <xref ref-type="bibr" rid="bib29">Laturney et al., 2022</xref>). Together these tools allow for the rapid determination of likely split-GAL4 lines and other enhancer-based approaches to target most neurons initially found in the FlyEM Hemibrain and eventually in the full <italic>Drosophila</italic> CNS.</p><p>While performing these analyses and practically applying the tools to screen split-GAL4 combinations, we made some qualitative observations: (1) In general, both CDM and PPPM are complimentary and best used in combination, although PPPM tended to bring good matches closer to the top of search results. (2) CDM occasionally struggled with occluded neurons and benefited from examination of full 3D stacks of matching MCFO samples. (3) PPPM correspondingly showed the most improvement in samples with occluded neurons. (4) Both techniques return some highly ranked false positives with clear flaws, such that rankings alone are insufficient for algorithmic association of EM and LM neurons. (5) We estimate the image collection and search techniques can lead to good split combinations for 50–80% of cell types, depending on how clean a combination is needed. More split hemidrivers would likely be needed to increase this rate. The search techniques do not significantly change which cell types can be targeted, but greatly simplify identifying candidate split combinations without requiring as much anatomical expertise.</p><p>There are several caveats for why close EM/LM matches do not always lead to successful split-GAL4 combinations: (1) Many CNS cell types contain multiple neurons that are indistinguishable based on morphology. Thus, two matches for a cell type may label different neurons within the cell type and fail as a split combination. Information from connectomic approaches and other modalities are also continuing to refine cell type definitions. (2) Although split-GAL4 hemidrivers are made with the same enhancer fragments as Gen1 GAL4 lines, they can differ in vector sequence and genomic insertion site. These differences can alter expression patterns and hence split-GAL4 effectiveness. (3) UAS reporters can vary in genomic insertion site, number of UAS elements, and other factors that affect how well they label particular cell types. MCFO reporters in particular can tend to brightly label neurons that are weakly labeled by reporters for the full GAL4 pattern. An examination of the full Gen1 GAL4 patterns (if not too dense) can help predict likely effectiveness of a split combination. (4) GAL4 driver expression can vary temporally, so there could be spatial but not temporal overlap between two split hemidrivers.</p><p>In creating the image resource, we have optimized driver line selection, sample preparation, and imaging to yield the maximum identifiable neurons per sample, per line, and across the central brain and VNC. For the search resource, we have implemented two complementary search approaches that effectively identify neuron matches in an easy to use interface. The image resource should be amenable to analysis with future search approaches as they continue to develop.</p><p>While our focus has been on the EM to split-GAL4 use case, we described other uses, including guiding EM proofreading and extending EM analyses beyond limited regions or sample sizes currently available. We anticipate other uses will be found for this resource.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Fly stocks</title><p>The 5155 Generation 1 GAL4 stocks included in this resource (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) were from <xref ref-type="bibr" rid="bib25">Jenett et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">Tirian and Dickson, 2017</xref>. Lines in the 20×/63× (Annotator) collection were selected by collaborators for individual projects. For the 40× collection we focused on driver lines with available AD or DBD hemidrivers (<xref ref-type="bibr" rid="bib57">Tirian and Dickson, 2017</xref>; <xref ref-type="bibr" rid="bib14">Dionne et al., 2018</xref>). Split-GAL4 stock MB310C consists of <italic>R52G04-p65ADZp in VK00027</italic> and <italic>R17C11-ZpGdbd in attP2</italic> (<xref ref-type="bibr" rid="bib3">Aso et al., 2014b</xref>). UAS reporters are described in key resources table. ‘R57C10-Flp MCFO’ in the text was JRC stock 3023701 for 94% of such samples, and JRC stock 3023700 for 6% of samples from sparser lines. ‘hs-Flp MCFO’ was JRC stock 3023951. See <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for details of individual samples.</p><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Reagent type (species) or resource</th><th align="left" valign="top">Designation</th><th align="left" valign="top">Source or reference</th><th align="left" valign="top">Identifiers</th><th align="left" valign="top">Additional information</th></tr></thead><tbody><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-1; hsPESTOPT_attP3_ 3stop1_X_0036; (w, pBPhsFlp2::PEST in attP3;; pJFRC201-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-HA in VK00005,pJFRC240- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFP-V5-THS-10XUASFRT &gt;STOP &gt; FRT-myr::smGFPFLAG in su(Hw)attP1/TM3,Sb)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64085">BDSC_64085</ext-link> (Janelia stock 1117734)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-2; pBPhsFLP_PEST_ HAV5_FLAG_OLLAS_ X3_0095; (w, pBPhsFlp2::PEST in attP3;; pJFRC210-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-OLLAS in attP2, pJFRC201- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFP-HA in VK0005, pJFRC240-10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFP-V5-THS10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFPFLAG in su(Hw)attP1/TM2)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64086">BDSC_64086</ext-link> (Janelia stock 3022015)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-4; 57C10wt_attp8_ 3stop1; (w, R57C10-Flp2 in su(Hw)attP8;; pJFRC201-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-HA in VK00005,pJFRC240- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFP-V5-THS-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-FLAG in su(Hw)attP1)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64088">BDSC_64088</ext-link> (Janelia stock 1116898)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-5; 57C10PEST_attp8_ 3stop1; (w, R57C10-Flp2::PEST in su(Hw)attP8;; pJFRC201- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFPHA in VK00005, pJFRC240-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-V5-THS-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-FLAG in su(Hw)attP1/TM2)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64089">BDSC_64089</ext-link> (Janelia stock 1116876)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-6; 57C10L_attp8_ 4stop1; (w, R57C10-FlpL in su(Hw)attp8;; pJFRC210-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-OLLAS in attP2, pJFRC201- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFP-HA in VK00005, pJFRC240-10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFP-V5-THS10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFPFLAG in su(Hw)attP1/TM2)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64090">BDSC_64090</ext-link> (Janelia stock 1116894)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-7; 57C10PEST_attp18_ 4stop1; (w, R57C10-Flp2::PEST in attp18;; pJFRC210-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-OLLAS in attP2, pJFRC201- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFPHA in VK00005, pJFRC240-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-V5-THS-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-FLAG in su(Hw)attP1/TM2)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64091">BDSC_64091</ext-link> (Janelia stock 1116875)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-3 derivative; 57C10L_brp_SNAP_ MCFO_X23_0117; (w, R57C10-FlpL in su(Hw)attP8; brp::Snap / CyO; pJFRC201-10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFPHA in VK00005,pJFRC240-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-V5-THS-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-FLAG in su(Hw)attP1/TM6B)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Kohl et al., 2014</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64087">BDSC_64087</ext-link> (Janelia stock 3023700)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">57C10PEST_brp_SNAP_ MCFO_X23_0099; (w, R57C10- Flp2::PEST in attP18; brp::Snap / CyO; pJFRC201-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-HA in VK00005,pJFRC240- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFP-V5-THS-10XUASFRT &gt;STOP &gt; FRT-myr::smGFP-FLAG in su(Hw)attP1/TM6B)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref></td><td align="left" valign="top">(Janelia stock 3023701)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">MCFO-1 derivative; pBPhsFlp2_PEST_ brp_SNAP_ MCFO_0128; (w, pBPhsFlp2::PEST in attP3; brp::Snap / CyO; pJFRC201- 10XUAS-FRT&gt;STOP &gt; FRT-myr::smGFPHA in VK00005,pJFRC240-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-V5-THS-10XUAS-FRT&gt;STOP &gt; FRTmyr::smGFP-FLAG in su(Hw)attP1/TM6B)</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Kohl et al., 2014</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_64085">BDSC_64085</ext-link> (Janelia stock 3023951)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top">pJFRC2-10XUAS-IVS-mCD8::GFP</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib44">Pfeiffer et al., 2010</xref></td><td align="left" valign="top">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_32185">BDSC_32185</ext-link> (Janelia stock 1115125)</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-Brp mouse monoclonal nc82</td><td align="left" valign="top">Developmental Studies Hybridoma Bank (DSHB)</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_2314866">AB_2314866</ext-link></td><td align="left" valign="top">1:30</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-HA rabbit monoclonal C29F4</td><td align="left" valign="top">Cell Signaling Technologies: 3724S</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_1549585">AB_1549585</ext-link></td><td align="left" valign="top">1:300</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-FLAG rat monoclonal DYKDDDDK Epitope Tag Antibody</td><td align="left" valign="top">Novus Biologicals: NBP1-06712</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_1625981">AB_1625981</ext-link></td><td align="left" valign="top">1:200</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">DyLight 550 conjugated anti-V5 mouse monoclonal</td><td align="left" valign="top">AbD Serotec: MCA1360D550GA</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_2687576">AB_2687576</ext-link></td><td align="left" valign="top">1:500</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-RAT IgG (H&amp;L) Goat Polyclonal Antibody ATTO 647N Conjugated</td><td align="left" valign="top">Rockland: 612-156-120</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_10893386">AB_10893386</ext-link></td><td align="left" valign="top">1:300</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Alexa Fluor 594 AffiniPure Donkey Polyclonal Anti-Rabbit IgG (H+L)</td><td align="left" valign="top">Jackson ImmunoResearch Labs: 711-585-152</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_2340621">AB_2340621</ext-link></td><td align="left" valign="top">1:500</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-Green Fluorescent Protein (GFP) Rabbit Polyclonal Antibody, Unconjugated</td><td align="left" valign="top">Thermo Fisher Scientific: A-11122</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_221569">AB_221569</ext-link></td><td align="left" valign="top">1:1000</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Goat Polyclonal anti-Rabbit IgG (H+L) Highly Cross-Adsorbed Antibody, Alexa Fluor 488</td><td align="left" valign="top">Thermo Fisher Scientific: A-11034</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_2576217">AB_2576217</ext-link></td><td align="left" valign="top">1:800</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Goat Polyclonal anti-Mouse IgG (H+L) Highly Cross-Adsorbed Antibody, Alexa Fluor 568</td><td align="left" valign="top">Thermo Fisher Scientific: A-11031</td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:AB_144696">AB_144696</ext-link></td><td align="left" valign="top">1:800</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">Janelia Workstation</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib49">Rokicki et al., 2019</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/JaneliaSciComp/workstation">https://github.com/JaneliaSciComp/workstation</ext-link>; <xref ref-type="bibr" rid="bib23">Howard Hughes Medical Institute, 2023</xref></td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_014302">SCR_014302</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">NeuronBridge codebase</td><td align="left" valign="top"><xref ref-type="bibr" rid="bib11">Clements et al., 2022</xref>; <xref ref-type="bibr" rid="bib10">Clements et al., 2021</xref><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25378/janelia.12159378.v2">https://doi.org/10.25378/janelia.12159378.v2</ext-link></td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">Fiji</td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://fiji.sc">https://fiji.sc</ext-link></td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_0022852">SCR_0022852</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">Affinity Designer</td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://affinity.serif.com/designer/">https://affinity.serif.com/designer/</ext-link></td><td align="left" valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_016952">SCR_016952</ext-link></td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">MCFO Hybrid Chemical Tag &amp; IHC for Adult CNS</td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17504/protocols.io.nyhdft6">https://doi.org/10.17504/protocols.io.nyhdft6</ext-link></td><td align="left" valign="top"/><td align="left" valign="top">Protocol</td></tr><tr><td align="left" valign="top">Other</td><td align="left" valign="top">FlyLight protocols for dissection, immunohistochemistry, and mounting</td><td align="left" valign="top"><ext-link ext-link-type="uri" xlink:href="https://www.janelia.org/project-team/flylight/protocols">https: //www.janelia.org/project-team/flylight/protocols</ext-link></td><td align="left" valign="top"/><td align="left" valign="top">Protocol</td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>Fly crosses, heat shock, and dissection</title><p>Flies were raised on standard corn meal molasses food, typically in at least partial-brightness 24 hr light. All crosses were performed at 21–25°C, with a few exceptions (~2.5% of all samples) performed at 18°C when scheduling necessitated. Crosses with hs-Flp in particular were held at 21°C until adulthood, when they were heat shocked at 37°C for 40 min (Category 2 lines) or 13 min (Category 3 lines). Flies were generally dissected at 5–14 days of adulthood, giving time for R57C10-Flp and then MCFO reporter expression.</p></sec><sec id="s4-3"><title>Tagging and immunohistochemistry</title><p>After dissection of the brain or full CNS, samples were fixed for 55 min in 2% paraformaldehyde.</p><p>For the 40× pipeline a hybrid labeling protocol was used, in which a chemical tag (Brp-SNAP and SNAP-tag ligand) labels the neuropil reference, and immunohistochemistry of MCFO markers labels specific GAL4 neurons (<xref ref-type="bibr" rid="bib27">Kohl et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Meissner et al., 2018</xref>). See Key resources table for specific antibodies and concentrations. Chemical tag labeling of the Brp reference was not as bright as Brp antibody staining with nc82, but was more consistent and had lower background. 40× pipeline samples were washed one to four times for 15 min and then tagged with 2 µM Cy2 SNAP-tag ligand to visualize the Brp-SNAP neuropil the same day, after which immunohistochemistry and DPX mounting followed.</p><p>20×/63× samples used nc82 for neuropil reference labeling, as in <xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>, and typically received four washes of 10 min each after fixation. See <ext-link ext-link-type="uri" xlink:href="https://www.janelia.org/project-team/flylight/protocols">https://www.janelia.org/project-team/flylight/protocols</ext-link> for full MCFO protocols with either nc82 or hybrid Brp-SNAP neuropil labeling.</p></sec><sec id="s4-4"><title>Imaging and image processing</title><p>Imaging was performed using eight Zeiss LSM 710 or 780 laser scanning confocal microscopes over a combined capture time of 11 years. 20×/63× imaging was performed with 20× air and 63× oil objectives to combine rapid scanning of all samples with detailed scanning of regions of interest. 40× imaging was performed with 40× oil objectives to cover the central brain and VNC with good axial resolution in a single pass. Confocal stacks were captured at 0.52 × 0.52 × 1.00 µm (20× objective), 0.19 × 0.19 × 0.38 µm (63×), or 0.44 µm isotropic resolution (40×). 40× resolution was selected to maximize effective <italic>z</italic>-resolution while limiting the size of the full dataset (about 100 TB combined). The field of view was set to the widest 0.7 zoom for 40× and 63× objectives, resulting in heightened lens distortion at the edges of images, which was corrected before stitching (<xref ref-type="bibr" rid="bib6">Bogovic et al., 2020</xref>). The whole brain and VNC (where present) were captured in separate 20× tiles for 20×/63× samples, followed by selected 63× tiles of regions of interest. The central brain and two VNC tiles (where present) were captured for each 40× sample. After merging and distortion correction, overlapping 40×/63× tiles were automatically stitched together, as described (<xref ref-type="bibr" rid="bib63">Yu and Peng, 2011</xref>). Brains and VNCs were aligned to the JRC2018 sex-specific and unisex templates using CMTK software, and color depth MIPs were generated (<xref ref-type="bibr" rid="bib48">Rohlfing and Maurer, 2003</xref>; <xref ref-type="bibr" rid="bib41">Otsuna et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Bogovic et al., 2020</xref>).</p><p>Four-color imaging was configured as described in <xref ref-type="bibr" rid="bib39">Nern et al., 2015</xref>. Briefly, two LSM confocal stacks were captured at each location, one with 488 and 594 nm laser lines and one with 488, 561, and 633 nm laser lines. Stacks were merged together after imaging. Imaging was performed using Zeiss’s ZEN software with a custom MultiTime macro. The macro was programmed to automatically select appropriate laser power for each sample and region, resulting in independent image parameters between samples and between brains and VNCs. Gain was typically set automatically for the 561 and 633 nm channels and manually for 488 and 594 nm. Imaging parameters were held constant within tiles covering a single brain or VNC.</p><p>The image processing pipeline (distortion correction, normalization, merging, stitching, alignment, MIP generation, file compression) was automated using the open-source Janelia Workstation software (<xref ref-type="bibr" rid="bib49">Rokicki et al., 2019</xref>), which was also used to review the secondary results and annotate lines for publishing. Images for published lines were uploaded to AWS S3 (Amazon Web Services) and made available in a public bucket (<ext-link ext-link-type="uri" xlink:href="https://registry.opendata.aws/janelia-flylight/">https://registry.opendata.aws/janelia-flylight/</ext-link>) for download or further analysis on AWS. Original LSM (i.e., lossless TIFF) imagery is available alongside the processed (merged/stitched/aligned) imagery in H5J format. H5J is a ‘visually lossless’ format developed at Janelia, which uses the H.265 codec and differential compression ratios on a per-channel basis to obtain maximum compression while minimizing visually relevant artifacts (see <ext-link ext-link-type="uri" xlink:href="http://data.janelia.org/h5j">http://data.janelia.org/h5j</ext-link>).</p><p>The open-source NeuronBridge tool (<xref ref-type="bibr" rid="bib10">Clements et al., 2021</xref>; <xref ref-type="bibr" rid="bib11">Clements et al., 2022</xref>) is a web application designed for ease of use and accessibility to neuron mappings across large multi-modal datasets. It hosts precomputed matches for publicly available EM and LM datasets originating at Janelia, and also supports ad hoc searches against those datasets based on user data. NeuronBridge was constructed as a single-page application built on the React framework for fast performance, responsiveness, and ease of deployment. The web app and backend services are both deployed to AWS to ensure scalability and reliability, and they use only serverless components to minimize costs. NeuronBridge also takes advantage of the innovative ‘burst-parallel’ compute paradigm (<xref ref-type="bibr" rid="bib17">Fouladi et al., 2019</xref>) to massively scale color depth MIP search by leveraging micro VMs (virtual machines) on AWS Lambda, thereby enabling rapid ad hoc searches across a nominally petabyte-scale dataset.</p></sec><sec id="s4-5"><title>Quality control and expression density categorization</title><p>Samples had to pass quality control at several stages to be included in the final collection. Samples lacking visible neuron expression or too dense for IHC were in most cases excluded prior to imaging. Samples were excluded that contained damage, distortion, debris, or low neuropil reference quality causing a failure to align or an error in the image processing pipeline. Samples with minor issues in neuron channels were typically included if neurons could be distinguished. Every effort was made to accurately track and correct line and sample metadata, but the dataset may still contain occasional errors.</p><p>Selected <italic>Drosophila</italic> lines were qualitatively grouped into Categories 1 through 5 by expression density, primarily using MCFO and less often by full GFP patterns. Category boundaries were selected based on our estimation of the utility of the lines and their anticipated performance for neuron segmentation. Category 1 and 5 samples were excluded due to lack of information, either no unique neurons or too many to label, respectively. Categories 3 and 4 were divided based on estimated difficulty of manual segmentation combined with intuition about future segmentation algorithm improvements, such that Category 3 lines are expected to be tractable for segmentation, whereas Category 4 lines are more challenging. Categories 2 and 3 were divided such that Category 2 mostly contained neurons that could easily be ‘segmented’ by eye, whereas Category 3 had more instances of overlapping neurons that were harder to distinguish.</p></sec><sec id="s4-6"><title>Search approach evaluation</title><p>For the forward analysis, the top 100 NeuronBridge search results were examined for one Hemibrain body in each cell type. About 20% of the samples were checked by opening the image stacks, including the majority of the samples annotated as including the cell type in question.</p><p>Reverse analysis was performed as in <xref ref-type="bibr" rid="bib31">Mais et al., 2021</xref>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con5"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con6"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con7"><p>Investigation</p></fn><fn fn-type="con" id="con8"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con9"><p>Validation, Investigation, Methodology</p></fn><fn fn-type="con" id="con10"><p>Data curation, Validation, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con11"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con12"><p>Data curation, Supervision, Validation, Investigation, Methodology, Project administration</p></fn><fn fn-type="con" id="con13"><p>Data curation, Validation, Investigation, Project administration</p></fn><fn fn-type="con" id="con14"><p>Data curation, Validation, Investigation, Methodology</p></fn><fn fn-type="con" id="con15"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con16"><p>Supervision, Funding acquisition, Project administration</p></fn><fn fn-type="con" id="con17"><p>Software, Visualization</p></fn><fn fn-type="con" id="con18"><p>Software, Visualization</p></fn><fn fn-type="con" id="con19"><p>Software, Formal analysis, Visualization, Methodology</p></fn><fn fn-type="con" id="con20"><p>Data curation, Software, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con21"><p>Data curation, Software, Validation</p></fn><fn fn-type="con" id="con22"><p>Conceptualization, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con23"><p>Conceptualization, Supervision</p></fn><fn fn-type="con" id="con24"><p>Conceptualization, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con25"><p>Investigation</p></fn><fn fn-type="con" id="con26"><p>Investigation</p></fn><fn fn-type="con" id="con27"><p>Investigation</p></fn><fn fn-type="con" id="con28"><p>Conceptualization, Software, Formal analysis, Supervision, Validation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con29"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Project administration</p></fn><fn fn-type="con" id="con30"><p>Software, Formal analysis, Validation, Visualization, Methodology</p></fn><fn fn-type="con" id="con31"><p>Investigation</p></fn><fn fn-type="con" id="con32"><p>Investigation</p></fn><fn fn-type="con" id="con33"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con34"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con35"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con36"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Project administration</p></fn><fn fn-type="con" id="con37"><p>Conceptualization, Data curation, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Generation 1 MultiColor FlpOut (MCFO) samples included in the study.</title><p>Metadata for the included 74,363 MCFO samples from 5155 Gen1 GAL4 lines are tabulated, including line name, landing site, effector, slide code, creation date, GUID, gender, heat shock duration, objectives, release name, and contributing annotator. See Key resources table for effector codes.</p></caption><media xlink:href="elife-80660-supp1-v2.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-80660-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The footprint of this image resource (~105 TB) exceeds our known current practical limits on standard public data repositories. Thus, we have made all the primary data (and a variety of processed outputs) used in this study freely available under a CC BY 4.0 license at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25378/janelia.21266625.v1">https://doi.org/10.25378/janelia.21266625.v1</ext-link> and through the publicly accessible website <ext-link ext-link-type="uri" xlink:href="https://gen1mcfo.janelia.org">https://gen1mcfo.janelia.org</ext-link>. The images are made searchable with the same permissions on the user-friendly NeuronBridge website <ext-link ext-link-type="uri" xlink:href="https://neuronbridge.janelia.org">https://neuronbridge.janelia.org</ext-link>. NeuronBridge code is available at <xref ref-type="bibr" rid="bib10">Clements et al., 2021</xref> and the application and implementation are discussed further in <xref ref-type="bibr" rid="bib11">Clements et al., 2022</xref>.All other data generated or analyzed during this study are included in the manuscript and supporting files.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Svirskas</surname><given-names>R</given-names></name><name><surname>Rokicki</surname><given-names>K</given-names></name><name><surname>Bates</surname><given-names>A</given-names></name><name><surname>Svirskas</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Fly Brain Anatomy: FlyLight Gen1 and Split-GAL4 Imagery</data-title><source>Registry of Open Data on AWS</source><pub-id pub-id-type="doi">10.25378/janelia.21266625.v1</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work is part of the FlyLight Project Team at Janelia Research Campus, Howard Hughes Medical Institute, Ashburn, VA. Author order includes the following alphabetical groups: FlyLight Project Team, Janelia Scientific Computing Shared Resource, and contributing laboratories. During this effort, the FlyLight Project Team included Megan Atkins, Shelby Bowers, Kari Close, Gina DePasquale, Zack Dorman, Kaitlyn Forster, Jaye Anne Gallagher, Theresa Gibney, Asish Gulati, Joanna Hausenfluck, Yisheng He, Kristin Hendersen, Hsing Hsi Li, Nirmala Iyer, Jennifer Jeter, Lauren Johnson, Rebecca Johnston, Rachel Lazarus, Kelley Lee, Hua-Peng Liaw, Oz Malkesman, Geoffrey Meissner, Brian Melton, Scott Miller, Reeham Motaher, Alexandra Novak, Omatara Ogundeyi, Alyson Petruncio, Jacquelyn Price, Sophia Protopapas, Susana Tae, Athreya Tata, Jennifer Taylor, Allison Vannan, Rebecca Vorimo, Brianna Yarborough, Kevin Xiankun Zeng, and Chris Zugates, with Steering Committee of Yoshinori Aso, Gwyneth Card, Barry Dickson, Reed George, Wyatt Korff, Gerald Rubin, and James Truman. We thank Gudrun Ihrke and Project Technical Resources for management coordination and staff support. We thank Melanie Radcliff for administrative support. We thank Barret Pfeiffer for his early work in developing the MCFO method. We thank Teri Ngo for her early collaborations with FlyLight. We thank Kei Ito, Kristin Scott, and Michael H Dickinson for contributions to visitor and team projects. For setting up thousands of crosses, we thank the Janelia Fly Facility: Amanda Cavallaro, Tam Dang, Guillermo Gonzalez, Scarlett Harrison, Jui-Chun Kao, Todd R Laverty, Brenda Perez, Brandi Sharp, Viruthika Vallanadu, and Grace Zheng. We thank Karen Hibbard for establishing the brp-SNAP MCFO reporter stocks. We thank Mark Bolstad, Tom Dolafi, Leslie L Foster, Sean Murphy, Donald J Olbris, Todd Safford, Eric Trautman, and Yang Yu for their work on software infrastructure. We thank Ruchi Parekh and Stephen M Plaza for EM/LM coordination. Stocks obtained from the Bloomington <italic>Drosophila</italic> Stock Center (NIH P40OD018537) were used in this study. We thank them, especially Annette Parks, Cale Whitworth, and Sam Zheng, for the maintenance and distribution of stocks from the Janelia collection. Funding was provided by Howard Hughes Medical Institute. This article is subject to HHMI’s Open Access to Publications policy. HHMI lab heads and project team leads have previously granted a nonexclusive CC BY 4.0 license to the public and a sublicensable license to HHMI in their research articles. Pursuant to those licenses, the author-accepted manuscript of this article can be made freely available under a CC BY 4.0 license immediately upon publication.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>M</given-names></name><name><surname>Bonner</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>The induction of gene activity in <italic>Drosophila</italic> by heat shock</article-title><source>Cell</source><volume>17</volume><fpage>241</fpage><lpage>254</lpage><pub-id pub-id-type="doi">10.1016/0092-8674(79)90150-8</pub-id><pub-id pub-id-type="pmid">110462</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aso</surname><given-names>Y</given-names></name><name><surname>Hattori</surname><given-names>D</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Johnston</surname><given-names>RM</given-names></name><name><surname>Iyer</surname><given-names>NA</given-names></name><name><surname>Ngo</surname><given-names>TTB</given-names></name><name><surname>Dionne</surname><given-names>H</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Axel</surname><given-names>R</given-names></name><name><surname>Tanimoto</surname><given-names>H</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>The neuronal architecture of the mushroom body provides a logic for associative learning</article-title><source>eLife</source><volume>3</volume><elocation-id>e04577</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.04577</pub-id><pub-id pub-id-type="pmid">25535793</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aso</surname><given-names>Y</given-names></name><name><surname>Sitaraman</surname><given-names>D</given-names></name><name><surname>Ichinose</surname><given-names>T</given-names></name><name><surname>Kaun</surname><given-names>KR</given-names></name><name><surname>Vogt</surname><given-names>K</given-names></name><name><surname>Belliart-Guérin</surname><given-names>G</given-names></name><name><surname>Plaçais</surname><given-names>PY</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Yamagata</surname><given-names>N</given-names></name><name><surname>Schnaitmann</surname><given-names>C</given-names></name><name><surname>Rowell</surname><given-names>WJ</given-names></name><name><surname>Johnston</surname><given-names>RM</given-names></name><name><surname>Ngo</surname><given-names>TTB</given-names></name><name><surname>Chen</surname><given-names>N</given-names></name><name><surname>Korff</surname><given-names>W</given-names></name><name><surname>Nitabach</surname><given-names>MN</given-names></name><name><surname>Heberlein</surname><given-names>U</given-names></name><name><surname>Preat</surname><given-names>T</given-names></name><name><surname>Branson</surname><given-names>KM</given-names></name><name><surname>Tanimoto</surname><given-names>H</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Mushroom body output neurons encode valence and guide memory-based action selection in <italic>Drosophila</italic></article-title><source>eLife</source><volume>3</volume><elocation-id>e04580</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.04580</pub-id><pub-id pub-id-type="pmid">25535794</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>AS</given-names></name><name><surname>Janssens</surname><given-names>J</given-names></name><name><surname>Jefferis</surname><given-names>GS</given-names></name><name><surname>Aerts</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuronal cell types in the fly: Single-cell anatomy meets single-cell genomics</article-title><source>Current Opinion in Neurobiology</source><volume>56</volume><fpage>125</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2018.12.012</pub-id><pub-id pub-id-type="pmid">30703584</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bidaye</surname><given-names>SS</given-names></name><name><surname>Laturney</surname><given-names>M</given-names></name><name><surname>Chang</surname><given-names>AK</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Bockemühl</surname><given-names>T</given-names></name><name><surname>Büschges</surname><given-names>A</given-names></name><name><surname>Scott</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Two brain pathways initiate distinct forward walking programs in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>108</volume><fpage>469</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.07.032</pub-id><pub-id pub-id-type="pmid">32822613</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Heinrich</surname><given-names>L</given-names></name><name><surname>Ito</surname><given-names>M</given-names></name><name><surname>Jeter</surname><given-names>J</given-names></name><name><surname>Meissner</surname><given-names>G</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Colonell</surname><given-names>J</given-names></name><name><surname>Malkesman</surname><given-names>O</given-names></name><name><surname>Ito</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An unbiased template of the <italic>Drosophila</italic> brain and ventral nerve cord</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0236495</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0236495</pub-id><pub-id pub-id-type="pmid">33382698</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brand</surname><given-names>AH</given-names></name><name><surname>Perrimon</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Targeted gene expression as a means of altering cell fates and generating dominant phenotypes</article-title><source>Development</source><volume>118</volume><fpage>401</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1242/dev.118.2.401</pub-id><pub-id pub-id-type="pmid">8223268</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>AS</given-names></name><name><surname>Lin</surname><given-names>CY</given-names></name><name><surname>Chuang</surname><given-names>CC</given-names></name><name><surname>Chang</surname><given-names>HM</given-names></name><name><surname>Hsieh</surname><given-names>CH</given-names></name><name><surname>Yeh</surname><given-names>CW</given-names></name><name><surname>Shih</surname><given-names>CT</given-names></name><name><surname>Wu</surname><given-names>JJ</given-names></name><name><surname>Wang</surname><given-names>GT</given-names></name><name><surname>Chen</surname><given-names>YC</given-names></name><name><surname>Wu</surname><given-names>CC</given-names></name><name><surname>Chen</surname><given-names>GY</given-names></name><name><surname>Ching</surname><given-names>YT</given-names></name><name><surname>Lee</surname><given-names>PC</given-names></name><name><surname>Lin</surname><given-names>CY</given-names></name><name><surname>Lin</surname><given-names>HH</given-names></name><name><surname>Wu</surname><given-names>CC</given-names></name><name><surname>Hsu</surname><given-names>HW</given-names></name><name><surname>Huang</surname><given-names>YA</given-names></name><name><surname>Chen</surname><given-names>JY</given-names></name><name><surname>Chiang</surname><given-names>HJ</given-names></name><name><surname>Lu</surname><given-names>CF</given-names></name><name><surname>Ni</surname><given-names>RF</given-names></name><name><surname>Yeh</surname><given-names>CY</given-names></name><name><surname>Hwang</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Three-dimensional reconstruction of brain-wide wiring networks in <italic>Drosophila</italic> at single-cell resolution</article-title><source>Current Biology</source><volume>21</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.11.056</pub-id><pub-id pub-id-type="pmid">21129968</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Clements</surname><given-names>J</given-names></name><name><surname>Dolafi</surname><given-names>T</given-names></name><name><surname>Umayam</surname><given-names>L</given-names></name><name><surname>Neubarth</surname><given-names>NL</given-names></name><name><surname>Berg</surname><given-names>S</given-names></name><name><surname>Scheffer</surname><given-names>LK</given-names></name><name><surname>Plaza</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neu Print: Analysis Tools for EM Connectomics</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.16.909465</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Clements</surname><given-names>J</given-names></name><name><surname>Goina</surname><given-names>C</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Kazimiers</surname><given-names>A</given-names></name><name><surname>Kawase</surname><given-names>T</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Svirskas</surname><given-names>R</given-names></name><name><surname>Rokicki</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><source>Neuronbridge codebase</source><publisher-name>Janelia Research Campus</publisher-name><pub-id pub-id-type="doi">10.25378/janelia.12159378.v2</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Clements</surname><given-names>J</given-names></name><name><surname>Goina</surname><given-names>C</given-names></name><name><surname>Hubbard</surname><given-names>PM</given-names></name><name><surname>Kawase</surname><given-names>T</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Svirskas</surname><given-names>R</given-names></name><name><surname>Rokicki</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neuronbridge: An Intuitive Web Application for Neuronal Morphology Search across Large Data Sets</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.07.20.500311</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>M</given-names></name><name><surname>Manton</surname><given-names>JD</given-names></name><name><surname>Ostrovsky</surname><given-names>AD</given-names></name><name><surname>Prohaska</surname><given-names>S</given-names></name><name><surname>Jefferis</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>NBLAST: Rapid, sensitive comparison of neuronal structure and construction of neuron family databases</article-title><source>Neuron</source><volume>91</volume><fpage>293</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.012</pub-id><pub-id pub-id-type="pmid">27373836</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>FP</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Picard</surname><given-names>S</given-names></name><name><surname>Reiser</surname><given-names>MB</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Eddy</surname><given-names>SR</given-names></name><name><surname>Henry</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A genetic, genomic, and computational resource for exploring neural circuit function</article-title><source>eLife</source><volume>9</volume><elocation-id>e50901</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.50901</pub-id><pub-id pub-id-type="pmid">31939737</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dionne</surname><given-names>H</given-names></name><name><surname>Hibbard</surname><given-names>KL</given-names></name><name><surname>Cavallaro</surname><given-names>A</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Genetic reagents for making split-gal4 lines in <italic>Drosophila</italic></article-title><source>Genetics</source><volume>209</volume><fpage>31</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1534/genetics.118.300682</pub-id><pub-id pub-id-type="pmid">29535151</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>MJ</given-names></name><name><surname>Frechter</surname><given-names>S</given-names></name><name><surname>Bates</surname><given-names>AS</given-names></name><name><surname>Dan</surname><given-names>C</given-names></name><name><surname>Huoviala</surname><given-names>P</given-names></name><name><surname>Roberts</surname><given-names>RJ</given-names></name><name><surname>Schlegel</surname><given-names>P</given-names></name><name><surname>Dhawan</surname><given-names>S</given-names></name><name><surname>Tabano</surname><given-names>R</given-names></name><name><surname>Dionne</surname><given-names>H</given-names></name><name><surname>Christoforou</surname><given-names>C</given-names></name><name><surname>Close</surname><given-names>K</given-names></name><name><surname>Sutcliffe</surname><given-names>B</given-names></name><name><surname>Giuliani</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>F</given-names></name><name><surname>Costa</surname><given-names>M</given-names></name><name><surname>Ihrke</surname><given-names>G</given-names></name><name><surname>Meissner</surname><given-names>GW</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name><name><surname>Aso</surname><given-names>Y</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Jefferis</surname><given-names>GS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neurogenetic dissection of the <italic>Drosophila</italic> lateral horn reveals major outputs, diverse behavioural functions, and interactions with the mushroom body</article-title><source>eLife</source><volume>8</volume><elocation-id>e43079</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.43079</pub-id><pub-id pub-id-type="pmid">31112130</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischbach</surname><given-names>KF</given-names></name><name><surname>Dittrich</surname><given-names>APM</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The optic lobe of <italic>Drosophila melanogaster</italic>. I. A golgi analysis of wild-type structure</article-title><source>Cell and Tissue Research</source><volume>258</volume><fpage>441</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.1007/BF00218858</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fouladi</surname><given-names>S</given-names></name><name><surname>Romero</surname><given-names>F</given-names></name><name><surname>Iter</surname><given-names>D</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Chatterjee</surname><given-names>S</given-names></name><name><surname>Kozyrakis</surname><given-names>C</given-names></name><name><surname>Zaharia</surname><given-names>M</given-names></name><name><surname>Winstein</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>From laptop to lambda: Outsourcing everyday jobs to thousands of transient functional containers</article-title><conf-name>In 2019 USENIX Annual Technical Conference</conf-name></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>S</given-names></name><name><surname>Takemura</surname><given-names>SY</given-names></name><name><surname>Ting</surname><given-names>CY</given-names></name><name><surname>Huang</surname><given-names>S</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Luan</surname><given-names>H</given-names></name><name><surname>Rister</surname><given-names>J</given-names></name><name><surname>Thum</surname><given-names>AS</given-names></name><name><surname>Yang</surname><given-names>M</given-names></name><name><surname>Hong</surname><given-names>ST</given-names></name><name><surname>Wang</surname><given-names>JW</given-names></name><name><surname>Odenwald</surname><given-names>WF</given-names></name><name><surname>White</surname><given-names>BH</given-names></name><name><surname>Meinertzhagen</surname><given-names>IA</given-names></name><name><surname>Lee</surname><given-names>CH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The neural substrate of spectral preference in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>60</volume><fpage>328</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.08.010</pub-id><pub-id pub-id-type="pmid">18957224</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Germani</surname><given-names>F</given-names></name><name><surname>Bergantinos</surname><given-names>C</given-names></name><name><surname>Johnston</surname><given-names>LA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mosaic analysis in <italic>Drosophila</italic></article-title><source>Genetics</source><volume>208</volume><fpage>473</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1534/genetics.117.300256</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Godfrey</surname><given-names>RK</given-names></name><name><surname>Swartzlander</surname><given-names>M</given-names></name><name><surname>Gronenberg</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Allometric analysis of brain cell number in hymenoptera suggests ant brains diverge from general trends</article-title><source>Proceedings. Biological Sciences</source><volume>288</volume><elocation-id>20210199</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2021.0199</pub-id><pub-id pub-id-type="pmid">33757353</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Pan</surname><given-names>Y</given-names></name><name><surname>Gong</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Recent advances in the genetic dissection of neural circuits in <italic>Drosophila</italic></article-title><source>Neuroscience Bulletin</source><volume>35</volume><fpage>1058</fpage><lpage>1072</lpage><pub-id pub-id-type="doi">10.1007/s12264-019-00390-9</pub-id><pub-id pub-id-type="pmid">31119647</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hirsch</surname><given-names>P</given-names></name><name><surname>Mais</surname><given-names>L</given-names></name><name><surname>Kainmueller</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Patchperpix for Instance Segmentation</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2001.07626</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Howard Hughes Medical Institute</collab></person-group><year iso-8601-date="2023">2023</year><data-title>Workstation</data-title><version designator="d4c5d73">d4c5d73</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/JaneliaSciComp/workstation">https://github.com/JaneliaSciComp/workstation</ext-link></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Israel</surname><given-names>S</given-names></name><name><surname>Rozenfeld</surname><given-names>E</given-names></name><name><surname>Weber</surname><given-names>D</given-names></name><name><surname>Huetteroth</surname><given-names>W</given-names></name><name><surname>Parnas</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Olfactory stimuli and Moonwalker sez neurons can drive backward locomotion in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>32</volume><fpage>1131</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.01.035</pub-id><pub-id pub-id-type="pmid">35139358</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenett</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Ngo</surname><given-names>T-TB</given-names></name><name><surname>Shepherd</surname><given-names>D</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Dionne</surname><given-names>H</given-names></name><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Cavallaro</surname><given-names>A</given-names></name><name><surname>Hall</surname><given-names>D</given-names></name><name><surname>Jeter</surname><given-names>J</given-names></name><name><surname>Iyer</surname><given-names>N</given-names></name><name><surname>Fetter</surname><given-names>D</given-names></name><name><surname>Hausenfluck</surname><given-names>JH</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Svirskas</surname><given-names>RR</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Iwinski</surname><given-names>ZR</given-names></name><name><surname>Aso</surname><given-names>Y</given-names></name><name><surname>DePasquale</surname><given-names>GM</given-names></name><name><surname>Enos</surname><given-names>A</given-names></name><name><surname>Hulamm</surname><given-names>P</given-names></name><name><surname>Lam</surname><given-names>SCB</given-names></name><name><surname>Li</surname><given-names>H-H</given-names></name><name><surname>Laverty</surname><given-names>TR</given-names></name><name><surname>Long</surname><given-names>F</given-names></name><name><surname>Qu</surname><given-names>L</given-names></name><name><surname>Murphy</surname><given-names>SD</given-names></name><name><surname>Rokicki</surname><given-names>K</given-names></name><name><surname>Safford</surname><given-names>T</given-names></name><name><surname>Shaw</surname><given-names>K</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name><name><surname>Sowell</surname><given-names>A</given-names></name><name><surname>Tae</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Zugates</surname><given-names>CT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A gal4-driver line resource for <italic>Drosophila</italic> neurobiology</article-title><source>Cell Reports</source><volume>2</volume><fpage>991</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2012.09.011</pub-id><pub-id pub-id-type="pmid">23063364</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawase</surname><given-names>T</given-names></name><name><surname>Sugano</surname><given-names>SS</given-names></name><name><surname>Shimada</surname><given-names>T</given-names></name><name><surname>Hara-Nishimura</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A direction-selective local-thresholding method, dslt, in combination with A dye-based method for automated three-dimensional segmentation of cells and airspaces in developing leaves</article-title><source>The Plant Journal</source><volume>81</volume><fpage>357</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1111/tpj.12738</pub-id><pub-id pub-id-type="pmid">25440085</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohl</surname><given-names>J</given-names></name><name><surname>Ng</surname><given-names>J</given-names></name><name><surname>Cachero</surname><given-names>S</given-names></name><name><surname>Ciabatti</surname><given-names>E</given-names></name><name><surname>Dolan</surname><given-names>MJ</given-names></name><name><surname>Sutcliffe</surname><given-names>B</given-names></name><name><surname>Tozer</surname><given-names>A</given-names></name><name><surname>Ruehle</surname><given-names>S</given-names></name><name><surname>Krueger</surname><given-names>D</given-names></name><name><surname>Frechter</surname><given-names>S</given-names></name><name><surname>Branco</surname><given-names>T</given-names></name><name><surname>Tripodi</surname><given-names>M</given-names></name><name><surname>Jefferis</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Ultrafast tissue staining with chemical tags</article-title><source>PNAS</source><volume>111</volume><fpage>E3805</fpage><lpage>E3814</lpage><pub-id pub-id-type="doi">10.1073/pnas.1411087111</pub-id><pub-id pub-id-type="pmid">25157152</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lai</surname><given-names>SL</given-names></name><name><surname>Lee</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Genetic mosaic with dual binary transcriptional systems in <italic>Drosophila</italic></article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>703</fpage><lpage>709</lpage><pub-id pub-id-type="doi">10.1038/nn1681</pub-id><pub-id pub-id-type="pmid">16582903</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Laturney</surname><given-names>M</given-names></name><name><surname>Sterne</surname><given-names>GR</given-names></name><name><surname>Scott</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Mating Activates Neuroendocrine Pathways Signaling Hunger in <italic>Drosophila</italic> Females</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.10.19.512959</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luan</surname><given-names>H</given-names></name><name><surname>Peabody</surname><given-names>NC</given-names></name><name><surname>Vinson</surname><given-names>CR</given-names></name><name><surname>White</surname><given-names>BH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Refined spatial manipulation of neuronal function by combinatorial restriction of transgene expression</article-title><source>Neuron</source><volume>52</volume><fpage>425</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.08.028</pub-id><pub-id pub-id-type="pmid">17088209</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mais</surname><given-names>L</given-names></name><name><surname>Hirsch</surname><given-names>P</given-names></name><name><surname>Managan</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Rokicki</surname><given-names>K</given-names></name><name><surname>Svirskas</surname><given-names>RR</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name><name><surname>Korff</surname><given-names>W</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Ihrke</surname><given-names>G</given-names></name><name><surname>Meissner</surname><given-names>GW</given-names></name><name><surname>Kainmueller</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Patch per Pix Match for Automated 3d Search of Neuronal Morphologies in Light Microscopy</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.07.23.453511</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Maniates-Selvin</surname><given-names>JT</given-names></name><name><surname>Hildebrand</surname><given-names>DGC</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Kuan</surname><given-names>AT</given-names></name><name><surname>Thomas</surname><given-names>LA</given-names></name><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>Buhmann</surname><given-names>J</given-names></name><name><surname>Azevedo</surname><given-names>AW</given-names></name><name><surname>Shanny</surname><given-names>BL</given-names></name><name><surname>Funke</surname><given-names>J</given-names></name><name><surname>Tuthill</surname><given-names>JC</given-names></name><name><surname>Lee</surname><given-names>WCA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Reconstruction of Motor Control Circuits in Adult <italic>Drosophila</italic> Using Automated Transmission Electron Microscopy</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.10.902478</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meissner</surname><given-names>GW</given-names></name><name><surname>Grimm</surname><given-names>JB</given-names></name><name><surname>Johnston</surname><given-names>RM</given-names></name><name><surname>Sutcliffe</surname><given-names>B</given-names></name><name><surname>Ng</surname><given-names>J</given-names></name><name><surname>Jefferis</surname><given-names>GSXE</given-names></name><name><surname>Cachero</surname><given-names>S</given-names></name><name><surname>Lavis</surname><given-names>LD</given-names></name><name><surname>Malkesman</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Optimization of fluorophores for chemical tagging and immunohistochemistry of <italic>Drosophila</italic> neurons</article-title><source>PLOS ONE</source><volume>13</volume><elocation-id>e0200759</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0200759</pub-id><pub-id pub-id-type="pmid">30110347</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milyaev</surname><given-names>N</given-names></name><name><surname>Osumi-Sutherland</surname><given-names>D</given-names></name><name><surname>Reeve</surname><given-names>S</given-names></name><name><surname>Burton</surname><given-names>N</given-names></name><name><surname>Baldock</surname><given-names>RA</given-names></name><name><surname>Armstrong</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The virtual fly brain browser and query interface</article-title><source>Bioinformatics</source><volume>28</volume><fpage>411</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr677</pub-id><pub-id pub-id-type="pmid">22180411</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morante</surname><given-names>J</given-names></name><name><surname>Desplan</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The color-vision circuit in the medulla of <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>18</volume><fpage>553</fpage><lpage>565</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.02.075</pub-id><pub-id pub-id-type="pmid">18403201</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morimoto</surname><given-names>MM</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Zhao</surname><given-names>A</given-names></name><name><surname>Rogers</surname><given-names>EM</given-names></name><name><surname>Wong</surname><given-names>AM</given-names></name><name><surname>Isaacson</surname><given-names>MD</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Reiser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Spatial readout of visual looming in the central brain of <italic>Drosophila</italic></article-title><source>eLife</source><volume>9</volume><elocation-id>e57685</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57685</pub-id><pub-id pub-id-type="pmid">33205753</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mu</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>SC</given-names></name><name><surname>Turner</surname><given-names>NL</given-names></name><name><surname>McKellar</surname><given-names>CE</given-names></name><name><surname>Dorkenwald</surname><given-names>S</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name><name><surname>Koolman</surname><given-names>S</given-names></name><name><surname>Moore</surname><given-names>M</given-names></name><name><surname>Morejohn</surname><given-names>S</given-names></name><name><surname>Silverman</surname><given-names>B</given-names></name><name><surname>Willie</surname><given-names>K</given-names></name><name><surname>Willie</surname><given-names>R</given-names></name><name><surname>Bland</surname><given-names>D</given-names></name><name><surname>Burke</surname><given-names>A</given-names></name><name><surname>Ashwood</surname><given-names>Z</given-names></name><name><surname>Luther</surname><given-names>K</given-names></name><name><surname>Castro</surname><given-names>M</given-names></name><name><surname>Ogedengbe</surname><given-names>O</given-names></name><name><surname>Silversmith</surname><given-names>W</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Halageri</surname><given-names>A</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Murthy</surname><given-names>M</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>3D Reconstruction of Cell Nuclei in a Full <italic>Drosophila</italic> Brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.11.04.467197</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Namiki</surname><given-names>S</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name><name><surname>Wong</surname><given-names>AM</given-names></name><name><surname>Korff</surname><given-names>W</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The functional organization of descending sensory-motor pathways in <italic>Drosophila</italic></article-title><source>eLife</source><volume>7</volume><elocation-id>e34272</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34272</pub-id><pub-id pub-id-type="pmid">29943730</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Optimized tools for multicolor stochastic labeling reveal diverse stereotyped cell arrangements in the fly visual system</article-title><source>PNAS</source><volume>112</volume><fpage>E2967</fpage><lpage>E2976</lpage><pub-id pub-id-type="doi">10.1073/pnas.1506763112</pub-id><pub-id pub-id-type="pmid">25964354</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nojima</surname><given-names>T</given-names></name><name><surname>Rings</surname><given-names>A</given-names></name><name><surname>Allen</surname><given-names>AM</given-names></name><name><surname>Otto</surname><given-names>N</given-names></name><name><surname>Verschut</surname><given-names>TA</given-names></name><name><surname>Billeter</surname><given-names>JC</given-names></name><name><surname>Neville</surname><given-names>MC</given-names></name><name><surname>Goodwin</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A sex-specific switch between visual and olfactory inputs underlies adaptive sex differences in behavior</article-title><source>Current Biology</source><volume>31</volume><fpage>1175</fpage><lpage>1191</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.12.047</pub-id><pub-id pub-id-type="pmid">33508219</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Ito</surname><given-names>M</given-names></name><name><surname>Kawase</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Color Depth MIP Mask Search: A New Tool to Expedite Split-GAL4 Creation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/318006</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Takemura</surname><given-names>S</given-names></name><name><surname>Shinomiya</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Kawase</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Robust search method for <italic>Drosophila</italic> neurons between electron and light microscopy</article-title><source>In Preparation</source><pub-id pub-id-type="pmid">36820523</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Jenett</surname><given-names>A</given-names></name><name><surname>Hammonds</surname><given-names>AS</given-names></name><name><surname>Ngo</surname><given-names>TTB</given-names></name><name><surname>Misra</surname><given-names>S</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Scully</surname><given-names>A</given-names></name><name><surname>Carlson</surname><given-names>JW</given-names></name><name><surname>Wan</surname><given-names>KH</given-names></name><name><surname>Laverty</surname><given-names>TR</given-names></name><name><surname>Mungall</surname><given-names>C</given-names></name><name><surname>Svirskas</surname><given-names>R</given-names></name><name><surname>Kadonaga</surname><given-names>JT</given-names></name><name><surname>Doe</surname><given-names>CQ</given-names></name><name><surname>Eisen</surname><given-names>MB</given-names></name><name><surname>Celniker</surname><given-names>SE</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Tools for neuroanatomy and neurogenetics in <italic>Drosophila</italic></article-title><source>PNAS</source><volume>105</volume><fpage>9715</fpage><lpage>9720</lpage><pub-id pub-id-type="doi">10.1073/pnas.0803697105</pub-id><pub-id pub-id-type="pmid">18621688</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Ngo</surname><given-names>TTB</given-names></name><name><surname>Hibbard</surname><given-names>KL</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Jenett</surname><given-names>A</given-names></name><name><surname>Truman</surname><given-names>JW</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Refinement of tools for targeted gene expression in <italic>Drosophila</italic></article-title><source>Genetics</source><volume>186</volume><fpage>735</fpage><lpage>755</lpage><pub-id pub-id-type="doi">10.1534/genetics.110.119917</pub-id><pub-id pub-id-type="pmid">20697123</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phelps</surname><given-names>JS</given-names></name><name><surname>Hildebrand</surname><given-names>DGC</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Kuan</surname><given-names>AT</given-names></name><name><surname>Thomas</surname><given-names>LA</given-names></name><name><surname>Nguyen</surname><given-names>TM</given-names></name><name><surname>Buhmann</surname><given-names>J</given-names></name><name><surname>Azevedo</surname><given-names>AW</given-names></name><name><surname>Sustar</surname><given-names>A</given-names></name><name><surname>Agrawal</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Shanny</surname><given-names>BL</given-names></name><name><surname>Funke</surname><given-names>J</given-names></name><name><surname>Tuthill</surname><given-names>JC</given-names></name><name><surname>Lee</surname><given-names>WCA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Reconstruction of motor control circuits in adult <italic>Drosophila</italic> using automated transmission electron microscopy</article-title><source>Cell</source><volume>184</volume><fpage>759</fpage><lpage>774</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.12.013</pub-id><pub-id pub-id-type="pmid">33400916</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Potter</surname><given-names>CJ</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Russler</surname><given-names>EV</given-names></name><name><surname>Liang</surname><given-names>L</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The Q system: A repressible binary system for transgene expression, lineage tracing, and mosaic analysis</article-title><source>Cell</source><volume>141</volume><fpage>536</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2010.02.025</pub-id><pub-id pub-id-type="pmid">20434990</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raji</surname><given-names>JI</given-names></name><name><surname>Potter</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The number of neurons in <italic>Drosophila</italic> and mosquito brains</article-title><source>PLOS ONE</source><volume>16</volume><elocation-id>e0250381</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0250381</pub-id><pub-id pub-id-type="pmid">33989293</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohlfing</surname><given-names>T</given-names></name><name><surname>Maurer</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Nonrigid image registration in shared-memory multiprocessor environments with application to brains, breasts, and bees</article-title><source>IEEE Transactions on Information Technology in Biomedicine</source><volume>7</volume><fpage>16</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1109/titb.2003.808506</pub-id><pub-id pub-id-type="pmid">12670015</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rokicki</surname><given-names>K</given-names></name><name><surname>Bruns</surname><given-names>CM</given-names></name><name><surname>Goina</surname><given-names>C</given-names></name><name><surname>Schauder</surname><given-names>D</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Svirskas</surname><given-names>R</given-names></name><name><surname>Clements</surname><given-names>J</given-names></name><name><surname>Ackerman</surname><given-names>D</given-names></name><name><surname>Kazimiers</surname><given-names>A</given-names></name><name><surname>Foster</surname><given-names>LL</given-names></name><name><surname>Dolafi</surname><given-names>T</given-names></name><name><surname>Bolstad</surname><given-names>M</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Safford</surname><given-names>T</given-names></name><name><surname>Murphy</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Janelia Workstation Codebase</source><publisher-name>Janelia Research Campus</publisher-name></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sareen</surname><given-names>PF</given-names></name><name><surname>McCurdy</surname><given-names>LY</given-names></name><name><surname>Nitabach</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A neuronal ensemble encoding adaptive choice during sensory conflict in <italic>Drosophila</italic></article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4131</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24423-y</pub-id><pub-id pub-id-type="pmid">34226544</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Scheffer</surname><given-names>LK</given-names></name><name><surname>Xu</surname><given-names>CS</given-names></name><name><surname>Januszewski</surname><given-names>M</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Takemura</surname><given-names>S</given-names></name><name><surname>Hayworth</surname><given-names>KJ</given-names></name><name><surname>Huang</surname><given-names>GB</given-names></name><name><surname>Shinomiya</surname><given-names>K</given-names></name><name><surname>Maitin-Shepard</surname><given-names>J</given-names></name><name><surname>Berg</surname><given-names>S</given-names></name><name><surname>Clements</surname><given-names>J</given-names></name><name><surname>Hubbard</surname><given-names>P</given-names></name><name><surname>Katz</surname><given-names>W</given-names></name><name><surname>Umayam</surname><given-names>L</given-names></name><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Ackerman</surname><given-names>D</given-names></name><name><surname>Blakely</surname><given-names>T</given-names></name><name><surname>Bogovic</surname><given-names>J</given-names></name><name><surname>Dolafi</surname><given-names>T</given-names></name><name><surname>Kainmueller</surname><given-names>D</given-names></name><name><surname>Kawase</surname><given-names>T</given-names></name><name><surname>Khairy</surname><given-names>KA</given-names></name><name><surname>Leavitt</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>PH</given-names></name><name><surname>Lindsey</surname><given-names>L</given-names></name><name><surname>Neubarth</surname><given-names>N</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Ito</surname><given-names>M</given-names></name><name><surname>Goldammer</surname><given-names>J</given-names></name><name><surname>Wolff</surname><given-names>T</given-names></name><name><surname>Svirskas</surname><given-names>R</given-names></name><name><surname>Schlegel</surname><given-names>P</given-names></name><name><surname>Neace</surname><given-names>ER</given-names></name><name><surname>Knecht</surname><given-names>CJ</given-names></name><name><surname>Alvarado</surname><given-names>CX</given-names></name><name><surname>Bailey</surname><given-names>DA</given-names></name><name><surname>Ballinger</surname><given-names>S</given-names></name><name><surname>Borycz</surname><given-names>JA</given-names></name><name><surname>Canino</surname><given-names>BS</given-names></name><name><surname>Cheatham</surname><given-names>N</given-names></name><name><surname>Cook</surname><given-names>M</given-names></name><name><surname>Dreher</surname><given-names>M</given-names></name><name><surname>Duclos</surname><given-names>O</given-names></name><name><surname>Eubanks</surname><given-names>B</given-names></name><name><surname>Fairbanks</surname><given-names>K</given-names></name><name><surname>Finley</surname><given-names>S</given-names></name><name><surname>Forknall</surname><given-names>N</given-names></name><name><surname>Francis</surname><given-names>A</given-names></name><name><surname>Hopkins</surname><given-names>GP</given-names></name><name><surname>Joyce</surname><given-names>EM</given-names></name><name><surname>Kim</surname><given-names>S</given-names></name><name><surname>Kirk</surname><given-names>NA</given-names></name><name><surname>Kovalyak</surname><given-names>J</given-names></name><name><surname>Lauchie</surname><given-names>SA</given-names></name><name><surname>Lohff</surname><given-names>A</given-names></name><name><surname>Maldonado</surname><given-names>C</given-names></name><name><surname>Manley</surname><given-names>EA</given-names></name><name><surname>McLin</surname><given-names>S</given-names></name><name><surname>Mooney</surname><given-names>C</given-names></name><name><surname>Ndama</surname><given-names>M</given-names></name><name><surname>Ogundeyi</surname><given-names>O</given-names></name><name><surname>Okeoma</surname><given-names>N</given-names></name><name><surname>Ordish</surname><given-names>C</given-names></name><name><surname>Padilla</surname><given-names>N</given-names></name><name><surname>Patrick</surname><given-names>C</given-names></name><name><surname>Paterson</surname><given-names>T</given-names></name><name><surname>Phillips</surname><given-names>EE</given-names></name><name><surname>Phillips</surname><given-names>EM</given-names></name><name><surname>Rampally</surname><given-names>N</given-names></name><name><surname>Ribeiro</surname><given-names>C</given-names></name><name><surname>Robertson</surname><given-names>MK</given-names></name><name><surname>Rymer</surname><given-names>JT</given-names></name><name><surname>Ryan</surname><given-names>SM</given-names></name><name><surname>Sammons</surname><given-names>M</given-names></name><name><surname>Scott</surname><given-names>AK</given-names></name><name><surname>Scott</surname><given-names>AL</given-names></name><name><surname>Shinomiya</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>C</given-names></name><name><surname>Smith</surname><given-names>K</given-names></name><name><surname>Smith</surname><given-names>NL</given-names></name><name><surname>Sobeski</surname><given-names>MA</given-names></name><name><surname>Suleiman</surname><given-names>A</given-names></name><name><surname>Swift</surname><given-names>J</given-names></name><name><surname>Takemura</surname><given-names>S</given-names></name><name><surname>Talebi</surname><given-names>I</given-names></name><name><surname>Tarnogorska</surname><given-names>D</given-names></name><name><surname>Tenshaw</surname><given-names>E</given-names></name><name><surname>Tokhi</surname><given-names>T</given-names></name><name><surname>Walsh</surname><given-names>JJ</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Horne</surname><given-names>JA</given-names></name><name><surname>Li</surname><given-names>F</given-names></name><name><surname>Parekh</surname><given-names>R</given-names></name><name><surname>Rivlin</surname><given-names>PK</given-names></name><name><surname>Jayaraman</surname><given-names>V</given-names></name><name><surname>Ito</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>George</surname><given-names>R</given-names></name><name><surname>Meinertzhagen</surname><given-names>IA</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Hess</surname><given-names>HF</given-names></name><name><surname>Jain</surname><given-names>V</given-names></name><name><surname>Plaza</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A Connectome and Analysis of the Adult <italic>Drosophila</italic> Central Brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.04.07.030213</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schretter</surname><given-names>CE</given-names></name><name><surname>Aso</surname><given-names>Y</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Dreher</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>MJ</given-names></name><name><surname>Chen</surname><given-names>N</given-names></name><name><surname>Ito</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Parekh</surname><given-names>R</given-names></name><name><surname>Branson</surname><given-names>KM</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cell types and neuronal circuitry underlying female aggression in <italic>Drosophila</italic></article-title><source>eLife</source><volume>9</volume><elocation-id>e58942</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.58942</pub-id><pub-id pub-id-type="pmid">33141021</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterne</surname><given-names>GR</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name><name><surname>Scott</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Classification and genetic targeting of cell types in the primary taste and premotor center of the adult <italic>Drosophila</italic> brain</article-title><source>eLife</source><volume>10</volume><elocation-id>e71679</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.71679</pub-id><pub-id pub-id-type="pmid">34473057</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname><given-names>SY</given-names></name><name><surname>Bharioke</surname><given-names>A</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Vitaladevuni</surname><given-names>S</given-names></name><name><surname>Rivlin</surname><given-names>PK</given-names></name><name><surname>Katz</surname><given-names>WT</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Plaza</surname><given-names>SM</given-names></name><name><surname>Winston</surname><given-names>P</given-names></name><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Horne</surname><given-names>JA</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Takemura</surname><given-names>S</given-names></name><name><surname>Blazek</surname><given-names>K</given-names></name><name><surname>Chang</surname><given-names>LA</given-names></name><name><surname>Ogundeyi</surname><given-names>O</given-names></name><name><surname>Saunders</surname><given-names>MA</given-names></name><name><surname>Shapiro</surname><given-names>V</given-names></name><name><surname>Sigmund</surname><given-names>C</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Scheffer</surname><given-names>LK</given-names></name><name><surname>Meinertzhagen</surname><given-names>IA</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A visual motion detection circuit suggested by <italic>Drosophila</italic> connectomics</article-title><source>Nature</source><volume>500</volume><fpage>175</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1038/nature12450</pub-id><pub-id pub-id-type="pmid">23925240</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname><given-names>SY</given-names></name><name><surname>Xu</surname><given-names>CS</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Rivlin</surname><given-names>PK</given-names></name><name><surname>Parag</surname><given-names>T</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Plaza</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Katz</surname><given-names>WT</given-names></name><name><surname>Umayam</surname><given-names>L</given-names></name><name><surname>Weaver</surname><given-names>C</given-names></name><name><surname>Hess</surname><given-names>HF</given-names></name><name><surname>Horne</surname><given-names>JA</given-names></name><name><surname>Nunez-Iglesias</surname><given-names>J</given-names></name><name><surname>Aniceto</surname><given-names>R</given-names></name><name><surname>Chang</surname><given-names>LA</given-names></name><name><surname>Lauchie</surname><given-names>S</given-names></name><name><surname>Nasca</surname><given-names>A</given-names></name><name><surname>Ogundeyi</surname><given-names>O</given-names></name><name><surname>Sigmund</surname><given-names>C</given-names></name><name><surname>Takemura</surname><given-names>S</given-names></name><name><surname>Tran</surname><given-names>J</given-names></name><name><surname>Langille</surname><given-names>C</given-names></name><name><surname>Le Lacheur</surname><given-names>K</given-names></name><name><surname>McLin</surname><given-names>S</given-names></name><name><surname>Shinomiya</surname><given-names>A</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name><name><surname>Meinertzhagen</surname><given-names>IA</given-names></name><name><surname>Scheffer</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Synaptic circuits and their variations within different columns in the visual system of <italic>Drosophila</italic></article-title><source>PNAS</source><volume>112</volume><fpage>13711</fpage><lpage>13716</lpage><pub-id pub-id-type="doi">10.1073/pnas.1509820112</pub-id><pub-id pub-id-type="pmid">26483464</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>R</given-names></name><name><surname>Clark</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neural mechanisms to exploit positional geometry for collision avoidance</article-title><source>Current Biology</source><volume>32</volume><fpage>2357</fpage><lpage>2374</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.04.023</pub-id><pub-id pub-id-type="pmid">35508172</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Tirian</surname><given-names>L</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The VT GAL4, LexA, and Split-GAL4 Driver Line Collections for Targeted Expression in the <italic>Drosophila</italic> Nervous System</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/198648</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tuthill</surname><given-names>JC</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Holtz</surname><given-names>SL</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Reiser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Contributions of the 12 neuron classes in the fly lamina to motion vision</article-title><source>Neuron</source><volume>79</volume><fpage>128</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.05.024</pub-id><pub-id pub-id-type="pmid">23849200</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Forknall</surname><given-names>N</given-names></name><name><surname>Parekh</surname><given-names>R</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>Circuit and behavioral mechanisms of sexual rejection by <italic>Drosophila</italic> females</article-title><source>Current Biology</source><volume>30</volume><fpage>3749</fpage><lpage>3760</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.07.083</pub-id><pub-id pub-id-type="pmid">32795445</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Forknall</surname><given-names>N</given-names></name><name><surname>Patrick</surname><given-names>C</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Parekh</surname><given-names>R</given-names></name><name><surname>Bock</surname><given-names>D</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>Neural circuitry linking mating and egg laying in <italic>Drosophila</italic> females</article-title><source>Nature</source><volume>579</volume><fpage>101</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2055-9</pub-id><pub-id pub-id-type="pmid">32103180</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>T</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuroarchitecture of the <italic>Drosophila</italic> central complex: A catalog of nodulus and asymmetrical body neurons and a revision of the protocerebral bridge catalog</article-title><source>The Journal of Comparative Neurology</source><volume>526</volume><fpage>2585</fpage><lpage>2611</lpage><pub-id pub-id-type="doi">10.1002/cne.24512</pub-id><pub-id pub-id-type="pmid">30084503</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>M</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Williamson</surname><given-names>WR</given-names></name><name><surname>Morimoto</surname><given-names>MM</given-names></name><name><surname>Reiser</surname><given-names>MB</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Visual projection neurons in the <italic>Drosophila</italic> lobula link feature detection to distinct behavioral programs</article-title><source>eLife</source><volume>5</volume><elocation-id>e21022</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21022</pub-id><pub-id pub-id-type="pmid">28029094</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Automated high speed stitching of large 3D microscopic images</article-title><conf-name>2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro IEEE</conf-name><fpage>238</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1109/ISBI.2011.5872396</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Z</given-names></name><name><surname>Lauritzen</surname><given-names>JS</given-names></name><name><surname>Perlman</surname><given-names>E</given-names></name><name><surname>Robinson</surname><given-names>CG</given-names></name><name><surname>Nichols</surname><given-names>M</given-names></name><name><surname>Milkie</surname><given-names>D</given-names></name><name><surname>Torrens</surname><given-names>O</given-names></name><name><surname>Price</surname><given-names>J</given-names></name><name><surname>Fisher</surname><given-names>CB</given-names></name><name><surname>Sharifi</surname><given-names>N</given-names></name><name><surname>Calle-Schuler</surname><given-names>SA</given-names></name><name><surname>Kmecova</surname><given-names>L</given-names></name><name><surname>Ali</surname><given-names>IJ</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Hanslovsky</surname><given-names>P</given-names></name><name><surname>Jefferis</surname><given-names>GSXE</given-names></name><name><surname>Kazhdan</surname><given-names>M</given-names></name><name><surname>Khairy</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A complete electron microscopy volume of the brain of adult <italic>Drosophila melanogaster</italic></article-title><source>Cell</source><volume>174</volume><fpage>730</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id><pub-id pub-id-type="pmid">30033368</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zolin</surname><given-names>A</given-names></name><name><surname>Cohn</surname><given-names>R</given-names></name><name><surname>Pang</surname><given-names>R</given-names></name><name><surname>Siliciano</surname><given-names>AF</given-names></name><name><surname>Fairhall</surname><given-names>AL</given-names></name><name><surname>Ruta</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Context-Dependent representations of movement in <italic>Drosophila</italic> dopaminergic reinforcement pathways</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1555</fpage><lpage>1566</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00929-y</pub-id><pub-id pub-id-type="pmid">34697455</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80660.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Grunwald Kadow</surname><given-names>Ilona C</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041nas322</institution-id><institution>University of Bonn</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2020.05.29.080473" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2020.05.29.080473"/></front-stub><body><p>This study bridges the gap between connectomic data from the fly hemibrain and driver lines needed for functional experiments. The large collection of labeled single cells clones from a large number of samples now provides the community to search both light microscopic and electron microscopic databases for matches using single cells, or cell types. Overall, this manuscript does a compelling job of describing an important resource for the community, which will hopefully be built upon via the collaborative science of many groups as the field develops.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80660.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Grunwald Kadow</surname><given-names>Ilona C</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041nas322</institution-id><institution>University of Bonn</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.05.29.080473">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.05.29.080473v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;A searchable image resource of <italic>Drosophila</italic> GAL4-driver expression patterns with single neuron resolution&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Claude Desplan as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>As you will see from the detailed reviews, the reviewers found the tools and resource described in your manuscript to be highly valuable to the fly community. Nevertheless, they request and recommend a number of changes to the manuscript and figures (and possibly database) to make the tool more widely accessible and user friendly. Please provide detailed answers to all points below and address in particular the points mentioned in 'recommendations to the authors' by providing additional explanation and/or editing the manuscript text.</p><p>As an additional note, one of the reviewers mentions the discrepancy between the number of central brain neurons cited in this paper (30,000) as compared to more rigorous evaluations from the Potter and Gronenberg labs that cite much higher numbers of neurons. A recent bioRxiv paper from Seung and Murthy (bioRxiv 2021.11.04.467197; doi: https://doi.org/10.1101/2021.11.04.467197) gets closer to the number cited here. It would be important, especially in this type of paper, to be precise in citing these numbers as further papers might reference the current paper as the truth, or at least to mention the discrepancies!</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>Points that might benefit the clarity of the revised manuscript:</p><p>1. Please consider revising Figure 1 to make it more clear which images belong to which label. For example, in Figure 1A and B1, a more accurate description of the images would be helpful (it was unclear that the VNC was not a separate panel from the CNS). Moving 'Gal4' and 'MCFO' text to the bottom of the VNC might help. Also, perhaps revising Figure 1 so it was organized like more of a flow chart (a bit like Figure 3) may be helpful.</p><p>2. Please clarify what makes a brain 'aligned' for upload as a 2D MIP.</p><p>3. Please clarify what score similarity numbers mean.</p><p>4. Quotations around hybrid are not necessary (line 384).</p><p>5. Perhaps abbreviate Color Depth Maximum intensity projection (CDM) without the MIP which adds confusion (line 81).</p><p>6. Material and Methods- For the IHC section it would be helpful if Table 1 was referenced so readers would know where to find the information for the antibodies and dilutions used.</p><p>7. We appreciated methodology differences between Flp methods in the intro. One additional sentence of background introducing this method (with citations) would be helpful for non-expert readers (~lines 61-64).</p><p>8. It would be helpful if the authors elaborate a bit more on the importance of evaluating the search performance of CDM &amp; PPPM approaches in the intro. A sentence clarifying why these are helpful would be appropriate.</p><p>9. Typo 'respectively' (line 300).</p><p>10. Perhaps add a comma at end of line 49.</p><p>11. doi for Rokicki et al. (2019) in the references is not working.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>1) The manuscript mentions that the NeuronBridge tool will be further described in Rokicki et al., 2022 (in preparation). At the same time, the abstract says &quot;we have also developed the NeuronBridge search tool&quot; (lines 26-27) and the introduction &quot;We have released the data, along with the NeuronBridge tool&quot; (line 99). Is the Rokicki et al., 2022 the same publication as the recent preprint Clements et al., 2022 (https://doi.org/10.1101/2022.07.20.500311)?</p><p>It would be helpful if the manuscript was clear on which aspects of NeuronBridge are being described for the first time in this work versus the recent preprint. For example, if it is the integration of the MCFO dataset and/or the application of the search tools, while the development of the tool pertains to the other publication.</p><p>2) lines 182-3: the estimate for number of neurons in the central brain and VNC seems low (30k and 15k respectively). There are more recent estimates from a whole brain connectomics dataset for the brain (Mu et al., 2021, bioRxiv, https://doi.org/10.1101/2021.11.04.467197) which put this number at 43k ± 4k. The Hemibrain dataset which does not include most of the subesophageal zone, already includes 26k (truncated and non-truncated). For the VNC a personal communication in Bates et al., 2019 (https://doi.org/10.1016/j.conb.2018.12.012) suggests ~20k.</p><p>Could the mention of neuron number refer to more recent publications, or present a range?</p><p>3) line 240-1: it is not made clear from the phrasing (&quot;currently allows&quot;) if it is expected that the NeuronBridge tool would integrate EM datasets beyond those generated by the FlyEM team. It would be helpful if this was clarified.</p><p>4) lines 270-1: regarding the option for users to upload an unregistered stack, could it be made clear if, after registration, how users can assess its quality, and thus take that into account when assessing search hits.</p><p>5) from line 286: regarding the reverse search examples, and more generally, providing the user with ways to gather more information on EM neurons or LM GAL4 or split-GAL4 lines. The NeuronBridge website displays a link from the search results to the Virtual Fly Brain website, though this mention is lacking in the manuscript. It would seem useful to add it.</p><p>6) From line 210: the sparse T neuron observed in many lines is an interesting observation. Without a comprehensive analysis to see if other neurons are commonly labeled, it is not clear if the neuron stands out simply because of its morphology. It would be helpful if it was made clear that this neuron might not be unique regarding its high frequency.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>Detailed Comments to the Authors:</p><p>Comments on Data Pre-Processing and Annotation:</p><p>P4, l145: „GAL4 lines were qualitatively categorized by density ….&quot; How was categorization performed? Please provide mathematical details on the quantitative quality measures and the algorithm if done automatically or explain the manual process (e.g. by whom this was done). Directly related to this is a comment on the Materials and methods section (making the above comment partially redundant. I leave it to the authors where best to address this): P15, l439++:</p><p>The description of quality assurance and data categorization processes would benefit from more precision:</p><p>– Who performed the quality control and categorization? What is the professional background of these persons?</p><p>– Where any automatic tools involved in quality assurance? If yes, provide details on tools and implemented methods, and of their use.</p><p>– The provided description of the different categories is imprecise and leaves plenty room for subjective decisions.</p><p>– Were persons doing the categorization (if done manually) provided with a clear protocol on how to decide on the categories? It is e.g. not explained what kind of visualization (2D section, 2D MIP, 3D, interactive 3D?) was used to do the categorization, which might influence the decision. Did people inspect all available imaging data related to a line or did they select a specific image? If I understood this correctly, MCFO is not labeling all neurons of a line. Is it therefore sufficient to inspect only the image of a single sample to define the category of a line or are more required? If not, please explain how many were inspected per line in average?</p><p>– &quot;Category boundaries were initially based on functional properties&quot; What are &quot;functional properties&quot; in this context? Please clarify.</p><p>– You state that category 3 and category 4 were separated using the result on a neuron segmentation algorithm and intuition on future segmentation difficulty. Which segmentation algorithm? What exactly is &quot;future segmentation difficulty&quot; referring to?</p><p>– Category 2 – what exactly do you mean with &quot;segmented&quot; by eye? Based on what kind of visualization? (see above)</p><p>P7, l237: From the text, it was not clear to me if the alignment to JRC2018 included also the EM dataset. As this is essential for the whole matching process, it would be helpful to explicitly mention that alignment has been done for both, LM and EM data.</p><p>Comments on Described Search Approaches</p><p>P7, l250: The reference (Otsuna et al. 2022) seems to contain important details on preprocessing and one of the used matching algorithms. However, the paper is still unpublished and is marked in the reference list as &quot;in preparation&quot;. For transparency and replicability reasons, the authors should ensure that algorithmic details are accessible to the public and either provide a prepublication highlighting the respective method or include method details in this paper.</p><p>P7, l244 + l255 and P15, l419: PPPM requires segmentation of neurons in LM images. However, information on how this segmentation is performed is missing. Please clarify.</p><p>P8, l269+</p><p>Providing a custom processing and search capability for private 3D image stacks is certainly a great service. However, it might also raise concerns of potential users in terms of trust in respect to potential disclosure of private research data after upload. To be transparent in this respect, it would be beneficial to add information on data handling procedures in terms of privacy and security. Simply said, as a user I would like to know what happens with my data and its derivations after upload and processing? Is it deleted? Who has access to it?</p><p>Comments on Search Approach Evaluation:</p><p>The described evaluation approach is only partially feasible to support the very general claim of the authors that &quot;NeuronBridge rapidly and effectively identifies neuron matches ….&quot; (P1, l28; and other parts of the manuscript): Although the evaluation appears to be straight forward and comprehensive at first glance, it lacks scientific rigor in several dimensions (see also comments below) and does not follow established evaluation standards in information retrieval. I understand that a full evaluation of the system according to the state of the art might be out of scope of this paper. However, in this case the claim should highlight that the performed experiments provide a demonstration of the potential of the method to effectively identify neuron matches, but not a proof.</p><p>If the authors want to keep the generality in the claim, they should consider to revise this section in respect to the design of their experiments and the formal selection, justification and use of appropriate quality measures introduced by the information retrieval community. (The following manuscript might serve as an entry point and design further experiments: https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-in-information-retrieval-1.html)</p><p>Besides of the more high-level comment above, I have some remarks that might further illustrate my concerns:</p><p>– The numbers of selected query items and performed queries are too low to draw general conclusions.</p><p>– Transparency of the experience design:</p><p>In both experiments sets of 10 and 9 neurons respectively were selected to perform query result analysis. It remains unclear based on what criteria exactly these neurons were selected, leaving open if there is any bias in the selection which would disqualify the results.</p><p>Forward, &quot;qualitative&quot;, Analysis: A true qualitative evaluation would require the repetition of retrieval experiments with several experts and an investigation of the question if there is e.g. an inter-observer variability, which seems not to be the case here. In this context also information on the number and professional background of the persons who judged on the query results should be added.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80660.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>As you will see from the detailed reviews, the reviewers found the tools and resource described in your manuscript to be highly valuable to the fly community. Nevertheless, they request and recommend a number of changes to the manuscript and figures (and possibly database) to make the tool more widely accessible and user friendly. Please provide detailed answers to all points below and address in particular the points mentioned in 'recommendations to the authors' by providing additional explanation and/or editing the manuscript text.</p><p>As an additional note, one of the reviewers mentions the discrepancy between the number of central brain neurons cited in this paper (30,000) as compared to more rigorous evaluations from the Potter and Gronenberg labs that cite much higher numbers of neurons. A recent bioRxiv paper from Seung and Murthy (bioRxiv 2021.11.04.467197; doi: https://doi.org/10.1101/2021.11.04.467197) gets closer to the number cited here. It would be important, especially in this type of paper, to be precise in citing these numbers as further papers might reference the current paper as the truth, or at least to mention the discrepancies!</p></disp-quote><p>We thank the reviewers for pointing out this issue and their comments in general. We now mention the different recently reported cell counts in the text:</p><p>Line 182. Although recent estimates vary (37k to 100k neurons for the central brain including subesophageal ganglion but not the optic lobes, 15k to 20k for the VNC (Bates 2019, Godfrey 2021, Mu 2021, Raji 2021)), the adult <italic>Drosophila</italic> central brain has many more neurons than the VNC, suggesting earlier diminishing returns in the VNC.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>Points that might benefit the clarity of the revised manuscript:</p><p>1. Please consider revising Figure 1 to make it more clear which images belong to which label. For example, in Figure 1A and B1, a more accurate description of the images would be helpful (it was unclear that the VNC was not a separate panel from the CNS). Moving 'Gal4' and 'MCFO' text to the bottom of the VNC might help. Also, perhaps revising Figure 1 so it was organized like more of a flow chart (a bit like Figure 3) may be helpful.</p></disp-quote><p>Reorganized Figure 1. Replaced split-GAL4 image with a different sample from the same line to illustrate full CNS.</p><disp-quote content-type="editor-comment"><p>2. Please clarify what makes a brain 'aligned' for upload as a 2D MIP.</p></disp-quote><p>This will be addressed on the revised website UI.</p><disp-quote content-type="editor-comment"><p>3. Please clarify what score similarity numbers mean.</p></disp-quote><p>This is already explained by the help page at https://neuronbridge.janelia.org/help, and we are adding more details to the explanation.</p><disp-quote content-type="editor-comment"><p>4. Quotations around hybrid are not necessary (line 384).</p></disp-quote><p>Line 384. Removed quotation marks.</p><disp-quote content-type="editor-comment"><p>5. Perhaps abbreviate Color Depth Maximum intensity projection (CDM) without the MIP which adds confusion (line 81).</p></disp-quote><p>Line 81. Changed to &quot;Color Depth Maximum intensity projection (CDM) search&quot;</p><disp-quote content-type="editor-comment"><p>6. Material and Methods- For the IHC section it would be helpful if Table 1 was referenced so readers would know where to find the information for the antibodies and dilutions used.</p></disp-quote><p>Line 386. Added &quot;See Table 1 for specific antibodies and concentrations.&quot;</p><disp-quote content-type="editor-comment"><p>7. We appreciated methodology differences between Flp methods in the intro. One additional sentence of background introducing this method (with citations) would be helpful for non-expert readers (~lines 61-64).</p></disp-quote><p>Line 65. Added sentences &quot;In brief, MCFO can use several UAS reporters that are independently stochastically activated by low levels of Flp recombinase. Flp levels can be adjusted to tailor MCFO labeling density for different GAL4 lines or purposes.&quot;</p><disp-quote content-type="editor-comment"><p>8. It would be helpful if the authors elaborate a bit more on the importance of evaluating the search performance of CDM &amp; PPPM approaches in the intro. A sentence clarifying why these are helpful would be appropriate.</p></disp-quote><p>Line 86. Added sentence &quot;Overlapping neurons remain challenging to segment manually or algorithmically, making this an area of rapid development. &quot;</p><disp-quote content-type="editor-comment"><p>9. Typo 'respectively' (line 300).</p></disp-quote><p>Line 300. Fixed typo in &quot;respectively&quot;.</p><disp-quote content-type="editor-comment"><p>10. Perhaps add a comma at end of line 49.</p></disp-quote><p>Line 49. Added comma.</p><disp-quote content-type="editor-comment"><p>11. doi for Rokicki et al. (2019) in the references is not working.</p></disp-quote><p>We agree that all DOI links are not being output correctly. It's not clear whether it's a limitation of the publishing system, but we'll try to remove incorrect links.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>1) The manuscript mentions that the NeuronBridge tool will be further described in Rokicki et al., 2022 (in preparation). At the same time, the abstract says &quot;we have also developed the NeuronBridge search tool&quot; (lines 26-27) and the introduction &quot;We have released the data, along with the NeuronBridge tool&quot; (line 99). Is the Rokicki et al., 2022 the same publication as the recent preprint Clements et al., 2022 (https://doi.org/10.1101/2022.07.20.500311)?</p><p>It would be helpful if the manuscript was clear on which aspects of NeuronBridge are being described for the first time in this work versus the recent preprint. For example, if it is the integration of the MCFO dataset and/or the application of the search tools, while the development of the tool pertains to the other publication.</p></disp-quote><p>The intention is for this paper to cover the usage of the NeuronBridge website to search the released data. Rokicki 2022 covers the details of the NeuronBridge application and development.</p><p>Line 26. Changed text &quot;also developed&quot; to &quot;made the images searchable on&quot;.</p><p>Line 99. Replaced sentence with &quot;We have released the image data and made it searchable on the NeuronBridge website together with data from the FlyEM hemibrain and published split-GAL4 lines.&quot;</p><disp-quote content-type="editor-comment"><p>2) lines 182-3: the estimate for number of neurons in the central brain and VNC seems low (30k and 15k respectively). There are more recent estimates from a whole brain connectomics dataset for the brain (Mu et al., 2021, bioRxiv, https://doi.org/10.1101/2021.11.04.467197) which put this number at 43k ± 4k. The Hemibrain dataset which does not include most of the subesophageal zone, already includes 26k (truncated and non-truncated). For the VNC a personal communication in Bates et al., 2019 (https://doi.org/10.1016/j.conb.2018.12.012) suggests ~20k.</p><p>Could the mention of neuron number refer to more recent publications, or present a range?</p></disp-quote><p>Please see response under Essential Revisions.</p><disp-quote content-type="editor-comment"><p>3) line 240-1: it is not made clear from the phrasing (&quot;currently allows&quot;) if it is expected that the NeuronBridge tool would integrate EM datasets beyond those generated by the FlyEM team. It would be helpful if this was clarified.</p></disp-quote><p>We will consider adding other data sets in the future, but for now are focused on adding new FlyLight/FlyEM data sets as they become available.</p><disp-quote content-type="editor-comment"><p>4) lines 270-1: regarding the option for users to upload an unregistered stack, could it be made clear if, after registration, how users can assess its quality, and thus take that into account when assessing search hits.</p></disp-quote><p>The revised website will (a) show an alignment score for each uploaded stack, and (b) allow the user to view the aligned reference channel overlaid on the alignment template, to allow for visual assessment of the registration.</p><disp-quote content-type="editor-comment"><p>5) from line 286: regarding the reverse search examples, and more generally, providing the user with ways to gather more information on EM neurons or LM GAL4 or split-GAL4 lines. The NeuronBridge website displays a link from the search results to the Virtual Fly Brain website, though this mention is lacking in the manuscript. It would seem useful to add it.</p></disp-quote><p>Line 268. Added &quot;Search results are linked directly to corresponding data in other online resources such as Virtual Fly Brain&quot; with citation.</p><disp-quote content-type="editor-comment"><p>6) From line 210: the sparse T neuron observed in many lines is an interesting observation. Without a comprehensive analysis to see if other neurons are commonly labeled, it is not clear if the neuron stands out simply because of its morphology. It would be helpful if it was made clear that this neuron might not be unique regarding its high frequency.</p></disp-quote><p>Line 218. Added &quot;No other neurons were observed to be so frequently labeled.&quot;</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>Detailed Comments to the Authors:</p><p>Comments on Data Pre-Processing and Annotation:</p><p>P4, l145: „GAL4 lines were qualitatively categorized by density ….&quot; How was categorization performed? Please provide mathematical details on the quantitative quality measures and the algorithm if done automatically or explain the manual process (e.g. by whom this was done). Directly related to this is a comment on the Materials and methods section (making the above comment partially redundant. I leave it to the authors where best to address this): P15, l439++:</p><p>The description of quality assurance and data categorization processes would benefit from more precision:</p><p>– Who performed the quality control and categorization? What is the professional background of these persons?</p><p>– Where any automatic tools involved in quality assurance? If yes, provide details on tools and implemented methods, and of their use.</p><p>– The provided description of the different categories is imprecise and leaves plenty room for subjective decisions.</p><p>– Were persons doing the categorization (if done manually) provided with a clear protocol on how to decide on the categories? It is e.g. not explained what kind of visualization (2D section, 2D MIP, 3D, interactive 3D?) was used to do the categorization, which might influence the decision. Did people inspect all available imaging data related to a line or did they select a specific image? If I understood this correctly, MCFO is not labeling all neurons of a line. Is it therefore sufficient to inspect only the image of a single sample to define the category of a line or are more required? If not, please explain how many were inspected per line in average?</p><p>– &quot;Category boundaries were initially based on functional properties&quot; What are &quot;functional properties&quot; in this context? Please clarify.</p><p>– You state that category 3 and category 4 were separated using the result on a neuron segmentation algorithm and intuition on future segmentation difficulty. Which segmentation algorithm? What exactly is &quot;future segmentation difficulty&quot; referring to?</p><p>– Category 2 – what exactly do you mean with &quot;segmented&quot; by eye? Based on what kind of visualization? (see above)</p></disp-quote><p>The reviewer raised a number of concerns related to quality control and qualitative analysis. Quality control was performed by most or all coauthors at many stages of data generation and review. In most cases it was a manual process integrated into routine work and data analysis, such as excluding an image that does not show any labeling or that could not be adequately registered. As described, we also examined the data set as a whole once complete.</p><p>We used the term &quot;qualitative&quot; to convey a manual analysis based on the judgement of the investigator, rather than in the formal context of the field of information retrieval. While we believe most readers of the paper would interpret our usage correctly, we have made several modifications below for clarity.</p><p>We don't feel that the professional background of the person performing the analysis is a relevant detail to include for the quality control and density categorization. In addition, the density categorization only served to facilitate decisions on which labeling conditions to focus on in view of limited resources but does not directly influence subsequent uses of the data (such as searches for neurons of interest).</p><p>Changes:</p><p>Line 145. Added &quot;into rough groups&quot;.</p><p>Line 448. Changed &quot;Category boundaries were initially established based on functional properties.&quot; to &quot;Category boundaries were selected based on our estimation of the utility of the lines and their anticipated performance for neuron segmentation.&quot;</p><p>Line 450. Changed &quot;Categories 3 and 4…&quot; sentence to &quot;Categories 3 and 4 were divided based on estimated difficulty of manual segmentation combined with intuition about future segmentation algorithm improvements, such that Category 3 lines are expected to be tractable for segmentation, whereas Category 4 lines are more challenging.&quot;</p><p>Line 687 (Figure 1 Supplement 1). Changed &quot;the full CNS expression pattern&quot; to &quot;2D MIPs of MCFO and full CNS expression patterns&quot;</p><disp-quote content-type="editor-comment"><p>P7, l237: From the text, it was not clear to me if the alignment to JRC2018 included also the EM dataset. As this is essential for the whole matching process, it would be helpful to explicitly mention that alignment has been done for both, LM and EM data.</p></disp-quote><p>Line 237. Changed &quot;samples&quot; to &quot;LM and EM data&quot;.</p><disp-quote content-type="editor-comment"><p>Comments on Described Search Approaches</p><p>P7, l250: The reference (Otsuna et al. 2022) seems to contain important details on preprocessing and one of the used matching algorithms. However, the paper is still unpublished and is marked in the reference list as &quot;in preparation&quot;. For transparency and replicability reasons, the authors should ensure that algorithmic details are accessible to the public and either provide a prepublication highlighting the respective method or include method details in this paper.</p></disp-quote><p>Development of CDM and PPPM search algorithms and associated pre- and post-processing optimizations has proceeded in parallel with the MCFO data release and NeuronBridge application described in the paper. Mais et al., 2021 describes in detail their work to optimize PPPM. CDM improvements since Otsuna et al., 2018 will be described in Otsuna et al., 2023, which isn't ready yet. While we view the search approach evaluations as showing that neuron matches can be found with CDM and PPPM, the evaluation can't be comprehensive across all neurons, datasets, and algorithm variations.</p><disp-quote content-type="editor-comment"><p>P7, l244 + l255 and P15, l419: PPPM requires segmentation of neurons in LM images. However, information on how this segmentation is performed is missing. Please clarify.</p></disp-quote><p>Line 244. Added &quot;(identified in our samples by PatchPerPix segmentation)&quot; and another Hirsch 2020 citation.</p><disp-quote content-type="editor-comment"><p>P8, l269+</p><p>Providing a custom processing and search capability for private 3D image stacks is certainly a great service. However, it might also raise concerns of potential users in terms of trust in respect to potential disclosure of private research data after upload. To be transparent in this respect, it would be beneficial to add information on data handling procedures in terms of privacy and security. Simply said, as a user I would like to know what happens with my data and its derivations after upload and processing? Is it deleted? Who has access to it?</p></disp-quote><p>This will be addressed on the revised website UI with the addition of an &quot;Uploaded Data Usage and Retention Policy&quot; which the user needs to agree with before uploading data. The full text of the policy is reproduced here:</p><p>&quot;By uploading data to the NeuronBridge alignment and search service, you acknowledge that the data will be converted to a MIP of the aligned image. The image stacks, aligned MIP image, and any other derived data will only be accessible to you, under your personal login, and the HHMI Janelia developers for maintenance purposes until you delete the search. The data is not accessed by Janelia personnel for any other reason. You further acknowledge that this service is free and HHMI, its employees, and officers accept no liability for its use and do not guarantee or warrant the accuracy or utility of the output.&quot;</p><disp-quote content-type="editor-comment"><p>Comments on Search Approach Evaluation:</p><p>The described evaluation approach is only partially feasible to support the very general claim of the authors that &quot;NeuronBridge rapidly and effectively identifies neuron matches ….&quot; (P1, l28; and other parts of the manuscript): Although the evaluation appears to be straight forward and comprehensive at first glance, it lacks scientific rigor in several dimensions (see also comments below) and does not follow established evaluation standards in information retrieval. I understand that a full evaluation of the system according to the state of the art might be out of scope of this paper. However, in this case the claim should highlight that the performed experiments provide a demonstration of the potential of the method to effectively identify neuron matches, but not a proof.</p><p>If the authors want to keep the generality in the claim, they should consider to revise this section in respect to the design of their experiments and the formal selection, justification and use of appropriate quality measures introduced by the information retrieval community. (The following manuscript might serve as an entry point and design further experiments: https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-in-information-retrieval-1.html)</p><p>Besides of the more high-level comment above, I have some remarks that might further illustrate my concerns:</p><p>– The numbers of selected query items and performed queries are too low to draw general conclusions.</p><p>– Transparency of the experience design:</p><p>In both experiments sets of 10 and 9 neurons respectively were selected to perform query result analysis. It remains unclear based on what criteria exactly these neurons were selected, leaving open if there is any bias in the selection which would disqualify the results.</p></disp-quote><p>We acknowledge the limited set of neurons examined in the evaluation of CDM and PPPM search, and tried to weight the claims accordingly in lines 305 and 309 of the submission. We agree more examples could be useful, but providing them hasn't proven feasible during the revision period. As mentioned by the reviewer, a full evaluation based on the state of the art in the field of information retrieval is beyond the scope of the paper. We attempted to select a range of neurons for analysis that were within our domain of anatomical expertise, favoring accuracy of the evaluation over randomization of the analyzed neurons. We made the following modifications to further temper the breadth of claims:</p><p>Line 28. Added &quot;We demonstrate the potential of NeuronBridge to…&quot;</p><p>Line 278. Replaced &quot;We evaluated…&quot; with &quot;We performed limited evaluations of…&quot;</p><p>Line 285. Added &quot;, and we restricted our analyzed set of neurons accordingly&quot;</p><disp-quote content-type="editor-comment"><p>Forward, &quot;qualitative&quot;, Analysis: A true qualitative evaluation would require the repetition of retrieval experiments with several experts and an investigation of the question if there is e.g. an inter-observer variability, which seems not to be the case here. In this context also information on the number and professional background of the persons who judged on the query results should be added.</p></disp-quote><p>Please see response under <italic>Comments on Data Pre-Processing and Annotation.</italic></p></body></sub-article></article>