<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">81256</article-id><article-id pub-id-type="doi">10.7554/eLife.81256</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Resource-rational account of sequential effects in human prediction</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-283806"><name><surname>Prat-Carrabin</surname><given-names>Arthur</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6710-1488</contrib-id><email>arthurpc@fas.harvard.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="pa1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-53268"><name><surname>Meyniel</surname><given-names>Florent</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6992-678X</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-53126"><name><surname>Azeredo da Silveira</surname><given-names>Rava</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8487-4105</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj8s172</institution-id><institution>Department of Economics, Columbia University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a26mh11</institution-id><institution>Laboratoire de Physique de l’École Normale Supérieure, ENS, Université PSL, CNRS, Sorbonne Université, Université de Paris</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xjwb503</institution-id><institution>Cognitive Neuroimaging Unit, Institut National de la Santé et de la Recherche Médicale, Commissariat à l’Energie Atomique et aux Energies Alternatives, Centre National de la Recherche Scientifique, Université Paris-Saclay, NeuroSpin center</institution></institution-wrap><addr-line><named-content content-type="city">Gif-sur-Yvette</named-content></addr-line><country>France</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f82e368</institution-id><institution>Institut de neuromodulation, GHU Paris, Psychiatrie et Neurosciences, Centre Hospitalier Sainte-Anne, Pôle Hospitalo-Universitaire 15, Université Paris Cité</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05e715194</institution-id><institution>Institute of Molecular and Clinical Ophthalmology Basel</institution></institution-wrap><addr-line><named-content content-type="city">Basel</named-content></addr-line><country>Switzerland</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s6k3f65</institution-id><institution>Faculty of Science, University of Basel</institution></institution-wrap><addr-line><named-content content-type="city">Basel</named-content></addr-line><country>Switzerland</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Zhang</surname><given-names>Hang</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Donders Institute for Brain, Cognition and Behaviour</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>Department of Psychology, Harvard University, Cambridge, United States</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>15</day><month>01</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>13</volume><elocation-id>e81256</elocation-id><history><date date-type="received" iso-8601-date="2022-06-21"><day>21</day><month>06</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-12-11"><day>11</day><month>12</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-06-22"><day>22</day><month>06</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.06.20.496900"/></event></pub-history><permissions><copyright-statement>© 2024, Prat-Carrabin et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Prat-Carrabin et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-81256-v1.pdf"/><abstract><p>An abundant literature reports on ‘sequential effects’ observed when humans make predictions on the basis of stochastic sequences of stimuli. Such sequential effects represent departures from an optimal, Bayesian process. A prominent explanation posits that humans are adapted to changing environments, and erroneously assume non-stationarity of the environment, even if the latter is static. As a result, their predictions fluctuate over time. We propose a different explanation in which sub-optimal and fluctuating predictions result from cognitive constraints (or costs), under which humans however behave rationally. We devise a framework of costly inference, in which we develop two classes of models that differ by the nature of the constraints at play: in one case the precision of beliefs comes at a cost, resulting in an exponential forgetting of past observations, while in the other beliefs with high predictive power are favored. To compare model predictions to human behavior, we carry out a prediction task that uses binary random stimuli, with probabilities ranging from 0.05 to 0.95. Although in this task the environment is static and the Bayesian belief converges, subjects’ predictions fluctuate and are biased toward the recent stimulus history. Both classes of models capture this ‘attractive effect’, but they depart in their characterization of higher-order effects. Only the precision-cost model reproduces a ‘repulsive effect’, observed in the data, in which predictions are biased away from stimuli presented in more distant trials. Our experimental results reveal systematic modulations in sequential effects, which our theoretical approach accounts for in terms of rationality under cognitive constraints.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>sequential effects</kwd><kwd>prediction</kwd><kwd>bounded rationality</kwd><kwd>inference</kwd><kwd>cognition</kwd><kwd>2AFC</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Albert P. Sloan Foundation</institution></institution-wrap></funding-source><award-id>Grant G-2020-12680</award-id><principal-award-recipient><name><surname>Azeredo da Silveira</surname><given-names>Rava</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004794</institution-id><institution>CNRS</institution></institution-wrap></funding-source><award-id>UMR8023</award-id><principal-award-recipient><name><surname>Azeredo da Silveira</surname><given-names>Rava</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100009627</institution-id><institution>Fondation Pierre-Gilles de Gennes pour la recherche</institution></institution-wrap></funding-source><award-id>Ph.D. Fellowship</award-id><principal-award-recipient><name><surname>Prat-Carrabin</surname><given-names>Arthur</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A proposed model of optimal inference under cognitive costs accounts for human sequential effects, including subtle patterns of attractive and repulsive influence of past observations, in a binary prediction task across a wide range of stimulus conditions.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In many situations of uncertainty, some outcomes are more probable than others. Knowing the probability distributions of the possible outcomes provides an edge that can be leveraged to improve and speed up decision making and perception (<xref ref-type="bibr" rid="bib109">Summerfield and de Lange, 2014</xref>). In the case of choice reaction-time tasks, it was noted in the early 1950s that human reactions were faster when responding to a stimulus whose probability was higher (<xref ref-type="bibr" rid="bib55">Hick, 1952</xref>; <xref ref-type="bibr" rid="bib58">Hyman, 1953</xref>). In addition, faster responses were obtained after a repetition of a stimulus (i.e., when the same stimulus was presented twice in a row), even in the case of serially-independent stimuli (i.e., when the preceding stimulus carried no information on subsequent ones; <xref ref-type="bibr" rid="bib58">Hyman, 1953</xref>; <xref ref-type="bibr" rid="bib15">Bertelson, 1965</xref>). The observation of this seemingly suboptimal behavior has motivated in the following decades a profuse literature on ‘sequential effects’, i.e., on the dependence of reaction times on the recent history of presented stimuli (<xref ref-type="bibr" rid="bib65">Kornblum, 1967</xref>; <xref ref-type="bibr" rid="bib106">Soetens et al., 1985</xref>; <xref ref-type="bibr" rid="bib22">Cho et al., 2002</xref>; <xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Jones et al., 2013</xref>; <xref ref-type="bibr" rid="bib122">Zhang et al., 2014</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>). These studies consistently report a <italic>recency effect</italic> whereby the more often a simple pattern of stimuli (e.g. a repetition) is observed in recent stimulus history, the faster subjects respond to it. In tasks in which subjects are asked to make predictions about sequences of random binary events, sequential effects are also observed and they have given rise since the 1950s to a rich literature (<xref ref-type="bibr" rid="bib60">Jarvik, 1951</xref>; <xref ref-type="bibr" rid="bib34">Edwards, 1961</xref>; <xref ref-type="bibr" rid="bib73">McClelland and Hackenberg, 1978</xref>; <xref ref-type="bibr" rid="bib72">Matthews and Sanders, 1984</xref>; <xref ref-type="bibr" rid="bib47">Gilovich et al., 1985</xref>; <xref ref-type="bibr" rid="bib5">Ayton and Fischer, 2004</xref>; <xref ref-type="bibr" rid="bib18">Burns and Corpus, 2004</xref>; <xref ref-type="bibr" rid="bib26">Croson and Sundali, 2005</xref>; <xref ref-type="bibr" rid="bib9">Bar-Eli et al., 2006</xref>; <xref ref-type="bibr" rid="bib82">Oskarsson et al., 2009</xref>; <xref ref-type="bibr" rid="bib87">Plonsky et al., 2015</xref>; <xref ref-type="bibr" rid="bib88">Plonsky and Erev, 2017</xref>; <xref ref-type="bibr" rid="bib48">Gökaydin and Ejova, 2017</xref>).</p><p>Sequential effects are intriguing: why do subjects change their behavior as a function of the recent past observations when those are in fact irrelevant to the current decision? A common theoretical account is that humans infer the statistics of the stimuli presented to them, but because they usually live in environments that change over time, they may believe that the process generating the stimuli is subject to random changes even when it is in fact constant (<xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>; <xref ref-type="bibr" rid="bib122">Zhang et al., 2014</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>). Consequently, they may rely excessively on the most recent stimuli to predict the next ones. In several studies, this was heuristically modeled as a ‘leaky integration’ of the stimuli, that is, an exponential discounting of past observations (<xref ref-type="bibr" rid="bib22">Cho et al., 2002</xref>; <xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Jones et al., 2013</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>). Here, instead of positing that subjects hold an incorrect belief on the dynamics of the environment and do not learn that it is stationary, we propose a different account, whereby a cognitive constraint is hindering the inference process and preventing it from converging to the correct, constant belief about the unchanging statistics of the environment. This proposal calls for the investigation of the kinds of choice patterns and sequential effects that would result from different cognitive constraints at play during inference.</p><p>We derive a framework of constrained inference, in which a cost hinders the representation of belief distributions (posteriors). This approach is in line with a rich literature that views several perceptual and cognitive processes as resulting from a constrained optimization: the brain is assumed to operate optimally, but within some posited limits on its resources or abilities. The ‘efficient coding’ hypothesis in neuroscience (<xref ref-type="bibr" rid="bib43">Ganguli and Simoncelli, 2016</xref>; <xref ref-type="bibr" rid="bib116">Wei and Stocker, 2015</xref>; <xref ref-type="bibr" rid="bib117">Wei and Stocker, 2017</xref>; <xref ref-type="bibr" rid="bib91">Prat-Carrabin and Woodford, 2021c</xref>) and the ‘rational inattention’ models in economics (<xref ref-type="bibr" rid="bib104">Sims, 2003</xref>; <xref ref-type="bibr" rid="bib119">Woodford, 2009</xref>; <xref ref-type="bibr" rid="bib20">Caplin et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Gabaix, 2017</xref>; <xref ref-type="bibr" rid="bib6">Azeredo da Silveira and Woodford, 2019</xref>; <xref ref-type="bibr" rid="bib7">Azeredo da Silveira et al., 2020</xref>) are examples of this approach, which has been called ‘resource-rational analysis’ (<xref ref-type="bibr" rid="bib51">Griffiths et al., 2015</xref>; <xref ref-type="bibr" rid="bib68">Lieder and Griffiths, 2019</xref>). Here, we investigate the proposal that human inference is resource-rational, i.e., optimal under a cost. As for the nature of this cost, we consider two natural hypotheses: first, that a higher precision in belief is harder for subjects to achieve, and thus that more precise posteriors come with higher costs; and second, that unpredictable environments are difficult for subjects to represent, and thus that they entail higher costs. Under the first hypothesis, the cost is a function of the belief held, while under the second hypothesis the cost is a function of the inferred environment. We show that the precision cost predicts ‘leaky integration’: in the resulting inference process, remote observations are discarded. Crucially, beliefs do not converge but fluctuate instead with the recent stimulus history. By contrast, under the unpredictability cost, the inference process does converge, although not to the correct (Bayesian) posterior, but rather to a posterior that implies a biased belief on the temporal structure of the stimuli. In both cases, sequential effects emerge as the result of a constrained inference process.</p><p>We examine experimentally the degree to which the models derived from our framework account for human behavior, with a task in which we repeatedly ask subjects to predict the upcoming stimulus in sequences of Bernoulli-distributed stimuli. Most studies on sequential effects only consider the equiprobable case, in which the two stimuli have the same probability. However, the models we consider here are more general than this singular case and they apply to the entire range of stimulus probability. We thus manipulate in separate blocks of trials the stimulus generative probability (i.e., the Bernoulli probability that parameterizes the stimulus) to span the range from 0.05 to 0.95 by increments of 0.05. This enables us to examine in detail the behavior of subjects in a large gamut of environments from the singular case of an equiprobable, maximally-uncertain environment (with a probability of 0.5 for both stimuli) to the strongly-biased, almost-certain environment in which one stimulus occurs with probability 0.95.</p><p>To anticipate on our results, the predictions of subjects depend on the stimulus generative probability, but also on the history of stimuli. We examine whether the occurrence of a stimulus, in past trials, increase the proportion of predictions identical to this stimulus (‘attractive effect’), or whether it decreases this proportion (‘repulsive effect’). The two costs presented above reproduce qualitatively the main patterns in subjects’ data, but they make distinct predictions as to the modulations of the recency effect as a function of the history of stimuli, beyond the last stimulus. We show that the responses of subjects exhibit an elaborate, and at times counter-intuitive, pattern of attractive and repulsive effects, and we compare these to the predictions of our models. Our results suggest that the brain infers a stimulus generative probability, but under a constraint on the precision of its internal representations; the inferred generative process may be more general than the actual one, and include higher-order statistics (e.g. transition probabilities), in contrast with the Bernoulli-distributed stimulus used in the experiment.</p><p>We present the behavioral task and we examine the predictions of subjects — in particular, how they vary with the stimulus generative probability, and how they depend, at each trial, on the preceding stimulus. We then introduce our framework of inference under constraint, and the two costs we consider, from which we derive two families of models. We examine the behavior of these models and the extent to which they capture the behavioral patterns of subjects. The models make different qualitative predictions about the sequential effects of past observations, which we confront to subjects’ data. We find that the predictions of subjects are qualitatively consistent with a model of inference of conditional probabilities, in which precise posteriors are costly.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Subjects’ predictions of a stimulus increase with the stimulus probability</title><p>In a computer-based task, subjects are asked to predict which of two rods the lightning will strike. On each trial, the subject first selects by a key press the left- or right-hand-side rod presented on screen. A lightning symbol (which is here the stimulus) then randomly strikes either of the two rods. The trial is a success if the lightning strikes the rod selected by the subject (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). The location of the lightning strike (left or right) is a Bernoulli random variable whose parameter <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> (the stimulus generative probability) we manipulate across blocks of 200 trials: in each block, <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> is a multiple of 0.05 chosen between 0.05 and 0.95. Changes of block are explicitly signaled to the subjects: each block is presented as a different town exposed to lightning strikes. The subjects are not told that the locations of the strikes are Bernoulli-distributed (in fact no information is given to them regarding how the locations are determined). Moreover, in order to capture the ‘stationary’ behavior of subjects, which presumably prevails after ample exposure to the stimulus, each block is preceded by 200 passive trials in which the stimuli (sampled with the probability chosen for the block) are successively shown with no action from the subject (<xref ref-type="fig" rid="fig1">Figure 1b</xref>); this is presented as a ‘useful track record’ of lightning strikes in the current town. (To verify the stationarity of subjects’ behavior, we compare their responses in the first and second halves of the 200 trials in which they are asked to make predictions. In most cases we find no significant differences. See Appendix.) We provide further details on the task in Methods.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The Bernoulli sequential prediction task.</title><p>(<bold>a</bold>) In each successive trial, the subject is asked to predict which of two rods the lightning will strike. (1) A trial begins. (1’) The subject chooses the right-hand-side rod (bold lines), but the lightning strikes the left one (this feedback is given immediately after the subject makes a choice). (2) 1.25 s after the beginning of the preceding trial, a new trial begins. (2’) The subject chooses the right-hand-side rod, and this time the lightning strikes the rod chosen by the subject (immediate feedback). The rod and the connected battery light up (yellow), indicating success. (3) A new trial begins. (3’) If after 1 s the subject has not made a prediction, a red cross bars the screen and the trial ends. (4) A new trial begins. (4’) The subject chooses the left-hand-side rod, and the lightning strikes the same rod. In all cases, the duration of a trial is 1.25 s. (<bold>b</bold>) In each block of trials, the location of the lightning strike is a Bernoulli random variable with parameter <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, the stimulus generative probability. Each subject experiences 10 blocks of trials. The stimulus generative probability for each block is chosen randomly among the 19 multiples of 0.05 ranging from 0.05 to 0.95, with the constraint that if <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> is chosen for a given block, neither <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> nor <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> can be chosen in the subsequent blocks; as a result for any value <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> among these 19 probabilities spanning the range from 0.05 to 0.95, there is one block in which one of the two rods receives the lightning strike with probability <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>. Within each block the first 200 trials consist in passive observation and the 200 following trials are active trials (depicted in panel a).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig1-v1.tif"/></fig><p>The behavior of subjects varies with the stimulus generative probability, <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>. In our analyses, we are interested in how the subjects’ predictions of an event (left or right strike) vary with the probability of this event, regardless of its nature (left or right). Thus, for instance, we would like to pool together the trials in which a subject makes a rightward prediction when the probability of a rightward strike is 0.7, and the trials in which a subject makes a leftward prediction when the probability of a leftward strike is also 0.7. Therefore, throughout the paper, we do not discuss whether subjects predict ‘right’ or ‘left’, and instead we discuss whether they predict the event ‘A’ or the complementary event ‘B’: in different blocks of trials, A (and similarly B) may refer to different locations; but importantly, B always corresponds to the location opposite to A, and <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> denotes the probability of A (thus B has probability <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>). This allows us, given a probability <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, to pool together the responses obtained in blocks of trials in which one of the two locations has probability <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>. One advantage of this pooling is that it reduces the noise in data. Looking at the unpooled data, however, does not change our conclusions; see Appendix.</p><p>Turning to the behavior of subjects, we denote by <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> the proportion of trials in which a subject predicts the event A. In the equiprobable condition (<inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), the subjects predict either side on about half the trials (<inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>.496</mml:mn></mml:mstyle></mml:math></inline-formula>, subjects pooled; standard error of the mean (sem): 0.008; p-value of t-test of equality with 0.5: 0.59). In the non-equiprobable conditions, the optimal behavior is to predict A on none of the trials (<inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) if <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, or on all trials (<inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>) if <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The proportion of predictions A adopted by the subjects also increases as a function of the stimulus generative probability (Pearson correlation coefficient between <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, subjects pooled: .97; p-value: 3.3e-6; correlation between the ‘logits’, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:math></inline-formula>: 0.994, p-value: 5.7e-9.), but not as steeply: it lies between the stimulus generative probability <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, and the optimal response 0 (if <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) or 1 (if <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig2">Figure 2a</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Across all stimulus generative probabilities, subjects are more likely than average to make a prediction equal to the preceding observation.</title><p>(<bold>a</bold>) Proportion of predictions A in subjects’ pooled responses as a function of the stimulus generative probability, conditional on observing an A (blue line) or a B (orange line) on the preceding trial, and unconditional (grey line). The widths of the shaded areas indicate the standard error of the mean (n = 178 to 3603). (<bold>b</bold>) Difference between the proportion of predictions A conditional on the preceding observation being an A, and the proportion of predictions A conditional on the preceding observation being a B. This difference is positive across all stimulus generative probabilities, that is, observing an A at the preceding trial increases the probability of predicting an A (p-values of Fisher’s exact tests, with Bonferroni-Holm-Šidák correction, are all below 1e-13). Bars are twice the square root of the sum of the two squared standard errors of the means (for each point, total n: 3582 to 3781). The binary nature of the task results in symmetries in this representation of data: in panel (<bold>a</bold>) the grey line is symmetric about the middle point and the blue and orange lines are reflections of each other, and in panel (<bold>b</bold>) the data is symmetric about the middle probability, 0.5. For this reason, for values of the stimulus generative probability below 0.5 we show the curves in panel (<bold>a</bold>) as dotted lines, and the data points in panel (<bold>b</bold>) as white dots with dotted error bars.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig2-v1.tif"/></fig></sec><sec id="s2-2"><title>First-order sequential effects: attractive influence of the most recent stimulus on subjects’ predictions</title><p>The sequences presented to subjects correspond to independent, Bernoulli-distributed random events. Having shown that the subjects’ predictions follow (in a non-optimal fashion) the stimulus generative probability, we now test whether they also exhibit the non-independence of consecutive trials featured by the Bernoulli process. Under this hypothesis and in the stationary regime, the proportion of predictions A conditional on the preceding stimulus being A, <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, should be no different than the proportion of predictions A conditional on the preceding stimulus being B, <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. (Here and below, <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> denotes the proportion of predictions X conditional on the preceding observation being Y, and not on the preceding response being Y. For the possibility that subjects’ responses depend on the preceding response, see Methods.)</p><p>In other words, conditioning on the preceding stimulus should have no effect. In subjects’ responses, however, these two conditional proportions are markedly different for all stimulus generative probabilities (Fisher exact test, subjects pooled: all p-values &lt; 1e-10; <xref ref-type="fig" rid="fig2">Figure 2a</xref>). Both quantities increase as a function of the stimulus generative probability, but the proportions of predictions A conditional on an A are consistently greater than the proportions of predictions A conditional on a B, i.e., <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). (We note that because the stimulus is either A or B, it follows that, symmetrically, the proportions of predictions B conditional on a B are consistently greater than the proportions of predictions B conditional on an A.) In other words, the preceding stimulus has an ‘attractive’ sequential effect. In addition, this attractive sequential effect seems stronger for values of the stimulus generative probability closer to the equiprobable case (p = 0.5), and to decrease for more extreme values (<inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> closer to 0 or to 1; <xref ref-type="fig" rid="fig2">Figure 2b</xref>). The results in <xref ref-type="fig" rid="fig2">Figure 2</xref> are obtained by pooling together the responses of the subjects. Results derived from an across-subjects analysis are very similar; see Appendix.</p></sec><sec id="s2-3"><title>A framework of costly inference</title><p>The attractive effect of the preceding stimulus on subjects’ responses suggests that the subjects have not correctly inferred the Bernoulli statistics of the process generating the stimuli. We investigate the hypothesis that their ability to infer the underlying statistics of the stimuli is hampered by cognitive constraints. We assume that these constraints can be understood as a cost, bearing on the representation, by the brain, of the subject’s beliefs about the statistics. Specifically, we derive an array of models from a framework of inference under costly posteriors (<xref ref-type="bibr" rid="bib89">Prat-Carrabin et al., 2021a</xref>), which we now present. We consider a model subject who is presented on each trial <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> with a stimulus <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> (where 0 and 1 encode for B and A, respectively) and who uses the sequence of stimuli <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> to infer the stimulus statistics, over which she holds the belief distribution <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. A Bayesian observer equipped with this belief <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and observing a new observation <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> would obtain its updated belief <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> through Bayes’ rule. However, a cognitive cost <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> hinders our model subject’s ability to represent probability distributions <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi></mml:mstyle></mml:math></inline-formula>. Thus, she approximates the posterior <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> through another distribution <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> that minimizes a loss function <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi></mml:mstyle></mml:math></inline-formula> defined as<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi></mml:mstyle></mml:math></inline-formula> is a measure of distance between two probability distributions, and <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> is a coefficient specifying the relative weight of the cost. (We are not proposing that subjects actively minimize this quantity, but rather that the brain’s inference process is an effective solution to this optimization problem.) Below, we use the Kullback-Leibler divergence for the distance (i.e. <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>). If <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, the solution to this minimization problem is the Bayesian posterior; if <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, the cost distorts the Bayesian solution in ways that depend on the form of the cost borne by the subject (we detail further below the two kinds of costs we investigate).</p><p>In our framework, the subject assumes that the <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> preceding stimuli (<inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) and a vector of parameters <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> jointly determine the distribution of the stimulus at trial <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. Although in our task the stimuli are Bernoulli-distributed (thus they do not depend on preceding stimuli) and a single parameter determines the probability of the outcomes (the stimulus generative probability), the subject may admit the possibility that more complex mechanisms govern the statistics of the stimuli, for example transition probabilities between consecutive stimuli. Therefore, the vector <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> may contain more than one parameter and the number <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> of preceding stimuli assumed to influence the probability of the following stimulus, which we call the ‘Markov order’, may be greater than 0.</p><p>Below, we call ‘Bernoulli observer’ any model subject who assumes that the stimuli are Bernoulli-distributed (<inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>); in this case the vector <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> consists of a single parameter that determines the probability of observing A, which we also denote by <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> for the sake of concision. The bias and variability in the inference of the Bernoulli observer is studied in <xref ref-type="bibr" rid="bib89">Prat-Carrabin et al., 2021a</xref>. We call ‘Markov observer’ any model subject who posits that the probability of the stimulus depends on the preceding stimuli (<inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). In this case, the vector <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> contains the <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mn>2</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> conditional probabilities of observing A after observing each possible sequence of <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> stimuli. For instance, with <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> the vector <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> is the pair of parameters <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> denoting the probabilities of observing a stimulus A after observing, respectively, a stimulus A and a stimulus B. In the absence of a cost, the belief over the parameter(s) eventually converges towards the parameter vector that is consistent with the generative Bernoulli statistics governing the stimulus (except if the prior precludes this parameter vector). Below, we assume a uniform prior.</p><p>To understand how the costs contort the inference process, it is useful to have in mind the solution to the ‘unconstrained’ inference problem (with <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), i.e., the Bayesian posterior, which we denote by <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. In the case of a Bernoulli observer (<inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), after <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> trials, the Bayesian posterior is a Beta distribution,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msup><mml:mi>q</mml:mi><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow/></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow/></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>X</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> is the number of stimuli <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>X</mml:mi></mml:mstyle></mml:math></inline-formula> observed up to trial <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. As more evidence is accumulated, the Bayesian posterior gradually narrows and converges towards the value of the stimulus generative probability (<xref ref-type="fig" rid="fig3">Figure 3c and d</xref>, grey lines).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Illustration of the Bernoulli-observer models, with unpredictability and precision costs.</title><p>(<bold>a</bold>) Precision cost (purple) and unpredictability cost (green lines) of a Beta distribution with parameters <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>, as functions of the mean of the distribution, <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, and keeping the entropy constant. The precision cost is the negative of the entropy and it is thus constant, regardless of the mean of the distribution. The unpredictability cost is larger when the mean of the distribution is closer to 0.5 (i.e. when unpredictable environments are likely, under the distribution). <italic>Insets:</italic> Beta distributions with mean 0.2, 0.5, and 0.8, and constant entropy. (<bold>b</bold>) Costs as functions of the sample size parameter, <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>. A larger sample size implies a higher precision and lower entropy, thus the precision cost increases as a function of the sample size, whereas the unpredictability cost is less sensitive to changes in this parameter. <italic>Insets:</italic> Beta distributions with mean 0.6 and sample size parameter, <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>, equal to 5, 50, and 200. (<bold>c</bold>) Posteriors <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> of an optimal observer (gray), a precision-cost observer (purple) and an unpredictability-cost observer (green lines), after the presentation of ten sequences of N = 50, 200, and 400 observations sampled from a Bernoulli distribution of parameter 0.7. The posteriors of the optimal observer narrow as evidence is accumulated, and the different posteriors obtained after different sequences of observations are drawn closer to each other and to the correct probability. The posteriors of the unpredictability-cost observer also narrow and group together, but around a probability larger (less unpredictable) than the correct probability. Precise distributions are costly to the precision-cost observer and thus the posteriors do not narrow after long sequences of observations. Instead, the posteriors fluctuate with the recent history of the stimuli. (<bold>d</bold>) Expected probability <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula> resulting from the inference. The optimal observer (gray) converges towards the correct probability; the unpredictability-cost observer (green) converges towards a biased (larger) probability; and the precision-cost observer (purple lines) does not converge, but instead fluctuates with the history of the stimuli.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig3-v1.tif"/></fig><p>The ways in which the Bayesian posterior is distorted, in our models, depend on the nature of the cost that weighs on the inference process. Although many assumptions could be made on the kind of constraint that hinders human inference, and on the cost it would entail in our framework, here we examine two costs that stem from two possible principles: that the cost is a function of the beliefs held by the subject, or that it is a function of the environment that the subject is inferring. We detail, below, these two costs.</p></sec><sec id="s2-4"><title>Precision cost</title><p>A first hypothesis about the inference process of subjects is that the brain mobilizes resources to represent probability distributions, and that more ‘precise’ distributions require more resources. We write the cost associated with a distribution, <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, as the negative of its entropy,<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>which is a measure of the amount of certainty in the distribution. Wider (less concentrated) distributions provide less information about the probability parameter and are thus less costly than narrower (more concentrated) distributions (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). As an extreme case, the uniform distribution is the least costly.</p><p>With this cost, the loss function (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) is minimized by the distribution equal to the product of the prior and the likelihood, raised to the exponent <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, and normalized, i.e.,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> is strictly positive, the exponent is positive and lower than 1. As a result, the solution ‘flattens’ the Bayesian posterior, and in the extreme case of an unbounded cost (<inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula>) the posterior is the uniform distribution.</p><p>Furthermore, in the expression of our model subject’s posterior, the likelihood <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is raised after <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> trials to the exponent <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, it thus decays to zero as the number <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> of new stimuli increases. One can interpret this effect as gradually forgetting past observations. Specifically, we recover the predictions of leaky-integration models, in which remote patterns in the sequence of stimuli are discounted through an exponential filter (<xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>); here, we do not posit the gradual forgetting of remote observations, but instead we derive it as an optimal solution to a problem of constrained inference. We illustrate leaky integration in the case of a Bernoulli observer (<inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>): in this case, the posterior after <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> trials, <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is a Beta distribution,<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msup><mml:mi>q</mml:mi><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow/></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow/></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> are exponentially-filtered counts of the number of stimuli A and B observed up to trial <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>, i.e.,<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>In other words, the solution to the constrained inference problem, with the precision cost, is similar to the Bayesian posterior (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>), but with counts of the two stimuli that gradually ‘forget’ remote observations (in the absence of a cost, that is, <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, we have <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>=</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>=</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula>, and thus we recover the Bayesian posterior). As a result, these counts fluctuate with the recent history of the stimuli. Consequently, the posterior <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is dominated by the recent stimuli: it does not converge, but instead fluctuates with the recent stimulus history (<xref ref-type="fig" rid="fig3">Figure 3c and d</xref>, purple lines; compare with the green and gray lines). Hence, this model implies predictions about subsequent stimuli that depend on the stimulus history, i.e., it predicts sequential effects.</p></sec><sec id="s2-5"><title>Unpredictability cost</title><p>A different hypothesis is that the subjects favor, in their inference, parameter vectors <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> that correspond to more predictable outcomes. We quantify the outcome unpredictability by the Shannon entropy (<xref ref-type="bibr" rid="bib99">Shannon, 1948</xref>) of the outcome implied by the vector of parameters <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>, which we denote by <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. (In the Bernoulli-observer case, <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>q</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>; for the Markov-observer cases, see Methods.) The cost associated with the distribution <inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is the expectation of this quantity averaged over beliefs, i.e.,<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>C</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>q</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>which we call the ‘unpredictability cost’. For a Bernoulli observer, a posterior concentrated on extreme values of the Bernoulli parameter (toward 0 or 1), thus representing more predictable environments, comes with a lower cost than a posterior concentrated on values of the Bernoulli parameter close to 0.5, which correspond to the most unpredictable environments (<xref ref-type="fig" rid="fig3">Figure 3a</xref>).</p><p>After <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> trials, the loss function (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) under this cost is minimized by the posterior<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mi>λ</mml:mi><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>i.e., the product of the Bayesian posterior, which narrows with <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> around the stimulus generative probability, and of a function that is larger for values of <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> that imply less entropic (i.e. more predictable) environments (see Methods). In short, with the unpredictability cost the model subject’s posterior is ‘pushed’ towards less entropic values of <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>.</p><p>In the Bernoulli case (<inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), the posterior after <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> stimuli has a global maximum, <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, that depends on the proportion <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> of stimuli A observed up to trial <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>. As the number of presented stimuli <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> grows, the posterior <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> becomes concentrated around this maximum. The proportion <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> naturally converges to the stimulus generative probability, <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, thus our subject’s inference converges towards the value <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> which is different from the true value <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, in the non-equiprobable case (<inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>≠</mml:mo><mml:mn>.5</mml:mn></mml:mstyle></mml:math></inline-formula>). The equiprobable case (<inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.5</mml:mn></mml:mstyle></mml:math></inline-formula>) is singular, in that with a weak cost (<inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) the inferred probability is unbiased (<inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>.5</mml:mn></mml:mstyle></mml:math></inline-formula>), while with a strong cost (<inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) the inferred probability does not converge but instead alternates between two values above and below 0.5; see <xref ref-type="bibr" rid="bib89">Prat-Carrabin et al., 2021a</xref>. In other words, except in the equiprobable case, the inference converges but it is biased, i.e., the posterior peaks at an incorrect value of the stimulus generative probability (<xref ref-type="fig" rid="fig3">Figure 3c and d</xref>, green lines). This value is closer to the extremes (0 and 1) than the stimulus generative probability, that is, it implies an environment more predictable than the actual one (<xref ref-type="fig" rid="fig3">Figure 3d</xref>).</p><p>In the case of a Markov observer (<inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), the posterior also converges to a vector of parameters <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> which implies not only a bias but also that the conditional probabilities of a stimulus A (conditioned on different stimulus histories) are not equal. The prediction of the next stimulus being A on a given trial depends on whether the preceding stimulus was A or B: this model therefore predicts sequential effects. We further examine below the behavior of this model in the cases of a Bernoulli observer and of different Markov observers. We refer the reader interested in more details on the Markov models, including their mathematical derivations, to the Methods section.</p><p>In short, with the unpredictability-cost models, when <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>≠</mml:mo><mml:mn>0.5</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, the inference process converges to an asymptotic posterior <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> which does not itself depend on the history of the stimulus, but that is biased (<xref ref-type="fig" rid="fig3">Figure 3c, d</xref>, green lines). In particular, for Markov observers (<inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), the asymptotic posterior corresponds to an erroneous belief about the dependency of the stimulus on the recent stimulus history, which results in sequential effects in behavior.</p></sec><sec id="s2-6"><title>Overview of the inference models</title><p>Although the two families of models derived from the two costs both potentially generate sequential effects, they do so by giving rise to qualitatively different inference processes. Under the unpredictability cost, the inference converges to a posterior that, in the Bernoulli case (<inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), implies a biased estimate of the stimulus generative probability (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, green lines), while in the Markov case (<inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) it implies the belief that there are serial dependencies in the stimuli: predictions therefore depend on the recent stimulus history. By contrast, the precision cost prevents beliefs from converging (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, purple lines). As a result, the subject’s predictions vary with the recent stimulus history (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). This inference process amounts to an exponential discount of remote observations, or equivalently, to the overweighting of recent observations (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>).</p><p>To investigate in more detail the sequential effects that these two costs produce, we implement two families of inference models derived from the two costs. Each model is characterized by the type of cost (unpredictability cost or precision cost), and by the assumed Markov order (<inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>): we examine the case of a Bernoulli observer (<inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) and three cases of Markov observers (with <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo></mml:mstyle></mml:math></inline-formula> 1, 2, and 3). We thus obtain <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>4</mml:mn><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mstyle></mml:math></inline-formula> models of inference. Each of these models has one parameter <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> controlling the weight of the cost. (We also examine a ‘hybrid’ model that combines the two costs; see below.)</p></sec><sec id="s2-7"><title>Response-selection strategy</title><p>We assume that the subject’s response on a given trial depends on the inferred posterior according to a generalization of ‘probability matching’ implemented in other studies (<xref ref-type="bibr" rid="bib11">Battaglia et al., 2011</xref>; <xref ref-type="bibr" rid="bib121">Yu and Huang, 2014</xref>; <xref ref-type="bibr" rid="bib90">Prat-Carrabin et al., 2021b</xref>). In this response-selection strategy, the subject predicts A with the probability <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>κ</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>κ</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>κ</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the expected probability of a stimulus A derived from the posterior, i.e., <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. The single parameter <inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> controls the randomness of the response: with <inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> the subject predicts A and B with equal probability; with <inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> the response-selection strategy corresponds to probability matching, that is, the subject predicts A with probability <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>; and as <inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> increases toward infinity the choices become optimal, that is, the subjects predicts A if the expected probability of observing a stimulus A, <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, is greater than 0.5, and predicts B if it is lower than 0.5 (if <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> the subject chooses A or B with equal probability). In our investigations, we also implement several other response-selection strategies, including one in which subjects have a propensity to repeat their preceding response, or conversely, to alternate; these analyses do not change our conclusions (see Methods).</p></sec><sec id="s2-8"><title>Model fitting favors Markov-observer models</title><p>Each of our eight models has two parameters: the factor weighting the cost, <inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula>, and the exponent of the generalized probability-matching, <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula>. We fit the parameters of each model to the responses of each subject, by maximizing their likelihoods. We find that 60% of subjects are best fitted by one of the unpredictability-cost models, while 40% are best fitted by one of the precision-cost models. When pooling the two types of cost, 65% of subjects are best fitted by a Markov-observer model. We implement a ‘Bayesian model selection’ procedure (<xref ref-type="bibr" rid="bib107">Stephan et al., 2009</xref>), which takes into account, for each subject, the likelihoods of all the models (and not only the maximum among them) in order to obtain a Bayesian posterior over the distribution of models in the general population (see Methods). The derived expected probability of unpredictability-cost models is 57% (and 43% for precision-cost models) with an exceedance probability (i.e. probability that unpredictability-cost models are more frequent in the general population) of 78%. The expected probability of Markov-observer models, regardless of the cost used in the model, is 70% (and 30% for Bernoulli-observer models) with an exceedance probability (i.e. probability that Markov-observer models are more frequent in the general population) of 98%. These results indicate that the responses of subjects are generally consistent with a Markov-observer model, although the stimuli used in the experiment are Bernoulli-distributed. As for the unpredictability-cost and the precision-cost families of models, Bayesian model selection does not provide decisive evidence in favor of either model, indicating that they both capture some aspects of the responses of the subjects. Below, we examine more closely the behaviors of the models, and point to qualitative differences between the predictions resulting from each model family.</p><p>Before turning to these results, we validate the robustness of our model-fitting procedure with several additional analyses. First, we estimate a confusion matrix to examine the possibility that the model-fitting procedure could misidentify the models which generated test sets of responses. We find that the best-fitting model corresponds to the true model in at least 70% of simulations (the chance level is 12.5%=1/8 models), and actually more than 90% for the majority of models (see Appendix).</p><p>Second, we seek to verify whether the best-fitting cost factor, <inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula>, that we obtain for each subject is consistent across the range of probabilities tested. Specifically, we fit separately the models to the responses obtained in the blocks of trials whose stimulus generative probability was ‘medium’ (between 0.3 and 0.7, included) on the one hand, and to the responses obtained when the probability was ‘extreme’ (below 0.3, and above 0.7) on the other hand; and we compare the values of the best-fitting cost factors <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> in these two cases. More precisely, for the precision-cost family, we look at the inverse of the decay time, <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, which is the inverse of the characteristic time over which the model subject ‘forgets’ past observations. With both families of models, we find that on a logarithmic scale the parameters in the medium- and extreme-probabilities cases are significantly correlated across subjects (Pearson’s <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi></mml:mstyle></mml:math></inline-formula>, precision-cost models: 0.75, p-value: 1e-4; unpredictability-cost models: <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.47</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, p-value: .036). In other words, if a subject is best fitted by a large cost factor in medium-probabilities trials, he or she is likely to be also best fitted by a large cost factor in extreme-probabilities trials. This indicates that our models capture idiosyncratic features of subjects that generalize across conditions instead of varying with the stimulus probability (see Appendix).</p><p>Third, as mentioned above we examine a variant of the response-selection strategy in which the subject sometimes repeats the preceding response, or conversely alternates and chooses the other response, instead of responding based on the inferred probability of the next stimulus. This propensity to repeat or alternate does not change the best-fitting inference model of most subjects, and the best-fitting values of the parameters <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> are very stable when allowing or not for this propensity. This analysis supports the results we present here, and speaks to the robustness of the model-fitting procedure (see Methods).</p><p>Finally, as the unpredictability-cost family and the precision-cost family of models both seem to capture the responses of a sizable share of the subjects, one might assume that the behavior of most subjects actually fall ‘somewhere in between’, and would be best accounted for by a hybrid model combining the two costs. In our investigations, we have implemented such a model, whereby the subject’s approximate posterior <inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> results from the minimization of a loss function that includes both a precision cost, with weight <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, and an unpredictability cost, with weight <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (and the response-selection strategy is the generalized probability matching, with parameter <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula>). We do not find that most subjects’ responses are better fitted (as measured by the Bayesian Information Criterion <xref ref-type="bibr" rid="bib97">Schwarz, 1978</xref>) by a combination of the two costs: instead, for more than two thirds of subjects, the best-fitting model features just one cost (see Methods). In other words, the two cost seems to capture different aspects of the behavior that are predominant in different subpopulations. Below, we examine the behavioral patterns resulting from each cost type, in comparison with the behavior of the subjects.</p></sec><sec id="s2-9"><title>Models of costly inference reproduce the attractive effect of the most recent stimulus</title><p>We now examine the behavioral patterns resulting from the models. All the models we consider predict that the proportion of predictions A, <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is a smooth, increasing function of the stimulus generative probability (when <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>κ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig4">Figure 4a–d</xref>, grey lines), thus we focus, here, on the ability of the models to reproduce the subjects’ sequential effects. With the unpredictability-cost model of a Bernoulli observer (<inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), the belief of the model subject, as mentioned above, asymptotically converges in non-equiprobable cases to an erroneous value of the stimulus generative probability (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, green lines). After a large number of observations (such as the 200 ‘passive’ trials, in our task), the sensitivity of the belief to new observations becomes almost imperceptible; as a result, this model predicts practically no sequential effects (<xref ref-type="fig" rid="fig4">Figure 4b</xref>), that is, <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>≃</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. With the unpredictability-cost model of a Markov observer (e.g. <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>), the belief of the model subject also converges, but to a vector of parameters <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> that implies a sequential dependency in the stimulus, that is, <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>≠</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula>, resulting in sequential effects in predictions, that is, <inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The parameter vector <inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> yields a more predictable (less entropic) environment if the probability conditional on the more frequent outcome (say, A) is less entropic than the probability conditional on the less frequent outcome (B). This is the case if the former is greater than the latter, resulting in the inequality <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, that is, in sequential effects of the attractive kind (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). (The case in which B is the more frequent outcome results in the inequality <inline-formula><mml:math id="inf172"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, i.e., <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, i.e., the same, attractive sequential effects.)</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>The precision-cost and unpredictability-cost models reproduce the subjects’ attractive sequential effects.</title><p>(<bold>a–h</bold>) <italic>Left subpanels:</italic> proportion of predictions A as a function of the stimulus generative probability, conditional on observing A (blue line) or B (orange line) on the preceding trial, and unconditional (grey line). <italic>Right subpanels:</italic> difference between the proportion of predictions A conditional on observing A, and conditional on observing B, <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. In all panels this difference is positive, indicating an attractive sequential effect (i.e. observing A at the preceding trial increases the probability of predicting A). (<bold>a–d</bold>) Models with the precision cost (<bold>a,c</bold>) or the unpredictability cost (<bold>b,d</bold>), and with a Bernoulli observer (<inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>; <bold>a,b</bold>) or a Markov observer with <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> (<bold>c,d</bold>). (<bold>a</bold>) Behavior with the generalized probability-matching response-selection strategy with <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.8</mml:mn></mml:mstyle></mml:math></inline-formula> (solid lines, red dots) and with <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> (dotted lines, light-red dots). (<bold>e,f</bold>) Pooled responses of the subjects best-fitted by a precision-cost model (<bold>e</bold>) or by an unpredictability-cost model (<bold>f</bold>). <italic>Right subpanels:</italic> bars are twice the square root of the sum of the two squared standard errors of the means (for each point, total n: <bold>e</bold>: 1393, <bold>f</bold>: 2189 to 2388). (<bold>g,h</bold>) Pooled responses of the models that best fit the corresponding subjects in panels (<bold>e,f</bold>). (<bold>i,j</bold>) Pooled responses of the unpredictability-cost models (<bold>i</bold>) and of the precision-cost models (<bold>j</bold>), fitted to the subjects best-fitted, respectively, by precision-cost models, and by unpredictability-cost models.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig4-v1.tif"/></fig><p>Turning to the precision-cost models, we have noted that in these models the posterior fluctuates with the recent history of the stimuli (<xref ref-type="fig" rid="fig3">Figure 3c</xref>): as a result, sequential effects are obtained, even with a Bernoulli observer (<inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig4">Figure 4a</xref>). The most recent stimulus has the largest weight in the exponentially filtered counts that determine the posterior (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>), thus the model subject’s prediction is biased towards the last stimulus, that is, the sequential effect is attractive (<inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). With the traditional probability-matching response-selection strategy (i.e. <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>), the strength of the attractive effect is the same across all stimulus generative probabilities (i.e. the difference <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is constant; <xref ref-type="fig" rid="fig4">Figure 4a</xref>, dotted lines and light-red dots). With the generalized probability-matching response-selection strategy, if <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, proportions below and above 0.5 are brought closer to the extremes (0 and 1, respectively), resulting in larger sequential effects for values of the stimulus generative probability closer to 0.5 (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, solid lines and red dots; the model is simulated with <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.8</mml:mn></mml:mstyle></mml:math></inline-formula>, a value representative of the subjects’ best-fitting values for this parameter). We also find stronger sequential effects closer to the equiprobable case in subjects’ data (<xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p><p>The precision-cost model of a Markov observer (<inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>) also predicts attractive sequential effects (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). While the behavior of the Bernoulli observer (with a precision cost) is determined by two exponentially-filtered counts of the two possible stimuli (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>), that of the Markov observer with <inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> depends on four exponentially filtered counts of the four possible pairs of stimuli. After observing a stimulus B, the belief that the following stimulus should be A or B is determined by the exponentially filtered counts of the pairs BA and BB. If <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> is large, i.e., if the stimulus B is infrequent, then the BA and BB pairs are also infrequent and the corresponding counts are close to zero: the model subject thus behaves as if only very little evidence had been observed about the transitions B to A and B to B in this case, resulting in a proportion of predictions A conditional on a preceding B, <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, close to 0.5 (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, orange line). Consequently, the sequential effects are stronger for values of the stimulus generative probabilities closer to the extreme (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, red dots).</p><p>Both families of costs are thus able to produce attractive sequential effects, albeit with some qualitative differences. (In <xref ref-type="fig" rid="fig4">Figure 4a–d</xref> we show the behaviors resulting from the two costs for a Bernoulli observer and a Markov observer of order <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>; the Markov observers of higher order exhibit qualitatively similar behaviors; see Methods.) As the model fitting indicates that different groups of subjects are best fitted by models belonging to the two families, we examine separately the behaviors of the subjects whose responses are best fitted by each of the two costs (<xref ref-type="fig" rid="fig4">Figure 4e and f</xref>), in comparison with the behaviors of the corresponding best-fitting models (<xref ref-type="fig" rid="fig4">Figure 4g and h</xref>). This provides a finer understanding of the behavior of subjects than the group average shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. For the subjects best fitted by precision-cost models, the proportion of predictions A, <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, when the stimulus generative probability is close to 0.5, is a less steep function of this probability than for the subjects best-fitted by unpredictability-cost models (<xref ref-type="fig" rid="fig4">Figure 4e and f</xref>, grey lines); furthermore, their sequential effects are larger (as measured by the difference <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>), and do not depend much on the stimulus generative probability (<xref ref-type="fig" rid="fig4">Figure 4e and f</xref>, red dots). The corresponding models reproduce the behavioral patterns of the subjects that they best fit (<xref ref-type="fig" rid="fig4">Figure 4g and h</xref>). Each family of models seems to capture specific behaviors exhibited by the subjects: when fitting the unpredictability-cost models to the responses of the subjects that are best fitted by precision-cost models, and conversely when fitting the precision-cost models to the responses of the subjects that are best fitted by unpredictability-cost models, the models do not reproduce well the subjects’ behavioral patterns (<xref ref-type="fig" rid="fig4">Figure 4i and j</xref>). The precision-cost models, however, seem slightly better than the unpredictability-cost models at capturing the behavior of the subjects that they do not best fit (<xref ref-type="fig" rid="fig4">Figure 4</xref>, compare panel j to panel f, and panel i to panel e). Substantiating this observation, the examination of the distributions of the models’ BICs across subjects shows that when fitting the models onto the subjects that they do not best fit, the precision-cost models fare better than the unpredictability-cost models (see Appendix).</p></sec><sec id="s2-10"><title>Beyond the most recent stimulus: patterns of higher-order sequential effects</title><p>Notwithstanding the quantitative differences just presented, both families of models yield qualitatively similar attractive sequential effects: the model subjects’ predictions are biased towards the preceding stimulus. Does this pattern also apply to the longer history of the stimulus, i.e., do more distant trials also influence the model subjects’ predictions? To investigate this hypothesis, we examine the difference between the proportion of predictions A after observing a sequence of length <inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula> that starts with A, minus the proportion of predictions A after the same sequence, but starting with B, i.e., <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> is a sequence of length <inline-formula><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> denote the same sequence preceded by A and by B. This quantity enables us to isolate the influence of the <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula>-to-last stimulus on the current prediction. If the difference is positive, the effect is ‘attractive’; if it is negative, the effect is ‘repulsive’ (in this latter case, the presentation of an A decreases the probability that the subjects predicts A in a later trial, as compared to the presentation of a B); and if the difference is zero there is no sequential effect stemming from the <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula>-to-last stimulus. The case <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> corresponds to the immediately preceding stimulus, whose effect we have shown to be attractive, i.e., <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, in the responses both of the best-fitting models and of the subjects (<xref ref-type="fig" rid="fig2">Figures 2b</xref>, <xref ref-type="fig" rid="fig4">4g and h</xref>).</p><p>We investigate the effect of the <inline-formula><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula>-to-last stimulus on the behavior of the two families of models, with <inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. We present here the main results of this investigation; we refer the reader to Methods for a more detailed analysis. With unpredictability-cost models of Markov order <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>, there are non-vanishing sequential effects stemming from the <inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula>-to-last stimulus only if the Markov order is greater than or equal to the distance from this stimulus to the current trial, i.e., if <inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>≥</mml:mo><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula>. In this case, the sequential effects are attractive (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Higher-order sequential effects: the precision-cost model of a Markov observer predicts a repulsive effect of the third-to-last stimulus.</title><p>Sequential effect of the second-to-last (<bold>a</bold>) and third-to-last (<bold>b,c</bold>) stimuli, in the responses of the precision-cost model of a Bernoulli observer (<inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>; white circles), of the precision-cost model of a Markov observer with <inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> (filled circles), and of the unpredictability-cost model of a Markov observer with <inline-formula><mml:math id="inf211"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula> (crosses). (<bold>a</bold>) Difference between the proportion of prediction A conditional on observing AA, and conditional on observing BA, i.e., <inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, as a function of the stimulus generative probability. With the three models, this difference is positive, indicating an attractive sequential effect of the second-to-last stimulus. (<bold>b</bold>) Difference between the proportion of prediction A conditional on observing AAA, and conditional on observing BAA, i.e., <inline-formula><mml:math id="inf213"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The positive difference indicates an attractive sequential effect of the third-to-last stimulus in this case. (<bold>c</bold>) Difference between the proportion of prediction A conditional on observing ABA, and conditional on observing BBA, i.e., <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. With the precision-cost model of a Markov observer, the negative difference when the stimulus generative probability is lower than 0.8 indicates a repulsive sequential effect of the third-to-last stimulus in this case, while when the probability is greater than 0.8, and with the predictability-cost model of a Bernoulli observer and with the unpredictability-cost model of a Markov observer, the positive difference indicates an attractive sequential effect of the third-to-last stimulus.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig5-v1.tif"/></fig><p>With precision-cost models, the <inline-formula><mml:math id="inf215"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula>-to-last stimuli yield non-vanishing sequential effects regardless of the Markov order, <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>. With <inline-formula><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, the effect is attractive, i.e., <inline-formula><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. With <inline-formula><mml:math id="inf219"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> (second-to-last stimulus), the effect is also attractive, i.e., in the case of the pair of sequences AA and BA, <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). By symmetry, the difference is also positive for the other pair of relevant sequences, AB and BB (e.g. we note that <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and that <inline-formula><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> when the probability of A is <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> is equal to <inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> when the probability of A is <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>. We detail in Methods such relations between the proportions of predictions A or B in different situations. These relations result in the symmetries of <xref ref-type="fig" rid="fig2">Figure 2</xref>, for the sequential effect of the last stimulus, while for higher-order sequential effects they imply that we do not need to show, in <xref ref-type="fig" rid="fig5">Figure 5</xref>, the effects following all possible past sequences of two or three stimuli, as the ones we do not show are readily derived from the ones we do.)</p><p>As for the third-to-last stimulus (<inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>), it can be followed by four different sequences of length two, but we only need to examine two of these four, for the reasons just presented. We find that for the precision-cost models, with all the Markov orders we examine (from 0 to 3), the probability of predicting A after observing the sequence AAA is greater than that after observing the sequence BAA, i.e., <inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, that is, there is an attractive sequential effect of the third-to-last stimulus if the sequence following it is AA (and, by symmetry, if it is BB; <xref ref-type="fig" rid="fig5">Figure 5b</xref>). So far, thus, we have found only attractive effects. However, the results are less straightforward when the third-to-last stimulus is followed by the sequence BA. In this case, for a Bernoulli observer (<inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), the effect is also attractive: <inline-formula><mml:math id="inf229"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, white circles). With Markov observers (<inline-formula><mml:math id="inf230"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), over a range of stimulus generative probability <inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, the effect is repulsive: <inline-formula><mml:math id="inf232"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, that is, the presentation of an A <italic>decreases</italic> the probability that the model subject predicts A three trials later, as compared to the presentation of a B (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, filled circles). The occurrence of the repulsive effect in this particular case is a distinctive trait of the precision-cost models of Markov observers (<inline-formula><mml:math id="inf233"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>); we do not obtain any repulsive effect with any of the unpredictability-cost models, nor with the precision-cost model of a Bernoulli observer (<inline-formula><mml:math id="inf234"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>).</p></sec><sec id="s2-11"><title>Subjects’ predictions exhibit higher-order repulsive effects</title><p>We now examine the sequential effects in subjects’ responses, beyond the attractive effect of the preceding stimulus (<inline-formula><mml:math id="inf235"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>; discussed above). With <inline-formula><mml:math id="inf236"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> (second-to-last stimulus), for the majority of the 19 stimulus generative probabilities <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, we find attractive sequential effects: the difference <inline-formula><mml:math id="inf238"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is significantly positive (<xref ref-type="fig" rid="fig6">Figure 6a</xref>; p-values &lt;0.01 for 11 stimulus generative probabilities, &lt;0.05 for 13 probabilities; subjects pooled). With <inline-formula><mml:math id="inf239"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula> (third-to-last stimulus), we also find significant attractive sequential effects in subjects’ responses for some of the stimulus generative probabilities, when the third-to-last stimulus is followed by the sequence AA (<xref ref-type="fig" rid="fig6">Figure 6b</xref>; p-values &lt;0.01 for four probabilities, &lt;0.05 for seven probabilities). When it is instead followed by the sequence BA, we find that for eight stimulus generative probabilities, all between 0.25 and 0.75, there is a significant repulsive sequential effect: <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (p-values &lt;0.01 for six probabilities, &lt;0.05 for eight probabilities; subjects pooled). Thus, in these cases, the occurrence of A as the third-to-last stimulus increases (in comparison with the occurrence of a B) the proportion of the <italic>opposite</italic> prediction, B. For the remaining stimulus generative probabilities, this difference is in most cases also negative although not significantly different from zero (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). (An across-subjects analysis yields similar results; see Supplementary Materials.) <xref ref-type="fig" rid="fig6">Figure 6d</xref> summarizes subjects’ sequential effects, and exhibits the attractive and repulsive sequential effects in their responses (compare solid and dotted lines). (In this tree-like representation, we show averages across the stimulus generative probabilities; a figure with the individual ‘trees’ for each probability is provided in the Appendix.)</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Patterns of attractive and repulsive sequential effects in subjects’ responses.</title><p>(<bold>a</bold>) Difference between the proportion of prediction A conditional on observing the sequence AA, and conditional on observing BA, i.e., <inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, as a function of the stimulus generative probability. This difference is in most cases positive, indicating an attractive sequential effect of the second-to-last stimulus. (<bold>b</bold>) Difference between the proportion of prediction A conditional on observing AAA, and conditional on observing BAA, i.e., <inline-formula><mml:math id="inf242"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. This difference is positive in most cases, indicating an attractive sequential effect of the third-to-last stimulus. (<bold>c</bold>) Difference between the proportion of prediction A conditional on observing ABA, and conditional on observing BBA, i.e., <inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. This difference is negative in most cases, indicating a repulsive sequential effect of the third-to-last stimulus. (<bold>d</bold>) Differences, averaged over all tested stimulus generative probabilities, between the proportion of predictions A conditional on sequences of up to three past observations, minus the unconditional proportion. The proportion conditional on a sequence is an average of the two proportions conditional on the same sequence preceded by another, ‘older’ observation, A or B, resulting in a binary-tree structure in this representation. If this additional past observation is A (respectively, B), we connect the two sequences with a solid line (respectively, a dotted line). In most cases, conditioning on an additional A increases the proportion of predictions A (in comparison to conditioning on an additional B), indicating an attractive sequential effect, except when the additional observation precedes the sequence BA (or its symmetric AB), in which cases repulsive sequential effects are observed (dotted line ‘above’ solid line). (<bold>e</bold>) Same as (<bold>c</bold>), with subjects split in two groups: the subjects best-fitted by precision-cost models (left) and the subjects best-fitted by unpredictability-cost models (right). In panels <bold>a-c</bold> and <bold>e</bold>, the filled circles indicate that the p-value of the Fisher exact test is below 0.05, and the filled squares indicate that the p-value with Bonferroni-Holm-Šidák correction is below 0.05. Bars are twice the square root of the sum of the two squared standard errors of the means (for each point, total n: <bold>a</bold>: 178 to 3584, <bold>b</bold>: 37 to 3394, <bold>c</bold>: 171 to 1868, <bold>e</bold>: 63 to 1184). In all panels, the responses of all the subjects are pooled together.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig6-v1.tif"/></fig><p>The repulsive sequential effect of the third-to-last stimulus in subjects’ predictions only occurs when the third-to-last stimulus is A followed by the sequence BA. It is also only in this case that the repulsive effect appears with the precision-cost models of a Markov observer (while it never appears with the unpredictability-cost models). This qualitative difference suggests that the precision-cost models offer a better account of sequential effects in subjects. However, model-fitting onto the overall behavior presented above showed that a fraction of the subjects is better fitted by the unpredictability-cost models. We investigate, thus, the presence of a repulsive effect in the predictions of the subjects best fitted by the precision-cost models, and of those best fitted by the unpredictability-cost models. For the subjects best fitted by the precision-cost models, we find (expectedly) that there is a significant repulsive sequential effect of the third-to-last stimulus (<inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; p-values &lt;0.01 for two probabilities, &lt;0.05 for four probabilities; subjects pooled; <xref ref-type="fig" rid="fig6">Figure 6e</xref>, left panel). For the subjects best fitted by the unpredictability-cost models (a family of model that does not predict any repulsive sequential effects), we also find, perhaps surprisingly, a significant repulsive effect of the third-to-last stimulus (p-values &lt;0.01 for three probabilities, &lt;0.05 for five probabilities; subjects pooled), which demonstrates the robustness of this effect (<xref ref-type="fig" rid="fig6">Figure 6e</xref>, right panel). Thus, in spite of the results of the model-selection procedure, some sequential effects in subjects’ predictions support only one of the two families of model. Regardless of the model that best fits their overall predictions, the behavior of the subjects is consistent only with the precision-cost family of models with Markov order equal to or greater than 1, that is, with a model of inference of conditional probabilities hampered by a cognitive cost weighing on the precision of belief distributions.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We investigated the hypothesis that sequential effects in human predictions result from cognitive constraints hindering the inference process carried out by the brain. We devised a framework of constrained inference, in which the model subject bears a cognitive cost when updating its belief distribution upon the arrival of new evidence: the larger the cost, the more the subject’s posterior differs from the Bayesian posterior. The models we derive from this framework make specific predictions. First, the proportion of forced-choice predictions for a given stimulus should increase with the stimulus generative probability. Second, most of those models predict sequential effects: predictions also depend on the recent stimulus history. Models with different types of cognitive cost resulted in different patterns of attractive and repulsive effects of the past few stimuli on predictions. To compare the predictions of constrained inference with human behavior, we asked subjects to predict each next outcome in sequences of binary stimuli. We manipulated the stimulus generative probability in blocks of trials, exploring exhaustively the probability range from 0.05 to 0.95 by increments of 0.05. We found that subjects’ predictions depend on both the stimulus generative probability and the recent stimulus history. Sequential effects exhibited both attractive and repulsive components which were modulated by the stimulus generative probability. This behavior was qualitatively accounted for by a model of constrained inference in which the subject infers the transition probabilities underlying the sequences of stimuli and bears a cost that increases with the precision of the posterior distributions. Our study proposes a novel theoretical account of sequential effects in terms of optimal inference under cognitive constraints and it uncovers the richness of human behavior over a wide range of stimulus generative probabilities.</p><p>The notion that human decisions can be understood as resulting from a constrained optimization has gained traction across several fields, including neuroscience, cognitive science, and economics. In neuroscience, a voluminous literature that started with <xref ref-type="bibr" rid="bib4">Attneave, 1954</xref> and <xref ref-type="bibr" rid="bib10">Barlow, 1961</xref> investigates the idea that perception maximizes the transmission of information, under the constraint of costly and limited neural resources (<xref ref-type="bibr" rid="bib66">Laughlin, 1981</xref>; <xref ref-type="bibr" rid="bib67">Laughlin et al., 1998</xref>; <xref ref-type="bibr" rid="bib103">Simoncelli and Olshausen, 2001</xref>); related theories of ‘efficient coding’ account for the bias and the variability of perception (<xref ref-type="bibr" rid="bib43">Ganguli and Simoncelli, 2016</xref>; <xref ref-type="bibr" rid="bib116">Wei and Stocker, 2015</xref>; <xref ref-type="bibr" rid="bib117">Wei and Stocker, 2017</xref>; <xref ref-type="bibr" rid="bib91">Prat-Carrabin and Woodford, 2021c</xref>). In cognitive science and economics, ‘bounded rationality’ is a precursory concept introduced in the 1950s by Herbert Simon, who defines it as “rational choice that takes into account the cognitive limitations of the decision maker — limitations of both knowledge and computational capacity” (<xref ref-type="bibr" rid="bib102">Simon, 1997</xref>). For Gigerenzer, these limitations promote the use of heuristics, which are ‘fast and frugal’ ways of reasoning, leading to biases and errors in humans and other animals (<xref ref-type="bibr" rid="bib45">Gigerenzer and Goldstein, 1996</xref>; <xref ref-type="bibr" rid="bib46">Gigerenzer and Selten, 2002</xref>). A range of more recent approaches can be understood as attempts to specify formally the limitations in question, and the resulting trade-off. The ‘resource-rational analysis’ paradigm aims at a unified theoretical account that reconciles principles of rationality with realistic constraints about the resources available to the brain when it is carrying out computations (<xref ref-type="bibr" rid="bib51">Griffiths et al., 2015</xref>). In this approach, biases result from the constraints on resources, rather than from ‘simple heuristics’ (see <xref ref-type="bibr" rid="bib68">Lieder and Griffiths, 2019</xref> for an extensive review). For instance, in economics, theories of ‘rational inattention’ propose that economic agents optimally allocate resources (a limited amount of attention) to make decisions, thereby proposing new accounts of empirical findings in the economic literature (<xref ref-type="bibr" rid="bib104">Sims, 2003</xref>; <xref ref-type="bibr" rid="bib119">Woodford, 2009</xref>; <xref ref-type="bibr" rid="bib20">Caplin et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Gabaix, 2017</xref>; <xref ref-type="bibr" rid="bib6">Azeredo da Silveira and Woodford, 2019</xref>; <xref ref-type="bibr" rid="bib7">Azeredo da Silveira et al., 2020</xref>).</p><p>Our study puts forward a ‘resource-rational’ account of sequential effects. Traditional accounts since the 1960s attribute these effects to a belief in sequential dependencies between successive outcomes (<xref ref-type="bibr" rid="bib34">Edwards, 1961</xref>; <xref ref-type="bibr" rid="bib72">Matthews and Sanders, 1984</xref>) (potentially ‘acquired through life experience’ <xref ref-type="bibr" rid="bib5">Ayton and Fischer, 2004</xref>), and more generally to the incorrect models that people assume about the processes generating sequences of events (see <xref ref-type="bibr" rid="bib82">Oskarsson et al., 2009</xref> for a review; similar rationales have been proposed to account for suboptimal behavior in other contexts, for example in exploration-exploitation tasks <xref ref-type="bibr" rid="bib79">Navarro et al., 2016</xref>). This traditional account was formalized, in particular, by models in which subjects carry out a statistical inference about the sequence of stimuli presented to them, and this inference assumes that the parameters underlying the generating process are subject to changes (<xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>; <xref ref-type="bibr" rid="bib122">Zhang et al., 2014</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>). In these models, sequential effects are thus understood as resulting from a rational adaptation to a changing world. Human subjects indeed dynamically adapt their learning rate when the environment changes (<xref ref-type="bibr" rid="bib84">Payzan-LeNestour et al., 2013</xref>; <xref ref-type="bibr" rid="bib76">Meyniel and Dehaene, 2017</xref>; <xref ref-type="bibr" rid="bib78">Nassar et al., 2010</xref>), and they can even adapt their inference to the statistics of these changes (<xref ref-type="bibr" rid="bib13">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib90">Prat-Carrabin et al., 2021b</xref>). However, in our task and in many previous studies in which sequential effects have been reported, the underlying statistics are in fact not changing across trials. The models just mentioned thus leave unexplained why subjects’ behavior, in these tasks, is not rationally adapted to the unchanging statistics of the stimulus.</p><p>What underpins our main hypothesis is a different kind of rational adaptation: one, instead, to the ‘cognitive limitations of the decision maker’, which we assume hinder the inference carried out by the brain. We show that rational models of inference under a cost yield rich patterns of sequential effects. When the cost varies with the precision of the posterior (measured here by the negative of its entropy, <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>), the resulting optimal posterior is proportional to the product of the prior and the likelihood, each raised to an exponent <inline-formula><mml:math id="inf245"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). Many previous studies on biased belief updating have proposed models that adopt the same form except for the different exponents applied to the prior and to the likelihood (<xref ref-type="bibr" rid="bib50">Grether, 1980</xref>; <xref ref-type="bibr" rid="bib71">Matsumori et al., 2018</xref>; <xref ref-type="bibr" rid="bib14">Benjamin, 2019</xref>). Here, with the precision cost, both quantities are raised to the same exponent and we note that in this case the inference of the subject amounts to an exponentially decaying count of the patterns observed in the sequence of stimuli, which is sometimes called ‘leaky integration’ in the literature (<xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Jones et al., 2013</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>). The models mentioned above, that posit a belief in changing statistics, indeed are well approximated by models of leaky integration (<xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>), which shows that the exponential discount can have different origins. <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref> show that the precision-cost, Markov-observer model with <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> (named ‘local transition probability model’ in this study) accounts for a range of other findings, in addition to sequential effects, such as biases in the perception of randomness and patterns in the surprise signals recorded through EEG and fMRI. Here we reinterpret these effects as resulting from an optimal inference subject to a cost, rather than from a suboptimal erroneous belief in the dynamics of the stimulus’ statistics. In our modeling approach, the minimization of a loss function (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) formalizes a trade-off between the distance to optimality of the inference, and the cognitive constraints under which it is carried out. We stress that our proposal is not that the brain actively solves this optimization problem online, but instead that it is endowed with an inference algorithm (whose origin remains to be elucidated) which is effectively a solution to the constrained optimization problem.</p><p>By grounding the sequential effects in the optimal solution to a problem of constrained optimization, our approach opens avenues for exploring the origins of sequential effects, in the form of hypotheses about the nature of the constraint that hinders the inference carried out by the brain. With the precision cost, more precise posterior distributions are assumed to take a larger cognitive toll. The intuitive assumption that it is costly to be precise finds a more concrete realization in neural models of inference with probabilistic population codes: in these models, the precision of the posterior is proportional to the average activity of the population of neurons and to the number of neurons (<xref ref-type="bibr" rid="bib69">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib98">Seung and Sompolinsky, 1993</xref>). More neural activity and more neurons arguably come with a metabolic cost, and thus more precise posteriors are more costly in these models. Imprecisions in computations, moreover, was shown to successfully account for decision variability and adaptive behavior in volatile environments (<xref ref-type="bibr" rid="bib35">Findling et al., 2019</xref>; <xref ref-type="bibr" rid="bib36">Findling et al., 2021</xref>).</p><p>The unpredictability cost, which we introduce, yields models that also exhibit sequential effects (for Markov observers), and that fit several subjects better than the precision-cost models. The unpredictability cost relies on a different hypothesis: that the cost of representing a distribution over different possible states of the world (here, different possible values of <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>) resides in the difficulty of representing these states. This could be the case, for instance, under the hypothesis that the brain runs stochastic simulations of the implied environments, as proposed in models of ‘intuitive physics’ (<xref ref-type="bibr" rid="bib12">Battaglia et al., 2013</xref>) and in Kahneman and Tversky’s ‘simulation heuristics’ (<xref ref-type="bibr" rid="bib62">Kahneman et al., 1982</xref>). More entropic environments imply more possible scenarios to simulate, giving rise, under this assumption, to higher costs. A different literature explores the hypothesis that the brain carries out a mental compression of sequences (<xref ref-type="bibr" rid="bib101">Simon, 1972</xref>; <xref ref-type="bibr" rid="bib21">Chekaf et al., 2016</xref>; <xref ref-type="bibr" rid="bib86">Planton et al., 2021</xref>); entropy in this context is a measure of the degree of compressibility of a sequence (<xref ref-type="bibr" rid="bib86">Planton et al., 2021</xref>), and thus, presumably, of its implied cost. As a result, the brain may prefer predictable environments over unpredictable ones. Human subjects exhibit a preference for predictive information indeed (<xref ref-type="bibr" rid="bib81">Ogawa and Watanabe, 2011</xref>; <xref ref-type="bibr" rid="bib110">Trapp et al., 2015</xref>), while unpredictable stimuli have been shown not only to increase anxiety-like behavior (<xref ref-type="bibr" rid="bib54">Herry et al., 2007</xref>), but also to induce more neural activity (<xref ref-type="bibr" rid="bib54">Herry et al., 2007</xref>; <xref ref-type="bibr" rid="bib30">den Ouden et al., 2009</xref>; <xref ref-type="bibr" rid="bib2">Alink et al., 2010</xref>) — a presumably costly increase, which may result from the encoding of larger prediction errors (<xref ref-type="bibr" rid="bib54">Herry et al., 2007</xref>; <xref ref-type="bibr" rid="bib96">Schultz and Dickinson, 2000</xref>).</p><p>We note that both costs (precision and unpredictability) can predict sequential effects, even though neither carries <italic>ex ante</italic> an explicit assumption that presupposes the existence of sequential effects. They both reproduce the attractive recency effect of the last stimulus exhibited by the subjects. They make quantitatively different predictions (<xref ref-type="fig" rid="fig4">Figure 4</xref>); we also find this diversity of behaviors in subjects.</p><p>The precision cost, as mentioned above, yields leaky-integration models which can be summarized by a simple algorithm in which the observed patterns are counted with an exponential decay. The psychology and neuroscience literature proposes many similar ‘leaky integrators’ or ‘leaky accumulators’ models (<xref ref-type="bibr" rid="bib105">Smith, 1995</xref>; <xref ref-type="bibr" rid="bib93">Roe et al., 2001</xref>; <xref ref-type="bibr" rid="bib112">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib25">Cook and Maunsell, 2002</xref>; <xref ref-type="bibr" rid="bib115">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib108">Sugrue et al., 2004</xref>; <xref ref-type="bibr" rid="bib17">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib63">Kiani et al., 2008</xref>; <xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib44">Gao et al., 2011</xref>; <xref ref-type="bibr" rid="bib111">Tsetsos et al., 2012</xref>; <xref ref-type="bibr" rid="bib83">Ossmy et al., 2013</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>). In connectionist models of decision-making, for instance, decision units in abstract network models have activity levels that accumulate evidence received from input units, and which decay to zero in the absence of input (<xref ref-type="bibr" rid="bib93">Roe et al., 2001</xref>; <xref ref-type="bibr" rid="bib112">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib115">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib17">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib111">Tsetsos et al., 2012</xref>). In other instances, perceptual evidence (<xref ref-type="bibr" rid="bib63">Kiani et al., 2008</xref>; <xref ref-type="bibr" rid="bib44">Gao et al., 2011</xref>; <xref ref-type="bibr" rid="bib83">Ossmy et al., 2013</xref>) or counts of events (<xref ref-type="bibr" rid="bib108">Sugrue et al., 2004</xref>; <xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref>) are accumulated through an exponential temporal filter. In our approach, leaky integration is not an assumption about the mechanisms underpinning some cognitive process: instead, we find that it is an optimal strategy in the face of a cognitive cost weighing on the precision of beliefs. Although it is less clear whether the unpredictability-cost models lend themselves to a similar algorithmic simplification, they consist in a distortion of Bayesian inference, for which various neural-network models have been proposed (<xref ref-type="bibr" rid="bib29">Deneve et al., 2001</xref>; <xref ref-type="bibr" rid="bib70">Ma et al., 2008</xref>; <xref ref-type="bibr" rid="bib42">Ganguli and Simoncelli, 2014</xref>; <xref ref-type="bibr" rid="bib32">Echeveste et al., 2020</xref>).</p><p>Turning to the experimental results, we note that in spite of the rich literature on sequential effects, the majority of studies have focused on equiprobable Bernoulli environments, in which the two possible stimuli both had a probability equal to 0.5, as in tosses of a fair coin (<xref ref-type="bibr" rid="bib106">Soetens et al., 1985</xref>; <xref ref-type="bibr" rid="bib22">Cho et al., 2002</xref>; <xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Jones et al., 2013</xref>; <xref ref-type="bibr" rid="bib122">Zhang et al., 2014</xref>; <xref ref-type="bibr" rid="bib5">Ayton and Fischer, 2004</xref>; <xref ref-type="bibr" rid="bib48">Gökaydin and Ejova, 2017</xref>). In environments of this kind, the two stimuli play symmetric roles and all sequences of a given length are equally probable. In contrast, in biased environments one of the two possible stimuli is more probable than the other. Although much less studied, this situation breaks the regularities of equiprobable environments and is arguably very frequent in real life. In our experiment, we explore stimulus generative probabilities from 0.05 to 0.95, thus allowing to investigate the behavior of subjects in a wide spectrum of Bernoulli environments: from these with ‘extreme’ probabilities (e.g. p = 0.95) to these only slightly different from the equiprobable case (e.g. p = 0.55) to the equiprobable case itself (p = 0.5). The subjects are sensitive to the imbalance of the non-equiprobable cases: while they predict A in half the trials of the equiprobable case, a probability of just p = 0.55 suffices to prompt the subjects to predict A in about in 60% of trials, a significant difference (<inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.602</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; sem: 0.008; p-value of t-test against null hypothesis that <inline-formula><mml:math id="inf249"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>: 1.7e-11; subjects pooled).</p><p>The well-known ‘probability matching’ hypothesis (<xref ref-type="bibr" rid="bib53">Herrnstein, 1961</xref>; <xref ref-type="bibr" rid="bib114">Vulkan, 2000</xref>; <xref ref-type="bibr" rid="bib40">Gaissmaier and Schooler, 2008</xref>) suggests that the proportion of predictions A matches the stimulus generative probability: <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. This hypothesis is not supported by our data. We find that in the non-equiprobable conditions these two quantities are significantly different (all p-values &lt;1e-11, when <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>≠</mml:mo><mml:mn>0.5</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). More precisely, we find that the proportion of prediction A is more extreme than the stimulus generative probability (i.e. <inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf253"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf255"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig2">Figure 2a</xref>). This result is consistent with the observations made by <xref ref-type="bibr" rid="bib34">Edwards, 1961</xref>; <xref ref-type="bibr" rid="bib33">Edwards, 1956</xref> and with the conclusions of a more recent review (<xref ref-type="bibr" rid="bib114">Vulkan, 2000</xref>).</p><p>In addition to varying with the stimulus generative probability, the subjects’ predictions depend on the recent history of stimuli. Recency effects are common in the psychology literature; they were reported from memory (<xref ref-type="bibr" rid="bib31">Ebbinghaus et al., 1913</xref>) to causal learning (<xref ref-type="bibr" rid="bib24">Collins and Shanks, 2002</xref>) to inference (<xref ref-type="bibr" rid="bib100">Shanteau, 1972</xref>; <xref ref-type="bibr" rid="bib56">Hogarth and Einhorn, 1992</xref>; <xref ref-type="bibr" rid="bib14">Benjamin, 2019</xref>). Recency effects, in many studies, are obtained in the context of reaction tasks, in which subjects must identify a stimulus and quickly provide a response (<xref ref-type="bibr" rid="bib58">Hyman, 1953</xref>; <xref ref-type="bibr" rid="bib15">Bertelson, 1965</xref>; <xref ref-type="bibr" rid="bib65">Kornblum, 1967</xref>; <xref ref-type="bibr" rid="bib106">Soetens et al., 1985</xref>; <xref ref-type="bibr" rid="bib22">Cho et al., 2002</xref>; <xref ref-type="bibr" rid="bib120">Yu and Cohen, 2008</xref>; <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Jones et al., 2013</xref>; <xref ref-type="bibr" rid="bib122">Zhang et al., 2014</xref>). Although our task is of a different kind (subjects must predict the next stimulus), we find some evidence of recency effects in the response times of subjects: after observing the less frequent of the two stimuli (when <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), subjects seem slower at providing a response (see Appendix). In prediction tasks (like ours), both attractive recency effects, also called ‘hot-hand fallacy’, and repulsive recency effects, also called ‘gambler’s fallacy’, have been reported (<xref ref-type="bibr" rid="bib60">Jarvik, 1951</xref>; <xref ref-type="bibr" rid="bib34">Edwards, 1961</xref>; <xref ref-type="bibr" rid="bib5">Ayton and Fischer, 2004</xref>; <xref ref-type="bibr" rid="bib18">Burns and Corpus, 2004</xref>; <xref ref-type="bibr" rid="bib26">Croson and Sundali, 2005</xref>; <xref ref-type="bibr" rid="bib82">Oskarsson et al., 2009</xref>). The observation of both effects within the same experiment has been reported in a visual identification task (<xref ref-type="bibr" rid="bib23">Chopin and Mamassian, 2012</xref>) and in risky choices (‘wavy recency effect’ <xref ref-type="bibr" rid="bib87">Plonsky et al., 2015</xref>; <xref ref-type="bibr" rid="bib88">Plonsky and Erev, 2017</xref>). As to the heterogeneity of these results, several explanations have been proposed; two important factors seem to be the perceived degree of randomness of the predicted variable and whether it relates to human performance (<xref ref-type="bibr" rid="bib5">Ayton and Fischer, 2004</xref>; <xref ref-type="bibr" rid="bib18">Burns and Corpus, 2004</xref>; <xref ref-type="bibr" rid="bib26">Croson and Sundali, 2005</xref>; <xref ref-type="bibr" rid="bib82">Oskarsson et al., 2009</xref>). In any event, most studies focus exclusively on the influence of ‘runs’ of identical outcomes on the upcoming prediction, for example, in our task, on whether three As in a row increases the proportion of predictions A. With this analysis, Edwards (<xref ref-type="bibr" rid="bib34">Edwards, 1961</xref>) in a task similar to ours concluded to an attractive recency effect (which he called ‘probability following’). Although our results are consistent with this observation (in our data three As in a row do increase the proportion of predictions A), we provide a more detailed picture of the influence of each stimulus preceding the prediction, whether it is in a ‘run’ of identical stimuli or not, which allows us to exhibit the non-trivial finer structure of the recency effects that is often overlooked.</p><p>Up to two stimuli in the past, the recency effect is attractive: observing A at trial <inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> or at trial <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> induces, all else being equal, a higher proportion of predictions A at trial <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> (in comparison to observing B; <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig6">6a</xref>). The influence of the third-to-last stimulus is more intricate: it can yield either an attractive or a repulsive effect, depending on the second-to-last and the last stimuli. For a majority of probability parameters, <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, while an A followed by the sequence AA has an attractive effect (i.e. <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>), an A followed by the sequence BA has a repulsive effect (i.e. <inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig6">Figure 6b and c</xref>). How can this reversal be intuited? Only one of our models, the precision-cost model with a Markov order 1 (<inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>), reproduces this behavior; we show how it provides an interpretation for this result. From the update equation of this model (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), it is straightforward to show that the posterior of the model subject (a Dirichlet distribution of order 4) is determined by four quantities, which are exponentially-decaying counts of the four two-long patterns observed in the sequence of stimuli: BB, BA, AB, and AA. The higher the count of a pattern, the more likely the model subject deems this pattern to happen again. In the equiprobable case (<inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mstyle></mml:math></inline-formula>), after observing the sequence AAA, the count of AA is higher than after observing BAA, thus the model subject believes that AA is more probable, and accordingly predicts A more frequently, i.e., <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. As for the sequences ABA and BBA, both result in the same count of AA, but the former results in a higher count of AB — in other words, the short sequence ABA suggests that A is usually followed by B, but the sequence BBA does not — and thus the model subject predicts more frequently B, i.e., less frequently A (<inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><p>In short, the ability of the precision-cost model of a Markov observer to capture the repulsive effect found in behavioral data suggests that human subjects extrapolate the local statistical properties of the presented sequence of stimuli in order to make predictions, and that they pay attention not only to the ‘base rate’ — the marginal probability of observing A, unconditional on the recent history — as a Bernoulli observer would do, but also to the statistics of more complex patterns, including the repetitions and the alternations, thus capturing the transition probabilities between consecutive observations. <xref ref-type="bibr" rid="bib118">Wilder et al., 2009</xref>, <xref ref-type="bibr" rid="bib61">Jones et al., 2013</xref>, and <xref ref-type="bibr" rid="bib75">Meyniel et al., 2016</xref> similarly argue that sequential effects result from an imperfect inference of the base rate and of the frequency of repetitions and alternations. <xref ref-type="bibr" rid="bib28">Dehaene et al., 2015</xref> argue that the knowledge of transition probabilities is a central mechanism in the brain’s processing of sequences (e.g. in language comprehension), and infants as young as 5 months were shown to be able to track both base rates and transition probabilities (see <xref ref-type="bibr" rid="bib94">Saffran and Kirkham, 2018</xref> for a review). Learning of transition probabilities has also been observed in rhesus monkeys (<xref ref-type="bibr" rid="bib74">Meyer and Olson, 2011</xref>).</p><p>The deviations from perfect inference, in the precision-cost model, originate in the constraints faced by the brain when performing computation with probability distributions. In spite of the success of the Bayesian framework, we note that human performance in various inference tasks is often suboptimal (<xref ref-type="bibr" rid="bib78">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib57">Hu et al., 2013</xref>; <xref ref-type="bibr" rid="bib1">Acerbi et al., 2014</xref>; <xref ref-type="bibr" rid="bib90">Prat-Carrabin et al., 2021b</xref>; <xref ref-type="bibr" rid="bib92">Prat-Carrabin and Woodford, 2022</xref>). Our approach suggests that the deviations from optimality in these tasks may be explained by the cognitive constraints at play in the inference carried out by humans.</p><p>Other studies have considered the hypothesis that suboptimal behavior in inference tasks results from cognitive constraints. <xref ref-type="bibr" rid="bib64">Kominers et al., 2016</xref> consider a model in which Bayesian inference comes with a fixed cost; the observer can choose to forgo updating her belief, so as to avoid the cost. In some cases, the model predicts ‘permanently cycling beliefs’ that do not converge; but in general the model predicts that subjects will choose not to react to new evidence that is unsurprising under the current belief. The significant sequential effects we find in our subjects’ responses, however, seem to indicate that they are sensitive to both unsurprising (e.g. outcome A when p&gt;0.5) and surprising (outcome B when p&gt;0.5) observations, at least across the values of the stimulus generative probability that we test (<xref ref-type="fig" rid="fig2">Figure 2</xref>). <xref ref-type="bibr" rid="bib49">Graeber, 2020</xref> considers costly information processing as an account of subjects’ neglect of confounding variables in an inference task, but concludes instead that the suboptimal behavior of subjects results from their misunderstanding of the information structure in the task. A model close to ours is the one proposed in <xref ref-type="bibr" rid="bib6">Azeredo da Silveira and Woodford, 2019</xref> and <xref ref-type="bibr" rid="bib7">Azeredo da Silveira et al., 2020</xref>, in which an information-theoretic cost limits the memory of an otherwise optimal and Bayesian decision-maker, resulting, here also, in beliefs that fluctuate and do not converge, and in an overweighting, in decisions, of the recent evidence.</p><p>Taking a different approach, <xref ref-type="bibr" rid="bib27">Dasgupta et al., 2020</xref> implement a neural network that learns to approximate Bayesian posteriors. Possible approximate posteriors are constrained not only by the structure of the network, but also by the fact that the same network is used to address a series of different inference problems. Thus the network’s parameters must be ‘shared’ across problems, which is meant to capture the brain’s limited computational resources. Although this constraint differs from the ones we consider, we note that in this study the distance function (which the approximation aims to minimize) is the same as in our models, namely, the Kullback-Leibler divergence from the optimal posterior to the approximate posterior, <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. Minimizing this divergence (under a cost) allows the model subject to obtain a posterior as close as possible (at least by this measure) to the optimal posterior given the most recent stimulus and the subject’s belief prior to observing the stimulus, which in turn enables the subject to perform reasonably well in the task.</p><p>In principle, rewarding subjects with a higher payoff when they make a correct prediction would change the optimal trade-off (between the distance to the optimal posterior and the cognitive costs) formalized in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, resulting in ‘better’ posteriors (closer to the Bayesian posterior), and thus to higher performance in the task. At the same time, incentivization is known to influence, also in the direction of higher performance, the extent to which choice behavior is close to probability matching (<xref ref-type="bibr" rid="bib114">Vulkan, 2000</xref>). The interesting question of the respective sensitivities of the subjects’ inference process and of their response-selection strategy in response to different levels of incentives is beyond the scope of this study, in which we have focussed on the sensitivity of behavior to different stimulus generative probabilities.</p><p>In any case, the approach of minimizing the Kullback-Leibler divergence from the optimal posterior to the approximate posterior is widely used in the machine learning literature, and forms the basis of the ‘variational’ family of approximate-inference techniques (<xref ref-type="bibr" rid="bib16">Bishop, 2006</xref>). These techniques have inspired various cognitive models (<xref ref-type="bibr" rid="bib95">Sanborn, 2017</xref>; <xref ref-type="bibr" rid="bib41">Gallistel and Latham, 2022</xref>; <xref ref-type="bibr" rid="bib3">Aridor and Woodford, 2023</xref>); alternatively, a bound on the divergence, known as the ‘evidence bound’, or, in neuroscience, as the negative of the ‘free energy’, is maximized (<xref ref-type="bibr" rid="bib77">Moustafa, 2017</xref>; <xref ref-type="bibr" rid="bib37">Friston et al., 2006</xref>; <xref ref-type="bibr" rid="bib38">Friston, 2009</xref>). (We note that the ‘opposite’ divergence, <inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is minimized in a different machine-learning technique, ‘expectation propagation’ (<xref ref-type="bibr" rid="bib16">Bishop, 2006</xref>), and in the cognitive model of causal reasoning of <xref ref-type="bibr" rid="bib59">Icard and Goodman, 2015</xref>.) In these techniques, the approximate posterior is chosen within a convenient family of tractable, parameterized distributions; other distributions are precluded. This can be understood, in our framework, as positing a cost <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> that is infinite for most distributions, but zero for the distributions that belong to some arbitrary family (<xref ref-type="bibr" rid="bib89">Prat-Carrabin et al., 2021a</xref>). The precision cost and the unpredictability cost, in comparison, are ‘smooth’, and allow for any distribution, but they penalize, respectively, more precise belief distributions, and belief distributions that imply more unpredictable environments. Our study shows that inference, when subject to either of these costs, yields an attractive sequential effect of the most recent observation; and with a precision cost weighing on the inference of transition probabilities (i.e., <inline-formula><mml:math id="inf270"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>), the model predicts the subtle pattern of attractive and repulsive sequential effects that we find in subjects’ responses.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Task and subjects</title><p>The computer-based task was programmed using the Python library PsychoPy (<xref ref-type="bibr" rid="bib85">Peirce, 2008</xref>). The experiment comprised ten blocks of trials, which differed by the stimulus generative probability, p, used in all the trials of each block. The probability p was chosen randomly among the ten values ranging from 0.50 to 0.95 by increments of 0.05, excluding the values already chosen; and with probability 1/2 the stimulus generative probability <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> was used instead. Each block started with 200 passive trials, in which the subject was only asked to look at the 200 stimuli sampled with the block’s probability and successively presented. No action from the subject was required for these passive trials. The subject was then asked to predict, in each of 200 trials, the next location of the stimulus. Subjects provided their responses by a keypress. The task was presented as a game to the subjects: the stimulus was a lightning symbol, and predicting correctly whether the lightning would strike the left or the right rod resulted in the electrical energy of the lightning being collected in a battery (<xref ref-type="fig" rid="fig1">Figure 1</xref>). A gauge below the battery indicated the amount of energy accumulated in the current block of trials (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Twenty subjects (7 women, 13 men; age: 18–41, mean 25.5, standard deviation 6.2) participated in the experiment. All subjects completed the ten blocks of trials, except one subject who did not finish the experiment and was excluded from the analysis. The study was approved by the ethics committee Île de France VII (CPP 08–021). Participants gave their written consent prior to participating. The number of blocks of trials and the number of trials per block were chosen as a trade-off between maximizing the statistical power of the study, scanning the values of the generative probability parameter from 0.05 to 0.95 with a satisfying resolution, and maintaining the duration of the experiment under a reasonable length of time. The number of subjects was chosen consistently with similar studies and so as to capture individual variability. Throughout the study, we conduct Student’s t-tests when comparing the subjects’ proportion of predictions A to a given value (e.g. 0.5). When comparing two proportions of predictions A obtained under different conditions (e.g. depending on whether the preceding stimulus is A or B), we accordingly conduct Fisher exact tests. The trials in which subjects failed to respond within the limit of 1 s were not included in the analysis. They represented 1.27% of the trials, on average (across subjects); and for 95% of the subjects these trials represented less than 2.5% of the trials.</p></sec><sec id="s4-2"><title>Sequential effects of the models</title><p>We run simulations of the eight models and look at the predictions they yield. To reproduce the conditions faced by the subjects, which included 200 passive trials, we start each simulation by showing to the model subject 200 randomly sampled stimuli (without collecting predictions at this stage). We then show an additional 200 samples, and obtain a prediction from the model subject after each sample. The sequential effects of the most recent stimulus, with the different models, are shown in <xref ref-type="fig" rid="fig7">Figure 7</xref>. With the precision-cost models, the posterior distribution of the model subject does not converge, but fluctuates instead with the recent history of the stimulus. This results in attractive sequential effects (<xref ref-type="fig" rid="fig7">Figure 7a</xref>), including for the Bernoulli observer, who assumes that the probability of A does not depend on the most recent stimulus. With the unpredictability-cost models, the posterior of the model subject does converge. With Markov observers, it converges toward a parameter vector <inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> that implies that the probability of observing A depends on the most recent stimulus, resulting in the presence of sequential effects of the most recent stimulus (<xref ref-type="fig" rid="fig7">Figure 7b</xref>, second to fourth row). With a Bernoulli observer, the posterior of the model subject converges toward a value of the stimulus generative probability that does not depend on the stimulus history. As more evidence is accumulated, the posterior narrows around this value but not without some fluctuations that depend on the sequence of stimuli presented. In consequence the model subject’s estimate of the stimulus generative probability is also subject to fluctuations, and depends on the history of stimuli (including the most recent stimulus), although the width of the fluctuations tend to zero as more stimuli are observed. After the 200 stimuli of the passive trials, the sequential effects of the most recent stimulus resulting from this transient regime appear small in comparison to the sequential effects obtained with the other models (<xref ref-type="fig" rid="fig7">Figure 7b</xref>, first row). The <xref ref-type="fig" rid="fig7">Figure 7</xref> also shows the behaviors of the models when augmented with a propensity to repeat the preceding response: we comment on these in the section dedicated to these models, below.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Sequential effects of the most recent stimulus in precision-cost and unpredictability-cost models.</title><p>(<bold>a</bold>) Precision-cost models. (<bold>b</bold>) Unpredictability-cost models. <italic>First row</italic>: Bernoulli observers (m = 0). <italic>Second to fourth rows</italic>: Markov observers (m = 1, 2, and 3). <italic>First column (each panel</italic>): proportion of predictions A in the models’ responses as a function of the stimulus generative probability, conditional on the preceding observation being A (blue line) or B (orange line), and unconditional (grey line); with repetition propensity (<inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mstyle></mml:math></inline-formula>, dotted lines), and without (solid lines). <italic>Second column (each panel</italic>): difference between the proportion of predictions A conditional on the preceding observation being A, and the same proportion conditional on a B; with repetition propensity (dotted lines), and without (solid lines). A positive difference indicates an attractive sequential effect of the most recent stimulus.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig7-v1.tif"/></fig><p>Turning to higher-order sequential effects, we look at the influence on predictions of the second- and third-to-last stimulus (<xref ref-type="fig" rid="fig8">Figure 8</xref>). As mentioned, only precision-cost models of Markov observers yield repulsive sequential effects, and these occur only when the third-to-last-stimulus is followed by BA. They do not occur with the second-to-last stimulus, nor with the third-to-last-stimulus when it is followed by AA (<xref ref-type="fig" rid="fig8">Figure 8a</xref>); and they do not occur in any case with the unpredictability-cost models (<xref ref-type="fig" rid="fig8">Figure 8b</xref>).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Sequential effects of the second- and third-to-last stimuli in precision-cost and unpredictability-cost models.</title><p>(<bold>a</bold>) Precision-cost models. (<bold>b</bold>) Unpredictability-cost models. <italic>First row</italic>: Bernoulli observers (m = 0). <italic>Second to fourth rows</italic>: Markov observers (m = 1, 2, and 3). <italic>First column (each panel</italic>): difference between the proportion of predictions A in the model subject’s responses, conditional on the two preceding observations being the sequence AA, and the same proportion conditional on the sequence BA. A positive difference indicates an attractive sequential effect of the second-to-last stimulus. <italic>Second column (each panel</italic>): difference between the proportion of predictions A in the model subject’s responses, conditional on the three preceding observations being the sequence AAA, and the same proportion conditional on the sequence BAA. <italic>Third column (each panel</italic>): difference between the proportion of predictions A in the model subject’s responses, conditional on the three preceding observations being the sequence ABA, and the same proportion conditional on the sequence BBA. The precision-cost models of Markov observers are the only models that yield a negative difference, i.e., a repulsive sequential effect of the third-to-last stimulus, in this case.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-fig8-v1.tif"/></fig></sec><sec id="s4-3"><title>Derivation of the approximate posteriors</title><p>We derive the solution to the constrained optimization problem, in the general case of a ‘hybrid’ model subject who bears both a precision cost, with weight <inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, and an unpredictability cost, with weight <inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. Thus the subject minimizes the loss function<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∫</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:mi>q</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mstyle></mml:mstyle></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>∫</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>q</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>∫</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>q</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∫</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>q</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>in which we have included a Lagrange multiplier, μ, corresponding to the normalization constraint, <inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∫</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>. Taking the functional derivative of <inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi></mml:mstyle></mml:math></inline-formula> and setting to zero, we obtain<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and thus we write the approximate posterior as<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is the Bayesian update of the preceding belief, <inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, i.e.,<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Setting the weight of the unpredictability cost to zero (i.e., <inline-formula><mml:math id="inf280"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), we obtain the posterior in presence of the precision cost only, as<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The main text provides more details about the posterior in this case (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), in particular with a Bernoulli observer (<inline-formula><mml:math id="inf281"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>; <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>, <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>).</p><p>For the hybrid model (in which both <inline-formula><mml:math id="inf282"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf283"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> are potentially different from zero), we obtain<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>With <inline-formula><mml:math id="inf284"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, the sum in the exponential is equal to <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>, and the precision-cost posterior, <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is the Bayesian posterior, <inline-formula><mml:math id="inf287"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, and thus we obtain the posterior in presence of the unpredictability cost only (see <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>).</p></sec><sec id="s4-4"><title>Hybrid models</title><p>The hybrid model, described above, features both a precision cost and an unpredictability cost, with respective weights <inline-formula><mml:math id="inf288"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf289"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. As with the models that include only one type of cost, we consider a Bernoulli observer (<inline-formula><mml:math id="inf290"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), and three Markov observers (<inline-formula><mml:math id="inf291"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo></mml:mstyle></mml:math></inline-formula> and 3). As for the response-selection strategy, we use, here also, the generalized probability-matching strategy parameterized by <inline-formula><mml:math id="inf292"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula>. We thus obtain four new models; each one has three parameters (<inline-formula><mml:math id="inf293"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf295"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula>), while the non-hybrid models (featuring only one type of cost) have only two parameters.</p><p>We fit these models to the responses of subjects. For 68% of subjects, the BIC of the best-fitting hybrid model is larger than the BIC of the best-fitting non-hybrid model, indicating a worse fit, by this measure. This suggests that for these subjects, allowing for a second type of cost result in a modest improvement of the fit that does not justify the additional parameter. For the remaining 32% of subjects, the hybrid models yield a better fit (a lower BIC) than the non-hybrid models, although for half of these, the difference in BICs is lower than 6, which is only weak evidence in favor of the hybrid models.</p><p>Moreover, we compute the exceedance probability, defined below in the section ‘Bayesian Model Selection’, of the hybrid models (together with the complementary probability of the non-hybrid models). We find that the exceedance probability of the hybrid models is 8.1% while that of the non-hybrid models is 91.9%, suggesting that subjects best-fitted by non-hybrid models are more prevalent.</p><p>In summary, we find that for more than two thirds of subjects, allowing for a second cost type does not improve much the fit to the behavioral data (the BIC is higher with the best-fitting hybrid model). These subjects are best-fitted by non-hybrid models, that is, by models featuring only one type of cost, instead of ‘falling in between’ the two cost types. This suggests that for most subjects, only one of the two costs, either the prediction cost or the unpredictability cost, dominates the inference process.</p></sec><sec id="s4-5"><title>Alternative response-selection strategy, and repetition or alternation propensity</title><p>In addition to the generalized probability-matching response-selection strategy presented in the main text, in our investigations we also implement several other response-selection strategies. First, a strategy based on a ‘softmax’ function that smoothes the optimal decision rule; it does not yield, however, a behavior substantially different from that of the generalized probability-matching response-selection strategy. Second, we examine a strategy in which the model subject chooses the optimal response with a probability that is fixed across conditions, which we fit onto subjects’ choices. No subject is best-fitted by this strategy. Third, another possible strategy proposed in the game-theory literature (<xref ref-type="bibr" rid="bib80">Nowak and Sigmund, 1993</xref>) is ‘win-stay, lose-shift’: it prescribes to repeat the same response as long as it proves correct and to change otherwise. In the context of our binary-choice prediction task, it is indistinguishable from a strategy in which the model subject chooses a prediction equal to the outcome that last occurred. This strategy is a special case of our Bernoulli observer hampered by a precision cost whose weight <inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> is large combined with the optimal response-selection strategy (<inline-formula><mml:math id="inf297"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula>). Since the generalized probability-matching strategy parameterized by the exponent <inline-formula><mml:math id="inf298"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> appears either more general, better than or indistinguishable from those other response-selection strategies, we selected it to obtain the results presented in the main text.</p><p>Furthermore, we consider the possibility that subjects may have a tendency to repeat their preceding response, or, conversely, to alternate and choose the other response, independently from their inference of the stimulus statistics. Specifically, we examine a generalization of the response-selection strategy, in which a parameter <inline-formula><mml:math id="inf299"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf300"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>η</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, modulates the probability of a repetition or of an alternation. With probability <inline-formula><mml:math id="inf301"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the model subject chooses a response with the generalized probability-matching response-selection strategy, with parameter <inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula>. With probability <inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the model subject repeats the preceding response, if <inline-formula><mml:math id="inf304"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> is positive; or chooses the opposite of the preceding response, if <inline-formula><mml:math id="inf305"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> is negative. With <inline-formula><mml:math id="inf306"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, there is no propensity for repetition nor alternation, and the response-selection strategy is the same as the one we have considered in the main text. We have allowed for alternations (<inline-formula><mml:math id="inf307"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) in this model for the sake of generality, but for all the subjects the best-fitting value of <inline-formula><mml:math id="inf308"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> is non-negative, thus henceforth we only consider the possibility of repetitions, i.e., non-negative values of the parameter (<inline-formula><mml:math id="inf309"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>).</p><p>We note that with a repetition probability <inline-formula><mml:math id="inf310"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, such that <inline-formula><mml:math id="inf311"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>η</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, the unconditional probability of a prediction A, which we denote by <inline-formula><mml:math id="inf312"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is not different from the unconditional probability of a prediction A in the absence of a repetition probability <inline-formula><mml:math id="inf313"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf314"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, as in the event of a repetition, the response that is repeated is itself A with probability <inline-formula><mml:math id="inf315"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>; formally, <inline-formula><mml:math id="inf316"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, which implies the equality <inline-formula><mml:math id="inf317"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>.</p><p>Now turning to sequential effects, we note that with a repetition probability <inline-formula><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, the probability of a prediction <inline-formula><mml:math id="inf319"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> conditional on an observation A is<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In other words, when introducing the repetition probability <inline-formula><mml:math id="inf320"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, the resulting probability of a prediction A conditional on observing A is a weighted mean of the unconditional probability of a prediction A and of the conditional probability of a prediction A in the absence of a repetition probability. <xref ref-type="fig" rid="fig7">Figure 7</xref> (dotted lines) illustrates this for the eight models, with <inline-formula><mml:math id="inf321"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mstyle></mml:math></inline-formula>. Consequently the sequential effects with this response-selection strategy are more modest (<xref ref-type="fig" rid="fig7">Figure 7</xref>, light-red dots).</p><p>We fit (by maximizing their likelihoods) our eight models now equipped with a propensity for repetition (or alternation) parameterized by <inline-formula><mml:math id="inf322"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>. The average best-fitting value of <inline-formula><mml:math id="inf323"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, across subjects, is 0.21 (standard deviation: 0.19; median: 0.18); as mentioned, no subjects have a negative best-fitting value of <inline-formula><mml:math id="inf324"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>. In order to assess the degree to which the models with repetition propensity are able to capture subjects’ data, in comparison with the models without such propensity, we use the Bayesian Information Criterion (BIC) (<xref ref-type="bibr" rid="bib97">Schwarz, 1978</xref>), which penalizes the number of parameters, as a comparative metric (a lower BIC is better). For 26% of subjects, the BIC with this response-selection strategy (allowing for <inline-formula><mml:math id="inf325"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) is higher than with the original response-selection strategy (which sets <inline-formula><mml:math id="inf326"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>,) suggesting that the responses of these subjects do not warrant the introduction of a repetition (or alternation) propensity. In addition, for these subjects the best-fitting inference model, characterized by a cost type and a Markov order, is the same when the response-selection strategy allows for repetition or alternation (<inline-formula><mml:math id="inf327"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) and when it does not (<inline-formula><mml:math id="inf328"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>). For 47% of subjects, the BIC is lower when including the parameter <inline-formula><mml:math id="inf329"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> (suggesting that allowing for <inline-formula><mml:math id="inf330"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> results in a better fit to the data), and importantly, here also the best-fitting inference model (cost type and Markov order) is the same with <inline-formula><mml:math id="inf331"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> and with <inline-formula><mml:math id="inf332"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>. For 11% of subjects, a better fit (lower BIC) is obtained with <inline-formula><mml:math id="inf333"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>; and the best-fitting inference models, with <inline-formula><mml:math id="inf334"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> and with <inline-formula><mml:math id="inf335"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, belong to the same family of models, that is, they have the same cost type (precision cost or unpredictability cost), and only their Markov orders differ. Finally, only for the remaining 16% does the cost type change when allowing for <inline-formula><mml:math id="inf336"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>. In other words, for 84% of subjects the best-fitting cost type is the same whether or not <inline-formula><mml:math id="inf337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> is allowed to differ from 0.</p><p>Furthermore, the best-fitting parameters <inline-formula><mml:math id="inf338"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf339"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> are also stable across these two cases. Among the 73% of subjects whose best-fitting inference model (including both cost type and Markov order) remains the same regardless of the presence of a repetition propensity, we find that the best-fitting values of <inline-formula><mml:math id="inf340"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf341"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> and with <inline-formula><mml:math id="inf342"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, differ by less than 10% for 93% of subjects, and the best-fitting values of <inline-formula><mml:math id="inf343"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> differ by less than 10% for 71% of subjects. For these two parameters, the correlation coefficient (between the best-fitting value with <inline-formula><mml:math id="inf344"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> and the best-fitting value with <inline-formula><mml:math id="inf345"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) is above 0.99 (with p-values lower than 1e-19).</p><p>The responses of a majority of subjects are thus better reproduced by a response-selection strategy that includes a probability of repeating the preceding response. The impact of this repetition propensity on sequential effects is relatively small in comparison to the magnitude of these effects (<xref ref-type="fig" rid="fig7">Figure 7</xref>). For most subjects, moreover, the best-fitting inference model, characterized by its cost type and its Markov order, is the same — with or without repetition propensity —, and the best-fitting parameters <inline-formula><mml:math id="inf346"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf347"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> are very close in the two cases. Therefore, this analysis supports the results of the model-fitting and model-selection procedure, and validates its robustness. We conclude that the models of costly inference are essential in reproducing the behavioral data, notwithstanding a positive repetition propensity in a fraction of subjects.</p></sec><sec id="s4-6"><title>Computation of the models’ likelihoods</title><p>Model fitting is conducted by maximizing for each model the likelihood of the subject’s choices. With the precision-cost models, the likelihood can be derived analytically and thus easily computed: the model’s posterior is a Dirichlet distribution of order <inline-formula><mml:math id="inf348"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mn>2</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, whose parameters are exponentially filtered counts of the observed sequences of length <inline-formula><mml:math id="inf349"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>. With a Bernoulli observer, i.e., <inline-formula><mml:math id="inf350"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, this is the Beta distribution presented in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>. The expected probability of a stimulus A, conditional on the sequence of <inline-formula><mml:math id="inf351"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> stimuli most recently observed, is a simple ratio involving the exponentially filtered counts, for example <inline-formula><mml:math id="inf352"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>+</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>n</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> in the case of a Bernoulli observer. This probability is then raised to the power <inline-formula><mml:math id="inf353"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> and normalized (as prescribed by the generalized probability-matching response-selection strategy) in order to obtain the probability of a prediction A.</p><p>As for the unpredictability-cost models, the posterior is given in <xref ref-type="disp-formula" rid="equ8">Equation 8</xref> up to a normalization constant. Unfortunately, the expected probability of a stimulus A implied by this posterior does not come in a closed-form expression. Thus we compute the (unnormalized) posterior on a discretized grid of values of the vector <inline-formula><mml:math id="inf354"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>. The dimension of the vector <inline-formula><mml:math id="inf355"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> is <inline-formula><mml:math id="inf356"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mn>2</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, and each element of <inline-formula><mml:math id="inf357"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> is in the segment <inline-formula><mml:math id="inf358"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>. If we discretize each dimension into <inline-formula><mml:math id="inf359"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula> bins, we obtain <inline-formula><mml:math id="inf360"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mn>2</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> different possible values of the vector <inline-formula><mml:math id="inf361"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>; for each of these, at each trial, we compute the unnormalized value of the posterior (as given by <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>). As <inline-formula><mml:math id="inf362"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> increases, this becomes computationally prohibitive: for instance, with <inline-formula><mml:math id="inf363"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mstyle></mml:math></inline-formula> bins and <inline-formula><mml:math id="inf364"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>, the multidimensional grid of values of <inline-formula><mml:math id="inf365"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> contains  10<sup>16</sup> numbers (with a typical computer, this would represent 80,000 terabytes). In order to keep the needed computational resources within reasonable limits, we choose a lower resolution of the grid for larger values of <inline-formula><mml:math id="inf366"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>. Specifically, for <inline-formula><mml:math id="inf367"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> we choose a grid (over <inline-formula><mml:math id="inf368"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>) with increments of 0.01; for <inline-formula><mml:math id="inf369"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, increments of 0.02 (in each dimension); for <inline-formula><mml:math id="inf370"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>, increments of 0.05; and for <inline-formula><mml:math id="inf371"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>, increments of 0.1. We then compute the mean of the discretized posterior and pass it through the generalized probability-matching response-selection model to obtain the choice probability.</p><p>To find the best-fitting parameters <inline-formula><mml:math id="inf372"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf373"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula>, the likelihood was maximized with the L-BFGS-B algorithm (<xref ref-type="bibr" rid="bib19">Byrd et al., 1995</xref>; <xref ref-type="bibr" rid="bib123">Zhu et al., 1997</xref>). These computations were run using Python and the libraries Numpy and Scipy (<xref ref-type="bibr" rid="bib52">Harris et al., 2020</xref>; <xref ref-type="bibr" rid="bib113">Virtanen et al., 2020</xref>).</p></sec><sec id="s4-7"><title>Symmetries and relations between conditional probabilities</title><p>Throughout the paper, we leverage the symmetry inherent to the Bernoulli prediction task to present results in a condensed manner. Specifically, in our analysis, the proportion of predictions A when the probability of A (the stimulus generative probability) is <inline-formula><mml:math id="inf374"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, which we denote here by <inline-formula><mml:math id="inf375"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is equal to the proportion of predictions B when the probability of A is <inline-formula><mml:math id="inf376"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, which we denote by <inline-formula><mml:math id="inf377"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>; i.e., <inline-formula><mml:math id="inf378"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. More generally, the predictions conditional on a given sequence when the probability of A is <inline-formula><mml:math id="inf379"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> are equal to the predictions conditional on the ‘mirror’ sequence (in which A and B have been swapped), when the probability of A is <inline-formula><mml:math id="inf380"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, for example extending our notation, <inline-formula><mml:math id="inf381"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. Here, we show how this results in the symmetries in <xref ref-type="fig" rid="fig2">Figure 2</xref>, and in the fact that in <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref>, it suffices to plot the sequential effects obtained with only a fraction of all the possible sequences of two or three stimuli.</p><p>First, we note that<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>which implies the symmetry of <inline-formula><mml:math id="inf382"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> in <xref ref-type="fig" rid="fig2">Figure 2a</xref> (grey line). Turning to conditional probabilities (and thus sequential effects), we have<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>and </mml:mtext><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>As a result, the lines representing <inline-formula><mml:math id="inf383"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (blue) and <inline-formula><mml:math id="inf384"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (orange) in <xref ref-type="fig" rid="fig2">Figure 2a</xref> are reflections of each other. In addition, these equations result in the equality<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>which implies the symmetry in <xref ref-type="fig" rid="fig2">Figure 2b</xref>.</p><p>As for the sequential effect of the second-to-last stimulus, we show in <xref ref-type="fig" rid="fig5">Figures 5a</xref> and <xref ref-type="fig" rid="fig6">6a</xref> the difference in the proportions of predictions A conditional on two past sequences of two stimuli, AA and BA; i.e., <inline-formula><mml:math id="inf385"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. There are two other possible sequences of two stimuli: <inline-formula><mml:math id="inf386"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf387"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula>. The difference in the proportions conditional on these two sequences is implied by the former difference, as:<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>As for the sequential effect of the third-to-last stimulus, we show in <xref ref-type="fig" rid="fig5">Figures 5b</xref> and <xref ref-type="fig" rid="fig6">6b</xref> the difference in the proportions conditional on the sequences AAA and BAA, and in <xref ref-type="fig" rid="fig5">Figures 5c</xref> and <xref ref-type="fig" rid="fig6">6c</xref> the difference in the proportions conditional on the sequences ABA and BBA. The differences in the proportions conditional on the sequences AAB and BAB, and conditional on the sequences ABB and BBB, are recovered as a function of the former two, as<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>and </mml:mtext><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-8"><title>Bayesian model selection</title><p>We implement the Bayesian model selection (BMS) procedure described in <xref ref-type="bibr" rid="bib107">Stephan et al., 2009</xref>. Given <inline-formula><mml:math id="inf388"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> models, this procedure aims at deriving a probabilistic belief on the distribution of these models among the general population. This unknown distribution is a categorical distribution, parameterized by the probabilities of the <inline-formula><mml:math id="inf389"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> models, denoted by <inline-formula><mml:math id="inf390"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf391"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∑</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>. With a finite sample of data, one cannot determine with infinite precision the values of the probabilities <inline-formula><mml:math id="inf392"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. The BMS, thus, computes an approximation of the Bayesian posterior over the vector <inline-formula><mml:math id="inf393"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi></mml:mstyle></mml:math></inline-formula>, as a Dirichlet distribution parameterized by the vector <inline-formula><mml:math id="inf394"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, i.e., the posterior distribution<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∏</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msubsup><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Computing the parameters <inline-formula><mml:math id="inf395"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> of this posterior makes use of the log-evidence of each model for each subject, i.e., the logarithm of the joint probability, <inline-formula><mml:math id="inf396"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, of a given subject’s responses, <inline-formula><mml:math id="inf397"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>, under the assumption that a given model, <inline-formula><mml:math id="inf398"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>, generated the responses. We use the model’s maximum likelihood to obtain an approximation of the model’s log-evidence, as (<xref ref-type="bibr" rid="bib8">Balasubramanian, 1997</xref>)<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≃</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>θ</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">[</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf399"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> denotes the parameters of the model, <inline-formula><mml:math id="inf400"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is the likelihood of the model when parameterized with <inline-formula><mml:math id="inf401"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf402"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula> is the dimension of <inline-formula><mml:math id="inf403"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf404"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> is the size of the data, that is, the number of responses. (The well-known Bayesian Information Criterion <xref ref-type="bibr" rid="bib97">Schwarz, 1978</xref> is equal to this approximation of the model’s log-evidence, multiplied by <inline-formula><mml:math id="inf405"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>.)</p><p>In our case, there are <inline-formula><mml:math id="inf406"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> models, each with <inline-formula><mml:math id="inf407"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> parameters: <inline-formula><mml:math id="inf408"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The posterior distribution over the parameters of the categorical distribution of models in the general population, <inline-formula><mml:math id="inf409"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, allows for the derivation of several quantities of interest; following <xref ref-type="bibr" rid="bib107">Stephan et al., 2009</xref>, we derive two types of quantities. First, given a family of models, that is, a set <inline-formula><mml:math id="inf410"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">M</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> of different models (for instance, the prediction-cost models, or the Bernoulli-observer models), the expected probability of this class of model, that is, the expected probability that the behavior of a subject randomly chosen in the general population follows a model belonging to this class, is the ratio<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">M</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>We compute the expected probability of the precision-cost models (and the complementary probability of the unpredictability-cost models), and the expected probability of the Bernoulli-observer models (and the complementary probability of the Markov-observer models; see Results).</p><p>Second, we estimate, for each family of models <inline-formula><mml:math id="inf411"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, the probability that it is the most likely, i.e., the probability of the inequality<disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi mathvariant="script">M</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>which is called the ‘exceedance probability’. We compute an estimate of this probability by sampling one million times the Dirichlet belief distribution (<xref ref-type="disp-formula" rid="equ21">Equation 21</xref>), and counting the number of samples in which the inequality is verified. We estimate in this way the exceedance probability of the precision-cost models (and the complementary probability of the unpredictability-cost models), and the exceedance probability of the Bernoulli-observer models (and the complementary probability of the Markov-observer models; see Results).</p></sec><sec id="s4-9"><title>Unpredictability cost for Markov observers</title><p>Here we derive the expression of the unpredictability cost for Markov observers as a function of the elements of the parameter vector <inline-formula><mml:math id="inf412"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>. For an observer of Markov order 1 (<inline-formula><mml:math id="inf413"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>), the vector <inline-formula><mml:math id="inf414"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> has two elements, which are the probability of observing A at a given trial conditional on the preceding outcome being A, and the probability of observing A at a given trial conditional on the preceding outcome being B, which we denote by <inline-formula><mml:math id="inf415"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf416"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula>, respectively. The Shannon entropy, <inline-formula><mml:math id="inf417"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, implied by the vector <inline-formula><mml:math id="inf418"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>, is the average of the conditional entropies implied by each conditional probability, i.e.,<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf419"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf420"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> are the <italic>unconditional</italic> probabilities of observing A and B, respectively (see below), and<disp-formula id="equ26"><label>(26)</label><mml:math id="m26"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf421"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>X</mml:mi></mml:mstyle></mml:math></inline-formula> is A or B.</p><p>The unconditional probabilities <inline-formula><mml:math id="inf422"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf423"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> are functions of the conditional probabilities <inline-formula><mml:math id="inf424"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf425"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula>. Indeed, at trial <inline-formula><mml:math id="inf426"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, the marginal probability of the event <inline-formula><mml:math id="inf427"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf428"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is a weighted average of the probabilities of this event conditional on the preceding stimulus, <inline-formula><mml:math id="inf429"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, as given by the law of total probability:<disp-formula id="equ27"><label>(27)</label><mml:math id="m27"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>i.e.<disp-formula id="equ28"><label>(28)</label><mml:math id="m28"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo>=</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo>+</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Solving for <inline-formula><mml:math id="inf430"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we find:<disp-formula id="equ29"><label>(29)</label><mml:math id="m29"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow/></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext> and </mml:mtext><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow/><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow/></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The entropy <inline-formula><mml:math id="inf431"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> implied by the vector <inline-formula><mml:math id="inf432"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> is obtained by substituting these quantities in <xref ref-type="disp-formula" rid="equ25">Equation 25</xref>.</p><p>Similarly, for <inline-formula><mml:math id="inf433"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> and 3, the <inline-formula><mml:math id="inf434"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mn>2</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> elements of the vector <inline-formula><mml:math id="inf435"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> are the parameters <inline-formula><mml:math id="inf436"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf437"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, respectively, where <inline-formula><mml:math id="inf438"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, and where <inline-formula><mml:math id="inf439"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the probability of observing A at a given trial conditional on the two preceding outcomes being the sequence ‘<inline-formula><mml:math id="inf440"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula>’, and <inline-formula><mml:math id="inf441"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the probability of observing A at a given trial conditional on the three preceding outcomes being the sequence ‘<inline-formula><mml:math id="inf442"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula>’. The Shannon entropy, <inline-formula><mml:math id="inf443"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, implied by the vector <inline-formula><mml:math id="inf444"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>, is here also the average of the conditional entropies implied by each conditional probability, as<disp-formula id="equ30"><label>(30)</label><mml:math id="m30"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mtext> for </mml:mtext><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ31"><label>(31)</label><mml:math id="m31"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mtext> and </mml:mtext></mml:mtd><mml:mtd><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mtext> for </mml:mtext><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf445"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf446"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> are the unconditional probabilities of observing the sequence ‘<inline-formula><mml:math id="inf447"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula>’, and of observing the sequence ‘<inline-formula><mml:math id="inf448"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula>’, respectively. These unconditional probabilities verify a system of linear equations whose coefficients are given by the conditional probabilities. For instance, for <inline-formula><mml:math id="inf449"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>, we have the relation<disp-formula id="equ32"><label>(32)</label><mml:math id="m32"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:mrow/><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow/><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>i.e.,<disp-formula id="equ33"><label>(33)</label><mml:math id="m33"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The system of linear equations can be written as<disp-formula id="equ34"><label>(34)</label><mml:math id="m34"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>A</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mrow/><mml:mi>B</mml:mi><mml:mrow/></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The solution is the eigenvector corresponding to the eigenvalue equal to 1 of the matrix in the equation above, with the additional constraint that the unconditional probabilities must sum to 1, i.e., <inline-formula><mml:math id="inf450"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>. We find:<disp-formula id="equ35"> <mml:math id="m35"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ36"><mml:math id="m36"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ37"><mml:math id="m37"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ38"><mml:math id="m38"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For <inline-formula><mml:math id="inf451"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>, we find the relations:<disp-formula id="equ39"><mml:math id="m39"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ40"><mml:math id="m40"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ41"><mml:math id="m41"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ42"><mml:math id="m42"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ43"><mml:math id="m43"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ44"><mml:math id="m44"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ45"><mml:math id="m45"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Together with the normalization constraint <inline-formula><mml:math id="inf452"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, these relations allow determining the eight unconditional probabilities <inline-formula><mml:math id="inf453"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, and thus the expression of the Shannon entropy.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Visualization, Methodology, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>The study was approved by the ethics committee Île de France VII (CPP 08-021). Participants gave their written consent prior to participating.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-81256-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The behavioral data for this study and the computer code used for data analysis are freely and publicly available through the Open Science Framework repository at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/BS5CY">https://doi.org/10.17605/OSF.IO/BS5CY</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Prat-Carrabin</surname><given-names>A</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Resource-Rational Account of Sequential Effects in Human Prediction: Data &amp; Code</data-title><source>Open Science Framework</source><pub-id pub-id-type="doi">10.17605/OSF.IO/BS5CY</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Doron Cohen and Michael Woodford for inspiring discussions. This work was supported by the Alfred P Sloan Foundation through grant G-2020–12680 and the CNRS through UMR8023. A.P.C. was supported by a Ph.D. fellowship of the Fondation Pierre-Gilles de Gennes pour la Recherche. We acknowledge computing resources from Columbia University’s Shared Research Computing Facility project, which is supported by NIH Research Facility Improvement Grant 1G20RR030893-01, and associated funds from the New York State Empire State Development, Division of Science Technology and Innovation (NYSTAR) Contract C090171, both awarded April 15, 2010.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acerbi</surname><given-names>L</given-names></name><name><surname>Vijayakumar</surname><given-names>S</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>On the origins of suboptimality in human probabilistic inference</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003661</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003661</pub-id><pub-id pub-id-type="pmid">24945142</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alink</surname><given-names>A</given-names></name><name><surname>Schwiedrzik</surname><given-names>CM</given-names></name><name><surname>Kohler</surname><given-names>A</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Muckli</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus predictability reduces responses in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>2960</fpage><lpage>2966</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3730-10.2010</pub-id><pub-id pub-id-type="pmid">20181593</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Aridor</surname><given-names>G</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Information-Constrained Coordination of Economic Behavior</article-title><source>Hal.Science</source><ext-link ext-link-type="uri" xlink:href="https://hal.science/hal-04305663">https://hal.science/hal-04305663</ext-link></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attneave</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1954">1954</year><article-title>Some informational aspects of visual perception</article-title><source>Psychological Review</source><volume>61</volume><fpage>183</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1037/h0054663</pub-id><pub-id pub-id-type="pmid">13167245</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayton</surname><given-names>P</given-names></name><name><surname>Fischer</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The hot hand fallacy and the gambler’s fallacy: two faces of subjective randomness?</article-title><source>Memory &amp; Cognition</source><volume>32</volume><fpage>1369</fpage><lpage>1378</lpage><pub-id pub-id-type="doi">10.3758/bf03206327</pub-id><pub-id pub-id-type="pmid">15900930</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Noisy memory and over-reaction to news</article-title><source>AEA Papers and Proceedings</source><volume>109</volume><fpage>557</fpage><lpage>561</lpage><pub-id pub-id-type="doi">10.1257/pandp.20191049</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name><name><surname>Sung</surname><given-names>Y</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><source>Optimally Imprecise Memory and Biased Forecasts</source><publisher-name>National Bureau of Economic Research</publisher-name><pub-id pub-id-type="doi">10.2139/ssrn.3731244</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Statistical inference, occam’s razor, and statistical mechanics</article-title><source>Neural Computation</source><volume>368</volume><fpage>349</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.2.349</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bar-Eli</surname><given-names>M</given-names></name><name><surname>Avugos</surname><given-names>S</given-names></name><name><surname>Raab</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Twenty years of “hot hand” research: Review and critique</article-title><source>Psychology of Sport and Exercise</source><volume>7</volume><fpage>525</fpage><lpage>553</lpage><pub-id pub-id-type="doi">10.1016/j.psychsport.2006.03.001</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><year iso-8601-date="1961">1961</year><chapter-title>Possible principles underlying the transformations of sensory messages</chapter-title><person-group person-group-type="editor"><name><surname>Rosenblith</surname><given-names>Walter A</given-names></name></person-group><source>Sensory Communication, Chapter 13</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>The MIT Press</publisher-name><fpage>217</fpage><lpage>234</lpage></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battaglia</surname><given-names>PW</given-names></name><name><surname>Kersten</surname><given-names>D</given-names></name><name><surname>Schrater</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How haptic size sensations improve distance perception</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1002080</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002080</pub-id><pub-id pub-id-type="pmid">21738457</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battaglia</surname><given-names>PW</given-names></name><name><surname>Hamrick</surname><given-names>JB</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Simulation as an engine of physical scene understanding</article-title><source>PNAS</source><volume>110</volume><fpage>18327</fpage><lpage>18332</lpage><pub-id pub-id-type="doi">10.1073/pnas.1306572110</pub-id><pub-id pub-id-type="pmid">24145417</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Benjamin</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><chapter-title>Errors in probabilistic reasoning and judgment biases</chapter-title><person-group person-group-type="editor"><name><surname>Benjamin</surname><given-names>DJ</given-names></name></person-group><source>Handbook of Behavioral Economics</source><publisher-name>Elsevier B.V</publisher-name><fpage>69</fpage><lpage>186</lpage></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bertelson</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Serial choice reaction-time as a function of response versus signal-and-response repetition</article-title><source>Nature</source><volume>206</volume><fpage>217</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1038/206217a0</pub-id><pub-id pub-id-type="pmid">5830165</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern Recognition and Machine Learning</source><publisher-name>Springer New York, NY</publisher-name></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name><name><surname>Moehlis</surname><given-names>J</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burns</surname><given-names>BD</given-names></name><name><surname>Corpus</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Randomness and inductions from streaks: “gambler’s fallacy” versus “hot hand.”</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>11</volume><fpage>179</fpage><lpage>184</lpage><pub-id pub-id-type="doi">10.3758/bf03206480</pub-id><pub-id pub-id-type="pmid">15117006</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Byrd</surname><given-names>RH</given-names></name><name><surname>Lu</surname><given-names>P</given-names></name><name><surname>Nocedal</surname><given-names>J</given-names></name><name><surname>Zhu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>A limited memory algorithm for bound constrained optimization</article-title><source>SIAM Journal on Scientific Computing</source><volume>16</volume><fpage>1190</fpage><lpage>1208</lpage><pub-id pub-id-type="doi">10.1137/0916069</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caplin</surname><given-names>A</given-names></name><name><surname>Dean</surname><given-names>M</given-names></name><name><surname>Leahy</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Rational inattention, optimal consideration sets, and stochastic choice</article-title><source>The Review of Economic Studies</source><volume>86</volume><fpage>1061</fpage><lpage>1094</lpage><pub-id pub-id-type="doi">10.1093/restud/rdy037</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chekaf</surname><given-names>M</given-names></name><name><surname>Cowan</surname><given-names>N</given-names></name><name><surname>Mathy</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Chunk formation in immediate memory and how it relates to data compression</article-title><source>Cognition</source><volume>155</volume><fpage>96</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2016.05.024</pub-id><pub-id pub-id-type="pmid">27367593</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>RY</given-names></name><name><surname>Nystrom</surname><given-names>LE</given-names></name><name><surname>Brown</surname><given-names>ET</given-names></name><name><surname>Jones</surname><given-names>AD</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Holmes</surname><given-names>PJ</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Mechanisms underlying dependencies of performance on stimulus history in a two-alternative forced-choice task</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>2</volume><fpage>283</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.3758/cabn.2.4.283</pub-id><pub-id pub-id-type="pmid">12641174</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chopin</surname><given-names>A</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Predictive properties of visual adaptation</article-title><source>Current Biology</source><volume>22</volume><fpage>622</fpage><lpage>626</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.02.021</pub-id><pub-id pub-id-type="pmid">22386314</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>DJ</given-names></name><name><surname>Shanks</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Momentary and integrative response strategies in causal judgment</article-title><source>Memory &amp; Cognition</source><volume>30</volume><fpage>1138</fpage><lpage>1147</lpage><pub-id pub-id-type="doi">10.3758/bf03194331</pub-id><pub-id pub-id-type="pmid">12507378</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>EP</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dynamics of neuronal responses in macaque MT and VIP during motion detection</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>985</fpage><lpage>994</lpage><pub-id pub-id-type="doi">10.1038/nn924</pub-id><pub-id pub-id-type="pmid">12244324</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Croson</surname><given-names>R</given-names></name><name><surname>Sundali</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The Gambler’s fallacy and the hot hand: empirical data from casinos</article-title><source>Journal of Risk and Uncertainty</source><volume>30</volume><fpage>195</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1007/s11166-005-1153-2</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dasgupta</surname><given-names>I</given-names></name><name><surname>Schulz</surname><given-names>E</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A theory of learning to infer</article-title><source>Psychological Review</source><volume>127</volume><fpage>412</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1037/rev0000178</pub-id><pub-id pub-id-type="pmid">32223286</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neural representation of sequences: from transition probabilities to algebraic patterns and linguistic trees</article-title><source>Neuron</source><volume>88</volume><fpage>2</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.019</pub-id><pub-id pub-id-type="pmid">26447569</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Efficient computation and cue integration with noisy population codes</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>826</fpage><lpage>831</lpage><pub-id pub-id-type="doi">10.1038/90541</pub-id><pub-id pub-id-type="pmid">11477429</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>den Ouden</surname><given-names>HEM</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>McIntosh</surname><given-names>AR</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A dual role for prediction error in associative learning</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>1175</fpage><lpage>1185</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn161</pub-id><pub-id pub-id-type="pmid">18820290</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ebbinghaus</surname><given-names>H</given-names></name><name><surname>Ruger</surname><given-names>HA</given-names></name><name><surname>Bussenius</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="1913">1913</year><source>Memory: A Contribution to Experimental Psychology</source><publisher-name>Teachers College Press</publisher-name><pub-id pub-id-type="doi">10.1037/10011-000</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Echeveste</surname><given-names>R</given-names></name><name><surname>Aitchison</surname><given-names>L</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cortical-like dynamics in recurrent circuits optimized for sampling-based probabilistic inference</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1138</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0671-1</pub-id><pub-id pub-id-type="pmid">32778794</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1956">1956</year><article-title>Reward probability, amount, and information as determiners of sequential two-alternative decisions</article-title><source>Journal of Experimental Psychology</source><volume>52</volume><fpage>177</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1037/h0047727</pub-id><pub-id pub-id-type="pmid">13357700</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1961">1961</year><article-title>Probability learning in 1000 trials</article-title><source>Journal of Experimental Psychology</source><volume>62</volume><fpage>385</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1037/h0041970</pub-id><pub-id pub-id-type="pmid">13889318</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Findling</surname><given-names>C</given-names></name><name><surname>Skvortsova</surname><given-names>V</given-names></name><name><surname>Dromnelle</surname><given-names>R</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational noise in reward-guided learning drives behavioral variability in volatile environments</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>2066</fpage><lpage>2077</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0518-9</pub-id><pub-id pub-id-type="pmid">31659343</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Findling</surname><given-names>C</given-names></name><name><surname>Chopin</surname><given-names>N</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Imprecise neural computations as a source of adaptive behaviour in volatile environments</article-title><source>Nature Human Behaviour</source><volume>5</volume><fpage>99</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1038/s41562-020-00971-z</pub-id><pub-id pub-id-type="pmid">33168951</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Kilner</surname><given-names>J</given-names></name><name><surname>Harrison</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A free energy principle for the brain</article-title><source>Journal of Physiology, Paris</source><volume>100</volume><fpage>70</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2006.10.001</pub-id><pub-id pub-id-type="pmid">17097864</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The free-energy principle: a rough guide to the brain?</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>293</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.04.005</pub-id><pub-id pub-id-type="pmid">19559644</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Gabaix</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>Behavioral Inattention</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>National Bureau of Economic Research</publisher-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaissmaier</surname><given-names>W</given-names></name><name><surname>Schooler</surname><given-names>LJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The smart potential behind probability matching</article-title><source>Cognition</source><volume>109</volume><fpage>416</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2008.09.007</pub-id><pub-id pub-id-type="pmid">19019351</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname><given-names>CR</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Bringing Bayes and Shannon to the study of behavioural and neurobiological timing and associative learning</article-title><source>Timing &amp; Time Perception</source><volume>11</volume><fpage>29</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1163/22134468-bja10069</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganguli</surname><given-names>D</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Efficient sensory encoding and bayesian inference with heterogeneous neural populations</article-title><source>Neural Computation</source><volume>26</volume><fpage>2103</fpage><lpage>2134</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00638</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ganguli</surname><given-names>D</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural and perceptual signatures of efficient sensory coding</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1603.00058">https://arxiv.org/abs/1603.00058</ext-link></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>Tortell</surname><given-names>R</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Dynamic integration of reward and stimulus information in perceptual decision-making</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e16749</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0016749</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gigerenzer</surname><given-names>G</given-names></name><name><surname>Goldstein</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Reasoning the fast and frugal way: Models of bounded rationality</article-title><source>Psychological Review</source><volume>103</volume><fpage>650</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.103.4.650</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gigerenzer</surname><given-names>G</given-names></name><name><surname>Selten</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2002">2002</year><chapter-title>Bounded rationality</chapter-title><person-group person-group-type="editor"><name><surname>Gigerenzer</surname><given-names>G</given-names></name><name><surname>Selten</surname><given-names>R</given-names></name></person-group><source>Bounded Rationality: The Adaptive Toolbox</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/1654.001.0001</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilovich</surname><given-names>T</given-names></name><name><surname>Vallone</surname><given-names>R</given-names></name><name><surname>Tversky</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The hot hand in basketball: On the misperception of random sequences</article-title><source>Cognitive Psychology</source><volume>17</volume><fpage>295</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(85)90010-6</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gökaydin</surname><given-names>D</given-names></name><name><surname>Ejova</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sequential effects in prediction</article-title><conf-name>Proceedings of the Annual Conference of the Cognitive Science Society</conf-name><fpage>397</fpage><lpage>402</lpage></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graeber</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Inattentive inference</article-title><source>SSRN Electronic Journal</source><volume>1</volume><elocation-id>3658112</elocation-id><pub-id pub-id-type="doi">10.2139/ssrn.3658112</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grether</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Bayes rule as a descriptive model: the representativeness heuristic</article-title><source>The Quarterly Journal of Economics</source><volume>95</volume><elocation-id>537</elocation-id><pub-id pub-id-type="doi">10.2307/1885092</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Goodman</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rational use of cognitive resources: levels of analysis between the computational and the algorithmic</article-title><source>Topics in Cognitive Science</source><volume>7</volume><fpage>217</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1111/tops.12142</pub-id><pub-id pub-id-type="pmid">25898807</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Wieser</surname><given-names>E</given-names></name><name><surname>Taylor</surname><given-names>J</given-names></name><name><surname>Berg</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>NJ</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Picus</surname><given-names>M</given-names></name><name><surname>Hoyer</surname><given-names>S</given-names></name><name><surname>van Kerkwijk</surname><given-names>MH</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Haldane</surname><given-names>A</given-names></name><name><surname>Del Río</surname><given-names>JF</given-names></name><name><surname>Wiebe</surname><given-names>M</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Gérard-Marchant</surname><given-names>P</given-names></name><name><surname>Sheppard</surname><given-names>K</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Abbasi</surname><given-names>H</given-names></name><name><surname>Gohlke</surname><given-names>C</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Array programming with NumPy</article-title><source>Nature</source><volume>585</volume><fpage>357</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id><pub-id pub-id-type="pmid">32939066</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrnstein</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1961">1961</year><article-title>Relative and absolute strength of response as a function of frequency of reinforcement</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>4</volume><fpage>267</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1901/jeab.1961.4-267</pub-id><pub-id pub-id-type="pmid">13713775</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herry</surname><given-names>C</given-names></name><name><surname>Bach</surname><given-names>DR</given-names></name><name><surname>Esposito</surname><given-names>F</given-names></name><name><surname>Di Salle</surname><given-names>F</given-names></name><name><surname>Perrig</surname><given-names>WJ</given-names></name><name><surname>Scheffler</surname><given-names>K</given-names></name><name><surname>Lüthi</surname><given-names>A</given-names></name><name><surname>Seifritz</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Processing of temporal unpredictability in human and animal amygdala</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>5958</fpage><lpage>5966</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5218-06.2007</pub-id><pub-id pub-id-type="pmid">17537966</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hick</surname><given-names>WE</given-names></name></person-group><year iso-8601-date="1952">1952</year><article-title>On the rate of gain of information</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>4</volume><fpage>11</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1080/17470215208416600</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hogarth</surname><given-names>RM</given-names></name><name><surname>Einhorn</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Order effects in belief updating: The belief-adjustment model</article-title><source>Cognitive Psychology</source><volume>24</volume><fpage>1</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(92)90002-J</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Kayaba</surname><given-names>Y</given-names></name><name><surname>Shum</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Nonparametric learning rules from bandit experiments: The eyes have it!</article-title><source>Games and Economic Behavior</source><volume>81</volume><fpage>215</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1016/j.geb.2013.05.003</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyman</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1953">1953</year><article-title>Stimulus information as a determinant of reaction time</article-title><source>Journal of Experimental Psychology</source><volume>45</volume><fpage>188</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1037/h0056940</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Icard</surname><given-names>TF</given-names></name><name><surname>Goodman</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Resource-Rational Approach to the Causal Frame Problem</article-title><conf-name>Proceedings of the 37th Annual Meeting of the Cognitive Science Society</conf-name></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarvik</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1951">1951</year><article-title>Probability learning and a negative recency effect in the serial anticipation of alternative symbols</article-title><source>Journal of Experimental Psychology</source><volume>41</volume><fpage>291</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.1037/h0056878</pub-id><pub-id pub-id-type="pmid">14850645</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>M</given-names></name><name><surname>Curran</surname><given-names>T</given-names></name><name><surname>Mozer</surname><given-names>MC</given-names></name><name><surname>Wilder</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Sequential effects in response time reveal learning mechanisms and event representations</article-title><source>Psychological Review</source><volume>120</volume><fpage>628</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1037/a0033180</pub-id><pub-id pub-id-type="pmid">23915086</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name><name><surname>Slovic</surname><given-names>P</given-names></name><name><surname>Tversky</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1982">1982</year><source>The Simulation Heuristic</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511809477</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bounded integration in parietal cortex underlies decisions even when viewing duration is dictated by the environment</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>3017</fpage><lpage>3029</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4761-07.2008</pub-id><pub-id pub-id-type="pmid">18354005</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kominers</surname><given-names>SD</given-names></name><name><surname>Mu</surname><given-names>X</given-names></name><name><surname>Peysakhovich</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Paying (for) attention: the impact of information processing costs on bayesian inference</article-title><source>SSRN Electronic Journal</source><volume>1</volume><pub-id pub-id-type="doi">10.2139/ssrn.2857978</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kornblum</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Choice reaction time for repetitions and non-repetitions: a re-examination of the information hypothesis</article-title><source>Acta Psychologica</source><volume>27</volume><fpage>178</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/0001-6918(67)90058-3</pub-id><pub-id pub-id-type="pmid">6062209</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laughlin</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>A simple coding procedure enhances a neuron’s information capacity</article-title><source>Zeitschrift Für Naturforschung C</source><volume>36</volume><fpage>910</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1515/znc-1981-9-1040</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laughlin</surname><given-names>SB</given-names></name><name><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name><name><surname>Anderson</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The metabolic cost of neural information</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>36</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1038/236</pub-id><pub-id pub-id-type="pmid">10195106</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources</article-title><source>The Behavioral and Brain Sciences</source><volume>43</volume><elocation-id>e1</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X1900061X</pub-id><pub-id pub-id-type="pmid">30714890</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id><pub-id pub-id-type="pmid">17057707</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spiking networks for Bayesian inference and choice</article-title><source>Current Opinion in Neurobiology</source><volume>18</volume><fpage>217</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2008.07.004</pub-id><pub-id pub-id-type="pmid">18678253</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumori</surname><given-names>K</given-names></name><name><surname>Koike</surname><given-names>Y</given-names></name><name><surname>Matsumoto</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A biased bayesian inference for decision-making and cognitive control</article-title><source>Frontiers in Neuroscience</source><volume>12</volume><elocation-id>734</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2018.00734</pub-id><pub-id pub-id-type="pmid">30369867</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matthews</surname><given-names>L</given-names></name><name><surname>Sanders</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Effects of causal and noncausal sequences of information on subjective prediction</article-title><source>Psychological Reports</source><volume>54</volume><fpage>211</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.2466/pr0.1984.54.1.211</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>GH</given-names></name><name><surname>Hackenberg</surname><given-names>BH</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Subjective probabilities for sex of next child: U.S. College students and Philippine villagers</article-title><source>Journal of Population Behavioral, Social, and Environmental Issues</source><volume>1</volume><fpage>132</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1007/BF01277598</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>T</given-names></name><name><surname>Olson</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Statistical learning of visual transitions in monkey inferotemporal cortex</article-title><source>PNAS</source><volume>108</volume><fpage>19401</fpage><lpage>19406</lpage><pub-id pub-id-type="doi">10.1073/pnas.1112895108</pub-id><pub-id pub-id-type="pmid">22084090</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Human inferences about sequences: a minimal transition probability model</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005260</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005260</pub-id><pub-id pub-id-type="pmid">28030543</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Brain networks for confidence weighting and hierarchical inference during probabilistic learning</article-title><source>PNAS</source><volume>114</volume><fpage>E3859</fpage><lpage>E3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.1615773114</pub-id><pub-id pub-id-type="pmid">28439014</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Moustafa</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>Computational Models of Brain and Behavior</source><publisher-name>Wiley</publisher-name><pub-id pub-id-type="doi">10.1002/9781119159193</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id><pub-id pub-id-type="pmid">20844132</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navarro</surname><given-names>DJ</given-names></name><name><surname>Newell</surname><given-names>BR</given-names></name><name><surname>Schulze</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning and choosing in an uncertain world: An investigation of the explore–exploit dilemma in static and dynamic environments</article-title><source>Cognitive Psychology</source><volume>85</volume><fpage>43</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2016.01.001</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nowak</surname><given-names>M</given-names></name><name><surname>Sigmund</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>A strategy of win-stay, lose-shift that outperforms tit-for-tat in the Prisoner’s Dilemma game</article-title><source>Nature</source><volume>364</volume><fpage>56</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1038/364056a0</pub-id><pub-id pub-id-type="pmid">8316296</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogawa</surname><given-names>H</given-names></name><name><surname>Watanabe</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Implicit learning increases preference for predictive visual display</article-title><source>Attention, Perception &amp; Psychophysics</source><volume>73</volume><fpage>1815</fpage><lpage>1822</lpage><pub-id pub-id-type="doi">10.3758/s13414-010-0041-2</pub-id><pub-id pub-id-type="pmid">21594733</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oskarsson</surname><given-names>AT</given-names></name><name><surname>Van Boven</surname><given-names>L</given-names></name><name><surname>McClelland</surname><given-names>GH</given-names></name><name><surname>Hastie</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>What’s next? Judging sequences of binary events</article-title><source>Psychological Bulletin</source><volume>135</volume><fpage>262</fpage><lpage>285</lpage><pub-id pub-id-type="doi">10.1037/a0014821</pub-id><pub-id pub-id-type="pmid">19254080</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ossmy</surname><given-names>O</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Pfeffer</surname><given-names>T</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The timescale of perceptual evidence integration can be adapted to the environment</article-title><source>Current Biology</source><volume>23</volume><fpage>981</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.04.039</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payzan-LeNestour</surname><given-names>E</given-names></name><name><surname>Dunne</surname><given-names>S</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The neural representation of unexpected uncertainty during value-based decision making</article-title><source>Neuron</source><volume>79</volume><fpage>191</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.04.037</pub-id><pub-id pub-id-type="pmid">23849203</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Generating stimuli for neuroscience using psychoPy</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.010.2008</pub-id><pub-id pub-id-type="pmid">19198666</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Planton</surname><given-names>S</given-names></name><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Abbih</surname><given-names>L</given-names></name><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Figueira</surname><given-names>S</given-names></name><name><surname>Romano</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A theory of memory for binary sequences: Evidence for A mental compression algorithm in humans</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008598</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008598</pub-id><pub-id pub-id-type="pmid">33465081</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plonsky</surname><given-names>O</given-names></name><name><surname>Teodorescu</surname><given-names>K</given-names></name><name><surname>Erev</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reliance on small samples, the wavy recency effect, and similarity-based learning</article-title><source>Psychological Review</source><volume>122</volume><fpage>621</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1037/a0039413</pub-id><pub-id pub-id-type="pmid">26075914</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plonsky</surname><given-names>O</given-names></name><name><surname>Erev</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Learning in settings with partial feedback and the wavy recency effect of rare events</article-title><source>Cognitive Psychology</source><volume>93</volume><fpage>18</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2017.01.002</pub-id><pub-id pub-id-type="pmid">28160610</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prat-Carrabin</surname><given-names>A</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Biases and variability from costly Bayesian inference</article-title><source>Entropy</source><volume>23</volume><elocation-id>603</elocation-id><pub-id pub-id-type="doi">10.3390/e23050603</pub-id><pub-id pub-id-type="pmid">34068364</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prat-Carrabin</surname><given-names>A</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Human inference in changing environments with temporal structure</article-title><source>Psychological Review</source><volume>128</volume><fpage>879</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1037/rev0000276</pub-id><pub-id pub-id-type="pmid">34516148</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Prat-Carrabin</surname><given-names>A</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021c</year><article-title>Bias and variance of the Bayesian-mean decoder</article-title><conf-name>Advances in Neural Information Processing Systems 34 (NeurIPS 2021)</conf-name><fpage>23793</fpage><lpage>23805</lpage></element-citation></ref><ref id="bib92"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Prat-Carrabin</surname><given-names>A</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Imprecise Probabilistic Inference from Sequential Data</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/xn5mk</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roe</surname><given-names>RM</given-names></name><name><surname>Busemeyer</surname><given-names>JR</given-names></name><name><surname>Townsend</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Multialternative decision field theory: a dynamic connectionist model of decision making</article-title><source>Psychological Review</source><volume>108</volume><fpage>370</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.108.2.370</pub-id><pub-id pub-id-type="pmid">11381834</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Kirkham</surname><given-names>NZ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Infant statistical learning</article-title><source>Annual Review of Psychology</source><volume>69</volume><fpage>181</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-122216-011805</pub-id><pub-id pub-id-type="pmid">28793812</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanborn</surname><given-names>AN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Types of approximation for probabilistic cognition: sampling and variational</article-title><source>Brain and Cognition</source><volume>112</volume><fpage>98</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2015.06.008</pub-id><pub-id pub-id-type="pmid">26228974</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dickinson</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neuronal coding of prediction errors</article-title><source>Annual Review of Neuroscience</source><volume>23</volume><fpage>473</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.473</pub-id><pub-id pub-id-type="pmid">10845072</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Estimating the Dimension of a Model</article-title><source>The Annals of Statistics</source><volume>6</volume><fpage>461</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1214/aos/1176344136</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Simple models for reading neuronal population codes</article-title><source>PNAS</source><volume>90</volume><fpage>10749</fpage><lpage>10753</lpage><pub-id pub-id-type="doi">10.1073/pnas.90.22.10749</pub-id><pub-id pub-id-type="pmid">8248166</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>A mathematical theory of communication</article-title><source>The Bell System Technical Journal</source><volume>27</volume><fpage>1</fpage><lpage>55</lpage></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shanteau</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Descriptive versus normative models of sequential inference judgment</article-title><source>Journal of Experimental Psychology</source><volume>93</volume><fpage>63</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1037/h0032509</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Complexity and the representation of patterned sequences of symbols</article-title><source>Psychological Review</source><volume>79</volume><fpage>369</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1037/h0033118</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="1997">1997</year><chapter-title>Bounded rationality</chapter-title><person-group person-group-type="editor"><name><surname>Simon</surname><given-names>HA</given-names></name></person-group><source>Models of Bounded Rationality: Empirically Grounded Economic Reason</source><publisher-name>The MIT Press</publisher-name><fpage>291</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.7551/mitpress/4711.001.0001</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Natural image statistics and neural representation</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>1193</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.1193</pub-id><pub-id pub-id-type="pmid">11520932</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sims</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Implications of rational inattention</article-title><source>Journal of Monetary Economics</source><volume>50</volume><fpage>665</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1016/S0304-3932(03)00029-1</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Psychophysically principled models of visual simple reaction time</article-title><source>Psychological Review</source><volume>102</volume><fpage>567</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.567</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soetens</surname><given-names>E</given-names></name><name><surname>Boer</surname><given-names>LC</given-names></name><name><surname>Hueting</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Expectancy or automatic facilitation? Separating sequential effects in two-choice reaction time</article-title><source>Journal of Experimental Psychology</source><volume>11</volume><fpage>598</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.11.5.598</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Penny</surname><given-names>WD</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Moran</surname><given-names>RJ</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Bayesian model selection for group studies</article-title><source>NeuroImage</source><volume>46</volume><fpage>1004</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.025</pub-id><pub-id pub-id-type="pmid">19306932</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugrue</surname><given-names>LP</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Matching behavior and the representation of value in the parietal cortex</article-title><source>Science</source><volume>304</volume><fpage>1782</fpage><lpage>1787</lpage><pub-id pub-id-type="doi">10.1126/science.1094765</pub-id><pub-id pub-id-type="pmid">15205529</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Expectation in perceptual decision making: neural and computational mechanisms</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>745</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1038/nrn3838</pub-id><pub-id pub-id-type="pmid">25315388</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trapp</surname><given-names>S</given-names></name><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Bitzer</surname><given-names>S</given-names></name><name><surname>Bar</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Human preferences are biased towards associative information</article-title><source>Cognition &amp; Emotion</source><volume>29</volume><fpage>1054</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1080/02699931.2014.966064</pub-id><pub-id pub-id-type="pmid">25303050</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Using time-varying evidence to test models of decision dynamics: bounded diffusion vs. the leaky competing accumulator model</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>79</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00079</pub-id><pub-id pub-id-type="pmid">22701399</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title><source>Psychological Review</source><volume>108</volume><fpage>550</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.108.3.550</pub-id><pub-id pub-id-type="pmid">11488378</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Joshua Wilson</surname><given-names>KJM</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Eric Larson</surname><given-names>CJC</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Ian Henriksen</surname><given-names>EAQ</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vulkan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>An economist’s perspective on probability matching</article-title><source>Journal of Economic Surveys</source><volume>14</volume><fpage>101</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1111/1467-6419.00106</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title><source>Neuron</source><volume>36</volume><fpage>955</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01092-9</pub-id><pub-id pub-id-type="pmid">12467598</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>XX</given-names></name><name><surname>Stocker</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Bayesian observer model constrained by efficient coding can explain “anti-Bayesian” percepts</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1509</fpage><lpage>1517</lpage><pub-id pub-id-type="doi">10.1038/nn.4105</pub-id><pub-id pub-id-type="pmid">26343249</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>XX</given-names></name><name><surname>Stocker</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Lawful relation between perceptual bias and discriminability</article-title><source>PNAS</source><volume>114</volume><fpage>10244</fpage><lpage>10249</lpage><pub-id pub-id-type="doi">10.1073/pnas.1619153114</pub-id><pub-id pub-id-type="pmid">28874578</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wilder</surname><given-names>MH</given-names></name><name><surname>Jones</surname><given-names>M</given-names></name><name><surname>Mozer</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sequential effects reflect parallel learning of multiple environmental regularities</article-title><conf-name>Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference</conf-name><fpage>2053</fpage><lpage>2061</lpage></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Information-constrained state-dependent pricing</article-title><source>Journal of Monetary Economics</source><volume>56</volume><fpage>S100</fpage><lpage>S124</lpage><pub-id pub-id-type="doi">10.1016/j.jmoneco.2009.06.014</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sequential effects: Superstition or rational behavior?</article-title><source>Advances in Neural Information Processing Systems</source><volume>21</volume><fpage>1873</fpage><lpage>1880</lpage><pub-id pub-id-type="pmid">26412953</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Huang</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Maximizing masquerading as matching in human visual search choice behavior</article-title><source>Decision</source><volume>1</volume><fpage>275</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1037/dec0000013</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>CH</given-names></name><name><surname>Yu</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Sequential effects: A Bayesian analysis of prior bias on reaction time and behavioral choice</article-title><conf-name>Proceedings of the 36th Annual Conference of the Cognitive Science Society</conf-name><fpage>1844</fpage><lpage>1849</lpage></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>C</given-names></name><name><surname>Byrd</surname><given-names>RH</given-names></name><name><surname>Lu</surname><given-names>P</given-names></name><name><surname>Nocedal</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization</article-title><source>ACM Transactions on Mathematical Software. Association for Computing Machinery</source><volume>23</volume><fpage>550</fpage><lpage>560</lpage><pub-id pub-id-type="doi">10.1145/279232.279236</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Stability of subjects’ behavior throughout the experiment</title><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Subjects’ behavior in the first and second halves of the task.</title><p>(<bold>a</bold>) Proportion of predictions A as a function of the stimulus generative probability, conditional on observing A (blue lines) or B (orange lines), and unconditional (grey lines), in the first half of the experiment (solid lines) and in the second half (dashed lines). Filled circles indicate p-values of Fisher’s exact test (of the equality of the proportions in the first and second halves, with Bonferroni-Holm-Šidák correction) below .05. (<bold>b</bold>) Difference between the proportions of predictions A conditional on an A, and conditional on a B, in the first half of the experiment (red circles), and in the second half (dark-red diamonds). The p-values of Fisher’s exact tests (of equality of the conditional proportions, i.e., <inline-formula><mml:math id="inf454"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"/><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>), with Bonferroni-Holm-Šidák correction, are all below 1e-6. Bars indicate the standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig1-v1.tif"/></fig><p>To validate the assumption that we capture, in our experiment, the ‘stationary’ behavior of subjects, we compare their responses in the first half of the task (first 100 trials) to their responses in the second half (last 100 trials). We find that the unconditional proportions of prediction A in these two cases are not significantly different, for most values of the stimulus generative probability. The sign of the difference (regardless of its statistical significance) implies that the proportions of predictions A in the second half of the experiment are slightly closer to 1 when the probability of the stimulus A is greater than 0.5; which would mean that the responses of subjects are slightly closer to optimality, in the second half of the experiment (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1a</xref>, grey lines). Regarding the sequential effects, we also obtain very similar behaviors in the first and second halves of the experiment (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). We conclude that for our analysis it is reasonable to assume that the behavior of subjects is stationary throughout the task.</p></sec><sec sec-type="appendix" id="s9"><title>Robustness of the model fitting</title><p>To evaluate the ability of the model-fitting procedure to correctly identify the model that generated a given set of responses, we compute a confusion matrix of the eight models. For each model, we simulate 200 runs of the task (each with 200 passive trials followed by 200 trials in which a prediction is obtained), with values of <inline-formula><mml:math id="inf455"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf456"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> close to values typically obtained when fitting the subjects’ responses (for prediction-cost models, <inline-formula><mml:math id="inf457"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0.03</mml:mn><mml:mo>,</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>15</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; for unpredictability-cost models, <inline-formula><mml:math id="inf458"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; and <inline-formula><mml:math id="inf459"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mn>1.5</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> for both families of models). We then fit each of the eight models to each of these simulated datasets, and count how many times each model best fit each dataset (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2a</xref>). To further test the robustness of the model-fitting procedure, we randomly introduce errors in the simulated responses: for 10% of the responses, randomly chosen in each dataset, we substitute the response by its opposite (i.e., B for A, and A for B), and compute a confusion matrix using these new responses (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2b</xref>). In both cases, the model-fitting procedure identifies the correct model a majority of times (i.e., the best-fitting model is the model that generated the data; <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p><p>Finally, to examine the robustness of the weight of the cost, <inline-formula><mml:math id="inf460"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, we consider for each subject its best-fitting model in each family (the precision-cost family and the unpredictability-cost family), and we fit separately each model to the subject’s responses obtained in trials in which the stimulus generative probability was medium (<inline-formula><mml:math id="inf461"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>.3</mml:mn><mml:mo>,</mml:mo><mml:mn>.35</mml:mn><mml:mo>,</mml:mo><mml:mn>.4</mml:mn><mml:mo>,</mml:mo><mml:mn>.45</mml:mn><mml:mo>,</mml:mo><mml:mn>.5</mml:mn><mml:mo>,</mml:mo><mml:mn>.55</mml:mn><mml:mo>,</mml:mo><mml:mn>.6</mml:mn><mml:mo>,</mml:mo><mml:mn>.65</mml:mn><mml:mo>,</mml:mo><mml:mn>.7</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) and those in which it was extreme (<inline-formula><mml:math id="inf462"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>.05</mml:mn><mml:mo>,</mml:mo><mml:mn>.1</mml:mn><mml:mo>,</mml:mo><mml:mn>.15</mml:mn><mml:mo>,</mml:mo><mml:mn>.2</mml:mn><mml:mo>,</mml:mo><mml:mn>.25</mml:mn><mml:mo>,</mml:mo><mml:mn>.75</mml:mn><mml:mo>,</mml:mo><mml:mn>.8</mml:mn><mml:mo>,</mml:mo><mml:mn>.85</mml:mn><mml:mo>,</mml:mo><mml:mn>.9</mml:mn><mml:mo>,</mml:mo><mml:mn>.95</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). The <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref> shows the correlation between the best-fitting parameters obtained in these two cases.</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Model-fitting confusion matrix.</title><p>(<bold>a</bold>) For each row models (‘true model’), percentage of simulated datasets of 200 responses that were best fitted by column models (‘best-fitting model’). Example: when fitting data generated by the precision-cost model with <inline-formula><mml:math id="inf463"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>, the best-fitting model was the correct model on 98% of the fits, and the precision-cost model with <inline-formula><mml:math id="inf464"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> on 2% of the fits. (<bold>b</bold>) Same as (<bold>a</bold>), with 10% of responses (randomly chosen in each simulated dataset) replaced by the opposite responses.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig2-v1.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Stability of the cost-weight parameter across medium and extreme values of the stimulus generative probability.</title><p>Best-fitting parameters of individual subjects when fitting the data obtained in trials with extreme values of the stimulus generative probability (i.e., <inline-formula><mml:math id="inf465"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> or <inline-formula><mml:math id="inf466"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> in <inline-formula><mml:math id="inf467"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>.75</mml:mn><mml:mo>,</mml:mo><mml:mn>.8</mml:mn><mml:mo>,</mml:mo><mml:mn>.85</mml:mn><mml:mo>,</mml:mo><mml:mn>.9</mml:mn><mml:mo>,</mml:mo><mml:mn>.95</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>), plotted against the best-fitting parameters when fitting the data obtained in trials with medium values of the stimulus generative probability (i.e., <inline-formula><mml:math id="inf468"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> or <inline-formula><mml:math id="inf469"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> in <inline-formula><mml:math id="inf470"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>.5</mml:mn><mml:mo>,</mml:mo><mml:mn>.55</mml:mn><mml:mo>,</mml:mo><mml:mn>.6</mml:mn><mml:mo>,</mml:mo><mml:mn>.65</mml:mn><mml:mo>,</mml:mo><mml:mn>.7</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>), with (<bold>a</bold>) precision-cost models, and (<bold>b</bold>) unpredictability-cost models. <italic>Purple dots:</italic> subjects best-fitted by prediction-cost models. <italic>Green dots:</italic> subjects best-fitted by unpredictability-cost models. The plots are in log-log scale, except below <inline-formula><mml:math id="inf471"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> (<bold>a</bold>) and <inline-formula><mml:math id="inf472"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> (<bold>b</bold>), where the scale is linear (allowing in particular for the value 0 to be plotted.) For the precision-cost models, we plot the inverse of the characteristic decay time, <inline-formula><mml:math id="inf473"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The grey line shows the identity function.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig3-v1.tif"/></fig></sec><sec sec-type="appendix" id="s10"><title>Distribution of subjects’ BICs</title><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Distribution of subjects’ BICs.</title><p>(<italic>Left</italic>) Box-and-whisker plots showing the 5th and 95th percentiles (whiskers), the first and third quartiles (box), and the median (vertical line) of the BICs (across subjects) of the unpredictability-cost models (green boxes) and of the precision-cost models (purple boxes), fitted on the subjects best-fitted by the unpredictability-cost models (first two rows) and on the subjects best-fitted by the precision-cost models (last two rows). (<italic>Right</italic>) Box-and-whisker plots (same quantiles) showing the distribution of the difference, for each subject, between the BIC of the best model in the family that does not best fit the subject, and the BIC of the best-fitting model; for the subjects best-fitted by the unpredictability-cost models (top box) and for the subjects best-fitted by the precision-cost models (bottom box). The unpredictability-cost models, when fitted to the responses of the subjects best-fitted by the precision-cost models (bottom box), yield larger differences in the BIC with the best-fitting models, than the precision-cost models when fitted to the responses of the subjects best-fitted by the unpredictability-cost models (top box). This suggests that the precision-cost models are better than the unpredictability-cost models at capturing the responses of the subjects that they do not best fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig4-v1.tif"/></fig></sec><sec sec-type="appendix" id="s11"><title>Subjects’ sequential effects — tree representation</title><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Composition of sequential effects in subjects’ responses.</title><p>Proportion of predictions A conditional on sequences of up to three past observations, as a function of the stimulus generative probability. See <xref ref-type="fig" rid="fig6">Figure 6d</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig5-v1.tif"/></fig></sec><sec sec-type="appendix" id="s12"><title>Subjects’ sequential effects — unpooled data</title><p>As mentioned in the main text, we pool together the predictions that correspond, in different blocks of trials, to either event (left or right), as long as these events have the same probability. The <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>, below, is the same as <xref ref-type="fig" rid="fig2">Figure 2</xref>, but without such pooling. Given a stimulus generative probability, <inline-formula><mml:math id="inf474"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>, all the subjects experience one (and only one) block of trials in which either the event ‘right’ or the event ‘left’ had probability <inline-formula><mml:math id="inf475"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>. For one group of subjects the ‘right’ event has probability <inline-formula><mml:math id="inf476"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> and for the group of remaining subjects it is the ‘left’ event that has probability <inline-formula><mml:math id="inf477"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>. The responses of these subjects are not pooled together in <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>, while they were in <xref ref-type="fig" rid="fig2">Figure 2</xref>. This also applies for any other stimulus generative probability, <inline-formula><mml:math id="inf478"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>. However, we note that the two groups of subjects for whom <inline-formula><mml:math id="inf479"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> was the probability of a ‘right’ event or a ‘left’ event are not the same as the two groups just mentioned in the case of the probability <inline-formula><mml:math id="inf480"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula>. As a result, from one proportion shown in <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> to another, the underlying group of subjects changes. In <xref ref-type="fig" rid="fig2">Figure 2</xref>, each proportion is computed with the responses of all the subjects. This illustrates another advantage of the pooling that we use in the main text.</p><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Sequential effects in subjects’ responses.</title><p>As <xref ref-type="fig" rid="fig2">Figure 2</xref>, but without pooling together the rightward and leftward predictions from different block of trials in which the corresponding stimuli have the same probability. See main text.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig6-v1.tif"/></fig></sec><sec sec-type="appendix" id="s13"><title>Subjects’ response times</title><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Subjects’ response times.</title><p>Average response times conditional on having observed a stimulus A (blue line), a stimulus B (orange line), and unconditional (grey line), as a function of the stimulus generative probability. The stars indicate that the p-values below 0.05 of the <inline-formula><mml:math id="inf481"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>-tests of equality between the response times after an A and after a B. The subjects seem slower after observing the less frequent stimulus (e.g., B, when <inline-formula><mml:math id="inf482"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>.5</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig7-v1.tif"/></fig></sec><sec sec-type="appendix" id="s14"><title>Across-subjects results</title><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Subjects’ sequential effects — across-subjects analysis.</title><p>The statistics used for this figure are obtained by computing first the proportions of predictions A for each subject, and then computing the across-subject averages and standard errors of the mean (instead of pooling together the responses of all the subjects). (<bold>a,b</bold>) As in <xref ref-type="fig" rid="fig2">Figure 2</xref>, with across-subjects statistics. (<bold>c,d,e</bold>) As in <xref ref-type="fig" rid="fig6">Figure 6a, b and c</xref>, with across-subjects statistics. The filled circles indicate that the p-value of the Student’s t-test is below 0.05, and the filled squares indicate that the p-value with Bonferroni-Holm-Šidák correction is below 0.05.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81256-app1-fig8-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81256.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Hang</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.06.20.496900" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.06.20.496900"/></front-stub><body><p>This valuable work addresses a long-standing empirical puzzle from a new computational perspective. The authors provide convincing evidence that attractive and repulsive sequential effects in perceptual decisions may emerge from rational choices under cognitive resource constraints rather than adjustments to changing environments. It is relevant to understanding how people represent uncertain events in the world around them and make decisions, with broad applications to economic behavior.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81256.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Zhang</surname><given-names>Hang</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.06.20.496900">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.06.20.496900v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Resource-Rational Account of Sequential Effects in Human Prediction&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Floris de Lange as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Including alternative models of sequential effects in the model comparison would be necessary. Please see Reviewers #2's and #3's comments for details.</p><p>2) Additional statistical tests are required to tease out potentially confounding effects of motor responses (see Reviewer #3's comments). Besides, there should be corrections for multiple comparisons (see Reviewer #2's comments).</p><p>3) The costs assumed in the resource-rational models need better theoretical justification. Please see Reviewers #1's and #3's comments for details.</p><p>4) Testing a hybrid model that combines the precision cost and unpredictability cost is highly recommended, given that the two models seem to explain complementary aspects of the data. Please see Reviewer #1's comments for details.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>There is a clear inverted-U shape in Figure 2b that the authors don't comment on. This seems like a salient feature of the data that should be explained or at least commented on. Interestingly, the best-fitting models can account for this (Figure 4b), but it doesn't seem to be discussed. It would also be helpful to see the predictions separately for precision-cost and unpredictability-cost models.</p><p>At a conceptual level, I'm not sure I understand the reasoning behind the unpredictability cost. It's not intuitive to me why more unpredictability should be registered by an observer as a cost of updating their beliefs. The Discussion didn't really clear this up; there's a reference to a preference for predictable environments, but the argument that this is somehow costly to the brain is hand-wavy. Just because unpredictability increases neural activity doesn't mean that it's something the brain is trying to minimize.</p><p>The pattern of higher-order sequential effects (Figure 6) seems to suggest that behavior is consistent with some combination of precision cost and unpredictability cost. Neither model on its own explains the data particularly well (compare with Figure 5). Have the authors considered hybrid models?</p><p>There are a few references related to the costly inference that deserve mention:</p><p>– Kominers et al. (2016), who develop a model of costly updating.</p><p>– Dasgupta et al. (2020), who develop a model of resource-bounded inference.</p><p>– Graeber (202), who develops a model of inattentive inference.</p><p>The authors cite a number of earlier modeling papers, but it's not clear to me what those previous models would predict about the new data, and whether the new models proposed in this paper predict the earlier data.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I would recommend the authors conduct additional modeling analyses including models that express the alternative hypotheses clearly, generate and present individual model predictions, and consider running a (possibly online) larger experiment with incentives in place. The ideal test of the hypothesis would be an experiment with multiple levels of incentives, showing that people adjust their representations as this model predicts as they trade off computational costs and real rewards. If monetary rewards cannot be used, incentives could be implemented by having a longer delay after erroneous predictions.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>1. I recommend using regression analyses (e.g. a GLM) where regressors for both previous choices and previous stimuli are entered (as e.g. in Urai et al. Nature Communications 2017) to resolve this possible confound. Such GLM also allows looking back further back in time at the impact of longer lags on decisions. This would allow testing for example if the repulsive bias to the stimulus at lag 2 (in sequences 111 or 101) extends to longer lags, both in experimental data and simulations.</p><p>2. Authors could test whether the very first prediction on each block already shows a signature of the p and whether the prediction is stable within blocks.</p><p>I provide here some recommendations on how the clarity of the manuscript could be improved. A thorough work on improving the text and figures and the general flow and organization of the manuscript would make a major difference in the impact of that paper on the wider community. which is very frustrating for the reader is to see one statement (e.g. a choice of methods or a result) exposed at some point and then the explanation for the statement much later in the manuscript (see below). Here are my suggestions:</p><p>– I believe the models would be better motivated to the reader if the Introduction made a brief mention of the ideas of bounded rationality (and related concepts) and justified focus on these two specific types of cost – all of which are nicely detailed in the Discussion.</p><p>– Please try to make understanding figures more intuitive; for example, using a colour code for the different cost types may help differentiate them. A tree-like representation of history biases (showing the mean accuracy for different types of sequences, e.g. in Meyniel et al. 2016 Plos CB) may be more intuitive to read and reveal a richer structure in the data and models than the current Figure 5-6 (also given than the authors do not comment much on the impact of the &quot;probability of observation 1&quot;, so perhaps this effects could be marginalized out).</p><p>– Figure 3 is really helpful in understanding the two types of cost (much more than the equations for most readers). Unfortunately, it is hardly referred to in the main text. I suggest rewriting the presentation of that part of the Results section around these examples.</p><p>– Why and how the two types of costs give rise to historical effects (beyond the fact that these costs generate suboptimalities) is a central idea in the paper but it is only exposed in the Discussion session. Integrating these explanations within the Results section would help a lot. Plotting some example simulations for a sequence of trials and/or some cartoon explanations of how the historical effects emerge for the different models would also help.</p><p>– Placing figures in Methods does not help in my opinion – please consider moving to the main text or as supplementary Figures.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81256.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Reviewer #1 (Recommendations for the authors):</p><p>There is a clear inverted-U shape in Figure 2b that the authors don't comment on. This seems like a salient feature of the data that should be explained or at least commented on. Interestingly, the best-fitting models can account for this (Figure 4b), but it doesn't seem to be discussed. It would also be helpful to see the predictions separately for precision-cost and unpredictability-cost models.</p></disp-quote><p>We agree with Reviewer #1 that it is notable that there is an inverted U shape in Figure 2b, i.e., that the sequential effect of the last stimulus is smaller for more extreme values of the stimulus generative probability, in the responses of the subjects. Some models reproduce this pattern: following Reviewer #1’s suggestion, we now show in Figure 4 the predictions of the precision-cost and unpredictability cost models separately.</p><p>The panels a, b, c, and d in Figure 4 show the predictions of the precision-cost model of a Bernoulli observer (a) and of a Markov observer with m=1 (c), and the unpredictability-cost model of a Bernoulli observer (b) and of a Markov observer with m=1 (d). In panel (a) we also show the predictions of the precision-cost model of a Bernoulli observer (m=0) with the “traditional” probability-matching strategy, i.e., with kappa = 1 (in this case the probability of predicting A is equal to the inferred probability of the event A). In this case the size of the sequential effect, p(A|A)-p(A|B), is the same for all values of stimulus generative probability (see dotted lines and light-red dots). But with kappa = 2.8 (a value representative of subjects’ best-fitting values), the proportions of predictions are brought closer to optimality (i.e., to the extremes), and the sequential effect, p(A|A)-p(A|B) now depends on the stimulus generative probability, resulting in the inverted U-shape of the sequential effects in Figure 4a.</p><p>We note, however, that the precision-cost model of a Markov observer (with m=1) yields a (non-inverted) U shape of the sequential effects. While the behavior of the precision-cost model of a Bernoulli observer is determined by two exponentiallyfiltered counts of the two possible stimuli, the behavior of the precision-cost model of a Markov observer (m=1) is determined by four exponentially-filtered counts of the four possible <italic>pairs</italic> of stimuli, and in particular p(A|B) is determined by the counts of the pairs BA and BB. But when p is large, the pairs BA and BB are rare: thus it is as if the model subject had little total evidence to inform its decision. The resulting predictions are close to that of an uninformed observer, i.e., p(A|B) ≈ 0.5. By contrast, p(A|A) is more extreme, and this difference yields stronger sequential effects for more extreme values of the stimulus generative probability (i.e., U shape in Figure 4c, right).</p><p>Among the subjects that are best-fitted by a precision-cost model, some are bestfitted by a model of a Bernoulli observer (m=0) while some others are best-fitted by a model of a Markov observer (m&gt;0). Overall the sequential effects for these subjects exhibit a small decrease at more extreme stimulus generative probabilities (Figure 4e, right). By contrast, the subjects best-fitted by an unpredictability-cost model show a stronger decrease in the sequential effects at more extreme probabilities (Figure 4f, right). In addition the latter subjects exhibit weaker sequential effects than the former ones. This is reproduced by simulations of the corresponding best-fitting models (Figure 4g,h). The models belonging to the ‘other’ family, which does not best fit each subject (i.e., the precision-cost models, for the subjects best-fitted by an unpredictability-cost model; and the unpredictabilitycost models, for the subjects that are best-fitted by a precision-cost model) do not reproduce well the patterns in subjects’ data (Figure 4i,j).</p><p>In the revised version of the manuscript, we now point to the inverted U-shape of sequential effects in group average of subjects’ data (l. 182-185), and we have completely reworked the presentation of the sequential effects of the model. In particular we detail the behavior of each family of models, separately, using the updated Figure 4; we explain the origin of the shape of the sequential effects (inverted U-shape in Figure 4a and U-shape in Figure 4c); and we compare the models’ behaviors with that of the subjects (l. 422-493).</p><disp-quote content-type="editor-comment"><p>At a conceptual level, I'm not sure I understand the reasoning behind the unpredictability cost. It's not intuitive to me why more unpredictability should be registered by an observer as a cost of updating their beliefs. The Discussion didn't really clear this up; there's a reference to a preference for predictable environments, but the argument that this is somehow costly to the brain is hand-wavy. Just because unpredictability increases neural activity doesn't mean that it's something the brain is trying to minimize.</p></disp-quote><p>In the revised version of the manuscript, we now provide more details on the rationale for the unpredictability cost. We note, first, that we make a similar argument based on the cost of neural activity for the precision cost. Although the two cases differ by the hypothesized origin of the increase in the neural activity, in both cases we assume that this neural activity comes with a metabolic cost, which is not to be minimized per se, but which enters a trade-off with the correctness of the represented belief, in comparison to the optimal, Bayesian belief.</p><p>As to the rationale subtending the unpredictability cost, it resides in the assumption that the difficulty of representing a belief distribution over the parameters generating the environment (here, q), originates in the difficulty of representing the environments themselves. For instance, in the models of ‘intuitive physics’ (e.g., Battaglia, Hamrick, and Tenenbaum, 2013) or in the ‘simulation heuristic’ of Kahneman and Tversky (1982), the brain runs simulations of the possible sequences of outcomes, in a given environment. Environments that are more entropic result in a greater diversity of sequences of outcomes, and thus in more simulations, resulting, presumably, in higher costs. Furthermore, several cognitive models posit that the brain <italic>compresses</italic> sequences (Simon, 1972; Planton <italic>et al.</italic>, 2021); but a greater entropy in sequences reduces the compression rate, resulting in longer descriptions of these sequences (here also, because of the greater diversity of potential outcomes), which presumably is more costly.</p><p>We note that for neither the precision cost nor the unpredictability cost do we provide a mechanistic account of the underlying representational system in which the cost naturally emerges. But under the assumption that the cost of representing a distribution over environments resides in the cost of representing the environments themselves, it seems that, for the reasons just presented, a reasonable assumption is that more unpredictable environments are more difficult to represent.</p><p>In the revised version of the manuscript, we now provide more details on the rationale for the unpredictability cost, in the Discussion (l. 687-700). We have also reworked the short presentation of the costs in the Introduction (l. 71-79).</p><p>References:</p><p>Peter W. Battaglia, Jessica B. Hamrick, and Joshua B. Tenenbaum. Simulation as an engine of physical scene understanding. Proceedings of the National Academy of Sciences of the United States of America, 110(45):18327–18332, 2013.</p><p>Daniel Kahneman and Amos Tversky. The simulation heuristic, pages 201–208. Cambridge University Press, 1982.</p><p>Herbert A Simon. Complexity and the representation of patterned sequences of symbols. Psychological review, 79(5):369, 1972.</p><p>Samuel Planton, Timo van Kerkoerle, Leïla Abbih, Maxime Maheu, Florent Meyniel, Mariano Sigman, Liping Wang, Santiago Figueira, Sergio Romano, and Stanislas Dehaene. A theory of memory for binary sequences: Evidence for a mental compression algorithm in humans, 2021.</p><disp-quote content-type="editor-comment"><p>The pattern of higher-order sequential effects (Figure 6) seems to suggest that behavior is consistent with some combination of precision cost and unpredictability cost. Neither model on its own explains the data particularly well (compare with Figure 5). Have the authors considered hybrid models?</p></disp-quote><p>Regarding the patterns of sequential effects in subjects’ data and resulting from the models, we note that the main objective of Figure 5 was to illustrate the signs of the sequential effects occurring with the models, and in particular that the sequential effects are repulsive only with the precision-cost model of a Markov observer (m=1). A diversity of behaviors, however, can result from the models, depending on the type of cost (precision or unpredictability), on the Markov order (m=0 to 3), and on the values of the model’s parameters (λ and kappa). The Figure 8, in Methods, shows the higher-order sequential effects for the two types of costs and the four Markov orders we consider: depending on the model, the sequential effects can be an increasing function of the stimulus generative probability, or a decreasing function, or a non-monotonous function; but in all these cases the signs of the sequential effects are consistent with what is shown in Figure 5 and with the message we seek to convey, that in most cases the sequential effects are attractive, except in one case with the precision-cost model of a Markov observer (m&gt;0).</p><p>Taking into account Reviewer #1’s comment, however, and for the benefit of the reader, we have added the behavior of another model to Figure 5, in the revised version of the manuscript: that of the precision-cost model of a Bernoulli observer (m=0). Not only does it exhibit how this model does not yield repulsive sequential effects (unlike the precision-cost model of a Markov observer, m=1; Figure 5c), but also it shows how it yields attractive sequential effects, in Figure 5a and 5b, whose behaviors as a function of the stimulus generative probability are qualitatively different from that of the precision-cost model of a Markov observer (m=1), thus suggesting the diversity of behaviors resulting from the models.</p><p>However, we agree with Reviewer #1 that hybrid models are an interesting possibility. Thus, we have investigated a hybrid model, in which both the precision cost and the unpredictability cost weigh on the representation of posteriors, each with a different weight parameter (denoted by λ<sub>p</sub> and λ<sub>u</sub>). We derive the optimal inference procedure under this double cost, and find that it results in a posterior that fluctuates with the recent history of stimuli, and that is biased toward values of the generative parameter q that implies less entropic environments; in other words, it combines features of the two costs taken separately. For a given Markov order, m, this model is a generalization of both the precision-cost model and the unpredictability-cost model. It has one more parameter than these models (due to the two weights of the costs). To compare the ability of models to capture parsimoniously subjects’ data, we use as a comparison metric the well-known Bayesian Information Criterion (BIC), which is based on the log-likelihood but also includes a penalty term for the number of parameters. Although one might expect that the behavior of most subjects may be best captured (as per the BIC) by this hybrid model, we find that its BIC is in fact larger (indicating a worse fit) than the best-fitting non-hybrid model for more than two thirds of subjects; and for half of the remaining subjects (for whom the BIC is lower with the hybrid model), the difference in BIC is lower than 6, which indicates weak evidence in support of the hybrid models. In other words, for a majority of subjects, the improvement in the log-likelihood that results from allowing a second type of cost is too modest to justify the additional parameter. This suggests that the two families of models capture specific behaviors that are prevalent in different subpopulations of subjects. In the revised manuscript, we comment on the hybrid model in the main text (l. 407-419) and we present it in more detail in Methods (p. 44-46).</p><disp-quote content-type="editor-comment"><p>There are a few references related to the costly inference that deserve mention:</p><p>– Kominers et al. (2016), who develop a model of costly updating.</p><p>– Dasgupta et al. (2020), who develop a model of resource-bounded inference.</p><p>– Graeber (202), who develops a model of inattentive inference.</p></disp-quote><p>We thank Reviewer #1 for pointing to these papers which also consider the hypothesis of a cost in the inference process of decision-makers. We note that Dasgupta et al. (2020) also uses the Kullback-Leibler function as a distance metric to be minimized. We comment on these papers in the Discussion of the revised manuscript (l. 804-827).</p><disp-quote content-type="editor-comment"><p>The authors cite a number of earlier modeling papers, but it's not clear to me what those previous models would predict about the new data, and whether the new models proposed in this paper predict the earlier data.</p></disp-quote><p>The main kind of other models that we refer to, in the Introduction and in the Discussion, are ‘leaky integration’ models, in which past observations are gradually forgotten (through an exponential discount). We show that the optimal solution to the problem of constrained inference (Equation (1)) with a precision cost (Equation (3)), is precisely one in which remote patterns in the sequence of observed stimuli are discounted, in the posterior, through an exponential filter. In other words, we recover the leaky-integration model (i.e., a model identical, for instance, to the one examined by Meyniel, Maheu and Dehaene, 2016), and thus the predictions of the precision-cost model are exactly those of a leaky-integration model (precision-cost models with different Markov order differ by the length of the sequences of observations that are counted through an exponential filter). One difference of our study, in comparison with previous works, is that the leaky integration is derived as the optimal solution to a problem of constrained optimization, rather than posited a priori in the definition of the model. We improved the revised manuscript, by clarifying in the Introduction that we recover leaky integration (l.76-79); by explaining in more details, in Results, that the precision-cost model results in a leaky-integration model, and by explicitly providing the posterior in the case of a Bernoulli observer (with the exponentially-filtered counts of past observations, Equation (6)); and by pointing out, in the Discussion, that we derive the exponential filtering from the constrained-inference problem, rather than assuming leaky integration from the start (l. 706-716).</p><p>Reference:</p><p>Florent Meyniel, Maxime Maheu, and Stanislas Dehaene. Human Inferences about Sequences: A Minimal Transition Probability Model. PLoS Computational Biology, 12(12):1–26, 2016.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>I would recommend the authors conduct additional modeling analyses including models that express the alternative hypotheses clearly, generate and present individual model predictions, and consider running a (possibly online) larger experiment with incentives in place. The ideal test of the hypothesis would be an experiment with multiple levels of incentives, showing that people adjust their representations as this model predicts as they trade off computational costs and real rewards. If monetary rewards cannot be used, incentives could be implemented by having a longer delay after erroneous predictions.</p></disp-quote><p>We thank Reviewer #2 for her/his attention to our paper and for her/his comments.</p><p>As for the point on the models: many models in the sequential-effects literature (Refs. [7-12] in the manuscript) are ‘leaky-integration’ models that interpret sequential effects as resulting from an attempt to learn the statistics of a sequence of stimuli, through exponentially decaying counts of the simple patterns in the sequence (e.g., single stimuli, repetitions, and alternations). In some studies, the ‘forgetting’ of remote observations that results from the exponential decay is justified by the fact that people live in environments that are usually changing: it is thus natural that they should expect that the statistics underlying the task’s stimuli undergo changes (although in most experiments, they do not), and if they expect changes, then they should discard old observations that are not anymore relevant. This theoretical justification raises the question as to why subjects do not seem to learn that the generative parameters in these tasks are in fact not changing — all the more as other studies suggest that subjects are able to learn the statistics of changes (and consistently they are able to adapt their inference) when the environment does undergo changes (Refs. [42,57]).</p><p>Our models are derived from a different approach: we derive behavior from the resolution of a problem of constrained optimization of the inference process. It is not a phenomenological model. When the constraint that weighs on the inference process is a cost on the precision of the posterior, as measured by its entropy, we find that the resulting posterior is one in which remote observations are ‘forgotten’, through an exponentially discount, i.e., we recover the predictions of the leaky-integration models, which past studies have empirically found to be reasonably good accounts of sequential effects. (Thus these models are already in our model comparison.) In our framework, the sequential effects do not stem from the subjects’ irrevocable belief that the statistics of the stimuli change from time to time, but rather from the difficulty that they have in representing precise belief; a rather different theoretical justification.</p><p>Furthermore, we show that a large fraction of subjects are not best-fitted by precision-cost models (i.e., they are not best-fitted by leaky integration), but instead they are best fitted by unpredictability-cost models. These models suggest a different explanation of sequential effects: that they result from the subjects favoring predictable environments, in their inference.</p><p>In the revised version of the manuscript, we have made clearer that the derivation of the optimal posterior under a precision cost results in the exponential forgetting of remote observations, as in the leaky-integration models. We mention it in the abstract, in the Introduction (l. 76-78), in the Results when presenting the precision-cost models (l. 264-278), and in the Discussion (l.706-716).</p><p>As for the point on incentivization: we agree that it would be very interesting to measure whether and to which extent the performance of subjects increases with the level of incentivization. Here, however, we wanted, first, to establish that subjects’ behavior could be understood as resulting from inference under a cost, and second, to examine the sensitivity of their predictions to the underlying generative probability — rather than to manipulating a tradeoff involving this cost (e.g. with financial reward). We note that we do find that subjects are sensitive to the generative probability, which implies that they exhibit some degree of motivation to put some effort in the task (which is the goal of incentivization), in spite of the lack of economic incentives. But it would indeed be interesting to know how the potential sensitivity to reward interacts with the sensitivity to the generative probability. Furthermore, as Reviewer #2 mentions, some studies show that incentives affect probability-matching behavior: it is then unclear whether the introduction of incentives in our task would change the inference of subjects (through a modification of the optimal trade-off that we model); or whether it would change their probability-matching behavior, as modeled by our generalized probability-matching response-selection strategy; or both. Note that we disentangled both aspects in our modeling and that our conclusions are about the inference, not the response-selection strategy. We deem the incentivization effects very much worth investigating; but they fall outside of the scope of our paper.</p><p>We now mention this point in the Discussion of the revised manuscript (l. 828-840).</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>1. I recommend using regression analyses (e.g. a GLM) where regressors for both previous choices and previous stimuli are entered (as e.g. in Urai et al. Nature Communications 2017) to resolve this possible confound. Such GLM also allows looking back further back in time at the impact of longer lags on decisions. This would allow testing for example if the repulsive bias to the stimulus at lag 2 (in sequences 111 or 101) extends to longer lags, both in experimental data and simulations.</p></disp-quote><p>We thank Reviewer #3 for pointing out the possibility that subjects may have a tendency to repeat motor responses that is not related to their inference.</p><p>We note that in Urai et al., 2017, as in many other sensory 2AFC tasks, successive trials are independent: the stimulus at a given trial is a random event independent of the stimulus at the preceding trial; the response at a given trial should in principle be independent of the stimulus at the preceding trial; and the response at the preceding trial conveys no information about the response that should be given at the current trial (although subjects might exhibit a serial dependency in their responses). By contrast, in our task an event is more likely than not to be followed by the same event (because observing this event suggests that its probability is greater than.5); and a prediction at a given trial should be correlated with the stimuli at the preceding trials, and with the predictions at the preceding trials. In a logit model (or any other GLM), this would mean that the predictors exhibit multicollinearity, i.e., they are strongly correlated. Multicollinearity does not reduce the predictive power of a model, but it makes the identification of parameters extremely unreliable: in other words, we wouldn’t be able to confidently attribute to each predictor (e.g., the past observations and the past responses) a reliable weight in the subjects’ decisions. Furthermore, our study shows that past stimuli can yield both attractive and repulsive effects, depending on the exact sequence of past observations. To capture this in a (generalized) linear model, we would have to introduce interaction terms for each possible past sequence, resulting in a very high number of parameters to be identified.</p><p>However, this does not preclude the possibility that subjects may have a motor propensity to repeat responses. In order to take this hypothesis into account, we examined the behavior and the ability to capture subjects’ data of models in which the response-selection strategy allows for the possibility of repeating, or alternating, the preceding response. Specifically, we consider models that are identical to those in our study, except for the response-selection strategy, which is an extension of the generalized probability-matching strategy, in which a parameter eta, greater than -1 and lower than 1, determines the probability that the model subject repeats its preceding response, or conversely alternates and chooses the other response. With probability 1-|η|, the model subject follows the generalized probability-matching response-selection strategy (parameterized by κ). With probability |η|, the model subject repeats the preceding response, if η &gt; 0, or chooses the other response, if η &lt; 0. We included the possibility of an alternation bias (negative η), but we find that no subject is best-fitted by a negative η, thus we focus on the repetition bias (positive η). We fit the models by maximizing their likelihoods, and we compared, using the Bayesian Information Criterion (BIC), the quality of their fit to that of the original models that do not include a repetition propensity.</p><p>Taking into account the repetition bias of subjects leaves the assignment of subjects into two families of inference cost mostly unchanged. We find that for 26% of subjects the introduction of the repetition propensity does not improve the fit (as measured by the BIC) and can therefore be discarded. For 47% of subjects, the fit is better with the repetition propensity (lower BIC), and the best-fitting inference model (i.e., the type of cost, precision or unpredictability, and the Markov order) is the same with or without repetition propensity. Thus for 73% (=26+47) of subjects, allowing for a repetition propensity does not change the inference model. We also find that the best-fitting parameters λ and κ, for these subjects, are very stable, when allowing or not for the repetition propensity. For 11% of subjects, the fit is better with the repetition propensity, and the cost type of the inference model is the same (as without the repetition propensity), but the Markov order changes. For the remaining 16%, both the cost type and the Markov order change.</p><p>Thus for a majority of subjects, the BIC is improved when a repetition propensity is included, suggesting that there is indeed a tendency to repeat responses, independent of the subjects’ inference process and generative stimulus probability. In Figure 7, in Methods, we show the behavior of the models without repetition propensity, and with repetition propensity, with a parameter η = 0.2 close to the average best-fitting value of eta across subjects. We show, in Methods, that (i) the unconditional probability of a prediction A, p(A), is the same with and without repetition propensity, and that (ii) the conditional probabilities p(A|A) and p(A|B) when η≠0 are weighted means of the unconditional probability p(A) and of the conditional probabilities when eta=0 (see p. 47-49 of the revised manuscript).</p><p>In summary, our results suggest that a majority of subjects do exhibit a propensity to repeat their responses. Most subjects, however, are best-fitted by the same inference model, with or without repetition propensity, and the parameters λ and κ are stable, across these two cases; this speaks to the robustness of our model fitting. We conclude that the models of inference under a cost capture essential aspects of the behavioral data, which does not exclude, and is not confounded by, the existence of a tendency, in subjects, to repeat motor responses.</p><p>In the revised manuscript, we present this analysis in Methods (p.47-49), and we refer to it in the main text (l. 353-356 and 400-406).</p><disp-quote content-type="editor-comment"><p>2. Authors could test whether the very first prediction on each block already shows a signature of the p and whether the prediction is stable within blocks.</p></disp-quote><p>The assumptions that subjects reach their asymptotic behavior after being presented with 200 observations in the passive trials should indeed be tested. To that end, we compared the behavior of the subjects in the first 100 active trials with their behavior in the remaining 100 active trials. The results of this analysis are shown in figure 9.</p><p>For most values of the stimulus generative probability, the unconditional proportions of predictions A, in the first and the second half (panel a, solid and dashed gray lines), are not significantly different (panel a, white dots), except for two values (p-value &lt; 0.05; panel a, filled dots). Although in most cases the difference between the two is not significant, in the second half the proportions of prediction A seem slightly closer to the extremes (0 and 1), i.e., closer to the optimal proportions. As for the sequential effects, they appear very similar in the two halves of trials. We conclude that for the purpose of our analysis we can reasonably consider that the behavior of the subjects is stationary throughout the task.</p><disp-quote content-type="editor-comment"><p>On top of that, I provide here some recommendations on how the clarity of the manuscript could be improved. A thorough work on improving the text and figures and the general flow and organization of the manuscript would make a major difference in the impact of that paper on the wider community. which is very frustrating for the reader is to see one statement (e.g. a choice of methods or a result) exposed at some point and then the explanation for the statement much later in the manuscript (see below). Here are my suggestions:</p><p>– I believe the models would be better motivated to the reader if the Introduction made a brief mention of the ideas of bounded rationality (and related concepts) and justified focus on these two specific types of cost – all of which are nicely detailed in the Discussion.</p><p>– Please try to make understanding figures more intuitive; for example, using a colour code for the different cost types may help differentiate them. A tree-like representation of history biases (showing the mean accuracy for different types of sequences, e.g. in Meyniel et al. 2016 Plos CB) may be more intuitive to read and reveal a richer structure in the data and models than the current Figure 5-6 (also given than the authors do not comment much on the impact of the &quot;probability of observation 1&quot;, so perhaps this effects could be marginalized out).</p><p>– Figure 3 is really helpful in understanding the two types of cost (much more than the equations for most readers). Unfortunately, it is hardly referred to in the main text. I suggest rewriting the presentation of that part of the Results section around these examples.</p><p>– Why and how the two types of costs give rise to historical effects (beyond the fact that these costs generate suboptimalities) is a central idea in the paper but it is only exposed in the Discussion session. Integrating these explanations within the Results section would help a lot. Plotting some example simulations for a sequence of trials and/or some cartoon explanations of how the historical effects emerge for the different models would also help.</p><p>– Placing figures in Methods does not help in my opinion – please consider moving to the main text or as supplementary Figures.</p></disp-quote><p>We thank Reviewer #3 for these recommendations, which we have followed in the revised manuscript.</p><p>– We now explain early in the Introduction how our approach relates to other “resource-rational” accounts of perceptual and cognitive processes, in which behavior is assumed to result from some constrained optimization. We also provide more details on the two costs we consider in the paper (l. 65-79).</p><p>– As for the color code for the different costs, the colors used for each cost in Figure 3 are consistent across panels. In the other figures, we have favored a color-coding that emphasizes the sequential effects (allowing to distinguish, for instance, p(A|A) and p(A|B)). However, in the revised manuscript, wherever a figure shows a simulation resulting from one of the two costs, we have set the color of the figure’s axes, and of the diagonal (\bar p = p), to the color that corresponds to the cost (consistently with Figure 3), so as to facilitate the identification of the models across figures.</p><p>– We have now included a “tree-like” representation of the sequential effects, in Figure 6d of the revised manuscript. The impact of the stimulus generative probability was “marginalized out”, as suggested by Reviewer #3. The nonmarginalized tree representations (per stimulus probability) can be found in Methods (Figure 13).</p><p>– We now refer more often to Figure 3, in the Results section of the main text (p. 11-15), so as to connect what is described in the text (e.g., the nonconvergence of the posterior with the precision cost) to its illustration in Figure 3. In addition we also refer to it in the section describing the sequential effects of the model, so as to make clear that with the precision-cost models the sequential effects stem from the non-convergence of the posterior (p. 20).</p><p>– In the revised manuscript we give more detailed explanations as to how each cost gives rise to sequential effects (which we agree is an important conceptual idea in the paper). In particular we have revised the passages in the Results section in which we present these costs and the corresponding solutions to the optimization problem (p. 11-15). Furthermore, we have added a new panel in Figure 3 (panel d), which shows, as suggested by the reviewer, the “trajectories” of a subject’s estimates, for different sequences of observations (though with the same stimulus generative probability), under the two costs, and under no cost (the Bayesian solution). It shows that the Bayesian observer converges to the correct value of the stimulus generative probability; that the observer under an unpredictability cost converges to an erroneous value; and that the observer under a precision cost does not converge, but keeps fluctuating with the history of stimuli. Finally, when describing the sequential effects of the model, we explain in detail how and why each cost gives rise to the sequential effects shown in Figure 4.</p><p>– We have reconsidered the Figures in Methods and whether we should place them elsewhere. We now place in Supplementary Materials the modelfitting confusion matrix and the figure showing the stability of the costweight parameter across medium and extreme values of the stimulus generative probability. We have kept the two figures (Figures 7 and 8) showing the sequential effects of each of the eight models (with each cost type and each Markov order) in Methods, because we think that they provide interesting information and that they are probably expected by the reader, although it is not crucial that they appear in the flow of the main text.</p></body></sub-article></article>