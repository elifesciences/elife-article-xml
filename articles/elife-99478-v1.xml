<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">99478</article-id><article-id pub-id-type="doi">10.7554/eLife.99478</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99478.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A direct neural signature of serial dependence in working memory</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Fischer</surname><given-names>Cora</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5668-9439</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Kaiser</surname><given-names>Jochen</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6740-5000</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Bledowski</surname><given-names>Christoph</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3628-7683</contrib-id><email>bledowski@em.uni-frankfurt.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Institute of Medical Psychology</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Cooperative Brain Imaging Center</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kok</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><addr-line><named-content content-type="city">Providence</named-content></addr-line><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>23</day><month>06</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP99478</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-05-13"><day>13</day><month>05</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-05-14"><day>14</day><month>05</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.05.13.593912"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-08"><day>08</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99478.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-04-23"><day>23</day><month>04</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99478.2"/></event></pub-history><permissions><copyright-statement>© 2024, Fischer et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Fischer et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-99478-v1.pdf"/><abstract><p>Serial dependence describes the phenomenon that current object representations are attracted to previously encoded and reported representations. While attractive biases have been observed reliably in behavior, a direct neural correlate has not been established. Previous studies have either shown a reactivation of past information without observing a neural signal related to the bias of the current information, or a repulsive distortion of current neural representations contrasting the behavioral bias. The present study recorded neural signals with magnetoencephalography (MEG) during a working memory task to identify neural correlates of serial dependence. Participants encoded and memorized two sequentially presented motion directions per trial, one of which was later retro-cued for report. Multivariate analyses provided reliable reconstructions of both motion directions. Importantly, the reconstructed directions in the current trial were attractively shifted toward the target direction of the previous trial. This neural bias mirrored the behavioral attractive bias, thus reflecting a direct neural signature of serial dependence. The use of a retro-cue task in combination with MEG allowed us to determine that this neural bias emerged at later, post-encoding time points. This timing suggests that serial dependence in working memory affects memorized information during read-out and reactivation processes that happen after the initial encoding.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>serial dependence</kwd><kwd>working memory</kwd><kwd>perception</kwd><kwd>MEG</kwd><kwd>bias</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004350</institution-id><institution>German Academic Scholarship Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Fischer</surname><given-names>Cora</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Magnetoencephalographic recordings revealed a direct neural signature of serial dependence, that is, an attractive bias of current toward previous representations, which emerged at late, post-encoding stages of processing in working memory.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Our visual input can change quickly from moment to moment. Nevertheless, we represent our environment as remarkably stable and coherent across short periods of time. This coherence is thought to be supported by serial dependence (<xref ref-type="bibr" rid="bib14">Fischer and Whitney, 2014</xref>), that is, the phenomenon that a current visual object is reported as more similar to a previously encountered visual object than it actually was. This attractive bias acts most strongly between current and previous objects that are close in time and space, that are attended, and that are similar to each other both with regard to the visual feature that has to be recalled and with regard to accompanying context features (<xref ref-type="bibr" rid="bib11">Czoschke et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">Fischer et al., 2020</xref>; <xref ref-type="bibr" rid="bib14">Fischer and Whitney, 2014</xref>). Furthermore, serial dependence occurs at different levels of object processing including encoding (<xref ref-type="bibr" rid="bib33">Murai and Whitney, 2021</xref>), memorization (<xref ref-type="bibr" rid="bib7">Bliss et al., 2017</xref>), and read-out or decision (<xref ref-type="bibr" rid="bib19">Fritsche et al., 2017</xref>; <xref ref-type="bibr" rid="bib34">Pascucci et al., 2019</xref>).</p><p>While the cognitive aspects of serial dependence have been intensively studied (for reviews see <xref ref-type="bibr" rid="bib26">Kiyonaga et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Pascucci et al., 2023</xref>), its neural mechanisms are still largely unclear and a matter of active research. One important aspect that has been investigated on the neural level is the nature of the memory traces that impact current processing and the timing of their reactivation. Single-unit recordings from monkey prefrontal cortex combined with electroencephalography (EEG) and transcranial magnetic stimulation in humans have demonstrated that information about a previous stimulus was reactivated shortly before a new stimulus was encoded (<xref ref-type="bibr" rid="bib5">Barbosa et al., 2020</xref>). This study found that the strength of this pre-encoding reactivation in the prefrontal cortex predicted the attractive bias of the behavioral response to the new stimulus. Moreover, subjects showed an enhanced serial bias after single-pulse transcranial magnetic stimulation of their prefrontal cortex, which further supported a causal link between the observed reactivation and serial dependence. Another study (<xref ref-type="bibr" rid="bib2">Akrami et al., 2018</xref>) showed that memory traces from previous trials recorded from the posterior parietal cortex in rats reappeared during the inter-trial interval (ITI) of a working memory task, were present throughout the next trial, and predicted the behavioral bias. The observed results indicate that frontal and parietal regions are involved in the storage of memory traces and their transfer into current processing. Several human EEG studies have also shown reactivation signatures of the previous stimulus or a response during the current trial, establishing reactivation as an important neural prerequisite for the emergence of serial dependence (<xref ref-type="bibr" rid="bib4">Bae and Luck, 2019</xref>; <xref ref-type="bibr" rid="bib5">Barbosa et al., 2020</xref>; <xref ref-type="bibr" rid="bib16">Fornaciai and Park, 2018</xref>; <xref ref-type="bibr" rid="bib17">Fornaciai and Park, 2020</xref>; <xref ref-type="bibr" rid="bib18">Fornaciai et al., 2023</xref>; <xref ref-type="bibr" rid="bib27">Luo and Collins, 2023</xref>; <xref ref-type="bibr" rid="bib38">Ranieri et al., 2022</xref>).</p><p>Rather than looking for reactivation of past information, recent studies have investigated the neural activity elicited by the current stimulus itself. This approach provides a more direct measure of how the current neural representation is influenced by the recent past. Neural activity in the visual cortex measured with functional magnetic resonance imaging (fMRI) was influenced by orientations presented on a previous trial during the encoding and maintenance of a current orientation (<xref ref-type="bibr" rid="bib45">St. John-Saaltink et al., 2016</xref>). However, as the current orientation was either identical or differed by exactly 90° from the previous trial, it remained unclear whether this neural bias reflected an attraction or repulsion in relation to the past. Furthermore, the bias in the V1 signal was partially explained by the orientation that was presented at the same position in the previous trial, which could reflect a reactivation of the previous orientation rather than an altered current orientation. In a more recent fMRI study (<xref ref-type="bibr" rid="bib40">Sheehan and Serences, 2022</xref>), the current neural representation of an orientation in the visual cortex was repulsed from an orientation remembered in the previous trial, which was in contrast to an observed behavioral attraction. In line with this finding, a recent magnetoencephalography (MEG) study (<xref ref-type="bibr" rid="bib22">Hajonides et al., 2023</xref>) observed a neural repulsion of a current representation during encoding, in contrast to a behavioral attractive bias toward past information. The authors of both studies proposed that the attractive behavioral bias is driven by post-encoding processes. This view is supported by another computational model (<xref ref-type="bibr" rid="bib20">Fritsche et al., 2020</xref>), which states that early visual representations are repulsed and the behavioral attraction emerges during post-encoding read-out of memorized information.</p><p>Until now, a direct reflection of the attractive bias of current information on the neural level has not been observed, and it has remained unclear during which processing step memory representations are actually biased toward the past. The current study applied an inverted encoding model (IEM) analysis to neural signals measured with MEG to reconstruct the information about currently remembered stimuli (the term 'reconstruction' or 'reconstructed representation' refers to the reconstructed channel response, i.e., the output of the IEM analysis; it is not supposed to relate to the reconstruction of single-unit responses and is used throughout the manuscript for brevity and readability). We expected that a direct neural signature of serial dependence should mirror the attractive bias in behavior by showing an attractive shift of the reconstructed information toward the target information in the previous trial. The aforementioned models <xref ref-type="bibr" rid="bib20">Fritsche et al., 2020</xref>; <xref ref-type="bibr" rid="bib40">Sheehan and Serences, 2022</xref> have assumed that neural representations become attracted toward the recent past after encoding. We employed a task that allowed us to differentiate between early processes including encoding and maintenance and later, post-encoding read-out processes to inform these models and determine not only if, but also during which processing stage the neural representation becomes attracted toward the recent past. More specifically, we asked subjects to encode two motion directions and memorize them for a short delay, followed by a retro-cue that indicated which direction served as the target for an upcoming report. This retro-cue design, in combination with the high temporal resolution of MEG, enabled us to track the current representations across the whole trial to determine not only if, but also during which processing stage the neural representations become attractively biased toward the direction reported in the previous trial.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral results</title><p>Ten human participants (seven females) memorized two sequentially presented visual objects per trial (S1 and S2), while their neural signals were measured via MEG. Each participant completed two sessions with a total of 1022 trials. The objects were colored dot fields, and participants had to remember the motion direction of the dots. After a short delay, one of the motion directions was cued via the dot color (red or green, <xref ref-type="fig" rid="fig1">Figure 1a</xref>). As expected, we observed a serial dependence toward the target of the previous trial, as the reported target motion direction of the current trial was systematically attracted to the retro-cued motion direction of the previous trial. This attraction (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) followed a derivative-of-Gaussian (DoG)-shaped curve with an amplitude parameter of 3.51° (bootstrapped SD: 0.479°, lower 95% of permutations between –3.51° and 2.03°, p &lt; 0.001, <italic>R</italic><sup>2</sup> = 0.236) and a <italic>w</italic> parameter of 0.024, equaling a width of 47.37° (full width at half maximum, FWHM). We ran one-sided permutation tests (<italic>n</italic> = 10) to assess whether this attraction differed from zero. In contrast, we did not observe a significant serial dependence toward the non-target of the previous trial (amplitude: –1.02°, bootstrapped SD: 0.788°, middle 95% of permutations between –1.63 and 1.49, p <italic>=</italic> 0.206, <italic>R</italic><sup>2</sup> = 0.014; <italic>w</italic> parameter: 0.046, equaling 24.53° FWHM), which replicated our previous observations (<xref ref-type="bibr" rid="bib11">Czoschke et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">Fischer et al., 2020</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental paradigm and behavioral results.</title><p>(<bold>A</bold>) Participants had to remember two motion directions (S1 and S2) per trial (motion directions are indicated here by gray arrows for illustration only). The stimuli were either red or green. After a short delay, a retro-cue indicated which of the two motion directions (red or green) they had to recall by adjusting a randomly oriented line. (<bold>B</bold>) Response errors in the current trial were biased toward the target direction of the previous trial (pink curve), but not toward the previous non-target direction (gray curve). The <italic>x</italic>-axis shows the motion direction difference between the previous and the current target, with positive values indicating that the previous target direction was more clockwise than the current target direction. The response error on the current trial is displayed on the <italic>y</italic>-axis, with positive values indicating a clockwise deviation from the true target direction. Therefore, shifts of the response errors to the lower left and upper right quadrant indicate an attraction, whereas shifts to the upper left and lower right quadrant indicate a repulsion. The asterisk marks significant attractive serial dependence toward the previous target direction (one-sided permutation test, <italic>N</italic> = 10).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-fig1-v1.tif"/></fig><p>We also estimated serial dependence between the current and the previously cued object with regard to their color congruence. Serial dependence was modulated by task-relevant color. It was stronger when the current item had the same color as the cued item of the previous trial (amplitude = 4.02°, SD = 0. 528°, lower 95% of permutations between –3.70° and 2.41°, p &lt; 0.001, <italic>R</italic><sup>2</sup> = 0.167) than when their colors differed (amplitude = for all three epochs, we observed 2.99°, SD = 0. 538°, lower 95% of permutations between –2.99° and 1.79°, p = 0.001, <italic>R</italic><sup>2</sup> = 0.106). The amplitude difference amounted to 1.02°, p = 0.038. This replicated the context effect found in our previous study (<xref ref-type="bibr" rid="bib15">Fischer et al., 2020</xref>). The behavioral results thus showed that our two-item working memory task, performed during an MEG recording, produced reliably an attractive bias between target items across trials.</p></sec><sec id="s2-2"><title>MEG results</title><p>We applied an IEM (<xref ref-type="bibr" rid="bib8">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib9">Brouwer and Heeger, 2011</xref>; <xref ref-type="bibr" rid="bib41">Sprague and Serences, 2013</xref>) to the MEG data from all active sensors (271) within defined time windows of 100 ms length. MEG data were recorded in two sessions on different days. Specifically, we constructed an encoding model with 18 motion direction-selective channels. Each channel was designed to show peak sensitivity to a specific motion direction, with gradually decreasing sensitivity to less similar directions. In a training step, the encoding model was fitted to the MEG data of one session to obtain a weight matrix that indicates how well the sensor activity can be explained by the modeled direction. In the testing step, the weight matrix was inverted and applied to the MEG data of the other session, resulting in a response profile of ‘reconstruction strengths’, that is, how strongly each motion direction was present in a trial. When a specific motion direction was present in the MEG signal, the reconstruction strengths peaked at that specific direction and decreased with increasing direction difference. If no information was present, reconstruction strengths were comparable across all modeled directions, that is, the response profile was flat. To integrate response profiles across trials, single-trial profiles were aligned to a common center direction (i.e., 180°) and then averaged.</p><p>To quantify the accuracy of each IEM reconstruction, that is, how well the response profile represents a specific motion direction relative to all other directions, we computed the ‘reconstruction fidelity’. Fidelity was obtained by projecting the polar vector of the reconstruction at every direction angle (in steps of 1°) onto the common center (180°) and averaging across all direction angles (<xref ref-type="bibr" rid="bib37">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Sprague et al., 2016</xref>). As such, ‘reconstruction fidelity’ is a summary metric with fidelity greater than zero indicating an accurate reconstruction (see Methods for details).</p></sec><sec id="s2-3"><title>Reconstruction of the remembered directions per epoch</title><p>First, we estimated how well we could reconstruct the motion direction of both current items throughout the current trial. For this aim, we divided the current trial into three epochs, including the encoding and maintenance epochs of S1 and S2 (termed S1 and S2 epochs, respectively) and the retro-cue epoch. Specifically, during the S1 epoch, we reconstructed the direction of S1, during the S2 epoch, we reconstructed the direction of S2, and during the retro-cue epoch, we reconstructed the motion direction of the currently retro-cued S1 or S2 (current target). Our reconstruction procedure used the stimulus information during the training step by modeling the presented or memorized directions with the chosen encoding model and fitting them to the MEG data from the corresponding epoch in one MEG session by creating a weight matrix. Then the inverted weight matrix was applied to independent testing MEG data from the corresponding epoch in the other MEG session to reconstruct the direction information, which was then aligned on a single-trial level to a common center with regard to the presented or memorized direction. For example, to reconstruct S1 direction during the S1 epoch, the model was trained on data from the S1 epoch in one MEG session and applied to the S1 epoch of the other MEG session (see Methods for details).</p><p>For all three epochs, we observed successful reconstructions of the corresponding motion directions with a fidelity significantly greater than zero (S1 epoch: p <italic>&lt;</italic> 0.002, cluster extent: 300–1200 ms, mean fidelity = 0.139; S2 epoch: p <italic>&lt;</italic> 0.002, cluster extent: 0–1300 ms, mean fidelity = 0.120; retro-cue epoch: p <italic>&lt;</italic> 0.002, cluster extent: 300–1500 ms, mean fidelity = 0.115) (<xref ref-type="fig" rid="fig2">Figure 2a, b</xref>). This shows that the information about the motion direction of S1, S2, and the retro-cued target was represented in the neural signals during the respective epochs.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Reconstruction, fidelity, and systematic shifts of currently relevant motion direction.</title><p>(<bold>a</bold>) The reconstructed direction of the currently relevant motion direction across the course of a trial. The left panel shows the reconstruction of the S1 direction, the middle panel the reconstruction of the S2 direction, and the right panel the reconstruction of the cued direction (either S1 or S2). Higher reconstruction strength is depicted in yellow and lower strength in dark blue. Time points (<italic>x</italic>-axis) with direction information show a pronounced yellow area around the common center set to zero (<italic>y</italic>-axis) and darker areas with increasing distance from this center. (<bold>b</bold>) Fidelity of reconstructed direction of the currently relevant motion direction across the course of a trial. The left panel shows the fidelity of the S1 direction, the middle panel depicts the fidelity of the S2 direction, and the right panel shows the fidelity of the cued direction (either S1 or S2). Small circles show the fidelity of each participant. Colored circles indicate time points with a fidelity significantly greater than zero (cluster-based permutation test within each epoch, <italic>N</italic> = 10). (<bold>c</bold>) The reconstructed direction during all time points with a significant reconstruction fidelity was averaged within each epoch, and the maximum of the reconstructed direction was compared to the common center set to zero. A negative shift of the reconstructed mean indicates a repulsion from the target direction of the previous trial, whereas a positive shift indicates an attraction. For a more detailed visualization, the range of direction shifts from –40° to +80° is magnified, and reconstructed shift values for each participant are indicated by dots. The upper row shows the bootstrapping distributions (see section on MEG analysis for details). Significant shifts are marked with an asterisk (one-sided bootstrapping test, <italic>N</italic> = 10).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-fig2-v1.tif"/></fig><p>For completeness, we also reconstructed the direction of S1 during the S2 epoch, as the direction of S1 was still maintained in working memory in parallel to the concurrent encoding and maintenance of the S2 direction (<xref ref-type="fig" rid="fig3">Figure 3a, b</xref>). Here, we used the MEG data from the S2 epoch again, but now for S1 training, that is, the model was informed about S1 direction. Accordingly, the alignment to a common center direction during testing was done with regard to the S1 direction. We observed that during the S2 epoch, the direction of S1 could be successfully reconstructed with a fidelity significantly greater than zero (S1 during S2 epoch: p <italic>=</italic> 0.005, p<sub>Bonferroni</sub> = 0.015<italic>,</italic> cluster extent: 100–700 ms, mean fidelity = 0.065). However, its mean fidelity within the significant cluster was significantly smaller than the fidelities of the currently relevant direction during all other epochs, that is, S1 during S1 epoch, S2 during S2 epoch, and target during the retro-cue epoch (all p-values below 0.005).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Reconstruction, fidelity, and systematic shifts of S1 direction during the S2 epoch.</title><p>(<bold>a</bold>) The reconstructed direction of the S1 motion direction during the S2 epoch. (<bold>b</bold>) Fidelity of reconstructed S1 motion direction across the course of the S2 epoch. Small circles show the fidelity values for each participant. Colored circles indicate time points with a fidelity significantly greater than zero (cluster-based permutation test within each epoch, <italic>N</italic> = 10). (<bold>c</bold>) The reconstructed direction for all time points with a significant reconstruction fidelity was averaged within the S2 epoch to indicate attractive and repulsive shifts in relation to the target of the previous trials. Significant shifts are marked with an asterisk (one-sided bootstrapping test, <italic>N</italic> = 10). For details, refer to <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-fig3-v1.tif"/></fig><p>Furthermore, we tried to reconstruct the motion direction that was not retro-cued during the retro-cue epoch, that is, the non-target of a given trial that became task-irrelevant after the retro-cue. As expected, the information about the non-target item could not be reconstructed in the retro-cue phase (all cluster p-values &gt;0.05).</p></sec><sec id="s2-4"><title>Attractive shift of motion direction reconstructions as a direct signature of serial dependence</title><p>The main analysis of our study aimed to identify the neural signature of serial dependence. For this aim, we looked for an attractive bias of the reconstructed neural representations that mirrored the attractive behavioral bias by testing whether the mean of the significant reconstructions within the S1, S2, or retro-cue epochs showed positive shifts of their maxima from the common center of 180° toward the previous target (<xref ref-type="fig" rid="fig2">Figure 2c</xref>; see Methods for details). We found that the shift of the mean reconstruction of the first and second item did not differ from 0° for the S1 epoch (–2.83°, p = 0.743, bootstrapping test, p<sub>FDR</sub> = 0.870, 95% of permutations between –11.60° and 6.00°) or for the S2 epoch (–2.50°, p = 0.870, bootstrapping test, p<sub>FDR</sub> = 0<italic>.</italic>870, 95% of permutations between –7.57° and 2.11°), respectively. In contrast, for the retro-cue epoch, we found that the mean reconstruction of the current target was shifted toward the previous target (10.22°, p = 0.009, bootstrapping test, p<sub>FDR</sub> = 0.026, 95% of permutations between 1.64° and 21.97°; <xref ref-type="fig" rid="fig2">Figure 2c</xref>). In addition, there was an attractive shift of the S1 direction toward the target of the previous trial during the S2 epoch (11.69°, p &lt; 0.001, bootstrapping test, 95% of permutations between 4.96° and 31.06°; <xref ref-type="fig" rid="fig3">Figure 3c</xref>). Thus, our MEG data provided evidence for an attractive distortion of current neural representations toward the target information in the previous trial, thereby revealing a direct neural signature of serial dependence.</p></sec><sec id="s2-5"><title>Correlation between neural representation and behavioral response</title><p>To assess whether the observed item reconstructions from the MEG signals were behaviorally relevant, we correlated them with the subjects’ behavioral responses. Specifically, we calculated the circular correlation between the maximum of the stimulus direction reconstructions and the response error for each time point and epoch separately across <italic>single trials</italic>, that is, we tested whether the shift/deviation of the neural response from the true value, for example, in the clockwise (CW) direction, was accompanied by a corresponding shift/deviation of the behavioral response.</p><p>Indeed, <xref ref-type="fig" rid="fig4">Figure 4</xref> shows that the reconstructed shift of the retro-cued target item during the retro-cue phase predicted the upcoming behavior between 400 and 800 ms after the onset of the retro-cue (p <italic>=</italic> 0.003, permutation test, p<sub>Bonferroni</sub> = 0.009; mean <italic>r</italic> = 0.030). In contrast, there were no significant correlations for any other time points during the S1 and S2 epochs (cluster-based permutation test exact test, one-tailed). While the maximum of the S1 reconstruction also showed a significant shift toward the previous target, there were no significant correlations of the S1 reconstruction with the response error during the S2 epoch (no clusters with a p-value &lt;0.05).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Correlation between single-trial shift of reconstruction and upcoming response.</title><p>For each time point, the shift of the maximum of the reconstructed direction in a single trial was correlated with the response deviation from the target direction. Small circles show the <italic>r</italic>-values of each participant. Time points where the shift of the reconstructed direction significantly correlated with the upcoming response deviation are indicated by colored circles (cluster-based permutation test within each epoch).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-fig4-v1.tif"/></fig><p>For each time point, the shift of the maximum of the reconstructed direction in a single trial was correlated with the response deviation from the target direction. Small circles show the <italic>r</italic>-values of each participant. Time points where the shift of the reconstructed direction significantly correlated with the upcoming response deviation are indicated by colored circles (cluster-based permutation test within each epoch).</p><p>The presented single trial-wise correlation between the neural shift and behavioral shift did not directly incorporate the behavioral bias toward the previous trial. Thus, in order to relate the neural attractive shift and the behavioral indicators of serial dependence more directly, we performed an additional correlation analysis on aggregated data on the <italic>between-subject</italic> level. In detail, we correlated the individual neuronal shift during the retro-cue epoch with the two individual parameter fits of the behavior shift, that is, amplitude (<italic>a</italic>) and tuning width (<italic>w</italic>). In line with the correlation analysis on single-trial level, the analysis on the <italic>between-subject</italic> level also revealed a significant correlation between the <italic>w</italic> parameter of serial dependence and the neural shifts for the retro-cue epoch. Details of this correlation analysis are displayed in Appendix 1.</p></sec><sec id="s2-6"><title>Reactivation of the previous target direction</title><p>Finally, we used our IEM analysis approach to replicate previous results that have shown a reactivation of memory traces from the previous trial before the stimulus presentation of the current trial (<xref ref-type="bibr" rid="bib5">Barbosa et al., 2020</xref>). Specifically, we reconstructed the motion direction of the target from the previous trial during the 1 s of the ITI immediately preceding the current trial (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Consistent with previous findings from monkey single cell and human EEG recordings (<xref ref-type="bibr" rid="bib5">Barbosa et al., 2020</xref>), we observed that the information about the previous target was reactivated just prior to the onset of the next trial. Direction reconstructions showed a fidelity significantly greater than zero during a time period at the end of the ITI (p <italic>=</italic> 0.019, cluster extent: –200 to 100 ms (relative to S1 onset), mean fidelity = 0.069). Importantly, we also tracked the information of the previous target throughout the whole current trial to test whether it was reactivated also during the processing of the current items. Interestingly, we found that the target from the previous trial was reactivated once more, but at a later time period during the current trial, that is, when the retro-cue indicated which item of the current trial was the target for the upcoming response (p = 0.040, cluster extent: 2700–2900 ms relative to trial onset, mean fidelity = 0.057). In contrast, we found no evidence of previous target reactivations during the encoding or maintenance of current items (no clusters with a p-value &lt;0.05).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Reconstruction and fidelity of previous target direction.</title><p>(<bold>a</bold>) The target direction of the previous trial was reconstructed throughout the last second of the inter-trial interval (ITI) and the whole following trial. (<bold>b</bold>) Fidelity of reconstructed direction of the previous target. Small circles show the fidelity of each participant. Colored circles indicate time points with a fidelity significantly greater than zero (cluster-based permutation test within each epoch, <italic>N</italic> = 10). For details, refer to <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-fig5-v1.tif"/></fig><p>Additionally, in order to test whether a reactivation of the previous target could explain the neural attractive shift observed in the current trial, we reconstructed the motion direction of the previous target from MEG data recorded during the different epochs of the current trial. Specifically, we trained the encoding model either on the presented stimuli in the S1 and S2 epochs or on the currently relevant item during the retro-cue epoch, respectively, and tried to reconstruct the target direction of the previous trial within each epoch. We observed that there was no cross-reconstruction between the current and the previous representation during the retro-cue epoch, which indicates that the observed attractive shift of the current target reconstruction following the retro-cue was not driven by a reactivation of the previous target in the same neural code. However, during the beginning of the S2 epoch, we observed a significant cross-reconstruction, that is, previous target reactivation co-occurred with the reconstruction of S2 while it was presented to the subjects. The complete analysis and results are described in Appendix 1.</p></sec><sec id="s2-7"><title>Eye movement control</title><p>To control for influences of eye movements on the MEG data, we recorded horizontal and vertical electrooculograms to identify blinks and eye-movement-related independent components of the MEG data that were removed during our MEG preprocessing (see Methods). In addition, we also recorded continuous gaze position with a higher spatial resolution using an eye tracker. We used the eye-tracking data to estimate whether there was a systematic relationship between eye movements and the motion direction of currently processed items in the S1, S2, or retro-cue phases. We found that gaze directions were systematically related to presentation and memorization of the stimulus direction (S1 and S2 epoch) and its cue-based retrieval (retro-cue phase). They also varied considerably between subjects. Most importantly, gaze directions were not systematically related to the MEG data, thus ruling out that they had mainly driven our MEG results. The details of the eye movement control analysis are displayed in Appendix 1. Importantly, the central finding of our study is that serial dependence emerged at a later post-encoding stage of object processing in working memory, irrespective of any possible eye movements.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The current study aimed to identify a direct neural signature of serial dependence. Previous studies searching for neural markers of this attractive bias have investigated either the reactivation of information from the past trial in the current trial or have tried to directly capture biases of current item representations by information from the past. The present study found evidence for both types of neural correlates. We replicated reactivations of target representations of the previous trial. More importantly, our study provides the first evidence for an attractive bias of neural representations in the current trial toward information from the previous trial, which mirrors the behavioral effects of serial dependence and as such represents a neural signature of serial dependence.</p><p>The reactivation of past information in the current trial is crucial because an attractive bias can only occur when information from the past has left a memory trace that interacts with the processing of the current object. <xref ref-type="bibr" rid="bib5">Barbosa et al., 2020</xref> have shown that the working memory trace of an object representation from a previous trial, measured via decoding of both neural activity in monkey prefrontal cortex and human EEG signals, was reactivated just before new visual input was presented in the current trial. This was in line with modulations of early visual evoked potentials in human EEG by past stimulus information found in numerosity tasks (<xref ref-type="bibr" rid="bib16">Fornaciai and Park, 2018</xref>; <xref ref-type="bibr" rid="bib17">Fornaciai and Park, 2020</xref>). Using human EEG, <xref ref-type="bibr" rid="bib4">Bae and Luck, 2019</xref> observed the reactivation of past stimulus information also during encoding and maintenance phases in the current trial of an orientation working memory task. In our study, we applied a similar analysis approach and tracked the reconstructed motion direction of the target item from the previous trial both during the ITI, that is, prior to the encoding of the new stimulus, and throughout the whole current trial. Similar to the previous studies, we also found that the memory trace of the previous target was reactivated just prior to the onset of the current trial and later in the current trial after the retro-cue indicated the current target.</p><p>Reactivations of information from the previous trial may be seen as crucial but indirect neural correlates of serial dependence. A memory trace of a previously relevant representation is an important prerequisite for the emergence of serial dependence, since a current representation can only be biased by integrating the information from the past into the present trial. However, our main goal was to observe the direct effect of this past information on current representations. More specifically, we asked whether neural representations of current information are biased toward the recent past in the same way as the behavioral response. Previous studies that aimed to measure neural correlates of serial dependence directly found repulsive rather than attractive distortions of neural representations in relation to the recent past, which were in contrast to the attractive bias in the behavioral response (<xref ref-type="bibr" rid="bib22">Hajonides et al., 2023</xref>; <xref ref-type="bibr" rid="bib40">Sheehan and Serences, 2022</xref>). The repulsive neural biases were attributed to visual adaptation during early perceptual processes. In contrast to these previous reports, the present study found attractive biases of representations in the present trial toward information from the previous trial that were consistent across the neural and behavioral level.</p><p>We propose that our combination of a retro-cue paradigm with the high temporal resolution of MEG accounts for the successful demonstration of serial dependence at the neural level in the present study. <xref ref-type="bibr" rid="bib40">Sheehan and Serences, 2022</xref> recorded fMRI while participants made a delayed report about a single memorized grating orientation. In contrast to the attractive behavioral bias, the orientation reconstructed from the fMRI signals measured in the visual cortex was repulsed away from the orientation presented in the previous trial. The authors proposed a computational model in which early encoding-related signals are repulsed from the recent past. The attraction observed in behavior was attributed to a later decoding process that overcomes the repulsion of sensory signals and leads to serial dependence but is not directly detectable in hemodynamic response patterns. This is consistent with the notion of an ideal observer model that combines two steps of object processing, including an early encoding and a later decoding of current information to explain serial dependence (<xref ref-type="bibr" rid="bib20">Fritsche et al., 2020</xref>). According to this model, a repulsive bias occurs early during encoding, whereas an attractive bias is due to the read-out of the current object representation in a Bayesian history-dependent manner. Previous behavioral studies have already identified read-out as a crucial processing stage for serial dependence. <xref ref-type="bibr" rid="bib19">Fritsche et al., 2017</xref>, for example, asked participants either to remember and report the orientation of a grating after a short delay (working memory task) or to compare two simultaneously presented orientations directly (perception task). They found a repulsive bias in the perception task, when the grating was still visually present and compared to another grating, whereas in the working memory task, the current target orientation was attracted toward the orientation reported in the preceding trial. This supported the emergence of serial dependence at a late, post-perceptual processing stage.</p><p>Similarly, <xref ref-type="bibr" rid="bib22">Hajonides et al., 2023</xref> observed a repulsion of currently remembered orientations as decoded from MEG signals, while the behavioral recall was attracted toward the past. Participants performed a working memory task with two sequentially presented sample stimuli similar to our study. However, instead of using a temporally separated retro-cue, <xref ref-type="bibr" rid="bib22">Hajonides et al., 2023</xref> presented a cue that indicated the target for later recall simultaneously with the second sample stimulus. As participants knew which item would be the response target as soon as the second item was presented, the read-out process for a specific item could not be disentangled from the encoding or maintenance stages. Multivariate analysis of MEG signals revealed that the reconstructed orientation information during and shortly after stimulus presentation was repulsed from the orientation recalled in the previous trial. In line with <xref ref-type="bibr" rid="bib40">Sheehan and Serences, 2022</xref>, the authors assumed that the observed repulsion at the neural level reflected visual adaptation, whereas the attraction of the neural representation may have occurred at later processing stages, which were not accessible by their analysis. <xref ref-type="bibr" rid="bib22">Hajonides et al., 2023</xref> speculated that the integration of past memory traces, putatively stored in parietal areas (<xref ref-type="bibr" rid="bib2">Akrami et al., 2018</xref>), only happened during the behavioral response. This would mean that the neural representation of the current representation is not affected by serial dependence, but that this bias emerges as a result of integration processes during the response.</p><p>The present study provided support for the notion that the neural markers of serial dependence occur during post-perceptual phases of a working memory task, which is in agreement with existing models and behavioral findings (<xref ref-type="bibr" rid="bib20">Fritsche et al., 2020</xref>; <xref ref-type="bibr" rid="bib22">Hajonides et al., 2023</xref>; <xref ref-type="bibr" rid="bib40">Sheehan and Serences, 2022</xref>). The use of a retro-cue task, which facilitates the segregation of earlier and later processing stages, in combination with motion direction reconstructions from MEG signals, revealed shifts of the current representation toward the motion direction of the target in the previous trial. We observed such an attractive bias only at post-encoding processing stages in two time windows: First, for S1 during and after the presentation of S2 and, second, for the cued target stimulus after the presentation of the retro-cue. This demonstrates that serial dependence can be observed on the neural level as a distortion of current neural representations that mirrors the attractive bias in behavior. This direct neural signature of serial dependence emerges after encoding but prior to the response, thus speaking against the proposal that serial dependence is attributable to response-related processes (<xref ref-type="bibr" rid="bib22">Hajonides et al., 2023</xref>).</p><p>To further underscore the relevance of the observed neural distortions, we examined whether the reconstructed neural representation predicted the behavioral response deviation. Indeed, we observed a positive correlation between the deviations of the neural reconstruction and response errors on a single-trial level. Interestingly, this correlation was found during the presentation of the retro-cue, coinciding with the time point at which the neural representation of the current target stimulus was biased toward the recent past. This observation was further supported by a positive correlation between the attractive shift of the neural reconstruction during the retro-cue epoch and a behavioral measure of serial dependence on the between-subject level. In addition, we observed a reactivation of previous target information during the retro-cue presentation. The distortion of the current neural representation could thus be the result of an integration of past information. Taking these findings together, the retro-cue period emerges at the time point when different neural markers of serial dependence appear together. This suggests that the selective read-out of memorized information for an upcoming report might be a crucial process for serial dependence during working memory.</p><p>The neural representation of S1 already became attracted toward the target of the previous trial when S2 was presented. Notably, the reconstruction of the S1 direction had dropped to baseline and reappeared during the S2 epoch. This fits well with the observation that memory content that has become neurally silent can be successfully reconstructed from the impulse response elicited by a ‘ping’ or probe stimulus (<xref ref-type="bibr" rid="bib49">Wolff et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Wolff et al., 2017</xref>). This impulse-driven reconstruction is thought to reflect a ‘hidden state’ of working memory, in which unattended information is stored. Therefore, the observed S1 reconstruction elicited by S2 presentation in our study likely reflects the same type of memory read-out, which might have driven the observed neural distortion. On the other hand, S1 had been maintained for a certain time when S2 was presented. As <xref ref-type="bibr" rid="bib7">Bliss et al., 2017</xref> observed, serial dependence in behavior increases as a function of delay duration, so the distortion of the neural representation of S1 during the S2 period could also reflect an increasing bias during working memory maintenance.</p><p>Several recent studies have shown that serial dependence operates already during perception (<xref ref-type="bibr" rid="bib28">Manassi et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Murai and Whitney, 2021</xref>). In the current study, the neural representation of the current information became biased only after encoding. However, we did observe a reactivation of previous information as an indirect marker of serial dependence before and during the onset of S1, replicating previous results (<xref ref-type="bibr" rid="bib5">Barbosa et al., 2020</xref>). This early reactivation of past information could reflect a comparison of prior information with new visual input. <xref ref-type="bibr" rid="bib10">Cicchini et al., 2021</xref> proposed a predictive coding framework, in which priors informed by past visual input are compared against incoming visual information during early encoding. This comparison results in a prediction error, which determines whether a current stimulus will be biased toward the past. In combination with the observed distortion of the neural representation, this could indicate a two-step process: New visual information is compared against past information during early encoding processes, and the integration of past and current information happens during later processing stages, before the actual report is given.</p><p>How can these findings of serial dependence operating already during perception (<xref ref-type="bibr" rid="bib14">Fischer and Whitney, 2014</xref>; <xref ref-type="bibr" rid="bib28">Manassi et al., 2018</xref>) be reconciled with other behavioral studies and our findings that pinpoint the emergence of serial dependence at post-perceptual processing stages (<xref ref-type="bibr" rid="bib7">Bliss et al., 2017</xref>; <xref ref-type="bibr" rid="bib19">Fritsche et al., 2017</xref>)? One possibility is that serial dependence does not operate at a single but rather at different levels of object processing, including early perceptual and later, memory-related processes (<xref ref-type="bibr" rid="bib48">Whitney et al., 2022</xref>). Moreover, perception and working memory might not be as different as they appear: both functions build mental representations from sensory input, involving feedforward and feedback processing. Hence, encoding and decoding of information, including the neural computations in lower- and higher-level cortical areas, represent integral parts of both perception and working memory. Thus, in a perceptual task that requires an immediate response when visual input is still physically present, read-out of the noisy information via decoding is closely intertwined with its encoding. In working memory tasks that require encoding and memorization of several items, the read-out of a single item is typically postponed: It starts when a retro-cue or probe indicates which memorized item is task-relevant. Serial dependence that operates during the read-out stage of object processing appears to happen both early in perception and later in working memory tasks. However, as shown in this study, in order to identify the neural basis of serial dependence, a multi-item working memory task offers the advantage of separating different processing stages to isolate the time point when an object representation is actually distorted. Furthermore, while the present results indicate a particular importance of post-encoding processes for serial dependence in working memory, they do not suggest that serial dependence could not emerge during encoding. First, we cannot exclude that our data analysis was not sensitive enough to detect small shifts in the neural signals during encoding, especially as our analysis involved averaging across time points to increase the signal-to-noise ratio. Second, with the used motion direction stimuli, reconstruction strength built up slowly during the stimulus presentation, reaching its maximum only after stimulus offset. Possibly, different stimulus material with faster build-ups might help to track the neural representation during early encoding stages. Another possibility why serial dependence emerged in our study only during the retro-cue epoch is that the neural representation of the stimulus during its post-encoding processing was noisier than during its encoding and thus potentially more susceptible to bias. However, we found comparable time courses of the reconstruction fidelities between S1, S2, and retro-cue epochs. On the other hand, a biased representation, which represents a small and hard-to-detect neural effect, should be easier to observe for less noisy data. The fact that we found a significant neural bias only during the potentially ‘noisier’ retro-cue epoch makes our finding even more noteworthy.</p><p>It is also worth mentioning that the neural attractive bias in our study was about three times larger than the behavioral attraction bias. As both measures provided an identical metric (angle degree), one could expect that their magnitudes should be directly comparable. However, we speculate that these magnitudes inform only about the direction of the bias and their significant difference from zero, thus they operate on different scales and are not directly comparable. In line with this, <xref ref-type="bibr" rid="bib23">Hallenbeck et al., 2021</xref> showed that fMRI-based reconstructed orientation bias and behavioral bias correlated on both individual and group levels, despite strong magnitude differences.</p><p>In summary, our study provides a direct neural signature of serial dependence that mirrors the attractive behavioral bias. This demonstrates that serial dependence in working memory directly acts on memory representations and biases them toward the past. The attractive distortion of the current representation happened after object encoding, suggesting that read-out processes during object decoding are important for the emergence of serial dependence.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">MATLAB, 2019</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/">https://www.mathworks.com/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_001622">SCR_001622</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Circular statistics</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://de.mathworks.com/matlabcentral/fileexchange/10676-circular-statistics-toolbox-directional-statistics">https://de.mathworks.com/matlabcentral/fileexchange/10676-circular-statistics-toolbox-directional-statistics</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_016651">SCR_016651</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">BADS</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib1">Acerbi and Ma, 2017</xref></td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1705.04405">https://arxiv.org/abs/1705.04405</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">EzyFit v2.44</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://de.mathworks.com/matlabcentral/fileexchange/10176-ezyfit-2-44">https://de.mathworks.com/matlabcentral/fileexchange/10176-ezyfit-2-44</ext-link></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Python 38</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.anaconda.com/docs/main">https://www.anaconda.com/docs/main</ext-link></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Spyder v.4.1.5</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.spyder-ide.org/">https://www.spyder-ide.org/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_017585">SCR_017585</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">autoreject v0.2.2</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://autoreject.github.io/stable/index.html">https://autoreject.github.io/stable/index.html</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_022515">SCR_022515</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">MNE software v0.22.0</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://mne.tools/stable/index.html">https://mne.tools/stable/index.html</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_005972">SCR_005972</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">NumPy v1.19.2</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://numpy.org/">https://numpy.org/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_008633">SCR_008633</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Pandas v1.1.3</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://pandas.pydata.org/">https://pandas.pydata.org/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_018214">SCR_018214</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">SciPy v1.5.2</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://scipy.org/">https://scipy.org/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:SCR_008058">SCR_008058</ext-link></td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Experimental design</title><sec id="s4-1-1"><title>Subjects</title><p>Thirteen participants were recruited from the Goethe-University Frankfurt and the Fresenius University of Applied Sciences Frankfurt. All subjects reported normal or corrected-to-normal vision and were screened for red–green blindness. One subject participated as a pilot subject for only one MEG session, one subject was excluded after the first behavioral training session because of dependency on glasses, and one subject dropped out after the first MEG session due to exhaustion because of the MEG setting. This resulted in a sample of 10 subjects (3 male), aged between 22 and 30 years (mean: 25.2 years). All subjects gave informed consent and received either a compensation of €10/hr or course credit. The study was approved by the Ethics Committee of the Medical Faculty of the Goethe-University Frankfurt am Main.</p><p>The choice for the sample size was based on a priori power calculation. At the time of the sample size calculation, there were no comparable EEG or MEG studies to inform our power calculation. Thus, we based our calculation on a robust serial dependence effect that we found in a behavioral study including four different experiments with overall more than 100 participants with 1632 trials each (<xref ref-type="bibr" rid="bib15">Fischer et al., 2020</xref>). Based on the contrast between target and non-target with an effect size of 1.359 in Experiment 1, a power analysis with 80% desired power led to a small, estimated sample size of six subjects. However, we expected that the detection of the neural signature of this effect would require more participants. Thus, we based our final power calculation on a much smaller behavioral effect, that is, the modulation of serial dependence by the context-feature congruency. We focused again on the results from Experiment 1 of our previous study that used color as the context feature for retro-cueing (<xref ref-type="bibr" rid="bib15">Fischer et al., 2020</xref>), as we planned to use the same paradigm for the MEG study. This color congruency effect resulted in a more conservative power estimate: Based on an effect size of 0.856 in that experiment, a sample size of <italic>n</italic> = 10 should yield a power of 80% with two MEG sessions per subject.</p></sec></sec><sec id="s4-2"><title>Experimental paradigm</title><sec id="s4-2-1"><title>Stimuli</title><p>Random dot patterns (RDP) were presented centrally on the screen and consisted of 200 dots colored in red (RGB: 255, 0, 0) or green (RGB: 0, 86.4105, 0) on a black background. The green was adjusted to match the luminance of the red in DKL color space and then transferred back to RGB space. The dots were presented within an invisible circular aperture which had a radius of 7.5° of visual angle. The dots had a diameter of 0.15° of visual angle and were placed randomly within the circular aperture of the RDP at stimulus onset. The dots moved with a velocity of 3.5°/s and were fully coherent in a direction randomly drawn from a pool of directions between 5° and 355° spaced 10° from one another, therefore avoiding cardinal directions. Dots reaching the edge of the aperture were repositioned randomly on the edge of the opposing side of the aperture, so that dot density was kept constant throughout the presentation. Throughout the whole experiment, a white fixation square with a diagonal of 0.15° of visual angle was presented centrally on the screen, except for the cue presentation, when the fixation square changed its color to red or green to cue which item should be reported. The item was reported by adjusting a randomly oriented line to match the reported direction. The response line was white, with a width of 0.6° and a length equaling the dot field radius. The starting point of the line was the fixation square, and the end point could be altered so that the line could point in all possible directions.</p></sec><sec id="s4-2-2"><title>Procedure</title><p>The experiment consisted of a delayed-estimation task. Specifically, each trial began with the presentation of the first stimulus (S1) for 200 ms followed by a noise mask for 100 ms consisting of dots moving with 0% coherence (i.e., randomly) and of the same color as the preceding RDP. After a 1000-ms interval (ISI), the second stimulus (S2) and its noise mask were presented for 200 and 100 ms, respectively (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Subjects were asked to memorize the motion direction of both RDP for a delay of 1000 ms. Then the fixation square changed its color to red or green for 1500 ms, thereby cueing which motion direction became a target item and had to be reported. Immediately after cue offset, a randomly oriented line was presented. Subjects had to report the target motion direction by rotating the line by moving an MEG-compatible track ball horizontally. No time limit was given for the response, and subjects were encouraged to work as precisely as possible. After adjusting the line direction, subjects had to confirm their response by pressing the left trackball button. At the end of each trial, a fixation screen of 2000–2500 ms (jittered in steps of 10 ms, randomized) was presented. Subjects were instructed to fixate the fixation square throughout the whole experiment.</p><p>Between trials, 36 possible direction differences (–170°:10°:180°) were balanced so that every possible direction difference between the items of the current trial and the previous target occurred equally often. This was done with the restriction that the items of the current trial were not allowed to have the same motion direction difference to the previous target item, that is, cued for report in the previous trial. Thereby, it was ensured that the items within a trial could not have the same motion direction. Furthermore, the congruence of color and temporal position between target items of the previous and current trial was balanced, which automatically led to a balancing for the non-target item of the current trial, too, and ensured that in each trial the two items had different colors from one another.</p><p>Every subject completed 1022 trials in two sessions on different days. Each session lasted approximately 90 min and was divided into 7 blocks of 73 trials with breaks in between. After the completion of each block, subjects received feedback (‘You deviated by more than 30° in XX% of trials.’ – German: ‘Du bist in XX% der Durchgänge um mehr als 30° abgewichen.’) about their performance in the previous block, displayed on the screen. Subjects were seated at a viewing distance of approximately 50 cm from the display. MATLAB software with the Psychophysics Toolbox extensions was used for stimulus generation and presentation. A PROPixx projector (VPixx Technologies Inc) with a resolution of 1920 × 1080 and running with a 120 Hz refresh rate was used.</p><p>Prior to the two MEG sessions, each subject was invited for a behavioral practice session. This session consisted of eight blocks of the task and was therefore slightly longer than the MEG experiment. We screened the participants for red–green blindness, checked MEG and MRI contraindications, and instructed them in the behavioral task before participants started to practice the task. In addition to the feedback presented at the end of each block as in the MEG part of the study, subjects received trial-wise feedback in this first session. If their response deviated more than 30° from the cued motion direction, we presented feedback (‘&gt;30°!’). Thereby they could practice to be as precise as possible for the MEG sessions.</p></sec></sec><sec id="s4-3"><title>MEG recording and preprocessing</title><sec id="s4-3-1"><title>Data acquisition</title><p>We recorded MEG with a whole-head MEG system (Omega 2005; VSM MedTech Ltd, Port Coquitlam, Canada) with 275 axial gradiometers (271 active) at a sampling rate of 1200 Hz and without online filtering. Additionally, we recorded electrocardiogram (ECG), vertical and horizontal electrooculograms (EOG) as well as continuous gaze position and pupil dilation of the right eye by an MEG-compatible eye tracker (Eyelink CL 1000, SR Research Ltd). Head position was continuously recorded via head localization coils placed at the nasion and above both ear canal entrances using ear plugs. The initial head position was saved at the beginning of the first MEG session and presented to the participants for repositioning at the beginning of the second session as well as throughout each session if repositioning was necessary. Behavioral responses were recorded with an MEG-compatible trackball (Current Designs Inc), enabling subjects to continuously recall motion directions.</p></sec></sec><sec id="s4-4"><title>Preprocessing</title><p>MEG data were preprocessed using the python-based M/EEG analysis toolbox MNE (version 0.22.0; <xref ref-type="bibr" rid="bib21">Gramfort et al., 2013</xref>). The MEG signal was first notch filtered at 50 Hz and up to 250 Hz in steps of 50 Hz to remove line noise and then cut into trials from 1000 ms before S1 onset until 500 ms after response onset. Trials containing SQUID jump artifacts were manually identified and excluded. The remaining trials were then high-pass filtered (1 Hz) and decomposed via independent component analysis (ICA) with the FastICA method implemented in MNE. The decomposition was then applied to the notch-filtered continuous data, and ICs representing cardiac and ocular activity were identified via correlation with ECG and EOG signals. The notch-filtered continuous data were then low-pass filtered at 25 Hz and cut for the respective analysis. To analyze reactivations of the previous target direction, the data were cut into one long epoch (last second of the ITI up until the end of the retro-cue delay). For the analysis regarding the directions of the current trial, we used three epochs per trial: S1 encoding and maintenance (called S1 epoch), S2 encoding and maintenance (called S2 epoch), and retro-cue presentation and delay (called retro-cue epoch). The epochs started 200 ms before stimulus/retro-cue onset and lasted until 1500 ms after stimulus/retro-cue onset. For the S1/S2 epochs, only 1300 ms after stimulus onset were included in the analysis as those reflected the presentation + delay time. Those epochs were baseline-corrected (–200 to 0 ms), the previously identified ICs reflecting cardiac and ocular activity were removed, and the data resampled at 300 Hz.</p></sec><sec id="s4-5"><title>Statistical analysis</title><sec id="s4-5-1"><title>Behavioral analysis</title><p>First, we excluded trials in which the response error was at least 3 SDs higher than the subject’s mean response error, or in which the response time exceeded 20 s, indicating potential attentional lapses. We also excluded the first trial of each block, as serial dependence cannot occur on those trials, and demeaned the response errors by subtracting the overall mean response error of a participant from each individual response error to remove general individual response biases independent of serial dependence.</p><p>The evaluation of serial dependence was based on individual response errors, defined as the deviation between presented and entered direction. The errors were sorted regarding the difference between the target stimulus of the current trial and the target stimulus from the previous trial, as well as the relation of difference between the current item and the item of the previous trial (CW or counter-clockwise [CCW]). The difference was computed by subtracting the direction of the current item from the direction of the item of the previous trial. Therefore, when the current item was oriented more CW or more CCW, this resulted in a negatively or positively signed distance, respectively. A mean response error for a signed distance (distance * relation) deviating from 0 indicated a systematic response bias. When the sign of this systematic bias matched the sign of the distance between the directions, it indicated an attractive response bias. Conversely, an opposite sign of the systematic bias compared to the signed distance indicated a repulsive response bias. In addition, the signed response errors were sorted according to the color congruence between the two items (same vs. different color). The individual mean response biases were used to evaluate the serial dependence per color congruence level. We fitted the first derivative of a Gaussian curve DoG; for example, (1), a model which is usually used to describe serial dependence. The DoG, given by<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi><mml:mi>c</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle y=xawce^{-\left (wx\right)^{2}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>was fitted to the pooled mean response biases of all subjects (similar to the procedure by <xref ref-type="bibr" rid="bib19">Fritsche et al., 2017</xref>) per factor level, that is, one data point per subject and distance for the respective factor level. In the DoG, <italic>x</italic> is the relative direction difference of two stimuli, <italic>a</italic> is the amplitude of the curve peak, <italic>w</italic> scales the curve width, and <italic>c</italic> is the constant <inline-formula><alternatives><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>y</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$y\sqrt{2}/e^{-0.5}$\end{document}</tex-math></alternatives></inline-formula>. The <italic>w</italic> parameter was constrained to a value range of 0.01–0.1. We optimized the log likelihoods of our curve fitting using Bayesian adaptive direct search (BADS; <xref ref-type="bibr" rid="bib1">Acerbi and Ma, 2017</xref>). BADS alternates between a series of fast, local Bayesian optimization steps and a systematic, slower exploration of a mesh grid. To estimate the variability of the parameters <italic>a</italic> and <italic>w</italic>, we bootstrapped the DoG curve fit 1000 times, sampling the data with replacement on each iteration, and computed the standard deviation of the resulting bootstrapped distributions of <italic>a</italic> (see <xref ref-type="bibr" rid="bib15">Fischer et al., 2020</xref>) for a similar procedure. To assess the significance of serial dependence on a group level, we used permutation tests, that is, we randomly inverted the signs of each participant’s mean response error, fitted a new DoG model to the pooled group data, and collected the resulting amplitude parameters a in a permutation distribution. We repeated this permutation procedure 1000 times and reported the percentage of permutations that led to equal or higher values for <italic>a</italic> than the one estimated for the empirical data as p-values. The significance level was set to <italic>α</italic> = 0.05 (one-sided permutation test).</p></sec></sec><sec id="s4-6"><title>MEG analysis</title><sec id="s4-6-1"><title>IEM analysis</title><p>To reconstruct motion directions from neural signals, we used the so-called IEM technique (<xref ref-type="bibr" rid="bib44">Sprague et al., 2018</xref>). We built an encoding model characterizing motion direction-selective responses in the MEG signal with the underlying assumption that the MEG signal in each sensor reflects a weighted sum of neural activity revealed by different motion directions. Our model consisted of a basis set of 18 channels spanning the room of 0–360° with centers in steps of 20°. The channels had the shape of sinusoids raised to the 18th power (adapted from <xref ref-type="bibr" rid="bib12">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib42">Sprague, 2016</xref>). This model was applied to the MEG data, which was separated into a training and a test dataset. For each subject, we trained the model on one MEG session and tested it on the other one in two iterations, so that each MEG session was once training and once test data, and training and test data were independent. To analyze the currently relevant motion directions, we applied this reconstruction approach to the three types of epochs (S1 epoch, S2 epoch, and post-cue epoch) separately, and in each epoch, the currently relevant direction was the aim of the reconstruction (S1 epoch: S1 direction, S2 epoch: S2 direction, post-cue epoch: cued target direction). To increase the signal-to-noise ratio, the epoched data were averaged across time bins of 100 ms, centered on 50 ms, 150 ms, etc. after epoch onset. This led to 13 analysis time points for the S1 and S2 epoch and 15 analysis time points for the post-cue epoch. For each epoch, the directions were reconstructed for each time point separately in a time point by time point fashion. To check for reactivations of the previous target direction, we applied the same analysis on the last second of the ITI and the whole time course of the current trial, resulting in 51 analysis time points. This time, the aim of the reconstruction was the previous target direction; therefore, the data were trained and tested on this direction.</p><p>In the first step, we modeled the activation of each sensor as a weighted sum of filter responses:<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>W</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle B_{1}=\ C_{1}W$$\end{document}</tex-math></alternatives></disp-formula></p><p><italic>B</italic><sub>1</sub> is the MEG signal in each sensor at a given time point (<italic>n</italic> trials * <italic>n</italic> sensors), <italic>C</italic><sub>1</sub> the modeled response of each channel given the presented direction in each trial (<italic>n</italic> trials * <italic>n</italic> channels) and <italic>W</italic> a weight matrix representing the contribution of each channel to the measured signal in each sensor (<italic>n</italic> channels * <italic>n</italic> sensors). <italic>W</italic> was estimated by using ordinary least-squares regression:<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>C</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle \hat{W} = \left(C_1^T C_1\right)^{-1} C_1^T B_1$$\end{document}</tex-math></alternatives></disp-formula></p><p>In the second step, we inverted <italic>W</italic> and applied it to the independent test MEG data <italic>B</italic><sub>2</sub> (<italic>n</italic> sensors * <italic>n</italic> trials) to compute the estimated channel responses <italic>Ĉ</italic><sub>2</sub> (<italic>n</italic> channels * <italic>n</italic> trials):<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle \hat{C}_2 = \left(\hat{W}^T \hat{W}\right)^{-1} \hat{W}^T B_2$$\end{document}</tex-math></alternatives></disp-formula></p><p>The estimated channel responses <italic>Ĉ</italic><sub>2</sub> were transformed from the channel space back to the direction space by weighting <italic>Ĉ</italic><sub>2</sub> with each channel’s sensitivity from the basis set. Those reconstructed channel responses were then circularly shifted to a common center (180°). This whole reconstruction procedure was done separately per subject, session, epoch, and time point, and this was iterated 20 times. Across those iterations, the centers of the basis set were shifted by 1° so that the channel centers were evenly spaced in steps of 1° across the whole direction space as a result of those iterations. The single-trial reconstructions were then analyzed in two different ways, described in the following paragraphs.</p></sec><sec id="s4-6-2"><title>Shifts of the reconstructed direction</title><p>The main goal of our analysis was to examine potential shifts of the neural representation in relation to the target item of the previous trial. Therefore, the single-trial reconstructions were ordered in two groups, those with a previous target that was CW oriented in relation to the currently relevant item and those with a previous target that was CCW oriented. The CCW reconstructions were flipped along the direction space. Thereby, for both CW and CCW trials, a negative deviation of the maximum of the reconstruction from 180° indicated an attraction toward the previous target, whereas a positive deviation indicated a repulsion. Those reconstructions were then first averaged within each possible motion direction and then across them to account for different presentation numbers of the directions. This averaged reconstruction was obtained for each iteration (see above) and then later averaged across sessions. Thereby, the analysis resulted in a reconstruction per participant, epoch, and time point. In the next step, the fidelity of those reconstructions was assessed per epoch and time point to identify time points with significant direction information in the MEG signal. A fidelity above 0 indicates a meaningful direction signal and was obtained by projecting the polar vector of the reconstruction at every direction angle (in steps of 1°) onto the common center (180°). The length of this projected vector indicates the information strengths of the reconstruction at each angle. The fidelity <italic>F</italic> was obtained by averaging those information strengths:<disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle F=mean\left (r\left (\theta \right) \cos \left (\theta \right)\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>We identified the time points in each epoch with significant direction reconstruction fidelity by computing a one-sided cluster-based permutation test (as implemented in MNE) against zero. As the effect of the neural shift was expected to be very small, we averaged the reconstructions in each epoch only over those time points that showed significant reconstruction fidelity and thus interpretable data. To examine systematic shifts, we then tested if the maximum of the reconstruction was systematically different from the common center (180°). For display purposes, we subtracted the reconstructed maximum from 180° to compute the direction shifts. A positive shift thus reflected attraction, and a negative shift reflected repulsion.</p></sec><sec id="s4-6-3"><title>Statistical inference of shifts</title><p>To assess the significance of potential shifts, we used a bootstrapping procedure similar to <xref ref-type="bibr" rid="bib13">Ester et al., 2020</xref>. To this aim, we randomly selected reconstructions from 10 participants (with replacement), then computed the mean reconstruction over the resampled participants and collected the shift. This was done on 10,000 iterations. The distribution of shifts was then used to examine if the observed shift was significantly larger than zero. A shift was significant when 95% of the resampling iterations led to a shift equal to or higher than 0°, that is, we conducted a one-sided bootstrapping test as we expected an attraction, which was indicated by a shift larger than 0°. To obtain an indicator for the variability of the shifts, the middle 95% of shifts resulting from the described resampling procedure are reported. Thus, our bootstrapping procedure relied on (1) detecting an offset against zero and (2) evaluating the robustness of the observed effect across participants. As such, it contrasts with the frequently used permutation approach that assesses whether an empirical neural shift is more extreme than the permutation distribution. The permutation approach seemed more suited to assess the magnitude of the shift, which in our study was not a priority. Therefore, we reasoned that bootstrapping was better suited to assess the direction of the neural shift and its robustness across participants.</p></sec><sec id="s4-6-4"><title>Correlation between neural representation and behavioral response</title><p>In addition, we correlated the maximum of single-trial reconstructions with the upcoming behavioral response to test whether shifts in behavior and in the neural signal on a single-trial level were systematically related to each other. Both behavioral and neural shifts in any direction (CW or CCW) in a single-trial response can originate from or be modulated by different sources like, for example, noise in the motor response, but they can also result from attractive serial dependence that can be observed by averaging over trials. We collected the reconstructions before flipping them with regard to the previous target and removed trials where the behavioral response deviated more than three SDs from the individual response error. Then we computed the circular correlation between the deviation of the reconstructed maximum from the presented direction and the response error for each participant, session, epoch, and time point. For S1 and S2 epochs, only epochs from trials where the respective item was cued as the response target were included.</p></sec><sec id="s4-6-5"><title>Statistical inference of correlations</title><p>The obtained correlation coefficients were averaged across sessions and then time points for each epoch with a correlation significantly differing from zero were identified by computing a one-sided cluster-based permutation test (as implemented in MNE) against zero.</p></sec><sec id="s4-6-6"><title>Reconstruction of previous target direction</title><p>We also examined whether the neural signals of the current trial contained memory traces of the previous target direction. Therefore, another IEM analysis was employed, but this time trained and tested on the target direction of the previous trial throughout the last second of the ITI and the current trial. Time points that contained significant direction information from the previous target were identified by computing the fidelity of the reconstructions as described above and tested against zero with a one-sided cluster-based permutation test.</p></sec><sec id="s4-6-7"><title>Multiple comparison correction</title><p>In order to correct for multiple comparisons, we applied an FDR correction (Benjamini–Hochberg) to those analyses that resulted in one p-value per epoch, that is, the bootstrapping tests of the shifts against zero, and reported these corrected values alongside the original ones. Furthermore, for cluster-based permutation tests that were applied to each epoch individually, we multiplied p-values higher than the minimally possible (p &lt; 0.002) for significant clusters by the number of epochs (3), thus resulting in a Bonferroni correction.</p></sec></sec><sec id="s4-7"><title>Software</title><p>All behavioral analysis was performed with <xref ref-type="bibr" rid="bib29">MATLAB, 2019</xref> and the following toolboxes/functions: Circular Statistics Toolbox (<xref ref-type="bibr" rid="bib6">Berens, 2009</xref>), BADS (<xref ref-type="bibr" rid="bib1">Acerbi and Ma, 2017</xref>), and EzyFit v2.44 (<xref ref-type="bibr" rid="bib31">Moisy, 2016</xref>). The MEG analysis was performed with Python 3.8 in the distribution v.2020.11 (<xref ref-type="bibr" rid="bib3">Anaconda, 2020</xref>) using spyder v.4.1.5 (<xref ref-type="bibr" rid="bib39">Raybaut, 2009</xref>) and the following toolboxes: autoreject v0.2.2 (<xref ref-type="bibr" rid="bib25">Jas et al., 2017</xref>), MNE v0.22.0 (<xref ref-type="bibr" rid="bib21">Gramfort et al., 2013</xref>), numpy v1.19.2 (<xref ref-type="bibr" rid="bib24">Harris et al., 2020</xref>), pandas v1.1.3 (<xref ref-type="bibr" rid="bib30">McKinney, 2010</xref>; <xref ref-type="bibr" rid="bib46">The Pandas Development Team, 2020</xref>), and scipy v1.5.2 (<xref ref-type="bibr" rid="bib47">Virtanen et al., 2020</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Methodology, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Methodology, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Methodology, Supervision, Visualization, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All subjects gave informed consent and received either a compensation of €10/hr or course credit. The study was approved by the Ethics Committee of the Medical Faculty of the Goethe-University Frankfurt am Main.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-99478-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Code, behavioral data, and preprocessed MEG data used for the present analyses are available on OSF via <ext-link ext-link-type="uri" xlink:href="https://osf.io/yjc93/">https://osf.io/yjc93/</ext-link>. Due to storage limitations (50 GB), only the preprocessed MEG data for the main IEM analyses focusing on the current direction were uploaded. Researchers interested in accessing the raw MEG data (ca. 220GB) should contact the principal investigator Christoph Bledowski (bledowski@em.uni-frankfurt.de), providing a rationale for their non-commercial request. Upon review, they will be granted access to the raw data.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>C</given-names></name><name><surname>Kaiser</surname><given-names>J</given-names></name><name><surname>Bledowski</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>A direct neural signature of serial dependence</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/yjc93/">yjc93</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Magdalena Feldmann, Nicole Huizinga, Philipp Deutsch, and Susanna Wenzel for their help in data collection and Benjamin Rahm for helpful discussions.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Acerbi</surname><given-names>L</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Practical bayesian optimization for model fitting with bayesian adaptive direct search</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1705.04405">https://arxiv.org/abs/1705.04405</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akrami</surname><given-names>A</given-names></name><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Posterior parietal cortex represents sensory history and mediates its effects on behaviour</article-title><source>Nature</source><volume>554</volume><fpage>368</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1038/nature25510</pub-id><pub-id pub-id-type="pmid">29414944</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="web"><person-group person-group-type="author"><collab>Anaconda</collab></person-group><year iso-8601-date="2020">2020</year><article-title>Anaconda Software Distribution</article-title><ext-link ext-link-type="uri" xlink:href="https://docs.anaconda.com/">https://docs.anaconda.com/</ext-link><date-in-citation iso-8601-date="2020-01-01">January 1, 2020</date-in-citation></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bae</surname><given-names>GY</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reactivation of previous experiences in a working memory task</article-title><source>Psychological Science</source><volume>30</volume><fpage>587</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1177/0956797619830398</pub-id><pub-id pub-id-type="pmid">30817224</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbosa</surname><given-names>J</given-names></name><name><surname>Stein</surname><given-names>H</given-names></name><name><surname>Martinez</surname><given-names>RL</given-names></name><name><surname>Galan-Gadea</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Dalmau</surname><given-names>J</given-names></name><name><surname>Adam</surname><given-names>KCS</given-names></name><name><surname>Valls-Solé</surname><given-names>J</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Interplay between persistent activity and activity-silent dynamics in the prefrontal cortex underlies serial biases in working memory</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1016</fpage><lpage>1024</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0644-4</pub-id><pub-id pub-id-type="pmid">32572236</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CircStat: A MATLAB toolbox for circular statistics</article-title><source>Journal of Statistical Software</source><volume>31</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.18637/jss.v031.i10</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bliss</surname><given-names>DP</given-names></name><name><surname>Sun</surname><given-names>JJ</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Serial dependence is absent at the time of perception but increases in visual working memory</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>14739</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-15199-7</pub-id><pub-id pub-id-type="pmid">29116132</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding and reconstructing color from responses in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>13992</fpage><lpage>14003</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3577-09.2009</pub-id><pub-id pub-id-type="pmid">19890009</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cross-orientation suppression in human visual cortex</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>2108</fpage><lpage>2119</lpage><pub-id pub-id-type="doi">10.1152/jn.00540.2011</pub-id><pub-id pub-id-type="pmid">21775720</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Benedetto</surname><given-names>A</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Perceptual history propagates down to early levels of sensory analysis</article-title><source>Current Biology</source><volume>31</volume><fpage>1245</fpage><lpage>1250</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.12.004</pub-id><pub-id pub-id-type="pmid">33373639</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Czoschke</surname><given-names>S</given-names></name><name><surname>Fischer</surname><given-names>C</given-names></name><name><surname>Beitner</surname><given-names>J</given-names></name><name><surname>Kaiser</surname><given-names>J</given-names></name><name><surname>Bledowski</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Two types of serial dependence in visual working memory</article-title><source>British Journal of Psychology</source><volume>110</volume><fpage>256</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1111/bjop.12349</pub-id><pub-id pub-id-type="pmid">30198553</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory</article-title><source>Neuron</source><volume>87</volume><fpage>893</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.013</pub-id><pub-id pub-id-type="pmid">26257053</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Categorical biases in human occipitoparietal cortex</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>917</fpage><lpage>931</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2700-19.2019</pub-id><pub-id pub-id-type="pmid">31862856</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>J</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Serial dependence in visual perception</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>738</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1038/nn.3689</pub-id><pub-id pub-id-type="pmid">24686785</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>C</given-names></name><name><surname>Czoschke</surname><given-names>S</given-names></name><name><surname>Peters</surname><given-names>B</given-names></name><name><surname>Rahm</surname><given-names>B</given-names></name><name><surname>Kaiser</surname><given-names>J</given-names></name><name><surname>Bledowski</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Context information supports serial dependence of multiple visual objects across memory episodes</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>1932</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15874-w</pub-id><pub-id pub-id-type="pmid">32321924</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Park</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attractive serial dependence in the absence of an explicit task</article-title><source>Psychological Science</source><volume>29</volume><fpage>437</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1177/0956797617737385</pub-id><pub-id pub-id-type="pmid">29381415</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Park</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural Dynamics of serial dependence in numerosity perception</article-title><source>Journal of Cognitive Neuroscience</source><volume>32</volume><fpage>141</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01474</pub-id><pub-id pub-id-type="pmid">31560267</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Togoli</surname><given-names>I</given-names></name><name><surname>Bueti</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Perceptual history biases are predicted by early visual-evoked activity</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>3860</fpage><lpage>3875</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1451-22.2023</pub-id><pub-id pub-id-type="pmid">37085319</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname><given-names>M</given-names></name><name><surname>Mostert</surname><given-names>P</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Opposite effects of recent history on perception and decision</article-title><source>Current Biology</source><volume>27</volume><fpage>590</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.01.006</pub-id><pub-id pub-id-type="pmid">28162897</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname><given-names>M</given-names></name><name><surname>Spaak</surname><given-names>E</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A Bayesian and efficient observer model explains concurrent attractive and repulsive history biases in visual perception</article-title><source>eLife</source><volume>9</volume><elocation-id>217</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55389</pub-id><pub-id pub-id-type="pmid">32479264</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MEG and EEG data analysis with MNE-Python</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hajonides</surname><given-names>JE</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>Myers</surname><given-names>NE</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Multiple and dissociable effects of sensory history on working-memory performance</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>2730</fpage><lpage>2740</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1200-22.2023</pub-id><pub-id pub-id-type="pmid">36868858</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallenbeck</surname><given-names>GE</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Rahmati</surname><given-names>M</given-names></name><name><surname>Sreenivasan</surname><given-names>KK</given-names></name><name><surname>Curtis</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Working memory representations in visual cortex mediate distraction effects</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4714</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24973-1</pub-id><pub-id pub-id-type="pmid">34354071</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Wieser</surname><given-names>E</given-names></name><name><surname>Taylor</surname><given-names>J</given-names></name><name><surname>Berg</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>NJ</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Picus</surname><given-names>M</given-names></name><name><surname>Hoyer</surname><given-names>S</given-names></name><name><surname>van Kerkwijk</surname><given-names>MH</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Haldane</surname><given-names>A</given-names></name><name><surname>Del Río</surname><given-names>JF</given-names></name><name><surname>Wiebe</surname><given-names>M</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Gérard-Marchant</surname><given-names>P</given-names></name><name><surname>Sheppard</surname><given-names>K</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Abbasi</surname><given-names>H</given-names></name><name><surname>Gohlke</surname><given-names>C</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Array programming with NumPy</article-title><source>Nature</source><volume>585</volume><fpage>357</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id><pub-id pub-id-type="pmid">32939066</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Bekhti</surname><given-names>Y</given-names></name><name><surname>Raimondo</surname><given-names>F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Autoreject: Automated artifact rejection for MEG and EEG data</article-title><source>NeuroImage</source><volume>159</volume><fpage>417</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.030</pub-id><pub-id pub-id-type="pmid">28645840</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiyonaga</surname><given-names>A</given-names></name><name><surname>Scimeca</surname><given-names>JM</given-names></name><name><surname>Bliss</surname><given-names>DP</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Serial dependence across perception, attention, and memory</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>493</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.04.011</pub-id><pub-id pub-id-type="pmid">28549826</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>J</given-names></name><name><surname>Collins</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The representational similarity between visual perception and recent perceptual history</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>3658</fpage><lpage>3665</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2068-22.2023</pub-id><pub-id pub-id-type="pmid">36944487</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manassi</surname><given-names>M</given-names></name><name><surname>Liberman</surname><given-names>A</given-names></name><name><surname>Kosovicheva</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Serial dependence in position occurs at the time of perception</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>25</volume><fpage>2245</fpage><lpage>2253</lpage><pub-id pub-id-type="doi">10.3758/s13423-018-1454-5</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><collab>MATLAB</collab></person-group><year iso-8601-date="2019">2019</year><source>MATLAB</source><publisher-name>The MathWorks Inc</publisher-name></element-citation></ref><ref id="bib30"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>McKinney</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Data Structures for Statistical Computing in Python</article-title><conf-name>Python in Science Conference</conf-name><fpage>56</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Moisy</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>MATLAB central file exchange</article-title><ext-link ext-link-type="uri" xlink:href="https://de.mathworks.com/matlabcentral/fileexchange/10176-ezyfit-2-44">https://de.mathworks.com/matlabcentral/fileexchange/10176-ezyfit-2-44</ext-link><date-in-citation iso-8601-date="2018-04-06">April 6, 2018</date-in-citation></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mostert</surname><given-names>P</given-names></name><name><surname>Albers</surname><given-names>AM</given-names></name><name><surname>Brinkman</surname><given-names>L</given-names></name><name><surname>Todorova</surname><given-names>L</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Eye movement-related confounds in neural decoding of visual working memory representations</article-title><source>eNeuro</source><volume>5</volume><elocation-id>ENEURO.0401-17.2018</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0401-17.2018</pub-id><pub-id pub-id-type="pmid">30310862</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murai</surname><given-names>Y</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Serial dependence revealed in history-dependent perceptual templates</article-title><source>Current Biology</source><volume>31</volume><fpage>3185</fpage><lpage>3191</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.05.006</pub-id><pub-id pub-id-type="pmid">34087105</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascucci</surname><given-names>D</given-names></name><name><surname>Mancuso</surname><given-names>G</given-names></name><name><surname>Santandrea</surname><given-names>E</given-names></name><name><surname>Della Libera</surname><given-names>C</given-names></name><name><surname>Plomp</surname><given-names>G</given-names></name><name><surname>Chelazzi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Laws of concatenated perception: Vision goes for novelty, decisions for perseverance</article-title><source>PLOS Biology</source><volume>17</volume><elocation-id>e3000144</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000144</pub-id><pub-id pub-id-type="pmid">30835720</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascucci</surname><given-names>D</given-names></name><name><surname>Tanrikulu</surname><given-names>ÖD</given-names></name><name><surname>Ozkirli</surname><given-names>A</given-names></name><name><surname>Houborg</surname><given-names>C</given-names></name><name><surname>Ceylan</surname><given-names>G</given-names></name><name><surname>Zerr</surname><given-names>P</given-names></name><name><surname>Rafiei</surname><given-names>M</given-names></name><name><surname>Kristjánsson</surname><given-names>Á</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Serial dependence in visual perception: A review</article-title><source>Journal of Vision</source><volume>23</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1167/jov.23.1.9</pub-id><pub-id pub-id-type="pmid">36648418</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quax</surname><given-names>SC</given-names></name><name><surname>Dijkstra</surname><given-names>N</given-names></name><name><surname>van Staveren</surname><given-names>MJ</given-names></name><name><surname>Bosch</surname><given-names>SE</given-names></name><name><surname>van Gerven</surname><given-names>MAJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Eye movements explain decodability during perception and cued attention in MEG</article-title><source>NeuroImage</source><volume>195</volume><fpage>444</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.03.069</pub-id><pub-id pub-id-type="pmid">30951848</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rademaker</surname><given-names>RL</given-names></name><name><surname>Chunharas</surname><given-names>C</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Coexisting representations of sensory and mnemonic information in human visual cortex</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1336</fpage><lpage>1344</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0428-x</pub-id><pub-id pub-id-type="pmid">31263205</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranieri</surname><given-names>G</given-names></name><name><surname>Benedetto</surname><given-names>A</given-names></name><name><surname>Ho</surname><given-names>HT</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name><name><surname>Morrone</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Evidence of serial dependence from decoding of visual evoked potentials</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>8817</fpage><lpage>8825</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1879-21.2022</pub-id><pub-id pub-id-type="pmid">36223998</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Raybaut</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>Spyder-Documentation</source><publisher-name>Ythonhosted.org</publisher-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheehan</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Attractive serial dependence overcomes repulsive neuronal adaptation</article-title><source>PLOS Biology</source><volume>20</volume><elocation-id>e3001711</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3001711</pub-id><pub-id pub-id-type="pmid">36067148</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1879</fpage><lpage>1887</lpage><pub-id pub-id-type="doi">10.1038/nn.3574</pub-id><pub-id pub-id-type="pmid">24212672</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Sprague</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>IEM-tutorial</data-title><version designator="19393c1">19393c1</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/tommysprague/IEM-tutorial">https://github.com/tommysprague/IEM-tutorial</ext-link></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Restoring latent visual working memory representations in human cortex</article-title><source>Neuron</source><volume>91</volume><fpage>694</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.006</pub-id><pub-id pub-id-type="pmid">27497224</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Adam</surname><given-names>KCS</given-names></name><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Rahmati</surname><given-names>M</given-names></name><name><surname>Sutterer</surname><given-names>DW</given-names></name><name><surname>Vo</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inverted encoding models assay population-level stimulus representations, not single-unit neural tuning</article-title><source>eNeuro</source><volume>5</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1523/ENEURO.0098-18.2018</pub-id><pub-id pub-id-type="pmid">29876523</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>St. John-Saaltink</surname><given-names>E</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Lau</surname><given-names>HC</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Serial dependence in perceptual decisions is reflected in activity patterns in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>6186</fpage><lpage>6192</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4390-15.2016</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="software"><person-group person-group-type="author"><collab>The Pandas Development Team</collab></person-group><year iso-8601-date="2020">2020</year><data-title>Pandas-dev/pandas: pandas</data-title><version designator="1.0.0">1.0.0</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3630805">https://doi.org/10.5281/zenodo.3630805</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Carey</surname><given-names>CJ</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Henriksen</surname><given-names>I</given-names></name><name><surname>Quintero</surname><given-names>EA</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>van Mulbregt</surname><given-names>P</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitney</surname><given-names>D</given-names></name><name><surname>Manassi</surname><given-names>M</given-names></name><name><surname>Murai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Searching for serial dependencies in the brain</article-title><source>PLOS Biology</source><volume>20</volume><elocation-id>e3001788</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3001788</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Myers</surname><given-names>NE</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Revealing hidden states in visual working memory using electroencephalography</article-title><source>Frontiers in Systems Neuroscience</source><volume>9</volume><elocation-id>123</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2015.00123</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Jochim</surname><given-names>J</given-names></name><name><surname>Akyürek</surname><given-names>EG</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>864</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1038/nn.4546</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Correlation between the neural shift and individual serial dependence parameters</title><p>In addition to the single-trial-based correlation between neural and behavioral shifts reported in the main manuscript, we calculated correlations between the neural shift and individual <italic>a</italic> and <italic>w</italic> parameters obtained from DoG serial dependence fits on a between-subject level. This analysis revealed no significant correlations during the S1 and S2 epochs for neither <italic>a</italic> nor <italic>w</italic> parameter (a parameter, S1: <italic>r</italic> = 0.01, p = 0.9767; S2: <italic>r</italic> = 0.08, p = 0.8114; <italic>w</italic> parameter: S1: <italic>r</italic> = 0.36, p = 0.3096; S2: <italic>r</italic> = 0.30, p = 0.4054). While during the retro-cue epoch, there was no significant correlation with the <italic>a</italic> parameter either (<italic>r</italic> = −0.35, p = 0.3258), we did observe a significant correlation between individual neural shifts and <italic>w</italic> parameters (<italic>r</italic> = −0.70, p = 0.0246). This means that smaller individual w parameters indicating a broader tuning of serial dependence went along with larger neural shifts.</p><p>This further demonstrates that the neural shift during the retro-cue epoch reflected behavioral serial dependence. These results are displayed in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>.</p><p>It is important to note that for the calculation of the neural shift, all trials entered the analysis to increase the signal-to-noise ratio, that is, it included many trials where current and previous targets were separated by, for example, 100° or more. These trials were unlikely to produce serial dependence. Subjects with a more broadly tuned serial dependence had more inter-item differences that showed a behavioral attraction and therefore more trials affected by serial dependence that entered the calculation of the neural shift. In contrast, individual differences in the amplitude (<italic>a</italic>) parameter were most likely too small, and higher individual amplitude did not involve more trials as compared to smaller amplitude to affect the neural bias in a way to be observed in a significant correlation.</p></sec><sec sec-type="appendix" id="s9"><title>Different codes for reactivation of previous information and reconstructed biases of current information</title><p>In the retro-cue epoch, we observed both an attractive bias toward the target of the previous trial and a transient reactivation of the previous target itself. Therefore, one alternative explanation of the observed attractive bias could be a reactivation of the previous target in the same neural code as the current target that in sum led to an attractive shift of the reconstruction. To rule out this explanation, we ran a cross-validation analysis. Therefore, we trained the encoding model on the currently relevant item (S1 during the S1 epoch, S2 during the S2 epoch, and the cued item during the retro-cue epoch) and aimed to reconstruct the motion direction of the previous trial.</p><p>This analysis revealed that during the retro-cue epoch, where we observed the neural shift toward the past, as well as during the S1 epoch, there was no reactivation in the same neural code as the current representation. In contrast, a reactivation of target information from the previous trial using the same neural code could be observed during stimulus presentation in the S2 epoch. This indicated that during the S2 phase, information from the current S2 and the previous target was reconstructed in the same neural code. These results are displayed in <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</p></sec><sec sec-type="appendix" id="s10"><title>Eye movement control</title><p>Participants were instructed to maintain fixation on a small square at the center of the screen throughout each trial, and independent component analysis (ICA) was used during preprocessing to remove any eye movement artifacts. However, recent studies showed that systematic eye movements can potentially confound decoding results (e.g., <xref ref-type="bibr" rid="bib32">Mostert et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Quax et al., 2019</xref>). In the present study, participants viewed dynamic stimuli (moving dot patterns) and had to remember a spatial feature (motion direction), which made systematic eye movement behavior more likely. Therefore, we thoroughly tested (1) whether eye movements were associated with the presented/remembered motion direction and if so, (2) whether eye movements could have driven our MEG results.</p><p>As a first step of our eye movement control analysis, we tested how much of the variance of gaze direction could be explained by the stimulus direction that was either currently presented or had to be maintained at a given moment in time. More specifically, we first transformed the <italic>x</italic> and <italic>y</italic> positions measured by the eye tracker (in relation to a baseline from 200 ms until trial onset) into polar coordinates to obtain a gaze direction in degrees. This transformation was performed on the same time points as the MEG analysis, that is, gaze directions were averaged within bins of 100 ms. Then we computed the circular variance of these gaze directions separately for each specific stimulus direction and time bin per subject. This circular variance was compared to a random distribution of gaze direction variance. To obtain this distribution, we shuffled the motion direction labels randomly over trials and then computed the circular variance for each pseudo direction, which was unrelated to the direction that was actually presented in the trial. The empirical and shuffled variances were averaged across directions, and then a ratio was computed between them. The resulting value reflects the extent to which the variance of the stimulus-related gaze directions was reduced compared with random gaze direction patterns. This procedure was able to reveal not only systematic gaze directions that were in accordance with the stimulus direction or the opposite direction, but also picked up all stimulus-related gaze directions, even if the relation differed across participants or time. We identified time points with a significant amount of stimulus-related gaze directions in each analyzed epoch with cluster-based permutation tests. <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3a</xref> shows that gaze directions were systematically related to the presented or remembered motion direction at different time points during each epoch. However, stimulus-related gaze directions differed considerably between participants as indicated by the standard errors.</p><p>In the second step, we plotted the time courses of stimulus-related gaze direction separately for each subject. This is shown in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3b</xref>. This revealed that while some participants showed a high amount of stimulus-related gaze directions, others showed very little or no stimulus-related gaze directions at all. In <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3a</xref>, we marked the time courses in dark red for subjects with the highest amount of direction-related gaze positions (high) and dark green for those with the lowest amount (low), with gradients in between.</p><p>In the third step, we addressed the question of how the stimulus-related gaze directions related to our MEG results. To this aim, we plotted the MEG-based reconstruction fidelity of presented and remembered motion direction separately for each subject and epoch and, crucially, coded them by the amount of stimulus-related gaze directions shown by each subject. This is shown in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3c</xref>. Comparing the stimulus reconstruction fidelity time courses with the individual color codes derived from the gaze direction analyses revealed that the reconstruction fidelities of each participant did not correspond to their amount of stimulus-related gaze behavior (compare <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3b</xref> with <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3c</xref>). This suggests that there was no systematic relationship at any time point between the fidelity measure and the amount of direction-related gaze positions.</p><p>To support this observation statistically, we calculated Spearman rank correlations between the amount of stimulus-related gaze directions and reconstruction fidelities individually for each time point of each epoch. The resulting p-values are shown in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3d</xref>. Even before correcting for multiple comparisons, the p-values were consistently above 0.05, except for one single time point in the retro-cue epoch. Moreover, the p-values within each epoch did not show any consistent time profile but varied considerably between time points, supporting our interpretation that MEG-based reconstruction fidelity was not driven by the amount of stimulus-related gaze directions.</p><p>In consequence, we also did not find any relationship between the attractive neural shift that was based on these reconstructed MEG signals (i.e., the main finding of our study) and stimulus-related gaze directions. Specifically, there was no correlation between each subject’s rank of the strength of neural shift toward the previous target and the subject’s rank of the amount of stimulus-related gaze directions in any of the epochs (S1: p = 0.986, S2: p = 0.260, retro-cue: p = 0.244).</p><p>We conclude that our MEG results were not crucially driven by eye movements.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Correlation between the neural shift and individual serial dependence parameters.</title><p>Relation between the individual <italic>a</italic> (upper panels) and <italic>w</italic> (lower panels) parameters of a derivative-of-Gaussian (DoG) serial dependence fit (<italic>x</italic>-axis) and the neural reconstruction shift (<italic>y</italic>-axis). Colored circles show individual values for the S1 (left panels), S2 (middle panels), and retro-cue epochs (right panels). Solid lines depict significant correlations, dashed gray lines mark a reconstruction shift of 0°. <italic>N</italic> = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-app1-fig1-v1.tif"/></fig><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Cross-validated reconstruction fidelity of previous direction, model trained on currently relevant direction.</title><p>Fidelity of reconstructed direction of the previous target using a model that was trained on the currently relevant direction. The left panel shows the fidelity of the previous target during the S1 epoch, the middle panel depicts the fidelity during the S2 epoch, and the right panel shows the fidelity of the cued direction (either S1 or S2). Small circles show the fidelity of each participant. Colored circles indicate time points with a fidelity significantly greater than zero. Cluster-based permutation test within each epoch. <italic>N</italic> = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-app1-fig2-v1.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Systematic eye movements and reconstruction time courses were uncorrelated.</title><p>(<bold>a</bold>) Amount of stimulus-related gaze direction (indicated by variance reduction) during each epoch as a function of time with error bars indicating standard errors and colored circles indicating time points with a variance reduction significantly greater than zero. Cluster-based permutation test within each epoch; p &lt; 0.05. <italic>N</italic> = 10. (<bold>b</bold>) Time courses of individual stimulus-related gaze directions. Dark red indicates the subject with the highest average variance reduction in a given epoch, while green indicates the one with the smallest average variance reduction, with color gradients in between according to the individual rank of average variance reduction. (<bold>c</bold>) Time courses of individual reconstruction fidelities. Lines are colored as in (b), reflecting the stimulus-related gaze direction rank of a subject in a given epoch. (<bold>d</bold>) Time courses of p-values (uncorrected for multiple comparisons) of time point-by-time point Spearman rank correlations between the systematic gaze directions as shown in (<bold>b</bold>) and the reconstruction fidelity as shown in (<bold>c</bold>). <italic>N</italic> = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-app1-fig3-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99478.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kok</surname><given-names>Peter</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>This study reveals a neural signature of a common behavioural phenomenon: serial dependence, whereby estimates of a visual feature (here motion direction) are attracted towards the recent history of encoded and reported stimuli. The study provides <bold>solid</bold> evidence that this phenomenon arises primarily during working memory maintenance. The pervasiveness of serial dependencies across modalities and species makes these findings <bold>important</bold> for researchers interested in perceptual decision-making across subfields.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99478.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This study uses MEG to test for a neural signature of the trial history effect known as 'serial dependence.' This is a behavioral phenomenon whereby stimuli are judged to be more similar than they really are, in feature space, to stimuli that were relevant in the recent past (i.e., the preceding trials). This attractive bias is prevalent across stimulus classes and modalities, but a neural source has been elusive. This topic has generated great interest in recent years, and I believe this study makes a unique contribution to the field.</p><p>Specifically, while previous neuroimaging studies have found apparent reactivations of previous information, or repulsive biases that may indirectly relate to serial dependence, here Fischer at al. find an attractive bias in neural activity patterns that aligns with the direction of the behavioral effect. Moreover, the data show that the bias emerges later in a trial, after perceptual encoding, which speaks to an ongoing debate about whether such biases are perceptual or decisional.</p><p>The revised preprint thoroughly addresses many of the initial concerns, but the results are still open to interpretation. For instance, the model training/testing regime allows that some training data timepoints may be inherently noisier than others (e.g., delay period more so than encoding), and potentially more (or differently) susceptible to bias. The S1 and S2 epochs show no attractive bias, but they may also be based on more high fidelity training sets (i.e., encoding), and therefore less susceptible to the bias that is evident in the retrocue epoch. So, the results could reflect that serial dependence is indeed a post-perceptual process, or it may instead be that the WM representations, as detected with these MEG analyses, become noisier and more subject to reveal the attractive bias over time.</p><p>The results are intriguing, but the study was not powered to examine whether there is any feature-specificity to the neural bias (e.g., whether it matches the behavioral pattern that biases are amplified within a particular range of feature distances between stimuli). Nor do analyses get at temporally precise information about when attractive and repulsive biases appear, which would help to better reconcile the work with previous findings. As in, the reconstructions average across coarse trial epochs. The S1 and S2 reconstructions show no attractive bias, and appear to show subtle repulsion, but if the timing were examined more precisely, we might see repulsion magnified at earlier timepoints that shift toward attraction at later time points, thereby counteracting the effect. That is to say that the averaging approach, across feature values and timepoints, still leaves these important theoretical questions unresolved.</p><p>Nonetheless, the work marks an important step in identifying the neurophysiological bases of serial dependence. Ideally, all of the data, including the eye-tracking, would be made available so that others might try to address some of these follow-up questions.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99478.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The study aims to probe the neural correlates of visual serial dependence - the phenomenon that estimates of a visual feature (here motion direction) are attracted towards the recent history of encoded and reported stimuli. The authors utilize an established retro-cue working memory task together with magnetoencephalography, which allows to probe neural representations of motion direction during encoding and retrieval (retro-cue) periods of each trial. The main finding is that neural representations of motion direction are not systematically biased during the encoding of motion stimuli, but are attracted towards the motion direction of the previous trial's target during the retrieval (retro-cue period), just prior to the behavioral response. By demonstrating a neural signature of attractive biases in working memory representations, which align with attractive behavioral biases, this study highlights the importance of post-encoding memory processes in visual serial dependence.</p><p>Strengths:</p><p>The main strength of the study is its elegant use of a retro-cue working memory task together with high temporal resolution MEG, enabling to probe neural representations related to stimulus encoding and working memory. The behavioral task elicits robust behavioral serial dependence and replicates previous behavioral findings by the same research group. The careful neural decoding analysis benefits from a large number of trials per participant, considering the slow-paced nature of the working memory paradigm. This is crucial in a paradigm with considerable trial-by-trial behavioral variability (serial dependence biases are typically small, relative to the overall variability in response errors). While the current study is broadly consistent with previous studies showing that attractive biases in neural responses are absent during stimulus encoding (prev. studies reported repulsive biases), to my knowledge, it is the first study showing attractive biases in current stimulus representations during working memory. The study also connects to previous literature showing reactivations of previous stimulus representations, although the link between reactivations and biases remains somewhat vague in the current manuscript. Together, the study reveals an interesting avenue for future studies investigating the neural basis of visual serial dependence.</p><p>Weaknesses:</p><p>The main weakness of the current manuscript is that the authors could have done more analyses to address the concern that their neural decoding results are driven by signals related to eye movements. The authors show that participants' gaze position systematically depended on the current stimuli's motion directions, which, together with previous studies on eye movement-related confounds in neural decoding, justifies such a concern. The authors seek to rule out this confound by showing that the consistency of stimulus-dependent gaze position does not correlate with (a) the neural reconstruction fidelity and (b) the attractive shift in reconstructed motion direction. However, the authors' approach of quantifying stimulus-dependent eye movements only considers gaze angle and not gaze amplitude, and thus potentially misses important features of eye movements that could manifest in the MEG data. Moreover, it is unclear whether the gaze consistency metric should correlate with attractive history biases in neural decoding, if there were a confound. These two concerns could be potentially addressed by (1) directly decoding stimulus motion direction from x-y gaze coordinates and relating this decoding performance to neural reconstruction fidelity, and (2) investigating whether gaze coordinates themselves are history-dependent and are attracted to the average gaze position associated with the previous trials' target stimulus. If the authors could show that (2) is not the case, I would be much more convinced that their main finding is not driven by eye movement confounds.</p><p>The sample size (n = 10) is definitely at the lower end of sample sizes in this field. The authors collected two sessions per participant, which partly alleviates the concern. However, given that serial dependencies can be very variable across participants, I believe that future studies should aim for larger sample sizes.</p><p>It would have been great to see an analysis in source space. As the authors mention in their introduction, different brain areas, such as PPC, mPFC and dlPFC have been implicated in serial biases. This begs the question which brain areas contribute to the serial dependencies observed in the current study? For instance, it would be interesting to see whether attractive shifts in current representations and pre-stimulus reactivations of previous stimuli are evident in the same or different brain areas.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99478.3.sa3</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The study aims to probe the neural correlates of visual serial dependence - the phenomenon that estimates of a visual feature (here motion direction) are attracted towards the recent history of encoded and reported stimuli. The authors utilize an established retro-cue working memory task together with magnetoencephalography, which allows to probe neural representations of motion direction during encoding and retrieval (retro-cue) periods of each trial. The main finding is that neural representations of motion direction are not systematically biased during the encoding of motion stimuli, but are attracted towards the motion direction of the previous trial's target during the retrieval (retro-cue period), just prior to the behavioral response. By demonstrating a neural signature of attractive biases in working memory representations, which align with attractive behavioral biases, this study highlights the importance of post-encoding memory processes in visual serial dependence.</p><p>Strengths:</p><p>The main strength of the study is its elegant use of a retro-cue working memory task together with high temporal resolution MEG, enabling to probe neural representations related to stimulus encoding and working memory. The behavioral task elicits robust behavioral serial dependence and replicates previous behavioral findings by the same research group. The careful neural decoding analysis benefits from a large number of trials per participant, considering the slow-paced nature of the working memory paradigm. This is crucial in a paradigm with considerable trial-by-trial behavioral variability (serial dependence biases are typically small, relative to the overall variability in response errors). While the current study is broadly consistent with previous studies showing that attractive biases in neural responses are absent during stimulus encoding (prev. studies reported repulsive biases), to my knowledge, it is the first study showing attractive biases in current stimulus representations during working memory. The study also connects to previous literature showing reactivations of previous stimulus representations, although the link between reactivations and biases remains somewhat vague in the current manuscript. Together, the study reveals an interesting avenue for future studies investigating the neural basis of visual serial dependence.</p><p>Weaknesses:</p><p>The main weakness of the current manuscript is that the authors could have done more analyses to address the concern that their neural decoding results are driven by signals related to eye movements. The authors show that participants' gaze position systematically depended on the current stimuli's motion directions, which, together with previous studies on eye movement-related confounds in neural decoding, justifies such a concern. The authors seek to rule out this confound by showing that the consistency of stimulus-dependent gaze position does not correlate with (a) the neural reconstruction fidelity and (b) the attractive shift in reconstructed motion direction. However, the authors' approach of quantifying stimulus-dependent eye movements only considers gaze angle and not gaze amplitude, and thus potentially misses important features of eye movements that could manifest in the MEG data. Moreover, it is unclear whether the gaze consistency metric should correlate with attractive history biases in neural decoding, if there were a confound. These two concerns could be potentially addressed by (1) directly decoding stimulus motion direction from x-y gaze coordinates and relating this decoding performance to neural reconstruction fidelity, and (2) investigating whether gaze coordinates themselves are history-dependent and are attracted to the average gaze position associated with the previous trials' target stimulus. If the authors could show that (2) is not the case, I would be much more convinced that their main finding is not driven by eye movement confounds.</p><p>The sample size (n = 10) is definitely at the lower end of sample sizes in this field. The authors collected two sessions per participant, which partly alleviates the concern. However, given that serial dependencies can be very variable across participants, I believe that future studies should aim for larger sample sizes.</p><p>It would have been great to see an analysis in source space. As the authors mention in their introduction, different brain areas, such as PPC, mPFC and dlPFC have been implicated in serial biases. This begs the question which brain areas contribute to the serial dependencies observed in the current study? For instance, it would be interesting to see whether attractive shifts in current representations and pre-stimulus reactivations of previous stimuli are evident in the same or different brain areas.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99478.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Fischer</surname><given-names>Cora</given-names></name><role specific-use="author">Author</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Institute of Medical Psychology</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Cooperative Brain Imaging Center</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Kaiser</surname><given-names>Jochen</given-names></name><role specific-use="author">Author</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Institute of Medical Psychology</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Cooperative Brain Imaging Center</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Bledowski</surname><given-names>Christoph</given-names></name><role specific-use="author">Author</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Institute of Medical Psychology</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04cvxnb49</institution-id><institution>Goethe University Frankfurt, Cooperative Brain Imaging Center</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt am Main</named-content></addr-line><country>Germany</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews</p><p>We were delighted by the reviewers' general comments. We thank the reviewers for their thoughtful reviews, constructive criticism, and analysis suggestions. We have carefully addressed each of their points during the revision of the manuscript.</p><p>Unfortunately, after the paper was submitted to eLife, the first author, who ran all the analyses, left academia. We now realized that we currently do not have sufficient resources to perform all additional analyses as requested by the reviewers.3</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>This study uses MEG to test for a neural signature of the trial history effect known as 'serial dependence.' This is a behavioral phenomenon whereby stimuli are judged to be more similar than they really are, in feature space, to stimuli that were relevant in the recent past (i.e., the preceding trials). This attractive bias is prevalent across stimulus classes and modalities, but a neural source has been elusive. This topic has generated great interest in recent years, and I believe this study makes a unique contribution to the field. The paper is overall clear and compelling, and makes effective use of data visualizations to illustrate the findings. Below, I list several points where I believe further detail would be important to interpreting the results. I also make suggestions for additional analyses that I believe would enrich understanding but are inessential to the main conclusions.</p><p>(1) In the introduction, I think the study motivation could be strengthened, to clarify the importance of identifying a neural signature here. It is clear that previous studies have focused mainly on behavior, and that the handful of neuroscience investigations have found only indirect signatures. But what would the type of signature being sought here tell us? How would it advance understanding of the underlying processes, the function of serial dependence, or the theoretical debates around the phenomenon?</p></disp-quote><p>Thank you for pointing this out. Our MEG study was designed to address two questions: 1. we asked whether we could observe a direct neural signature of serial dependence, and 2. if so, whether this signature occurs at the encoding or post-encoding stage of stimulus processing in working memory. This second question directly concerns the current theoretical debate on serial dependence.</p><p>Previous studies have found only indirect signatures of serial dependence such as reactivations of information from the previous trial or signatures of a repulsive bias, which were in contrast to the attractive bias in behavior. Thus, it remained unclear whether an attractive neural bias can be observed as a direct reflection of the behavioral bias. Moreover, previous studies observed the neuronal repulsion during early visual processes, leading to the proposal that neural signals become attracted only during later, post-encoding processes. However, these later processing stages were not directly accessible in previous studies. To address these two questions, we combined MEG recordings with an experimental paradigm with two items and a retro-cue. This design allowed to record neural signals during separable encoding and post-encoding task phases and so to pinpoint the task phase at which a direct neural signature of serial dependence occurred that mirrored the behavioral effect.</p><p>We have slightly modified the Introduction to strengthen the study motivation.</p><disp-quote content-type="editor-comment"><p>(1a) As one specific point of clarification, on p. 5, lines 91-92, a previous study (St. JohnSaaltink et al.) is described as part of the current study motivation, stating that &quot;as the current and previous orientations were either identical or orthogonal to each other, it remained unclear whether this neural bias reflected an attraction or repulsion in relation to the past.&quot; I think this statement could be more explicit as to why/how these previous findings are ambiguous. The St. John-Saaltink study stands as one of very few that may be considered to show evidence of an early attractive effect in neural activity, so it would help to clarify what sort of advance the current study represents beyond that.</p></disp-quote><p>Thank you for this comment. In the study by St. John-Saaltink et al. (2016), two gratings oriented at 45° and 135° were always presented to either the left or right side of a central fixation point in a trial (90° orientation difference). As only the left/right position of the 45° and 135° gratings varied across trials, the target stimulus in the current trial was either the same or differed by exactly 90° from the previous trial. In consequence, this study could not distinguish whether the observed bias was attractive or repulsive, which concerned both the behavioral effect and the V1 signal. Furthermore, the bias in the V1 signal was partially explained by the orientation that was presented at the same position in the previous trial, which could reflect a reactivation of the previous orientation rather than an actual altered orientation.</p><p>We have changed the Introduction accordingly.</p><p>References:</p><p>St. John-Saaltink E, Kok P, Lau HC, de Lange FP (2016) Serial Dependence in Perceptual Decisions Is Reflected in Ac6vity Pa9erns in Primary Visual Cortex. Journal of Neuroscience 36: 6186–6192.</p><disp-quote content-type="editor-comment"><p>(1b) The study motivation might also consider the findings of Ranieri et al (2022, J. Neurosci) Fornaciai, Togoli, &amp; Bueti (2023, J. Neurosci), and Lou&amp; Collins (2023, J. Neurosci) who all test various neural signatures of serial dependence.</p></disp-quote><p>Thank you. As all listed findings showed neural signatures revealing a reactivation of the previous stimulus or a response during the current trial, we have added them to the paragraph in the Introduction referring to this class of evidence for the neural basis for serial dependence.</p><disp-quote content-type="editor-comment"><p>(2) Regarding the methods and results, it would help if the initial description of the reconstruction approach, in the main text, gave more context about what data is going into reconstruction (e.g., which sensors), a more conceptual overview of what the 'reconstruction' entails, and what the fidelity metric indexes. To me, all of that is important to interpreting the figures and results. For instance, when I first read, it was unclear to me what it meant to &quot;reconstruct the direction of S1 during the S2 epoch&quot; (p. 10, line 199)? As in, I couldn't tell how the data/model knows which item it is reconstructing, as opposed to just reporting whatever directional information is present in the signal.</p><p>(2a) Relatedly, what does &quot;reconstruction strength&quot; reflect in Figure 2a? Is this different than the fidelity metric? Does fidelity reflect the strength of the particular relevant direction, or does it just mean that there is a high level of any direction information in the signal? In the main text explain what reconstruction strength and what fidelity is?</p></disp-quote><p>Thank you for pointing this out. We applied the inverted encoding model method to MEG data from all active sensors (271) within defined time-windows of 100 ms length. MEG data was recorded in two sessions on different days. Specifically, we constructed an encoding model with 18 motion direction-selective channels. Each channel was designed to show peak sensitivity to a specific motion direction, with gradually decreasing sensitivity to less similar directions. In a training step, the encoding model was fiCed to the MEG data of one session to obtain a weight matrix that indicates how well the sensor activity can be explained by the modeled direction. In the testing step, the weight matrix was inverted and applied to the MEG data of the other session, resulting in a response profile of ‘reconstruction strengths’, i.e., how strongly each motion direction was present in a trial. When a specific motion direction was present in the MEG signal, the reconstruction strengths peaked at that specific direction and decreased with increasing direction difference. If no information was present, reconstruction strengths were comparable across all modeled directions, i.e., the response profile was flat. To integrate response profiles across trials, single trial profiles were aligned to a common center direction (i.e., 180°) and then averaged.</p><p>To quantify the accuracy of each IEM reconstruction, i.e., how well the response profile represents a specific motion direction relative to all other directions we computed the ‘reconstruction fidelity’. Fidelity was obtained by projecting the polar vector of the reconstruction at every direction angle (in steps of 1°) onto the common center (180°) and averaging across all direction angles (Rademaker et al 2019, Sprague, Ester &amp; Serences, 2016). As such, ‘reconstruction fidelity’ is a summary metric with fidelity greater than zero indicating an accurate reconstruction.</p><p>How does the model know which direction to reconstruct? Our modelling procedure was informed about the stimulus in question during both the training and the testing step. Specifically, we informed our model during the training step about e.g., the current S2. Then, we fit the model to training data from the S2 epoch and applied it to testing data from the S2 epoch. Crucially, during the testing step the motion direction in question, i.e., current S2, becomes relevant again. For example, when S2 was 120°, the reconstructions were shifted by 60° in order to align with the common center, i.e., 180°. In addition, we also tested whether we could reconstruct the motion direction of S1 during the S2 epoch. Here, we used again the MEG data from the S2 epoch but now for S1 training. i.e., the model was informed about S1 direction. Accordingly, the recentering step during testing was done with regard to the S1 direction. Similarly, we also reconstructed the motion direction of the previous target (i.e., the previous S1 or S2), e.g., during the S2 epoch.</p><p>Together, the multi-variate pattern of MEG activity across all sensors during the S2 epoch could contain information about the currently presented direction of S2, the direction of the preceding S1 and the direction of the target stimulus from the previous trial (i.e., either previous S1 or previous S2) at the same time. An important exception from this regime was the cross-reconstruction analysis (Appendix 1—figure 2). Here we trained the encoding model on the currently relevant item (S1 during the S1 epoch, S2 during the S2 epoch and the cued item during the retro-cue epoch) of one MEG session and reconstructed the previous target on the other MEG session.</p><p>Finally, to examine shifts of the neural representation, single-trial reconstructions were assigned to two groups, those with a previous target that was oriented clockwise (CW) in relation to the currently relevant item and those with a previous target that was oriented counter-clockwise (CCW). The CCW reconstructions were flipped along the direction space, hence, a negative deviation of the maximum of the reconstruction from 180° indicated an attraction toward the previous target, whereas a positive deviation indicated a repulsion. Those reconstructions were then first averaged within each possible motion direction and then across them to account for different presentation numbers of the directions, resulting in one reconstruction per participant, epoch and time point. To examine systematic shifts, we then tested if the maximum of the reconstruction was systematically different from the common center (180°). For display purposes, we subtracted the reconstructed maximum from 180° to compute the direction shifts. A positive shift thus reflected attraction and a negative shift reflected repulsion.</p><p>We have updated the Results accordingly.</p><p>References:</p><p>Rademaker RL, Chunharas C, Serences JT (2019) Coexisting representations of sensory and mnemonic information in human visual cortex. Nature Neuroscience. 22: 1336-1344.</p><p>Sprague TC, Ester EF, Serences JT (2016) Restoring Latent Visual Working Memory Representations in Human Cortex. Neuron. 91: 694-707</p><disp-quote content-type="editor-comment"><p>(3) Then in the Methods, it would help to provide further detail still about the IEM training/testing procedure. For instance, it's not entirely clear to me whether all the analyses use the same model (i.e., all trained on stimulus encoding) or whether each epoch and timepoint is trained on the corresponding epoch and timepoint from the other session. This speaks to whether the reconstructions reflect a shared stimulus code across different conditions vs. that stimulus information about various previous and current trial items can be extracted if the model is tailored accordingly.</p></disp-quote><p>As reported above, our modeling procedure was informed about same stimulus during both the training and the testing step, except for the cross-reconstruction analysis.</p><p>Regarding the training and testing data, the model was always trained on data from one session and tested on data from the other session, so that each MEG session once served as the training data set and once as the test data set, hence, training and test data were independent. Importantly, training and testing was always performed in an epoch- and time point-specific way: For example, the model that was trained on the first 100-ms time bin from the S1 epoch of the first MEG session was tested on the first 100-ms time bin from the S1 epoch of the second MEG session.</p><disp-quote content-type="editor-comment"><p>Specifically, when you say &quot;aim of the reconstruction&quot; (p. 31, line 699), does that simply mean the reconstruction was centered in that direction (that the same data would go into reconstructing S1 or S2 in a given epoch, and what would differentiate between them is whether the reconstruction was centered to the S1 or S2 direction value)?</p></disp-quote><p>As reported above, during testing the reconstruction was centered at the currently relevant direction. The encoding model was trained with the direction labels of S1, S2 or the target item, corresponding to the currently relevant direction, i.e., S1 in S1 epochs, S2 in S2 epochs and target item (S1 or S2) in the retro-cue epoch. The only exception was the reconstruction of S1 during the S2 epoch. Here the encoding model was trained on the S1 direction, but with data from the S2 epoch and then applied to the S2 epoch data and recentered to the S1 direction. So here, S1 and S2 were indeed trained and tested separately for the same epoch.</p><disp-quote content-type="editor-comment"><p>(4) I think training and testing were done separately for each epoch and timepoint, but this could have important implications for interpreting the results. Namely if the models are trained and tested on different time points, and reference directions, then some will be inherently noisier than others (e.g., delay period more so than encoding), and potentially more (or differently) susceptible to bias. For instance, the S1 and S2 epochs show no attractive bias, but they may also be based on more high-fidelity training sets (i.e., encoding), and therefore less susceptible to the bias that is evident in the retrocue epoch.</p></disp-quote><p>Thanks for pointing this out. Training and testing were performed in an epoch- and time point-specific way. Thus, potential differences in the signal-to-noise ratio between different task phases could cause quality differences between the corresponding reconstructed MEG signals. However, we did not observe such differences. Instead, we found comparable time courses of the reconstruction fidelities and the averaged reconstruction strengths between epochs (Figure 2b and 2c, respectively). Fig. 2b, e.g., shows that reconstruction fidelity for motion direction stimuli built up slowly during the stimulus presentation, reaching its maximum only after stimulus offset. This observation may contrast to different stimulus materials with faster build-ups, like the orientation of a Gabor.</p><p>We agree with the reviewer that, regardless of the comparable but not perfectly equal reconstruction fidelities, there are good arguments to assume that the neural representation of the stimulus during its encoding is typically less noisy than during its post-encoding processing and that this difference could be one of the reasons why serial dependence emerged in our study only during the retro-cue epoch. However, the argument could also be reversed: a biased representation, which represents a small and hard-to-detect neural effect, might be easier to observe for less noisy data. So, the fact that we found a significant bias only during the potentially “noisier” retro-cue epoch makes the effect even more noteworthy.</p><p>We mentioned the limitation related to our stimulus material already at the end of the Discussion. We have now added a new paragraph to the Discussion to address the two opposing lines of reasoning.</p><disp-quote content-type="editor-comment"><p>(4) I believe the work would benefit from a further effort to reconcile these results with previous findings (i.e., those that showed repulsion, like Sheehan &amp; Serences), potentially through additional analyses. The discussion attributes the difference in findings to the &quot;combination of a retro-cue paradigm with the high temporal resolution of MEG,&quot; but it's unclear how that explains why various others observed repulsion (thought to happen quite early) that is not seen at any stage here. In my view, the temporal (as well as spatial) resolution of MEG could be further exploited here to better capture the early vs. late stages of processing. For instance, by separately examining earlier vs. later time points (instead of averaging across all of them), or by identifying and analyzing data in the sensors that might capture early vs. late stages of processing. Indeed, the S1 and S2 reconstructions show subtle repulsion, which might be magnified at earlier time points but then shift (toward attraction) at later time points, thereby counteracting any effect. Likewise, the S1 reconstruction becomes biased during the S2 epoch, consistent with previous observations that the SD effects grow across a WM delay. Maybe both S1 and S2 would show an attractive bias emerging during the later (delay) portion of their corresponding epoch? As is, the data nicely show that an attractive bias can be detected in the retrocue period activity, but they could still yield further specificity about when and where that bias emerges.</p></disp-quote><p>We are grateful for this suggestion. Before going into detail, we would like to explain our motivation for choosing the present analysis approach that included averaging time points within an epoch of interest.</p><p>Our aim was to detect a neuronal signature of serial dependence which is manifested as an attractive shift of about 3.5° degrees within the 360° direction space. To be able to detect such a small effect in the neural data and given the limited resolution of the reconstruction method and the noisy MEG signals, we needed to maximize the signal-to-noise ratio. A common method to obtain this is by averaging data points. In our study we asked subjects to perform 1022 trials, down-sampled the MEG data from the recorded sampling rate of 1200 Hz to 10 Hz (one data point per 100 ms) that we used for the estimation of reconstruction fidelity and calculated the final neural shift estimates by averaging time points that showed a robust reconstruction fidelity, thus representing interpretable data points.</p><p>Our procedure to maximize the signal-to-noise ratio was successful as we were able to reliably reconstruct the presented and remembered motion direction in all epochs (Figure 1a and 1b in the manuscript). However, the reconstruction did not work equally well for all time points within each epoch. In particular, there were time points with a non-significant reconstruction fidelity. In consequence, for the much smaller neural shift effect we did not expect to observe reliable time-resolved results, i.e., when considering each time point separately. Instead, we used the reconstruction results to define the time window in order to calculate the neural shift, i.e., we averaged across all time points with a significant reconstruction fidelity.</p><p>Author response image 1 depicts the neural shift separately for each time point during the retro-cue epoch. Importantly, the gray parts of the time courses indicate time points where the reconstruction of the presented or cued stimulus was not significant. This means that the reconstructed maxima at those time points were very variable/unreliable and therefore the neural shifts were hardly interpretable.</p><fig id="sa4fig1" position="float"><label>Author response image 1.</label><caption><title>Time courses of the reconstruction shift reveal a tendency for an attractive bias during the retrocue phase.</title><p>Time courses of the neural shift separately for each time point during the S1 (left panel), S2 (middle panel) and retro-cue epochs (right panel). Gray lines indicate time points with non-significant reconstruction fidelities and therefore very variable and non-interpretable neural reconstruction shifts. The colored parts of the lines correspond to the time periods of significant reconstruction fidelities with interpretable reconstruction shifts. Error bars indicate the middle 95% of the resampling distribution. Time points with less than 5% (equaling p &lt; .05) of the resampling distribution below 0° are indicated by a colored circle. N = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99478-sa4-fig1-v1.tif"/></fig><p>First, the time courses in the Author response image 1 show that the neural bias varied considerably between subjects, as revealed by the resampling distributions, at given time points. In this resampling procedure, we drew 10 participants in 10.000 iterations with replacement and calculated the reconstruction shift based on the mean reconstruction of the resampled participants. The observed variability stresses the necessity to average the values across all time points that showed a significant reconstruction fidelity to increase the signal-to-noise ratio.</p><p>Second, despite this high variability/low signal-to-noise ratio, Author response image 1 (right panel) shows that our choice for this procedure was sensible as it revealed a clear tendency of an attractive shift at almost all time points between 300 through 1500 ms after retro-cue onset with only a few individual time-points showing a significant effect (uncorrected for multiple comparisons). It is worth to mention that this time course did not overlap with the time course of previous target cross-reconstruction (Appendix 1—figure 2, right panel), as there was no significant target cross-reconstruction during the retro-cue epoch with an almost flat profile around zero. Also, there was no overlap with previous target decoding in the retro-cue epoch (Figure 5 in the manuscript). Here, the previous target was reactivated significantly only at early time points of 200 and 300 ms post cue onset (i.e., at time points with a non-significant reconstruction fidelity and therefore no interpretable neural shift), while the nominally highest values of the attractive neural shift were visible at later time points that also showed a significant reconstruction fidelity (Figure 2b in the manuscript).</p><p>Third, Author response image 1 (left and middle panel) shows the time courses of the neural shift during the S1 and S2 epochs. While no neural shift could be observed for S1, during the S2 epoch the time-resolved analysis indicated an initial attractive shift followed by a (nonsignificant) tendency for a repulsive shift. After averaging neural shifts across time points with a significant reconstruction fidelity, there was no significant effect with an overall tendency for repulsion, as reported in the paper. The attractive part of the neural shift during the S2 epoch was nominally strongest at very early time points (at 100-300 ms after S2 onset) and overlapped perfectly with the reactivation of the previous target as shown by the cross-reconstruction analysis (Appendix 1—figure 2, middle panel). This overlap suggests that the neural attractive shift did not reflect an actual bias of the early S2 representation, but rather a consequence of the concurrent reactivation of the previous target in the same neural code as the current representation. Finally, this neural attractive shift during S2 presentation did not correlate with the behavioral error (single trial-wise correlation: no significant time points during S2 epoch) or the behavioral bias (subject-wise correlation). In contrast, for the retro-cue epoch, we observed a significant correlation between the neural attractive shift and behavior.</p><p>Together, the time-resolved results show a clear tendency for an attractive neural bias during the retro-cue phase, thus supporting our interpretation that the attractive shift during the retro-cue phase reflects a direct neuronal signature of serial dependence. However, these additional analyses also demonstrated a large variability between participants and across time points, warranting a cautious interpretation. We conclude that our initial approach of averaging across time points was an appropriate way of reducing the high level of noise in the data and revealed the reported significant and robust attractive neural shift in the retrocue phase.</p><disp-quote content-type="editor-comment"><p>(5) A few other potentially interesting (but inessential considerations): A benchmark property of serial dependence is its feature-specificity, in that the attractive bias occurs only between current and previous stimuli that are within a certain range of similarity to each other in feature space. I would be very curious to see if the neural reconstructions manifest this principle - for instance, if one were to plot the trialwise reconstruction deviation from 0, across the full space of current-previous trial distances, as in the behavioral data. Likewise, something that is not captured by the DoG fivng approach, but which this dataset may be in a position to inform, is the commonly observed (but little understood) repulsive effect that appears when current and previous stimuli are quite distinct from each other. As in, Figure 1b shows an attractive bias for direction differences around 30 degrees, but a repulsive one for differences around 170 degrees - is there a corresponding neural signature for this component of the behavior?</p></disp-quote><p>We appreciate the reviewer's idea to split the data. However, given that our results strongly relied on the inclusion of all data points, i.e., including all distances in motion direction between the current S1, S2 or target and the previous target and requiring data averaging, we are concerned that our study was vastly underpowered to be able to inform whether the attractive bias occurs only within a certain range of inter-stimulus similarity. To address this important question, future studies would require neural measurements with much higher signal-to-noise-ratio than the present MEG recordings with two sessions per participant and 1022 trials in total.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>The study aims to probe the neural correlates of visual serial dependence - the phenomenon that estimates of a visual feature (here motion direction) are attracted towards the recent history of encoded and reported stimuli. The authors utilize an established retro-cue working memory task together with magnetoencephalography, which allows to probe neural representations of motion direction during encoding and retrieval (retro-cue) periods of each trial. The main finding is that neural representations of motion direction are not systematically biased during the encoding of motion stimuli, but are attracted towards the motion direction of the previous trial's target during the retrieval (retro-cue period), just prior to the behavioral response. By demonstrating a neural signature of attractive biases in working memory representations, which align with attractive behavioral biases, this study highlights the importance of post-encoding memory processes in visual serial dependence.</p><p>Strengths:</p><p>The main strength of the study is its elegant use of a retro-cue working memory task together with high temporal resolution MEG, enabling to probe neural representations related to stimulus encoding and working memory. The behavioral task elicits robust behavioral serial dependence and replicates previous behavioral findings by the same research group. The careful neural decoding analysis benefits from a large number of trials per participant, considering the slow-paced nature of the working memory paradigm. This is crucial in a paradigm with considerable trial-by-trial behavioral variability (serial dependence biases are typically small, relative to the overall variability in response errors). While the current study is broadly consistent with previous studies showing that attractive biases in neural responses are absent during stimulus encoding (previous studies reported repulsive biases), to my knowledge it is the first study showing attractive biases in current stimulus representations during working memory. The study also connects to previous literature showing reactivations of previous stimulus representations, although the link between reactivations and biases remains somewhat vague in the current manuscript. Together, the study reveals an interesting avenue for future studies investigating the neural basis of visual serial dependence.</p><p>Weaknesses:</p><p>(1) The main weakness of the current manuscript is that the authors could have done more analyses to address the concern that their neural decoding results are driven by signals related to eye movements. The authors show that participants' gaze position systematically depended on the current stimuli's motion directions, which together with previous studies on eye movement-related confounds in neural decoding justifies such a concern. The authors seek to rule out this confound by showing that the consistency of stimulus-dependent gaze position does not correlate with (a) the neural reconstruction fidelity and (b) the repulsive shift in reconstructed motion direction. However, both of these controls do not directly address the concern. If I understand correctly the metric quantifying the consistency of stimulus-dependent gaze position (Figure S3a) only considers gaze angle and not gaze amplitude. Furthermore, it does not consider gaze position as a function of continuous motion direction, but instead treats motion directions as categorical variables. Therefore, assuming an eye movement confound, it is unclear whether the gaze consistency metric should strongly correlate with neural reconstruction fidelity, or whether there are other features of eye movements (e.g., amplitude differences across participants, and tuning of gaze in the continuous space of motion directions) which would impact the relationship with neural decoding. Moreover, it is unclear whether the consistency metric, which does not consider history dependencies in eye movements, should correlate with attractive history biases in neural decoding. It would be more straightforward if the authors would attempt to (a) directly decode stimulus motion direction from x-y gaze coordinates and relate this decoding performance to neural reconstruction fidelity, and (b) investigate whether gaze coordinates themselves are history-dependent and are attracted to the average gaze position associated with the previous trials' target stimulus. If the authors could show that (b) is not the case, I would be much more convinced that their main finding is not driven by eye movement confounds.</p></disp-quote><p>The reviewer is correct that our eye-movement analysis approach considered gaze angle (direction) and not gaze amplitude. We considered gaze direction to be the more important feature to control for when investigating the neural basis of serial dependence that manifests, given the stimulus material used in our study, as a shift/deviation of angle/direction of a representation towards the previous target motion direction. To directly relate gaze direction and MEG data to each other we equaled the temporal resolution of the eye tracking data to match that of the MEG data. Specifically, our analysis procedure of gaze direction provided a measure indicating to which extent the variance of the gaze directions was reduced compared with random gaze direction patterns, in relation to the specific stimulus direction within each 100 ms time bin. Importantly, this procedure was able to reveal not only systematic gaze directions that were in accordance with the stimulus direction or the opposite direction, but also picked up all stimulus-related gaze directions, even if the relation differed across participants or time.</p><p>Our analysis approach was highly sensitive to detect stimulus-related gaze directions during all task phases (Appendix 1—figure 3). As expected, we found systematic gaze directions when S1 and S2 were presented on the screen, and they were reduced thereafter, indicating a clear relationship between stimulus presentation and eye movement. Systematic gaze directions were also present in the retro-cue phase where no motion direction was presented. Here they showed a clearly different temporal dynamic as compared to the S1 and S2 phases. They appeared at later time points and with a higher variability between participants, indicating that they coincided with retrieving the target motion direction from working memory.</p><p>To relate gaze directions with MEG results, we calculated Spearman rank correlations. We found that there was no systematic relationship at any time point between the stimulus related reconstruction fidelity and the amount of stimulus-related gaze direction. Even more, the correlation varied strongly from time point to time point revealing its random nature. In addition to the lack of significant correlations, we observed clearly distinct temporal profiles for gaze direction (Appendix 1—figure 3a and Appendix 1—figure 3b) and the reconstruction fidelities (Figure 2b in the manuscript, Appendix 1—figure 3c), in particular in the critical retro-cue phase.</p><p>We favored this analysis approach over one that directly decoded stimulus motion direction from x-y gaze coordinates, as we considered it hardly feasible to compute an inverted encoding model with only two eye-tracker channels as an input (in comparison to 271 MEG sensors), and to our knowledge, this has not been done before. Other decoding methods have previously been applied to x-y gaze coordinates. However, in contrast to the inverted encoding model, they did not provide a measure of the representation shift which would be crucial for our investigation of serial dependence.</p><p>We appreciate the suggestion to conduct additional analyses on eye tracking data (including different temporal and spatial resolution and different features) and their relation to MEG data. However, the first author, who ran all the analyses, has in the meantime left academia. Unfortunately, we currently do not have sufficient resources to perform additional analyses.</p><p>While the presented eye movement control analysis makes us confident that our MEG finding was not crucially driven by stimulus-related gaze directions, we agree with the reviewer that we cannot completely exclude that other eye movement-related features could have contributed to our MEG findings. However, we would like to stress that whatever that main source for the observed MEG effect was (shift of the neuronal stimulus representation, (other) features of gaze movement, or shift of the neuronal stimulus representation that leads to systematic gaze movement), our study still provided clear evidence that serial dependence emerged at a later post-encoding stage of object processing in working memory. This central finding of our study is hard to observe with behavioral measures alone and is not affected by the possible effects of eye movements.</p><p>We have slightly modified our conclusion in the Results and Appendix 1. Please see also our response to comment 1 from reviewer 3.</p><disp-quote content-type="editor-comment"><p>(2) I am not convinced by the across-participant correlation between attractive biases in neural representations and attractive behavioral biases in estimation reports. One would expect a correlation with the behavioral bias amplitude, which is not borne out. Instead, there is a correlation with behavioral bias width, but no explanation of how bias width should relate to the bias in neural representations. The authors could be more explicit in their arguments about how these metrics would be functionally related, and why there is no correlation with behavioral bias amplitude.</p></disp-quote><p>We are grateful for this suggestion. We correlated the individual neuronal shift with the two individual parameter fits of the behavior shift, i.e., amplitude (a) and tuning width (w). We found a significant correlation between the individual neural bias and the w parameter (r = .70, p = .0246) but not with the a parameter (r = -.35, p = .3258) during the retro-cue period (Appendix 1—figure 1). This indicates that a broader tuning width of the individual bias (as reflected by a smaller w parameter) was associated with a stronger individual neural attraction.</p><p>It is important to note that for the calculation of the neural shift, all trials entered the analysis to increase the signal-to-noise ratio, i.e., it included many trials where current and previous targets were separated by, e.g., 100° or more. These trials were unlikely to produce serial dependence. Subjects with a more broadly tuned serial dependence had more interitem differences that showed a behavioral attraction and therefore more trials affected by serial dependence that entered the calculation of the neural shift. In contrast, individual differences in the amplitude (a) parameter were most likely too small, and higher individual amplitude did not involve more trials as compared to smaller amplitude to affect the neural bias in a way to be observed in a significant correlation.</p><p>We have added this explanation to Appendix 1.</p><disp-quote content-type="editor-comment"><p>(3) The sample size (n = 10) is definitely at the lower end of sample sizes in this field. The authors collected two sessions per participant, which partly alleviates the concern. However, given that serial dependencies can be very variable across participants, I believe that future studies should aim for larger sample sizes.</p></disp-quote><p>We want to express our appreciation for raising this issue. We apologize that we did not explicitly explain and justifythe choice for the sample size used in our paper, in particular, as we had in fact performed a formal a-priori power analysis.</p><p>At the time of the sample size calculation, there were no comparable EEG or MEG studies to inform our power calculation. Thus, we based our calculation merely on the behavioral effect reported in the literature and, in particular, observed in a behavioral study from our lab that included four different experiments with overall more than 100 participants with 1632 trials each (see Fischer et al., 2020), in which the behavioral serial dependence effect (target vs. nontarget) was very robust. Based on the contrast between target and non-target with an effect size of 1.359 in Experiment 1, a power analysis with 80% desired power led to a small, estimated sample size of 6 subjects.</p><p>However, we expected that the detection of the neural signature of this effect would require more participants. Therefore, we based our power calculation on a much smaller behavioral effect, i.e. the modulation of serial dependence by the context-feature congruency that we observed in our previous study (Fischer et al., 2020). In particular, we focused on Experiment 1 of the previous study that used color as the feature for retro-cueing, as we planned to use exactly the same paradigm for the MEG study. In contrast to the serial dependence effect, its modulation by color resulted in a more conservative power estimate: Based on an effect size of 0.856 in that experiment, a sample size of n = 10 should yield a power of 80% with two MEG sessions per subject.</p><p>At the time when we conducted our study, two other studies were published that investigated serial dependence on the neural level. Both studies included a smaller number of data points than our study: Sheehan &amp; Serences (2022) recorded about 840 trials in each of 6 participants, resulting in fewer data points both on the participant and on the trial level. Hajonides et al. (2023) measured 20 participants with 400 trials each, again resulting in fewer datapoints than our study (10 participants with 1022 trials each). Taken together, our a-priori sample size estimation resulted in comparable if not higher power as compared to other similar studies, making us feel confident that the estimated sample was sufficient to yield reliable results.</p><p>We have now included this description and the results of this power analysis in the Materials and Methods section.</p><p>Despite this, we fully agree with the reviewer that our study would profit from higher power. With the knowledge of the results from this study, future projects should attempt to increase substantially the signal-to-noise-ratio by increasing the number of trials in particular, in order to observe, e.g., robust time-resolved effects (see our comments to review 1).</p><p>References:</p><p>Fischer C, Czoschke S, Peters B, Rahm B, Kaiser J, Bledowski C (2020) Context information supports serial dependence of multiple visual objects across memory episodes. Nature Communication 11: 1932.</p><p>Sheehan TC, Serences JT (2022) Attractive serial dependence overcomes repulsive neuronal adaptation PLOS Biology 20: e3001711.</p><p>Hajonides JE, Van Ede F, Stokes MG, Nobre AC, Myers NE (2023) Multiple and Dissociable Effects of Sensory History on Working-Memory Performance Journal of Neuroscience 43: 2730–2740.</p><disp-quote content-type="editor-comment"><p>(4) It would have been great to see an analysis in source space. As the authors mention in their introduction, different brain areas, such as PPC, mPFC, and dlPFC have been implicated in serial biases. This begs the question of which brain areas contribute to the serial dependencies observed in the current study. For instance, it would be interesting to see whether attractive shifts in current representations and pre-stimulus reactivations of previous stimuli are evident in the same or different brain areas.</p></disp-quote><p>We appreciate this suggestion. As mentioned above, we currently do not have sufficient resources to perform a MEG source analysis.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Summary:</p><p>This study identifies the neural source of serial dependence in visual working memory, i.e., the phenomenon that recall from visual working memory is biased towards recently remembered but currently irrelevant stimuli. Whether this bias has a perceptual or postperceptual origin has been debated for years - the distinction is important because of its implications for the neural mechanism and ecological purpose of serial dependence. However, this is the first study to provide solid evidence based on human neuroimaging that identifies a post-perceptual memory maintenance stage as the source of the bias. The authors used multivariate pattern analysis of magnetoencephalography (MEG) data while observers remembered the direction of two moving dot stimuli. After one of the two stimuli was cued for recall, decoding of the cued motion direction re-emerged, but with a bias towards the motion direction cued on the previous trial. By contrast, decoding of the stimuli during the perceptual stage was not biased.</p><p>Strengths:</p><p>The strengths of the paper are its design, which uses a retrospective cue to clearly distinguish the perceptual/encoding stage from the post-perceptual/maintenance stage, and the rigour of the careful and well-powered analysis. The study benefits from high within participant power through the use of sensitive MEG recordings (compared to the more common EEG), and the decoding and neural bias analysis are done with care and sophistication, with appropriate controls to rule out confounds.</p><p>Weaknesses:</p><p>A minor weakness of the study is the remaining (but slight) possibility of an eye movement confound. A control analysis shows that participants make systematic eye movements that are aligned with the remembered motion direction during both the encoding and maintenance phases of the task. The authors go some way to show that this eye gaze bias seems unrelated to the decoding of MEG data, but in my opinion do not rule it out conclusively. They merely show that the strengths of the gaze bias and the strength of MEGbased decoding/neural bias are uncorrelated across the 10 participants. Therefore, this argument seems to rest on a null result from an underpowered analysis.</p></disp-quote><p>Our MEG as well eye-movement analysis showed that they were sensitive to pick up robustly stimulus-related effects, both for presented and remembered motion directions. When relating both signals to each other by correlating MEG reconstruction strength with gaze direction, we found a null effect, as pointed out by the reviewer. Importantly, there was also a null effect when the shift of the reconstruction (representing our main finding) was correlated with gaze direction. Furthermore, an examination of the individual time courses of gaze direction and individual MEG reconstruction strength revealed that the lack of a relationship between MEG and gaze data did not rest on a singular observation but was present across all time points. Even more, the temporal profile of the correlation varied strongly from time point to time point revealing its random nature and indicating that there was no hint of a pattern that just failed to reach significance. Taking these observations together, our MEG findings were unlikely to be explained by eye position.</p><p>Nevertheless, we agree with the reviewer that there is general problem of interpreting a null effect with a limited number of observations (and an analysis approach that focused on one out of many possible features of the gaze movement). Thus, we admit that there is a (slight) possibility that eye movements contributed to the observed MEG effects. This possibility, however, did not affect our novel finding that serial dependence occurred during the postencoding stage of object processing in working memory.</p><p>Please see also our response to point 1 from reviewer 2.</p><disp-quote content-type="editor-comment"><p>Impact:</p><p>This important study contributes to the debate on serial dependence with solid evidence that biased neural representations emerge only at a relatively late post-perceptual stage, in contrast to previous behavioural studies. This finding is of broad relevance to the study of working memory, perception, and decision-making by providing key experimental evidence favouring one class of computational models of how stimulus history affects the processing of the current environment.</p><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>Minor concerns:</p><p>The significance statement opens &quot;Our perception is biased towards sensory input from the recent past.&quot; This is a semantic point, but it seems a somewhat odd statement, given there is so much debate about whether serial dependence is perceptual vs. decisional, and that the current work indeed claims that it emerges at a late, post-encoding stage.</p></disp-quote><p>Thank you for this point. We agree. “Visual cognition is biased towards sensory input from the recent past.” would be a more appropriate statement. According to the Journal's guidelines, however, the paragraph with the Significant Statement will be not included in the final manuscript.</p><disp-quote content-type="editor-comment"><p>It would be preferable for data and code to be available at review so that reviewers might verify some procedural points for clarity.</p></disp-quote><p>Code and preprocessed data used for the presented analyses are now available on OSF via <ext-link ext-link-type="uri" xlink:href="http://osf.io/yjc93/">http://osf.io/yjc93/</ext-link>. Due to storage limitations, only the preprocessed MEG data for the main IEM analyses focusing on the current direction are uploaded. For access to additional data, please contact the authors.</p><disp-quote content-type="editor-comment"><p>For instance, I could use some clarification on the trial sequence. The methods first say the direction was selected randomly, but then later say each direction occurred equally often, and there were restrictions on the relationships between current and previous trial items. So it seems it couldn't have truly been random direction selection - was the order selected randomly from a predetermined set of possibilities?</p></disp-quote><p>For the S1/S2 stimuli in a trial the dots moved fully coherent in a direction randomly drawn from a pool of directions between 5° and 355° spaced 10° from one another, therefore avoiding cardinal directions. Across trials, there was a predetermined set of possible differences in motion direction between the current and the previous target. This set included 18 motion direction differences, ranging from -170° to 180°, in steps of 10°. Trial sequences were balanced in a way that each of these differences occurred equally often during a MEG session.</p><disp-quote content-type="editor-comment"><p>I could also use some additional assurance the sample size (participants or data points) is sufficient for the analysis approach deployed here.</p></disp-quote><p>We performed a formal a-priori power analysis to justify our choice for the sample size. Please see our response to reviewer 2, point 3, where we explained the procedure of the apriori power analysis in detail. We have now included this description and the results of this power analysis in the Materials and Methods.</p><disp-quote content-type="editor-comment"><p>Did you consider a decoding approach, instead of reconstruction, to test what information predominates the signal, in an unbiased way?</p></disp-quote><p>Thank you for this argument. With our analysis approach based on the inverted encoding model, we believe to be unbiased, since we first reconstructed whether the MEG signal contained information about the presented and remembered motion direction. Only in the next step, we tested whether this reconstructed signal showed an offset and if so, whether this offset was biased towards or away from the previous target. A decoding approach aims to answer classification questions and is not suitable to reveal the actual shifts of the neural information. In our study, we could decode, e.g., the current direction or the previous target, but this would not answer the question of whether and at which stage of object processing the current representation was biased towards the past. Moreover, in a decoding approach to reveal which information predominates in the signal, we would have to classify different options (e.g. current information vs previous), thereby biasing the possible set of results more than in our chosen analysis.</p><disp-quote content-type="editor-comment"><p>I think the claim of a &quot;direct&quot; neural signature may come off as an overstatement when the spatial and temporal aspects of the attractive bias are still so coarsely specified here.</p></disp-quote><p>Thank you for pointing this out. We agree that the term “direct neural signature” can be seen as an overstatement when it is interpreted to indicate a narrowly defined activity of a brain region (ideally via “direct” invasive recordings) that reflects serial dependence. Our definition of the term “direct” referred to the observation of an attractive shift in a neural representation of the current target motion direction item towards the previous target. This was in contrast to previous “indirect” evidence for the neural basis of serial dependence based on either repulsive shifts of neural representations that were opposite to the attractive bias in behavior or on a reactivation of previous information in the current trial without presenting evidence for the actual neural shift. With this definition in mind, we consider the title of our study a valid description of our findings.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>I was wondering why the authors chose a bootstrap test for their neural bias analysis instead of a permutation test, similar to the one they used for their behavioral analysis. As far as I know, bootstrap tests do not provide guaranteed type-1 error rate control. The procedure for the permutation test would be quite straightforward here, randomly permuting the sign of each participant's neural shift and recording the group-average shift in a permutation distribution. This test seems more adequate and more consistent with the behavioral analysis.</p></disp-quote><p>Thank you for this comment. We adapted a resampling approach (bootstrapping) that was similar to that by Ester et al. (2020) who also investigated categorical biases and also applied a reconstruction method (Inverted Encoding Model) to assess significance of a bias of the reconstructed orientation against zero in a certain direction. The bootstrapping method relied on (a) detecting an offset against zero and (b) evaluating the robustness of the observed effect across participants. In contrast, a permutation approach, as suggested by the reviewer, assesses whether an empirical neural shift is more extreme than the permutation distribution. The permutation approach seems more suited to assess the magnitude of the shift which in our study was not a priority. Therefore, we reasoned that the bootstrapping for our inference statistics was better suited to assess the direction of the neural shift and its robustness across participants.</p><p>We have added this additional information to the Materials and Methods:</p><p>References:</p><p>Ester EF, Sprague TC, Serences JT (2020) Categorical biases in human occipitoparietal cortex. Journal of Neuroscience 40:917–931.</p><disp-quote content-type="editor-comment"><p>The manuscript could be improved by more clearly spelling how the training and testing data were labelled, particularly for the reactivation analyses. If I understood correctly, in the first reactivation analysis the authors train and test on current trial data, but label both training and testing data according to the previous trial's motion direction. In the second analysis, they label the training data according to the current motion direction, but label the testing data according to the previous motion direction. Is that correct?</p></disp-quote><p>Yes, this is correct. Please see also our response to reviewer 1, point 2 and 3, for a detailed description.</p><disp-quote content-type="editor-comment"><p>I was surprised to see that the shift in the reconstructed direction is about three times larger than the behavioral attraction bias. Would one not expect these to be comparable in magnitude? It would be helpful to address and discuss this in the discussion section.</p></disp-quote><p>Thank you for pointing this out. We agree with the reviewer that as both measures provided an identical metric (angle degree), one would expect that their magnitudes should be directly comparable. However, we speculate that these magnitudes inform only about the direction of the bias and their significant difference from zero, thus they operate on different scales and are not directly comparable. For example, Hallenbeck et al. (2022) showed that fMRI-based reconstructed orientation bias and behavioral bias correlated on both individual and group level, despite strong magnitude differences. This is in line with our observation and supports the speculation that the magnitudes of neural and behavioral biases operate on different scales and, thus, are not directly comparable.</p><p>We have updated to the Discussion accordingly.</p><p>References:</p><p>Hallenbeck GE, Sprague TC, Rahmati M, Sreenivasan KK, Curtis CE (2022) Working memory representations in visual cortex mediate distraction effects Nature Communications 12: 471.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>(1) It may be worth showing that the gaze bias towards the current/cued stimulus is not biased towards the previous target. One option might be to run the same analysis pipeline used for the MEG decoding but on the eye-tracking data. Another could be to remove all participants with significant gaze bias, but given the small sample size, this might not be feasible.</p></disp-quote><p>We appreciate this suggestion. However, as mentioned above, we currently do not have sufficient resources to conduct additional analyses on the eye tracking data.</p><disp-quote content-type="editor-comment"><p>(2) Minor typo: Figure 3c - bias should be 11.7º, not -11.7º.</p></disp-quote><p>Corrected. Thank you!</p><disp-quote content-type="editor-comment"><p>Note on data/code availability: The authors state that preprocessed data and analysis code will be made available on publication, but are not available yet.</p></disp-quote><p>Code and preprocessed data used for the present analyses are now available on OSF via <ext-link ext-link-type="uri" xlink:href="http://osf.io/yjc93/">http://osf.io/yjc93/</ext-link>. Due to storage limitations, only the preprocessed MEG data for the main IEM analyses focusing on the current direction are uploaded. For access to additional data, please contact the authors.</p></body></sub-article></article>