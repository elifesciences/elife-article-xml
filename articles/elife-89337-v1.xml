<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">89337</article-id><article-id pub-id-type="doi">10.7554/eLife.89337</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89337.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>Neural criticality from effective latent variables</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-319183"><name><surname>Morrell</surname><given-names>Mia C</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-7348"><name><surname>Nemenman</surname><given-names>Ilya</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-266658"><name><surname>Sederberg</surname><given-names>Audrey</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4458-3773</contrib-id><email>audrey.sederberg@gatech.edu</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="pa1">†</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Department of Physics, New York University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03czfpz43</institution-id><institution>Department of Physics, Department of Biology, Initiative in Theory and Modeling of Living Systems, Emory University</institution></institution-wrap><addr-line><named-content content-type="city">Atlanta</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/017zqws13</institution-id><institution>Department of Neuroscience, University of Minnesota Medical School</institution></institution-wrap><addr-line><named-content content-type="city">Minneapolis</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>School of Psychology and School of Physics, Georgia Institute of Technology, Atlanta, United States</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>12</day><month>03</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP89337</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-05-30"><day>30</day><month>05</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-06-08"><day>08</day><month>06</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.48550/arXiv.2301.00759"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-09-12"><day>12</day><month>09</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89337.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-02-02"><day>02</day><month>02</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89337.2"/></event></pub-history><permissions><copyright-statement>© 2023, Morrell et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Morrell et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-89337-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-89337-figures-v1.pdf"/><abstract><p>Observations of power laws in neural activity data have raised the intriguing notion that brains may operate in a critical state. One example of this critical state is ‘avalanche criticality’, which has been observed in various systems, including cultured neurons, zebrafish, rodent cortex, and human EEG. More recently, power laws were also observed in neural populations in the mouse under an activity coarse-graining procedure, and they were explained as a consequence of the neural activity being coupled to multiple latent dynamical variables. An intriguing possibility is that avalanche criticality emerges due to a similar mechanism. Here, we determine the conditions under which latent dynamical variables give rise to avalanche criticality. We find that populations coupled to multiple latent variables produce critical behavior across a broader parameter range than those coupled to a single, quasi-static latent variable, but in both cases, avalanche criticality is observed without fine-tuning of model parameters. We identify two regimes of avalanches, both critical but differing in the amount of information carried about the latent variable. Our results suggest that avalanche criticality arises in neural systems in which activity is effectively modeled as a population driven by a few dynamical variables and these variables can be inferred from the population activity.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural criticality</kwd><kwd>latent dynamics</kwd><kwd>fine-tuning</kwd><kwd>power laws</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>Simons-Emory Consortium on Motor Control</award-id><principal-award-recipient><name><surname>Nemenman</surname><given-names>Ilya</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>BCS/1822677</award-id><principal-award-recipient><name><surname>Nemenman</surname><given-names>Ilya</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>2R01NS084844</award-id><principal-award-recipient><name><surname>Nemenman</surname><given-names>Ilya</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>1RF1MH130413</award-id><principal-award-recipient><name><surname>Sederberg</surname><given-names>Audrey</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>Investigator Program</award-id><principal-award-recipient><name><surname>Nemenman</surname><given-names>Ilya</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Signatures of criticality that have been observed across diverse neural systems, such as power-law avalanche distributions and exponent relationships, can arise without fine-tuning in networks coupled to latent, dynamical variables.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The neural criticality hypothesis – the idea that neural systems operate close to a phase transition, perhaps for optimal information processing – is both ambitious and banal. Measurements from biological systems are limited in the range of spatial and temporal scales that can be sampled, not only because of the limitations of recording techniques but also due to the fundamentally non-stationary behavior of most, if not all, biological systems. These limitations make proving that an observation indicates critical behavior difficult. At the same time, the idea that brain networks are critical echoes the anthropic principle: tuned another way, a network becomes quiescent or epileptic and in either state, seems unlikely to support perception, thought, or flexible behavior, yet these observations do not explain how such fine-tuning could be achieved. Further muddying the water, researchers have reported multiple kinds of criticality in neural networks, including through analysis of avalanches (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>; <xref ref-type="bibr" rid="bib32">Plenz et al., 2021</xref>; <xref ref-type="bibr" rid="bib28">O’Byrne and Jerbi, 2022</xref>; <xref ref-type="bibr" rid="bib13">Girardi-Schappo, 2021</xref>) and of coarse-grained activity (<xref ref-type="bibr" rid="bib23">Meshulam et al., 2019</xref>), as well as of correlations (<xref ref-type="bibr" rid="bib10">Dahmen et al., 2019</xref>). How these flavors of critical behavior relate to each other or any functional network mechanism is unknown.</p><p>The phenomenon that we will refer to as ‘avalanche criticality’ appears remarkably widespread. It was first observed in cultured neurons (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>) and later studied in zebrafish (<xref ref-type="bibr" rid="bib34">Ponce-Alvarez et al., 2018</xref>), turtles (<xref ref-type="bibr" rid="bib39">Shew et al., 2015</xref>), rodents (<xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref>), monkeys (<xref ref-type="bibr" rid="bib31">Petermann et al., 2009</xref>), and even humans (<xref ref-type="bibr" rid="bib33">Poil et al., 2008</xref>). The standard analysis, described later, requires extracting power-law exponents from fits to the distributions of avalanche size and of duration and assessing the relationship between exponents. There is debate over whether these observations reflect true power laws, but within the resolution achievable from experiments, neural avalanches exhibit power laws with exponent relationships predicted from theory developed in physical systems (<xref ref-type="bibr" rid="bib30">Perkovic et al., 1995</xref>).</p><p>Avalanche criticality is not the only form of criticality observed in neural systems. Zipf’s law, in which the frequency of a network state is inversely proportional to its rank, appears in systems as diverse as fly motion estimation and the salamander retina (<xref ref-type="bibr" rid="bib24">Mora and Bialek, 2011</xref>; <xref ref-type="bibr" rid="bib36">Schwab et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Aitchison et al., 2016</xref>). More recently, <xref ref-type="bibr" rid="bib23">Meshulam et al., 2019</xref> reported various statistics of population activity in the mouse hippocampus, including the eigenvalue spectrum of the covariance matrix and the activity variance. These were found to scale as populations were ‘coarse-grained’ through a procedure in which neural activities were iteratively combined based on similarity. Similar observations have been reported in spontaneous activity recorded across a wide range of brain areas in the mouse (<xref ref-type="bibr" rid="bib25">Morales et al., 2023</xref>). Simple neural network models of such data explain neither Zipf’s law nor coarse-grained criticality (<xref ref-type="bibr" rid="bib23">Meshulam et al., 2019</xref>).</p><p>Even though these three forms of criticality are observed through different analyses, they may originate from similar mechanisms. Numerous studies have reported relatively low-dimensional structure in the activity of large populations of neurons (<xref ref-type="bibr" rid="bib22">Mazor and Laurent, 2005</xref>; <xref ref-type="bibr" rid="bib1">Ahrens et al., 2012</xref>; <xref ref-type="bibr" rid="bib20">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Pandarinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib40">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="bib27">Nieh et al., 2021</xref>), which can be modeled by a population of neurons that are broadly and heterogeneously coupled to multiple latent (i.e. unobserved) dynamical variables. Using such a model, we previously reproduced scaling under coarse-graining analysis within experimental uncertainty (<xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>). Zipf’s law has been explained by a similar mechanism (<xref ref-type="bibr" rid="bib36">Schwab et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Aitchison et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Humplik and Tkačik, 2017</xref>). A single quasi-static latent variable has been shown to produce avalanche power laws, but not the relationships expected between the critical exponents (<xref ref-type="bibr" rid="bib35">Priesemann and Shriki, 2018</xref>), while a model including a global modulation of activity can generate avalanche criticality (<xref ref-type="bibr" rid="bib21">Mariani et al., 2021</xref>), but has not demonstrated coarse-grained criticality (<xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>). It is not known under what conditions the more general latent dynamical variable model generates avalanche criticality.</p><p>Here, we examine avalanche criticality in the latent dynamical variable model of neural population activity. We find that avalanche criticality is observed over a wide range of parameters, some of which may be optimal for information representation. These results demonstrate how criticality in neural recordings can arise from latent dynamics in neural activity, without need for fine-tuning of network parameters.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Critical exponents values and crackling noise</title><p>We begin by defining the metrics used to quantify avalanche statistics and briefly summarize experimental observations, which have been reviewed in detail elsewhere (<xref ref-type="bibr" rid="bib32">Plenz et al., 2021</xref>; <xref ref-type="bibr" rid="bib28">O’Byrne and Jerbi, 2022</xref>; <xref ref-type="bibr" rid="bib13">Girardi-Schappo, 2021</xref>). Activity is recorded across a set of neurons and binned in time. Avalanches are then defined as contiguous time bins, in which at least one neuron in the population is active. The duration of an avalanche is the number of contiguous time bins and the size is the summed activity during the avalanche. The distributions of avalanche size and duration are fit to power laws (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> for size <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> for duration <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi></mml:mstyle></mml:math></inline-formula>) using standard methods (<xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref>).</p><p>Power laws can be indicative of criticality, but they can also result from non-critical mechanisms (<xref ref-type="bibr" rid="bib41">Touboul and Destexhe, 2017</xref>; <xref ref-type="bibr" rid="bib35">Priesemann and Shriki, 2018</xref>). A more stringent test of criticality is the ‘crackling’ relationship (<xref ref-type="bibr" rid="bib30">Perkovic et al., 1995</xref>; <xref ref-type="bibr" rid="bib41">Touboul and Destexhe, 2017</xref>), which involves fitting a third power-law relationship, <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>S</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, and comparing <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> to the predicted exponent <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, derived from the size and duration exponents, <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mover><mml:mo>=</mml:mo><mml:mo>?</mml:mo></mml:mover><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Previous work demonstrating approximate power laws in size and duration distributions through the mechanism of a slowly changing latent variable did not generate crackling (<xref ref-type="bibr" rid="bib41">Touboul and Destexhe, 2017</xref>; <xref ref-type="bibr" rid="bib35">Priesemann and Shriki, 2018</xref>).</p><p>Measuring power-laws in empirical data is challenging: it generally requires setting a lower cut-off in the size and duration, and the power-law behavior only has limited range due to the finite size and duration of the recording itself. Nonetheless, there is some consensus (<xref ref-type="bibr" rid="bib39">Shew et al., 2015</xref>; <xref ref-type="bibr" rid="bib11">Fontenele et al., 2019</xref>; <xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref>) that even if <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> vary over a wide range (1.5 to about 3) across recordings, the values of <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> stay in a relatively narrow range, from about 1.1 to 1.3.</p></sec><sec id="s2-2"><title>Avalanche scaling in a latent dynamical variable model</title><p>We study a model of a population of neurons that are not coupled to each other directly but are driven by a small number of latent dynamical variables – that is, slowly changing inputs that are not themselves measured (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). We are agnostic as to the origin of these inputs: they may be externally driven from other brain areas, or they may arise from large fluctuations in local recurrent dynamics. The model was chosen for its simplicity, and because we have previously shown that this model with at least about five latent variables can produce power laws under the coarse-graining analysis (<xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>). In this paper, we examine avalanche criticality in the same model.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Latent dynamical variable model produces avalanche criticality.</title><p>Simulated network is <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1024</mml:mn></mml:mstyle></mml:math></inline-formula> neurons. Other parameters in <xref ref-type="table" rid="table1">Table 1</xref>. (<bold>A</bold>) Model structure. Latent dynamical variables <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> are broadly coupled to neurons <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> in the recorded population. (<bold>B</bold>) Raster plot of a sample of activity binned at 3 ms resolution across 128 neurons with five latent variables, each with correlation timescale <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>15</mml:mn><mml:mo>⁢</mml:mo><mml:mtext>s</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>C</bold>) Projection of activity into a simulated field of view for illustration. (<bold>D-F</bold>) Avalanche analysis in a network (parameters <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mstyle></mml:math></inline-formula>), showing size distribution (<bold>D</bold>), duration distribution (<bold>E</bold>), and size with duration scaling (<bold>F</bold>). Lower cutoffs used in fitting are shown with vertical lines and their values are indicated in the figures. There are <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>42725</mml:mn></mml:mstyle></mml:math></inline-formula> avalanches of size <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> in this simulated dataset. Estimated values of the critical exponents are shown in the titles of the panels.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig1-v1.tif"/></fig><p>Specifically, we model the neurons as binary units (<inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) that are randomly (<inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>) coupled to dynamical variables <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The probability of any pattern <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, given the current state of the latent variables, is<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where the parameter <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> controls the scaling of the variables and <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> controls the overall activity level. We modeled each latent variable as an Ornstein-Uhlenbeck process with the time scale <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (see Materials and methods). Thus our model has four parameters: <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> (input scaling), <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> (activity threshold), <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (dynamical timescale), and <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (number of latent variables).</p><p>Distributions of avalanche size and avalanche duration within this model followed approximate power laws (<xref ref-type="fig" rid="fig1">Figure 1C</xref>; see Materials and methods). In the example shown (<inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mstyle></mml:math></inline-formula>), we found exponents <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.89</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:math></inline-formula> (size) and <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2.11</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:math></inline-formula> (duration). Further, the average size of avalanches with fixed duration scaled as <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>∼</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>γ</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, with the fitted <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.24</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:math></inline-formula>, in agreement with the predicted value <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.24</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:math></inline-formula>. Thus, our model could generate avalanche scaling, at least for some parameter choices. In the following sections, we examine how avalanche scaling depends on model parameters (<inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>; see Table 2). We first focus on two sets of simulations: one set with <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> latent variable, which does not generate scaling under coarse-graining (<xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>), and one set with <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula> latent variables, which can generate such scaling for some values of parameters <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>; <xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Simulation parameters for <xref ref-type="fig" rid="fig1">Figure 1</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Description</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">bias towards silence</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">variance multiplier</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>4.0</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">number of latent fields</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">latent field time constant</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">number of cells</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1024</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s2-3"><title>Avalanche scaling depends on the number of latent variables</title><p>We analyzed avalanches from one- and five-variable simulations, each with fixed latent dynamical timescale (<inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> time steps; see <xref ref-type="table" rid="table2">Table 2</xref> for parameters). In the following sections, time is measured in simulation time steps, see Materials and methods for converting time steps to seconds. We used established methods for measuring empirical power laws (<xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref>). The minimum cutoffs for size (<inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>S</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) and duration (<inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) are indicated by vertical lines in <xref ref-type="fig" rid="fig2">Figure 2</xref>. For the population coupled to a single latent variable, the avalanche size distribution was not well fit by a power law (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). With a sufficiently high minimum cut-off (<inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>), the duration distribution was approximately power-law (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Simulation parameters for <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Description</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">bias towards silence</td><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mstyle></mml:math></inline-formula> (for <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>) or <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mstyle></mml:math></inline-formula> (for <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula>)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">variance multiplier</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>4.0</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">number of latent fields</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext> or </mml:mtext><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">latent field time constant</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msup><mml:mn>.10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">number of cells</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1024</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Multiple latent variables generate avalanche scaling at shorter timescales than a single latent variable.</title><p>Simulated network is <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1024</mml:mn></mml:mstyle></mml:math></inline-formula> neurons. Other parameters used for simulations for this figure are found in <xref ref-type="table" rid="table2">Table 2</xref>. (<bold>A-C</bold>) Scaling analysis for one variable models where the dynamic timescale is equal to 5×10<sup>3</sup> time steps. (<bold>A</bold>) Distribution of avalanche sizes. MLE value of exponent for best-fit power law is <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.98</mml:mn></mml:mstyle></mml:math></inline-formula> (0.02 SE), with lower cutoff indicated by the vertical line. (<bold>B</bold>) Distribution of avalanche duration. MLE value of <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> is 1.81 (0.02 SE). (<bold>C</bold>) Average size plotted against avalanche duration (blue points), with power-law fit (black line) and predicted relationship (yellow line) from MLE values for exponents in A and B. Gray bar on the horizontal axis indicates range, over which a power law with <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.72</mml:mn></mml:mstyle></mml:math></inline-formula> fits the data (see Materials and methods). (<bold>D-F</bold>) Analysis of avalanches from a simulation of a population coupled to five independent latent variables where the dynamic timescale is equal to 5×10<sup>3</sup> time steps. (<bold>G</bold>) Exponents <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> for avalanche size distributions across timescales for one-variable (blue) and five-variable (red) simulations. Each circle is a simulation with independently drawn coupling parameters. Simulations had to show scaling over at least two decades to be included in panels (<bold>G–J</bold>). (<bold>H</bold>) Exponents <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> for avalanche duration distributions for simulations in G. (<bold>I</bold>) Fitted values of <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> for simulations in G. (<bold>J</bold>) Difference between fitted and predicted <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> values. Five-variable simulations produce crackling over a wider range of timescales than single-variable simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Illustration of algorithm for determining <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>, using one variable example in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title><p>(<bold>A-B</bold>) Probability density function for avalanche size (<bold>A</bold>) and duration (<bold>B</bold>) on a log-log scale, with the best power law fit (red). (<bold>C-D</bold>) In blue: Maximum likelihood exponent of a power-law model as a function of the minimum (lower cutoff) size (<bold>C</bold>) and duration (<bold>D</bold>). In red: KS statistics (see Materials and methods) for each fit. ‘Best fit‘ is the power law with the minimum KS statistic. (<bold>E-F</bold>) Surrogate data procedure. To generate each surrogate, samples were drawn from a power law with size / duration cutoff indicated (<bold>E</bold>, <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>S</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>; <bold>F</bold>, <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>18</mml:mn></mml:mstyle></mml:math></inline-formula>) and the KS statistic was computed. Histograms illustrate KS statistic across surrogates (blue), while values derived from data are in red. Because the red line does not fall within the blue histogram, the hypothesis that the data is fitted well by a power law fit was rejected in E. At the same time, since the red line falls within the blue histogram in F, the hypothesis was accepted.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Illustration of algorithm for determining <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>, using example in <xref ref-type="fig" rid="fig2">Figure 2</xref>, five latent variables.</title><p>Notation the same as in <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Illustration of algorithm for fitting the exponent <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> and determining the range, over which power law scaling of average size with duration is observed, using example in <xref ref-type="fig" rid="fig2">Figure 2(A–D)</xref>.</title><p>(<bold>A-C</bold>) Determining the lower bound, the minimum duration <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. (<bold>A</bold>) The relation <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-OP MJX-fixedlimits"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-OP MJX-fixedlimits"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mi>D</mml:mi></mml:mstyle></mml:math></inline-formula> was fit using linear least-squares, restricted to (overlapping) 1-decade ranges (blue, red: example decades). (<bold>B</bold>) Confidence intervals for fit parameters (<inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mstyle></mml:math></inline-formula>) for fits starting at each value of <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. (<bold>C</bold>) Best value of <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> was selected based on how many subsequent start points yielded consistent slope/intercept values. (<bold>D-F</bold>) Determining the upper bound, maximum duration.<inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (<bold>D</bold>) Keeping <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> fixed based of value obtained in C, we test values of <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> up to the maximum duration event, and fit over the range.<inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula> (<bold>E</bold>) Average residual over the fit range <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>, calculated for each fit and plotted against the value of <inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> used for that fit. The largest value of <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> without evidence of bias in the residual was then selected. (<bold>F</bold>) Final fit and range.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Illustration of algorithm for fitting the exponent <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> and determining the range over which power-law scaling of average size with duration is observed, using example in <xref ref-type="fig" rid="fig2">Figure 2E–H</xref>.</title><p>See <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> for caption. In this example, a lower value of <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> was selected. Panel E, which was flat for <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, now shows how extending the range to high values of <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> can generate systematic errors at the low range of the fit, even while having a high overall goodness of fit metric.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig2-figsupp4-v1.tif"/></fig></fig-group><p>We next assessed whether the simulation produced crackling. If so, the value <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> obtained by fitting <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>S</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> would be similar to <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:math></inline-formula>. In many cases, such as the one-variable example shown in <xref ref-type="fig" rid="fig2">Figure 2C</xref>, the full range of avalanche durations were not fit by a single power law. Therefore, we determined the largest range, over which a power law was a good fit to the simulated observations. In this case, slightly over two decades of apparent scaling were observed starting from avalanches with minimum duration slightly less than 100 time steps (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), with a best-fit value of <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1.69</mml:mn><mml:mo>,</mml:mo><mml:mn>1.74</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>. As we did not find a power-law in the size distribution, calculating <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is meaningless. If we do it anyway, we obtain <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.83</mml:mn><mml:mo>±</mml:mo><mml:mn>0.03</mml:mn></mml:mstyle></mml:math></inline-formula> (yellow line in <xref ref-type="fig" rid="fig2">Figure 2C</xref>), which clearly deviates from the fitted value of <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula>. Thus, for the single latent dynamical variable model (<inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5000</mml:mn></mml:mstyle></mml:math></inline-formula>), power-law fits are poor, and there is no crackling.</p><p>The five-variable model produces a different picture. We now find avalanches, for which size and duration distributions are much better fit by power-law models starting from very low minimum cutoffs (<xref ref-type="fig" rid="fig2">Figure 2D–E</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Average size scaled with duration, again over more than two decades, with <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.27</mml:mn><mml:mo>±</mml:mo><mml:mn>0.03</mml:mn></mml:mstyle></mml:math></inline-formula>, which was in close agreement with <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.25</mml:mn><mml:mo>±</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). Holding other parameters constant, we thus found that scaling relationships and crackling arise in the multi-variable model but not the single-variable model.</p></sec><sec id="s2-4"><title>Avalanche scaling depends on the time scale of latent variables</title><p>Based on simulations in the previous section, we surmised that the five-variable simulation generated scaling more readily due to creating an ‘effective’ latent variable that had slower dynamics than any individual latent variable. We reasoned that at any moment in time, the latent variable state <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is a vector in the latent space. Because coupling to the latent variables is random throughout the population, only the length (<inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:msqrt><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:mstyle></mml:math></inline-formula>) and not the direction of this vector matters, and the timescale of changes in this length would be much slower than <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, the timescale of each of the components <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. We therefore speculated that increasing the timescale of dynamics of the latent variables should eventually lead to scaling and crackling in the single-variable model as well as the five-variable one. To examine the dependence of avalanche scaling on this timescale, we simulated one-variable and five-variable networks at fixed <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> coupled to latent variables with the correlation time of their Ornstein-Uhlenbeck dynamics of <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>5</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula> time steps, spanning from a factor of 10 faster to a factor of 10 slower than the original <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Simulations were replicated five times at each combination of parameters by drawing new latent variable coupling values (<inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>), as well as new latent variable dynamics and instances of neural firing. For simulations that passed the criteria to be fitted by power laws, we plot the fitted values of <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> , <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2G–J</xref>). Missing points are those for which distributions did not pass the power law fit criteria.</p><p>In the single-variable model, best-fit exponents changed abruptly for latent variable timescale around <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2G and H</xref>), while in the five-variable model, exponents tended to increase gradually (<xref ref-type="fig" rid="fig2">Figure 2G and H</xref>, red). The discontinuity in the single-variable case reflected a change in the lower cutoff values in the power-law fits: size and duration distributions generated with faster latent dynamics could be fit reasonably well to a power law by using a high value of the lower cutoff (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). For time scales greater than ∼10<sup>4</sup>, the minimum cutoffs dropped, and the single-variable model generated power-law distributed avalanches and crackling (<xref ref-type="fig" rid="fig2">Figure 2J</xref>), similar to the five-variable model. In summary, in the latent dynamical variable model, introducing multiple variables generated scaling at faster timescales. However, by slowing the timescale of the latent dynamics, the model generated signatures of critical avalanche scaling for both multi- and single-variable simulations.</p></sec><sec id="s2-5"><title>Avalanche criticality, input scaling, and firing threshold</title><p>In the previous section, we found that a very slow single latent dynamical variable generated avalanche criticality in the simulation population. Thus, from now on, we simplify the model in order to characterize avalanche statistics across values of input scaling <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and firing threshold <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>. Specifically, we modeled a population of <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>128</mml:mn></mml:mstyle></mml:math></inline-formula> neurons coupled to a single quasi-static latent variable. We simulated 10<sup>3</sup> segments of 10<sup>4</sup> steps each and drew a new value of the latent variable (<inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>) for each segment. Ten replicates of the simulation were generated at each of the combinations of <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> (see Materials and methods).</p><p>Almost independent of <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>, we found quality power law fits and crackling. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows the average (across <inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mstyle></mml:math></inline-formula> network realizations) of the exponents extracted from size (<inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3A</xref>) and duration (<inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3C</xref>) distributions. At small firing threshold (<inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>), we do not observe scaling because the system is always active, and all avalanches merge into one. At large firing threshold <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> and low input scaling <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, we do not observe scaling because activity is so sparse that all avalanches are small. At intermediate values of the parameters, the simulations generated plausible scaling relationships in size and duration. The difference between <inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> was typically less than 0.1 (<xref ref-type="fig" rid="fig4">Figure 4D–F</xref>), which was consistent with previously reported differences between fit and predicted exponents (<xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref>). Thus, there appears to be no need for fine-tuning to generate apparent scaling in this model, at least in the limit of (near) infinite observation time. Wherever <inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> generate avalanches, there are approximate power-law distributions and crackling.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Exponents across network simulations for networks of <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>128</mml:mn></mml:mstyle></mml:math></inline-formula> neurons.</title><p>Each parameter combination <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> was simulated for ten replicates, each time drawing randomly the couplings <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, the latent variable values, and the neural activities. Other parameters in <xref ref-type="table" rid="table3">Table 3</xref>. (<bold>A</bold>) Average across replicates for the size exponent <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula>. (<bold>B</bold>) Scatter plot of <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> vs. <inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> for each network replicate for parameter combinations indicated in A. Linear relationships between <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>, corresponding to the minimum and maximum values of <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> from panel E, are shown to guide the eye. (<bold>C</bold>) Same as A, for duration exponent <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>. (<bold>D</bold>) Predicted exponent, <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, derived from A and C. (<bold>E</bold>) Value of <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> from fit to <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>S</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>∼</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>F</bold>) Difference between <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>pred</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>fit</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig3-v1.tif"/></fig><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Avalanches in the latent dynamical variable model with a single quasistatic variable.</title><p>Parameters in <xref ref-type="table" rid="table3">Table 3</xref>. (<bold>A</bold>) Number of avalanches in simulations from <xref ref-type="fig" rid="fig3">Figure 3</xref> as a function of the calculated probability of avalanches at fixed <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> across values of <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> and latent variable <inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>. Line indicates equality. (<bold>B</bold>) Probability of avalanches with <inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> across values of <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf172"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>. The latent variable <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> is normally distributed with mean 0 and variance 1. Where the distribution of <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> overlaps with regions of high probability (black), avalanches occur. (<bold>C</bold>) Probability of avalanches at <inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mstyle></mml:math></inline-formula> across values of <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>. Increasing <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> narrows the range of <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> that generates avalanches. (<bold>D</bold>) Probability of avalanches at <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> for a populations of 128 neurons (black line) and for a varying <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>. Size distributions corresponding to simulations marked by the green and orange crosses are in E, F. (<bold>E</bold>) Example of size distribution with <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (orange marker in D). Size cutoff is close to 100. (<bold>F</bold>) Example of size distribution with <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (green marker in D). Size cutoff is &lt; 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Estimate of how long it takes to observe avalanche criticality at each combination of <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>.</title><p>We took a parameter combination with a low rate of avalanches but good apparent scaling (<inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>14</mml:mn></mml:mstyle></mml:math></inline-formula>) and assumed that this is a reasonable estimate of the minimum number of observations (approximately 10<sup>6</sup> avalanches) required to observe scaling. To translate to observation length (in hours), we divided the number of avalanches observed in each full-length simulation by this minimum count and converted to a time using a time bin of 10ms. Simulations were for a recorded population of 128 neurons. For this size of population, <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5.2</mml:mn></mml:mstyle></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig4-figsupp1-v1.tif"/></fig></fig-group><p>To determine where avalanches occur, we derive the avalanche rate across values of the latent variable <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>. In the quasi-static model, the probability of an avalanche initiation is the probability of a transition from the quiet to an active state. Because all neurons are conditionally independent, this is <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>silence</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>silence</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. Then the expected number of avalanches <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>N</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is obtained by integrating <inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> over <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> at each value of <inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>N</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is the standard normal distribution. This probability tracks the observed number of avalanches across simulations, <xref ref-type="fig" rid="fig4">Figure 4A</xref>.</p><p>To gain an intuition for the conditions under which avalanches occur, we show two slices of the avalanche probability, at fixed <inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) and at fixed <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Black regions indicate where avalanches are likely to occur. If, for a given value of <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, there is no overlap between high avalanche probability regions and the distribution of <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>, then there will be no avalanches. For large <inline-formula><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>, avalanches occur because neurons with large coupling to the latent variable (<inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, recall <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>) are occasionally activated by a value of the latent variable <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> that is sufficient to exceed <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Thus, the scaling parameter <inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> controls the value of <inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> for which avalanches occur most frequently (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). As <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> decreases, avalanches occur for smaller and smaller <inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> until avalanches primarily occur when <inline-formula><mml:math id="inf211"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>.</p><p>To calculate the probability of avalanches, we must integrate over all values of <inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>, but we can gain a qualitative understanding of which avalanche regime the system is in by examining the probability of avalanches at <inline-formula><mml:math id="inf213"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>. At <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, the avalanche probability (see Materials and methods) is<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>which is maximized at <inline-formula><mml:math id="inf215"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, independent of <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>. After some algebra, we find that <inline-formula><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> for large <inline-formula><mml:math id="inf219"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula>. The dependence on <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> reflects that a larger threshold is required for larger networks: large networks (<inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula>) are unlikely to achieve complete network silence, therefore preventing avalanches from occurring. Similarly, small networks (<inline-formula><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>∼</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>) are unlikely to fire consecutively and thus are unlikely to avalanche.</p><p>We plot <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> as a function of <inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> in <xref ref-type="fig" rid="fig4">Figure 4D</xref>. The peak at <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> divides the space into two regions. For <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, a power-law is only observed in the large-size avalanches, which are rare (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, green). By contrast, when <inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, minimum size cutoffs are low (<xref ref-type="fig" rid="fig4">Figure 4F</xref>, orange). Both regions, <inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf229"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, exhibit crackling noise scaling. If observation times are not sufficiently long (estimated in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), then scaling will not be observed in the <inline-formula><mml:math id="inf230"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> region, whose scaling relations arise from rare events. Insufficient observation times may explain experiments and simulations where avalanche scaling was not found.</p></sec><sec id="s2-6"><title>Inferring the latent variable</title><p>Our analysis of <inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> at <inline-formula><mml:math id="inf232"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> suggested that there are two types of avalanche regimes: one with high activity and high minimum cutoffs in the power law fit (Type 1), and the other with lower activity and size cutoffs (Type 2). Further, when <inline-formula><mml:math id="inf233"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> drops to zero, avalanches disappear because the activity is too high or too low. We now examine how information about the value of the latent variables represented in the network activity relates to the activity type. To delineate these types, we calculated numerically <inline-formula><mml:math id="inf234"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, the value of <inline-formula><mml:math id="inf235"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>, for which the probability of avalanches is maximized, and the contours of <inline-formula><mml:math id="inf236"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Curves for <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf238"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf239"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> are shown in <xref ref-type="fig" rid="fig5">Figure 5A and B</xref>.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Information in the neural activity about the latent variable is higher in the low-<inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> avalanche region, compared to high-<inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> avalanche or high-rate avalanche-free activity.</title><p>(<bold>A</bold>) Probability of avalanche per time step across values of <inline-formula><mml:math id="inf242"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>. Solid magenta curve follows <inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, the value of <inline-formula><mml:math id="inf245"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> maximizing the probability of avalanches at fixed <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>. Dashed magenta line indicates <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, calculated analytically, which matches <inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> at <inline-formula><mml:math id="inf249"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>. (<bold>B</bold>) Information about latent variable, calculated from maximum likelihood estimate of <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> using population activity. MLE approximation is invalid in the dark-blue region bounded by gray curve. Magenta line marks the maximum values of <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, reproduced from A. Dashed black curve indicates <inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mstyle></mml:math></inline-formula>. The highest information region falls between <inline-formula><mml:math id="inf253"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and the contour for <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mstyle></mml:math></inline-formula>. (<bold>C - E</bold>) Slices of B, showing <inline-formula><mml:math id="inf255"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>. Magenta and dashed black lines again indicate <inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mstyle></mml:math></inline-formula>, respectively, as in B. Black dashed line marks the approximate boundary between the high-activity/no avalanche and the high-cutoff avalanche, and magenta line marks boundary between high-cutoff and low-cutoff avalanche regions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89337-fig5-v1.tif"/></fig><p>We expect that the more cells fire, the more information they would convey, until the firing rate saturates, and inferring the value of the latent variable becomes impossible. <xref ref-type="fig" rid="fig5">Figure 5B</xref> supports the prediction: generally, information is higher in regions with more activity (lower <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>, higher <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>), but only up to a limit: as <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>, information decreases. This decrease begins approximately where the probability of avalanches drops to nearly zero (dashed black lines, <xref ref-type="fig" rid="fig5">Figure 5B–E</xref>) because all of the activity merges into a few very large avalanches. In other words, the Type-1 avalanche region coincides with the highest information about the latent variable.</p><p>The critical brain hypothesis suggests that the brain operates in a critical state, and its functional role may be in optimizing information processing (<xref ref-type="bibr" rid="bib5">Beggs, 2008</xref>; <xref ref-type="bibr" rid="bib7">Chialvo, 2010</xref>). Under this hypothesis, we would expect the information conveyed by the network to be maximized in the regions we observe avalanche criticality. However, we see that critical regions do not always have optimal information transmission. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, the region that displays crackling noise is that where avalanches exist (<inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), which corresponds to any <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> value and <inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>≳</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>. This avalanche region encompasses both networks with high information transmission and networks with low information transmission. In summary, observing avalanche criticality in a system does not imply a high-information processing network state. However, the scaling can be seen at smaller cutoffs, and hence with shorter recordings, in the high-information state. This parallels the discussion by <xref ref-type="bibr" rid="bib36">Schwab et al., 2014</xref>, who noticed that the Zipf’s law always emerges in neural populations driven by quasi-stationary latent fields, but it emerges at smaller system sizes when the information about the latent variable is high.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here, we studied systems with distributed, random coupling to latent dynamical variables and we found that avalanche criticality is nearly always observed, with no fine-tuning required. Avalanche criticality was surprisingly robust to changes in input gain and firing rate threshold. Loss of avalanche criticality could occur if the latent process was not well-sampled, either because the simulation was not long enough or the dynamics of the latent variables were too fast. Finally, while information about the latent variables in the network activity was higher where avalanches were generated compared to when they were not, there was a range of information values across the critical avalanche regime. Thus, avalanche criticality alone was not a predictor of optimal information transmission.</p><sec id="s3-1"><title>Explaining experimental exponents</title><p>A wide range of critical exponents has been found in ex vivo and in vivo recordings from various systems. For instance, the seminal work on avalanche statistics in cultured neuronal networks by <xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref> found size and duration exponents of 1.5 and 2.0 respectively, along with <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>, when time was discretized with a time bin equal to the average inter-event interval in the system. A subset of the in vivo recordings analyzed from anesthetized cat (<xref ref-type="bibr" rid="bib14">Hahn et al., 2010</xref>) and macaque monkeys (<xref ref-type="bibr" rid="bib31">Petermann et al., 2009</xref>) also exhibited a size distribution exponent close to 1.5. By contrast, a survey of many in vivo and ex vivo recordings found power-law size distributions with exponents ranging from 1 to 3 depending on the system (<xref ref-type="bibr" rid="bib11">Fontenele et al., 2019</xref>). Separately, <xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref> reported recordings in freely moving rats with size exponents ranging from 1.5 to 2.7. In these recordings, when the crackling relationship held, the reported value of <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> was near 1.2 (<xref ref-type="bibr" rid="bib11">Fontenele et al., 2019</xref>; <xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref>).</p><p>A model for generating avalanche criticality is a critical branching process (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>), which predicts size and duration exponents of 1.5 and 2 and scaling exponent <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> of 2. However, there are alternatives: <xref ref-type="bibr" rid="bib18">Lombardi et al., 2023</xref> showed that avalanche criticality may also be produced by an adaptive Ising model in the sub-critical regime, and in this case, the scaling exponent <inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> was not 2 but close to 1.6. Our model, across the parameters we tested that produced exponents consistent with the scaling relationship, generated <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> values that ranged from 1.9 to about 2.5. Across those simulations, we found values <inline-formula><mml:math id="inf270"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> within a narrow band from 1.1 to 1.3 (see <xref ref-type="fig" rid="fig2">Figure 2I and J</xref> and <xref ref-type="fig" rid="fig3">Figure 3H</xref>). While the exponent values our model produces are inconsistent with a critical branching process (<inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>), they match the ranges of exponents estimated from experiments and reported by <xref ref-type="bibr" rid="bib11">Fontenele et al., 2019</xref>. In this context, it might be useful to explore if our model and that of <xref ref-type="bibr" rid="bib18">Lombardi et al., 2023</xref> might be related, with the adaptive feedback signal of the latter viewed as an effective, latent variable of the former.</p><p>A genuine challenge in comparing exponents estimated from different experiments with different recording modalities (spiking activity, calcium imaging, LFP, EEG, or MEG) arises from differences in spatial and temporal scale specific to a particular recording, as well as the myriad decisions made in avalanche analysis, such as defining thresholds or binning in time. Thus, one possible reason for differences in exponents across studies may derive from how the system is sub-sampled in space or coarse-grained in time, both of which systematically change exponents <inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>; <xref ref-type="bibr" rid="bib39">Shew et al., 2015</xref>) and could account for differences in <inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib6">Capek et al., 2023</xref>). The model we presented here could be used as a test bed for examining how specific analysis choices affect exponents estimated from recordings.</p><p>A second possible explanation for differences in exponents is that different experiments study similar, but distinct biological phenomena. For instance, networks that were cultured in vitro may differ from those that were not, whether they are in vivo or ex vivo (i.e. brain slices), and sensory-processing networks may have different dynamics from networks with different processing demands. It is possible that certain networks develop connections between neurons such that they truly do produce dynamics that approximate a critical branching process, while other networks have different structure and resulting dynamics and thus can be better understood as coupled neurons receiving feedback (<xref ref-type="bibr" rid="bib18">Lombardi et al., 2023</xref>) or as a system coupled to latent dynamical variables. This is especially true in sensory systems, where coupling to (latent) external stimuli in a way that the neural activity can be used to infer the stimuli is the reason for the networks’ existence (<xref ref-type="bibr" rid="bib36">Schwab et al., 2014</xref>).</p></sec><sec id="s3-2"><title>Relationship to past modeling work</title><p>Our model is not the first to produce approximate power-law size and duration distributions for avalanches from a latent variable process (<xref ref-type="bibr" rid="bib41">Touboul and Destexhe, 2017</xref>; <xref ref-type="bibr" rid="bib35">Priesemann and Shriki, 2018</xref>). In particular, <xref ref-type="bibr" rid="bib35">Priesemann and Shriki, 2018</xref> derived the conditions, under which an inhomogeneous Poisson process could produce such approximate scaling. The basic idea is to generate a weighted sum of exponentially distributed event sizes, each of which are generated from a homogeneous Poisson process. How each process is weighted in this sum determines the approximate power-law exponent, allowing one to tune the system to obtain the critical values of 1.5 and 2. Interestingly, this model did not generate non-trivial scaling of size with duration (<inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>∼</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>γ</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>). Instead, they found <inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, not the predicted <inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>. Our results differ significantly, in that <inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> was typically between 1.1 and 1.3 and it was nearly always close to the prediction from <inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf280"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula>. We speculate that this is due to nonlinearity in the mapping from latent variable to spiking activity, as doubling the latent field <inline-formula><mml:math id="inf281"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> does not double the population activity, but doubling the rate of a homogeneous Poisson process does double the expected spike count. As biological networks are likely to have such nonlinearities in their responses to common inputs, this scenario may be more applicable to certain kinds of recordings.</p></sec><sec id="s3-3"><title>Summary</title><p>Latent variables – whether they are emergent from network dynamics (<xref ref-type="bibr" rid="bib8">Clark et al., 2023</xref>; <xref ref-type="bibr" rid="bib37">Sederberg and Nemenman, 2020</xref>) or derived from shared inputs – are ubiquitous in large-scale neural population recordings. This fact is reflected most directly in the relatively low-dimensional structure in large-scale population recordings (<xref ref-type="bibr" rid="bib40">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Pandarinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib27">Nieh et al., 2021</xref>). We previously used a model based on this observation to examine signatures of neural criticality under a coarse-graining analysis and found that coarse-grained criticality is generated by systems driven by many latent variables (<xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>). Here, we showed that the same model also generates avalanche criticality, and that when information about the latent variables can be inferred from the network, avalanche criticality is also observed. Crucially, finding signatures of avalanche criticality required long observation times, such that the latent variable was well-sampled. Previous studies showed that Zipf’s law appears generically in systems coupled to a latent variable that changes slowly relative to the sampling time, and that the Zipf’s behavior is easier to observe in the higher information regime (<xref ref-type="bibr" rid="bib36">Schwab et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Aitchison et al., 2016</xref>). However, this also suggests that observation of either scaling at modest data set sizes indeed points to some fine-tuning — namely to the increase of the information in the individual neurons (and, since neurons in these models are conditionally independent, also in the entire network) about the value of the latent variables. In other words, one would expect a sensory part of the brain, if adapted to the statistics of the external stimuli, to exhibit all of these critical signatures at relatively modest data set sizes. In monocular deprivation experiments, when the activity in the visual cortex is transiently not adapted to its inputs, scaling disappears, at least for recordings of a typical duration, and is restored as the system adapts to the new stimulus (<xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref>). We speculate that the observed recovery of criticality by <xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref> could be driven by neurons adapting to the reduced stimuli state, for instance, by adjusting <inline-formula><mml:math id="inf282"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> (input scaling) and <inline-formula><mml:math id="inf283"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> (firing rate threshold).</p><p>Taken together, these results suggest that critical behavior in neural systems – whether based on the Zipf’s law, avalanches, or coarse-graining analysis – is expected whenever neural recordings exhibit some latent structure in population dynamics and this latent structure can be inferred from observations of the population activity.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Simulation of dynamic latent variable model</title><p>We study a model from <xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>, originally constructed as a model of large populations of neurons in mouse hippocampus. In the original version of the model, neurons are non-interacting, receiving inputs reflective of place-field selectivity as well as input current arising from a random projection from a small number of latent dynamical variables, representing inputs shared across the population of neurons that are not directly measured or controlled. In the current paper, we incorporate only the latent variables (no place variables), and we assume that every cell is coupled to every latent variable with some randomly drawn coupling strength.</p><p>The probability of observing a certain population state <inline-formula><mml:math id="inf284"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> given latent variables <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> at time <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> is<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf287"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Z</mml:mi></mml:mstyle></mml:math></inline-formula> is the normalization, and <inline-formula><mml:math id="inf288"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi></mml:mstyle></mml:math></inline-formula> is the ‘energy’:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi>η</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The latent variables <inline-formula><mml:math id="inf289"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>μ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> are Ornstein-Uhlenbeck processes with zero mean, unit variance, and time constant <inline-formula><mml:math id="inf290"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. Couplings <inline-formula><mml:math id="inf291"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> are drawn from the standard normal distribution.</p><p>Parameters for each figure are laid out in <xref ref-type="table" rid="table1 table2 table3">Tables 1–3</xref>. For the infinite time constant simulation, we draw a value <inline-formula><mml:math id="inf292"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and simulate for 10000 time steps, then repeat for 1000 draws of <inline-formula><mml:math id="inf293"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Simulation parameters for <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Description</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">bias towards silence</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf295"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mn>.14</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">variance multiplier</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf297"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mn>.10</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf298"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">number of latent fields</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf299"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf300"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">latent field time constant</td><td align="left" valign="bottom">quasistatic</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf301"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">number of cells</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>128</mml:mn></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>Time step units</title><p>Most results were presented using arbitrary time units: all times (i.e. <inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and avalanche duration <inline-formula><mml:math id="inf304"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi></mml:mstyle></mml:math></inline-formula>) are measured in units of an unspecified time step. Specifying a time bin converts the probability of firing into actual firing rates, in spikes per second, and this choice determines which part of the <inline-formula><mml:math id="inf305"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>-<inline-formula><mml:math id="inf306"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> phase space is most relevant to a given experiment.</p><p>The time step is the temporal resolution at which activity is discretized, which varies from several to hundreds of milliseconds across different experimental studies (<xref ref-type="bibr" rid="bib4">Beggs and Plenz, 2003</xref>; <xref ref-type="bibr" rid="bib11">Fontenele et al., 2019</xref>; <xref ref-type="bibr" rid="bib19">Ma et al., 2019</xref>). In physical units and assuming a bin size of 3 ms to 10 ms, our choice of <inline-formula><mml:math id="inf307"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf308"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> in <xref ref-type="fig" rid="fig2">Figure 2</xref> would yield physiologically realistic firing rate ranges (<xref ref-type="bibr" rid="bib15">Hengen et al., 2016</xref>), with high-firing neurons reaching averages rates of 20-50 spikes/second and median firing-rate neurons around 1-2 spikes/second. The timescales of latent variables examined range from about 3 s to 3000 s, assuming 3-ms bins. Inputs with such timescales may arise from external sources, such as sensory stimuli, or from internal sources, such as changes in physiological state.</p><p>Simulations were carried out for the same number of time steps (2×10<sup>6</sup>), which would be approximately 1 to 2 ‘hours’, a reasonable duration for in vivo neural recordings. Note that at large values of <inline-formula><mml:math id="inf309"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, the latent variable space is not well sampled during this time period.</p></sec><sec id="s4-3"><title>Analysis of avalanche statistics</title><sec id="s4-3-1"><title>Setting the threshold for observing avalanches</title><p>In our model, we count avalanches as periods of continuous activity (in any subset of neurons) that is book-ended by time bins with no activity in the entire simulated neural network. For real neural populations of modest size, this method fails because there are no periods of quiescence. The typical solution is to set a threshold, and to only count avalanches when the population activity exceeds that threshold, with the hope that results are relatively robust to that choice. In our model, this operation is equivalent to changing <inline-formula><mml:math id="inf310"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula>, which shifts the probability of firing up or down by a constant amount across all cells independent of inputs. Our results in <xref ref-type="fig" rid="fig3">Figure 3</xref> show that <inline-formula><mml:math id="inf311"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf312"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> decrease as the threshold for detection is increased (equivalent to large <inline-formula><mml:math id="inf313"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>), but that the scaling relationship is maintained. The model predicts that <inline-formula><mml:math id="inf314"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> would initially increase slightly with the detection threshold before decreasing back to near zero.</p><p>Following the algorithm laid out in <xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref>, we fit power laws to the size and duration distributions from simulations generating avalanches. We use least-squares fitting to estimate <inline-formula><mml:math id="inf315"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, the scaling exponent for size with duration, assessing the consistency of the fit across decades.</p></sec><sec id="s4-3-2"><title>Reading power laws from data</title><p>We want, from each simulation, a quantification of the quality of scaling (how many decades, minimally) and an estimate of the scaling exponents (<inline-formula><mml:math id="inf316"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> for the size distribution, <inline-formula><mml:math id="inf317"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> for the duration distribution). We first compile all avalanches observed in the simulation and for each avalanche, calculate its size (total activity across the population during the avalanche) and its duration (number of time bins). Following the steps outlined by <xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref>, we use the maximum-likelihood estimator to determine the scaling exponent. This is the solution to the transcendental equation<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>α</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>ζ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>α</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ζ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> is the Hurwitz zeta function and <inline-formula><mml:math id="inf319"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> are observations; that is, either the size or the duration of each avalanche <italic>i</italic>. For values of <inline-formula><mml:math id="inf320"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, a numerical look-up table based on the built-in Hurwitz zeta function in the symbolic math toolbox was used (MATLAB2019b). For <inline-formula><mml:math id="inf321"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> we use an approximation (<xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref>),<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>α</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>To determine <inline-formula><mml:math id="inf322"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, we computed the maximum absolute difference between the empirical cumulative density (<inline-formula><mml:math id="inf323"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>) function and model’s cumulative density function <inline-formula><mml:math id="inf324"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (the Kolmogorov-Smirnov (KS) statistic; <inline-formula><mml:math id="inf325"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>max</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). The KS statistic was computed between for power-law models with scaling parameter <inline-formula><mml:math id="inf326"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>α</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> and cutoffs <inline-formula><mml:math id="inf327"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. The value of <inline-formula><mml:math id="inf328"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> that minimizes the KS statistic was chosen. Occasionally the KS statistic had two local minima (as in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), indicating two different power-laws. In these cases, the minimum size and duration cutoffs were the smallest values that were within 10% of the absolute minimum of the KS statistic. Note that the statistic is computed for each model only on the power-law portion of the CDF (i.e. <inline-formula><mml:math id="inf329"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>). We do not attempt to determine an upper cut-off value.</p><p>To assess the quality of the power-law fit, <xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref> compared the empirical observations to surrogate data generated from a semi-parametric power-law model. The semi-parametric model sets the value of the CDF equal to the empirical CDF values up to <inline-formula><mml:math id="inf330"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and then according to the power-law model for <inline-formula><mml:math id="inf331"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. If the KS statistic for the real data (relative to its fitted model) is within the distribution of the KS statistics for surrogate datasets relative to their respective fitted models, the power-law model was considered a reasonable fit.</p><p>Strict application of this methodology could give misleading results. Much of this is due to the loss of statistical power when the minimum cutoff is so high that the number of observations drops. For instance, in the simulations shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, the one-variable duration distribution passed the <xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref> criterion, with a minimum KS statistic of 0.03 when the duration cutoff was 18 time steps. However, for the five-variable simulation in <xref ref-type="fig" rid="fig2">Figure 2</xref>, a power-law would be narrowly rejected for both size and duration, despite having much smaller KS statistics: for <inline-formula><mml:math id="inf332"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula>, the KS statistic was 0.0087 (simulation range: 0.0008 to 0.0082; number of avalanches observed: 58,787) and for <inline-formula><mml:math id="inf333"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> it was 0.0084 (simulation range: 0.0011 to 0.0075). Below we discuss this problem in more detail.</p></sec><sec id="s4-3-3"><title>Determining range over which avalanche size scales with duration</title><p>For fitting <inline-formula><mml:math id="inf334"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula>, our aim was to find the longest sampled range, over which we have apparent power-law scaling of size with duration. Because our sampled duration values have linear spacing, error estimates are skewed if a naive goodness of fit criterion is used. We devised the following algorithm. First, the simulation must have at least one avalanche of size 500. We fit <inline-formula><mml:math id="inf335"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:msup><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>γ</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> over one decade at a time. We chose as the lower duration cutoff the value of minimum duration, for which the largest number of subsequent (longer-duration) fits produced consistent fit parameters (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplements 3</xref> and <xref ref-type="fig" rid="fig2s4">4</xref>, top row). Next, with the minimum duration set, we gradually increased the maximum duration cut-off, and we determined whether there was a significant bias in the residual over the first decade of the fit. We selected the highest duration cutoff, for which there was no bias. Finally, over this range, we re-fit the power law relationship and extracted confidence intervals.</p><p>Our analysis focused on finding the apparent power-law relationship that held over the largest log-scale range. A common feature across simulation parameters (<inline-formula><mml:math id="inf336"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) was the existence of two distinct power-law regimes. This is apparent in <xref ref-type="fig" rid="fig2">Figure 2I</xref>, which shows that when <inline-formula><mml:math id="inf338"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> at small <inline-formula><mml:math id="inf339"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, the best-fit <inline-formula><mml:math id="inf340"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> (that showing the largest range with power-law-consistent scaling) is much larger ( 1.7), and then above <inline-formula><mml:math id="inf341"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mn>3000</mml:mn></mml:mstyle></mml:math></inline-formula>, the best-fit <inline-formula><mml:math id="inf342"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> drops to around 1.3.</p></sec><sec id="s4-3-4"><title>Statistical power of power-law tests</title><p>In several cases, we found examples of power-law fits that passed the rejection criteria commonly used to determine avalanche scaling relationships because of limited number of observations. A key example is that of the single latent variable simulation shown in <xref ref-type="fig" rid="fig2">Figure 2B</xref>, where we could not reject a power law for the duration distribution. Conversely, strict application of the surrogate criteria would reject a power law for distributions that were quantitatively much closer to a power-law (i.e. lower KS statistic), but for which we had many more observations and thus a much stronger surrogate test (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This points to the difficulty of applying a single criterion to determining a power-law fit. In this work, we adhere to the criteria set forth in <xref ref-type="bibr" rid="bib9">Clauset et al., 2009</xref>, with a modification to control for the unreasonably high statistical power of simulated data. Specifically, the number of avalanches used for fitting and for surrogate analysis was capped at 500,000, drawn randomly from the entire pool of avalanches.</p><p>Additionally, we found examples, in which a short simulation was rejected, but increasing the simulation time by a factor of five yielded excellent power-law fits. We speculate that this arises due to insufficient sampling of the latent space. These observations raise an important biological point. Simulations provide the luxury of assuming the network is unchanging for as long as the simulator cares to keep drawing samples. In a biological network, this is not the case. Over the course of hours, the effective latent degrees of freedom could change drastically (e.g. due to circadian effects [<xref ref-type="bibr" rid="bib3">Aton et al., 2009</xref>], changes in behavioral state [<xref ref-type="bibr" rid="bib12">Fu et al., 2014</xref>], plasticity [<xref ref-type="bibr" rid="bib16">Hooks and Chen, 2020</xref>], etc.), and the network itself (synaptic scaling, firing thresholds, etc.) could be plastic (<xref ref-type="bibr" rid="bib15">Hengen et al., 2016</xref>). All these factors can be modeled in our framework by determining appropriate cutoffs (in duration of recording, in time step sizes, for activity distributions) based on specific experimental timescales.</p></sec><sec id="s4-3-5"><title>Calculation of avalanche regimes</title><p>In the quasistatic model, we derive the dependence of the avalanche rate on <inline-formula><mml:math id="inf343"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>η</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf344"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math></inline-formula> and number of neurons <inline-formula><mml:math id="inf345"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula>, finding that there are two distinct regimes, in which avalanches occur. Each time bin is independent, conditioned on the value of <inline-formula><mml:math id="inf346"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>. For an avalanche to occur, the probability of silence in the population (i.e. all <inline-formula><mml:math id="inf347"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) must not be too close to 0 (or there are no breaks in activity) or too close to 1 (or there is no activity). At fixed <inline-formula><mml:math id="inf348"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula>, the probability of silence is<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mtext>silence</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>An avalanche occurs when a silent time bin is followed by an active bin, which has probability <inline-formula><mml:math id="inf349"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>ava</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>silence</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>% silence</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>.</p></sec></sec><sec id="s4-4"><title>Information calculation</title><sec id="s4-4-1"><title>Maximum-likelihood decoding</title><p>For large populations coupled to a single latent variable, we estimated the information between population spiking activity and the latent variable as the information between the maximum-likelihood estimator <inline-formula><mml:math id="inf350"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> of the latent variable <inline-formula><mml:math id="inf351"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> and the latent variable itself. This approximation fails at extremes of network activity levels (low or high).</p><p>Specifically, we approximated the log-likelihood of <inline-formula><mml:math id="inf352"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> given <inline-formula><mml:math id="inf353"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>true</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> near <inline-formula><mml:math id="inf354"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> by <inline-formula><mml:math id="inf355"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac></mml:mstyle></mml:math></inline-formula>. Thus we assume that <inline-formula><mml:math id="inf356"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is normally distributed about <inline-formula><mml:math id="inf357"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>true</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> with variance <inline-formula><mml:math id="inf358"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>true</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The variance is then derived from the curvature of the log-likelihood at the maximum. The information between two Gaussian variables, here <inline-formula><mml:math id="inf359"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf360"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, is<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mi>T</mml:mi><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where the average is taken over <inline-formula><mml:math id="inf361"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>true</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>.</p><p>Given a set of <inline-formula><mml:math id="inf362"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi></mml:mstyle></mml:math></inline-formula> observations of the neurons <inline-formula><mml:math id="inf363"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, the likelihood is<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Maximizing the log likelihood gives the following condition:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf364"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the average over observations <inline-formula><mml:math id="inf365"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>. The uncertainty in <inline-formula><mml:math id="inf366"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is <inline-formula><mml:math id="inf367"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, which was calculated from the second derivative of the log likelihood:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:msup><mml:mi>cosh</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>This expression depends on the observations <inline-formula><mml:math id="inf368"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> only through the maximum-likelihood estimate <inline-formula><mml:math id="inf369"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>. When <inline-formula><mml:math id="inf370"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>true</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, then the variance is<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:msup><mml:mi>cosh</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>≡</mml:mo><mml:mfrac><mml:mi>T</mml:mi><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>To generate <xref ref-type="fig" rid="fig5">Figure 5</xref>, we evaluated <xref ref-type="disp-formula" rid="equ10">Equation 10</xref> using <xref ref-type="disp-formula" rid="equ18">Equation 18</xref>.</p></sec></sec><sec id="s4-5"><title>Code availability</title><p>Simulation code was adapted from our previous work (<xref ref-type="bibr" rid="bib26">Morrell et al., 2021</xref>). Code to run simulations and perform analyses presented in this paper is uploaded as <xref ref-type="supplementary-material" rid="scode1">Source code 1</xref> and also available from <ext-link ext-link-type="uri" xlink:href="https://github.com/ajsederberg/avalanche">https://github.com/ajsederberg/avalanche</ext-link> (copy archived at <xref ref-type="bibr" rid="bib38">Sederberg, 2024</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-89337-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="scode1"><label>Source code 1.</label><caption><title>Code (Python and MATLAB) used to run simulations, analyses, and calculations.</title></caption><media xlink:href="elife-89337-code1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no data were generated for this manuscript. Modelling code is uploaded as <xref ref-type="supplementary-material" rid="scode1">Source code 1</xref>.</p></sec><ack id="ack"><title>Acknowledgements</title><p>IN was supported in part by the Simons Foundation Investigator program, the Simons-Emory Consortium on Motor Control, NSF grant BCS/1822677 and NIH grant 2R01NS084844. AS was supported in part by NIH grant 1RF1MH130413-01 and by startup funds from the University of Minnesota Medical School. The authors acknowledge the Minnesota Supercomputing Institute (MSI) at the University of Minnesota for providing resources that contributed to the research results reported within this paper.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahrens</surname><given-names>MB</given-names></name><name><surname>Li</surname><given-names>JM</given-names></name><name><surname>Orger</surname><given-names>MB</given-names></name><name><surname>Robson</surname><given-names>DN</given-names></name><name><surname>Schier</surname><given-names>AF</given-names></name><name><surname>Engert</surname><given-names>F</given-names></name><name><surname>Portugues</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Brain-wide neuronal dynamics during motor adaptation in zebrafish</article-title><source>Nature</source><volume>485</volume><fpage>471</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1038/nature11057</pub-id><pub-id pub-id-type="pmid">22622571</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aitchison</surname><given-names>L</given-names></name><name><surname>Corradi</surname><given-names>N</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Zipf’s law arises naturally when there are underlying, unobserved variables</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005110</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005110</pub-id><pub-id pub-id-type="pmid">27997544</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aton</surname><given-names>SJ</given-names></name><name><surname>Seibt</surname><given-names>J</given-names></name><name><surname>Dumoulin</surname><given-names>M</given-names></name><name><surname>Jha</surname><given-names>SK</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Coleman</surname><given-names>T</given-names></name><name><surname>Naidoo</surname><given-names>N</given-names></name><name><surname>Frank</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Mechanisms of sleep-dependent consolidation of cortical plasticity</article-title><source>Neuron</source><volume>61</volume><fpage>454</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.007</pub-id><pub-id pub-id-type="pmid">19217381</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beggs</surname><given-names>JM</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neuronal avalanches in neocortical circuits</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>11167</fpage><lpage>11177</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-35-11167.2003</pub-id><pub-id pub-id-type="pmid">14657176</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beggs</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The criticality hypothesis: how local cortical networks might optimize information processing</article-title><source>Philosophical Transactions of the Royal Society A</source><volume>366</volume><fpage>329</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1098/rsta.2007.2092</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Capek</surname><given-names>E</given-names></name><name><surname>Ribeiro</surname><given-names>TL</given-names></name><name><surname>Kells</surname><given-names>P</given-names></name><name><surname>Srinivasan</surname><given-names>K</given-names></name><name><surname>Miller</surname><given-names>SR</given-names></name><name><surname>Geist</surname><given-names>E</given-names></name><name><surname>Victor</surname><given-names>M</given-names></name><name><surname>Vakili</surname><given-names>A</given-names></name><name><surname>Pajevic</surname><given-names>S</given-names></name><name><surname>Chialvo</surname><given-names>DR</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Parabolic avalanche scaling in the synchronization of cortical cell assemblies</article-title><source>Nature Communications</source><volume>14</volume><elocation-id>2555</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-37976-x</pub-id><pub-id pub-id-type="pmid">37137888</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chialvo</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Emergent complex neural dynamics</article-title><source>Nature Physics</source><volume>6</volume><fpage>744</fpage><lpage>750</lpage><pub-id pub-id-type="doi">10.1038/nphys1803</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>DG</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Litwin-Kumar</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Dimension of activity in random neural networks</article-title><source>Physical Review Letters</source><volume>131</volume><elocation-id>118401</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.131.118401</pub-id><pub-id pub-id-type="pmid">37774280</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clauset</surname><given-names>A</given-names></name><name><surname>Shalizi</surname><given-names>CR</given-names></name><name><surname>Newman</surname><given-names>MEJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Power-law distributions in empirical data</article-title><source>SIAM Review</source><volume>51</volume><fpage>661</fpage><lpage>703</lpage><pub-id pub-id-type="doi">10.1137/070710111</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dahmen</surname><given-names>D</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Helias</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Second type of criticality in the brain uncovers rich multiple-neuron dynamics</article-title><source>PNAS</source><volume>116</volume><fpage>13051</fpage><lpage>13060</lpage><pub-id pub-id-type="doi">10.1073/pnas.1818972116</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fontenele</surname><given-names>AJ</given-names></name><name><surname>de Vasconcelos</surname><given-names>NAP</given-names></name><name><surname>Feliciano</surname><given-names>T</given-names></name><name><surname>Aguiar</surname><given-names>LAA</given-names></name><name><surname>Soares-Cunha</surname><given-names>C</given-names></name><name><surname>Coimbra</surname><given-names>B</given-names></name><name><surname>Dalla Porta</surname><given-names>L</given-names></name><name><surname>Ribeiro</surname><given-names>S</given-names></name><name><surname>Rodrigues</surname><given-names>AJ</given-names></name><name><surname>Sousa</surname><given-names>N</given-names></name><name><surname>Carelli</surname><given-names>PV</given-names></name><name><surname>Copelli</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Criticality between Cortical States</article-title><source>Physical Review Letters</source><volume>122</volume><elocation-id>208101</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.122.208101</pub-id><pub-id pub-id-type="pmid">31172737</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Y</given-names></name><name><surname>Tucciarone</surname><given-names>JM</given-names></name><name><surname>Espinosa</surname><given-names>JS</given-names></name><name><surname>Sheng</surname><given-names>N</given-names></name><name><surname>Darcy</surname><given-names>DP</given-names></name><name><surname>Nicoll</surname><given-names>RA</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A cortical circuit for gain control by behavioral state</article-title><source>Cell</source><volume>156</volume><fpage>1139</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.01.050</pub-id><pub-id pub-id-type="pmid">24630718</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Girardi-Schappo</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Brain criticality beyond avalanches: open problems and how to approach them</article-title><source>Journal of Physics</source><volume>2</volume><elocation-id>031003</elocation-id><pub-id pub-id-type="doi">10.1088/2632-072X/ac2071</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hahn</surname><given-names>G</given-names></name><name><surname>Petermann</surname><given-names>T</given-names></name><name><surname>Havenith</surname><given-names>MN</given-names></name><name><surname>Yu</surname><given-names>S</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name><name><surname>Nikolic</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neuronal avalanches in spontaneous activity in vivo</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>3312</fpage><lpage>3322</lpage><pub-id pub-id-type="doi">10.1152/jn.00953.2009</pub-id><pub-id pub-id-type="pmid">20631221</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hengen</surname><given-names>KB</given-names></name><name><surname>Torrado Pacheco</surname><given-names>A</given-names></name><name><surname>McGregor</surname><given-names>JN</given-names></name><name><surname>Van Hooser</surname><given-names>SD</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neuronal firing rate homeostasis is inhibited by sleep and promoted by wake</article-title><source>Cell</source><volume>165</volume><fpage>180</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2016.01.046</pub-id><pub-id pub-id-type="pmid">26997481</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hooks</surname><given-names>BM</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Circuitry underlying experience-dependent plasticity in the mouse visual system</article-title><source>Neuron</source><volume>106</volume><fpage>21</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.01.031</pub-id><pub-id pub-id-type="pmid">32272065</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humplik</surname><given-names>J</given-names></name><name><surname>Tkačik</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Probabilistic models for neural populations that naturally capture global coupling and criticality</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005763</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005763</pub-id><pub-id pub-id-type="pmid">28926564</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lombardi</surname><given-names>F</given-names></name><name><surname>Pepić</surname><given-names>S</given-names></name><name><surname>Shriki</surname><given-names>O</given-names></name><name><surname>Tkačik</surname><given-names>G</given-names></name><name><surname>De Martino</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Statistical modeling of adaptive neural networks explains co-existence of avalanches and oscillations in resting human brain</article-title><source>Nature Computational Science</source><volume>3</volume><fpage>254</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1038/s43588-023-00410-9</pub-id><pub-id pub-id-type="pmid">38177880</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>Z</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name><name><surname>Hengen</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical circuit dynamics are homeostatically tuned to criticality in vivo</article-title><source>Neuron</source><volume>104</volume><fpage>655</fpage><lpage>664</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.08.031</pub-id><pub-id pub-id-type="pmid">31601510</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mariani</surname><given-names>B</given-names></name><name><surname>Nicoletti</surname><given-names>G</given-names></name><name><surname>Bisio</surname><given-names>M</given-names></name><name><surname>Maschietto</surname><given-names>M</given-names></name><name><surname>Oboe</surname><given-names>R</given-names></name><name><surname>Leparulo</surname><given-names>A</given-names></name><name><surname>Suweis</surname><given-names>S</given-names></name><name><surname>Vassanelli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neuronal avalanches across the rat somatosensory barrel cortex and the effect of single whisker stimulation</article-title><source>Frontiers in Systems Neuroscience</source><volume>15</volume><elocation-id>709677</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2021.709677</pub-id><pub-id pub-id-type="pmid">34526881</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazor</surname><given-names>O</given-names></name><name><surname>Laurent</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Transient dynamics versus fixed points in odor representations by locust antennal lobe projection neurons</article-title><source>Neuron</source><volume>48</volume><fpage>661</fpage><lpage>673</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.09.032</pub-id><pub-id pub-id-type="pmid">16301181</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meshulam</surname><given-names>L</given-names></name><name><surname>Gauthier</surname><given-names>JL</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Coarse graining, fixed points, and scaling in a large population of neurons</article-title><source>Physical Review Letters</source><volume>123</volume><elocation-id>178103</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.123.178103</pub-id><pub-id pub-id-type="pmid">31702278</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mora</surname><given-names>T</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Are biological systems poised at criticality?</article-title><source>Journal of Statistical Physics</source><volume>144</volume><fpage>268</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1007/s10955-011-0229-4</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morales</surname><given-names>GB</given-names></name><name><surname>di Santo</surname><given-names>S</given-names></name><name><surname>Muñoz</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Quasiuniversal scaling in mouse-brain neuronal activity stems from edge-of-instability critical dynamics</article-title><source>PNAS</source><volume>120</volume><elocation-id>e2208998120</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2208998120</pub-id><pub-id pub-id-type="pmid">36827262</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrell</surname><given-names>MC</given-names></name><name><surname>Sederberg</surname><given-names>AJ</given-names></name><name><surname>Nemenman</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Latent dynamical variables produce signatures of spatiotemporal criticality in large biological systems</article-title><source>Physical Review Letters</source><volume>126</volume><elocation-id>118302</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.126.118302</pub-id><pub-id pub-id-type="pmid">33798342</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieh</surname><given-names>EH</given-names></name><name><surname>Schottdorf</surname><given-names>M</given-names></name><name><surname>Freeman</surname><given-names>NW</given-names></name><name><surname>Low</surname><given-names>RJ</given-names></name><name><surname>Lewallen</surname><given-names>S</given-names></name><name><surname>Koay</surname><given-names>SA</given-names></name><name><surname>Pinto</surname><given-names>L</given-names></name><name><surname>Gauthier</surname><given-names>JL</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Geometry of abstract learned knowledge in the hippocampus</article-title><source>Nature</source><volume>595</volume><fpage>80</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03652-7</pub-id><pub-id pub-id-type="pmid">34135512</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Byrne</surname><given-names>J</given-names></name><name><surname>Jerbi</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>How critical is brain criticality?</article-title><source>Trends in Neurosciences</source><volume>45</volume><fpage>820</fpage><lpage>837</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2022.08.007</pub-id><pub-id pub-id-type="pmid">36096888</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pandarinath</surname><given-names>C</given-names></name><name><surname>O’Shea</surname><given-names>DJ</given-names></name><name><surname>Collins</surname><given-names>J</given-names></name><name><surname>Jozefowicz</surname><given-names>R</given-names></name><name><surname>Stavisky</surname><given-names>SD</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name><name><surname>Trautmann</surname><given-names>EM</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Henderson</surname><given-names>JM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title><source>Nature Methods</source><volume>15</volume><fpage>805</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0109-9</pub-id><pub-id pub-id-type="pmid">30224673</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perkovic</surname><given-names>O</given-names></name><name><surname>Dahmen</surname><given-names>K</given-names></name><name><surname>Sethna</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Avalanches, Barkhausen noise, and plain old criticality</article-title><source>Physical Review Letters</source><volume>75</volume><fpage>4528</fpage><lpage>4531</lpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.75.4528</pub-id><pub-id pub-id-type="pmid">10059931</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petermann</surname><given-names>T</given-names></name><name><surname>Thiagarajan</surname><given-names>TC</given-names></name><name><surname>Lebedev</surname><given-names>MA</given-names></name><name><surname>Nicolelis</surname><given-names>MAL</given-names></name><name><surname>Chialvo</surname><given-names>DR</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spontaneous cortical activity in awake monkeys composed of neuronal avalanches</article-title><source>PNAS</source><volume>106</volume><fpage>15921</fpage><lpage>15926</lpage><pub-id pub-id-type="doi">10.1073/pnas.0904089106</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plenz</surname><given-names>D</given-names></name><name><surname>Ribeiro</surname><given-names>TL</given-names></name><name><surname>Miller</surname><given-names>SR</given-names></name><name><surname>Kells</surname><given-names>PA</given-names></name><name><surname>Vakili</surname><given-names>A</given-names></name><name><surname>Capek</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Self-organized criticality in the brain</article-title><source>Frontiers in Physics</source><volume>9</volume><elocation-id>639389</elocation-id><pub-id pub-id-type="doi">10.3389/fphy.2021.639389</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poil</surname><given-names>S-S</given-names></name><name><surname>van Ooyen</surname><given-names>A</given-names></name><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Avalanche dynamics of human brain oscillations: relation to critical branching processes and temporal correlations</article-title><source>Human Brain Mapping</source><volume>29</volume><fpage>770</fpage><lpage>777</lpage><pub-id pub-id-type="doi">10.1002/hbm.20590</pub-id><pub-id pub-id-type="pmid">18454457</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce-Alvarez</surname><given-names>A</given-names></name><name><surname>Jouary</surname><given-names>A</given-names></name><name><surname>Privat</surname><given-names>M</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Sumbre</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Whole-brain neuronal activity displays crackling noise dynamics</article-title><source>Neuron</source><volume>100</volume><fpage>1446</fpage><lpage>1459</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.045</pub-id><pub-id pub-id-type="pmid">30449656</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priesemann</surname><given-names>V</given-names></name><name><surname>Shriki</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Can a time varying external drive give rise to apparent criticality in neural systems?</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006081</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006081</pub-id><pub-id pub-id-type="pmid">29813052</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwab</surname><given-names>DJ</given-names></name><name><surname>Nemenman</surname><given-names>I</given-names></name><name><surname>Mehta</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Zipf’s law and criticality in multivariate data without fine-tuning</article-title><source>Physical Review Letters</source><volume>113</volume><elocation-id>068102</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.113.068102</pub-id><pub-id pub-id-type="pmid">25148352</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>A</given-names></name><name><surname>Nemenman</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Randomly connected networks generate emergent selectivity and predict decoding properties of large populations of neurons</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007875</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007875</pub-id><pub-id pub-id-type="pmid">32379751</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Avalanche</data-title><version designator="swh:1:rev:c2e91a5341d1aa5978650cb2c22227c7e52997dc">swh:1:rev:c2e91a5341d1aa5978650cb2c22227c7e52997dc</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:de294ef532e0e07507488df691f10a229fd29665;origin=https://github.com/ajsederberg/avalanche;visit=swh:1:snp:83b5ae292da441d80eb6e99588c5dd3ac359a2fd;anchor=swh:1:rev:c2e91a5341d1aa5978650cb2c22227c7e52997dc">https://archive.softwareheritage.org/swh:1:dir:de294ef532e0e07507488df691f10a229fd29665;origin=https://github.com/ajsederberg/avalanche;visit=swh:1:snp:83b5ae292da441d80eb6e99588c5dd3ac359a2fd;anchor=swh:1:rev:c2e91a5341d1aa5978650cb2c22227c7e52997dc</ext-link></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shew</surname><given-names>WL</given-names></name><name><surname>Clawson</surname><given-names>WP</given-names></name><name><surname>Pobst</surname><given-names>J</given-names></name><name><surname>Karimipanah</surname><given-names>Y</given-names></name><name><surname>Wright</surname><given-names>NC</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Adaptation to sensory input tunes visual cortex to criticality</article-title><source>Nature Physics</source><volume>11</volume><fpage>659</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1038/nphys3370</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>255</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Touboul</surname><given-names>J</given-names></name><name><surname>Destexhe</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Power-law statistics and universal scaling in the absence of criticality</article-title><source>Physical Review. E</source><volume>95</volume><elocation-id>012413</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.95.012413</pub-id><pub-id pub-id-type="pmid">28208383</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89337.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Latham</surname><given-names>Peter</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This paper provides a simple example of a neural-like system that displays criticality, but not for any deep reason; it's just because a population of neurons are driven (independently!) by a slowly varying latent variable, something that is common in the brain. Moreover, criticality does not imply optimal information transmission (one of its proposed functions). The work is likely to have an <bold>important</bold> impact on the study of criticality in neural systems and is <bold>convincingly</bold> supported by the experiments presented.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89337.3.sa1</article-id><title-group><article-title>Joint Public Review</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This paper shows that networks of binary neurons can exhibit power law behavior (including &quot;crackling&quot;, which refers to a particular relationship among the power law exponents) without fine tuning. If, as is standard, we equate power law behavior to criticality, then criticality can arise in networks of neurons without fine tuning. The network model used to show this was extremely simple: a population of completely uncoupled neurons was driven by a small number of slowly varying &quot;hidden&quot; variables (either 1 or 5). This caused the firing rate of every neuron to change slowly over time, in a correlated fashion. Criticality was observed over a large range of couplings, time constants, and average firing rates.</p><p>This paper is extremely important in light of the hypothesis that criticality in the brain is both special, in the sense that it requires fine tuning, and that it leads to optimal information processing. As mentioned above, this paper shows that fine tuning is not required. It also shows that criticality does not imply optimal information transmission. This does not, of course, rule out the above &quot;critical brain&quot; hypothesis. But it does show that simply observing power law behavior is not enough to draw conclusions about either fine tuning or function.</p><p>These authors are not the first to show that slowly varying firing rates can give rise to power law behavior (see, for example, Touboul and Destexhe, 2017; Priesemann and Shriki, 2018). However, to our knowledge they are the first to show crackling, and to compute information transmission in, and out of, the critical state.</p><p><bold>References:</bold></p><p>Touboul and Destexhe, 2017: Touboul J, Destexhe A. Power-law statistics and universal scaling in the absence of criticality. Phys Rev E. 2017 95:012413, 2017.</p><p>Priesemann and Shriki, 2018: Priesemann V, Shriki O. PLOS Comp. Bio. 14:1-29, 2018.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89337.3.sa2</article-id><title-group><article-title>Author Response:</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Morrell</surname><given-names>Mia C</given-names></name><role specific-use="author">Author</role><aff><institution>New York University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Nemenman</surname><given-names>Ilya</given-names></name><role specific-use="author">Author</role><aff><institution>Emory University</institution><addr-line><named-content content-type="city">Atlanta</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Sederberg</surname><given-names>Audrey</given-names></name><role specific-use="author">Author</role><aff><institution>Georgia Institute of Technology</institution><addr-line><named-content content-type="city">Atlanta</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Joint Public Review:</bold></p><p>[…] While this does not rule out criticality in the brain, it decidedly weakens the evidence for it, which was based on the following logic: critical systems give rise to power law behavior; power law behavior is observed in cortical networks; therefore, cortical networks operate near a critical point. Given, as shown in this paper, that power laws can arise from noncritical processes, the logic breaks. Moreover, the authors show that criticality does not imply optimal information transmission (one of its proposed functions). This highlights the necessity for more rigorous analyses to affirm criticality in the brain. In particular, it suggests that attention should be focused on the question &quot;does the brain implement a dynamical latent variable model?&quot;.</p><p>These authors are not the first to show that slowly varying firing rates can give rise to power law behavior (see, for example, Touboul and Destexhe, 2017; Priesemann and Shriki, 2018). However, to our knowledge they are the first to show crackling, and to compute information transmission in the critical state.</p></disp-quote><p>We thank the reviewers for their thoughtful assessment of our paper.</p><p>We would push back on the assessment that our model ‘has nothing to do with criticality,’ and that we observed ‘signatures of criticality [that] emerge through fundamentally non-critical mechanisms.’ This assessment partially stems from the definition of criticality provided in the Public Comment, that ‘criticality is a very specific set of phenomena in physics in which fundamentally local interactions produce unexpected long-range behavior.’</p><p>Our disagreement is largely focused on this definition, which we do not think is a standard definition. Taking the favorite textbook example, the Ising model, criticality is characterized by a set of power-law divergences in thermodynamic quantities (e.g., susceptibility, specific heat, magnetization) at the critical temperature, with exponents of these power laws governed by scaling laws. It is not defined by local interactions. All-to-all Ising model is generally viewed as showing a critical behavior at a certain temperature, even though interactions there are manifestly non-local. It is possible that, by “local” in the definition, the Public Comment meant that interactions are “collective” and among microscopic degrees of freedom. However, that same all-to-all Ising model is mathematically equivalent to the mean-field model, where criticality is achieved through large fluctuations of the mean field, but not through microscopic interactions.</p><p>More commonly, criticality is defined by power laws and scaling relationships that emerge at a critical value of a parameter(s) of the system. That is, criticality is defined by its signatures. What is crucial in all such definitions is that this atypical, critical state requires fine tuning. For example, in the textbook example of the Ising model, a parameter (the temperature) must be tuned to a critical value for critical behavior to appear. In the branching process model that generates avalanche criticality, criticality requires tuning m=1. The key result of our paper is that all signatures expected for avalanche criticality (power laws, crackling, and, as shown below, estimates of the branching rate m), and hence the criticality itself, appear without fine-tuning.</p><p>As we discussed in our introduction, there are a few other instances of signatures of criticality (and hence of criticality itself) emerging without fine-tuning. The first we are aware of was the demonstration of Zipf’s Law (by Schwab, et al. 2014, and Aitchison et al. 2016), a power-law relationship between rank and frequency of states, which was shown to emerge generically in systems driven by a broadly distributed latent variable. A second example, arising from applications of coarse-graining analysis to neural data (cf., Meshulam et al. 2019; also, Morales et al., 2023), was demonstrated in our earlier paper (Morrell et al. 2021). Thus, here we have a third example: the model in this paper generates signatures of criticality in the statistics of avalanches of activity, and it does so without fine-tuning (cf., Fig. 2-3).</p><p>The rate at which these ‘criticality without fine-tuning' examples are piling up may inspire revisiting the requirement of fine-tuning in the definition of criticality, and our ongoing work (Ngampruetikorn et al. 2023) suggests that criticality may be more accurately defined through large fluctuations (variance &gt; 1/N) rather than through fine-tuning or scaling relations.</p><p><bold>References:</bold></p><list list-type="bullet"><list-item><p>Schwab DJ, Nemenman I, Mehta P. “Zipf’s Law and Criticality in Multivariate Data without FineTuning.” Phys Rev Lett. 2014 Aug; doi::101103/PhysRevLett.113.068102,</p></list-item><list-item><p>Aitchison L, Corradi N, Latham PE. “Zipf’s Law Arising Naturally When There Are Underlying, Unobserved Variables.” PLOS Computational biology. 2016 12; 12(12):1-32. doi:10.1371/journal.pcbi.1005110</p></list-item><list-item><p>Meshulam L, Gauthier JL, Brody CD, Tank DW, Bialek W. “Coarse Graining, Fixed Points, and Scaling in a Large Population of Neurons.” Phys Rev Lett. 2019 Oct; doi: 10.1103/PhysRevLett.123.178103.</p></list-item><list-item><p>Morales GB, di Santo S, Muñoz MA. “Quasiuniversal scaling in mouse-brain neuronal activity stems from edge-of-instability critical dynamics.” Proceedings of the National Academy of Sciences. 2023; 120(9):e2208998120.</p></list-item><list-item><p>Morrell MC, Sederberg AJ, Nemenman I. “Latent Dynamical Variables Produce Signatures of Spatiotemporal Criticality in Large Biological Systems.” Phys Rev Lett. 2021 Mar; doi: 10.1103/PhysRevLett.126.118302.</p></list-item><list-item><p>Ngampruetikorn, V., Nemenman, I., Schwab, D., “Extrinsic vs Intrinsic Criticality in Systems with Many Components.” arXiv: arXiv:2309.13898 [physics.bio-ph]</p></list-item></list><disp-quote content-type="editor-comment"><p>Major comments:</p><p>1. For many readers, the essential messages of the paper may not be immediately clear. For example, is the paper criticizing the criticality hypothesis of cortical networks, or does the criticism extend deeper, to the theoretical predictions of &quot;crackling&quot; relationships in physical systems as they can emerge without criticality? Statements like &quot;We show that a system coupled to one or many dynamical latent variables can generate avalanche criticality ...&quot; could be misinterpreted as affirming criticality. A more accurate language is needed; for instance, the paper could state that the model generates relationships observed in critical systems. The paper should provide a clearer conclusion and interpretation of the findings in the context of the criticality hypothesis of cortical dynamics.</p></disp-quote><p>Please see the response to the Public Review, above. To clarify the essential message that the dynamical latent variable model produces avalanche criticality without fine-tuning, we have made revisions to the abstract and introduction. This point was already made in the discussion (first sentence).</p><p>Key sentences changed in the abstract:</p><p>&quot;… We find that populations coupled to multiple latent variables produce critical behavior across a broader parameter range than those coupled to a single, quasi-static latent variable, but in both cases, avalanche criticality is observed without fine-tuning of model parameters. … Our results suggest that avalanche criticality arises in neural systems in which activity is effectively modeled as a population driven by a few dynamical variables and these variables can be inferred from the population activity.&quot;</p><p>In the introduction, we changed the final sentence to read:</p><p>&quot;These results demonstrate how criticality in neural recordings can arise from latent dynamics in neural activity, without need for fine-tuning of network parameters.&quot;</p><disp-quote content-type="editor-comment"><p>2. On lines 97-99, the authors state that &quot;We are agnostic as to the origin of these inputs: they may be externally driven from other brain areas, or they may arise from recurrent dynamics locally&quot;. This idea is also repeated at the beginning of the Summary section. Perhaps being agnostic isn't such a good idea: it's possible that the recurrent dynamics is in a critical regime, which would just push the problem upstream. Presumably you're thinking of recurrent dynamics with slow timescales that's not critical? Or are you happy if it's in the critical regime? This should be clarified.</p></disp-quote><p>We have amended this sentence to clarify that any latent dynamics with large fluctuations would suffice:</p><p>”We are agnostic as to the origin of these inputs: they may be externally driven from other brain areas, or they may arise from large fluctuations in local recurrent dynamics.”</p><disp-quote content-type="editor-comment"><p>3. Even though the model in Equation 2 has been described in a previous publication and the Methods section, more details regarding the origin and justification of this model in the context of cortical networks would be helpful in the Results section. Was it chosen just for simplicity, or was there a deeper reason?</p></disp-quote><p>This model was chosen for its simplicity: there are no direct interactions between neurons, coupling between neurons and latent variables is random, and simulation is straightforward. More complex latent dynamics or non-random structure in the coupling matrices could have been used, but our aim was to explore this model in the simplest setting possible.</p><p>We have revised the Results (“Avalanche scaling in a dynamical latent variable model,” first paragraph) to justify the choice of the model:</p><p>&quot;We study a model of a population of neurons that are not coupled to each other directly but are driven by a small number of dynamical latent variables -- that is, slowly changing inputs that are not themselves measured (Fig.A). We are agnostic as to the origin of these inputs: they may be externally driven from other brain areas, or they may arise from large fluctuations in local recurrent dynamics. The model was chosen for its simplicity, and because we have previously shown that this model with at least about five latent variables can produce power laws under the coarse-graining analysis Morrell2021.&quot;</p><p>We have added the following to the beginning of the Methods section expanding on the reasons for this choice:</p><p>&quot;We study a model from Morrell 2021, originally constructed as a model of large populations of neurons in mouse hippocampus. Neurons are non-interacting, receiving inputs reflective of place-field selectivity as well as input current arising from a random projection from a small number of dynamical latent variables, representing inputs shared across the population of neurons that are not directly measured or controlled. In the current paper, we incorporate only the latent variables (no place variables), and we assume that every cell is coupled to every latent variable with some randomly drawn coupling strength.&quot;</p><disp-quote content-type="editor-comment"><p>4. The Methods section (paragraph starting on line 340) connects the time scale to actual time scales in neuronal systems, stating that &quot;The timescales of latent variables examined range from about 3 seconds to 3000 seconds, assuming 3-ms bins&quot;. While bins of 3 ms are relevant for electrophysiological data from LFPs or high-density EEG/MEG, time scales above 10 seconds are difficult to generate through biophysically clear processes like ionic channels and synaptic transmission. The paper suggests that slow time scales of the latent variables are crucial for obtaining power law behavior resembling criticality. Yet, one way to generate such slow time scales is via critical slowing down, implying that some brain areas providing input to the network under study may operate near criticality. This pushes the problem toward explaining the criticality of those external networks. Hence, discussing potential sources for slow time scales in latent variables is crucial. One possibility you might want to consider is sources external to the organism, which could easily have time scales in the 1-24 hour range.</p></disp-quote><p>As the reviewers note, it is a possibility that slow timescales arise from some other brain area in which dynamics are slow due to critical dynamics, but many other plausible sources exist. These include slowly varying sensory stimuli or external sources, as suggested by the reviewers. It is also possible to generate “effective” slow dynamics from non-critical internal sources. One example, from recordings in awake mice, is the slow change in the level of arousal that occurs on the scale of many seconds to minutes. These changes arise from release of neuromodulators that have broad effects on neural populations and correlations in activity (for a focused review, see Poulet and Crochet, 2019).</p><p>We have added the following sentence to the Methods section where timescales of latent variables was discussed:</p><p>&quot;The timescales of latent variables examined range from about $3$ seconds to $3000$ seconds, assuming $3$-ms bins. Inputs with such timescales may arise from external sources, such as sensory stimuli, or from internal sources, such as changes in physiological state.&quot;</p><disp-quote content-type="editor-comment"><p>5. It is common in neuronal avalanche analysis to calculate the branching parameter using the ratio of events in consecutive bins. Near-critical systems should display values close to 1, especially in simulations without subsampling. Including the estimated values of the branching parameter for the different cases investigated in this study could provide more comprehensive data. While the paper acknowledges that the obtained exponents in the model differ from those in a critical branching process, it would still be beneficial to offer the branching parameter of the observed avalanches for comparison.</p></disp-quote><p>The reviewers requested that the branching parameter be computed in our model. We point out that, for the quasi-stationary latent variables (as in Fig. 3), a branching parameter of 1 is expected because the summed activity at time t+k is, on average, equal to the summed activity at time t, regardless of k. Numerics are consistent with this expectation. Following the methodology for an unbiased estimate of the branching parameter from Wilting and Priesemann (2018), we checked an example set of parameters (epsilon = 8, eta = 3) for quasi-stationary latent fields. We found that the naïve (biased) estimate of the branching parameter was 0.94, and that the unbiased estimator was exp(−1.4⋅10−8) ≈ 0.999999986.</p><p>For faster time scales, it is no longer true that summed activity is constant over time, as the temporal correlations in activity decay exponentially. Using the five-field simulation from Figure 2, we calculated the branching parameter for several values of tau. The biased estimates of m are 0.76 (τ=50), 0.79 (τ=500), and 0.79 (τ=5000). The corrected estimates are 0.98 (τ=50), 0.998 (τ=500), and 0.9998 (τ=5000).</p><disp-quote content-type="editor-comment"><p>6. In the Discussion (l 269), the paper suggests potential differences between networks cultured in vitro and in vivo. While significant differences indeed exist, it's worth noting that exponents consistent with a critical branching process have also been observed in vivo (Petermann et al 2009; Hahn et al. 2010), as well as in large-scale human data.</p></disp-quote><p>We thank the reviewers for pointing out these studies, and we have added the missing one (Hahn et al. 2010) to our reference list. The following was added to the discussion, in the section “Explaining Experimental Exponents:”</p><p>&quot;A subset of the in vivo recordings analyzed from anesthetized cat (Hahn et al. 2010) and macaque monkeys (Petermann et al. 2009) exhibited a size distribution exponent close to 1.5.&quot;</p><p>Along these lines, we noted two additional studies of high relevance that have been published since our initial submission (Capek et al. 2023, Lombardi et al. 2023), and we have added these references to the discussion of experimental exponents.</p><disp-quote content-type="editor-comment"><p>Minor comments:</p><p>1. The term 'latent variable' should be rigorously explained, as it is likely to be unfamiliar to some readers.</p></disp-quote><p>Sentences and clauses have been added to the Introduction, Results and the Methods to clarify the term:</p><p>Intro: “Numerous studies have reported relatively low-dimensional structure in the activity of large populations of neurons [refs], which can be modeled by a population of neurons that are broadly and heterogeneously coupled to multiple dynamical latent (i.e., unobserved) variables.”</p><p>Results: “We studied a population of neurons that are not coupled to each other directly but are driven by a small number of dynamical latent variables -- that is, slowly changing inputs that are not themselves measured.”</p><p>Methods: “Neurons are non-interacting, receiving inputs reflective of place-field selectivity as well as input current reflecting a random projection from a small number of dynamical latent variables, representing inputs shared across the population of neurons that are not directly measured.”</p><disp-quote content-type="editor-comment"><p>2. There's a relatively important typo in the equations: Eq. 2 and Eq. 6 differ by a minus sign in the exponent. Eqs. 3 and 4 use the plus sign, but epsilon_0 on line 198 uses the minus sign. All very confusing until we figured out what was going on. But easy to fix.</p></disp-quote><p>Thank you for catching this. We have made the following corrections:</p><p>1. Figures adopted the sign convention that epsilon &gt; 0, with larger values of epsilon decreasing the activity level. Signs in Eqs. 3 and 4 have been corrected to match.</p><p>2. Equation 5 was missing a minus sign in front of the Hamiltonian. Restoring this minus sign fixed the discrepancy between 2 and 6.</p><p>3. In Eq. 7, the left hand side is zeta'/zeta', which is equal to 1. Maybe it should be zeta'/zeta? Fixed, thank you.</p><disp-quote content-type="editor-comment"><p>Additional comments:</p><p>The authors are free to ignore these; they are meant to improve the paper.</p></disp-quote><p>We are extremely grateful for the close reading of our paper and note the actions taken below.</p><disp-quote content-type="editor-comment"><p>1. We personally would not use the abbreviation DLV; we find abbreviations extremely hard to remember. And DLV is not used that often.</p></disp-quote><p>Done, thank you for the suggestion.</p><disp-quote content-type="editor-comment"><p>2. l 198: epsilon_0 = -log(2^{1/N}-1) was kind of hard to picture -- we had to do a little algebra to make sense of it. Why not write e^{-epsilon_0} = 2^{1/N}-1 \approx log(2)/N, which in turn implies that epsilon_0 ~ log(N)?</p></disp-quote><p>Thank you, good point. We have added a sentence now to better explain:</p><p>&quot;...which is maximized at $\epsilon_0 = - \log (2^{1/N} - 1)$, independent of $J_i$ and $\eta$. After some algebra, we find that $\epsilon_0 \sim \log N$ for large $N$.&quot;</p><disp-quote content-type="editor-comment"><p>3. Typo on l 202: &quot;We plot P_ava as a function of epsilon in Fig. 4B&quot;. 4B --&gt; 4D.</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>4. It would be easier on the reader if the tables were all in one place. It would be even nicer to put the parameters in the figure captions. Or at least N; that one is kind of important.</p></disp-quote><p>Table placement was a Latex issue, which we have now fixed. We also have included links between tables and relevant figures and indicated network size.</p><disp-quote content-type="editor-comment"><p>5. What's x_i in Eqs. 7 and 8?</p></disp-quote><p>We added a sentence of explanation. These are the individual observations of avalanche sizes or durations, depending on what is being fit.</p><disp-quote content-type="editor-comment"><p>6. The latent variables evolve according to an Ornstein-Uhlenbeck process. But we might equally expect oscillations or non-normal behavior coupling dynamical modes, and these are likely to give different behavior with respect to avalanches. It might be worth commenting on this.</p><p>7. The model assumes a normal distribution of the coupling strengths between the latent variables and the binary units. Discussing the potential effects of different types of random coupling could provide interesting insights.</p></disp-quote><p>Both 6 and 7 are interesting questions. At this point, we could speculate that the main results would be qualitatively unchanged, provided dynamics are sufficiently slow and that the distribution of coupling strengths is sufficiently broad (that is, there is variance in the coupling matrix across individual neurons). Further studies would be needed to make these statements more precise.</p><disp-quote content-type="editor-comment"><p>8. In Fig 1, tau_f = 1E4 whereas in Fig 2 tau_f = 5E3. Why the difference?</p></disp-quote><p>For Figure 1, we chose a set of parameters that gave clear scaling. In Figure 2, we saw some value in showing more than one example of scaling, hence different parameters for the examples in Fig 2 than Fig 1. Note that the Fig 1 simulations are represented in Fig. 2 G-J, as the 5-field simulation with tau_F = 1e4.</p></body></sub-article></article>