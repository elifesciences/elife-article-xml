<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">78606</article-id><article-id pub-id-type="doi">10.7554/eLife.78606</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Population codes enable learning from few examples by shaping inductive bias</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-275182"><name><surname>Bordelon</surname><given-names>Blake</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0455-9445</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-149984"><name><surname>Pehlevan</surname><given-names>Cengiz</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9767-6063</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">John A Paulson School of Engineering and Applied Sciences</institution>, <institution>Harvard University</institution>, <addr-line><named-content content-type="city">Cambridge</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-30108"><name><surname>Serre</surname><given-names>Thomas</given-names></name><role>Reviewing editor</role><aff><institution>Brown University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>cpehlevan@seas.harvard.edu</email> (CP);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>16</day><month>12</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e78606</elocation-id><history><date date-type="received"><day>14</day><month>03</month><year>2022</year></date><date date-type="accepted"><day>15</day><month>12</month><year>2022</year></date></history><permissions><copyright-statement>Â© 2022, Bordelon &amp; Pehlevan</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Bordelon &amp; Pehlevan</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-78606-v1.pdf"/><abstract><p>Learning from a limited number of experiences requires suitable inductive biases. To identify how inductive biases are implemented in and shaped by neural codes, we analyze sample-efficient learning of arbitrary stimulus-response maps from arbitrary neural codes with biologically-plausible readouts. We develop an analytical theory that predicts the generalization error of the readout as a function of the number of observed examples. Our theory illustrates in a mathematically precise way how the structure of population codes shapes inductive bias, and how a match between the code and the task is crucial for sample-efficient learning. It elucidates a bias to explain observed data with simple stimulus-response maps. Using recordings from the mouse primary visual cortex, we demonstrate the existence of an efficiency bias towards low frequency orientation discrimination tasks for grating stimuli and low spatial frequency reconstruction tasks for natural images. We reproduce the discrimination bias in a simple model of primary visual cortex, and further show how invariances in the code to certain stimulus variations alter learning performance. We extend our methods to time-dependent neural codes and predict the sample efficiency of readouts from recurrent networks. We observe that many different codes can support the same inductive bias. By analyzing recordings from the mouse primary visual cortex, we demonstrate that biological codes have lower total activity than other codes with identical bias. Finally, we discuss implications of our theory in the context of recent developments in neuroscience and artificial intelligence. Overall, our study provides a concrete method for elucidating inductive biases of the brain and promotes sample-efficient learning as a general normative coding principle.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>DMS-2134157</award-id><principal-award-recipient><name><surname>Bordelon</surname><given-names>Blake</given-names></name><name><surname>Pehlevan</surname><given-names>Cengiz</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>Mouse V1 neuron responses to orientation gratings and preprocessing code were obtained from a publicly available dataset: https://github.com/MouseLand/stringer-et-al-2019, [8, 9].Responses to ImageNet images and preprocessing code were obtained from another publicly available dataset, https://github.com/MouseLand/stringer-pachitariu-et-al-2018b [10, 11].The code generated by the authors for this paper is also available https://github.com/Pehlevan-Group/sample_efficient_pop_codes</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><collab>Carsen Stringer</collab><collab>Marius Pachitariu</collab><collab>Nicholas Steinmetz</collab><collab>Matteo Carandini</collab><collab>Kenneth D. Harris</collab></person-group><year iso-8601-date="2018">2018</year><source>Recordings of ten thousand neurons in visual cortex in response to 2,800 natural images</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25378/janelia.6845348.v4">https://doi.org/10.25378/janelia.6845348.v4</ext-link><comment>https://doi.org/10.25378/janelia.6845348.v4</comment></element-citation><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><collab>Pachitariu</collab><collab>Marius; Michaelos</collab><collab>Michalis; Stringer</collab><collab>Carsen</collab></person-group><year iso-8601-date="2019">2019</year><source>Recordings of ~20,000 neurons from V1 in response to oriented stimuli</source><ext-link ext-link-type="uri" xlink:href="https://figshare.com/articles/dataset/Recordings_of_20_000_neurons_from_V1_in_response_to_oriented_stimuli/8279387">https://figshare.com/articles/dataset/Recordings_of_20_000_neurons_from_V1_in_response_to_oriented_stimuli/8279387</ext-link><comment>https://doi.org/10.25378/janelia.8279387.v3</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-78606-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>